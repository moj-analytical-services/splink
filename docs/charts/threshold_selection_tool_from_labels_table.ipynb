{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `threshold_selection_tool_from_labels_table`\n",
    "\n",
    "!!! info \"At a glance\"\n",
    "    **Useful for:** Selecting an optimal match weight threshold for generating linked clusters.\n",
    "\n",
    "    **API Documentation:** [accuracy_chart_from_labels_table()](../linker.md#splink.linker.Linker.accuracy_chart_from_labels_table)\n",
    "\n",
    "    **What is needed to generate the chart?** A `linker` with some data and a corresponding labelled dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a115ace0f041407e844cf5d528fb0283.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a115ace0f041407e844cf5d528fb0283.vega-embed details,\n",
       "  #altair-viz-a115ace0f041407e844cf5d528fb0283.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a115ace0f041407e844cf5d528fb0283\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a115ace0f041407e844cf5d528fb0283\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a115ace0f041407e844cf5d528fb0283\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": {\"step\": 150}, \"discreteWidth\": {\"step\": 150}}, \"axis\": {\"gridWidth\": 0.5, \"labelFontSize\": 12, \"titleFontSize\": 16}, \"axisX\": {\"format\": \"+\", \"grid\": false, \"offset\": 20, \"values\": {\"expr\": \"[-25,-20,-15,-10,-5,0,5,10,15,20,25]\"}}, \"axisY\": {\"title\": \"Match probability threshold\", \"titleFontSize\": 16}, \"concat\": {\"spacing\": 40}}, \"hconcat\": [{\"vconcat\": [{\"layer\": [{\"layer\": [{\"mark\": {\"type\": \"rule\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 0.3, \"empty\": false}, \"value\": 0}, \"x\": {\"axis\": {\"orient\": \"bottom\"}, \"field\": \"truth_threshold\", \"scale\": {\"nice\": false}, \"title\": null, \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"threshold\", \"select\": {\"type\": \"point\", \"encodings\": [\"x\"], \"fields\": [\"truth_threshold\"], \"nearest\": true, \"on\": \"mouseover\", \"toggle\": false}, \"value\": null}]}, {\"mark\": {\"type\": \"rule\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 0.3, \"empty\": false}, \"value\": 0}, \"y\": {\"axis\": {\"orient\": \"right\"}, \"field\": \"match_probability\", \"title\": \" \", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"prob\", \"select\": {\"type\": \"point\", \"encodings\": [\"y\"], \"fields\": [\"match_probability\"], \"nearest\": true, \"on\": \"mouseover\", \"toggle\": false}}]}]}, {\"layer\": [{\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"fontWeight\": \"bold\", \"xOffset\": 25, \"yOffset\": 10}, \"encoding\": {\"text\": {\"aggregate\": \"min\", \"field\": \"truth_threshold\", \"format\": \"+.2f\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"match_probability\", \"title\": \"Match probability threshold\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"xOffset\": -25, \"yOffset\": -10}, \"encoding\": {\"text\": {\"aggregate\": \"min\", \"field\": \"match_probability\", \"format\": \".3f\"}}, \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}, {\"mark\": {\"type\": \"line\", \"color\": \"red\", \"opacity\": 0.5}}, {\"mark\": {\"type\": \"line\", \"color\": \"green\", \"opacity\": 0.5, \"strokeWidth\": 3}, \"transform\": [{\"filter\": \"datum.truth_threshold >= threshold.truth_threshold\"}]}, {\"mark\": {\"type\": \"point\", \"color\": \"green\", \"size\": 100}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 1, \"empty\": false}, \"value\": 0}}}], \"encoding\": {\"x\": {\"field\": \"truth_threshold\", \"type\": \"quantitative\", \"title\": \"Match weight threshold\", \"axis\": {\"orient\": \"top\"}}, \"y\": {\"field\": \"match_probability\", \"type\": \"quantitative\", \"title\": \"Match probability threshold\", \"axis\": {\"orient\": \"left\", \"titlePadding\": 10}}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"red\", \"fontSize\": 12, \"text\": \"Non-match\", \"x\": 0, \"y\": \"height\", \"yOffset\": 10}, \"data\": {\"values\": [{}]}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"color\": \"green\", \"fontSize\": 12, \"fontWeight\": \"bold\", \"text\": \"Match\", \"x\": \"width\", \"y\": 0, \"yOffset\": -10}, \"data\": {\"values\": [{}]}}], \"description\": \"Match weight vs probability\"}, {\"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"rect\", \"opacity\": 0.5}, \"encoding\": {\"color\": {\"field\": \"count\", \"legend\": null, \"scale\": {\"scheme\": \"reds\", \"zero\": true}, \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": \"datum.predicted == 0\"}]}, {\"mark\": {\"type\": \"rect\", \"opacity\": 0.5}, \"encoding\": {\"color\": {\"field\": \"count\", \"legend\": null, \"scale\": {\"scheme\": \"greens\", \"zero\": true}, \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": \"datum.predicted == 1\"}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"yOffset\": -40}, \"encoding\": {\"color\": {\"condition\": [{\"test\": \"datum.predicted==1 && datum.actual==1\", \"value\": \"darkgreen\"}, {\"test\": \"datum.predicted==0 && datum.actual==0\", \"value\": \"darkred\"}], \"value\": \"black\"}, \"opacity\": {\"condition\": {\"test\": \"datum.predicted != datum.actual\", \"value\": 1}, \"value\": 0.5}, \"text\": {\"field\": \"confusion_label\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"fontSize\": 28, \"fontWeight\": \"bold\", \"yOffset\": 10}, \"encoding\": {\"color\": {\"condition\": [{\"test\": \"datum.predicted==1 && datum.actual==1\", \"value\": \"darkgreen\"}, {\"test\": \"datum.predicted==0 && datum.actual==0\", \"value\": \"darkred\"}], \"value\": \"black\"}, \"text\": {\"field\": \"count\", \"format\": \",\", \"type\": \"nominal\"}}}], \"description\": \"Confusion matrix\", \"encoding\": {\"x\": {\"field\": \"actual\", \"type\": \"nominal\", \"title\": \"Actual\", \"axis\": {\"domain\": false, \"labelAngle\": 0, \"labelExpr\": \"datum.label == 1 ? 'Match' : 'Non-match'\", \"labelFontSize\": 18, \"labelPadding\": 10, \"orient\": \"top\", \"ticks\": false, \"titleAngle\": 0, \"titleFontSize\": 20}, \"sort\": \"-x\"}, \"y\": {\"field\": \"predicted\", \"type\": \"nominal\", \"title\": \"Predicted\", \"axis\": {\"domain\": false, \"labelExpr\": \"datum.label == 1 ? 'Match' : 'Non-match'\", \"labelFontSize\": 18, \"labelPadding\": 10, \"ticks\": false, \"titleAngle\": 0, \"titleFontSize\": 20, \"titlePadding\": -30}, \"sort\": \"-y\"}}, \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"transform\": [{\"filter\": {\"or\": [{\"param\": \"threshold\", \"empty\": false}, {\"and\": [{\"param\": \"threshold\", \"empty\": true}, \"datum.truth_threshold == datum.median_threshold\"]}]}}]}], \"transform\": [{\"fold\": [\"tp\", \"tn\", \"fp\", \"fn\"], \"as\": [\"label\", \"count\"]}, {\"calculate\": \"datum.label === 'tp' ? 'True Positive (TP)' : datum.label === 'tn' ? 'True Negative (TN)' : datum.label === 'fp' ? 'False Positive (FP)' : 'False Negative (FN)'\", \"as\": \"confusion_label\"}, {\"calculate\": \"datum.label === 'tp' || datum.label === 'fp' ? 1 : 0\", \"as\": \"predicted\"}, {\"calculate\": \"datum.label === 'tp' || datum.label === 'fn' ? 1 : 0\", \"as\": \"actual\"}, {\"joinaggregate\": [{\"op\": \"median\", \"field\": \"truth_threshold\", \"as\": \"median_threshold\"}]}]}]}, {\"layer\": [{\"layer\": [{\"mark\": {\"type\": \"point\", \"size\": 100}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 1, \"empty\": false}, \"value\": 0}, \"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".3f\", \"title\": \"Match weight threshold\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".3%\", \"title\": \"Match probability threshold\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"title\": \"Precision\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"title\": \"Recall (TPR)\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FPR\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"orient\": \"top\"}, \"field\": \"truth_threshold\", \"title\": \"Match weight threshold\"}}, \"params\": [{\"name\": \"metric\", \"select\": {\"type\": \"point\", \"fields\": [\"metric\"]}, \"bind\": \"legend\", \"value\": [{\"metric\": \"precision\"}, {\"metric\": \"recall\"}]}, {\"name\": \"threshold\", \"select\": {\"type\": \"point\", \"encodings\": [\"x\"], \"fields\": [\"truth_threshold\"], \"nearest\": true, \"on\": \"mouseover\", \"toggle\": false}, \"value\": null}], \"transform\": [{\"filter\": {\"param\": \"metric\", \"empty\": true}}]}, {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"metric\", \"value\": 1}, \"value\": 0.1}, \"x\": {\"axis\": {\"orient\": \"bottom\"}, \"field\": \"truth_threshold\", \"title\": null}}}], \"encoding\": {\"color\": {\"field\": \"metric\", \"type\": \"nominal\", \"sort\": [\"precision\", \"recall\", \"f1\"], \"title\": [\"Performance\", \"Metric\"], \"legend\": {\"fillColor\": \"whitesmoke\", \"labelExpr\": \"{'precision': 'Precision (PPV)', 'recall': 'Recall (TPR)', 'specificity': 'Specificity (TNR)', 'accuracy': 'Accuracy', 'npv': 'NPV', 'f1': 'F1', 'f2': 'F2', 'f0_5': 'F0.5', 'p4': 'P4', 'phi': '\\u03c6 (MCC)'}[datum.value]\", \"labelFontSize\": 14, \"legendX\": 800, \"legendY\": 160, \"orient\": \"none\", \"padding\": 10, \"titleFontSize\": 16, \"titlePadding\": 15}}, \"x\": {\"type\": \"quantitative\", \"field\": \"truth_threshold\"}, \"y\": {\"field\": \"value\", \"type\": \"quantitative\", \"axis\": {\"labelFontSize\": 12, \"title\": \"Performance metric score\", \"titleFontSize\": 18, \"titlePadding\": 10, \"values\": {\"expr\": \"[0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]\"}}, \"scale\": {\"domain\": [0.5, 1]}}}}, {\"layer\": [{\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"x\": {\"field\": \"truth_threshold\", \"title\": null, \"type\": \"quantitative\"}}}, {\"layer\": [{\"mark\": {\"type\": \"rect\", \"fill\": \"whitesmoke\", \"x\": 200, \"x2\": 10, \"y2Offset\": 20, \"yOffset\": -20}, \"encoding\": {\"y2\": {\"field\": \"score_index\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"baseline\": \"middle\", \"fontSize\": 16, \"x\": 200, \"xOffset\": -10}}], \"encoding\": {\"color\": {\"field\": \"metric\", \"sort\": [\"precision\", \"recall\", \"f1\"]}, \"text\": {\"field\": \"y_text\"}, \"y\": {\"field\": \"score_index\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"metric\", \"empty\": true}}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"fontWeight\": \"bold\", \"xOffset\": 20, \"y\": 0, \"yOffset\": -10}, \"encoding\": {\"text\": {\"condition\": {\"param\": \"threshold\", \"aggregate\": \"min\", \"empty\": false, \"field\": \"truth_threshold\", \"format\": \"+.2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"field\": \"truth_threshold\", \"type\": \"quantitative\"}}}], \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}], \"description\": \"Accuracy chart\", \"height\": 700, \"transform\": [{\"fold\": [\"precision\", \"recall\", \"f1\"], \"as\": [\"metric\", \"value\"]}, {\"calculate\": \"0.6375 - 0.025*indexof(['precision', 'recall', 'f1'], datum.metric)\", \"as\": \"score_index\"}, {\"calculate\": \"{'precision': 'Precision (PPV)', 'recall': 'Recall (TPR)', 'specificity': 'Specificity (TNR)', 'accuracy': 'Accuracy', 'npv': 'NPV', 'f1': 'F1', 'f2': 'F2', 'f0_5': 'F0.5', 'p4': 'P4', 'phi': '\\u03c6 (MCC)'}[datum.metric]\", \"as\": \"metric_text\"}, {\"calculate\": \"datum.metric_text + ' = ' + format(datum.value, ',.3g')\", \"as\": \"y_text\"}], \"width\": 500}], \"data\": {\"name\": \"data-786b7aee5871a4608d75627e88f0f74b\"}, \"title\": {\"text\": \"Match Threshold Selection Tool\", \"anchor\": \"middle\", \"baseline\": \"line-bottom\", \"fontSize\": 28, \"subtitle\": [\"Hover over either line graph to show Confusion Matrix (bottom left) and selected performance metrics (right).\", \"\", \"Click a legend value to show a specific evaluation metric. Shift + Click to show multiple metrics\"], \"subtitleFontSize\": 14, \"subtitleFontStyle\": \"italic\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-786b7aee5871a4608d75627e88f0f74b\": [{\"truth_threshold\": -31.584422057499875, \"match_probability\": 3.1055717311745525e-10, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 0.0, \"fp\": 1145.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0, \"precision\": 0.6394836272040302, \"recall\": 1.0, \"specificity\": 0.0, \"npv\": 1.0, \"accuracy\": 0.6394836272040302, \"f1\": 0.7801037065488765, \"f2\": 0.8986725663716815, \"f0_5\": 0.6891754326433661, \"p4\": 0.0, \"phi\": 0.0}, {\"truth_threshold\": -30.47994537230207, \"match_probability\": 6.677627306671843e-10, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 47.0, \"fp\": 1098.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.04104803493449782, \"fp_rate\": 0.9589519650655022, \"fn_rate\": 0.0, \"precision\": 0.6490891658676894, \"recall\": 1.0, \"specificity\": 0.04104803493449782, \"npv\": 1.0, \"accuracy\": 0.6542821158690176, \"f1\": 0.7872093023255814, \"f2\": 0.9024260197280725, \"f0_5\": 0.6980820787791298, \"p4\": 0.14335724197588712, \"phi\": 0.163229393052051}, {\"truth_threshold\": -29.510432000806542, \"match_probability\": 1.3075996094275913e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 154.0, \"fp\": 991.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.13449781659388646, \"fp_rate\": 0.8655021834061135, \"fn_rate\": 0.0, \"precision\": 0.672071475843812, \"recall\": 1.0, \"specificity\": 0.13449781659388646, \"npv\": 1.0, \"accuracy\": 0.6879722921914357, \"f1\": 0.8038788838313873, \"f2\": 0.9110891799748789, \"f0_5\": 0.7192435724909696, \"p4\": 0.3661996978718435, \"phi\": 0.3006528664357345}, {\"truth_threshold\": -29.50570129733988, \"match_probability\": 1.3118943625608392e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 185.0, \"fp\": 960.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.1615720524017467, \"fp_rate\": 0.8384279475982532, \"fn_rate\": 0.0, \"precision\": 0.679037111334002, \"recall\": 1.0, \"specificity\": 0.1615720524017467, \"npv\": 1.0, \"accuracy\": 0.6977329974811083, \"f1\": 0.8088410991636799, \"f2\": 0.9136302294197031, \"f0_5\": 0.7256162915326902, \"p4\": 0.4139988430708206, \"phi\": 0.3312301612703591}, {\"truth_threshold\": -29.08247912902825, \"match_probability\": 1.7591441690666615e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 230.0, \"fp\": 915.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.20087336244541484, \"fp_rate\": 0.7991266375545851, \"fn_rate\": 0.0, \"precision\": 0.6894093686354379, \"recall\": 1.0, \"specificity\": 0.20087336244541484, \"npv\": 1.0, \"accuracy\": 0.7119017632241813, \"f1\": 0.8161543098251959, \"f2\": 0.9173441734417345, \"f0_5\": 0.7350705754614549, \"p4\": 0.4745646484233625, \"phi\": 0.3721343547419009}, {\"truth_threshold\": -28.405955315608736, \"match_probability\": 2.8116120327999e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 238.0, \"fp\": 907.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.20786026200873362, \"fp_rate\": 0.7921397379912664, \"fn_rate\": 0.0, \"precision\": 0.691286589516678, \"recall\": 1.0, \"specificity\": 0.20786026200873362, \"npv\": 1.0, \"accuracy\": 0.7144206549118388, \"f1\": 0.8174683034815858, \"f2\": 0.9180075935635509, \"f0_5\": 0.7367771892911558, \"p4\": 0.48440797245142486, \"phi\": 0.37906597264864145}, {\"truth_threshold\": -28.401224612142073, \"match_probability\": 2.820846648260217e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 311.0, \"fp\": 834.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.27161572052401745, \"fp_rate\": 0.7283842794759825, \"fn_rate\": 0.0, \"precision\": 0.7089005235602094, \"recall\": 1.0, \"specificity\": 0.27161572052401745, \"npv\": 1.0, \"accuracy\": 0.7374055415617129, \"f1\": 0.8296568627450981, \"f2\": 0.9241059241059241, \"f0_5\": 0.7527240382477207, \"p4\": 0.5639913638847518, \"phi\": 0.43880351694882697}, {\"truth_threshold\": -27.431711240646546, \"match_probability\": 5.523725416998398e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 338.0, \"fp\": 807.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.29519650655021834, \"fp_rate\": 0.7048034934497817, \"fn_rate\": 0.0, \"precision\": 0.7156448202959831, \"recall\": 1.0, \"specificity\": 0.29519650655021834, \"npv\": 1.0, \"accuracy\": 0.7459068010075567, \"f1\": 0.8342575477510783, \"f2\": 0.9263820470717022, \"f0_5\": 0.7587984756780991, \"p4\": 0.5895431109164512, \"phi\": 0.4596257726478499}, {\"truth_threshold\": -27.008489072334918, \"match_probability\": 7.406868740496471e-09, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 368.0, \"fp\": 777.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.32139737991266376, \"fp_rate\": 0.6786026200873363, \"fn_rate\": 0.0, \"precision\": 0.7232905982905983, \"recall\": 1.0, \"specificity\": 0.32139737991266376, \"npv\": 1.0, \"accuracy\": 0.7553526448362721, \"f1\": 0.8394296342219467, \"f2\": 0.9289242590559824, \"f0_5\": 0.7656638769509161, \"p4\": 0.6159547804695636, \"phi\": 0.48214489855857784}, {\"truth_threshold\": -26.32723455544874, \"match_probability\": 1.1877162291138644e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 374.0, \"fp\": 771.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.3266375545851528, \"fp_rate\": 0.6733624454148471, \"fn_rate\": 0.0, \"precision\": 0.7248394004282656, \"recall\": 1.0, \"specificity\": 0.3266375545851528, \"npv\": 1.0, \"accuracy\": 0.7572418136020151, \"f1\": 0.840471756672874, \"f2\": 0.9294343767160901, \"f0_5\": 0.7670518921368683, \"p4\": 0.6210106586824145, \"phi\": 0.48657966379911216}, {\"truth_threshold\": -25.875801628024018, \"match_probability\": 1.6240804594658213e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2031.0, \"tn\": 390.0, \"fp\": 755.0, \"fn\": 0.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 1.0, \"tn_rate\": 0.3406113537117904, \"fp_rate\": 0.6593886462882096, \"fn_rate\": 0.0, \"precision\": 0.7290021536252692, \"recall\": 1.0, \"specificity\": 0.3406113537117904, \"npv\": 1.0, \"accuracy\": 0.7622795969773299, \"f1\": 0.8432634419763338, \"f2\": 0.9307974335472043, \"f0_5\": 0.7707779886148007, \"p4\": 0.6341520531041999, \"phi\": 0.49830353240280517}, {\"truth_threshold\": -25.019294831869566, \"match_probability\": 2.940639404527941e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2030.0, \"tn\": 442.0, \"fp\": 703.0, \"fn\": 1.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999507631708518, \"tn_rate\": 0.3860262008733624, \"fp_rate\": 0.6139737991266375, \"fn_rate\": 0.0004923682914820286, \"precision\": 0.7427735089645079, \"recall\": 0.999507631708518, \"specificity\": 0.3860262008733624, \"npv\": 0.9977426636568849, \"accuracy\": 0.7783375314861462, \"f1\": 0.852225020990764, \"f2\": 0.9348807221147647, \"f0_5\": 0.7829977628635347, \"p4\": 0.673450761521903, \"phi\": 0.5343164213456207}, {\"truth_threshold\": -24.77132494282621, \"match_probability\": 3.4921118442642666e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2030.0, \"tn\": 478.0, \"fp\": 667.0, \"fn\": 1.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999507631708518, \"tn_rate\": 0.41746724890829695, \"fp_rate\": 0.5825327510917031, \"fn_rate\": 0.0004923682914820286, \"precision\": 0.7526881720430108, \"recall\": 0.999507631708518, \"specificity\": 0.41746724890829695, \"npv\": 0.9979123173277662, \"accuracy\": 0.7896725440806045, \"f1\": 0.8587140439932318, \"f2\": 0.9379909435357175, \"f0_5\": 0.7917934316249318, \"p4\": 0.6985004059960724, \"phi\": 0.5594475394943681}, {\"truth_threshold\": -24.668064476201067, \"match_probability\": 3.751220917114142e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2030.0, \"tn\": 542.0, \"fp\": 603.0, \"fn\": 1.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999507631708518, \"tn_rate\": 0.4733624454148472, \"fp_rate\": 0.5266375545851528, \"fn_rate\": 0.0004923682914820286, \"precision\": 0.7709836688188378, \"recall\": 0.999507631708518, \"specificity\": 0.4733624454148472, \"npv\": 0.998158379373849, \"accuracy\": 0.809823677581864, \"f1\": 0.8704974271012007, \"f2\": 0.9435716277772613, \"f0_5\": 0.8079280426649685, \"p4\": 0.739108120744415, \"phi\": 0.6030789829265308}, {\"truth_threshold\": -23.91481814667176, \"match_probability\": 6.322988173956573e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2030.0, \"tn\": 544.0, \"fp\": 601.0, \"fn\": 1.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999507631708518, \"tn_rate\": 0.47510917030567684, \"fp_rate\": 0.5248908296943231, \"fn_rate\": 0.0004923682914820286, \"precision\": 0.7715697453439757, \"recall\": 0.999507631708518, \"specificity\": 0.47510917030567684, \"npv\": 0.998165137614679, \"accuracy\": 0.8104534005037783, \"f1\": 0.8708708708708709, \"f2\": 0.9437470943747094, \"f0_5\": 0.8084428514536042, \"p4\": 0.7403062397642433, \"phi\": 0.6044246094829422}, {\"truth_threshold\": -23.801811571330685, \"match_probability\": 6.838183270883711e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2030.0, \"tn\": 593.0, \"fp\": 552.0, \"fn\": 1.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999507631708518, \"tn_rate\": 0.5179039301310043, \"fp_rate\": 0.4820960698689956, \"fn_rate\": 0.0004923682914820286, \"precision\": 0.7862122385747483, \"recall\": 0.999507631708518, \"specificity\": 0.5179039301310043, \"npv\": 0.9983164983164983, \"accuracy\": 0.8258816120906801, \"f1\": 0.8801213960546282, \"f2\": 0.9480665047636839, \"f0_5\": 0.8212638562990533, \"p4\": 0.7684977158900097, \"phi\": 0.6371218400454403}, {\"truth_threshold\": -23.797080867864025, \"match_probability\": 6.860642980140474e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2030.0, \"tn\": 605.0, \"fp\": 540.0, \"fn\": 1.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999507631708518, \"tn_rate\": 0.5283842794759825, \"fp_rate\": 0.47161572052401746, \"fn_rate\": 0.0004923682914820286, \"precision\": 0.7898832684824902, \"recall\": 0.999507631708518, \"specificity\": 0.5283842794759825, \"npv\": 0.9983498349834984, \"accuracy\": 0.8296599496221663, \"f1\": 0.8824168658987177, \"f2\": 0.9491303534692351, \"f0_5\": 0.8244659247827146, \"p4\": 0.7750860466051922, \"phi\": 0.6450595937179376}, {\"truth_threshold\": -23.373858699552397, \"match_probability\": 9.19956679600327e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 646.0, \"fp\": 499.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.5641921397379913, \"fp_rate\": 0.43580786026200874, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8026107594936709, \"recall\": 0.999015263417036, \"specificity\": 0.5641921397379913, \"npv\": 0.9969135802469136, \"accuracy\": 0.8422544080604534, \"f1\": 0.8901074797104628, \"f2\": 0.9524033045437477, \"f0_5\": 0.8354607592851849, \"p4\": 0.7964222386649716, \"phi\": 0.6710424928009643}, {\"truth_threshold\": -23.373065878246585, \"match_probability\": 9.204623731891755e-08, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 654.0, \"fp\": 491.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.5711790393013101, \"fp_rate\": 0.42882096069868997, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8051587301587302, \"recall\": 0.999015263417036, \"specificity\": 0.5711790393013101, \"npv\": 0.9969512195121951, \"accuracy\": 0.8447732997481109, \"f1\": 0.8916721599648428, \"f2\": 0.953119128147313, \"f0_5\": 0.837668235488399, \"p4\": 0.8005124134634918, \"phi\": 0.6762828723663352}, {\"truth_threshold\": -22.945304775176233, \"match_probability\": 1.2381548102860292e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 660.0, \"fp\": 485.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.5764192139737991, \"fp_rate\": 0.42358078602620086, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8070803500397773, \"recall\": 0.999015263417036, \"specificity\": 0.5764192139737991, \"npv\": 0.9969788519637462, \"accuracy\": 0.8466624685138538, \"f1\": 0.8928492849284928, \"f2\": 0.9536567023876669, \"f0_5\": 0.8393315131959957, \"p4\": 0.8035519403165537, \"phi\": 0.6802083406546773}, {\"truth_threshold\": -22.94057407170957, \"match_probability\": 1.2422214745454855e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 669.0, \"fp\": 476.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.5842794759825327, \"fp_rate\": 0.41572052401746723, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8099800399201597, \"recall\": 0.999015263417036, \"specificity\": 0.5842794759825327, \"npv\": 0.9970193740685543, \"accuracy\": 0.8494962216624685, \"f1\": 0.894620811287478, \"f2\": 0.9544642017122965, \"f0_5\": 0.8418388515475894, \"p4\": 0.8080672122832793, \"phi\": 0.6860892892897772}, {\"truth_threshold\": -22.69733488613288, \"match_probability\": 1.4703519903945135e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 704.0, \"fp\": 441.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.6148471615720524, \"fp_rate\": 0.3851528384279476, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8214574898785425, \"recall\": 0.999015263417036, \"specificity\": 0.6148471615720524, \"npv\": 0.9971671388101983, \"accuracy\": 0.8605163727959698, \"f1\": 0.9015774272383915, \"f2\": 0.9576175193505758, \"f0_5\": 0.8517336915456301, \"p4\": 0.8251513528353357, \"phi\": 0.7088884959728592}, {\"truth_threshold\": -22.69260418266622, \"match_probability\": 1.475181295824806e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 735.0, \"fp\": 410.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.6419213973799127, \"fp_rate\": 0.35807860262008734, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8318983189831898, \"recall\": 0.999015263417036, \"specificity\": 0.6419213973799127, \"npv\": 0.9972862957937585, \"accuracy\": 0.8702770780856424, \"f1\": 0.9078299776286354, \"f2\": 0.960427908738048, \"f0_5\": 0.8606939848986171, \"p4\": 0.8397010822592479, \"phi\": 0.7290094774276542}, {\"truth_threshold\": -22.517351903397945, \"match_probability\": 1.6657183950415448e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 749.0, \"fp\": 396.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.6541484716157205, \"fp_rate\": 0.34585152838427946, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8367010309278351, \"recall\": 0.999015263417036, \"specificity\": 0.6541484716157205, \"npv\": 0.9973368841544608, \"accuracy\": 0.8746851385390428, \"f1\": 0.9106822262118492, \"f2\": 0.9617025310455968, \"f0_5\": 0.8648026596198107, \"p4\": 0.8461076357416938, \"phi\": 0.7380808355282539}, {\"truth_threshold\": -22.26858919304878, \"match_probability\": 1.9791859797416093e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 755.0, \"fp\": 390.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.6593886462882096, \"fp_rate\": 0.3406113537117904, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8387763538652335, \"recall\": 0.999015263417036, \"specificity\": 0.6593886462882096, \"npv\": 0.9973579920739762, \"accuracy\": 0.8765743073047859, \"f1\": 0.9119101123595506, \"f2\": 0.9622498340130893, \"f0_5\": 0.8665755530878961, \"p4\": 0.8488236725000513, \"phi\": 0.741966388999673}, {\"truth_threshold\": -21.840828089978427, \"match_probability\": 2.6622908476220173e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 760.0, \"fp\": 385.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.6637554585152838, \"fp_rate\": 0.33624454148471616, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8405136702568351, \"recall\": 0.999015263417036, \"specificity\": 0.6637554585152838, \"npv\": 0.9973753280839895, \"accuracy\": 0.8781486146095718, \"f1\": 0.9129358830146231, \"f2\": 0.9627063959005504, \"f0_5\": 0.8680585265679815, \"p4\": 0.8510738112147038, \"phi\": 0.7452035267827821}, {\"truth_threshold\": -21.836097386511764, \"match_probability\": 2.671035021938051e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 777.0, \"fp\": 368.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.6786026200873363, \"fp_rate\": 0.32139737991266376, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8464747601168127, \"recall\": 0.999015263417036, \"specificity\": 0.6786026200873363, \"npv\": 0.9974326059050064, \"accuracy\": 0.8835012594458438, \"f1\": 0.9164408310749774, \"f2\": 0.9642619522859044, \"f0_5\": 0.873138824339444, \"p4\": 0.8586369498629696, \"phi\": 0.7562054768629057}, {\"truth_threshold\": -21.723090811170692, \"match_probability\": 2.888670071340877e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 844.0, \"fp\": 301.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.737117903930131, \"fp_rate\": 0.262882096069869, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.8708154506437769, \"recall\": 0.999015263417036, \"specificity\": 0.737117903930131, \"npv\": 0.9976359338061466, \"accuracy\": 0.9045969773299748, \"f1\": 0.930520522815868, \"f2\": 0.9704419361010139, \"f0_5\": 0.893753854285966, \"p4\": 0.8872446496778739, \"phi\": 0.7995597965894448}, {\"truth_threshold\": -21.294345118086593, \"match_probability\": 3.888330863650323e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2029.0, \"tn\": 851.0, \"fp\": 294.0, \"fn\": 2.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.999015263417036, \"tn_rate\": 0.743231441048035, \"fp_rate\": 0.25676855895196504, \"fn_rate\": 0.0009847365829640572, \"precision\": 0.87343951786483, \"recall\": 0.999015263417036, \"specificity\": 0.743231441048035, \"npv\": 0.9976553341148886, \"accuracy\": 0.906801007556675, \"f1\": 0.9320165365181442, \"f2\": 0.9710921795730831, \"f0_5\": 0.8959639671465159, \"p4\": 0.890132946764072, \"phi\": 0.8040940760622696}, {\"truth_threshold\": -20.866584015016237, \"match_probability\": 5.23036596594003e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 851.0, \"fp\": 294.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.743231441048035, \"fp_rate\": 0.25676855895196504, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8733850129198967, \"recall\": 0.9985228951255539, \"specificity\": 0.743231441048035, \"npv\": 0.9964871194379391, \"accuracy\": 0.9064861460957179, \"f1\": 0.9317711922811854, \"f2\": 0.9707064905226881, \"f0_5\": 0.8958388550225285, \"p4\": 0.8897883899656822, \"phi\": 0.8032629868810032}, {\"truth_threshold\": -20.618614125972883, \"match_probability\": 6.211241412505773e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 864.0, \"fp\": 281.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.754585152838428, \"fp_rate\": 0.24541484716157205, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8783022953659593, \"recall\": 0.9985228951255539, \"specificity\": 0.754585152838428, \"npv\": 0.9965397923875432, \"accuracy\": 0.9105793450881612, \"f1\": 0.9345622119815669, \"f2\": 0.9719160356560913, \"f0_5\": 0.8999733735688293, \"p4\": 0.8951062668963445, \"phi\": 0.811696135869067}, {\"truth_threshold\": -20.44336184670461, \"match_probability\": 7.013496221273128e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 871.0, \"fp\": 274.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.7606986899563318, \"fp_rate\": 0.23930131004366811, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8809730668983493, \"recall\": 0.9985228951255539, \"specificity\": 0.7606986899563318, \"npv\": 0.9965675057208238, \"accuracy\": 0.9127833753148614, \"f1\": 0.9360720055388876, \"f2\": 0.972568578553616, \"f0_5\": 0.9022154995996086, \"p4\": 0.8979455619346578, \"phi\": 0.8162400042374757}, {\"truth_threshold\": -20.43863114323795, \"match_probability\": 7.036531723500859e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 872.0, \"fp\": 273.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.7615720524017467, \"fp_rate\": 0.23842794759825328, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8813559322033898, \"recall\": 0.9985228951255539, \"specificity\": 0.7615720524017467, \"npv\": 0.9965714285714286, \"accuracy\": 0.9130982367758187, \"f1\": 0.9362880886426593, \"f2\": 0.9726618705035971, \"f0_5\": 0.9025367156208278, \"p4\": 0.8983498229122852, \"phi\": 0.81688931393483}, {\"truth_threshold\": -20.194599136355446, \"match_probability\": 8.333348562680092e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 874.0, \"fp\": 271.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.7633187772925765, \"fp_rate\": 0.2366812227074236, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8821226620269682, \"recall\": 0.9985228951255539, \"specificity\": 0.7633187772925765, \"npv\": 0.9965792474344356, \"accuracy\": 0.913727959697733, \"f1\": 0.9367205542725173, \"f2\": 0.9728485081070709, \"f0_5\": 0.9031798343279593, \"p4\": 0.8991573405625541, \"phi\": 0.8181880787820613}, {\"truth_threshold\": -20.189868432888787, \"match_probability\": 8.360719054928763e-07, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 877.0, \"fp\": 268.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.765938864628821, \"fp_rate\": 0.23406113537117904, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8832752613240418, \"recall\": 0.9985228951255539, \"specificity\": 0.765938864628821, \"npv\": 0.9965909090909091, \"accuracy\": 0.9146725440806045, \"f1\": 0.93737000231107, \"f2\": 0.9731285988483686, \"f0_5\": 0.9041462327240303, \"p4\": 0.9003661213299434, \"phi\": 0.8201365989783385}, {\"truth_threshold\": -19.76210732981843, \"match_probability\": 1.124637156120077e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 878.0, \"fp\": 267.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.7668122270742358, \"fp_rate\": 0.2331877729257642, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8836601307189542, \"recall\": 0.9985228951255539, \"specificity\": 0.7668122270742358, \"npv\": 0.996594778660613, \"accuracy\": 0.9149874055415617, \"f1\": 0.9375866851595007, \"f2\": 0.973221998272387, \"f0_5\": 0.9044688252609044, \"p4\": 0.9007683867217675, \"phi\": 0.8207862076308152}, {\"truth_threshold\": -19.310674402393712, \"match_probability\": 1.5378256503968125e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2028.0, \"tn\": 893.0, \"fp\": 252.0, \"fn\": 3.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9985228951255539, \"tn_rate\": 0.7799126637554585, \"fp_rate\": 0.2200873362445415, \"fn_rate\": 0.0014771048744460858, \"precision\": 0.8894736842105263, \"recall\": 0.9985228951255539, \"specificity\": 0.7799126637554585, \"npv\": 0.9966517857142857, \"accuracy\": 0.9197103274559194, \"f1\": 0.940848990953375, \"f2\": 0.9746251441753172, \"f0_5\": 0.9093354856066721, \"p4\": 0.9067634212644065, \"phi\": 0.8305369199617925}, {\"truth_threshold\": -19.207413935768564, \"match_probability\": 1.6519296519182332e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2024.0, \"tn\": 932.0, \"fp\": 213.0, \"fn\": 7.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9965534219596258, \"tn_rate\": 0.8139737991266376, \"fp_rate\": 0.18602620087336244, \"fn_rate\": 0.0034465780403741997, \"precision\": 0.9047831917746982, \"recall\": 0.9965534219596258, \"specificity\": 0.8139737991266376, \"npv\": 0.9925452609158679, \"accuracy\": 0.9307304785894207, \"f1\": 0.9484536082474226, \"f2\": 0.9767396969404497, \"f0_5\": 0.9217597231077511, \"p4\": 0.920651963837052, \"phi\": 0.8528242123444439}, {\"truth_threshold\": -18.559422858557706, \"match_probability\": 2.5885460364314582e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2024.0, \"tn\": 933.0, \"fp\": 212.0, \"fn\": 7.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9965534219596258, \"tn_rate\": 0.8148471615720524, \"fp_rate\": 0.1851528384279476, \"fn_rate\": 0.0034465780403741997, \"precision\": 0.9051878354203936, \"recall\": 0.9965534219596258, \"specificity\": 0.8148471615720524, \"npv\": 0.9925531914893617, \"accuracy\": 0.9310453400503779, \"f1\": 0.9486758846965081, \"f2\": 0.9768339768339769, \"f0_5\": 0.9220956719817768, \"p4\": 0.9210375470467499, \"phi\": 0.8534796969435791}, {\"truth_threshold\": -18.364641086544616, \"match_probability\": 2.9627218925769356e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2024.0, \"tn\": 935.0, \"fp\": 210.0, \"fn\": 7.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9965534219596258, \"tn_rate\": 0.8165938864628821, \"fp_rate\": 0.18340611353711792, \"fn_rate\": 0.0034465780403741997, \"precision\": 0.9059982094897046, \"recall\": 0.9965534219596258, \"specificity\": 0.8165938864628821, \"npv\": 0.9925690021231423, \"accuracy\": 0.9316750629722922, \"f1\": 0.9491207502930832, \"f2\": 0.977022591233829, \"f0_5\": 0.9227683049147443, \"p4\": 0.9218078772137334, \"phi\": 0.8547909156979293}, {\"truth_threshold\": -18.236831961530868, \"match_probability\": 3.2371673228053025e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2024.0, \"tn\": 936.0, \"fp\": 209.0, \"fn\": 7.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9965534219596258, \"tn_rate\": 0.8174672489082969, \"fp_rate\": 0.18253275109170305, \"fn_rate\": 0.0034465780403741997, \"precision\": 0.9064039408866995, \"recall\": 0.9965534219596258, \"specificity\": 0.8174672489082969, \"npv\": 0.9925768822905621, \"accuracy\": 0.9319899244332494, \"f1\": 0.949343339587242, \"f2\": 0.9771169257507, \"f0_5\": 0.9231049895101706, \"p4\": 0.9221926258236366, \"phi\": 0.8554466510426889}, {\"truth_threshold\": -18.206197717195906, \"match_probability\": 3.3066402210399875e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2024.0, \"tn\": 938.0, \"fp\": 207.0, \"fn\": 7.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9965534219596258, \"tn_rate\": 0.8192139737991266, \"fp_rate\": 0.18078602620087336, \"fn_rate\": 0.0034465780403741997, \"precision\": 0.9072164948453608, \"recall\": 0.9965534219596258, \"specificity\": 0.8192139737991266, \"npv\": 0.9925925925925926, \"accuracy\": 0.9326196473551638, \"f1\": 0.9497888315344909, \"f2\": 0.9773056494447127, \"f0_5\": 0.923779096303058, \"p4\": 0.9229612942086429, \"phi\": 0.8567583766379636}, {\"truth_threshold\": -18.11587837619545, \"match_probability\": 3.520267629626552e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2011.0, \"tn\": 982.0, \"fp\": 163.0, \"fn\": 20.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9901526341703595, \"tn_rate\": 0.8576419213973799, \"fp_rate\": 0.1423580786026201, \"fn_rate\": 0.009847365829640572, \"precision\": 0.9250229990800368, \"recall\": 0.9901526341703595, \"specificity\": 0.8576419213973799, \"npv\": 0.9800399201596807, \"accuracy\": 0.9423803526448362, \"f1\": 0.9564803804994054, \"f2\": 0.9764031850844824, \"f0_5\": 0.9373543395171063, \"p4\": 0.9351576022854229, \"phi\": 0.8759608526513483}, {\"truth_threshold\": -17.591420678036428, \"match_probability\": 5.063519776128294e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2011.0, \"tn\": 983.0, \"fp\": 162.0, \"fn\": 20.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9901526341703595, \"tn_rate\": 0.8585152838427947, \"fp_rate\": 0.14148471615720523, \"fn_rate\": 0.009847365829640572, \"precision\": 0.9254486884491486, \"recall\": 0.9901526341703595, \"specificity\": 0.8585152838427947, \"npv\": 0.9800598205383848, \"accuracy\": 0.9426952141057935, \"f1\": 0.9567078972407231, \"f2\": 0.9764980091288725, \"f0_5\": 0.9377040007460599, \"p4\": 0.9355303259758452, \"phi\": 0.8766276410572766}, {\"truth_threshold\": -17.395724301910878, \"match_probability\": 5.799127673684621e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2011.0, \"tn\": 984.0, \"fp\": 161.0, \"fn\": 20.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9901526341703595, \"tn_rate\": 0.8593886462882097, \"fp_rate\": 0.1406113537117904, \"fn_rate\": 0.009847365829640572, \"precision\": 0.9258747697974218, \"recall\": 0.9901526341703595, \"specificity\": 0.8593886462882097, \"npv\": 0.9800796812749004, \"accuracy\": 0.9430100755667506, \"f1\": 0.9569355222460147, \"f2\": 0.9765928515928516, \"f0_5\": 0.9380539229405728, \"p4\": 0.9359028097435722, \"phi\": 0.87729453685813}, {\"truth_threshold\": -17.23668434570038, \"match_probability\": 6.474976165294207e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2010.0, \"tn\": 984.0, \"fp\": 161.0, \"fn\": 21.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9896602658788775, \"tn_rate\": 0.8593886462882097, \"fp_rate\": 0.1406113537117904, \"fn_rate\": 0.0103397341211226, \"precision\": 0.9258406264394289, \"recall\": 0.9896602658788775, \"specificity\": 0.8593886462882097, \"npv\": 0.9791044776119403, \"accuracy\": 0.9426952141057935, \"f1\": 0.9566872917658258, \"f2\": 0.9762020398251579, \"f0_5\": 0.9379374708352777, \"p4\": 0.9355616449242148, \"phi\": 0.876551570739421}, {\"truth_threshold\": -17.231953642233716, \"match_probability\": 6.4962428002483e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2008.0, \"tn\": 988.0, \"fp\": 157.0, \"fn\": 23.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9886755292959133, \"tn_rate\": 0.862882096069869, \"fp_rate\": 0.137117903930131, \"fn_rate\": 0.011324470704086657, \"precision\": 0.9274826789838337, \"recall\": 0.9886755292959133, \"specificity\": 0.862882096069869, \"npv\": 0.9772502472799208, \"accuracy\": 0.9433249370277078, \"f1\": 0.9571020019065777, \"f2\": 0.9757993974147148, \"f0_5\": 0.9391076606491442, \"p4\": 0.9363673607322143, \"phi\": 0.8777426856883505}, {\"truth_threshold\": -17.137085979799725, \"match_probability\": 6.9377727266952745e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2007.0, \"tn\": 1040.0, \"fp\": 105.0, \"fn\": 24.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9881831610044313, \"tn_rate\": 0.9082969432314411, \"fp_rate\": 0.09170305676855896, \"fn_rate\": 0.011816838995568686, \"precision\": 0.9502840909090909, \"recall\": 0.9881831610044313, \"specificity\": 0.9082969432314411, \"npv\": 0.9774436090225563, \"accuracy\": 0.9593828715365239, \"f1\": 0.9688631426502534, \"f2\": 0.9803634232121923, \"f0_5\": 0.9576295448038935, \"p4\": 0.9550383468293904, \"phi\": 0.9119700790800263}, {\"truth_threshold\": -17.03043471319799, \"match_probability\": 7.4700768185240926e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2007.0, \"tn\": 1042.0, \"fp\": 103.0, \"fn\": 24.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9881831610044313, \"tn_rate\": 0.9100436681222708, \"fp_rate\": 0.08995633187772925, \"fn_rate\": 0.011816838995568686, \"precision\": 0.9511848341232227, \"recall\": 0.9881831610044313, \"specificity\": 0.9100436681222708, \"npv\": 0.9774859287054409, \"accuracy\": 0.9600125944584383, \"f1\": 0.9693310794494083, \"f2\": 0.9805550127027555, \"f0_5\": 0.9583611880431668, \"p4\": 0.9557580727295454, \"phi\": 0.9133219556094478}, {\"truth_threshold\": -16.80873147392209, \"match_probability\": 8.71091656848601e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2007.0, \"tn\": 1045.0, \"fp\": 100.0, \"fn\": 24.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9881831610044313, \"tn_rate\": 0.9126637554585153, \"fp_rate\": 0.08733624454148471, \"fn_rate\": 0.011816838995568686, \"precision\": 0.9525391551969625, \"recall\": 0.9881831610044313, \"specificity\": 0.9126637554585153, \"npv\": 0.9775491113189897, \"accuracy\": 0.9609571788413098, \"f1\": 0.9700338327694539, \"f2\": 0.9808425373863747, \"f0_5\": 0.9594607515058801, \"p4\": 0.9568361537587703, \"phi\": 0.9153508327025561}, {\"truth_threshold\": -16.80793865261628, \"match_probability\": 8.715704855556114e-06, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2005.0, \"tn\": 1046.0, \"fp\": 99.0, \"fn\": 26.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9871984244214672, \"tn_rate\": 0.9135371179039301, \"fp_rate\": 0.08646288209606987, \"fn_rate\": 0.012801575578532743, \"precision\": 0.9529467680608364, \"recall\": 0.9871984244214672, \"specificity\": 0.9135371179039301, \"npv\": 0.9757462686567164, \"accuracy\": 0.9606423173803527, \"f1\": 0.969770253929867, \"f2\": 0.9801525224872898, \"f0_5\": 0.9596056284100699, \"p4\": 0.9565151457277092, \"phi\": 0.9146074710396834}, {\"truth_threshold\": -16.162841904837535, \"match_probability\": 1.3629937112027833e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2001.0, \"tn\": 1051.0, \"fp\": 94.0, \"fn\": 30.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9852289512555391, \"tn_rate\": 0.9179039301310044, \"fp_rate\": 0.08209606986899563, \"fn_rate\": 0.014771048744460856, \"precision\": 0.9551312649164678, \"recall\": 0.9852289512555391, \"specificity\": 0.9179039301310044, \"npv\": 0.9722479185938946, \"accuracy\": 0.9609571788413098, \"f1\": 0.969946679592826, \"f2\": 0.9790586163029651, \"f0_5\": 0.9610027855153204, \"p4\": 0.9569488133530937, \"phi\": 0.9151757394848344}, {\"truth_threshold\": -16.132207660502573, \"match_probability\": 1.3922446298994795e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2001.0, \"tn\": 1052.0, \"fp\": 93.0, \"fn\": 30.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9852289512555391, \"tn_rate\": 0.9187772925764193, \"fp_rate\": 0.08122270742358079, \"fn_rate\": 0.014771048744460856, \"precision\": 0.9555873925501432, \"recall\": 0.9852289512555391, \"specificity\": 0.9187772925764193, \"npv\": 0.9722735674676525, \"accuracy\": 0.961272040302267, \"f1\": 0.9701818181818181, \"f2\": 0.9791544333529066, \"f0_5\": 0.9613721533583165, \"p4\": 0.957306655834134, \"phi\": 0.9158559391432707}, {\"truth_threshold\": -16.12747695703591, \"match_probability\": 1.3968173319947447e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 2001.0, \"tn\": 1059.0, \"fp\": 86.0, \"fn\": 30.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9852289512555391, \"tn_rate\": 0.9248908296943231, \"fp_rate\": 0.07510917030567686, \"fn_rate\": 0.014771048744460856, \"precision\": 0.9587925251557259, \"recall\": 0.9852289512555391, \"specificity\": 0.9248908296943231, \"npv\": 0.9724517906336089, \"accuracy\": 0.9634760705289672, \"f1\": 0.971830985915493, \"f2\": 0.9798256781901871, \"f0_5\": 0.9639656999710955, \"p4\": 0.9598061236552784, \"phi\": 0.9206214600458723}, {\"truth_threshold\": -15.934732389206488, \"match_probability\": 1.5964695684754743e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1999.0, \"tn\": 1100.0, \"fp\": 45.0, \"fn\": 32.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9842442146725751, \"tn_rate\": 0.9606986899563319, \"fp_rate\": 0.039301310043668124, \"fn_rate\": 0.015755785327424915, \"precision\": 0.9779843444227005, \"recall\": 0.9842442146725751, \"specificity\": 0.9606986899563319, \"npv\": 0.9717314487632509, \"accuracy\": 0.9757556675062973, \"f1\": 0.9811042944785276, \"f2\": 0.9829858379228954, \"f0_5\": 0.9792299402370922, \"p4\": 0.9735867711036135, \"phi\": 0.9473263430228673}, {\"truth_threshold\": -15.703461967418473, \"match_probability\": 1.8740396408330582e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1998.0, \"tn\": 1100.0, \"fp\": 45.0, \"fn\": 33.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.983751846381093, \"tn_rate\": 0.9606986899563319, \"fp_rate\": 0.039301310043668124, \"fn_rate\": 0.01624815361890694, \"precision\": 0.9779735682819384, \"recall\": 0.983751846381093, \"specificity\": 0.9606986899563319, \"npv\": 0.970873786407767, \"accuracy\": 0.97544080604534, \"f1\": 0.9808541973490427, \"f2\": 0.9825907347300088, \"f0_5\": 0.9791237871214349, \"p4\": 0.9732482925643352, \"phi\": 0.9466463928199584}, {\"truth_threshold\": -15.157963585540383, \"match_probability\": 2.7351831268064755e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1995.0, \"tn\": 1102.0, \"fp\": 43.0, \"fn\": 36.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.982274741506647, \"tn_rate\": 0.9624454148471616, \"fp_rate\": 0.03755458515283843, \"fn_rate\": 0.01772525849335303, \"precision\": 0.978900883218842, \"recall\": 0.982274741506647, \"specificity\": 0.9624454148471616, \"npv\": 0.968365553602812, \"accuracy\": 0.9751259445843828, \"f1\": 0.9805849102973704, \"f2\": 0.9815981106081481, \"f0_5\": 0.9795737994697044, \"p4\": 0.9729313856767784, \"phi\": 0.9459924398761695}, {\"truth_threshold\": -15.089477749564807, \"match_probability\": 2.8681517271540395e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1990.0, \"tn\": 1105.0, \"fp\": 40.0, \"fn\": 41.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9798129000492368, \"tn_rate\": 0.9650655021834061, \"fp_rate\": 0.034934497816593885, \"fn_rate\": 0.02018709995076317, \"precision\": 0.9802955665024631, \"recall\": 0.9798129000492368, \"specificity\": 0.9650655021834061, \"npv\": 0.9642233856893543, \"accuracy\": 0.9744962216624685, \"f1\": 0.9800541738488057, \"f2\": 0.9799093953121922, \"f0_5\": 0.9801989951728893, \"p4\": 0.9722881624319695, \"phi\": 0.9446986601162586}, {\"truth_threshold\": -15.058365219639729, \"match_probability\": 2.9306749707887795e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1990.0, \"tn\": 1107.0, \"fp\": 38.0, \"fn\": 41.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9798129000492368, \"tn_rate\": 0.9668122270742358, \"fp_rate\": 0.03318777292576419, \"fn_rate\": 0.02018709995076317, \"precision\": 0.9812623274161736, \"recall\": 0.9798129000492368, \"specificity\": 0.9668122270742358, \"npv\": 0.9642857142857143, \"accuracy\": 0.9751259445843828, \"f1\": 0.9805370780980537, \"f2\": 0.9801024428684003, \"f0_5\": 0.9809720989845213, \"p4\": 0.9729844685234712, \"phi\": 0.9460864311348092}, {\"truth_threshold\": -14.733948595922945, \"match_probability\": 3.669641010969834e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1990.0, \"tn\": 1109.0, \"fp\": 36.0, \"fn\": 41.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9798129000492368, \"tn_rate\": 0.9685589519650655, \"fp_rate\": 0.0314410480349345, \"fn_rate\": 0.02018709995076317, \"precision\": 0.9822309970384995, \"recall\": 0.9798129000492368, \"specificity\": 0.9685589519650655, \"npv\": 0.9643478260869566, \"accuracy\": 0.9757556675062973, \"f1\": 0.9810204584668474, \"f2\": 0.9802955665024631, \"f0_5\": 0.9817464232856438, \"p4\": 0.9736801149492355, \"phi\": 0.9474749134225178}, {\"truth_threshold\": -14.730010713762095, \"match_probability\": 3.6796707266506786e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1988.0, \"tn\": 1109.0, \"fp\": 36.0, \"fn\": 43.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9788281634662728, \"tn_rate\": 0.9685589519650655, \"fp_rate\": 0.0314410480349345, \"fn_rate\": 0.02117183653372723, \"precision\": 0.9822134387351779, \"recall\": 0.9788281634662728, \"specificity\": 0.9685589519650655, \"npv\": 0.9626736111111112, \"accuracy\": 0.9751259445843828, \"f1\": 0.980517879161529, \"f2\": 0.9795033504138747, \"f0_5\": 0.9815345117013923, \"p4\": 0.9730054766235877, \"phi\": 0.9461362568691166}, {\"truth_threshold\": -14.729217892456283, \"match_probability\": 3.6816933409755075e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1987.0, \"tn\": 1112.0, \"fp\": 33.0, \"fn\": 44.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9783357951747907, \"tn_rate\": 0.97117903930131, \"fp_rate\": 0.028820960698689956, \"fn_rate\": 0.021664204825209258, \"precision\": 0.9836633663366336, \"recall\": 0.9783357951747907, \"specificity\": 0.97117903930131, \"npv\": 0.9619377162629758, \"accuracy\": 0.9757556675062973, \"f1\": 0.9809923475685016, \"f2\": 0.9793966876971609, \"f0_5\": 0.9825932153100584, \"p4\": 0.9737106660619014, \"phi\": 0.9475559378870411}, {\"truth_threshold\": -14.305995724144656, \"match_probability\": 4.936790849772476e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1986.0, \"tn\": 1117.0, \"fp\": 28.0, \"fn\": 45.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9778434268833087, \"tn_rate\": 0.9755458515283842, \"fp_rate\": 0.02445414847161572, \"fn_rate\": 0.022156573116691284, \"precision\": 0.9860973187686196, \"recall\": 0.9778434268833087, \"specificity\": 0.9755458515283842, \"npv\": 0.9612736660929432, \"accuracy\": 0.9770151133501259, \"f1\": 0.9819530284301607, \"f2\": 0.9794831327678043, \"f0_5\": 0.984435411916328, \"p4\": 0.9751077119290652, \"phi\": 0.9503753677602026}, {\"truth_threshold\": -14.128882150348645, \"match_probability\": 5.581596354257064e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1985.0, \"tn\": 1117.0, \"fp\": 28.0, \"fn\": 46.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9773510585918267, \"tn_rate\": 0.9755458515283842, \"fp_rate\": 0.02445414847161572, \"fn_rate\": 0.022648941408173313, \"precision\": 0.9860904123199206, \"recall\": 0.9773510585918267, \"specificity\": 0.9755458515283842, \"npv\": 0.9604471195184867, \"accuracy\": 0.9767002518891688, \"f1\": 0.9817012858555886, \"f2\": 0.979086514747953, \"f0_5\": 0.9843300604978676, \"p4\": 0.9747708640342702, \"phi\": 0.9497118981046985}, {\"truth_threshold\": -14.053486900342577, \"match_probability\": 5.881029495991135e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1984.0, \"tn\": 1117.0, \"fp\": 28.0, \"fn\": 47.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9768586903003447, \"tn_rate\": 0.9755458515283842, \"fp_rate\": 0.02445414847161572, \"fn_rate\": 0.023141309699655343, \"precision\": 0.9860834990059643, \"recall\": 0.9768586903003447, \"specificity\": 0.9755458515283842, \"npv\": 0.9596219931271478, \"accuracy\": 0.9763853904282116, \"f1\": 0.9814494187484541, \"f2\": 0.978689818468824, \"f0_5\": 0.9842246254588749, \"p4\": 0.9744341238024875, \"phi\": 0.9490491061794165}, {\"truth_threshold\": -13.750425496060556, \"match_probability\": 7.255677323116204e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1981.0, \"tn\": 1124.0, \"fp\": 21.0, \"fn\": 50.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9753815854258986, \"tn_rate\": 0.9816593886462882, \"fp_rate\": 0.01834061135371179, \"fn_rate\": 0.024618414574101428, \"precision\": 0.9895104895104895, \"recall\": 0.9753815854258986, \"specificity\": 0.9816593886462882, \"npv\": 0.9574105621805792, \"accuracy\": 0.9776448362720404, \"f1\": 0.9823952392759733, \"f2\": 0.9781749950622161, \"f0_5\": 0.9866520569777867, \"p4\": 0.9758459240469327, \"phi\": 0.9519675654558195}, {\"truth_threshold\": -13.629471910725139, \"match_probability\": 7.890160941467207e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1978.0, \"tn\": 1124.0, \"fp\": 21.0, \"fn\": 53.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9739044805514525, \"tn_rate\": 0.9816593886462882, \"fp_rate\": 0.01834061135371179, \"fn_rate\": 0.026095519448547513, \"precision\": 0.9894947473736868, \"recall\": 0.9739044805514525, \"specificity\": 0.9816593886462882, \"npv\": 0.9549702633814783, \"accuracy\": 0.9767002518891688, \"f1\": 0.9816377171215881, \"f2\": 0.9769831077743751, \"f0_5\": 0.986336890395931, \"p4\": 0.9748375359928863, \"phi\": 0.9499982315768232}, {\"truth_threshold\": -13.624741207258477, \"match_probability\": 7.916073774999241e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1978.0, \"tn\": 1125.0, \"fp\": 20.0, \"fn\": 53.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9739044805514525, \"tn_rate\": 0.982532751091703, \"fp_rate\": 0.017467248908296942, \"fn_rate\": 0.026095519448547513, \"precision\": 0.98998998998999, \"recall\": 0.9739044805514525, \"specificity\": 0.982532751091703, \"npv\": 0.9550084889643463, \"accuracy\": 0.9770151133501259, \"f1\": 0.9818813601389923, \"f2\": 0.9770796285319107, \"f0_5\": 0.9867305198044498, \"p4\": 0.9751828508929973, \"phi\": 0.9507006516869957}, {\"truth_threshold\": -12.65522783576295, \"match_probability\": 0.00015499921509957678, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1976.0, \"tn\": 1136.0, \"fp\": 9.0, \"fn\": 55.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9729197439684885, \"tn_rate\": 0.9921397379912664, \"fp_rate\": 0.007860262008733625, \"fn_rate\": 0.02708025603151157, \"precision\": 0.9954659949622167, \"recall\": 0.9729197439684885, \"specificity\": 0.9921397379912664, \"npv\": 0.9538203190596137, \"accuracy\": 0.9798488664987406, \"f1\": 0.9840637450199203, \"f2\": 0.9773469185873974, \"f0_5\": 0.9908735332464146, \"p4\": 0.978299676447618, \"phi\": 0.9571404068585719}, {\"truth_threshold\": -12.64594881086275, \"match_probability\": 0.00015599918499661718, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1973.0, \"tn\": 1136.0, \"fp\": 9.0, \"fn\": 58.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9714426390940424, \"tn_rate\": 0.9921397379912664, \"fp_rate\": 0.007860262008733625, \"fn_rate\": 0.028557360905957656, \"precision\": 0.9954591321897074, \"recall\": 0.9714426390940424, \"specificity\": 0.9921397379912664, \"npv\": 0.9514237855946399, \"accuracy\": 0.978904282115869, \"f1\": 0.9833042611512585, \"f2\": 0.97615278052642, \"f0_5\": 0.9905613013354755, \"p4\": 0.9772932480815906, \"phi\": 0.9551961540647628}, {\"truth_threshold\": -12.394316821094904, \"match_probability\": 0.00018571979538504804, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1971.0, \"tn\": 1137.0, \"fp\": 8.0, \"fn\": 60.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9704579025110783, \"tn_rate\": 0.9930131004366812, \"fp_rate\": 0.0069868995633187774, \"fn_rate\": 0.029542097488921712, \"precision\": 0.9959575543203638, \"recall\": 0.9704579025110783, \"specificity\": 0.9930131004366812, \"npv\": 0.949874686716792, \"accuracy\": 0.9785894206549118, \"f1\": 0.9830423940149626, \"f2\": 0.9754528357913491, \"f0_5\": 0.9907509801950337, \"p4\": 0.9769663663435872, \"phi\": 0.9546108829739978}, {\"truth_threshold\": -12.227274963984662, \"match_probability\": 0.00020851288880033682, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1971.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 60.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9704579025110783, \"tn_rate\": 0.9956331877729258, \"fp_rate\": 0.004366812227074236, \"fn_rate\": 0.029542097488921712, \"precision\": 0.9974696356275303, \"recall\": 0.9704579025110783, \"specificity\": 0.9956331877729258, \"npv\": 0.95, \"accuracy\": 0.9795340050377834, \"f1\": 0.9837783878213127, \"f2\": 0.9757425742574257, \"f0_5\": 0.9919476597886261, \"p4\": 0.9779961316543299, \"phi\": 0.9567350590912768}, {\"truth_threshold\": -12.181458168342969, \"match_probability\": 0.0002152396181778507, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1969.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 62.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9694731659281143, \"tn_rate\": 0.9956331877729258, \"fp_rate\": 0.004366812227074236, \"fn_rate\": 0.03052683407188577, \"precision\": 0.997467071935157, \"recall\": 0.9694731659281143, \"specificity\": 0.9956331877729258, \"npv\": 0.9484193011647255, \"accuracy\": 0.978904282115869, \"f1\": 0.983270911360799, \"f2\": 0.9749455337690632, \"f0_5\": 0.9917396998086028, \"p4\": 0.9773261900068391, \"phi\": 0.955448035508959}, {\"truth_threshold\": -12.043367931448067, \"match_probability\": 0.0002368547653859326, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1968.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 63.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9689807976366323, \"tn_rate\": 0.9956331877729258, \"fp_rate\": 0.004366812227074236, \"fn_rate\": 0.0310192023633678, \"precision\": 0.9974657881398885, \"recall\": 0.9689807976366323, \"specificity\": 0.9956331877729258, \"npv\": 0.9476309226932669, \"accuracy\": 0.9785894206549118, \"f1\": 0.983016983016983, \"f2\": 0.9745468951173616, \"f0_5\": 0.9916355940743726, \"p4\": 0.9769913724178655, \"phi\": 0.9548054801027457}, {\"truth_threshold\": -11.67170473590056, \"match_probability\": 0.00030643168690159595, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1966.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 65.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9679960610536681, \"tn_rate\": 0.9956331877729258, \"fp_rate\": 0.004366812227074236, \"fn_rate\": 0.032003938946331856, \"precision\": 0.9974632166412988, \"recall\": 0.9679960610536681, \"specificity\": 0.9956331877729258, \"npv\": 0.946058091286307, \"accuracy\": 0.9779596977329975, \"f1\": 0.9825087456271864, \"f2\": 0.9737493808816245, \"f0_5\": 0.9914271306101866, \"p4\": 0.9763220428690601, \"phi\": 0.9535222751515374}, {\"truth_threshold\": -11.576939262108978, \"match_probability\": 0.00032722907679536413, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1965.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 66.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9675036927621861, \"tn_rate\": 0.9956331877729258, \"fp_rate\": 0.004366812227074236, \"fn_rate\": 0.03249630723781388, \"precision\": 0.9974619289340102, \"recall\": 0.9675036927621861, \"specificity\": 0.9956331877729258, \"npv\": 0.945273631840796, \"accuracy\": 0.9776448362720404, \"f1\": 0.9822544363909023, \"f2\": 0.9733505052506439, \"f0_5\": 0.9913227726768238, \"p4\": 0.9759875305731329, \"phi\": 0.9528816228546788}, {\"truth_threshold\": -11.550751150565144, \"match_probability\": 0.0003332212513493105, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1964.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 67.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.967011324470704, \"tn_rate\": 0.9956331877729258, \"fp_rate\": 0.004366812227074236, \"fn_rate\": 0.032988675529295915, \"precision\": 0.9974606399187405, \"recall\": 0.967011324470704, \"specificity\": 0.9956331877729258, \"npv\": 0.9444904722452361, \"accuracy\": 0.9773299748110831, \"f1\": 0.982, \"f2\": 0.9729515505796096, \"f0_5\": 0.9912183304734027, \"p4\": 0.9756531197054947, \"phi\": 0.9522416021821541}, {\"truth_threshold\": -11.436202193789663, \"match_probability\": 0.0003607475615997388, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1962.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 69.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.96602658788774, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.033973412112259974, \"precision\": 0.9979654120040692, \"recall\": 0.96602658788774, \"specificity\": 0.9965065502183406, \"npv\": 0.9429752066115702, \"accuracy\": 0.9770151133501259, \"f1\": 0.98173630222667, \"f2\": 0.9722497522299306, \"f0_5\": 0.9914098029307731, \"p4\": 0.975327649111701, \"phi\": 0.9516756413860702}, {\"truth_threshold\": -11.424803449599377, \"match_probability\": 0.0003636080799792259, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1958.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 73.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9640571147218119, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.035942885278188084, \"precision\": 0.9979612640163099, \"recall\": 0.9640571147218119, \"specificity\": 0.9965065502183406, \"npv\": 0.9398682042833608, \"accuracy\": 0.9757556675062973, \"f1\": 0.9807162534435262, \"f2\": 0.9706523894507237, \"f0_5\": 0.990990990990991, \"p4\": 0.9739918593428727, \"phi\": 0.9491285008674043}, {\"truth_threshold\": -11.33058864492844, \"match_probability\": 0.0003881363800831765, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1956.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 75.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9630723781388478, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.03692762186115214, \"precision\": 0.9979591836734694, \"recall\": 0.9630723781388478, \"specificity\": 0.9965065502183406, \"npv\": 0.9383223684210527, \"accuracy\": 0.9751259445843828, \"f1\": 0.9802054622901528, \"f2\": 0.9698532328441095, \"f0_5\": 0.990781075878837, \"p4\": 0.9733245659243989, \"phi\": 0.947858664780497}, {\"truth_threshold\": -11.107468111649636, \"match_probability\": 0.0004530249610438174, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1951.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 80.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9606105366814377, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.03938946331856229, \"precision\": 0.9979539641943734, \"recall\": 0.9606105366814377, \"specificity\": 0.9965065502183406, \"npv\": 0.9344799344799345, \"accuracy\": 0.9735516372795969, \"f1\": 0.9789262418464626, \"f2\": 0.9678539537652545, \"f0_5\": 0.9902547964673637, \"p4\": 0.9716580758901154, \"phi\": 0.9446948802792131}, {\"truth_threshold\": -10.938891246250261, \"match_probability\": 0.0005091484651345773, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1950.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 81.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9601181683899557, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.03988183161004431, \"precision\": 0.9979529170931423, \"recall\": 0.9601181683899557, \"specificity\": 0.9965065502183406, \"npv\": 0.9337152209492635, \"accuracy\": 0.9732367758186398, \"f1\": 0.9786700125470514, \"f2\": 0.9674538598928358, \"f0_5\": 0.9901492840459023, \"p4\": 0.9713250754294527, \"phi\": 0.9440639652010514}, {\"truth_threshold\": -10.830597076280572, \"match_probability\": 0.0005488162926872154, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1946.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 85.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9581486952240276, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.041851304775972424, \"precision\": 0.997948717948718, \"recall\": 0.9581486952240276, \"specificity\": 0.9965065502183406, \"npv\": 0.9306688417618271, \"accuracy\": 0.9719773299748111, \"f1\": 0.97764380808842, \"f2\": 0.9658526900933095, \"f0_5\": 0.989726375750178, \"p4\": 0.9699940598192258, \"phi\": 0.9415464005494172}, {\"truth_threshold\": -10.742221666609478, \"match_probability\": 0.0005834660463926033, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1945.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 86.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9576563269325455, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.04234367306745446, \"precision\": 0.9979476654694716, \"recall\": 0.9576563269325455, \"specificity\": 0.9965065502183406, \"npv\": 0.9299103504482478, \"accuracy\": 0.9716624685138538, \"f1\": 0.9773869346733668, \"f2\": 0.965452198947682, \"f0_5\": 0.9896204334995421, \"p4\": 0.9696615516367513, \"phi\": 0.9409185267894152}, {\"truth_threshold\": -10.630905946259881, \"match_probability\": 0.0006302380705481763, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1932.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 99.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9512555391432792, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.04874446085672083, \"precision\": 0.9979338842975206, \"recall\": 0.9512555391432792, \"specificity\": 0.9965065502183406, \"npv\": 0.9201612903225806, \"accuracy\": 0.9675692695214105, \"f1\": 0.9740357953113183, \"f2\": 0.9602385685884692, \"f0_5\": 0.9882352941176471, \"p4\": 0.9653477979984382, \"phi\": 0.9328106994083892}, {\"truth_threshold\": -10.567228050702754, \"match_probability\": 0.0006586599230816085, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1931.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 100.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9507631708517972, \"tn_rate\": 0.9965065502183406, \"fp_rate\": 0.0034934497816593887, \"fn_rate\": 0.049236829148202856, \"precision\": 0.9979328165374677, \"recall\": 0.9507631708517972, \"specificity\": 0.9965065502183406, \"npv\": 0.91941982272361, \"accuracy\": 0.9672544080604534, \"f1\": 0.9737771053958648, \"f2\": 0.9598369619246446, \"f0_5\": 0.9881281342748951, \"p4\": 0.9650166459131119, \"phi\": 0.9321911706918252}, {\"truth_threshold\": -10.472462576911171, \"match_probability\": 0.0007033460763833603, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1930.0, \"tn\": 1142.0, \"fp\": 3.0, \"fn\": 101.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9502708025603152, \"tn_rate\": 0.9973799126637555, \"fp_rate\": 0.0026200873362445414, \"fn_rate\": 0.04972919743968488, \"precision\": 0.9984480082772892, \"recall\": 0.9502708025603152, \"specificity\": 0.9973799126637555, \"npv\": 0.918744971842317, \"accuracy\": 0.9672544080604534, \"f1\": 0.9737638748738647, \"f2\": 0.9595306751516357, \"f0_5\": 0.9884256888251562, \"p4\": 0.9650287311531166, \"phi\": 0.9322974759210934}, {\"truth_threshold\": -10.465307487567681, \"match_probability\": 0.0007068405349787472, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1929.0, \"tn\": 1142.0, \"fp\": 3.0, \"fn\": 102.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9497784342688331, \"tn_rate\": 0.9973799126637555, \"fp_rate\": 0.0026200873362445414, \"fn_rate\": 0.050221565731166914, \"precision\": 0.9984472049689441, \"recall\": 0.9497784342688331, \"specificity\": 0.9973799126637555, \"npv\": 0.9180064308681672, \"accuracy\": 0.9669395465994962, \"f1\": 0.9735049205147616, \"f2\": 0.959128878281623, \"f0_5\": 0.988318475253612, \"p4\": 0.9646977757151833, \"phi\": 0.9316795107545506}, {\"truth_threshold\": -10.456329997229089, \"match_probability\": 0.0007112495827092619, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1929.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 102.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9497784342688331, \"tn_rate\": 0.9982532751091703, \"fp_rate\": 0.0017467248908296944, \"fn_rate\": 0.050221565731166914, \"precision\": 0.9989642672190575, \"recall\": 0.9497784342688331, \"specificity\": 0.9982532751091703, \"npv\": 0.9180722891566265, \"accuracy\": 0.9672544080604534, \"f1\": 0.9737506309944473, \"f2\": 0.9592242665340627, \"f0_5\": 0.9887237314197848, \"p4\": 0.9650407774435281, \"phi\": 0.9324053486027188}, {\"truth_threshold\": -10.331725508591855, \"match_probability\": 0.0007753608158132263, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1928.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 103.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9492860659773511, \"tn_rate\": 0.9982532751091703, \"fp_rate\": 0.0017467248908296944, \"fn_rate\": 0.05071393402264894, \"precision\": 0.9989637305699481, \"recall\": 0.9492860659773511, \"specificity\": 0.9982532751091703, \"npv\": 0.9173354735152488, \"accuracy\": 0.9669395465994962, \"f1\": 0.9734915425397627, \"f2\": 0.958822359259996, \"f0_5\": 0.9886165521484976, \"p4\": 0.9647099226891706, \"phi\": 0.9317883579853267}, {\"truth_threshold\": -10.226111959730632, \"match_probability\": 0.0008342017962744378, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1925.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 106.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.947808961102905, \"tn_rate\": 0.9982532751091703, \"fp_rate\": 0.0017467248908296944, \"fn_rate\": 0.052191038897095025, \"precision\": 0.9989621172807472, \"recall\": 0.947808961102905, \"specificity\": 0.9982532751091703, \"npv\": 0.9151321056845476, \"accuracy\": 0.9659949622166247, \"f1\": 0.9727134916624558, \"f2\": 0.9576161575962591, \"f0_5\": 0.9882944860868672, \"p4\": 0.9637179269864672, \"phi\": 0.9299408716080212}, {\"truth_threshold\": -10.193295591395295, \"match_probability\": 0.0008533781062867166, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1922.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 109.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9463318562284588, \"tn_rate\": 0.9982532751091703, \"fp_rate\": 0.0017467248908296944, \"fn_rate\": 0.05366814377154111, \"precision\": 0.998960498960499, \"recall\": 0.9463318562284588, \"specificity\": 0.9982532751091703, \"npv\": 0.9129392971246006, \"accuracy\": 0.9650503778337531, \"f1\": 0.9719342604298357, \"f2\": 0.9564092356687898, \"f0_5\": 0.987971625372674, \"p4\": 0.9627267806133902, \"phi\": 0.9280985877867722}, {\"truth_threshold\": -9.969377874754734, \"match_probability\": 0.000996518173794951, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1921.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 110.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9458394879369768, \"tn_rate\": 0.9982532751091703, \"fp_rate\": 0.0017467248908296944, \"fn_rate\": 0.05416051206302314, \"precision\": 0.998959958398336, \"recall\": 0.9458394879369768, \"specificity\": 0.9982532751091703, \"npv\": 0.9122106943335994, \"accuracy\": 0.964735516372796, \"f1\": 0.9716742539200809, \"f2\": 0.9560067681895094, \"f0_5\": 0.9878638280366142, \"p4\": 0.9623965864487978, \"phi\": 0.9274856436324254}, {\"truth_threshold\": -9.921816767208316, \"match_probability\": 0.0010298833534097493, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1919.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 112.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9448547513540128, \"tn_rate\": 0.9982532751091703, \"fp_rate\": 0.0017467248908296944, \"fn_rate\": 0.055145248645987195, \"precision\": 0.9989588755856325, \"recall\": 0.9448547513540128, \"specificity\": 0.9982532751091703, \"npv\": 0.9107569721115538, \"accuracy\": 0.9641057934508817, \"f1\": 0.9711538461538461, \"f2\": 0.9552015928322548, \"f0_5\": 0.9876479670612455, \"p4\": 0.9617364790562831, \"phi\": 0.9262614737556426}, {\"truth_threshold\": -9.880344986846525, \"match_probability\": 0.0010598862171977302, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1919.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 112.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9448547513540128, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.055145248645987195, \"precision\": 0.9994791666666667, \"recall\": 0.9448547513540128, \"specificity\": 0.9991266375545852, \"npv\": 0.910828025477707, \"accuracy\": 0.9644206549118388, \"f1\": 0.9713996456593268, \"f2\": 0.9552966945440063, \"f0_5\": 0.9880547832355061, \"p4\": 0.9620793861339125, \"phi\": 0.9269913956310123}, {\"truth_threshold\": -9.726120391082766, \"match_probability\": 0.0011793251063204845, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1918.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 113.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9443623830625307, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.05563761693746923, \"precision\": 0.9994788952579469, \"recall\": 0.9443623830625307, \"specificity\": 0.9991266375545852, \"npv\": 0.9101034208432777, \"accuracy\": 0.9641057934508817, \"f1\": 0.9711392405063292, \"f2\": 0.9548939559892462, \"f0_5\": 0.9879468424848048, \"p4\": 0.9617494769794241, \"phi\": 0.9263805527908022}, {\"truth_threshold\": -9.63774498141167, \"match_probability\": 0.0012537323710397376, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1916.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 115.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9433776464795667, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.05662235352043329, \"precision\": 0.9994783515910276, \"recall\": 0.9433776464795667, \"specificity\": 0.9991266375545852, \"npv\": 0.9086576648133439, \"accuracy\": 0.9634760705289672, \"f1\": 0.9706180344478217, \"f2\": 0.9540882382232845, \"f0_5\": 0.9877306938859677, \"p4\": 0.9610899377544238, \"phi\": 0.9251605730611465}, {\"truth_threshold\": -9.597714679207227, \"match_probability\": 0.0012889611922700193, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1900.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 131.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9354997538158543, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06450024618414574, \"precision\": 0.9994739610731194, \"recall\": 0.9354997538158543, \"specificity\": 0.9991266375545852, \"npv\": 0.8972549019607843, \"accuracy\": 0.9584382871536524, \"f1\": 0.9664292980671414, \"f2\": 0.9476309226932669, \"f0_5\": 0.9859885832900882, \"p4\": 0.9558268676353927, \"phi\": 0.9154815461248219}, {\"truth_threshold\": -9.357481433629667, \"match_probability\": 0.0015221443574108104, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1898.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 133.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9345150172328902, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.0654849827671098, \"precision\": 0.9994734070563455, \"recall\": 0.9345150172328902, \"specificity\": 0.9991266375545852, \"npv\": 0.8958496476115897, \"accuracy\": 0.957808564231738, \"f1\": 0.9659033078880407, \"f2\": 0.9468223086900129, \"f0_5\": 0.9857691908174925, \"p4\": 0.9551706192848115, \"phi\": 0.9142816296577047}, {\"truth_threshold\": -9.251867884768444, \"match_probability\": 0.0016375647548830953, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1897.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 134.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9340226489414082, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06597735105859183, \"precision\": 0.9994731296101159, \"recall\": 0.9340226489414082, \"specificity\": 0.9991266375545852, \"npv\": 0.8951486697965572, \"accuracy\": 0.9574937027707808, \"f1\": 0.9656401119877831, \"f2\": 0.9464178806625424, \"f0_5\": 0.9856593577886315, \"p4\": 0.9548426298070212, \"phi\": 0.9136824906936208}, {\"truth_threshold\": -9.193295591395295, \"match_probability\": 0.0017053009460814173, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1896.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 135.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9335302806499262, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06646971935007386, \"precision\": 0.9994728518713759, \"recall\": 0.9335302806499262, \"specificity\": 0.9991266375545852, \"npv\": 0.8944487881157154, \"accuracy\": 0.9571788413098237, \"f1\": 0.9653767820773931, \"f2\": 0.9460133719189702, \"f0_5\": 0.9855494334130367, \"p4\": 0.9545147299048048, \"phi\": 0.9130838964009184}, {\"truth_threshold\": -9.074203512331545, \"match_probability\": 0.0018517723538448185, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1895.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 136.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9330379123584441, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06696208764155588, \"precision\": 0.9994725738396625, \"recall\": 0.9330379123584441, \"specificity\": 0.9991266375545852, \"npv\": 0.89375, \"accuracy\": 0.9568639798488665, \"f1\": 0.9651133180544945, \"f2\": 0.9456087824351297, \"f0_5\": 0.9854394175767031, \"p4\": 0.954186919411087, \"phi\": 0.9124858456520881}, {\"truth_threshold\": -9.02874735148964, \"match_probability\": 0.0019109332721339533, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1894.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 137.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9325455440669621, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06745445593303791, \"precision\": 0.9994722955145119, \"recall\": 0.9325455440669621, \"specificity\": 0.9991266375545852, \"npv\": 0.8930523028883685, \"accuracy\": 0.9565491183879093, \"f1\": 0.9648497198166073, \"f2\": 0.945204112186845, \"f0_5\": 0.9853293101654355, \"p4\": 0.9538591981587878, \"phi\": 0.9118883373225621}, {\"truth_threshold\": -8.96730244125691, \"match_probability\": 0.0019939128635114087, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1893.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 138.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9320531757754801, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06794682422451995, \"precision\": 0.9994720168954594, \"recall\": 0.9320531757754801, \"specificity\": 0.9991266375545852, \"npv\": 0.8923556942277691, \"accuracy\": 0.9562342569269522, \"f1\": 0.9645859872611465, \"f2\": 0.9447993611499301, \"f0_5\": 0.9852191110648485, \"p4\": 0.9535315659808217, \"phi\": 0.9112913702907031}, {\"truth_threshold\": -8.95230339571279, \"match_probability\": 0.002014708821804702, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1892.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 139.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.931560807483998, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06843919251600197, \"precision\": 0.9994717379820391, \"recall\": 0.931560807483998, \"specificity\": 0.9991266375545852, \"npv\": 0.8916601714731099, \"accuracy\": 0.9559193954659949, \"f1\": 0.9643221202854231, \"f2\": 0.9443945293001896, \"f0_5\": 0.9851088201603666, \"p4\": 0.9532040227100975, \"phi\": 0.9106949434377939}, {\"truth_threshold\": -8.933466444012229, \"match_probability\": 0.002041132869425179, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1891.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 140.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.931068439192516, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.068931560807484, \"precision\": 0.9994714587737844, \"recall\": 0.931068439192516, \"specificity\": 0.9991266375545852, \"npv\": 0.8909657320872274, \"accuracy\": 0.9556045340050378, \"f1\": 0.9640581187866428, \"f2\": 0.9439896166134185, \"f0_5\": 0.9849984373372226, \"p4\": 0.9528765681795183, \"phi\": 0.9100990556480278}, {\"truth_threshold\": -8.867460447955294, \"match_probability\": 0.0021364836035206226, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1889.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 142.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.930083702609552, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.06991629739044805, \"precision\": 0.9994708994708995, \"recall\": 0.930083702609552, \"specificity\": 0.9991266375545852, \"npv\": 0.8895800933125972, \"accuracy\": 0.9549748110831234, \"f1\": 0.9635297118082122, \"f2\": 0.9431795486319153, \"f0_5\": 0.9847773954749244, \"p4\": 0.9522219246703738, \"phi\": 0.908908892809184}, {\"truth_threshold\": -8.864901189556928, \"match_probability\": 0.0021402688478976634, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1888.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 143.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.92959133431807, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.07040866568193008, \"precision\": 0.9994706193753309, \"recall\": 0.92959133431807, \"specificity\": 0.9991266375545852, \"npv\": 0.8888888888888888, \"accuracy\": 0.9546599496221663, \"f1\": 0.963265306122449, \"f2\": 0.9427743932887247, \"f0_5\": 0.984666736205278, \"p4\": 0.9518947353575811, \"phi\": 0.908314615542949}, {\"truth_threshold\": -8.828645716456817, \"match_probability\": 0.002194616605672812, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1887.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 144.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9290989660265879, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.07090103397341212, \"precision\": 0.9994703389830508, \"recall\": 0.9290989660265879, \"specificity\": 0.9991266375545852, \"npv\": 0.8881987577639752, \"accuracy\": 0.9543450881612091, \"f1\": 0.9630007655014035, \"f2\": 0.9423691570115861, \"f0_5\": 0.9845559845559846, \"p4\": 0.9515676341164773, \"phi\": 0.907720872905522}, {\"truth_threshold\": -8.827852895151006, \"match_probability\": 0.0021958203218311605, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1881.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 150.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9261447562776958, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.07385524372230429, \"precision\": 0.9994686503719448, \"recall\": 0.9261447562776958, \"specificity\": 0.9991266375545852, \"npv\": 0.884080370942813, \"accuracy\": 0.952455919395466, \"f1\": 0.9614106823409149, \"f2\": 0.9399360383769738, \"f0_5\": 0.9838895281933256, \"p4\": 0.9496068668152875, \"phi\": 0.904169582805711}, {\"truth_threshold\": -8.792646736347937, \"match_probability\": 0.0022499421548835994, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1879.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 152.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9251600196947316, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.07483998030526834, \"precision\": 0.999468085106383, \"recall\": 0.9251600196947316, \"specificity\": 0.9991266375545852, \"npv\": 0.8827160493827161, \"accuracy\": 0.9518261964735516, \"f1\": 0.9608795704423421, \"f2\": 0.939124350259896, \"f0_5\": 0.9836666317663072, \"p4\": 0.9489539747106858, \"phi\": 0.9029900468694608}, {\"truth_threshold\": -8.75660701958724, \"match_probability\": 0.002306724201036016, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1878.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 153.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9246676514032496, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.07533234859675036, \"precision\": 0.9994678020223523, \"recall\": 0.9246676514032496, \"specificity\": 0.9991266375545852, \"npv\": 0.882035466461064, \"accuracy\": 0.9515113350125944, \"f1\": 0.960613810741688, \"f2\": 0.9387183844846546, \"f0_5\": 0.9835550434691526, \"p4\": 0.9486276585927369, \"phi\": 0.9024010666675019}, {\"truth_threshold\": -8.668231609916143, \"match_probability\": 0.0024520879323333186, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1872.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 159.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9217134416543574, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.07828655834564253, \"precision\": 0.999466097170315, \"recall\": 0.9217134416543574, \"specificity\": 0.9991266375545852, \"npv\": 0.8779739063699156, \"accuracy\": 0.9496221662468514, \"f1\": 0.9590163934426229, \"f2\": 0.9362808842652796, \"f0_5\": 0.9828835451013336, \"p4\": 0.9466715704303053, \"phi\": 0.8988781465588541}, {\"truth_threshold\": -8.663500906449482, \"match_probability\": 0.002460121893530934, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1867.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 164.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9192516001969473, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.08074839980305268, \"precision\": 0.9994646680942184, \"recall\": 0.9192516001969473, \"specificity\": 0.9991266375545852, \"npv\": 0.8746177370030581, \"accuracy\": 0.9480478589420654, \"f1\": 0.9576814567837907, \"f2\": 0.9342473979183347, \"f0_5\": 0.9823213721982532, \"p4\": 0.9450438468942138, \"phi\": 0.8959566166075553}, {\"truth_threshold\": -8.493237994009421, \"match_probability\": 0.002767432625927421, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1861.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 170.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9162973904480551, \"tn_rate\": 0.9991266375545852, \"fp_rate\": 0.0008733624454148472, \"fn_rate\": 0.08370260955194485, \"precision\": 0.9994629430719656, \"recall\": 0.9162973904480551, \"specificity\": 0.9991266375545852, \"npv\": 0.8706240487062404, \"accuracy\": 0.9461586901763224, \"f1\": 0.9560750064217827, \"f2\": 0.9318045263368716, \"f0_5\": 0.9816436332946513, \"p4\": 0.9430933672772714, \"phi\": 0.8924676681686041}, {\"truth_threshold\": -8.456329997229089, \"match_probability\": 0.002838940744577297, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1859.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 172.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9153126538650911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08468734613490891, \"precision\": 1.0, \"recall\": 0.9153126538650911, \"specificity\": 1.0, \"npv\": 0.8694001518602885, \"accuracy\": 0.9458438287153652, \"f1\": 0.9557840616966581, \"f2\": 0.93108284082941, \"f0_5\": 0.9818316256469842, \"p4\": 0.9427867053899786, \"phi\": 0.8920610742936573}, {\"truth_threshold\": -8.443445458337857, \"match_probability\": 0.0028643355961717534, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1857.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 174.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.914327917282127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08567208271787297, \"precision\": 1.0, \"recall\": 0.914327917282127, \"specificity\": 1.0, \"npv\": 0.868081880212282, \"accuracy\": 0.9452141057934509, \"f1\": 0.9552469135802469, \"f2\": 0.9302675082657048, \"f0_5\": 0.981604820805582, \"p4\": 0.9421375437999479, \"phi\": 0.8909048757105602}, {\"truth_threshold\": -8.38655954141176, \"match_probability\": 0.0029791902677590515, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1856.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 175.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.913835548990645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08616445100935499, \"precision\": 1.0, \"recall\": 0.913835548990645, \"specificity\": 1.0, \"npv\": 0.8674242424242424, \"accuracy\": 0.9448992443324937, \"f1\": 0.9549781322356573, \"f2\": 0.9298597194388778, \"f0_5\": 0.9814912744579588, \"p4\": 0.9418130872496234, \"phi\": 0.8903275289372737}, {\"truth_threshold\": -8.265831603259677, \"match_probability\": 0.003238381835174978, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1855.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 176.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.913343180699163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08665681930083703, \"precision\": 1.0, \"recall\": 0.913343180699163, \"specificity\": 1.0, \"npv\": 0.8667676003028009, \"accuracy\": 0.9445843828715366, \"f1\": 0.9547092125579002, \"f2\": 0.9294518488826535, \"f0_5\": 0.9813776319966141, \"p4\": 0.9414887133057769, \"phi\": 0.8897506824878196}, {\"truth_threshold\": -8.257735451898522, \"match_probability\": 0.0032565468053282545, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1854.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 177.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.912850812407681, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08714918759231906, \"precision\": 1.0, \"recall\": 0.912850812407681, \"specificity\": 1.0, \"npv\": 0.8661119515885023, \"accuracy\": 0.9442695214105793, \"f1\": 0.9544401544401544, \"f2\": 0.9290438965724594, \"f0_5\": 0.9812638932994602, \"p4\": 0.9411644218008959, \"phi\": 0.8891743353491296}, {\"truth_threshold\": -8.240278738137855, \"match_probability\": 0.0032960599503189542, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1853.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 178.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9123584441161989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08764155588380108, \"precision\": 1.0, \"recall\": 0.9123584441161989, \"specificity\": 1.0, \"npv\": 0.8654572940287226, \"accuracy\": 0.9439546599496221, \"f1\": 0.9541709577754892, \"f2\": 0.9286358624837125, \"f0_5\": 0.9811500582442021, \"p4\": 0.9408402125674472, \"phi\": 0.8885984865106743}, {\"truth_threshold\": -8.1521219030373, \"match_probability\": 0.0035030211965550854, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1850.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 181.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9108813392417529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08911866075824718, \"precision\": 1.0, \"recall\": 0.9108813392417529, \"specificity\": 1.0, \"npv\": 0.8634992458521871, \"accuracy\": 0.9430100755667506, \"f1\": 0.9533625354290132, \"f2\": 0.9274112693001805, \"f0_5\": 0.980807973703743, \"p4\": 0.9398680768200446, \"phi\": 0.8868739197293399}, {\"truth_threshold\": -7.983779341394521, \"match_probability\": 0.003934872593998928, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1848.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 183.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9098966026587888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09010339734121123, \"precision\": 1.0, \"recall\": 0.9098966026587888, \"specificity\": 1.0, \"npv\": 0.8621987951807228, \"accuracy\": 0.9423803526448362, \"f1\": 0.9528228924980665, \"f2\": 0.9265944645006017, \"f0_5\": 0.9805794333014963, \"p4\": 0.9392203946065271, \"phi\": 0.8857266816300843}, {\"truth_threshold\": -7.969726827133738, \"match_probability\": 0.0039732343086816635, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1847.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 184.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9094042343673068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09059576563269325, \"precision\": 1.0, \"recall\": 0.9094042343673068, \"specificity\": 1.0, \"npv\": 0.8615500376222723, \"accuracy\": 0.9420654911838791, \"f1\": 0.9525528623001547, \"f2\": 0.9261859392237489, \"f0_5\": 0.9804650175177833, \"p4\": 0.9388966754822644, \"phi\": 0.8851538015130517}, {\"truth_threshold\": -7.967302441256911, \"match_probability\": 0.0039798901728118835, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1846.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 185.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9089118660758247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09108813392417528, \"precision\": 1.0, \"recall\": 0.9089118660758247, \"specificity\": 1.0, \"npv\": 0.8609022556390977, \"accuracy\": 0.9417506297229219, \"f1\": 0.9522826928037142, \"f2\": 0.925777331995988, \"f0_5\": 0.9803505045140732, \"p4\": 0.9385730374560877, \"phi\": 0.8845814126929296}, {\"truth_threshold\": -7.962571737790249, \"match_probability\": 0.0039929097518154235, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1845.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 186.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9084194977843427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0915805022156573, \"precision\": 1.0, \"recall\": 0.9084194977843427, \"specificity\": 1.0, \"npv\": 0.8602554470323065, \"accuracy\": 0.9414357682619647, \"f1\": 0.9520123839009288, \"f2\": 0.9253686427926573, \"f0_5\": 0.980235894166401, \"p4\": 0.9382494803602835, \"phi\": 0.8840095141791932}, {\"truth_threshold\": -7.890657114594739, \"match_probability\": 0.00419613383101672, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1844.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 187.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9079271294928607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09207287050713935, \"precision\": 1.0, \"recall\": 0.9079271294928607, \"specificity\": 1.0, \"npv\": 0.8596096096096096, \"accuracy\": 0.9411209068010076, \"f1\": 0.951741935483871, \"f2\": 0.9249598715890851, \"f0_5\": 0.98012118635059, \"p4\": 0.9379260040271141, \"phi\": 0.8834381049837795}, {\"truth_threshold\": -7.828989758814424, \"match_probability\": 0.004378581900968171, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1843.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 188.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9074347612013787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09256523879862137, \"precision\": 1.0, \"recall\": 0.9074347612013787, \"specificity\": 1.0, \"npv\": 0.8589647411852963, \"accuracy\": 0.9408060453400504, \"f1\": 0.9514713474445018, \"f2\": 0.92455101836059, \"f0_5\": 0.9800063809422525, \"p4\": 0.937602608288817, \"phi\": 0.8828671841210791}, {\"truth_threshold\": -7.817591014624138, \"match_probability\": 0.004413160859157262, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1841.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 190.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9064500246184146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09354997538158542, \"precision\": 1.0, \"recall\": 0.9064500246184146, \"specificity\": 1.0, \"npv\": 0.8576779026217228, \"accuracy\": 0.940176322418136, \"f1\": 0.9509297520661157, \"f2\": 0.9237330657300552, \"f0_5\": 0.979776476849388, \"p4\": 0.9369560579256638, \"phi\": 0.881726803463596}, {\"truth_threshold\": -7.762983762757488, \"match_probability\": 0.004582624250214648, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1839.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 192.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9054652880354506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09453471196454949, \"precision\": 1.0, \"recall\": 0.9054652880354506, \"specificity\": 1.0, \"npv\": 0.856394913986537, \"accuracy\": 0.9395465994962217, \"f1\": 0.9503875968992248, \"f2\": 0.9229147847034026, \"f0_5\": 0.9795461808884628, \"p4\": 0.9363098279282152, \"phi\": 0.8805883643706148}, {\"truth_threshold\": -7.723376209953201, \"match_probability\": 0.004709577176107309, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1831.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 200.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9015263417035942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09847365829640571, \"precision\": 1.0, \"recall\": 0.9015263417035942, \"specificity\": 1.0, \"npv\": 0.8513011152416357, \"accuracy\": 0.9370277078085643, \"f1\": 0.9482133609528741, \"f2\": 0.9196383726770467, \"f0_5\": 0.9786210582576162, \"p4\": 0.9337280847282874, \"phi\": 0.876053868270657}, {\"truth_threshold\": -7.652130334389432, \"match_probability\": 0.004946813455800192, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1829.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 202.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9005416051206302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09945839487936976, \"precision\": 1.0, \"recall\": 0.9005416051206302, \"specificity\": 1.0, \"npv\": 0.85003711952487, \"accuracy\": 0.9363979848866498, \"f1\": 0.9476683937823834, \"f2\": 0.9188184466994876, \"f0_5\": 0.9783887878463678, \"p4\": 0.9330834364050486, \"phi\": 0.8749250208040935}, {\"truth_threshold\": -7.584577086373498, \"match_probability\": 0.005182724351357303, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1820.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 211.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.896110290497292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10388970950270802, \"precision\": 1.0, \"recall\": 0.896110290497292, \"specificity\": 1.0, \"npv\": 0.8443952802359882, \"accuracy\": 0.9335642317380353, \"f1\": 0.9452090366138666, \"f2\": 0.915124698310539, \"f0_5\": 0.9773386317259156, \"p4\": 0.9301863642374388, \"phi\": 0.8698685532118136}, {\"truth_threshold\": -7.563754924718337, \"match_probability\": 0.005257671963616832, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1812.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 219.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8921713441654358, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10782865583456426, \"precision\": 1.0, \"recall\": 0.8921713441654358, \"specificity\": 1.0, \"npv\": 0.8394428152492669, \"accuracy\": 0.9310453400503779, \"f1\": 0.9430132708821234, \"f2\": 0.9118357487922706, \"f0_5\": 0.9763983187843518, \"p4\": 0.9276163988704911, \"phi\": 0.8654055840072653}, {\"truth_threshold\": -7.559024221251676, \"match_probability\": 0.005274849465643765, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1806.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 225.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8892171344165436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11078286558345643, \"precision\": 1.0, \"recall\": 0.8892171344165436, \"specificity\": 1.0, \"npv\": 0.8357664233576643, \"accuracy\": 0.9291561712846348, \"f1\": 0.9413604378420641, \"f2\": 0.9093655589123867, \"f0_5\": 0.9756888168557536, \"p4\": 0.9256920884275059, \"phi\": 0.8620776206465783}, {\"truth_threshold\": -7.4242284452556495, \"match_probability\": 0.005788464062233896, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1803.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 228.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8877400295420975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11225997045790251, \"precision\": 1.0, \"recall\": 0.8877400295420975, \"specificity\": 1.0, \"npv\": 0.8339402767662054, \"accuracy\": 0.9282115869017632, \"f1\": 0.9405320813771518, \"f2\": 0.908129344212753, \"f0_5\": 0.9753326841934437, \"p4\": 0.9247309371543908, \"phi\": 0.8604197614727223}, {\"truth_threshold\": -7.286891422024204, \"match_probability\": 0.006362897198913155, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1801.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 230.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8867552929591335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11324470704086657, \"precision\": 1.0, \"recall\": 0.8867552929591335, \"specificity\": 1.0, \"npv\": 0.8327272727272728, \"accuracy\": 0.9275818639798489, \"f1\": 0.9399791231732777, \"f2\": 0.9073047858942066, \"f0_5\": 0.9750947482403898, \"p4\": 0.9240905383726037, \"phi\": 0.859316773188056}, {\"truth_threshold\": -7.283491376936334, \"match_probability\": 0.006377814772263544, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1799.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 232.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8857705563761694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11422944362383063, \"precision\": 1.0, \"recall\": 0.8857705563761694, \"specificity\": 1.0, \"npv\": 0.831517792302106, \"accuracy\": 0.9269521410579346, \"f1\": 0.9394255874673629, \"f2\": 0.906479895192986, \"f0_5\": 0.9748563996965428, \"p4\": 0.9234504329987309, \"phi\": 0.8582155775352254}, {\"truth_threshold\": -7.223384641305333, \"match_probability\": 0.006647341810259097, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1797.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 234.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8847858197932054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11521418020679468, \"precision\": 1.0, \"recall\": 0.8847858197932054, \"specificity\": 1.0, \"npv\": 0.8303118201595359, \"accuracy\": 0.9263224181360201, \"f1\": 0.9388714733542319, \"f2\": 0.9056546719080738, \"f0_5\": 0.974617637487797, \"p4\": 0.9228106196785895, \"phi\": 0.8571161674381387}, {\"truth_threshold\": -7.169948009141407, \"match_probability\": 0.0068964424992212035, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1795.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 236.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8838010832102413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11619891678975874, \"precision\": 1.0, \"recall\": 0.8838010832102413, \"specificity\": 1.0, \"npv\": 0.8291093410572049, \"accuracy\": 0.9256926952141058, \"f1\": 0.9383167799268165, \"f2\": 0.9048291158382902, \"f0_5\": 0.9743784605363153, \"p4\": 0.9221710970572993, \"phi\": 0.8560185358542695}, {\"truth_threshold\": -7.16056209675606, \"match_probability\": 0.006941143325604225, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1793.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 238.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8828163466272771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1171836533727228, \"precision\": 1.0, \"recall\": 0.8828163466272771, \"specificity\": 1.0, \"npv\": 0.8279103398409255, \"accuracy\": 0.9250629722921915, \"f1\": 0.9377615062761506, \"f2\": 0.9040032267822931, \"f0_5\": 0.9741388677605128, \"p4\": 0.9215318637792689, \"phi\": 0.8549226757744313}, {\"truth_threshold\": -7.114574831235299, \"match_probability\": 0.007164352263652575, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1792.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 239.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8823239783357951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11767602166420482, \"precision\": 1.0, \"recall\": 0.8823239783357951, \"specificity\": 1.0, \"npv\": 0.8273121387283237, \"accuracy\": 0.9247481108312342, \"f1\": 0.9374836515825268, \"f2\": 0.9035901573215006, \"f0_5\": 0.9740189150994674, \"p4\": 0.9212123552201559, \"phi\": 0.8543754078672149}, {\"truth_threshold\": -7.095771750735605, \"match_probability\": 0.007257656457229453, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1791.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 240.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8818316100443131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11816838995568685, \"precision\": 1.0, \"recall\": 0.8818316100443131, \"specificity\": 1.0, \"npv\": 0.8267148014440433, \"accuracy\": 0.924433249370277, \"f1\": 0.9372056514913658, \"f2\": 0.903177004538578, \"f0_5\": 0.9738988580750407, \"p4\": 0.9208929184881818, \"phi\": 0.8538285802225557}, {\"truth_threshold\": -7.0702476262801985, \"match_probability\": 0.007386244456299404, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1789.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 242.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.880846873461349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11915312653865091, \"precision\": 1.0, \"recall\": 0.880846873461349, \"specificity\": 1.0, \"npv\": 0.8255227108868061, \"accuracy\": 0.9238035264483627, \"f1\": 0.9366492146596859, \"f2\": 0.9023504489054777, \"f0_5\": 0.9736584303907696, \"p4\": 0.9202542598269833, \"phi\": 0.8527362422554705}, {\"truth_threshold\": -7.052352340774079, \"match_probability\": 0.007477745135182014, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1788.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 243.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.880354505169867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11964549483013294, \"precision\": 1.0, \"recall\": 0.880354505169867, \"specificity\": 1.0, \"npv\": 0.8249279538904899, \"accuracy\": 0.9234886649874056, \"f1\": 0.9363707776904949, \"f2\": 0.9019370460048426, \"f0_5\": 0.9735380594576936, \"p4\": 0.9199350375583073, \"phi\": 0.8521907302054237}, {\"truth_threshold\": -6.989093298137944, \"match_probability\": 0.0078103048755581005, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1787.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 244.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.879862136878385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12013786312161497, \"precision\": 1.0, \"recall\": 0.879862136878385, \"specificity\": 1.0, \"npv\": 0.8243340532757379, \"accuracy\": 0.9231738035264484, \"f1\": 0.9360921948664223, \"f2\": 0.9015235596811624, \"f0_5\": 0.9734175836147728, \"p4\": 0.9196158864378663, \"phi\": 0.8516456549626794}, {\"truth_threshold\": -6.859476387318896, \"match_probability\": 0.008538229535440285, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1786.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 245.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.879369768586903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12063023141309699, \"precision\": 1.0, \"recall\": 0.879369768586903, \"specificity\": 1.0, \"npv\": 0.8237410071942446, \"accuracy\": 0.9228589420654912, \"f1\": 0.9358134660728321, \"f2\": 0.9011099899091827, \"f0_5\": 0.9732970027247957, \"p4\": 0.9192968062958145, \"phi\": 0.8511010156684959}, {\"truth_threshold\": -6.855538505158045, \"match_probability\": 0.008561366942429113, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1784.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 247.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8783850320039389, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12161496799606106, \"precision\": 1.0, \"recall\": 0.8783850320039389, \"specificity\": 1.0, \"npv\": 0.8225574712643678, \"accuracy\": 0.9222292191435768, \"f1\": 0.9352555701179555, \"f2\": 0.9002825999192572, \"f0_5\": 0.9730555252536272, \"p4\": 0.9186588582672518, \"phi\": 0.8500130415009118}, {\"truth_threshold\": -6.854745683852235, \"match_probability\": 0.008566032752069483, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1783.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 248.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8778926637124569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12210733628754308, \"precision\": 1.0, \"recall\": 0.8778926637124569, \"specificity\": 1.0, \"npv\": 0.8219669777458722, \"accuracy\": 0.9219143576826196, \"f1\": 0.934976402726796, \"f2\": 0.899868779650752, \"f0_5\": 0.9729346283968132, \"p4\": 0.9183399900408039, \"phi\": 0.8494697049200762}, {\"truth_threshold\": -6.784258402617329, \"match_probability\": 0.008991088701607046, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1782.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 249.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8774002954209749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12259970457902511, \"precision\": 1.0, \"recall\": 0.8774002954209749, \"specificity\": 1.0, \"npv\": 0.8213773314203731, \"accuracy\": 0.9215994962216625, \"f1\": 0.9346970889063729, \"f2\": 0.8994548758328286, \"f0_5\": 0.9728136259416967, \"p4\": 0.9180211921128707, \"phi\": 0.8489268008729182}, {\"truth_threshold\": -6.753862838457673, \"match_probability\": 0.00918077038668785, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1781.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 250.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8769079271294928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12309207287050714, \"precision\": 1.0, \"recall\": 0.8769079271294928, \"specificity\": 1.0, \"npv\": 0.8207885304659498, \"accuracy\": 0.9212846347607053, \"f1\": 0.934417628541448, \"f2\": 0.8990408884401817, \"f0_5\": 0.9726925177498634, \"p4\": 0.9177024643133584, \"phi\": 0.8483843285107042}, {\"truth_threshold\": -6.749924956296822, \"match_probability\": 0.009205632822605208, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1780.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 251.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8764155588380108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12358444116198916, \"precision\": 1.0, \"recall\": 0.8764155588380108, \"specificity\": 1.0, \"npv\": 0.8202005730659025, \"accuracy\": 0.9209697732997482, \"f1\": 0.9341380215166623, \"f2\": 0.898626817447496, \"f0_5\": 0.9725713036826577, \"p4\": 0.9173838064721223, \"phi\": 0.8478422869866835}, {\"truth_threshold\": -6.749132134991012, \"match_probability\": 0.009210646485045272, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1779.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 252.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8759231905465288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1240768094534712, \"precision\": 1.0, \"recall\": 0.8759231905465288, \"specificity\": 1.0, \"npv\": 0.819613457408733, \"accuracy\": 0.9206549118387909, \"f1\": 0.9338582677165355, \"f2\": 0.8982126628294457, \"f0_5\": 0.9724499836011807, \"p4\": 0.9170652184189663, \"phi\": 0.8473006754560798}, {\"truth_threshold\": -6.589510849756149, \"match_probability\": 0.010277161223550295, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1778.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 253.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8754308222550468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12456917774495323, \"precision\": 1.0, \"recall\": 0.8754308222550468, \"specificity\": 1.0, \"npv\": 0.8190271816881259, \"accuracy\": 0.9203400503778337, \"f1\": 0.933578367025466, \"f2\": 0.8977984245606948, \"f0_5\": 0.9723285573662912, \"p4\": 0.9167466999836424, \"phi\": 0.8467594930760858}, {\"truth_threshold\": -6.572260583859923, \"match_probability\": 0.010399496960517153, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1763.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 268.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8680452978828164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13195470211718366, \"precision\": 1.0, \"recall\": 0.8680452978828164, \"specificity\": 1.0, \"npv\": 0.8103326256192498, \"accuracy\": 0.9156171284634761, \"f1\": 0.9293621507643648, \"f2\": 0.8915747951855972, \"f0_5\": 0.9704943300671585, \"p4\": 0.911977161661481, \"phi\": 0.8386926882892364}, {\"truth_threshold\": -6.526011601712208, \"match_probability\": 0.010734641799224388, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1762.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 269.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8675529295913343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13244707040866568, \"precision\": 1.0, \"recall\": 0.8675529295913343, \"specificity\": 1.0, \"npv\": 0.8097595473833098, \"accuracy\": 0.9153022670025189, \"f1\": 0.9290798839968363, \"f2\": 0.8911592150515881, \"f0_5\": 0.9703711862539928, \"p4\": 0.911659733913786, \"phi\": 0.8381582592786062}, {\"truth_threshold\": -6.4503604672411665, \"match_probability\": 0.011306024039730281, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1760.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 271.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8665681930083703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13343180699162974, \"precision\": 1.0, \"recall\": 0.8665681930083703, \"specificity\": 1.0, \"npv\": 0.8086158192090396, \"accuracy\": 0.9146725440806045, \"f1\": 0.9285149037193353, \"f2\": 0.8903278025091056, \"f0_5\": 0.9701245728144636, \"p4\": 0.9110250783929349, \"phi\": 0.8370906458024485}, {\"truth_threshold\": -6.449567645935356, \"match_probability\": 0.01131216857730224, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1759.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 272.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8660758247168883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13392417528311176, \"precision\": 1.0, \"recall\": 0.8660758247168883, \"specificity\": 1.0, \"npv\": 0.808045165843331, \"accuracy\": 0.9143576826196473, \"f1\": 0.9282321899736148, \"f2\": 0.8899119700495801, \"f0_5\": 0.9700011029006287, \"p4\": 0.9107078502772067, \"phi\": 0.8365574597218397}, {\"truth_threshold\": -6.44091276948974, \"match_probability\": 0.011379460846066218, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1757.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 274.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8650910881339242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13490891186607581, \"precision\": 1.0, \"recall\": 0.8650910881339242, \"specificity\": 1.0, \"npv\": 0.806906272022551, \"accuracy\": 0.913727959697733, \"f1\": 0.9276663146779303, \"f2\": 0.8890800526262524, \"f0_5\": 0.9697538359642345, \"p4\": 0.9100735924782588, \"phi\": 0.8354923248516871}, {\"truth_threshold\": -6.419096397795696, \"match_probability\": 0.011550845461587163, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1756.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 275.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8645987198424422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13540128015755784, \"precision\": 1.0, \"recall\": 0.8645987198424422, \"specificity\": 1.0, \"npv\": 0.8063380281690141, \"accuracy\": 0.9134130982367759, \"f1\": 0.9273831528914708, \"f2\": 0.888663967611336, \"f0_5\": 0.969630038652678, \"p4\": 0.9097565624521012, \"phi\": 0.8349603744580988}, {\"truth_threshold\": -6.405408496744226, \"match_probability\": 0.01165967441944785, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1755.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 276.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8641063515509602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1358936484490399, \"precision\": 1.0, \"recall\": 0.8641063515509602, \"specificity\": 1.0, \"npv\": 0.8057705840957072, \"accuracy\": 0.9130982367758187, \"f1\": 0.9270998415213946, \"f2\": 0.8882477983601579, \"f0_5\": 0.9695061319191249, \"p4\": 0.9094395981127592, \"phi\": 0.8344288343591847}, {\"truth_threshold\": -6.350088681471035, \"match_probability\": 0.012109925014980285, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1754.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 277.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8636139832594781, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13638601674052192, \"precision\": 1.0, \"recall\": 0.8636139832594781, \"specificity\": 1.0, \"npv\": 0.8052039381153305, \"accuracy\": 0.9127833753148614, \"f1\": 0.9268163804491414, \"f2\": 0.887831544847135, \"f0_5\": 0.969382115618437, \"p4\": 0.9091226992886084, \"phi\": 0.8338977037574806}, {\"truth_threshold\": -6.325909966679385, \"match_probability\": 0.012312070579072994, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1753.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 278.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8631216149679961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13687838503200395, \"precision\": 1.0, \"recall\": 0.8631216149679961, \"specificity\": 1.0, \"npv\": 0.8046380885453268, \"accuracy\": 0.9124685138539043, \"f1\": 0.9265327695560254, \"f2\": 0.8874152070466741, \"f0_5\": 0.9692579896052195, \"p4\": 0.9088058658079613, \"phi\": 0.8333669818573352}, {\"truth_threshold\": -6.319751760057843, \"match_probability\": 0.012364086335669322, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1752.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 279.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8626292466765141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13737075332348597, \"precision\": 1.0, \"recall\": 0.8626292466765141, \"specificity\": 1.0, \"npv\": 0.8040730337078652, \"accuracy\": 0.9121536523929471, \"f1\": 0.9262490087232356, \"f2\": 0.8869987849331713, \"f0_5\": 0.9691337537338202, \"p4\": 0.9084890974990668, \"phi\": 0.8328366678649031}, {\"truth_threshold\": -6.254664091115616, \"match_probability\": 0.012927294384110031, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1749.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 282.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8611521418020679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13884785819793205, \"precision\": 1.0, \"recall\": 0.8611521418020679, \"specificity\": 1.0, \"npv\": 0.8023826208829713, \"accuracy\": 0.9112090680100756, \"f1\": 0.9253968253968254, \"f2\": 0.8857490124582194, \"f0_5\": 0.9687603855101362, \"p4\": 0.9075391818844284, \"phi\": 0.831248165422413}, {\"truth_threshold\": -6.253871269809806, \"match_probability\": 0.012934308514037342, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1745.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 286.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8591826686361398, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14081733136386015, \"precision\": 1.0, \"recall\": 0.8591826686361398, \"specificity\": 1.0, \"npv\": 0.8001397624039134, \"accuracy\": 0.9099496221662469, \"f1\": 0.9242584745762712, \"f2\": 0.8840814672205898, \"f0_5\": 0.9682610143158362, \"p4\": 0.9062735297052606, \"phi\": 0.829135825027529}, {\"truth_threshold\": -6.221392429432036, \"match_probability\": 0.013224901479391689, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1742.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 289.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8577055637616937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14229443623830626, \"precision\": 1.0, \"recall\": 0.8577055637616937, \"specificity\": 1.0, \"npv\": 0.798465829846583, \"accuracy\": 0.9090050377833753, \"f1\": 0.9234031274847602, \"f2\": 0.8828299209406041, \"f0_5\": 0.9678853205911768, \"p4\": 0.9053249610250113, \"phi\": 0.8275557894988181}, {\"truth_threshold\": -6.187110843099682, \"match_probability\": 0.013538611952504406, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1741.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 290.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8572131954702117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14278680452978829, \"precision\": 1.0, \"recall\": 0.8572131954702117, \"specificity\": 1.0, \"npv\": 0.7979094076655052, \"accuracy\": 0.9086901763224181, \"f1\": 0.9231177094379639, \"f2\": 0.8824125696908262, \"f0_5\": 0.9677598665925514, \"p4\": 0.9050088982512212, \"phi\": 0.827029910608251}, {\"truth_threshold\": -6.186318021793872, \"match_probability\": 0.013545953221032539, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1740.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 291.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8567208271787297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1432791728212703, \"precision\": 1.0, \"recall\": 0.8567208271787297, \"specificity\": 1.0, \"npv\": 0.7973537604456824, \"accuracy\": 0.908375314861461, \"f1\": 0.9228321400159109, \"f2\": 0.8819951338199513, \"f0_5\": 0.9676343009676343, \"p4\": 0.9046928985830542, \"phi\": 0.8265044302380331}, {\"truth_threshold\": -6.179014691738527, \"match_probability\": 0.013613764617508621, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1734.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 297.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8537666174298375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14623338257016247, \"precision\": 1.0, \"recall\": 0.8537666174298375, \"specificity\": 1.0, \"npv\": 0.7940360610263523, \"accuracy\": 0.9064861460957179, \"f1\": 0.9211155378486056, \"f2\": 0.8794887401095557, \"f0_5\": 0.9668785547005687, \"p4\": 0.9027982161205977, \"phi\": 0.8233598738946298}, {\"truth_threshold\": -6.166288681444521, \"match_probability\": 0.013732726397725046, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1732.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 299.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8527818808468735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14721811915312655, \"precision\": 1.0, \"recall\": 0.8527818808468735, \"specificity\": 1.0, \"npv\": 0.7929362880886427, \"accuracy\": 0.9058564231738035, \"f1\": 0.9205421206484188, \"f2\": 0.8786525974025974, \"f0_5\": 0.9666257394798526, \"p4\": 0.9021671523111625, \"phi\": 0.8223148418628785}, {\"truth_threshold\": -6.16155797797786, \"match_probability\": 0.013777209516174917, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1730.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 301.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8517971442639094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1482028557360906, \"precision\": 1.0, \"recall\": 0.8517971442639094, \"specificity\": 1.0, \"npv\": 0.7918395573997233, \"accuracy\": 0.9052267002518891, \"f1\": 0.9199680935921297, \"f2\": 0.8778161152831337, \"f0_5\": 0.9663724723494581, \"p4\": 0.9015363346996595, \"phi\": 0.8212713764087255}, {\"truth_threshold\": -6.073401142877304, \"match_probability\": 0.014632625545163477, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1729.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 302.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8513047759724274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14869522402757263, \"precision\": 1.0, \"recall\": 0.8513047759724274, \"specificity\": 1.0, \"npv\": 0.7912923289564616, \"accuracy\": 0.904911838790932, \"f1\": 0.9196808510638298, \"f2\": 0.8773977468791231, \"f0_5\": 0.9662456689393093, \"p4\": 0.9012210177849239, \"phi\": 0.8207502292603889}, {\"truth_threshold\": -6.0095080804364045, \"match_probability\": 0.015285101165909453, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1726.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 305.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8498276710979813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1501723289020187, \"precision\": 1.0, \"recall\": 0.8498276710979813, \"specificity\": 1.0, \"npv\": 0.7896551724137931, \"accuracy\": 0.9039672544080605, \"f1\": 0.9188182060154378, \"f2\": 0.8761421319796955, \"f0_5\": 0.965864577504197, \"p4\": 0.9002754325235871, \"phi\": 0.8191891211087271}, {\"truth_threshold\": -5.895736770440405, \"match_probability\": 0.016518573797404894, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1725.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 306.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8493353028064993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15066469719350073, \"precision\": 1.0, \"recall\": 0.8493353028064993, \"specificity\": 1.0, \"npv\": 0.7891109579600276, \"accuracy\": 0.9036523929471033, \"f1\": 0.9185303514376997, \"f2\": 0.8757234236978373, \"f0_5\": 0.9657373194491098, \"p4\": 0.8999603586855487, \"phi\": 0.8186695269929782}, {\"truth_threshold\": -5.883823791634327, \"match_probability\": 0.016653258842737807, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1724.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 307.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8488429345150172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15115706548498276, \"precision\": 1.0, \"recall\": 0.8488429345150172, \"specificity\": 1.0, \"npv\": 0.7885674931129476, \"accuracy\": 0.9033375314861462, \"f1\": 0.9182423435419441, \"f2\": 0.8753046303818034, \"f0_5\": 0.9656099473507337, \"p4\": 0.8996453451825817, \"phi\": 0.8181503192672758}, {\"truth_threshold\": -5.813854339952209, \"match_probability\": 0.017466378760146208, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1722.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 309.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8478581979320532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15214180206794684, \"precision\": 1.0, \"recall\": 0.8478581979320532, \"specificity\": 1.0, \"npv\": 0.7874828060522696, \"accuracy\": 0.9027078085642317, \"f1\": 0.9176658673061551, \"f2\": 0.874466788543571, \"f0_5\": 0.9653548604103599, \"p4\": 0.8990154984866054, \"phi\": 0.817113060011865}, {\"truth_threshold\": -5.810293107442943, \"match_probability\": 0.017508791220447524, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1721.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 310.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8473658296405712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15263417035942886, \"precision\": 1.0, \"recall\": 0.8473658296405712, \"specificity\": 1.0, \"npv\": 0.7869415807560137, \"accuracy\": 0.9023929471032746, \"f1\": 0.9173773987206824, \"f2\": 0.8740477399695277, \"f0_5\": 0.9652271452607964, \"p4\": 0.8987006649457736, \"phi\": 0.8165950069991748}, {\"truth_threshold\": -5.807236493480812, \"match_probability\": 0.01754527458737221, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1720.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 311.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8468734613490891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1531265386509109, \"precision\": 1.0, \"recall\": 0.8468734613490891, \"specificity\": 1.0, \"npv\": 0.7864010989010989, \"accuracy\": 0.9020780856423174, \"f1\": 0.917088776326313, \"f2\": 0.8736286062576188, \"f0_5\": 0.9650993154528111, \"p4\": 0.8983858910443667, \"phi\": 0.8160773374105551}, {\"truth_threshold\": -5.7703397385952835, \"match_probability\": 0.01799160281453795, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1719.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 312.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8463810930576071, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1536189069423929, \"precision\": 1.0, \"recall\": 0.8463810930576071, \"specificity\": 1.0, \"npv\": 0.7858613589567605, \"accuracy\": 0.9017632241813602, \"f1\": 0.9168, \"f2\": 0.8732093873818958, \"f0_5\": 0.96497137083193, \"p4\": 0.8980711766082768, \"phi\": 0.815560050508581}, {\"truth_threshold\": -5.763095853482245, \"match_probability\": 0.018080529787847754, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1718.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 313.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8458887247661251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15411127523387494, \"precision\": 1.0, \"recall\": 0.8458887247661251, \"specificity\": 1.0, \"npv\": 0.7853223593964335, \"accuracy\": 0.9014483627204031, \"f1\": 0.916511069618565, \"f2\": 0.8727900833163991, \"f0_5\": 0.9648433112434011, \"p4\": 0.8977565214633161, \"phi\": 0.8150431455574445}, {\"truth_threshold\": -5.75499970212109, \"match_probability\": 0.018180429923574125, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1717.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 314.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8453963564746431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15460364352535697, \"precision\": 1.0, \"recall\": 0.8453963564746431, \"specificity\": 1.0, \"npv\": 0.7847840986977381, \"accuracy\": 0.9011335012594458, \"f1\": 0.916221985058698, \"f2\": 0.872370694035159, \"f0_5\": 0.9647151365321947, \"p4\": 0.8974419254352168, \"phi\": 0.8145266218229484}, {\"truth_threshold\": -5.750268998654429, \"match_probability\": 0.018239053637023994, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1716.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 315.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.844903988183161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.155096011816839, \"precision\": 1.0, \"recall\": 0.844903988183161, \"specificity\": 1.0, \"npv\": 0.7842465753424658, \"accuracy\": 0.9008186397984886, \"f1\": 0.9159327461969575, \"f2\": 0.8719512195121951, \"f0_5\": 0.9645868465430016, \"p4\": 0.8971273883496309, \"phi\": 0.814010478572503}, {\"truth_threshold\": -5.649386153259867, \"match_probability\": 0.019534293949680634, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1715.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 316.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.844411619891679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15558838010832102, \"precision\": 1.0, \"recall\": 0.844411619891679, \"specificity\": 1.0, \"npv\": 0.783709787816564, \"accuracy\": 0.9005037783375315, \"f1\": 0.9156433529097704, \"f2\": 0.8715316597215164, \"f0_5\": 0.9644584411202339, \"p4\": 0.8968129100321289, \"phi\": 0.8134947150751188}, {\"truth_threshold\": -5.6446554497932055, \"match_probability\": 0.019597196128204483, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1714.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 317.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.843919251600197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15608074839980304, \"precision\": 1.0, \"recall\": 0.843919251600197, \"specificity\": 1.0, \"npv\": 0.7831737346101231, \"accuracy\": 0.9001889168765743, \"f1\": 0.9153538050734312, \"f2\": 0.8711120146371214, \"f0_5\": 0.964329920108023, \"p4\": 0.8964984903082001, \"phi\": 0.8129793306014036}, {\"truth_threshold\": -5.485034164558342, \"match_probability\": 0.02183987478148299, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1713.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 318.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.843426883308715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15657311669128507, \"precision\": 1.0, \"recall\": 0.843426883308715, \"specificity\": 1.0, \"npv\": 0.7826384142173616, \"accuracy\": 0.8998740554156172, \"f1\": 0.9150641025641025, \"f2\": 0.8706922842329978, \"f0_5\": 0.9642012833502195, \"p4\": 0.8961841290032514, \"phi\": 0.8124643244235554}, {\"truth_threshold\": -5.481480330070432, \"match_probability\": 0.02189256067866156, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1703.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 328.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8385032003938946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16149679960610536, \"precision\": 1.0, \"recall\": 0.8385032003938946, \"specificity\": 1.0, \"npv\": 0.7773251866938221, \"accuracy\": 0.8967254408060453, \"f1\": 0.9121585431173005, \"f2\": 0.8664902818764628, \"f0_5\": 0.9629085152097704, \"p4\": 0.8930436905276049, \"phi\": 0.807334909928681}, {\"truth_threshold\": -5.475797824635624, \"match_probability\": 0.02197706258493461, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1701.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 330.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8375184638109305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16248153618906944, \"precision\": 1.0, \"recall\": 0.8375184638109305, \"specificity\": 1.0, \"npv\": 0.7762711864406779, \"accuracy\": 0.896095717884131, \"f1\": 0.9115755627009646, \"f2\": 0.8656488549618321, \"f0_5\": 0.9626485568760611, \"p4\": 0.8924162863583879, \"phi\": 0.8063134945965403}, {\"truth_threshold\": -5.30361918037576, \"match_probability\": 0.024694055083665616, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1700.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 331.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8370260955194485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16297390448055146, \"precision\": 1.0, \"recall\": 0.8370260955194485, \"specificity\": 1.0, \"npv\": 0.7757452574525745, \"accuracy\": 0.8957808564231738, \"f1\": 0.9112838381131064, \"f2\": 0.865228013029316, \"f0_5\": 0.9625184010870796, \"p4\": 0.8921026685740049, \"phi\": 0.805803340749626}, {\"truth_threshold\": -5.260248012980055, \"match_probability\": 0.025428530128064626, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1698.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 333.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8360413589364845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16395864106351551, \"precision\": 1.0, \"recall\": 0.8360413589364845, \"specificity\": 1.0, \"npv\": 0.7746955345060893, \"accuracy\": 0.8951511335012594, \"f1\": 0.910699919549477, \"f2\": 0.8643860720830788, \"f0_5\": 0.9622577354641279, \"p4\": 0.8914756007267217, \"phi\": 0.8047841371638093}, {\"truth_threshold\": -5.2075256253981435, \"match_probability\": 0.026350049162013826, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1697.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 334.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8355489906450024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16445100935499754, \"precision\": 1.0, \"recall\": 0.8355489906450024, \"specificity\": 1.0, \"npv\": 0.7741717376605814, \"accuracy\": 0.8948362720403022, \"f1\": 0.9104077253218884, \"f2\": 0.8639649730170044, \"f0_5\": 0.962127225308992, \"p4\": 0.8911621503119651, \"phi\": 0.8042750860173319}, {\"truth_threshold\": -5.149394584612, \"match_probability\": 0.027403772363291348, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1696.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 335.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8350566223535204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16494337764647957, \"precision\": 1.0, \"recall\": 0.8350566223535204, \"specificity\": 1.0, \"npv\": 0.7736486486486487, \"accuracy\": 0.8945214105793451, \"f1\": 0.9101153742956801, \"f2\": 0.8635437881873728, \"f0_5\": 0.9619965967101531, \"p4\": 0.8908487553350769, \"phi\": 0.8037664010326047}, {\"truth_threshold\": -5.081841336596065, \"match_probability\": 0.028679776052264693, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1694.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 337.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8340718857705564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16592811422944362, \"precision\": 1.0, \"recall\": 0.8340718857705564, \"specificity\": 1.0, \"npv\": 0.7726045883940621, \"accuracy\": 0.8938916876574308, \"f1\": 0.9095302013422819, \"f2\": 0.8627011611326135, \"f0_5\": 0.9617349835358238, \"p4\": 0.890222130990195, \"phi\": 0.8027501267498}, {\"truth_threshold\": -4.983071617986242, \"match_probability\": 0.030649733760699554, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1689.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 342.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8316100443131462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16838995568685378, \"precision\": 1.0, \"recall\": 0.8316100443131462, \"specificity\": 1.0, \"npv\": 0.7700067249495629, \"accuracy\": 0.8923173803526449, \"f1\": 0.9080645161290323, \"f2\": 0.8605930907979211, \"f0_5\": 0.9610788665073404, \"p4\": 0.8886565279485639, \"phi\": 0.8002158000544144}, {\"truth_threshold\": -4.978979989541249, \"match_probability\": 0.030734107497564316, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1688.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 343.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8311176760216642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1688823239783358, \"precision\": 1.0, \"recall\": 0.8311176760216642, \"specificity\": 1.0, \"npv\": 0.769489247311828, \"accuracy\": 0.8920025188916877, \"f1\": 0.9077709061575693, \"f2\": 0.8601712189156135, \"f0_5\": 0.960947284526927, \"p4\": 0.8883435701252902, \"phi\": 0.7997100192879079}, {\"truth_threshold\": -4.975575511943442, \"match_probability\": 0.03080448283175628, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1687.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 344.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8306253077301822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16937469226981783, \"precision\": 1.0, \"recall\": 0.8306253077301822, \"specificity\": 1.0, \"npv\": 0.7689724647414372, \"accuracy\": 0.8916876574307305, \"f1\": 0.907477138246369, \"f2\": 0.8597492610335338, \"f0_5\": 0.9608155826403918, \"p4\": 0.8880306661511507, \"phi\": 0.7992045984364035}, {\"truth_threshold\": -4.930340770508476, \"match_probability\": 0.03175448213548341, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1686.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 345.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8301329394387001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16986706056129985, \"precision\": 1.0, \"recall\": 0.8301329394387001, \"specificity\": 1.0, \"npv\": 0.7684563758389261, \"accuracy\": 0.8913727959697733, \"f1\": 0.9071832122679581, \"f2\": 0.8593272171253823, \"f0_5\": 0.9606837606837607, \"p4\": 0.8877178158491477, \"phi\": 0.7986995368131737}, {\"truth_threshold\": -4.922285516784027, \"match_probability\": 0.03192660200442167, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1684.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 347.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8291482028557361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1708517971442639, \"precision\": 1.0, \"recall\": 0.8291482028557361, \"specificity\": 1.0, \"npv\": 0.767426273458445, \"accuracy\": 0.8907430730478589, \"f1\": 0.9065948855989233, \"f2\": 0.8584828711256117, \"f0_5\": 0.9604197559028174, \"p4\": 0.8870922755530783, \"phi\": 0.7976904885118942}, {\"truth_threshold\": -4.921492695478216, \"match_probability\": 0.0319435912257212, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1683.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 348.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8286558345642541, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17134416543574593, \"precision\": 1.0, \"recall\": 0.8286558345642541, \"specificity\": 1.0, \"npv\": 0.7669122572002679, \"accuracy\": 0.8904282115869018, \"f1\": 0.9063004846526656, \"f2\": 0.8580605689813399, \"f0_5\": 0.9602875727490585, \"p4\": 0.8867795852045331, \"phi\": 0.7971865004676407}, {\"truth_threshold\": -4.914151697397324, \"match_probability\": 0.032101315889212216, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1677.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 354.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8257016248153619, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17429837518463812, \"precision\": 1.0, \"recall\": 0.8257016248153619, \"specificity\": 1.0, \"npv\": 0.7638425617078052, \"accuracy\": 0.8885390428211587, \"f1\": 0.9045307443365695, \"f2\": 0.8555249464340373, \"f0_5\": 0.9594919327154137, \"p4\": 0.8849045491245728, \"phi\": 0.7941700348824948}, {\"truth_threshold\": -4.912213670578015, \"match_probability\": 0.032143080743734606, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1676.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 355.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8252092565238799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17479074347612014, \"precision\": 1.0, \"recall\": 0.8252092565238799, \"specificity\": 1.0, \"npv\": 0.7633333333333333, \"accuracy\": 0.8882241813602015, \"f1\": 0.9042352306447262, \"f2\": 0.8551020408163266, \"f0_5\": 0.9593589009730967, \"p4\": 0.8845922257876229, \"phi\": 0.7936685280895892}, {\"truth_threshold\": -4.80565051050113, \"match_probability\": 0.03452211370336441, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1674.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 357.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8242245199409158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1757754800590842, \"precision\": 1.0, \"recall\": 0.8242245199409158, \"specificity\": 1.0, \"npv\": 0.7623169107856191, \"accuracy\": 0.8875944584382871, \"f1\": 0.9036437246963562, \"f2\": 0.8542559706062461, \"f0_5\": 0.9590924716397388, \"p4\": 0.8839677340916142, \"phi\": 0.7926665691418547}, {\"truth_threshold\": -4.781548448464712, \"match_probability\": 0.035083290414010024, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1671.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 360.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8227474150664698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17725258493353027, \"precision\": 1.0, \"recall\": 0.8227474150664698, \"specificity\": 1.0, \"npv\": 0.760797342192691, \"accuracy\": 0.8866498740554156, \"f1\": 0.9027552674230146, \"f2\": 0.8529862174578867, \"f0_5\": 0.9586919104991394, \"p4\": 0.8830313813179738, \"phi\": 0.791166257292661}, {\"truth_threshold\": -4.780755627158901, \"match_probability\": 0.0351018985075707, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1669.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 362.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8217626784835057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17823732151649435, \"precision\": 1.0, \"recall\": 0.8217626784835057, \"specificity\": 1.0, \"npv\": 0.7597876575978766, \"accuracy\": 0.8860201511335013, \"f1\": 0.9021621621621622, \"f2\": 0.8521392831614418, \"f0_5\": 0.9584242563454691, \"p4\": 0.8824074005666601, \"phi\": 0.7901677926784536}, {\"truth_threshold\": -4.7714766022587005, \"match_probability\": 0.03532039219115348, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1666.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 365.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8202855736090596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17971442639094043, \"precision\": 1.0, \"recall\": 0.8202855736090596, \"specificity\": 1.0, \"npv\": 0.7582781456953642, \"accuracy\": 0.8850755667506297, \"f1\": 0.9012713010549094, \"f2\": 0.8508682328907048, \"f0_5\": 0.9580218516388729, \"p4\": 0.8814718075111811, \"phi\": 0.788672697446118}, {\"truth_threshold\": -4.760077858068414, \"match_probability\": 0.035590592745242886, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1662.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 369.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8183161004431314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18168389955686853, \"precision\": 1.0, \"recall\": 0.8183161004431314, \"specificity\": 1.0, \"npv\": 0.7562747688243064, \"accuracy\": 0.8838161209068011, \"f1\": 0.9000812347684809, \"f2\": 0.8491722869405273, \"f0_5\": 0.9574835810577256, \"p4\": 0.8802250483160751, \"phi\": 0.7866840659933549}, {\"truth_threshold\": -4.675934899603489, \"match_probability\": 0.037647614652134495, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1660.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 371.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8173313638601674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18266863613983259, \"precision\": 1.0, \"recall\": 0.8173313638601674, \"specificity\": 1.0, \"npv\": 0.7552770448548812, \"accuracy\": 0.8831863979848866, \"f1\": 0.8994852343538337, \"f2\": 0.848323793949305, \"f0_5\": 0.9572137008418867, \"p4\": 0.8796019647235972, \"phi\": 0.7856918080033143}, {\"truth_threshold\": -4.675142078297678, \"match_probability\": 0.03766752976237664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1658.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 373.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8163466272772033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18365337272279667, \"precision\": 1.0, \"recall\": 0.8163466272772033, \"specificity\": 1.0, \"npv\": 0.7542819499341239, \"accuracy\": 0.8825566750629723, \"f1\": 0.8988885876931417, \"f2\": 0.8474749539971376, \"f0_5\": 0.9569433221747663, \"p4\": 0.8789790765513171, \"phi\": 0.7847009148999347}, {\"truth_threshold\": -4.665863053397477, \"match_probability\": 0.037901366056843855, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1656.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 375.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8153618906942393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18463810930576072, \"precision\": 1.0, \"recall\": 0.8153618906942393, \"specificity\": 1.0, \"npv\": 0.7532894736842105, \"accuracy\": 0.881926952141058, \"f1\": 0.8982912937347437, \"f2\": 0.8466257668711656, \"f0_5\": 0.9566724436741768, \"p4\": 0.8783563823596343, \"phi\": 0.7837113815067549}, {\"truth_threshold\": -4.5472192053164795, \"match_probability\": 0.04101678607773693, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1654.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 377.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8143771541112752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18562284588872477, \"precision\": 1.0, \"recall\": 0.8143771541112752, \"specificity\": 1.0, \"npv\": 0.7522996057818659, \"accuracy\": 0.8812972292191436, \"f1\": 0.8976933514246948, \"f2\": 0.8457762323583555, \"f0_5\": 0.956401063952816, \"p4\": 0.8777338807071583, \"phi\": 0.7827232026685234}, {\"truth_threshold\": -4.506090228642222, \"match_probability\": 0.04215293797696276, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1653.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 378.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8138847858197932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1861152141802068, \"precision\": 1.0, \"recall\": 0.8138847858197932, \"specificity\": 1.0, \"npv\": 0.7518056467498359, \"accuracy\": 0.8809823677581864, \"f1\": 0.8973941368078175, \"f2\": 0.8453513347652655, \"f0_5\": 0.9562651856994099, \"p4\": 0.8774227016321944, \"phi\": 0.782229619602263}, {\"truth_threshold\": -4.486357548360511, \"match_probability\": 0.04270865918352125, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1652.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 379.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8133924175283112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18660758247168882, \"precision\": 1.0, \"recall\": 0.8133924175283112, \"specificity\": 1.0, \"npv\": 0.7513123359580053, \"accuracy\": 0.8806675062972292, \"f1\": 0.8970947597067608, \"f2\": 0.8449263502454992, \"f0_5\": 0.9561291816182429, \"p4\": 0.8771115701506905, \"phi\": 0.7817363732510626}, {\"truth_threshold\": -4.390613011222286, \"match_probability\": 0.04550583243070618, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1651.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 380.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8129000492368291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18709995076317085, \"precision\": 1.0, \"recall\": 0.8129000492368291, \"specificity\": 1.0, \"npv\": 0.7508196721311475, \"accuracy\": 0.8803526448362721, \"f1\": 0.8967952199891364, \"f2\": 0.8445012787723786, \"f0_5\": 0.9559930515344528, \"p4\": 0.8768004860819614, \"phi\": 0.7812434629764206}, {\"truth_threshold\": -4.364421551485213, \"match_probability\": 0.046300914146011785, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1650.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 381.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8124076809453471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18759231905465287, \"precision\": 1.0, \"recall\": 0.8124076809453471, \"specificity\": 1.0, \"npv\": 0.7503276539973788, \"accuracy\": 0.8800377833753149, \"f1\": 0.8964955175224124, \"f2\": 0.8440761203192142, \"f0_5\": 0.9558567952728537, \"p4\": 0.8764894492452066, \"phi\": 0.7807508881411364}, {\"truth_threshold\": -4.36156786087516, \"match_probability\": 0.04638833661367585, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1648.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 383.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.811422944362383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18857705563761692, \"precision\": 1.0, \"recall\": 0.811422944362383, \"specificity\": 1.0, \"npv\": 0.7493455497382199, \"accuracy\": 0.8794080604534005, \"f1\": 0.8958956238108181, \"f2\": 0.8432255423659435, \"f0_5\": 0.9555839035138582, \"p4\": 0.875867516543838, \"phi\": 0.7797667422463175}, {\"truth_threshold\": -4.281455616584327, \"match_probability\": 0.04890757794012096, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1647.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 384.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.810930576070901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18906942392909898, \"precision\": 1.0, \"recall\": 0.810930576070901, \"specificity\": 1.0, \"npv\": 0.7488554610856769, \"accuracy\": 0.8790931989924433, \"f1\": 0.8955954323001631, \"f2\": 0.842800122812404, \"f0_5\": 0.9554472676644622, \"p4\": 0.8755566203170421, \"phi\": 0.7792751699188473}, {\"truth_threshold\": -4.165871484749609, \"match_probability\": 0.052771850201453044, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1646.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 385.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.810438207779419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.189561792220581, \"precision\": 1.0, \"recall\": 0.810438207779419, \"specificity\": 1.0, \"npv\": 0.7483660130718954, \"accuracy\": 0.8787783375314862, \"f1\": 0.8952950775088387, \"f2\": 0.842374616171955, \"f0_5\": 0.955310504933256, \"p4\": 0.8752457705978546, \"phi\": 0.7787839304948556}, {\"truth_threshold\": -4.157496978653732, \"match_probability\": 0.053062767319424664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1645.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 386.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.809945839487937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19005416051206303, \"precision\": 1.0, \"recall\": 0.809945839487937, \"specificity\": 1.0, \"npv\": 0.7478772044415415, \"accuracy\": 0.878463476070529, \"f1\": 0.8949945593035908, \"f2\": 0.8419490224178524, \"f0_5\": 0.9551736151434213, \"p4\": 0.8749349672048905, \"phi\": 0.7782930233435834}, {\"truth_threshold\": -4.127578605388493, \"match_probability\": 0.054114493898563314, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1644.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 387.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8094534711964549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19054652880354506, \"precision\": 1.0, \"recall\": 0.8094534711964549, \"specificity\": 1.0, \"npv\": 0.7473890339425587, \"accuracy\": 0.8781486146095718, \"f1\": 0.8946938775510204, \"f2\": 0.8415233415233415, \"f0_5\": 0.955036598117811, \"p4\": 0.8746242099566458, \"phi\": 0.7778024478355472}, {\"truth_threshold\": -4.087567921284526, \"match_probability\": 0.05555173404099296, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1643.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 388.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8089611029049729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19103889709502708, \"precision\": 1.0, \"recall\": 0.8089611029049729, \"specificity\": 1.0, \"npv\": 0.7469015003261579, \"accuracy\": 0.8778337531486146, \"f1\": 0.894393032117583, \"f2\": 0.8410975734616566, \"f0_5\": 0.9548994536789492, \"p4\": 0.8743134986714977, \"phi\": 0.7773122033425358}, {\"truth_threshold\": -4.07441071035032, \"match_probability\": 0.05603215946237364, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1642.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 389.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8084687346134909, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1915312653865091, \"precision\": 1.0, \"recall\": 0.8084687346134909, \"specificity\": 1.0, \"npv\": 0.7464146023468058, \"accuracy\": 0.8775188916876574, \"f1\": 0.8940920228695889, \"f2\": 0.8406717182060209, \"f0_5\": 0.9547621816490289, \"p4\": 0.874002833167703, \"phi\": 0.7768222892376055}, {\"truth_threshold\": -4.048857845228498, \"match_probability\": 0.05697638720754652, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1641.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 390.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8079763663220089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19202363367799113, \"precision\": 1.0, \"recall\": 0.8079763663220089, \"specificity\": 1.0, \"npv\": 0.745928338762215, \"accuracy\": 0.8772040302267002, \"f1\": 0.8937908496732027, \"f2\": 0.8402457757296466, \"f0_5\": 0.9546247818499127, \"p4\": 0.8736922132633987, \"phi\": 0.7763327048950771}, {\"truth_threshold\": -4.029823626816482, \"match_probability\": 0.05768943323329177, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1640.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 391.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8074839980305268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19251600196947316, \"precision\": 1.0, \"recall\": 0.8074839980305268, \"specificity\": 1.0, \"npv\": 0.7454427083333334, \"accuracy\": 0.8768891687657431, \"f1\": 0.893489512394443, \"f2\": 0.8398197460057354, \"f0_5\": 0.9544872541031312, \"p4\": 0.8733816387766006, \"phi\": 0.7758434496905313}, {\"truth_threshold\": -3.9356758584011136, \"match_probability\": 0.06134106765366549, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1638.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 393.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8064992614475628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1935007385524372, \"precision\": 1.0, \"recall\": 0.8064992614475628, \"specificity\": 1.0, \"npv\": 0.7444733420026007, \"accuracy\": 0.8762594458438288, \"f1\": 0.892886345053148, \"f2\": 0.8389674247080516, \"f0_5\": 0.9542118140510311, \"p4\": 0.8727606253269781, \"phi\": 0.7748659242039853}, {\"truth_threshold\": -3.8401616407039914, \"match_probability\": 0.06526560686487608, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1637.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 394.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8060068931560808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19399310684391924, \"precision\": 1.0, \"recall\": 0.8060068931560808, \"specificity\": 1.0, \"npv\": 0.7439896036387265, \"accuracy\": 0.8759445843828715, \"f1\": 0.8925845147219194, \"f2\": 0.8385411330806269, \"f0_5\": 0.954073901387108, \"p4\": 0.8724501859995755, \"phi\": 0.7743776526794105}, {\"truth_threshold\": -3.81701601028041, \"match_probability\": 0.06625119924019664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1636.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 395.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8055145248645987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1944854751354013, \"precision\": 1.0, \"recall\": 0.8055145248645987, \"specificity\": 1.0, \"npv\": 0.7435064935064936, \"accuracy\": 0.8756297229219143, \"f1\": 0.8922825197709299, \"f2\": 0.8381147540983607, \"f0_5\": 0.953935860058309, \"p4\": 0.8721397913605214, \"phi\": 0.773889707807661}, {\"truth_threshold\": -3.7972325272965115, \"match_probability\": 0.06710456662357829, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1632.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 399.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8035450516986706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1964549483013294, \"precision\": 1.0, \"recall\": 0.8035450516986706, \"specificity\": 1.0, \"npv\": 0.741580310880829, \"accuracy\": 0.8743702770780857, \"f1\": 0.8910728910728911, \"f2\": 0.8364083640836408, \"f0_5\": 0.9533824044865055, \"p4\": 0.8708986560339702, \"phi\": 0.7719411825038563}, {\"truth_threshold\": -3.6796789870489652, \"match_probability\": 0.07238893248088421, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1630.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 401.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8025603151157066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19743968488429345, \"precision\": 1.0, \"recall\": 0.8025603151157066, \"specificity\": 1.0, \"npv\": 0.740620957309185, \"accuracy\": 0.8737405541561712, \"f1\": 0.8904670854957661, \"f2\": 0.8355546442485134, \"f0_5\": 0.9531049000116946, \"p4\": 0.8702783517473123, \"phi\": 0.7709688637547925}, {\"truth_threshold\": -3.676278941961095, \"match_probability\": 0.07254734369301864, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1629.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 402.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8020679468242246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19793205317577547, \"precision\": 1.0, \"recall\": 0.8020679468242246, \"specificity\": 1.0, \"npv\": 0.7401422107304461, \"accuracy\": 0.8734256926952141, \"f1\": 0.8901639344262295, \"f2\": 0.8351276530298369, \"f0_5\": 0.952965952965953, \"p4\": 0.8699682648069582, \"phi\": 0.7704831882127677}, {\"truth_threshold\": -3.5706653930998717, \"match_probability\": 0.07762970243088008, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1627.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 404.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8010832102412605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19891678975873953, \"precision\": 1.0, \"recall\": 0.8010832102412605, \"specificity\": 1.0, \"npv\": 0.7391865719819238, \"accuracy\": 0.8727959697732998, \"f1\": 0.8895571350464735, \"f2\": 0.8342734078556046, \"f0_5\": 0.9526876683452394, \"p4\": 0.8693482204147955, \"phi\": 0.7695128017456969}, {\"truth_threshold\": -3.5142183068142594, \"match_probability\": 0.08047797065231073, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1624.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 407.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7996061053668144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20039389463318563, \"precision\": 1.0, \"recall\": 0.7996061053668144, \"specificity\": 1.0, \"npv\": 0.7377577319587629, \"accuracy\": 0.8718513853904282, \"f1\": 0.8886456908344733, \"f2\": 0.8329913828477636, \"f0_5\": 0.9522692623431454, \"p4\": 0.8684184747918336, \"phi\": 0.7680596244796367}, {\"truth_threshold\": -3.444717692134105, \"match_probability\": 0.08411573531897505, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1623.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 408.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7991137370753324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20088626292466766, \"precision\": 1.0, \"recall\": 0.7991137370753324, \"specificity\": 1.0, \"npv\": 0.7372826786864134, \"accuracy\": 0.871536523929471, \"f1\": 0.8883415435139573, \"f2\": 0.8325638658048631, \"f0_5\": 0.9521295318549806, \"p4\": 0.8681086444390568, \"phi\": 0.7675758702864567}, {\"truth_threshold\": -3.4161658763441083, \"match_probability\": 0.08565301201035617, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1620.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 411.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7976366322008862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20236336779911374, \"precision\": 1.0, \"recall\": 0.7976366322008862, \"specificity\": 1.0, \"npv\": 0.7358611825192802, \"accuracy\": 0.8705919395465995, \"f1\": 0.8874281018898932, \"f2\": 0.8312807881773399, \"f0_5\": 0.9517095523440254, \"p4\": 0.8671794053656988, \"phi\": 0.7661265139596987}, {\"truth_threshold\": -3.2051561059655267, \"match_probability\": 0.0978235374740718, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1619.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 412.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7971442639094042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20285573609059576, \"precision\": 1.0, \"recall\": 0.7971442639094042, \"specificity\": 1.0, \"npv\": 0.7353885677585099, \"accuracy\": 0.8702770780856424, \"f1\": 0.8871232876712328, \"f2\": 0.8308529200451606, \"f0_5\": 0.9515692958739861, \"p4\": 0.866869742387817, \"phi\": 0.7656440286015744}, {\"truth_threshold\": -3.1963581132540826, \"match_probability\": 0.09836305930458436, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1618.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 413.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7966518956179222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2033481043820778, \"precision\": 1.0, \"recall\": 0.7966518956179222, \"specificity\": 1.0, \"npv\": 0.7349165596919127, \"accuracy\": 0.8699622166246851, \"f1\": 0.886818306385311, \"f2\": 0.8304249640730856, \"f0_5\": 0.9514289074444314, \"p4\": 0.86656012079201, \"phi\": 0.7651618589550606}, {\"truth_threshold\": -3.144800038241718, \"match_probability\": 0.10157833172175233, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1616.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 415.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7956671590349581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20433284096504184, \"precision\": 1.0, \"recall\": 0.7956671590349581, \"specificity\": 1.0, \"npv\": 0.7339743589743589, \"accuracy\": 0.8693324937027708, \"f1\": 0.8862078420619688, \"f2\": 0.8295687885010267, \"f0_5\": 0.9511477339611536, \"p4\": 0.8659410010067748, \"phi\": 0.7641984644119829}, {\"truth_threshold\": -3.137632356223198, \"match_probability\": 0.10203263420563406, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1615.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 416.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7951747907434761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2048252092565239, \"precision\": 1.0, \"recall\": 0.7951747907434761, \"specificity\": 1.0, \"npv\": 0.7335041639974376, \"accuracy\": 0.8690176322418136, \"f1\": 0.8859023587493143, \"f2\": 0.8291405688469042, \"f0_5\": 0.9510069485337416, \"p4\": 0.8656315024470852, \"phi\": 0.7637172383258942}, {\"truth_threshold\": -3.1288048652381484, \"match_probability\": 0.10259461291475487, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1613.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 418.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.794190054160512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20580994583948795, \"precision\": 1.0, \"recall\": 0.794190054160512, \"specificity\": 1.0, \"npv\": 0.7325655790147153, \"accuracy\": 0.8683879093198993, \"f1\": 0.8852908891328211, \"f2\": 0.8282838656670433, \"f0_5\": 0.9507249793705057, \"p4\": 0.865012627066886, \"phi\": 0.762755725559516}, {\"truth_threshold\": -3.127578605388493, \"match_probability\": 0.10267289599334684, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1610.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 421.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.792712949286066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20728705071393402, \"precision\": 1.0, \"recall\": 0.792712949286066, \"specificity\": 1.0, \"npv\": 0.731162196679438, \"accuracy\": 0.8674433249370277, \"f1\": 0.8843724251579237, \"f2\": 0.8269981508115882, \"f0_5\": 0.9503010270334081, \"p4\": 0.86408461556039, \"phi\": 0.7613157960637859}, {\"truth_threshold\": -3.096861935995838, \"match_probability\": 0.10465113702325661, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1609.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 422.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7922205809945839, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20777941900541605, \"precision\": 1.0, \"recall\": 0.7922205809945839, \"specificity\": 1.0, \"npv\": 0.7306955966815571, \"accuracy\": 0.8671284634760705, \"f1\": 0.884065934065934, \"f2\": 0.8265694030617486, \"f0_5\": 0.9501594425416322, \"p4\": 0.8637753580651635, \"phi\": 0.7608364411180943}, {\"truth_threshold\": -3.0644190376462115, \"match_probability\": 0.10677702920587313, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1608.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 423.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7917282127031019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20827178729689808, \"precision\": 1.0, \"recall\": 0.7917282127031019, \"specificity\": 1.0, \"npv\": 0.7302295918367347, \"accuracy\": 0.8668136020151134, \"f1\": 0.8837592745259687, \"f2\": 0.8261405672009864, \"f0_5\": 0.9500177242112726, \"p4\": 0.8634661400965793, \"phi\": 0.7603573959710088}, {\"truth_threshold\": -3.0612067404849723, \"match_probability\": 0.106989578234456, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1607.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 424.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7912358444116199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2087641555883801, \"precision\": 1.0, \"recall\": 0.7912358444116199, \"specificity\": 1.0, \"npv\": 0.7297641810070108, \"accuracy\": 0.8664987405541562, \"f1\": 0.8834524463991204, \"f2\": 0.8257116432021375, \"f0_5\": 0.9498758718524648, \"p4\": 0.8631569614683307, \"phi\": 0.7598786600375329}, {\"truth_threshold\": -3.0434253038319126, \"match_probability\": 0.10817287474191055, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1606.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 425.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7907434761201378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20925652387986213, \"precision\": 1.0, \"recall\": 0.7907434761201378, \"specificity\": 1.0, \"npv\": 0.7292993630573248, \"accuracy\": 0.8661838790931989, \"f1\": 0.8831454495463293, \"f2\": 0.8252826310380267, \"f0_5\": 0.9497338852749853, \"p4\": 0.8628478219939693, \"phi\": 0.7594002327338012}, {\"truth_threshold\": -3.018352133097287, \"match_probability\": 0.10986094415575674, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1605.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 426.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7902511078286558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20974889217134415, \"precision\": 1.0, \"recall\": 0.7902511078286558, \"specificity\": 1.0, \"npv\": 0.728835136855506, \"accuracy\": 0.8658690176322418, \"f1\": 0.8828382838283828, \"f2\": 0.8248535306814678, \"f0_5\": 0.9495917642882499, \"p4\": 0.8625387214869051, \"phi\": 0.7589221134770772}, {\"truth_threshold\": -3.016764820355816, \"match_probability\": 0.10996858462019457, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1604.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 427.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7897587395371738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2102412604628262, \"precision\": 1.0, \"recall\": 0.7897587395371738, \"specificity\": 1.0, \"npv\": 0.7283715012722646, \"accuracy\": 0.8655541561712846, \"f1\": 0.8825309491059147, \"f2\": 0.8244243421052632, \"f0_5\": 0.9494495087013141, \"p4\": 0.8622296597604054, \"phi\": 0.7584443016857485}, {\"truth_threshold\": -3.008486526324743, \"match_probability\": 0.11053145985275836, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1603.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 428.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7892663712456918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21073362875430823, \"precision\": 1.0, \"recall\": 0.7892663712456918, \"specificity\": 1.0, \"npv\": 0.7279084551811824, \"accuracy\": 0.8652392947103275, \"f1\": 0.8822234452394057, \"f2\": 0.8239950652822041, \"f0_5\": 0.9493071183228711, \"p4\": 0.8619206366275943, \"phi\": 0.7579667967793241}, {\"truth_threshold\": -2.8563507138151425, \"match_probability\": 0.12133254270578255, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1600.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 431.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7877892663712457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2122107336287543, \"precision\": 1.0, \"recall\": 0.7877892663712457, \"specificity\": 1.0, \"npv\": 0.7265228426395939, \"accuracy\": 0.864294710327456, \"f1\": 0.8812999173781327, \"f2\": 0.8227067050596463, \"f0_5\": 0.9488791365199858, \"p4\": 0.8609937969203728, \"phi\": 0.7565361175813073}, {\"truth_threshold\": -2.8505113188152995, \"match_probability\": 0.12176471876654911, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1599.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 432.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7872968980797637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21270310192023634, \"precision\": 1.0, \"recall\": 0.7872968980797637, \"specificity\": 1.0, \"npv\": 0.7260621433100825, \"accuracy\": 0.8639798488664987, \"f1\": 0.8809917355371901, \"f2\": 0.822277074976859, \"f0_5\": 0.9487362050551797, \"p4\": 0.8606849262906713, \"phi\": 0.7560598344318872}, {\"truth_threshold\": -2.83349291041802, \"match_probability\": 0.12303182710341214, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1598.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 433.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7868045297882816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21319547021171836, \"precision\": 1.0, \"recall\": 0.7868045297882816, \"specificity\": 1.0, \"npv\": 0.7256020278833967, \"accuracy\": 0.8636649874055415, \"f1\": 0.8806833838523009, \"f2\": 0.8218473565110059, \"f0_5\": 0.9485931378368753, \"p4\": 0.860376093318109, \"phi\": 0.7555838552816091}, {\"truth_threshold\": -2.8143925915914743, \"match_probability\": 0.12446742864091177, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1597.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 434.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7863121614967996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2136878385032004, \"precision\": 1.0, \"recall\": 0.7863121614967996, \"specificity\": 1.0, \"npv\": 0.7251424952501583, \"accuracy\": 0.8633501259445844, \"f1\": 0.880374862183021, \"f2\": 0.8214175496348113, \"f0_5\": 0.9484499346715762, \"p4\": 0.8600672978149376, \"phi\": 0.7551081795566347}, {\"truth_threshold\": -2.7970746866513743, \"match_probability\": 0.1257814600748985, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1595.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 436.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7853274249138356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21467257508616444, \"precision\": 1.0, \"recall\": 0.7853274249138356, \"specificity\": 1.0, \"npv\": 0.724225173940544, \"accuracy\": 0.8627204030226701, \"f1\": 0.8797573083287369, \"f2\": 0.8205576705422368, \"f0_5\": 0.9481631197241708, \"p4\": 0.8594498184650354, \"phi\": 0.7541577360927235}, {\"truth_threshold\": -2.7621359091442046, \"match_probability\": 0.1284686738852938, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1592.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 439.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7838503200393895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21614967996061055, \"precision\": 1.0, \"recall\": 0.7838503200393895, \"specificity\": 1.0, \"npv\": 0.7228535353535354, \"accuracy\": 0.8617758186397985, \"f1\": 0.8788296991443555, \"f2\": 0.8192671881432688, \"f0_5\": 0.947731872842005, \"p4\": 0.8585238757583832, \"phi\": 0.752734332303551}, {\"truth_threshold\": -2.7382442139045517, \"match_probability\": 0.1303342932228471, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1589.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 442.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7823732151649434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21762678483505662, \"precision\": 1.0, \"recall\": 0.7823732151649434, \"specificity\": 1.0, \"npv\": 0.7214870825456837, \"accuracy\": 0.860831234256927, \"f1\": 0.8779005524861878, \"f2\": 0.8179759085761351, \"f0_5\": 0.9472993919160606, \"p4\": 0.857598260108828, \"phi\": 0.7513136285674854}, {\"truth_threshold\": -2.731660453807797, \"match_probability\": 0.13085242832114471, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1588.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 443.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7818808468734614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21811915312653865, \"precision\": 1.0, \"recall\": 0.7818808468734614, \"specificity\": 1.0, \"npv\": 0.7210327455919395, \"accuracy\": 0.8605163727959698, \"f1\": 0.8775904946117712, \"f2\": 0.8175453047775947, \"f0_5\": 0.9471549564595013, \"p4\": 0.8572897933569306, \"phi\": 0.7508406580273359}, {\"truth_threshold\": -2.697486545565367, \"match_probability\": 0.13357005120780754, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1587.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 444.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7813884785819794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21861152141802068, \"precision\": 1.0, \"recall\": 0.7813884785819794, \"specificity\": 1.0, \"npv\": 0.7205789804908748, \"accuracy\": 0.8602015113350125, \"f1\": 0.8772802653399668, \"f2\": 0.8171146122953352, \"f0_5\": 0.9470103831006087, \"p4\": 0.8569813621887155, \"phi\": 0.7503679852338574}, {\"truth_threshold\": -2.6315645622368553, \"match_probability\": 0.13894723170021486, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1585.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 446.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7804037419990153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21959625800098473, \"precision\": 1.0, \"recall\": 0.7804037419990153, \"specificity\": 1.0, \"npv\": 0.7196731615336267, \"accuracy\": 0.8595717884130982, \"f1\": 0.8766592920353983, \"f2\": 0.8162529611700484, \"f0_5\": 0.9467208218850794, \"p4\": 0.856364605845547, \"phi\": 0.7494235306401207}, {\"truth_threshold\": -2.627390785536496, \"match_probability\": 0.13929371946981745, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1584.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 447.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7799113737075333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22008862629246675, \"precision\": 1.0, \"recall\": 0.7799113737075333, \"specificity\": 1.0, \"npv\": 0.7192211055276382, \"accuracy\": 0.8592569269521411, \"f1\": 0.8763485477178423, \"f2\": 0.8158220024721878, \"f0_5\": 0.9465758336321262, \"p4\": 0.8560562802913134, \"phi\": 0.7489517477191111}, {\"truth_threshold\": -2.6037745329375204, \"match_probability\": 0.14126789212547528, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1582.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 449.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7789266371245692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22107336287543083, \"precision\": 1.0, \"recall\": 0.7789266371245692, \"specificity\": 1.0, \"npv\": 0.7183186951066499, \"accuracy\": 0.8586272040302267, \"f1\": 0.8757265430390258, \"f2\": 0.8149598186688646, \"f0_5\": 0.946285440842206, \"p4\": 0.8554397334681781, \"phi\": 0.7480090678348302}, {\"truth_threshold\": -2.591872996704144, \"match_probability\": 0.14227161615708148, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1581.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 450.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7784342688330872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22156573116691286, \"precision\": 1.0, \"recall\": 0.7784342688330872, \"specificity\": 1.0, \"npv\": 0.7178683385579937, \"accuracy\": 0.8583123425692695, \"f1\": 0.8754152823920266, \"f2\": 0.8145285935085008, \"f0_5\": 0.9461400359066428, \"p4\": 0.8551315118190579, \"phi\": 0.7475381697571134}, {\"truth_threshold\": -2.574398051971839, \"match_probability\": 0.1437561493026426, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1580.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 451.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7779419005416052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2220580994583949, \"precision\": 1.0, \"recall\": 0.7779419005416052, \"specificity\": 1.0, \"npv\": 0.7174185463659147, \"accuracy\": 0.8579974811083123, \"f1\": 0.8751038493492107, \"f2\": 0.8140972794723825, \"f0_5\": 0.9459944916776434, \"p4\": 0.8548233244244939, \"phi\": 0.7470675655144556}, {\"truth_threshold\": -2.5598375375205613, \"match_probability\": 0.14500292021739583, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1579.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 452.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7774495322501231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2225504677498769, \"precision\": 1.0, \"recall\": 0.7774495322501231, \"specificity\": 1.0, \"npv\": 0.7169693174702567, \"accuracy\": 0.8576826196473551, \"f1\": 0.874792243767313, \"f2\": 0.813665876533031, \"f0_5\": 0.9458488079549539, \"p4\": 0.8545151710939816, \"phi\": 0.7465972545522392}, {\"truth_threshold\": -2.539015375865401, \"match_probability\": 0.14680144303808235, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1577.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 454.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.776464795667159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22353520433284096, \"precision\": 1.0, \"recall\": 0.776464795667159, \"specificity\": 1.0, \"npv\": 0.716072545340838, \"accuracy\": 0.8570528967254408, \"f1\": 0.8741685144124168, \"f2\": 0.8128028038346562, \"f0_5\": 0.9455570212255666, \"p4\": 0.8538989658622953, \"phi\": 0.7456575102558387}, {\"truth_threshold\": -2.520475581619984, \"match_probability\": 0.14841833314737204, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1574.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 457.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7749876907927129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22501230920728704, \"precision\": 1.0, \"recall\": 0.7749876907927129, \"specificity\": 1.0, \"npv\": 0.7147315855181023, \"accuracy\": 0.8561083123425692, \"f1\": 0.8732316227461858, \"f2\": 0.8115075273252217, \"f0_5\": 0.9451182899003242, \"p4\": 0.8529749087233359, \"phi\": 0.7442500796085201}, {\"truth_threshold\": -2.4684984451564844, \"match_probability\": 0.1530298129467379, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1573.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 458.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7744953225012309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22550467749876907, \"precision\": 1.0, \"recall\": 0.7744953225012309, \"specificity\": 1.0, \"npv\": 0.7142857142857143, \"accuracy\": 0.8557934508816121, \"f1\": 0.8729189789123196, \"f2\": 0.8110755903887801, \"f0_5\": 0.9449717649885858, \"p4\": 0.8526669557675629, \"phi\": 0.7437815167397859}, {\"truth_threshold\": -2.46610388200215, \"match_probability\": 0.15324506435842575, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1572.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 459.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7740029542097489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2259970457902511, \"precision\": 1.0, \"recall\": 0.7740029542097489, \"specificity\": 1.0, \"npv\": 0.7138403990024937, \"accuracy\": 0.8554785894206549, \"f1\": 0.8726061615320566, \"f2\": 0.8106435643564357, \"f0_5\": 0.9448250991705733, \"p4\": 0.8523590355378086, \"phi\": 0.743313243298003}, {\"truth_threshold\": -2.4531578858528653, \"match_probability\": 0.15441309893966682, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1570.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 461.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7730182176267848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22698178237321517, \"precision\": 1.0, \"recall\": 0.7730182176267848, \"specificity\": 1.0, \"npv\": 0.7129514321295143, \"accuracy\": 0.8548488664987406, \"f1\": 0.8719800055540128, \"f2\": 0.8097792448937488, \"f0_5\": 0.9445313440019252, \"p4\": 0.8517432924889973, \"phi\": 0.7423775625106276}, {\"truth_threshold\": -2.4515988221809755, \"match_probability\": 0.15455425316384586, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1568.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 463.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7720334810438207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22796651895617923, \"precision\": 1.0, \"recall\": 0.7720334810438207, \"specificity\": 1.0, \"npv\": 0.7120646766169154, \"accuracy\": 0.8542191435768262, \"f1\": 0.8713531536537927, \"f2\": 0.8089145687164672, \"f0_5\": 0.9442370227628568, \"p4\": 0.8511276780405328, \"phi\": 0.741443032887153}, {\"truth_threshold\": -2.4321001719488886, \"match_probability\": 0.15632853446809297, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1560.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 471.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7680945347119645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23190546528803546, \"precision\": 1.0, \"recall\": 0.7680945347119645, \"specificity\": 1.0, \"npv\": 0.7085396039603961, \"accuracy\": 0.8517002518891688, \"f1\": 0.8688387635756056, \"f2\": 0.80545229244114, \"f0_5\": 0.9430540442509975, \"p4\": 0.8486664754292597, \"phi\": 0.7377163394076073}, {\"truth_threshold\": -2.419549767006594, \"match_probability\": 0.15747931477728885, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1559.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 472.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7676021664204825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2323978335795175, \"precision\": 1.0, \"recall\": 0.7676021664204825, \"specificity\": 1.0, \"npv\": 0.7081014223871367, \"accuracy\": 0.8513853904282116, \"f1\": 0.8685236768802228, \"f2\": 0.8050191056490758, \"f0_5\": 0.9429055280029031, \"p4\": 0.8483589631234236, \"phi\": 0.7372517791567487}, {\"truth_threshold\": -2.3943414685779465, \"match_probability\": 0.15981153188722888, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1558.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 473.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7671097981290005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2328902018709995, \"precision\": 1.0, \"recall\": 0.7671097981290005, \"specificity\": 1.0, \"npv\": 0.707663782447466, \"accuracy\": 0.8510705289672544, \"f1\": 0.8682084146001672, \"f2\": 0.8045858293740963, \"f0_5\": 0.94275686796563, \"p4\": 0.8480514808431835, \"phi\": 0.7367875007737852}, {\"truth_threshold\": -2.377728472331055, \"match_probability\": 0.1613637690185596, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1557.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 474.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7666174298375185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23338257016248154, \"precision\": 1.0, \"recall\": 0.7666174298375185, \"specificity\": 1.0, \"npv\": 0.7072266831377394, \"accuracy\": 0.8507556675062973, \"f1\": 0.8678929765886287, \"f2\": 0.8041524635884723, \"f0_5\": 0.9426080639302579, \"p4\": 0.8477440283943714, \"phi\": 0.736323503726159}, {\"truth_threshold\": -2.3500041100670876, \"match_probability\": 0.1639812809615131, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1556.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 475.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7661250615460364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23387493845396357, \"precision\": 1.0, \"recall\": 0.7661250615460364, \"specificity\": 1.0, \"npv\": 0.7067901234567902, \"accuracy\": 0.85044080604534, \"f1\": 0.867577362698634, \"f2\": 0.8037190082644629, \"f0_5\": 0.9424591156874621, \"p4\": 0.8474366055826448, \"phi\": 0.7358597874822784}, {\"truth_threshold\": -2.2876972056181595, \"match_probability\": 0.16998820375749926, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1555.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 476.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7656326932545544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2343673067454456, \"precision\": 1.0, \"recall\": 0.7656326932545544, \"specificity\": 1.0, \"npv\": 0.7063541024059222, \"accuracy\": 0.8501259445843828, \"f1\": 0.8672615727830452, \"f2\": 0.8032854633743155, \"f0_5\": 0.9423100230275118, \"p4\": 0.8471292122134862, \"phi\": 0.7353963515115162}, {\"truth_threshold\": -2.287577804181826, \"match_probability\": 0.1699998812587726, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1546.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 485.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7612013786312162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23879862136878385, \"precision\": 1.0, \"recall\": 0.7612013786312162, \"specificity\": 1.0, \"npv\": 0.7024539877300614, \"accuracy\": 0.8472921914357683, \"f1\": 0.8644115180318703, \"f2\": 0.7993795243019648, \"f0_5\": 0.9409616555082166, \"p4\": 0.8443639646235935, \"phi\": 0.7312379529846068}, {\"truth_threshold\": -2.278812698687279, \"match_probability\": 0.17085885451324623, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1545.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 486.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7607090103397341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23929098966026588, \"precision\": 1.0, \"recall\": 0.7607090103397341, \"specificity\": 1.0, \"npv\": 0.7020232985898222, \"accuracy\": 0.8469773299748111, \"f1\": 0.8640939597315436, \"f2\": 0.7989450822215327, \"f0_5\": 0.9408111070515163, \"p4\": 0.8440568549426011, \"phi\": 0.730777290770382}, {\"truth_threshold\": -2.199321795947064, \"match_probability\": 0.17880662514970574, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1544.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 487.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7602166420482521, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2397833579517479, \"precision\": 1.0, \"recall\": 0.7602166420482521, \"specificity\": 1.0, \"npv\": 0.7015931372549019, \"accuracy\": 0.8466624685138538, \"f1\": 0.8637762237762238, \"f2\": 0.7985105502689285, \"f0_5\": 0.9406604118435482, \"p4\": 0.843749772552718, \"phi\": 0.730316903055119}, {\"truth_threshold\": -2.1818397324826697, \"match_probability\": 0.18059284733981082, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1543.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 488.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7597242737567701, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24027572624322993, \"precision\": 1.0, \"recall\": 0.7597242737567701, \"specificity\": 1.0, \"npv\": 0.7011635027556644, \"accuracy\": 0.8463476070528967, \"f1\": 0.863458310016788, \"f2\": 0.7980759284162615, \"f0_5\": 0.9405095696696331, \"p4\": 0.8434427172572686, \"phi\": 0.7298567893195214}, {\"truth_threshold\": -2.180899351584165, \"match_probability\": 0.18068932349084307, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1541.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 490.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.758739537173806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24126046282619398, \"precision\": 1.0, \"recall\": 0.758739537173806, \"specificity\": 1.0, \"npv\": 0.7003058103975535, \"accuracy\": 0.8457178841309824, \"f1\": 0.8628219484882419, \"f2\": 0.7972064148991206, \"f0_5\": 0.9402074435631482, \"p4\": 0.842828687162046, \"phi\": 0.7289373817147581}, {\"truth_threshold\": -2.173199149826056, \"match_probability\": 0.1814808189540905, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1540.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 491.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.758247168882324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.241752831117676, \"precision\": 1.0, \"recall\": 0.758247168882324, \"specificity\": 1.0, \"npv\": 0.6998777506112469, \"accuracy\": 0.8454030226700252, \"f1\": 0.8625035004200504, \"f2\": 0.796771523178808, \"f0_5\": 0.940056159199121, \"p4\": 0.8425217119679963, \"phi\": 0.7284780868116124}, {\"truth_threshold\": -2.166820289346195, \"match_probability\": 0.1821385366214769, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1539.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 492.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.757754800590842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24224519940915806, \"precision\": 1.0, \"recall\": 0.757754800590842, \"specificity\": 1.0, \"npv\": 0.6994502138057422, \"accuracy\": 0.845088161209068, \"f1\": 0.8621848739495799, \"f2\": 0.7963365414467557, \"f0_5\": 0.9399047270062294, \"p4\": 0.842214763079826, \"phi\": 0.7280190638201667}, {\"truth_threshold\": -2.1167520635404435, \"match_probability\": 0.18736541770480078, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1537.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 494.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7567700640078779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24322993599212211, \"precision\": 1.0, \"recall\": 0.7567700640078779, \"specificity\": 1.0, \"npv\": 0.6985967053081147, \"accuracy\": 0.8444584382871536, \"f1\": 0.8615470852017937, \"f2\": 0.7954663078356278, \"f0_5\": 0.9396014182662917, \"p4\": 0.8416009434305138, \"phi\": 0.7271018315144822}, {\"truth_threshold\": -2.115959242234633, \"match_probability\": 0.18744910511323398, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1536.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 495.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7562776957163959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24372230428360414, \"precision\": 1.0, \"recall\": 0.7562776957163959, \"specificity\": 1.0, \"npv\": 0.698170731707317, \"accuracy\": 0.8441435768261965, \"f1\": 0.8612279226240538, \"f2\": 0.7950310559006211, \"f0_5\": 0.9394495412844037, \"p4\": 0.8412940722735957, \"phi\": 0.7266436211735708}, {\"truth_threshold\": -2.0918814280562765, \"match_probability\": 0.19000438027628302, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1535.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 496.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7557853274249139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24421467257508617, \"precision\": 1.0, \"recall\": 0.7557853274249139, \"specificity\": 1.0, \"npv\": 0.6977452772699574, \"accuracy\": 0.8438287153652393, \"f1\": 0.8609085810431857, \"f2\": 0.7945957138420127, \"f0_5\": 0.9392975156039652, \"p4\": 0.840987226631003, \"phi\": 0.7261856806910075}, {\"truth_threshold\": -2.0411026641633545, \"match_probability\": 0.195480502782526, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1531.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 500.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7538158542589857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24618414574101427, \"precision\": 1.0, \"recall\": 0.7538158542589857, \"specificity\": 1.0, \"npv\": 0.6960486322188449, \"accuracy\": 0.8425692695214105, \"f1\": 0.8596294216732173, \"f2\": 0.7928534438114966, \"f0_5\": 0.9386879215205396, \"p4\": 0.839760095233761, \"phi\": 0.7243566071361862}, {\"truth_threshold\": -2.010603481709139, \"match_probability\": 0.19882662873380508, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1530.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 501.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7533234859675036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2466765140324963, \"precision\": 1.0, \"recall\": 0.7533234859675036, \"specificity\": 1.0, \"npv\": 0.695625759416768, \"accuracy\": 0.8422544080604534, \"f1\": 0.8593091828138163, \"f2\": 0.7924176507147297, \"f0_5\": 0.9385351490614648, \"p4\": 0.8394533741835204, \"phi\": 0.7239000082971623}, {\"truth_threshold\": -1.9748677885351642, \"match_probability\": 0.2028018231862612, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1529.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 502.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7528311176760216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24716888232397832, \"precision\": 1.0, \"recall\": 0.7528311176760216, \"specificity\": 1.0, \"npv\": 0.6952034001214329, \"accuracy\": 0.8419395465994962, \"f1\": 0.8589887640449438, \"f2\": 0.7919817673262198, \"f0_5\": 0.9383822265864735, \"p4\": 0.8391466774545462, \"phi\": 0.7234436762634593}, {\"truth_threshold\": -1.9389486186341065, \"match_probability\": 0.20685684113500366, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1527.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 504.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7518463810930576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2481536189069424, \"precision\": 1.0, \"recall\": 0.7518463810930576, \"specificity\": 1.0, \"npv\": 0.6943602183141298, \"accuracy\": 0.8413098236775819, \"f1\": 0.8583473861720068, \"f2\": 0.7911097295617034, \"f0_5\": 0.9380759307040177, \"p4\": 0.838533356162117, \"phi\": 0.7225318105900003}, {\"truth_threshold\": -1.9354891153021314, \"match_probability\": 0.20725054154572872, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1526.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 505.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7513540128015755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24864598719842443, \"precision\": 1.0, \"recall\": 0.7513540128015755, \"specificity\": 1.0, \"npv\": 0.693939393939394, \"accuracy\": 0.8409949622166247, \"f1\": 0.8580264267641271, \"f2\": 0.7906735751295336, \"f0_5\": 0.9379225568531039, \"p4\": 0.8382267311990319, \"phi\": 0.7220762759414389}, {\"truth_threshold\": -1.9295627062487586, \"match_probability\": 0.20792626763800312, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1525.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 506.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7508616445100935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24913835548990645, \"precision\": 1.0, \"recall\": 0.7508616445100935, \"specificity\": 1.0, \"npv\": 0.693519079345851, \"accuracy\": 0.8406801007556675, \"f1\": 0.8577052868391452, \"f2\": 0.7902373302932947, \"f0_5\": 0.9377690320993728, \"p4\": 0.8379201297579515, \"phi\": 0.7216210060805823}, {\"truth_threshold\": -1.9049899328479158, \"match_probability\": 0.21074536423131618, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1524.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 507.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7503692762186115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24963072378138848, \"precision\": 1.0, \"recall\": 0.7503692762186115, \"specificity\": 1.0, \"npv\": 0.6930992736077481, \"accuracy\": 0.8403652392947103, \"f1\": 0.8573839662447258, \"f2\": 0.7898009950248757, \"f0_5\": 0.9376153562200074, \"p4\": 0.8376135516385673, \"phi\": 0.7211660005052176}, {\"truth_threshold\": -1.9040098411269366, \"match_probability\": 0.21085838355024714, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1522.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 509.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7493845396356474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25061546036435256, \"precision\": 1.0, \"recall\": 0.7493845396356474, \"specificity\": 1.0, \"npv\": 0.6922611850060459, \"accuracy\": 0.839735516372796, \"f1\": 0.8567407824373768, \"f2\": 0.7889280530789965, \"f0_5\": 0.9373075501909102, \"p4\": 0.8370004645626585, \"phi\": 0.7202567802064647}, {\"truth_threshold\": -1.8639795389224934, \"match_probability\": 0.21551242625353056, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1521.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 510.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7488921713441654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2511078286558346, \"precision\": 1.0, \"recall\": 0.7488921713441654, \"specificity\": 1.0, \"npv\": 0.6918429003021148, \"accuracy\": 0.8394206549118388, \"f1\": 0.856418918918919, \"f2\": 0.7884914463452566, \"f0_5\": 0.9371534195933456, \"p4\": 0.83669395520452, \"phi\": 0.7198025644829947}, {\"truth_threshold\": -1.8616858017077802, \"match_probability\": 0.2157813467434969, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1519.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 512.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7479074347612014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25209256523879864, \"precision\": 1.0, \"recall\": 0.7479074347612014, \"specificity\": 1.0, \"npv\": 0.6910078455039228, \"accuracy\": 0.8387909319899244, \"f1\": 0.8557746478873239, \"f2\": 0.7876179612153894, \"f0_5\": 0.9368447021092883, \"p4\": 0.8360810038423322, \"phi\": 0.7188949193941375}, {\"truth_threshold\": -1.8569550982411185, \"match_probability\": 0.21633674793227547, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1518.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 513.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7474150664697193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25258493353028066, \"precision\": 1.0, \"recall\": 0.7474150664697193, \"specificity\": 1.0, \"npv\": 0.6905910735826297, \"accuracy\": 0.8384760705289672, \"f1\": 0.8554522400676247, \"f2\": 0.7871810827629122, \"f0_5\": 0.9366901147723066, \"p4\": 0.8357745614354601, \"phi\": 0.7184414890338364}, {\"truth_threshold\": -1.8516481824787163, \"match_probability\": 0.21696102925818747, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1517.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 514.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7469226981782373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2530773018217627, \"precision\": 1.0, \"recall\": 0.7469226981782373, \"specificity\": 1.0, \"npv\": 0.6901748040988547, \"accuracy\": 0.8381612090680101, \"f1\": 0.855129650507328, \"f2\": 0.7867441136811534, \"f0_5\": 0.9365353747376219, \"p4\": 0.8354681409425155, \"phi\": 0.7179883194677703}, {\"truth_threshold\": -1.8076898626917108, \"match_probability\": 0.22218209784474743, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1516.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 515.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7464303298867553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2535696701132447, \"precision\": 1.0, \"recall\": 0.7464303298867553, \"specificity\": 1.0, \"npv\": 0.6897590361445783, \"accuracy\": 0.8378463476070529, \"f1\": 0.8548068790527206, \"f2\": 0.7863070539419087, \"f0_5\": 0.9363804817788759, \"p4\": 0.835161742161578, \"phi\": 0.7175354102006172}, {\"truth_threshold\": -1.8056505105011302, \"match_probability\": 0.22242648321709502, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1515.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 516.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7459379615952733, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25406203840472674, \"precision\": 1.0, \"recall\": 0.7459379615952733, \"specificity\": 1.0, \"npv\": 0.6893437688139675, \"accuracy\": 0.8375314861460957, \"f1\": 0.8544839255499154, \"f2\": 0.7858699035169623, \"f0_5\": 0.9362254356692622, \"p4\": 0.834855364890522, \"phi\": 0.7170827607379041}, {\"truth_threshold\": -1.7632727728076216, \"match_probability\": 0.2275481959382267, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1514.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 517.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7454455933037912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25455440669620877, \"precision\": 1.0, \"recall\": 0.7454455933037912, \"specificity\": 1.0, \"npv\": 0.6889290012033694, \"accuracy\": 0.8372166246851386, \"f1\": 0.8541607898448519, \"f2\": 0.7854326623780867, \"f0_5\": 0.936070236181526, \"p4\": 0.8345490089270164, \"phi\": 0.7166303705860044}, {\"truth_threshold\": -1.7426376886946178, \"match_probability\": 0.23007205312616258, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1507.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 524.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.741999015263417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25800098473658295, \"precision\": 1.0, \"recall\": 0.741999015263417, \"specificity\": 1.0, \"npv\": 0.6860395446375075, \"accuracy\": 0.8350125944584383, \"f1\": 0.8518937252685133, \"f2\": 0.7823694320423632, \"f0_5\": 0.9349795259957812, \"p4\": 0.8324050967544926, \"phi\": 0.7134708589373455}, {\"truth_threshold\": -1.7232424706031781, \"match_probability\": 0.23246209972217038, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1505.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 526.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.741014278680453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.258985721319547, \"precision\": 1.0, \"recall\": 0.741014278680453, \"specificity\": 1.0, \"npv\": 0.6852184320766008, \"accuracy\": 0.8343828715365239, \"f1\": 0.8512443438914027, \"f2\": 0.7814934053380413, \"f0_5\": 0.9346665010557694, \"p4\": 0.8317927306077135, \"phi\": 0.7125704471726241}, {\"truth_threshold\": -1.6925980014535682, \"match_probability\": 0.23627353174560783, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1504.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 527.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.740521910388971, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25947808961102903, \"precision\": 1.0, \"recall\": 0.740521910388971, \"specificity\": 1.0, \"npv\": 0.6848086124401914, \"accuracy\": 0.8340680100755667, \"f1\": 0.850919377652051, \"f2\": 0.7810552555047777, \"f0_5\": 0.934509755188269, \"p4\": 0.8314865765456597, \"phi\": 0.7121206231636821}, {\"truth_threshold\": -1.6576592239463983, \"match_probability\": 0.24067145240363028, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1503.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 528.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.740029542097489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25997045790251105, \"precision\": 1.0, \"recall\": 0.740029542097489, \"specificity\": 1.0, \"npv\": 0.6843992827256425, \"accuracy\": 0.8337531486146096, \"f1\": 0.8505942275042445, \"f2\": 0.7806170146463073, \"f0_5\": 0.9343528534129056, \"p4\": 0.8311804415517049, \"phi\": 0.711671053090757}, {\"truth_threshold\": -1.641955527014122, \"match_probability\": 0.24266627843067337, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1481.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 550.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7291974396848843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2708025603151157, \"precision\": 1.0, \"recall\": 0.7291974396848843, \"specificity\": 1.0, \"npv\": 0.6755162241887905, \"accuracy\": 0.8268261964735516, \"f1\": 0.8433940774487472, \"f2\": 0.7709526288391463, \"f0_5\": 0.9308610936517914, \"p4\": 0.8244498789393335, \"phi\": 0.7018437868529338}, {\"truth_threshold\": -1.627390785536496, \"match_probability\": 0.24452644140729446, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1480.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 551.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7287050713934022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27129492860659776, \"precision\": 1.0, \"recall\": 0.7287050713934022, \"specificity\": 1.0, \"npv\": 0.6751179245283019, \"accuracy\": 0.8265113350125944, \"f1\": 0.8430646539447451, \"f2\": 0.770512286547272, \"f0_5\": 0.9307005408124764, \"p4\": 0.8241441255231906, \"phi\": 0.7013999254293956}, {\"truth_threshold\": -1.617628921741955, \"match_probability\": 0.2457785818097455, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1479.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 552.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7282127031019202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2717872968980798, \"precision\": 1.0, \"recall\": 0.7282127031019202, \"specificity\": 1.0, \"npv\": 0.6747200942840307, \"accuracy\": 0.8261964735516373, \"f1\": 0.8427350427350427, \"f2\": 0.7700718525460793, \"f0_5\": 0.9305398263495659, \"p4\": 0.823838386197093, \"phi\": 0.7009563065525244}, {\"truth_threshold\": -1.60015397700965, \"match_probability\": 0.24803084029325032, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1474.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 557.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7257508616445101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2742491383554899, \"precision\": 1.0, \"recall\": 0.7257508616445101, \"specificity\": 1.0, \"npv\": 0.672737955346651, \"accuracy\": 0.8246221662468514, \"f1\": 0.8410841654778888, \"f2\": 0.7678683058970619, \"f0_5\": 0.929733821117699, \"p4\": 0.8223098935491333, \"phi\": 0.6987418341231602}, {\"truth_threshold\": -1.5751201303976419, \"match_probability\": 0.251281345039336, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1473.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 558.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.725258493353028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27474150664697194, \"precision\": 1.0, \"recall\": 0.725258493353028, \"specificity\": 1.0, \"npv\": 0.6723429242513213, \"accuracy\": 0.8243073047858942, \"f1\": 0.8407534246575342, \"f2\": 0.7674273210378243, \"f0_5\": 0.9295721317682696, \"p4\": 0.8220042343390863, \"phi\": 0.6982996607897517}, {\"truth_threshold\": -1.5716749605728872, \"match_probability\": 0.25173088966911483, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1471.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 560.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.724273756770064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.275726243229936, \"precision\": 1.0, \"recall\": 0.724273756770064, \"specificity\": 1.0, \"npv\": 0.6715542521994134, \"accuracy\": 0.8236775818639799, \"f1\": 0.8400913763563678, \"f2\": 0.7665450755601876, \"f0_5\": 0.9292482627921668, \"p4\": 0.8213929535462696, \"phi\": 0.6974160315875885}, {\"truth_threshold\": -1.5573235729298933, \"match_probability\": 0.253609271991954, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1470.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 561.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.723781388478582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.276218611521418, \"precision\": 1.0, \"recall\": 0.723781388478582, \"specificity\": 1.0, \"npv\": 0.6711606096131302, \"accuracy\": 0.8233627204030227, \"f1\": 0.8397600685518424, \"f2\": 0.7661038148843027, \"f0_5\": 0.9290860826697004, \"p4\": 0.8210873315393467, \"phi\": 0.6969745748002024}, {\"truth_threshold\": -1.4893005486415942, \"match_probability\": 0.26263757735543075, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1469.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 562.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7232890201871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27671097981290005, \"precision\": 1.0, \"recall\": 0.7232890201871, \"specificity\": 1.0, \"npv\": 0.6707674282366726, \"accuracy\": 0.8230478589420654, \"f1\": 0.8394285714285714, \"f2\": 0.7656624622120296, \"f0_5\": 0.9289237384595928, \"p4\": 0.8207817215089066, \"phi\": 0.6965333559440808}, {\"truth_threshold\": -1.4876572891473023, \"match_probability\": 0.2628582186827172, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1464.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 567.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7208271787296898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2791728212703102, \"precision\": 1.0, \"recall\": 0.7208271787296898, \"specificity\": 1.0, \"npv\": 0.6688084112149533, \"accuracy\": 0.8214735516372796, \"f1\": 0.8377682403433476, \"f2\": 0.7634543178973717, \"f0_5\": 0.9281095473564093, \"p4\": 0.8192538435513413, \"phi\": 0.6943308146458437}, {\"truth_threshold\": -1.4343830620783267, \"match_probability\": 0.27007569304910023, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1463.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 568.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7203348104382078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2796651895617922, \"precision\": 1.0, \"recall\": 0.7203348104382078, \"specificity\": 1.0, \"npv\": 0.6684179801517806, \"accuracy\": 0.8211586901763224, \"f1\": 0.8374356038923869, \"f2\": 0.7630124126421195, \"f0_5\": 0.9279462133705442, \"p4\": 0.8189483009047794, \"phi\": 0.6938910137954826}, {\"truth_threshold\": -1.4217473006256596, \"match_probability\": 0.2718057598718078, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1462.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 569.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7198424421467258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28015755785327423, \"precision\": 1.0, \"recall\": 0.7198424421467258, \"specificity\": 1.0, \"npv\": 0.6680280046674446, \"accuracy\": 0.8208438287153652, \"f1\": 0.8371027769825365, \"f2\": 0.7625704151888171, \"f0_5\": 0.9277827135423277, \"p4\": 0.8186427687407167, \"phi\": 0.6934514476891785}, {\"truth_threshold\": -1.3789168965459029, \"match_probability\": 0.27772142508429104, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1460.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 571.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7188577055637617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2811422944362383, \"precision\": 1.0, \"recall\": 0.7188577055637617, \"specificity\": 1.0, \"npv\": 0.6672494172494172, \"accuracy\": 0.8202141057934509, \"f1\": 0.836436551131481, \"f2\": 0.761686143572621, \"f0_5\": 0.9274552153474781, \"p4\": 0.8180317350021501, \"phi\": 0.692573017899682}, {\"truth_threshold\": -1.3616271968043436, \"match_probability\": 0.2801317759130469, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1459.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 572.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7183653372722797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2816346627277203, \"precision\": 1.0, \"recall\": 0.7183653372722797, \"specificity\": 1.0, \"npv\": 0.6668608037274316, \"accuracy\": 0.8198992443324937, \"f1\": 0.8361031518624642, \"f2\": 0.7612438693519774, \"f0_5\": 0.9272912164738782, \"p4\": 0.8177262329980465, \"phi\": 0.6921341533137343}, {\"truth_threshold\": -1.3486812006550588, \"match_probability\": 0.281944914893692, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1458.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 573.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7178729689807977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2821270310192024, \"precision\": 1.0, \"recall\": 0.7178729689807977, \"specificity\": 1.0, \"npv\": 0.6664726426076834, \"accuracy\": 0.8195843828715366, \"f1\": 0.8357695614789338, \"f2\": 0.7608015028177834, \"f0_5\": 0.9271270507439908, \"p4\": 0.817420740617241, \"phi\": 0.6916955216663294}, {\"truth_threshold\": -1.3471221369831692, \"match_probability\": 0.28216374831477103, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1457.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 574.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7173806006893156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2826193993106844, \"precision\": 1.0, \"recall\": 0.7173806006893156, \"specificity\": 1.0, \"npv\": 0.6660849331006399, \"accuracy\": 0.8192695214105793, \"f1\": 0.8354357798165137, \"f2\": 0.7603590439411335, \"f0_5\": 0.9269627179030411, \"p4\": 0.8171152576442998, \"phi\": 0.691257122507855}, {\"truth_threshold\": -1.3469202208279873, \"match_probability\": 0.28219209722522637, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1454.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 577.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7159034958148696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2840965041851305, \"precision\": 1.0, \"recall\": 0.7159034958148696, \"specificity\": 1.0, \"npv\": 0.664924506387921, \"accuracy\": 0.8183249370277078, \"f1\": 0.8344332855093257, \"f2\": 0.7590311129672166, \"f0_5\": 0.926468714158277, \"p4\": 0.8161988630144861, \"phi\": 0.6899433154804018}, {\"truth_threshold\": -1.3287695132171036, \"match_probability\": 0.2847474924332938, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1453.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 578.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7154111275233875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2845888724766125, \"precision\": 1.0, \"recall\": 0.7154111275233875, \"specificity\": 1.0, \"npv\": 0.6645385954730122, \"accuracy\": 0.8180100755667506, \"f1\": 0.8340987370838117, \"f2\": 0.7585882844314503, \"f0_5\": 0.9263037103149305, \"p4\": 0.8158934155135413, \"phi\": 0.6895058417955253}, {\"truth_threshold\": -1.2952895988248894, \"match_probability\": 0.2894973912623797, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1452.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 579.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7149187592319055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28508124076809455, \"precision\": 1.0, \"recall\": 0.7149187592319055, \"specificity\": 1.0, \"npv\": 0.66415313225058, \"accuracy\": 0.8176952141057935, \"f1\": 0.8337639965546942, \"f2\": 0.7581453634085213, \"f0_5\": 0.9261385380788366, \"p4\": 0.8155879763394422, \"phi\": 0.6890685983619979}, {\"truth_threshold\": -1.2732517871332485, \"match_probability\": 0.29264945159455735, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1450.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 581.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7139340226489415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2860659773510586, \"precision\": 1.0, \"recall\": 0.7139340226489415, \"specificity\": 1.0, \"npv\": 0.6633835457705678, \"accuracy\": 0.8170654911838791, \"f1\": 0.8330939385234128, \"f2\": 0.7572592437852518, \"f0_5\": 0.9258076873962456, \"p4\": 0.8149771221036006, \"phi\": 0.6881948004679341}, {\"truth_threshold\": -1.2185682554280546, \"match_probability\": 0.3005569439949334, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1449.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 582.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7134416543574594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2865583456425406, \"precision\": 1.0, \"recall\": 0.7134416543574594, \"specificity\": 1.0, \"npv\": 0.6629994209612045, \"accuracy\": 0.8167506297229219, \"f1\": 0.8327586206896552, \"f2\": 0.7568160451269195, \"f0_5\": 0.9256420084323496, \"p4\": 0.8146717066071144, \"phi\": 0.6877582451185876}, {\"truth_threshold\": -1.1944067534303282, \"match_probability\": 0.3040893562171932, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1448.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 583.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7129492860659774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28705071393402265, \"precision\": 1.0, \"recall\": 0.7129492860659774, \"specificity\": 1.0, \"npv\": 0.6626157407407407, \"accuracy\": 0.8164357682619647, \"f1\": 0.8324231100891061, \"f2\": 0.7563727538654409, \"f0_5\": 0.925476160040905, \"p4\": 0.8143662985679848, \"phi\": 0.6873219182429656}, {\"truth_threshold\": -1.160542530237875, \"match_probability\": 0.3090793843381317, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1447.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 584.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7124569177744953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2875430822255047, \"precision\": 1.0, \"recall\": 0.7124569177744953, \"specificity\": 1.0, \"npv\": 0.6622325043377675, \"accuracy\": 0.8161209068010076, \"f1\": 0.8320874065554916, \"f2\": 0.7559293699717898, \"f0_5\": 0.9253101419618877, \"p4\": 0.8140608977681825, \"phi\": 0.6868858193983706}, {\"truth_threshold\": -1.157667655298531, \"match_probability\": 0.3095050883302145, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1446.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 585.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7119645494830132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2880354505169867, \"precision\": 1.0, \"recall\": 0.7119645494830132, \"specificity\": 1.0, \"npv\": 0.661849710982659, \"accuracy\": 0.8158060453400504, \"f1\": 0.8317515099223468, \"f2\": 0.7554858934169278, \"f0_5\": 0.9251439539347409, \"p4\": 0.8137555039894132, \"phi\": 0.6864499481427844}, {\"truth_threshold\": -1.1376323562231982, \"match_probability\": 0.31248081480324286, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1445.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 586.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7114721811915312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28852781880846873, \"precision\": 1.0, \"recall\": 0.7114721811915312, \"specificity\": 1.0, \"npv\": 0.6614673599075679, \"accuracy\": 0.8154911838790933, \"f1\": 0.8314154200230149, \"f2\": 0.7550423241718048, \"f0_5\": 0.9249775956983741, \"p4\": 0.8134501170131173, \"phi\": 0.6860143040348656}, {\"truth_threshold\": -1.1337253076705602, \"match_probability\": 0.31306292175833084, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1444.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 587.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7109798129000492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28902018709995075, \"precision\": 1.0, \"recall\": 0.7109798129000492, \"specificity\": 1.0, \"npv\": 0.6610854503464203, \"accuracy\": 0.815176322418136, \"f1\": 0.8310791366906475, \"f2\": 0.7545986622073578, \"f0_5\": 0.9248110669911618, \"p4\": 0.8131447366204683, \"phi\": 0.6855788866339472}, {\"truth_threshold\": -1.1264353458055316, \"match_probability\": 0.3141506209656002, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1442.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 589.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7099950763170851, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2900049236829148, \"precision\": 1.0, \"recall\": 0.7099950763170851, \"specificity\": 1.0, \"npv\": 0.660322952710496, \"accuracy\": 0.8145465994962217, \"f1\": 0.8304059890584509, \"f2\": 0.7537110600041814, \"f0_5\": 0.9244774971150147, \"p4\": 0.8125339947094666, \"phi\": 0.6847087301938041}, {\"truth_threshold\": -1.1192530704661154, \"match_probability\": 0.31522425258409126, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1441.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 590.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7095027080256031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29049729197439683, \"precision\": 1.0, \"recall\": 0.7095027080256031, \"specificity\": 1.0, \"npv\": 0.659942363112392, \"accuracy\": 0.8142317380352645, \"f1\": 0.8300691244239631, \"f2\": 0.7532671197072661, \"f0_5\": 0.9243104554201411, \"p4\": 0.8122286327521192, \"phi\": 0.6842739902765982}, {\"truth_threshold\": -1.104231023134606, \"match_probability\": 0.3174761833109746, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1440.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 591.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7090103397341211, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29098966026587886, \"precision\": 1.0, \"recall\": 0.7090103397341211, \"specificity\": 1.0, \"npv\": 0.6595622119815668, \"accuracy\": 0.8139168765743073, \"f1\": 0.8297320656871219, \"f2\": 0.7528230865746549, \"f0_5\": 0.9241432422025414, \"p4\": 0.8119232765004275, \"phi\": 0.6838394753104262}, {\"truth_threshold\": -1.0928302326528618, \"match_probability\": 0.3191909853599168, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1439.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 592.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7085179714426391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2914820285573609, \"precision\": 1.0, \"recall\": 0.7085179714426391, \"specificity\": 1.0, \"npv\": 0.6591824985607369, \"accuracy\": 0.8136020151133502, \"f1\": 0.8293948126801153, \"f2\": 0.7523789605772248, \"f0_5\": 0.9239758571978939, \"p4\": 0.8116179257342173, \"phi\": 0.6834051848579609}, {\"truth_threshold\": -1.0778311871087394, \"match_probability\": 0.32145447354111545, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1438.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 593.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.708025603151157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2919743968488429, \"precision\": 1.0, \"recall\": 0.708025603151157, \"specificity\": 1.0, \"npv\": 0.6588032220943614, \"accuracy\": 0.8132871536523929, \"f1\": 0.829057365234938, \"f2\": 0.7519347416858397, \"f0_5\": 0.9238083001413336, \"p4\": 0.8113125802330422, \"phi\": 0.6829711184825358}, {\"truth_threshold\": -1.0726197898684586, \"match_probability\": 0.32224289388686767, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1437.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 594.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.707533234859675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29246676514032494, \"precision\": 1.0, \"recall\": 0.707533234859675, \"specificity\": 1.0, \"npv\": 0.6584243818286372, \"accuracy\": 0.8129722921914357, \"f1\": 0.828719723183391, \"f2\": 0.7514904298713524, \"f0_5\": 0.9236405707674509, \"p4\": 0.811007239776182, \"phi\": 0.6825372757481436}, {\"truth_threshold\": -1.0488578452284976, \"match_probability\": 0.3258505770941434, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1436.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 595.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.707040866568193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.292959133431807, \"precision\": 1.0, \"recall\": 0.707040866568193, \"specificity\": 1.0, \"npv\": 0.6580459770114943, \"accuracy\": 0.8126574307304786, \"f1\": 0.8283818863570811, \"f2\": 0.7510460251046025, \"f0_5\": 0.9234726688102894, \"p4\": 0.8107019041426428, \"phi\": 0.6821036562194343}, {\"truth_threshold\": -1.0486615940243682, \"match_probability\": 0.32588045999407367, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1435.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 596.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.706548498276711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29345150172328904, \"precision\": 1.0, \"recall\": 0.706548498276711, \"specificity\": 1.0, \"npv\": 0.6576680068925904, \"accuracy\": 0.8123425692695214, \"f1\": 0.8280438545874207, \"f2\": 0.750601527356418, \"f0_5\": 0.9233045940033457, \"p4\": 0.8103965731111544, \"phi\": 0.6816702594617118}, {\"truth_threshold\": -1.045257116426562, \"match_probability\": 0.32639908023153524, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1434.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 597.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7060561299852289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29394387001477107, \"precision\": 1.0, \"recall\": 0.7060561299852289, \"specificity\": 1.0, \"npv\": 0.6572904707233066, \"accuracy\": 0.8120277078085643, \"f1\": 0.8277056277056277, \"f2\": 0.7501569365976145, \"f0_5\": 0.9231363460795674, \"p4\": 0.8100912464601709, \"phi\": 0.6812370850409329}, {\"truth_threshold\": -1.0228718793025047, \"match_probability\": 0.3298196734609405, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1433.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 598.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7055637616937469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2944362383062531, \"precision\": 1.0, \"recall\": 0.7055637616937469, \"specificity\": 1.0, \"npv\": 0.6569133677567413, \"accuracy\": 0.8117128463476071, \"f1\": 0.8273672055427251, \"f2\": 0.7497122527989954, \"f0_5\": 0.9229679247713513, \"p4\": 0.8097859239678689, \"phi\": 0.6808041325237048}, {\"truth_threshold\": -0.9722176382475164, \"match_probability\": 0.33762637174282234, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1430.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 601.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7040866568193008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2959133431806992, \"precision\": 1.0, \"recall\": 0.7040866568193008, \"specificity\": 1.0, \"npv\": 0.6557846506300115, \"accuracy\": 0.8107682619647355, \"f1\": 0.8263507656746605, \"f2\": 0.7483776428720954, \"f0_5\": 0.9224616178557605, \"p4\": 0.8088699792206349, \"phi\": 0.6795066020691028}, {\"truth_threshold\": -0.9553186312865701, \"match_probability\": 0.34025087952174204, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1426.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 605.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7021171836533727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2978828163466273, \"precision\": 1.0, \"recall\": 0.7021171836533727, \"specificity\": 1.0, \"npv\": 0.6542857142857142, \"accuracy\": 0.8095088161209067, \"f1\": 0.8249927682962106, \"f2\": 0.7465968586387435, \"f0_5\": 0.9217840982546864, \"p4\": 0.807648764272955, \"phi\": 0.6777796419330703}, {\"truth_threshold\": -0.9427747636624829, \"match_probability\": 0.3422053805567698, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1425.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 606.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7016248153618907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2983751846381093, \"precision\": 1.0, \"recall\": 0.7016248153618907, \"specificity\": 1.0, \"npv\": 0.653912050256996, \"accuracy\": 0.8091939546599496, \"f1\": 0.8246527777777778, \"f2\": 0.7461514294690543, \"f0_5\": 0.9216142801707412, \"p4\": 0.8073434670308465, \"phi\": 0.6773484491194175}, {\"truth_threshold\": -0.9417463901078561, \"match_probability\": 0.3423658536945229, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1424.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 607.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7011324470704087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29886755292959133, \"precision\": 1.0, \"recall\": 0.7011324470704087, \"specificity\": 1.0, \"npv\": 0.6535388127853882, \"accuracy\": 0.8088790931989924, \"f1\": 0.8243125904486251, \"f2\": 0.7457059069962296, \"f0_5\": 0.9214442862689272, \"p4\": 0.8070381719383619, \"phi\": 0.6769174743376838}, {\"truth_threshold\": -0.9344964696314093, \"match_probability\": 0.343498193439883, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1423.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 608.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7006400787789266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29935992122107336, \"precision\": 1.0, \"recall\": 0.7006400787789266, \"specificity\": 1.0, \"npv\": 0.6531660011409013, \"accuracy\": 0.8085642317380353, \"f1\": 0.8239722061378112, \"f2\": 0.74526029119095, \"f0_5\": 0.9212741162760585, \"p4\": 0.8067328787708493, \"phi\": 0.6764867171608602}, {\"truth_threshold\": -0.9297657661647478, \"match_probability\": 0.34423802713932555, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1419.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 612.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6986706056129985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30132939438700146, \"precision\": 1.0, \"recall\": 0.6986706056129985, \"specificity\": 1.0, \"npv\": 0.651678998292544, \"accuracy\": 0.8073047858942065, \"f1\": 0.8226086956521739, \"f2\": 0.7434768940584722, \"f0_5\": 0.920591669910471, \"p4\": 0.8055117208473576, \"phi\": 0.6747658559843733}, {\"truth_threshold\": -0.9225834908253312, \"match_probability\": 0.34536270614140346, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1418.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 613.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6981782373215165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3018217626784835, \"precision\": 1.0, \"recall\": 0.6981782373215165, \"specificity\": 1.0, \"npv\": 0.6513083048919226, \"accuracy\": 0.8069899244332494, \"f1\": 0.822267323861989, \"f2\": 0.7430308111507021, \"f0_5\": 0.9204206153446709, \"p4\": 0.8052064339247906, \"phi\": 0.6743361804488228}, {\"truth_threshold\": -0.9089146414077046, \"match_probability\": 0.34750790277153415, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1416.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 615.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6971935007385525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30280649926144754, \"precision\": 1.0, \"recall\": 0.6971935007385525, \"specificity\": 1.0, \"npv\": 0.6505681818181818, \"accuracy\": 0.806360201511335, \"f1\": 0.8215839860748477, \"f2\": 0.7421383647798742, \"f0_5\": 0.9200779727095516, \"p4\": 0.8045958615658608, \"phi\": 0.6734774741228791}, {\"truth_threshold\": -0.902672746966793, \"match_probability\": 0.34848957786237394, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1415.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 616.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6967011324470704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3032988675529296, \"precision\": 1.0, \"recall\": 0.6967011324470704, \"specificity\": 1.0, \"npv\": 0.6501987507098239, \"accuracy\": 0.8060453400503779, \"f1\": 0.8212420197330238, \"f2\": 0.7416920012579935, \"f0_5\": 0.9199063840852945, \"p4\": 0.8042905756758165, \"phi\": 0.6730484424877639}, {\"truth_threshold\": -0.8873746904900222, \"match_probability\": 0.35090096588702896, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1414.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 617.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6962087641555884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30379123584441164, \"precision\": 1.0, \"recall\": 0.6962087641555884, \"specificity\": 1.0, \"npv\": 0.6498297389330306, \"accuracy\": 0.8057304785894207, \"f1\": 0.820899854862119, \"f2\": 0.7412455441392325, \"f0_5\": 0.9197346168856511, \"p4\": 0.8039852896757712, \"phi\": 0.672619624642423}, {\"truth_threshold\": -0.8821348109831896, \"match_probability\": 0.35172867370432187, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1412.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 619.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6952240275726244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3047759724273757, \"precision\": 1.0, \"recall\": 0.6952240275726244, \"specificity\": 1.0, \"npv\": 0.6490929705215419, \"accuracy\": 0.8051007556675063, \"f1\": 0.8202149288411269, \"f2\": 0.7403523489932886, \"f0_5\": 0.919390545643964, \"p4\": 0.8033747164350464, \"phi\": 0.6717626286383197}, {\"truth_threshold\": -0.8781627018453902, \"match_probability\": 0.35235671510600225, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1408.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 623.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6932545544066963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3067454455933038, \"precision\": 1.0, \"recall\": 0.6932545544066963, \"specificity\": 1.0, \"npv\": 0.6476244343891403, \"accuracy\": 0.8038413098236776, \"f1\": 0.8188426868275661, \"f2\": 0.7385648342425514, \"f0_5\": 0.9187002479446692, \"p4\": 0.8021535585998486, \"phi\": 0.6700511836310209}, {\"truth_threshold\": -0.8095853840346647, \"match_probability\": 0.36327867815690573, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1407.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 624.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6927621861152142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3072378138847858, \"precision\": 1.0, \"recall\": 0.6927621861152142, \"specificity\": 1.0, \"npv\": 0.6472583380440927, \"accuracy\": 0.8035264483627204, \"f1\": 0.8184991273996509, \"f2\": 0.738117721120554, \"f0_5\": 0.918527222875049, \"p4\": 0.8018482654406616, \"phi\": 0.669623850564424}, {\"truth_threshold\": -0.8052686131505165, \"match_probability\": 0.36397106872030544, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1406.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 625.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6922698178237322, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30773018217626785, \"precision\": 1.0, \"recall\": 0.6922698178237322, \"specificity\": 1.0, \"npv\": 0.6468926553672316, \"accuracy\": 0.8032115869017632, \"f1\": 0.8181553680535351, \"f2\": 0.7376705141657922, \"f0_5\": 0.9183540169823645, \"p4\": 0.8015429703423823, \"phi\": 0.6691967279377447}, {\"truth_threshold\": -0.7937594013120942, \"match_probability\": 0.3658198435429423, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1405.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 626.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6917774495322502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3082225504677499, \"precision\": 1.0, \"recall\": 0.6917774495322502, \"specificity\": 1.0, \"npv\": 0.6465273856578204, \"accuracy\": 0.802896725440806, \"f1\": 0.8178114086146682, \"f2\": 0.737223213348725, \"f0_5\": 0.9181806299830088, \"p4\": 0.8012376730750075, \"phi\": 0.6687698153349331}, {\"truth_threshold\": -0.7890286978454328, \"match_probability\": 0.3665809086869395, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1404.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 627.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.691285081240768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3087149187592319, \"precision\": 1.0, \"recall\": 0.691285081240768, \"specificity\": 1.0, \"npv\": 0.6461625282167043, \"accuracy\": 0.8025818639798489, \"f1\": 0.8174672489082969, \"f2\": 0.7367758186397985, \"f0_5\": 0.9180070615927814, \"p4\": 0.8009323734082261, \"phi\": 0.6683431123405287}, {\"truth_threshold\": -0.7765212621219664, \"match_probability\": 0.36859627798622274, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1402.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 629.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.690300344657804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30969965534219596, \"precision\": 1.0, \"recall\": 0.690300344657804, \"specificity\": 1.0, \"npv\": 0.64543404735062, \"accuracy\": 0.8019521410579346, \"f1\": 0.816778327993009, \"f2\": 0.7358807474280915, \"f0_5\": 0.9176593794999346, \"p4\": 0.8003217659536572, \"phi\": 0.6674903335180326}, {\"truth_threshold\": -0.7595028537246867, \"match_probability\": 0.3713458883243709, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1399.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 632.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6888232397833579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31117676021664203, \"precision\": 1.0, \"recall\": 0.6888232397833579, \"specificity\": 1.0, \"npv\": 0.6443444006752954, \"accuracy\": 0.801007556675063, \"f1\": 0.8157434402332362, \"f2\": 0.734537435682033, \"f0_5\": 0.9171364887898256, \"p4\": 0.7994058310006902, \"phi\": 0.6662127269944811}, {\"truth_threshold\": -0.7089680141060319, \"match_probability\": 0.37955930212876116, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1397.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 634.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6878385032003939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3121614967996061, \"precision\": 1.0, \"recall\": 0.6878385032003939, \"specificity\": 1.0, \"npv\": 0.643620011242271, \"accuracy\": 0.8003778337531486, \"f1\": 0.8150525087514586, \"f2\": 0.7336414242201449, \"f0_5\": 0.9167869799186245, \"p4\": 0.7987951891462153, \"phi\": 0.6653620256392038}, {\"truth_threshold\": -0.6881458524508712, \"match_probability\": 0.38296400510831574, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1395.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 636.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6868537666174298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31314623338257014, \"precision\": 1.0, \"recall\": 0.6868537666174298, \"specificity\": 1.0, \"npv\": 0.6428972487366648, \"accuracy\": 0.7997481108312342, \"f1\": 0.8143607705779334, \"f2\": 0.7327450362433029, \"f0_5\": 0.9164367363027197, \"p4\": 0.7981845302790667, \"phi\": 0.6645121495072613}, {\"truth_threshold\": -0.6834151489842099, \"match_probability\": 0.383739155471364, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1393.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 638.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6858690300344658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31413096996553425, \"precision\": 1.0, \"recall\": 0.6858690300344658, \"specificity\": 1.0, \"npv\": 0.6421761076836792, \"accuracy\": 0.7991183879093199, \"f1\": 0.8136682242990654, \"f2\": 0.7318482715141326, \"f0_5\": 0.9160857556227805, \"p4\": 0.7975738525329583, \"phi\": 0.6636630953189379}, {\"truth_threshold\": -0.6688483157153498, \"match_probability\": 0.38612970483530307, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1391.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 640.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6848842934515017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3151157065484983, \"precision\": 1.0, \"recall\": 0.6848842934515017, \"specificity\": 1.0, \"npv\": 0.6414565826330533, \"accuracy\": 0.7984886649874056, \"f1\": 0.8129748684979544, \"f2\": 0.7309511297950604, \"f0_5\": 0.9157340355497038, \"p4\": 0.7969631540364932, \"phi\": 0.6628148598035907}, {\"truth_threshold\": -0.6529396936478018, \"match_probability\": 0.3887467373325311, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1390.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 641.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6843919251600197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3156080748399803, \"precision\": 1.0, \"recall\": 0.6843919251600197, \"specificity\": 1.0, \"npv\": 0.641097424412094, \"accuracy\": 0.7981738035264484, \"f1\": 0.8126278865828706, \"f2\": 0.7305024174900148, \"f0_5\": 0.9155578975102094, \"p4\": 0.7966577964206586, \"phi\": 0.6623910480286727}, {\"truth_threshold\": -0.6498783153304506, \"match_probability\": 0.3892510882169574, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1389.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 642.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6838995568685377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31610044313146235, \"precision\": 1.0, \"recall\": 0.6838995568685377, \"specificity\": 1.0, \"npv\": 0.6407386681589256, \"accuracy\": 0.7978589420654912, \"f1\": 0.8122807017543859, \"f2\": 0.7300536108483129, \"f0_5\": 0.9153815737445631, \"p4\": 0.7963524329131265, \"phi\": 0.6619674396995868}, {\"truth_threshold\": -0.6486048002510206, \"match_probability\": 0.38946096505918343, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1388.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 643.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6834071885770556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3165928114229444, \"precision\": 1.0, \"recall\": 0.6834071885770556, \"specificity\": 1.0, \"npv\": 0.6403803131991052, \"accuracy\": 0.797544080604534, \"f1\": 0.8119333138344546, \"f2\": 0.7296047098402019, \"f0_5\": 0.9152050639588554, \"p4\": 0.7960470632785187, \"phi\": 0.6615440344100268}, {\"truth_threshold\": -0.6268619367665261, \"match_probability\": 0.3930504773701659, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1387.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 644.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6829148202855736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3170851797144264, \"precision\": 1.0, \"recall\": 0.6829148202855736, \"specificity\": 1.0, \"npv\": 0.6400223588596982, \"accuracy\": 0.7972292191435768, \"f1\": 0.8115857226448215, \"f2\": 0.7291557144359163, \"f0_5\": 0.9150283678585566, \"p4\": 0.7957416872811305, \"phi\": 0.6611208317542412}, {\"truth_threshold\": -0.6187657854053716, \"match_probability\": 0.3943900447880931, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1386.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 645.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6824224519940916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3175775480059084, \"precision\": 1.0, \"recall\": 0.6824224519940916, \"specificity\": 1.0, \"npv\": 0.6396648044692738, \"accuracy\": 0.7969143576826196, \"f1\": 0.8112379280070237, \"f2\": 0.7287066246056783, \"f0_5\": 0.9148514851485149, \"p4\": 0.7954363046849302, \"phi\": 0.6606978313270317}, {\"truth_threshold\": -0.5877367321847995, \"match_probability\": 0.39953858069870285, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1385.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 646.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6819300837026095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31806991629739045, \"precision\": 1.0, \"recall\": 0.6819300837026095, \"specificity\": 1.0, \"npv\": 0.6393076493579006, \"accuracy\": 0.7965994962216625, \"f1\": 0.8108899297423887, \"f2\": 0.7282574403196971, \"f0_5\": 0.9146744155329547, \"p4\": 0.7951309152535574, \"phi\": 0.6602750327237519}, {\"truth_threshold\": -0.5697660710396182, \"match_probability\": 0.40253064919942916, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1384.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 647.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6814377154111275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3185622845888725, \"precision\": 1.0, \"recall\": 0.6814377154111275, \"specificity\": 1.0, \"npv\": 0.6389508928571429, \"accuracy\": 0.7962846347607053, \"f1\": 0.8105417276720351, \"f2\": 0.72780816154817, \"f0_5\": 0.9144971587154751, \"p4\": 0.7948255187503221, \"phi\": 0.6598524355403044}, {\"truth_threshold\": -0.5390484592075483, \"match_probability\": 0.4076617823174534, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1383.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 648.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6809453471196455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3190546528803545, \"precision\": 1.0, \"recall\": 0.6809453471196455, \"specificity\": 1.0, \"npv\": 0.6385945343000557, \"accuracy\": 0.7959697732997482, \"f1\": 0.8101933216168717, \"f2\": 0.7273587882612812, \"f0_5\": 0.914319714399048, \"p4\": 0.7945201149382034, \"phi\": 0.6594300393731392}, {\"truth_threshold\": -0.5131522365441487, \"match_probability\": 0.4120032880454098, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1382.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 649.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6804529788281635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31954702117183653, \"precision\": 1.0, \"recall\": 0.6804529788281635, \"specificity\": 1.0, \"npv\": 0.6382385730211817, \"accuracy\": 0.7956549118387909, \"f1\": 0.8098447113975974, \"f2\": 0.7269093204292026, \"f0_5\": 0.9141420822860167, \"p4\": 0.7942147035798486, \"phi\": 0.6590078438192518}, {\"truth_threshold\": -0.5129964898270091, \"match_probability\": 0.41202944119916984, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1379.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 652.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6789758739537174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3210241260462826, \"precision\": 1.0, \"recall\": 0.6789758739537174, \"specificity\": 1.0, \"npv\": 0.6371730662214803, \"accuracy\": 0.7947103274559194, \"f1\": 0.8087976539589443, \"f2\": 0.7255603493633589, \"f0_5\": 0.9136080561812641, \"p4\": 0.7932984218488349, \"phi\": 0.6577424568153551}, {\"truth_threshold\": -0.4956772918118437, \"match_probability\": 0.41494076648711037, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1378.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 653.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6784835056622354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32151649433776464, \"precision\": 1.0, \"recall\": 0.6784835056622354, \"specificity\": 1.0, \"npv\": 0.6368186874304783, \"accuracy\": 0.7943954659949622, \"f1\": 0.8084482252860077, \"f2\": 0.7251105030519891, \"f0_5\": 0.9134296698926156, \"p4\": 0.7929929779253273, \"phi\": 0.6573210596953777}, {\"truth_threshold\": -0.48104127510501676, \"match_probability\": 0.4174057016200519, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1375.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 656.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6770064007877893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3229935992122107, \"precision\": 1.0, \"recall\": 0.6770064007877893, \"specificity\": 1.0, \"npv\": 0.6357579122709606, \"accuracy\": 0.7934508816120907, \"f1\": 0.8073987081620669, \"f2\": 0.7237603958311402, \"f0_5\": 0.9128933740539105, \"p4\": 0.7920765927688658, \"phi\": 0.6560580583751121}, {\"truth_threshold\": -0.384823863443788, \"match_probability\": 0.43370769880734117, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1373.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 658.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6760216642048252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32397833579517477, \"precision\": 1.0, \"recall\": 0.6760216642048252, \"specificity\": 1.0, \"npv\": 0.6350526899611758, \"accuracy\": 0.7928211586901763, \"f1\": 0.8066980023501763, \"f2\": 0.7228598504790986, \"f0_5\": 0.9125348929948159, \"p4\": 0.7914656224449931, \"phi\": 0.655217045203576}, {\"truth_threshold\": -0.3838506599285539, \"match_probability\": 0.43387338500217265, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1370.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 661.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6745445593303792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3254554406696209, \"precision\": 1.0, \"recall\": 0.6745445593303792, \"specificity\": 1.0, \"npv\": 0.6339977851605758, \"accuracy\": 0.7918765743073047, \"f1\": 0.8056453984122317, \"f2\": 0.7215083210448704, \"f0_5\": 0.9119957395819465, \"p4\": 0.7905490918185237, \"phi\": 0.6539569990508374}, {\"truth_threshold\": -0.365806529533806, \"match_probability\": 0.4369480065841122, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1363.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 668.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.671097981290005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3289020187099951, \"precision\": 1.0, \"recall\": 0.671097981290005, \"specificity\": 1.0, \"npv\": 0.631549917264203, \"accuracy\": 0.7896725440806045, \"f1\": 0.803182086034178, \"f2\": 0.7183514282702645, \"f0_5\": 0.9107309902445543, \"p4\": 0.7884101358393227, \"phi\": 0.6510237127477586}, {\"truth_threshold\": -0.33720970693586416, \"match_probability\": 0.4418305980816295, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1362.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 669.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.670605612998523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3293943870014771, \"precision\": 1.0, \"recall\": 0.670605612998523, \"specificity\": 1.0, \"npv\": 0.6312017640573319, \"accuracy\": 0.7893576826196473, \"f1\": 0.8028293545534925, \"f2\": 0.7179000632511069, \"f0_5\": 0.9105495387083835, \"p4\": 0.7881045231905476, \"phi\": 0.6506054456515225}, {\"truth_threshold\": -0.3173001137014594, \"match_probability\": 0.44523665213630936, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1361.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 670.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6701132447070408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32988675529295913, \"precision\": 1.0, \"recall\": 0.6701132447070408, \"specificity\": 1.0, \"npv\": 0.6308539944903582, \"accuracy\": 0.7890428211586902, \"f1\": 0.8024764150943396, \"f2\": 0.7174486030574592, \"f0_5\": 0.9103678929765886, \"p4\": 0.7877988979323594, \"phi\": 0.6501873708280803}, {\"truth_threshold\": -0.3172706154278534, \"match_probability\": 0.4452417024832744, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1360.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 671.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6696208764155588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33037912358444116, \"precision\": 1.0, \"recall\": 0.6696208764155588, \"specificity\": 1.0, \"npv\": 0.6305066079295154, \"accuracy\": 0.788727959697733, \"f1\": 0.8021232674727219, \"f2\": 0.7169970476592156, \"f0_5\": 0.9101860527372507, \"p4\": 0.7874932598198026, \"phi\": 0.6497694878859451}, {\"truth_threshold\": -0.2990077121710596, \"match_probability\": 0.4483705922693663, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1359.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 672.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6691285081240768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3308714918759232, \"precision\": 1.0, \"recall\": 0.6691285081240768, \"specificity\": 1.0, \"npv\": 0.6301596037424326, \"accuracy\": 0.7884130982367759, \"f1\": 0.8017699115044248, \"f2\": 0.7165453970262575, \"f0_5\": 0.9100040176777823, \"p4\": 0.7871876086075619, \"phi\": 0.6493517964341311}, {\"truth_threshold\": -0.26019298067258284, \"match_probability\": 0.45503381029865814, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1357.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 674.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6681437715411127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33185622845888724, \"precision\": 1.0, \"recall\": 0.6681437715411127, \"specificity\": 1.0, \"npv\": 0.6294667399670149, \"accuracy\": 0.7877833753148614, \"f1\": 0.8010625737898465, \"f2\": 0.7156418099356608, \"f0_5\": 0.9096393618447514, \"p4\": 0.7865762659009635, \"phi\": 0.6485169864400239}, {\"truth_threshold\": -0.18815428380300406, \"match_probability\": 0.4674414831136762, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1350.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 681.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6646971935007385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3353028064992615, \"precision\": 1.0, \"recall\": 0.6646971935007385, \"specificity\": 1.0, \"npv\": 0.627053669222344, \"accuracy\": 0.7855793450881612, \"f1\": 0.7985803016858918, \"f2\": 0.7124762507916402, \"f0_5\": 0.9083568833266048, \"p4\": 0.7844361175550408, \"phi\": 0.6456011261657096}, {\"truth_threshold\": -0.1675820409178144, \"match_probability\": 0.47099285379374956, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1339.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 692.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6592811422944362, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34071885770556376, \"precision\": 1.0, \"recall\": 0.6592811422944362, \"specificity\": 1.0, \"npv\": 0.623298856831791, \"accuracy\": 0.7821158690176322, \"f1\": 0.7946587537091988, \"f2\": 0.7074923385818451, \"f0_5\": 0.9063219168810072, \"p4\": 0.7810714524065827, \"phi\": 0.6410375826134372}, {\"truth_threshold\": -0.15906450835026703, \"match_probability\": 0.4724641097715421, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1338.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 693.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6587887740029542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3412112259970458, \"precision\": 1.0, \"recall\": 0.6587887740029542, \"specificity\": 1.0, \"npv\": 0.6229597388465724, \"accuracy\": 0.781801007556675, \"f1\": 0.7943009795191451, \"f2\": 0.7070386810399493, \"f0_5\": 0.9061357171881349, \"p4\": 0.7807654687830268, \"phi\": 0.6406238230099892}, {\"truth_threshold\": -0.15692197431000499, \"match_probability\": 0.4728342716641504, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1336.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 695.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6578040374199902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34219596258000984, \"precision\": 1.0, \"recall\": 0.6578040374199902, \"specificity\": 1.0, \"npv\": 0.6222826086956522, \"accuracy\": 0.7811712846347607, \"f1\": 0.7935847935847936, \"f2\": 0.7061310782241015, \"f0_5\": 0.9057627118644068, \"p4\": 0.7801534455115435, \"phi\": 0.639796852458844}, {\"truth_threshold\": -0.12465503575906345, \"match_probability\": 0.47841235725776937, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1334.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 697.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6568193008370261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3431806991629739, \"precision\": 1.0, \"recall\": 0.6568193008370261, \"specificity\": 1.0, \"npv\": 0.6216069489685125, \"accuracy\": 0.7805415617128464, \"f1\": 0.7928677563150074, \"f2\": 0.7052230915626982, \"f0_5\": 0.9053888964300257, \"p4\": 0.7795413458460344, \"phi\": 0.6389706109180103}, {\"truth_threshold\": -0.12060103578706945, \"match_probability\": 0.47911359445456486, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1332.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 699.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6558345642540621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34416543574593794, \"precision\": 1.0, \"recall\": 0.6558345642540621, \"specificity\": 1.0, \"npv\": 0.6209327548806941, \"accuracy\": 0.779911838790932, \"f1\": 0.792149866190901, \"f2\": 0.7043147208121827, \"f0_5\": 0.9050142682429678, \"p4\": 0.778929167747172, \"phi\": 0.6381450953570468}, {\"truth_threshold\": -0.11409157023024805, \"match_probability\": 0.48023973476439025, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1324.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 707.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6518956179222059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3481043820777942, \"precision\": 1.0, \"recall\": 0.6518956179222059, \"specificity\": 1.0, \"npv\": 0.6182505399568035, \"accuracy\": 0.7773929471032746, \"f1\": 0.7892697466467958, \"f2\": 0.7006773920406435, \"f0_5\": 0.903507574723625, \"p4\": 0.7764796300097458, \"phi\": 0.6348502325555829}, {\"truth_threshold\": -0.11395724350377975, \"match_probability\": 0.48026297549928704, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1323.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 708.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6514032496307238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34859675036927623, \"precision\": 1.0, \"recall\": 0.6514032496307238, \"specificity\": 1.0, \"npv\": 0.6179168915272532, \"accuracy\": 0.7770780856423174, \"f1\": 0.7889087656529516, \"f2\": 0.7002222927913624, \"f0_5\": 0.9033183121671446, \"p4\": 0.7761733406911309, \"phi\": 0.6344391784423217}, {\"truth_threshold\": -0.09795899054816513, \"match_probability\": 0.4830315192759423, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1322.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 709.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6509108813392418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34908911866075826, \"precision\": 1.0, \"recall\": 0.6509108813392418, \"specificity\": 1.0, \"npv\": 0.6175836030204962, \"accuracy\": 0.7767632241813602, \"f1\": 0.7885475693408888, \"f2\": 0.6997670971839932, \"f0_5\": 0.9031288427380789, \"p4\": 0.775867028931697, \"phi\": 0.6340283016890773}, {\"truth_threshold\": -0.08385587433940386, \"match_probability\": 0.4854729739582381, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1321.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 710.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6504185130477598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3495814869522403, \"precision\": 1.0, \"recall\": 0.6504185130477598, \"specificity\": 1.0, \"npv\": 0.6172506738544474, \"accuracy\": 0.7764483627204031, \"f1\": 0.7881861575178998, \"f2\": 0.6993118051879301, \"f0_5\": 0.9029391660970608, \"p4\": 0.7755606944715063, \"phi\": 0.6336176019225929}, {\"truth_threshold\": -0.08011919966747504, \"match_probability\": 0.48611996772553545, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1320.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 711.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6499261447562777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3500738552437223, \"precision\": 1.0, \"recall\": 0.6499261447562777, \"specificity\": 1.0, \"npv\": 0.6169181034482759, \"accuracy\": 0.7761335012594458, \"f1\": 0.7878245299910475, \"f2\": 0.6988564167725541, \"f0_5\": 0.9027492819039803, \"p4\": 0.7752543370502095, \"phi\": 0.6332070787700438}, {\"truth_threshold\": -0.06407239135550513, \"match_probability\": 0.4888989252224639, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1318.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 713.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6489414081733137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35105859182668636, \"precision\": 1.0, \"recall\": 0.6489414081733137, \"specificity\": 1.0, \"npv\": 0.616254036598493, \"accuracy\": 0.7755037783375315, \"f1\": 0.7871006270528516, \"f2\": 0.6979453505613218, \"f0_5\": 0.9023688894974667, \"p4\": 0.7746415522808361, \"phi\": 0.6323865608176021}, {\"truth_threshold\": -0.029248622472753984, \"match_probability\": 0.4949317735429718, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1317.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 714.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6484490398818316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3515509601181684, \"precision\": 1.0, \"recall\": 0.6484490398818316, \"specificity\": 1.0, \"npv\": 0.615922538999462, \"accuracy\": 0.7751889168765743, \"f1\": 0.7867383512544803, \"f2\": 0.6974896727041627, \"f0_5\": 0.9021783806000822, \"p4\": 0.7743351244099922, \"phi\": 0.6319765652742048}, {\"truth_threshold\": -0.01623187762874232, \"match_probability\": 0.49718725961786664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1316.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 715.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6479566715903495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3520433284096504, \"precision\": 1.0, \"recall\": 0.6479566715903495, \"specificity\": 1.0, \"npv\": 0.6155913978494624, \"accuracy\": 0.7748740554156172, \"f1\": 0.7863758589781894, \"f2\": 0.6970338983050848, \"f0_5\": 0.9019876627827279, \"p4\": 0.774028672532505, \"phi\": 0.6315667448577293}, {\"truth_threshold\": -0.013116042790671146, \"match_probability\": 0.49772717863441557, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1315.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 716.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6474643032988675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35253569670113244, \"precision\": 1.0, \"recall\": 0.6474643032988675, \"specificity\": 1.0, \"npv\": 0.615260612573885, \"accuracy\": 0.77455919395466, \"f1\": 0.7860131500298865, \"f2\": 0.696578027333404, \"f0_5\": 0.9017967357015498, \"p4\": 0.7737221963859477, \"phi\": 0.6311570991974859}, {\"truth_threshold\": 0.01854934672791278, \"match_probability\": 0.5032143125657871, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1314.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 717.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6469719350073855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35302806499261447, \"precision\": 1.0, \"recall\": 0.6469719350073855, \"specificity\": 1.0, \"npv\": 0.6149301825993555, \"accuracy\": 0.7742443324937027, \"f1\": 0.7856502242152467, \"f2\": 0.6961220597584233, \"f0_5\": 0.901605599011939, \"p4\": 0.7734156957074743, \"phi\": 0.6307476279232052}, {\"truth_threshold\": 0.026645498089066976, \"match_probability\": 0.5046171817210149, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1311.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 720.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6454948301329394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35450516986706054, \"precision\": 1.0, \"recall\": 0.6454948301329394, \"specificity\": 1.0, \"npv\": 0.613941018766756, \"accuracy\": 0.7732997481108312, \"f1\": 0.7845601436265709, \"f2\": 0.6947535771065183, \"f0_5\": 0.9010309278350516, \"p4\": 0.7724960438457679, \"phi\": 0.6295202567197429}, {\"truth_threshold\": 0.036631867775282656, \"match_probability\": 0.5063474779432482, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1309.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 722.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6445100935499753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3554899064500246, \"precision\": 1.0, \"recall\": 0.6445100935499753, \"specificity\": 1.0, \"npv\": 0.6132833422603107, \"accuracy\": 0.7726700251889169, \"f1\": 0.7838323353293413, \"f2\": 0.6938407717587194, \"f0_5\": 0.9006467593229668, \"p4\": 0.7718828151071816, \"phi\": 0.6287028744111437}, {\"truth_threshold\": 0.0568811939799113, \"match_probability\": 0.5098554831529212, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1305.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 726.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6425406203840472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35745937961595275, \"precision\": 1.0, \"recall\": 0.6425406203840472, \"specificity\": 1.0, \"npv\": 0.6119722073757349, \"accuracy\": 0.7714105793450882, \"f1\": 0.7823741007194245, \"f2\": 0.6920139993636653, \"f0_5\": 0.8998758791890774, \"p4\": 0.7706560420857187, \"phi\": 0.6270701729352143}, {\"truth_threshold\": 0.08160480589530164, \"match_probability\": 0.514137266131592, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1304.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 727.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6420482520925652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3579517479074348, \"precision\": 1.0, \"recall\": 0.6420482520925652, \"specificity\": 1.0, \"npv\": 0.6116452991452992, \"accuracy\": 0.771095717884131, \"f1\": 0.7820089955022489, \"f2\": 0.6915570640644888, \"f0_5\": 0.8996826272940527, \"p4\": 0.7703492815381601, \"phi\": 0.6266624252473364}, {\"truth_threshold\": 0.08942864287053309, \"match_probability\": 0.5154918427277512, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1301.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 730.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6405711472181191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35942885278188086, \"precision\": 1.0, \"recall\": 0.6405711472181191, \"specificity\": 1.0, \"npv\": 0.6106666666666667, \"accuracy\": 0.7701511335012594, \"f1\": 0.7809123649459784, \"f2\": 0.6901856763925729, \"f0_5\": 0.899101589495508, \"p4\": 0.7694288341149976, \"phi\": 0.6254402027648458}, {\"truth_threshold\": 0.09773738557738462, \"match_probability\": 0.5169301236363298, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1300.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 731.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6400787789266371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3599212210733629, \"precision\": 1.0, \"recall\": 0.6400787789266371, \"specificity\": 1.0, \"npv\": 0.6103411513859275, \"accuracy\": 0.7698362720403022, \"f1\": 0.7805463824677275, \"f2\": 0.6897283531409168, \"f0_5\": 0.8989074816761167, \"p4\": 0.7691219621523272, \"phi\": 0.6250331342479231}, {\"truth_threshold\": 0.11148844584656128, \"match_probability\": 0.5193098667577485, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1299.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 732.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6395864106351551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3604135893648449, \"precision\": 1.0, \"recall\": 0.6395864106351551, \"specificity\": 1.0, \"npv\": 0.6100159829515184, \"accuracy\": 0.7695214105793451, \"f1\": 0.7801801801801802, \"f2\": 0.6892709328239415, \"f0_5\": 0.8987131589871316, \"p4\": 0.7688150616636867, \"phi\": 0.6246262346123782}, {\"truth_threshold\": 0.12421445614056736, \"match_probability\": 0.5215114379284997, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1298.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 733.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6390940423436731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36090595765632694, \"precision\": 1.0, \"recall\": 0.6390940423436731, \"specificity\": 1.0, \"npv\": 0.6096911608093717, \"accuracy\": 0.7692065491183879, \"f1\": 0.7798137578852509, \"f2\": 0.6888134154107408, \"f0_5\": 0.8985186210715769, \"p4\": 0.7685081323793148, \"phi\": 0.6242195034944581}, {\"truth_threshold\": 0.13225904695029, \"match_probability\": 0.5229027085121777, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1297.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 734.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.638601674052191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36139832594780896, \"precision\": 1.0, \"recall\": 0.638601674052191, \"specificity\": 1.0, \"npv\": 0.6093666844065992, \"accuracy\": 0.7688916876574308, \"f1\": 0.7794471153846154, \"f2\": 0.6883558008703959, \"f0_5\": 0.8983238675716858, \"p4\": 0.7682011740290052, \"phi\": 0.6238129405308033}, {\"truth_threshold\": 0.1491580539112364, \"match_probability\": 0.5258241220073325, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1292.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 739.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6361398325947809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3638601674052191, \"precision\": 1.0, \"recall\": 0.6361398325947809, \"specificity\": 1.0, \"npv\": 0.6077494692144374, \"accuracy\": 0.7673173803526449, \"f1\": 0.7776105928377972, \"f2\": 0.6860662701784197, \"f0_5\": 0.8973468537296847, \"p4\": 0.766665936799838, \"phi\": 0.6217826353362074}, {\"truth_threshold\": 0.169980215566397, \"match_probability\": 0.5294212994669113, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1291.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 740.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6356474643032989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3643525356967011, \"precision\": 1.0, \"recall\": 0.6356474643032989, \"specificity\": 1.0, \"npv\": 0.6074270557029178, \"accuracy\": 0.7670025188916877, \"f1\": 0.7772426249247442, \"f2\": 0.6856080722251726, \"f0_5\": 0.8971507991660875, \"p4\": 0.7663587983544642, \"phi\": 0.6213770736893809}, {\"truth_threshold\": 0.17471091903305866, \"match_probability\": 0.5302381499637207, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1290.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 741.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6351550960118169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36484490398818314, \"precision\": 1.0, \"recall\": 0.6351550960118169, \"specificity\": 1.0, \"npv\": 0.6071049840933191, \"accuracy\": 0.7666876574307305, \"f1\": 0.7768744354110207, \"f2\": 0.6851497769279796, \"f0_5\": 0.8969545264914477, \"p4\": 0.7660516289391232, \"phi\": 0.6209716776641626}, {\"truth_threshold\": 0.17713530490988597, \"match_probability\": 0.5306567061375795, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1287.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 744.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6336779911373708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3663220088626292, \"precision\": 1.0, \"recall\": 0.6336779911373708, \"specificity\": 1.0, \"npv\": 0.606140815246162, \"accuracy\": 0.7657430730478589, \"f1\": 0.7757685352622061, \"f2\": 0.6837743066624163, \"f0_5\": 0.8963643961554534, \"p4\": 0.7651299321327936, \"phi\": 0.6197564797172807}, {\"truth_threshold\": 0.1818931943724751, \"match_probability\": 0.531478002280116, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1286.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 745.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6331856228458888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36681437715411125, \"precision\": 1.0, \"recall\": 0.6331856228458888, \"specificity\": 1.0, \"npv\": 0.6058201058201058, \"accuracy\": 0.7654282115869018, \"f1\": 0.7753994573409707, \"f2\": 0.6833156216790648, \"f0_5\": 0.8961672473867596, \"p4\": 0.7648226360947802, \"phi\": 0.6193517425795022}, {\"truth_threshold\": 0.18743902111733518, \"match_probability\": 0.532435094875622, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1285.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 746.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6326932545544067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36730674544559333, \"precision\": 1.0, \"recall\": 0.6326932545544067, \"specificity\": 1.0, \"npv\": 0.6054997355896351, \"accuracy\": 0.7651133501259446, \"f1\": 0.7750301568154403, \"f2\": 0.682856839196514, \"f0_5\": 0.8959698786780086, \"p4\": 0.7645153077130921, \"phi\": 0.6189471692657128}, {\"truth_threshold\": 0.2142457228534624, \"match_probability\": 0.5370578754078176, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1284.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 747.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6322008862629247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36779911373707536, \"precision\": 1.0, \"recall\": 0.6322008862629247, \"specificity\": 1.0, \"npv\": 0.6051797040169133, \"accuracy\": 0.7647984886649875, \"f1\": 0.7746606334841629, \"f2\": 0.6823979591836735, \"f0_5\": 0.895772289660946, \"p4\": 0.7642079467115986, \"phi\": 0.6185427594175095}, {\"truth_threshold\": 0.2150385441592731, \"match_probability\": 0.5371945034069684, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1278.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 753.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6292466765140325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3707533234859675, \"precision\": 1.0, \"recall\": 0.6292466765140325, \"specificity\": 1.0, \"npv\": 0.6032665964172813, \"accuracy\": 0.7629093198992444, \"f1\": 0.772438803263826, \"f2\": 0.6796426292278238, \"f0_5\": 0.8945821083578328, \"p4\": 0.7623630801644073, \"phi\": 0.6161197130813998}, {\"truth_threshold\": 0.21710199470778435, \"match_probability\": 0.537550074476238, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1274.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 757.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6272772033481043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3727227966518956, \"precision\": 1.0, \"recall\": 0.6272772033481043, \"specificity\": 1.0, \"npv\": 0.6019978969505784, \"accuracy\": 0.7616498740554156, \"f1\": 0.7709531013615734, \"f2\": 0.6778037880400085, \"f0_5\": 0.8937842009260558, \"p4\": 0.7611324815228807, \"phi\": 0.6145075729562648}, {\"truth_threshold\": 0.22234187421461676, \"match_probability\": 0.5384528311303426, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1273.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 758.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6267848350566223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37321516494337764, \"precision\": 1.0, \"recall\": 0.6267848350566223, \"specificity\": 1.0, \"npv\": 0.6016815554387809, \"accuracy\": 0.7613350125944585, \"f1\": 0.7705811138014528, \"f2\": 0.6773438331382357, \"f0_5\": 0.8935841639758528, \"p4\": 0.760824743344281, \"phi\": 0.614104937679472}, {\"truth_threshold\": 0.2739055633821705, \"match_probability\": 0.5473221561584803, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1270.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 761.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6253077301821762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3746922698178237, \"precision\": 1.0, \"recall\": 0.6253077301821762, \"specificity\": 1.0, \"npv\": 0.6007345225603358, \"accuracy\": 0.7603904282115869, \"f1\": 0.7694637988488336, \"f2\": 0.6759633808814137, \"f0_5\": 0.8929827028547321, \"p4\": 0.7599013118572745, \"phi\": 0.6128979855932608}, {\"truth_threshold\": 0.2898951222305515, \"match_probability\": 0.5500666486667863, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1269.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 762.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6248153618906942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37518463810930575, \"precision\": 1.0, \"recall\": 0.6248153618906942, \"specificity\": 1.0, \"npv\": 0.600419507079182, \"accuracy\": 0.7600755667506297, \"f1\": 0.769090909090909, \"f2\": 0.6755030341743852, \"f0_5\": 0.8927817644575771, \"p4\": 0.7595934281018281, \"phi\": 0.6124959849679925}, {\"truth_threshold\": 0.2932352201392096, \"match_probability\": 0.5506395734740641, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1268.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 763.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6243229935992122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37567700640078777, \"precision\": 1.0, \"recall\": 0.6243229935992122, \"specificity\": 1.0, \"npv\": 0.600104821802935, \"accuracy\": 0.7597607052896725, \"f1\": 0.7687177932706881, \"f2\": 0.6750425894378195, \"f0_5\": 0.892580599746586, \"p4\": 0.7592855072439135, \"phi\": 0.6120941421230318}, {\"truth_threshold\": 0.3154479873523736, \"match_probability\": 0.5544462267086544, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1267.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 764.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6238306253077301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3761693746922698, \"precision\": 1.0, \"recall\": 0.6238306253077301, \"specificity\": 1.0, \"npv\": 0.5997904662126768, \"accuracy\": 0.7594458438287154, \"f1\": 0.7683444511825349, \"f2\": 0.6745820466404003, \"f0_5\": 0.8923792083392027, \"p4\": 0.7589775489992451, \"phi\": 0.6116924567060388}, {\"truth_threshold\": 0.3208960172947628, \"match_probability\": 0.5553789110924033, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1262.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 769.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.62136878385032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37863121614968, \"precision\": 1.0, \"recall\": 0.62136878385032, \"specificity\": 1.0, \"npv\": 0.5982236154649948, \"accuracy\": 0.7578715365239295, \"f1\": 0.7664743395080473, \"f2\": 0.6722778606435116, \"f0_5\": 0.8913688374064134, \"p4\": 0.7574371869898648, \"phi\": 0.6096863787325622}, {\"truth_threshold\": 0.3218363981932679, \"match_probability\": 0.555539861844595, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1261.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 770.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.620876415558838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.379123584441162, \"precision\": 1.0, \"recall\": 0.620876415558838, \"specificity\": 1.0, \"npv\": 0.597911227154047, \"accuracy\": 0.7575566750629723, \"f1\": 0.7660996354799514, \"f2\": 0.6718167288225892, \"f0_5\": 0.8911660777385159, \"p4\": 0.7571289984268484, \"phi\": 0.6092856305032893}, {\"truth_threshold\": 0.32795542307583986, \"match_probability\": 0.556586876546181, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1260.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 771.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.620384047267356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37961595273264404, \"precision\": 1.0, \"recall\": 0.620384047267356, \"specificity\": 1.0, \"npv\": 0.5975991649269311, \"accuracy\": 0.7572418136020151, \"f1\": 0.7657247037374658, \"f2\": 0.6713554987212276, \"f0_5\": 0.8909630886720408, \"p4\": 0.756820770473131, \"phi\": 0.6088850372450958}, {\"truth_threshold\": 0.39550867109177457, \"match_probability\": 0.5681103887750473, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1257.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 774.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6189069423929099, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3810930576070901, \"precision\": 1.0, \"recall\": 0.6189069423929099, \"specificity\": 1.0, \"npv\": 0.5966649296508598, \"accuracy\": 0.7562972292191436, \"f1\": 0.7645985401459854, \"f2\": 0.669971218420211, \"f0_5\": 0.8903527411814705, \"p4\": 0.7558958473823194, \"phi\": 0.6076841838021575}, {\"truth_threshold\": 0.416330832746935, \"match_probability\": 0.5716481011395127, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1254.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 777.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6174298375184638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3825701624815362, \"precision\": 1.0, \"recall\": 0.6174298375184638, \"specificity\": 1.0, \"npv\": 0.5957336108220603, \"accuracy\": 0.7553526448362721, \"f1\": 0.7634703196347032, \"f2\": 0.6685860524632118, \"f0_5\": 0.8897403150276714, \"p4\": 0.7549705593661282, \"phi\": 0.6064847125312826}, {\"truth_threshold\": 0.42106153621359665, \"match_probability\": 0.5724508473034705, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1252.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 779.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6164451009354998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38355489906450024, \"precision\": 1.0, \"recall\": 0.6164451009354998, \"specificity\": 1.0, \"npv\": 0.5951143451143451, \"accuracy\": 0.7547229219143576, \"f1\": 0.7627170271093512, \"f2\": 0.6676621160409556, \"f0_5\": 0.8893308708623384, \"p4\": 0.7543534940760434, \"phi\": 0.605685828249412}, {\"truth_threshold\": 0.5175327743188175, \"match_probability\": 0.5887320924609699, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1248.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 783.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6144756277695717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38552437223042835, \"precision\": 1.0, \"recall\": 0.6144756277695717, \"specificity\": 1.0, \"npv\": 0.5938796680497925, \"accuracy\": 0.753463476070529, \"f1\": 0.7612076852698993, \"f2\": 0.6658130601792573, \"f0_5\": 0.888509184109355, \"p4\": 0.7531188571035551, \"phi\": 0.6040898789455763}, {\"truth_threshold\": 0.5610047400343894, \"match_probability\": 0.5960079614330139, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1247.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 784.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6139832594780896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3860167405219104, \"precision\": 1.0, \"recall\": 0.6139832594780896, \"specificity\": 1.0, \"npv\": 0.5935717988595127, \"accuracy\": 0.7531486146095718, \"f1\": 0.760829774252593, \"f2\": 0.6653505495678156, \"f0_5\": 0.8883031770907537, \"p4\": 0.7528100906494462, \"phi\": 0.6036912686117273}, {\"truth_threshold\": 0.5803281328721631, \"match_probability\": 0.5992288011690642, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1246.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 785.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6134908911866076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3865091088133924, \"precision\": 1.0, \"recall\": 0.6134908911866076, \"specificity\": 1.0, \"npv\": 0.5932642487046632, \"accuracy\": 0.7528337531486146, \"f1\": 0.7604516325907843, \"f2\": 0.6648879402347919, \"f0_5\": 0.8880969351389879, \"p4\": 0.7525012807216611, \"phi\": 0.6032928083832734}, {\"truth_threshold\": 0.637963389549129, \"match_probability\": 0.6087837229873873, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1245.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 786.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6129985228951256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3870014771048744, \"precision\": 1.0, \"recall\": 0.6129985228951256, \"specificity\": 1.0, \"npv\": 0.5929570170895909, \"accuracy\": 0.7525188916876574, \"f1\": 0.76007326007326, \"f2\": 0.6644252321485751, \"f0_5\": 0.887890457851947, \"p4\": 0.7521924270246312, \"phi\": 0.6028944979150324}, {\"truth_threshold\": 0.6510875672987163, \"match_probability\": 0.6109481600087477, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1243.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 788.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6120137863121615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3879862136878385, \"precision\": 1.0, \"recall\": 0.6120137863121615, \"specificity\": 1.0, \"npv\": 0.5923435075012933, \"accuracy\": 0.7518891687657431, \"f1\": 0.7593158216249236, \"f2\": 0.6634995195900502, \"f0_5\": 0.8874767956590033, \"p4\": 0.7515745871378925, \"phi\": 0.6020983248799923}, {\"truth_threshold\": 0.6796485881153869, \"match_probability\": 0.6156432509998679, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1242.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 789.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6115214180206795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38847858197932056, \"precision\": 1.0, \"recall\": 0.6115214180206795, \"specificity\": 1.0, \"npv\": 0.5920372285418821, \"accuracy\": 0.7515743073047859, \"f1\": 0.7589367552703942, \"f2\": 0.6630365150544523, \"f0_5\": 0.8872696099442777, \"p4\": 0.7512656003543721, \"phi\": 0.6017004616243574}, {\"truth_threshold\": 0.7139101118479892, \"match_probability\": 0.6212470730273572, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1241.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 790.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6110290497291975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3889709502708026, \"precision\": 1.0, \"recall\": 0.6110290497291975, \"specificity\": 1.0, \"npv\": 0.5917312661498708, \"accuracy\": 0.7512594458438288, \"f1\": 0.758557457212714, \"f2\": 0.6625734116390817, \"f0_5\": 0.8870621872766261, \"p4\": 0.7509565686139796, \"phi\": 0.6013027467512604}, {\"truth_threshold\": 0.7206260252692525, \"match_probability\": 0.6223417980984107, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1239.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 792.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6100443131462334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38995568685376664, \"precision\": 1.0, \"recall\": 0.6100443131462334, \"specificity\": 1.0, \"npv\": 0.5911202891068663, \"accuracy\": 0.7506297229219143, \"f1\": 0.7577981651376147, \"f2\": 0.6616469080422941, \"f0_5\": 0.8866466294547016, \"p4\": 0.750338369069021, \"phi\": 0.6005077607783276}, {\"truth_threshold\": 0.7446418421467902, \"match_probability\": 0.6262462235868638, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1235.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 796.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6080748399803053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39192516001969474, \"precision\": 1.0, \"recall\": 0.6080748399803053, \"specificity\": 1.0, \"npv\": 0.5899021123132406, \"accuracy\": 0.7493702770780857, \"f1\": 0.7562767911818739, \"f2\": 0.659792712896677, \"f0_5\": 0.8858126524171568, \"p4\": 0.7491014173370169, \"phi\": 0.5989195543217117}, {\"truth_threshold\": 0.778700457868444, \"match_probability\": 0.6317551962626214, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1234.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 797.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6075824716888233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39241752831117677, \"precision\": 1.0, \"recall\": 0.6075824716888233, \"specificity\": 1.0, \"npv\": 0.5895983522142122, \"accuracy\": 0.7490554156171285, \"f1\": 0.755895865237366, \"f2\": 0.6593289164351357, \"f0_5\": 0.8856035596382948, \"p4\": 0.7487920625169007, \"phi\": 0.5985228685204671}, {\"truth_threshold\": 0.8054689730267467, \"match_probability\": 0.6360610805962966, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1233.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 798.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6070901033973413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3929098966026588, \"precision\": 1.0, \"recall\": 0.6070901033973413, \"specificity\": 1.0, \"npv\": 0.5892949047864128, \"accuracy\": 0.7487405541561712, \"f1\": 0.7555147058823529, \"f2\": 0.6588650208400129, \"f0_5\": 0.8853942266264541, \"p4\": 0.7484826603385862, \"phi\": 0.5981263283607483}, {\"truth_threshold\": 0.8195236607092122, \"match_probability\": 0.6383132200402312, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1230.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 801.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6056129985228951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39438700147710487, \"precision\": 1.0, \"recall\": 0.6056129985228951, \"specificity\": 1.0, \"npv\": 0.5883864337101747, \"accuracy\": 0.7477959697732998, \"f1\": 0.7543698252069917, \"f2\": 0.6574727389352149, \"f0_5\": 0.8847647820457488, \"p4\": 0.7475541666251978, \"phi\": 0.5969375783190497}, {\"truth_threshold\": 0.8451534591878181, \"match_probability\": 0.6424045066882677, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1229.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 802.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.605120630231413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3948793697685869, \"precision\": 1.0, \"recall\": 0.605120630231413, \"specificity\": 1.0, \"npv\": 0.5880842321520288, \"accuracy\": 0.7474811083123426, \"f1\": 0.7539877300613497, \"f2\": 0.6570084464877579, \"f0_5\": 0.8845544839499064, \"p4\": 0.747244571982039, \"phi\": 0.5965416173151645}, {\"truth_threshold\": 0.8753449642409366, \"match_probability\": 0.647197454633228, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1228.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 803.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.604628261939931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3953717380600689, \"precision\": 1.0, \"recall\": 0.604628261939931, \"specificity\": 1.0, \"npv\": 0.587782340862423, \"accuracy\": 0.7471662468513854, \"f1\": 0.7536054004295796, \"f2\": 0.6565440547476475, \"f0_5\": 0.8843439435402564, \"p4\": 0.7469349284618538, \"phi\": 0.5961458002490926}, {\"truth_threshold\": 0.884314006729667, \"match_probability\": 0.6486156674671224, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1227.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 804.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.604135893648449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39586410635155095, \"precision\": 1.0, \"recall\": 0.604135893648449, \"specificity\": 1.0, \"npv\": 0.5874807593637763, \"accuracy\": 0.7468513853904282, \"f1\": 0.7532228360957642, \"f2\": 0.6560795636830286, \"f0_5\": 0.8841331603977518, \"p4\": 0.7466252357591884, \"phi\": 0.5957501267809385}, {\"truth_threshold\": 0.9163224013948023, \"match_probability\": 0.6536554500134303, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1223.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 808.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6021664204825209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39783357951747905, \"precision\": 1.0, \"recall\": 0.6021664204825209, \"specificity\": 1.0, \"npv\": 0.5862775217613927, \"accuracy\": 0.7455919395465995, \"f1\": 0.7516902274124155, \"f2\": 0.6542206055418851, \"f0_5\": 0.8832875920843565, \"p4\": 0.7453859669947532, \"phi\": 0.5941688620993372}, {\"truth_threshold\": 0.9454121768475393, \"match_probability\": 0.658206011026527, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1212.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 819.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5967503692762186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4032496307237814, \"precision\": 1.0, \"recall\": 0.5967503692762186, \"specificity\": 1.0, \"npv\": 0.5829938900203666, \"accuracy\": 0.7421284634760705, \"f1\": 0.7474560592044404, \"f2\": 0.6491002570694088, \"f0_5\": 0.8809419973833406, \"p4\": 0.741973733860351, \"phi\": 0.5898320262205444}, {\"truth_threshold\": 0.9475547108878014, \"match_probability\": 0.6585400347792858, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1211.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 820.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5962580009847366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4037419990152634, \"precision\": 1.0, \"recall\": 0.5962580009847366, \"specificity\": 1.0, \"npv\": 0.5826972010178118, \"accuracy\": 0.7418136020151134, \"f1\": 0.7470697100555213, \"f2\": 0.648634172469202, \"f0_5\": 0.8807272727272727, \"p4\": 0.7416632122273779, \"phi\": 0.589438604316244}, {\"truth_threshold\": 0.9838756494107368, \"match_probability\": 0.6641783801264525, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1209.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 822.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5952732644017725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40472673559822747, \"precision\": 1.0, \"recall\": 0.5952732644017725, \"specificity\": 1.0, \"npv\": 0.5821047280122014, \"accuracy\": 0.7411838790931989, \"f1\": 0.7462962962962963, \"f2\": 0.6477017036322725, \"f0_5\": 0.8802970729576234, \"p4\": 0.7410420052546717, \"phi\": 0.5886521737558853}, {\"truth_threshold\": 0.9858905275071334, \"match_probability\": 0.6644898155320145, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1198.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 833.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5898572131954702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4101427868045298, \"precision\": 1.0, \"recall\": 0.5898572131954702, \"specificity\": 1.0, \"npv\": 0.5788675429726997, \"accuracy\": 0.7377204030226701, \"f1\": 0.7420253948590895, \"f2\": 0.6425659729671744, \"f0_5\": 0.8779129415213249, \"p4\": 0.7376213591906712, \"phi\": 0.5843365431899546}, {\"truth_threshold\": 1.1238188532315296, \"match_probability\": 0.685458486002875, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1197.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 834.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5893648449039882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41063515509601184, \"precision\": 1.0, \"recall\": 0.5893648449039882, \"specificity\": 1.0, \"npv\": 0.5785750378979283, \"accuracy\": 0.7374055415617129, \"f1\": 0.741635687732342, \"f2\": 0.6420984872867718, \"f0_5\": 0.8776946766388033, \"p4\": 0.737310046092469, \"phi\": 0.5839450209360738}, {\"truth_threshold\": 1.1411085529730889, \"match_probability\": 0.6880366032731672, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1195.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 836.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5883801083210242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4116198916789759, \"precision\": 1.0, \"recall\": 0.5883801083210242, \"specificity\": 1.0, \"npv\": 0.5779909136799596, \"accuracy\": 0.7367758186397985, \"f1\": 0.7408555486670799, \"f2\": 0.6411632149372251, \"f0_5\": 0.8772573777712523, \"p4\": 0.7366872427429624, \"phi\": 0.5831623756721471}, {\"truth_threshold\": 1.1442242905285855, \"match_probability\": 0.6884999701818811, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1189.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 842.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.585425898572132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41457410142786805, \"precision\": 1.0, \"recall\": 0.585425898572132, \"specificity\": 1.0, \"npv\": 0.5762455963764469, \"accuracy\": 0.7348866498740554, \"f1\": 0.7385093167701864, \"f2\": 0.6383549876516698, \"f0_5\": 0.8759392957123914, \"p4\": 0.7348173920177556, \"phi\": 0.5808176099748659}, {\"truth_threshold\": 1.1939053280683396, \"match_probability\": 0.6958370881351029, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1185.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 846.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5834564254062038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41654357459379615, \"precision\": 1.0, \"recall\": 0.5834564254062038, \"specificity\": 1.0, \"npv\": 0.5750878955298845, \"accuracy\": 0.7336272040302267, \"f1\": 0.7369402985074627, \"f2\": 0.6364808250080567, \"f0_5\": 0.8750553832521045, \"p4\": 0.7335695980796055, \"phi\": 0.5792570481403251}, {\"truth_threshold\": 1.2499183630431225, \"match_probability\": 0.7039913493733274, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1184.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 847.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5829640571147218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4170359428852782, \"precision\": 1.0, \"recall\": 0.5829640571147218, \"specificity\": 1.0, \"npv\": 0.5747991967871486, \"accuracy\": 0.7333123425692695, \"f1\": 0.736547433903577, \"f2\": 0.6360120326600773, \"f0_5\": 0.8748337520319196, \"p4\": 0.7332574932224606, \"phi\": 0.5788672315698303}, {\"truth_threshold\": 1.2849613588479007, \"match_probability\": 0.709027869537389, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1183.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 848.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5824716888232397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4175283111767602, \"precision\": 1.0, \"recall\": 0.5824716888232397, \"specificity\": 1.0, \"npv\": 0.57451078775715, \"accuracy\": 0.7329974811083123, \"f1\": 0.7361543248288737, \"f2\": 0.6355431395723649, \"f0_5\": 0.8746118586426143, \"p4\": 0.732945325152551, \"phi\": 0.578477543896111}, {\"truth_threshold\": 1.3195152293570795, \"match_probability\": 0.7139442713968626, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1176.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 855.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5790251107828656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42097488921713444, \"precision\": 1.0, \"recall\": 0.5790251107828656, \"specificity\": 1.0, \"npv\": 0.5725, \"accuracy\": 0.7307934508816121, \"f1\": 0.7333956969130028, \"f2\": 0.632258064516129, \"f0_5\": 0.8730512249443207, \"p4\": 0.7307583506489014, \"phi\": 0.5757533116910319}, {\"truth_threshold\": 1.3690104421068723, \"match_probability\": 0.7208990819562511, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1174.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 857.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5780403741999015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4219596258000985, \"precision\": 1.0, \"recall\": 0.5780403741999015, \"specificity\": 1.0, \"npv\": 0.5719280719280719, \"accuracy\": 0.7301637279596978, \"f1\": 0.7326053042121685, \"f2\": 0.6313185631318563, \"f0_5\": 0.8726029433625687, \"p4\": 0.7301329127821058, \"phi\": 0.5749761009926682}, {\"truth_threshold\": 1.3905749077091238, \"match_probability\": 0.7238965890807606, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1172.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 859.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5770556376169375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42294436238306254, \"precision\": 1.0, \"recall\": 0.5770556376169375, \"specificity\": 1.0, \"npv\": 0.5713572854291418, \"accuracy\": 0.7295340050377834, \"f1\": 0.731813924445832, \"f2\": 0.6303786574870912, \"f0_5\": 0.8721535942848638, \"p4\": 0.7295072086227041, \"phi\": 0.5741993927638691}, {\"truth_threshold\": 1.4182849479669015, \"match_probability\": 0.7277189701801084, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1170.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 861.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5760709010339734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4239290989660266, \"precision\": 1.0, \"recall\": 0.5760709010339734, \"specificity\": 1.0, \"npv\": 0.5707876370887338, \"accuracy\": 0.728904282115869, \"f1\": 0.7310215557638238, \"f2\": 0.6294383473208521, \"f0_5\": 0.8717031738936075, \"p4\": 0.7288812354500215, \"phi\": 0.5734231843906902}, {\"truth_threshold\": 1.4249045626686934, \"match_probability\": 0.7286271774066675, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1169.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 862.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5755785327424914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4244214672575086, \"precision\": 1.0, \"recall\": 0.5755785327424914, \"specificity\": 1.0, \"npv\": 0.5705032386646737, \"accuracy\": 0.7285894206549118, \"f1\": 0.730625, \"f2\": 0.6289680404605618, \"f0_5\": 0.8714775607574177, \"p4\": 0.728568147130481, \"phi\": 0.5730352668339465}, {\"truth_threshold\": 1.4301159599089743, \"match_probability\": 0.729340839067893, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1168.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 863.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5750861644510094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42491383554899065, \"precision\": 1.0, \"recall\": 0.5750861644510094, \"specificity\": 1.0, \"npv\": 0.5702191235059761, \"accuracy\": 0.7282745591939547, \"f1\": 0.7302281963113473, \"f2\": 0.6284976323719328, \"f0_5\": 0.8712516783529762, \"p4\": 0.7282549905323747, \"phi\": 0.5726474732622752}, {\"truth_threshold\": 1.4540741557530643, \"match_probability\": 0.7326065068153376, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1167.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 864.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5745937961595273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4254062038404727, \"precision\": 1.0, \"recall\": 0.5745937961595273, \"specificity\": 1.0, \"npv\": 0.5699352911896466, \"accuracy\": 0.7279596977329975, \"f1\": 0.7298311444652908, \"f2\": 0.6280271230222796, \"f0_5\": 0.8710255261979399, \"p4\": 0.7279417653125098, \"phi\": 0.5722598033497938}, {\"truth_threshold\": 1.5001225473702606, \"match_probability\": 0.7388125167692862, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1165.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 866.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5736090595765633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4263909404234367, \"precision\": 1.0, \"recall\": 0.5736090595765633, \"specificity\": 1.0, \"npv\": 0.5693684733963202, \"accuracy\": 0.7273299748110831, \"f1\": 0.7290362953692116, \"f2\": 0.627085800409086, \"f0_5\": 0.8705724107009416, \"p4\": 0.7273151076312403, \"phi\": 0.571484833199803}, {\"truth_threshold\": 1.508954689120377, \"match_probability\": 0.739992137145523, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1164.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 867.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5731166912850812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42688330871491875, \"precision\": 1.0, \"recall\": 0.5731166912850812, \"specificity\": 1.0, \"npv\": 0.5690854870775348, \"accuracy\": 0.7270151133501259, \"f1\": 0.7286384976525822, \"f2\": 0.6266149870801033, \"f0_5\": 0.8703454463885151, \"p4\": 0.7270016744799519, \"phi\": 0.571097532311457}, {\"truth_threshold\": 1.5097475104261877, \"match_probability\": 0.7400978571264175, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1163.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 868.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5726243229935992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4273756770064008, \"precision\": 1.0, \"recall\": 0.5726243229935992, \"specificity\": 1.0, \"npv\": 0.568802781917536, \"accuracy\": 0.7267002518891688, \"f1\": 0.728240450845335, \"f2\": 0.6261440723592118, \"f0_5\": 0.8701182103845578, \"p4\": 0.7266881713271315, \"phi\": 0.570710353780624}, {\"truth_threshold\": 1.546624297185052, \"match_probability\": 0.7449843453180761, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1162.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 869.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5721319547021172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4278680452978828, \"precision\": 1.0, \"recall\": 0.5721319547021172, \"specificity\": 1.0, \"npv\": 0.5685203574975174, \"accuracy\": 0.7263853904282116, \"f1\": 0.7278421547134356, \"f2\": 0.625673056213655, \"f0_5\": 0.8698907022009282, \"p4\": 0.7263745978260736, \"phi\": 0.5703232972823407}, {\"truth_threshold\": 1.5474171184908625, \"match_probability\": 0.7450887346903718, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1161.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 870.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5716395864106352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42836041358936483, \"precision\": 1.0, \"recall\": 0.5716395864106352, \"specificity\": 1.0, \"npv\": 0.5682382133995038, \"accuracy\": 0.7260705289672544, \"f1\": 0.7274436090225563, \"f2\": 0.6252019386106623, \"f0_5\": 0.8696629213483146, \"p4\": 0.7260609536293626, \"phi\": 0.5699363624918229}, {\"truth_threshold\": 1.5609893596695765, \"match_probability\": 0.7468714034968195, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1160.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 871.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5711472181191531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42885278188084686, \"precision\": 1.0, \"recall\": 0.5711472181191531, \"specificity\": 1.0, \"npv\": 0.5679563492063492, \"accuracy\": 0.7257556675062973, \"f1\": 0.7270448135380758, \"f2\": 0.6247307195174494, \"f0_5\": 0.8694348673362314, \"p4\": 0.7257472383888707, \"phi\": 0.5695495490844643}, {\"truth_threshold\": 1.5708530282282895, \"match_probability\": 0.748161781281949, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1158.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 873.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5701624815361891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4298375184638109, \"precision\": 1.0, \"recall\": 0.5701624815361891, \"specificity\": 1.0, \"npv\": 0.5673934588701685, \"accuracy\": 0.7251259445843828, \"f1\": 0.7262464722483537, \"f2\": 0.6237879767291532, \"f0_5\": 0.8689779378658262, \"p4\": 0.7251195933804556, \"phi\": 0.5687762851216785}, {\"truth_threshold\": 1.5793594376462907, \"match_probability\": 0.7492710905587684, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1157.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 874.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5696701132447071, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43032988675529293, \"precision\": 1.0, \"recall\": 0.5696701132447071, \"specificity\": 1.0, \"npv\": 0.5671124318969787, \"accuracy\": 0.7248110831234257, \"f1\": 0.7258469259723965, \"f2\": 0.6233164529684301, \"f0_5\": 0.8687490614206337, \"p4\": 0.7248056629126928, \"phi\": 0.5683898339179133}, {\"truth_threshold\": 1.6062841377137598, \"match_probability\": 0.7527608178008853, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1155.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 876.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.568685376661743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43131462333825704, \"precision\": 1.0, \"recall\": 0.568685376661743, \"specificity\": 1.0, \"npv\": 0.5665512122711529, \"accuracy\": 0.7241813602015114, \"f1\": 0.7250470809792844, \"f2\": 0.6223731005496282, \"f0_5\": 0.8682904826341904, \"p4\": 0.7241775842950429, \"phi\": 0.5676172914460832}, {\"truth_threshold\": 1.6198081174884325, \"match_probability\": 0.7545013148902534, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1154.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 877.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.568193008370261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43180699162973907, \"precision\": 1.0, \"recall\": 0.568193008370261, \"specificity\": 1.0, \"npv\": 0.566271018793274, \"accuracy\": 0.7238664987405542, \"f1\": 0.7246467817896389, \"f2\": 0.6219012718258246, \"f0_5\": 0.8680607792989319, \"p4\": 0.7238634354409746, \"phi\": 0.5672311995307053}, {\"truth_threshold\": 1.687361365504367, \"match_probability\": 0.7630708572793372, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1153.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 878.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.567700640078779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4322993599212211, \"precision\": 1.0, \"recall\": 0.567700640078779, \"specificity\": 1.0, \"npv\": 0.5659911023232822, \"accuracy\": 0.7235516372795969, \"f1\": 0.7242462311557789, \"f2\": 0.6214293413819123, \"f0_5\": 0.8678307993376486, \"p4\": 0.7235492130860749, \"phi\": 0.5668452267310902}, {\"truth_threshold\": 1.6881541868101777, \"match_probability\": 0.7631701966335923, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1152.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 879.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5672082717872969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4327917282127031, \"precision\": 1.0, \"recall\": 0.5672082717872969, \"specificity\": 1.0, \"npv\": 0.5657114624505929, \"accuracy\": 0.7232367758186398, \"f1\": 0.7238454288407163, \"f2\": 0.6209573091849935, \"f0_5\": 0.8676005422503389, \"p4\": 0.7232349168764273, \"phi\": 0.5664593727239978}, {\"truth_threshold\": 1.7088319559006644, \"match_probability\": 0.7657509377255275, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1151.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 880.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5667159034958149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43328409650418515, \"precision\": 1.0, \"recall\": 0.5667159034958149, \"specificity\": 1.0, \"npv\": 0.5654320987654321, \"accuracy\": 0.7229219143576826, \"f1\": 0.7234443746071653, \"f2\": 0.6204851752021563, \"f0_5\": 0.8673700075357951, \"p4\": 0.7229205464573797, \"phi\": 0.5660736371863528}, {\"truth_threshold\": 1.7254216663496555, \"match_probability\": 0.7678073006161239, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1150.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 881.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5662235352043329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43377646479566717, \"precision\": 1.0, \"recall\": 0.5662235352043329, \"specificity\": 1.0, \"npv\": 0.5651530108588352, \"accuracy\": 0.7226070528967254, \"f1\": 0.7230430682175416, \"f2\": 0.6200129394004744, \"f0_5\": 0.8671391946916001, \"p4\": 0.722606101473543, \"phi\": 0.5656880197952422}, {\"truth_threshold\": 1.7262144876554661, \"match_probability\": 0.7679052581063435, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1148.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 883.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5652387986213688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4347612013786312, \"precision\": 1.0, \"recall\": 0.5652387986213688, \"specificity\": 1.0, \"npv\": 0.564595660749507, \"accuracy\": 0.7219773299748111, \"f1\": 0.7222396980182447, \"f2\": 0.6190681622088007, \"f0_5\": 0.8666767325985203, \"p4\": 0.7219769863862414, \"phi\": 0.5649171381617742}, {\"truth_threshold\": 1.7432839322686087, \"match_probability\": 0.7700072852185416, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1137.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 894.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5598227474150664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4401772525849335, \"precision\": 1.0, \"recall\": 0.5598227474150664, \"specificity\": 1.0, \"npv\": 0.5615497793035802, \"accuracy\": 0.7185138539042821, \"f1\": 0.7178030303030303, \"f2\": 0.6138645934564302, \"f0_5\": 0.8641130870953032, \"p4\": 0.7185113682272454, \"phi\": 0.5606855984061428}, {\"truth_threshold\": 1.7929749143655902, \"match_probability\": 0.7760502377991484, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1136.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 895.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5593303791235844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44066962087641554, \"precision\": 1.0, \"recall\": 0.5593303791235844, \"specificity\": 1.0, \"npv\": 0.5612745098039216, \"accuracy\": 0.718198992443325, \"f1\": 0.7173981686138301, \"f2\": 0.6133909287257019, \"f0_5\": 0.8638783269961977, \"p4\": 0.7181958416012424, \"phi\": 0.560301601247963}, {\"truth_threshold\": 1.7937677356714008, \"match_probability\": 0.7761457316323651, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1135.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 896.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5588380108321024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44116198916789756, \"precision\": 1.0, \"recall\": 0.5588380108321024, \"specificity\": 1.0, \"npv\": 0.560999510044096, \"accuracy\": 0.7178841309823678, \"f1\": 0.7169930511686671, \"f2\": 0.612917161680527, \"f0_5\": 0.8636432810835489, \"p4\": 0.717880234989325, \"phi\": 0.5599177174110734}, {\"truth_threshold\": 1.813797076020751, \"match_probability\": 0.7785486111374769, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1134.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 897.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5583456425406204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44165435745937964, \"precision\": 1.0, \"recall\": 0.5583456425406204, \"specificity\": 1.0, \"npv\": 0.5607247796278159, \"accuracy\": 0.7175692695214105, \"f1\": 0.7165876777251184, \"f2\": 0.6124432922877512, \"f0_5\": 0.8634079488350845, \"p4\": 0.7175645480239453, \"phi\": 0.5595339465749515}, {\"truth_threshold\": 1.8185277794874124, \"match_probability\": 0.7791134420350184, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1132.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 899.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5573609059576563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4426390940423437, \"precision\": 1.0, \"recall\": 0.5573609059576563, \"specificity\": 1.0, \"npv\": 0.5601761252446184, \"accuracy\": 0.7169395465994962, \"f1\": 0.7157761618716408, \"f2\": 0.611495246326707, \"f0_5\": 0.8629364232352493, \"p4\": 0.7169329315586919, \"phi\": 0.5587667426236015}, {\"truth_threshold\": 1.8209656039031745, \"match_probability\": 0.7794041071981349, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1130.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 901.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5563761693746923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44362383062530775, \"precision\": 1.0, \"recall\": 0.5563761693746923, \"specificity\": 1.0, \"npv\": 0.5596285434995112, \"accuracy\": 0.7163098236775819, \"f1\": 0.7149636191078772, \"f2\": 0.6105467905770477, \"f0_5\": 0.8624637459929781, \"p4\": 0.7163009892493953, \"phi\": 0.5579999868324339}, {\"truth_threshold\": 1.823945855583546, \"match_probability\": 0.7797590740237094, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1129.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 902.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5558838010832102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4441161989167898, \"precision\": 1.0, \"recall\": 0.5558838010832102, \"specificity\": 1.0, \"npv\": 0.5593551538837322, \"accuracy\": 0.7159949622166247, \"f1\": 0.7145569620253165, \"f2\": 0.6100724089484492, \"f0_5\": 0.8622269741866504, \"p4\": 0.7159848949759955, \"phi\": 0.557616776197034}, {\"truth_threshold\": 1.9959480692089187, \"match_probability\": 0.7995502478409868, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1128.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 903.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5553914327917282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4446085672082718, \"precision\": 1.0, \"recall\": 0.5553914327917282, \"specificity\": 1.0, \"npv\": 0.55908203125, \"accuracy\": 0.7156801007556675, \"f1\": 0.7141500474833808, \"f2\": 0.6095979247730221, \"f0_5\": 0.8619899128839982, \"p4\": 0.7156687181273125, \"phi\": 0.5572336766420773}, {\"truth_threshold\": 2.0150784606301304, \"match_probability\": 0.8016670127395735, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1127.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 904.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5548990645002462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4451009354997538, \"precision\": 1.0, \"recall\": 0.5548990645002462, \"specificity\": 1.0, \"npv\": 0.5588091752074182, \"accuracy\": 0.7153652392947103, \"f1\": 0.7137428752374921, \"f2\": 0.6091233380175116, \"f0_5\": 0.8617525615537543, \"p4\": 0.7153524583302613, \"phi\": 0.5568506878479639}, {\"truth_threshold\": 2.0358263229347506, \"match_probability\": 0.8039436837467253, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1126.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 905.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5544066962087641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44559330379123585, \"precision\": 1.0, \"recall\": 0.5544066962087641, \"specificity\": 1.0, \"npv\": 0.5585365853658537, \"accuracy\": 0.7150503778337531, \"f1\": 0.7133354450427621, \"f2\": 0.6086486486486486, \"f0_5\": 0.8615149196633511, \"p4\": 0.7150361152109546, \"phi\": 0.5564678094952189}, {\"truth_threshold\": 2.0433580252396224, \"match_probability\": 0.8047652366074675, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1125.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 906.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5539143279172821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4460856720827179, \"precision\": 1.0, \"recall\": 0.5539143279172821, \"specificity\": 1.0, \"npv\": 0.5582642613359337, \"accuracy\": 0.714735516372796, \"f1\": 0.7129277566539924, \"f2\": 0.6081738566331495, \"f0_5\": 0.861276986678916, \"p4\": 0.7147196883947, \"phi\": 0.5560850412644919}, {\"truth_threshold\": 2.047145084094834, \"match_probability\": 0.8051773401290918, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1124.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 907.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5534219596258001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4465780403741999, \"precision\": 1.0, \"recall\": 0.5534219596258001, \"specificity\": 1.0, \"npv\": 0.5579922027290448, \"accuracy\": 0.7144206549118388, \"f1\": 0.7125198098256735, \"f2\": 0.6076989619377162, \"f0_5\": 0.8610387620652673, \"p4\": 0.7144031775059975, \"phi\": 0.5557023828365546}, {\"truth_threshold\": 2.1155312141990508, \"match_probability\": 0.8125057018117979, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1123.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 908.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5529295913343181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44707040866568193, \"precision\": 1.0, \"recall\": 0.5529295913343181, \"specificity\": 1.0, \"npv\": 0.5577204091573308, \"accuracy\": 0.7141057934508817, \"f1\": 0.7121116043119848, \"f2\": 0.6072239645290365, \"f0_5\": 0.8608002452859114, \"p4\": 0.714086582168536, \"phi\": 0.5553198338922999}, {\"truth_threshold\": 2.118092268543068, \"match_probability\": 0.8127759842094026, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1122.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 909.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.552437223042836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44756277695716395, \"precision\": 1.0, \"recall\": 0.552437223042836, \"specificity\": 1.0, \"npv\": 0.5574488802336903, \"accuracy\": 0.7137909319899244, \"f1\": 0.7117031398667936, \"f2\": 0.6067488643737833, \"f0_5\": 0.8605614358030372, \"p4\": 0.7137699020051912, \"phi\": 0.5549373941127399}, {\"truth_threshold\": 2.1300411276056885, \"match_probability\": 0.8140330507092985, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1121.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 910.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.551944854751354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.448055145248646, \"precision\": 1.0, \"recall\": 0.551944854751354, \"specificity\": 1.0, \"npv\": 0.5571776155717761, \"accuracy\": 0.7134760705289672, \"f1\": 0.7112944162436549, \"f2\": 0.6062736614386155, \"f0_5\": 0.8603223330775134, \"p4\": 0.7134531366380221, \"phi\": 0.5545550631790046}, {\"truth_threshold\": 2.1485391792188344, \"match_probability\": 0.8159662568002977, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1115.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 916.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5489906450024619, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45100935499753814, \"precision\": 1.0, \"recall\": 0.5489906450024619, \"specificity\": 1.0, \"npv\": 0.5555555555555556, \"accuracy\": 0.7115869017632241, \"f1\": 0.7088366179275271, \"f2\": 0.6034202835804741, \"f0_5\": 0.8588815282699122, \"p4\": 0.7115507338864071, \"phi\": 0.5522633454966439}, {\"truth_threshold\": 2.166231417513063, \"match_probability\": 0.817800652094268, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1114.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 917.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5484982767109798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45150172328902016, \"precision\": 1.0, \"recall\": 0.5484982767109798, \"specificity\": 1.0, \"npv\": 0.555286129970902, \"accuracy\": 0.711272040302267, \"f1\": 0.7084260731319555, \"f2\": 0.6029443602511366, \"f0_5\": 0.8586403576383537, \"p4\": 0.7112333614409344, \"phi\": 0.5518817675648915}, {\"truth_threshold\": 2.1838260690887803, \"match_probability\": 0.8196108041484635, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1113.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 918.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5480059084194978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4519940915805022, \"precision\": 1.0, \"recall\": 0.5480059084194978, \"specificity\": 1.0, \"npv\": 0.5550169655841009, \"accuracy\": 0.7109571788413098, \"f1\": 0.7080152671755725, \"f2\": 0.6024683338746346, \"f0_5\": 0.8583988894030541, \"p4\": 0.7109159007383705, \"phi\": 0.5515002959320586}, {\"truth_threshold\": 2.216989903983028, \"match_probability\": 0.8229845340417229, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1112.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 919.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5475135401280158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45248645987198427, \"precision\": 1.0, \"recall\": 0.5475135401280158, \"specificity\": 1.0, \"npv\": 0.5547480620155039, \"accuracy\": 0.7106423173803527, \"f1\": 0.7076041998090996, \"f2\": 0.6019922044174968, \"f0_5\": 0.8581571230128107, \"p4\": 0.7105983513932957, \"phi\": 0.5511189302802658}, {\"truth_threshold\": 2.2303767786221935, \"match_probability\": 0.8243322699642311, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1111.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 920.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5470211718365338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4529788281634663, \"precision\": 1.0, \"recall\": 0.5470211718365338, \"specificity\": 1.0, \"npv\": 0.5544794188861986, \"accuracy\": 0.7103274559193955, \"f1\": 0.7071928707829408, \"f2\": 0.6015159718462372, \"f0_5\": 0.857915057915058, \"p4\": 0.7102807130194447, \"phi\": 0.5507376702917357}, {\"truth_threshold\": 2.248700975726392, \"match_probability\": 0.8261639664277827, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1110.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 921.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5465288035450517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4534711964549483, \"precision\": 1.0, \"recall\": 0.5465288035450517, \"specificity\": 1.0, \"npv\": 0.5542110358180058, \"accuracy\": 0.7100125944584383, \"f1\": 0.7067812798471824, \"f2\": 0.6010396361273554, \"f0_5\": 0.8576726935558646, \"p4\": 0.7099629852297031, \"phi\": 0.5503565156487915}, {\"truth_threshold\": 2.2614290778106683, \"match_probability\": 0.827427376804015, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1105.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 926.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5440669620876416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45593303791235845, \"precision\": 1.0, \"recall\": 0.5440669620876416, \"specificity\": 1.0, \"npv\": 0.5528730082085949, \"accuracy\": 0.7084382871536524, \"f1\": 0.704719387755102, \"f2\": 0.5986564091450861, \"f0_5\": 0.8564563633545187, \"p4\": 0.7083729914338502, \"phi\": 0.5484523115060287}, {\"truth_threshold\": 2.3137886446686178, \"match_probability\": 0.8325482705488699, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1104.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 927.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5435745937961596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4564254062038405, \"precision\": 1.0, \"recall\": 0.5435745937961596, \"specificity\": 1.0, \"npv\": 0.5526061776061776, \"accuracy\": 0.7081234256926953, \"f1\": 0.7043062200956938, \"f2\": 0.5981794538361509, \"f0_5\": 0.8562121917170777, \"p4\": 0.7080547189714588, \"phi\": 0.5480717822708321}, {\"truth_threshold\": 2.326945855602825, \"match_probability\": 0.8338158354992301, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1099.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 932.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5411127523387493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4588872476612506, \"precision\": 1.0, \"recall\": 0.5411127523387493, \"specificity\": 1.0, \"npv\": 0.5512758786711603, \"accuracy\": 0.7065491183879093, \"f1\": 0.7022364217252396, \"f2\": 0.5957931258809498, \"f0_5\": 0.8549867745448888, \"p4\": 0.7064619665204549, \"phi\": 0.5461706766256442}, {\"truth_threshold\": 2.3272530032875696, \"match_probability\": 0.8338453341137361, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1096.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 935.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5396356474643033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4603643525356967, \"precision\": 1.0, \"recall\": 0.5396356474643033, \"specificity\": 1.0, \"npv\": 0.5504807692307693, \"accuracy\": 0.7056045340050378, \"f1\": 0.7009913655260633, \"f2\": 0.5943600867678959, \"f0_5\": 0.8542478565861262, \"p4\": 0.7055051886749361, \"phi\": 0.5450312342613898}, {\"truth_threshold\": 2.3813418926845524, \"match_probability\": 0.8389748841756043, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1095.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 936.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5391432791728212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4608567208271787, \"precision\": 1.0, \"recall\": 0.5391432791728212, \"specificity\": 1.0, \"npv\": 0.5502162421912542, \"accuracy\": 0.7052896725440806, \"f1\": 0.7005758157389635, \"f2\": 0.5938821998047511, \"f0_5\": 0.8540009358914366, \"p4\": 0.7051860726067039, \"phi\": 0.5446516217447076}, {\"truth_threshold\": 2.388644179547185, \"match_probability\": 0.8396575081022343, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1094.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 937.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5386509108813392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46134908911866074, \"precision\": 1.0, \"recall\": 0.5386509108813392, \"specificity\": 1.0, \"npv\": 0.5499519692603266, \"accuracy\": 0.7049748110831234, \"f1\": 0.70016, \"f2\": 0.5934042091559991, \"f0_5\": 0.8537537068830966, \"p4\": 0.7048668608108392, \"phi\": 0.544272109503198}, {\"truth_threshold\": 2.3894380440457073, \"match_probability\": 0.8397315779535042, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1093.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 938.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5381585425898572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46184145741014276, \"precision\": 1.0, \"recall\": 0.5381585425898572, \"specificity\": 1.0, \"npv\": 0.5496879500720115, \"accuracy\": 0.7046599496221663, \"f1\": 0.6997439180537772, \"f2\": 0.5929261147878919, \"f0_5\": 0.8535061689832891, \"p4\": 0.7045475528853299, \"phi\": 0.5438926972206558}, {\"truth_threshold\": 2.4154488680914383, \"match_probability\": 0.8421431726961238, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1086.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 945.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.534711964549483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.465288035450517, \"precision\": 1.0, \"recall\": 0.534711964549483, \"specificity\": 1.0, \"npv\": 0.5478468899521531, \"accuracy\": 0.702455919395466, \"f1\": 0.6968238691049086, \"f2\": 0.5895765472312704, \"f0_5\": 0.851764705882353, \"p4\": 0.7023096718169206, \"phi\": 0.5412395835474714}, {\"truth_threshold\": 2.426073154747743, \"match_probability\": 0.8431196894736591, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1084.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 947.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.533727227966519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46627277203348105, \"precision\": 1.0, \"recall\": 0.533727227966519, \"specificity\": 1.0, \"npv\": 0.5473231357552581, \"accuracy\": 0.7018261964735516, \"f1\": 0.6959871589085073, \"f2\": 0.5886185925282363, \"f0_5\": 0.8512643317103816, \"p4\": 0.701669388939399, \"phi\": 0.5404824326919393}, {\"truth_threshold\": 2.4453140261216046, \"match_probability\": 0.8448756656449682, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1083.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 948.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5332348596750369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4667651403249631, \"precision\": 1.0, \"recall\": 0.5332348596750369, \"specificity\": 1.0, \"npv\": 0.5470616340181558, \"accuracy\": 0.7015113350125944, \"f1\": 0.6955684007707129, \"f2\": 0.588139459107201, \"f0_5\": 0.851013672795851, \"p4\": 0.7013490974061563, \"phi\": 0.5401040026228908}, {\"truth_threshold\": 2.4529151028080287, \"match_probability\": 0.8455649269420745, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1082.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 949.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5327424913835549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4672575086164451, \"precision\": 1.0, \"recall\": 0.5327424913835549, \"specificity\": 1.0, \"npv\": 0.5468003820439351, \"accuracy\": 0.7011964735516373, \"f1\": 0.6951493735946033, \"f2\": 0.5876602215946122, \"f0_5\": 0.8507626985375059, \"p4\": 0.7010287052607143, \"phi\": 0.5397256690389717}, {\"truth_threshold\": 2.4705692456767343, \"match_probability\": 0.8471561350846746, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1081.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 950.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5322501230920729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46774987690792713, \"precision\": 1.0, \"recall\": 0.5322501230920729, \"specificity\": 1.0, \"npv\": 0.5465393794749404, \"accuracy\": 0.7008816120906801, \"f1\": 0.6947300771208226, \"f2\": 0.5871808799565453, \"f0_5\": 0.8505114083398898, \"p4\": 0.7007082120899899, \"phi\": 0.5393474316247386}, {\"truth_threshold\": 2.49505159290693, \"match_probability\": 0.849340517230903, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1080.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 951.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5317577548005908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46824224519940916, \"precision\": 1.0, \"recall\": 0.5317577548005908, \"specificity\": 1.0, \"npv\": 0.5462786259541985, \"accuracy\": 0.700566750629723, \"f1\": 0.6943105110896818, \"f2\": 0.5867014341590613, \"f0_5\": 0.8502598016060463, \"p4\": 0.7003876174799554, \"phi\": 0.5389692900648018}, {\"truth_threshold\": 2.520283105833218, \"match_probability\": 0.8515648038158019, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1072.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 959.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5278188084687346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47218119153126537, \"precision\": 1.0, \"recall\": 0.5278188084687346, \"specificity\": 1.0, \"npv\": 0.5442015209125475, \"accuracy\": 0.6980478589420654, \"f1\": 0.690944247502417, \"f2\": 0.5828621139625925, \"f0_5\": 0.8482354802975154, \"p4\": 0.6978191587869178, \"phi\": 0.5359475705094053}, {\"truth_threshold\": 2.584340555672734, \"match_probability\": 0.85709006132643, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1071.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 960.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5273264401772526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4726735598227474, \"precision\": 1.0, \"recall\": 0.5273264401772526, \"specificity\": 1.0, \"npv\": 0.5439429928741093, \"accuracy\": 0.6977329974811083, \"f1\": 0.690522243713733, \"f2\": 0.5823817292006526, \"f0_5\": 0.8479809976247031, \"p4\": 0.6974976324343694, \"phi\": 0.5355702774535427}, {\"truth_threshold\": 2.6139070654748906, \"match_probability\": 0.8595819730360399, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1069.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 962.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5263417035942886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4736582964057115, \"precision\": 1.0, \"recall\": 0.5263417035942886, \"specificity\": 1.0, \"npv\": 0.5434266729947793, \"accuracy\": 0.697103274559194, \"f1\": 0.6896774193548387, \"f2\": 0.5814206461438051, \"f0_5\": 0.847471063897257, \"p4\": 0.6968542624078266, \"phi\": 0.5348159691357846}, {\"truth_threshold\": 2.6349947967277227, \"match_probability\": 0.8613369892372468, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1068.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 963.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5258493353028065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4741506646971935, \"precision\": 1.0, \"recall\": 0.5258493353028065, \"specificity\": 1.0, \"npv\": 0.543168880455408, \"accuracy\": 0.6967884130982368, \"f1\": 0.6892545982575025, \"f2\": 0.5809399477806788, \"f0_5\": 0.8472156116135173, \"p4\": 0.6965324178835663, \"phi\": 0.5344389532440967}, {\"truth_threshold\": 2.6486114789335784, \"match_probability\": 0.8624604260798694, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1067.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 964.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5253569670113245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47464303298867555, \"precision\": 1.0, \"recall\": 0.5253569670113245, \"specificity\": 1.0, \"npv\": 0.5429113323850165, \"accuracy\": 0.6964735516372796, \"f1\": 0.6888315041962556, \"f2\": 0.5804591448155805, \"f0_5\": 0.8469598348944277, \"p4\": 0.6962104664501566, \"phi\": 0.5340620291107292}, {\"truth_threshold\": 2.651893803688669, \"match_probability\": 0.8627300855530031, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1066.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 965.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5248645987198425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4751354012801576, \"precision\": 1.0, \"recall\": 0.5248645987198425, \"specificity\": 1.0, \"npv\": 0.542654028436019, \"accuracy\": 0.6961586901763224, \"f1\": 0.6884081369066839, \"f2\": 0.5799782372143635, \"f0_5\": 0.846703733121525, \"p4\": 0.6958884076799895, \"phi\": 0.5336851964208649}, {\"truth_threshold\": 2.672840832632327, \"match_probability\": 0.8644405314881777, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1065.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 966.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5243722304283605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4756277695716396, \"precision\": 1.0, \"recall\": 0.5243722304283605, \"specificity\": 1.0, \"npv\": 0.5423969682614874, \"accuracy\": 0.6958438287153652, \"f1\": 0.687984496124031, \"f2\": 0.5794972249428665, \"f0_5\": 0.8464473056747734, \"p4\": 0.6955662411444608, \"phi\": 0.5333084548597151}, {\"truth_threshold\": 2.709737587517856, \"match_probability\": 0.867409639895638, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1064.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 967.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5238798621368784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47612013786312163, \"precision\": 1.0, \"recall\": 0.5238798621368784, \"specificity\": 1.0, \"npv\": 0.5421401515151515, \"accuracy\": 0.695528967254408, \"f1\": 0.6875605815831987, \"f2\": 0.5790161079669134, \"f0_5\": 0.8461905519325592, \"p4\": 0.6952439664139662, \"phi\": 0.5329318041125186}, {\"truth_threshold\": 2.7169814726308954, \"match_probability\": 0.8679860503558711, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1063.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 968.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5233874938453964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47661250615460365, \"precision\": 1.0, \"recall\": 0.5233874938453964, \"specificity\": 1.0, \"npv\": 0.5418835778513961, \"accuracy\": 0.6952141057934509, \"f1\": 0.687136393018746, \"f2\": 0.5785348862523131, \"f0_5\": 0.8459334712716855, \"p4\": 0.6949215830578982, \"phi\": 0.5325552438645393}, {\"truth_threshold\": 2.7198377444852166, \"match_probability\": 0.8682127449385981, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1060.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 971.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5219103889709503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47808961102904973, \"precision\": 1.0, \"recall\": 0.5219103889709503, \"specificity\": 1.0, \"npv\": 0.5411153119092628, \"accuracy\": 0.6942695214105793, \"f1\": 0.6858621805241022, \"f2\": 0.5770905923344948, \"f0_5\": 0.8451602615212884, \"p4\": 0.6939537769150447, \"phi\": 0.5314261029688891}, {\"truth_threshold\": 2.7250776239920493, \"match_probability\": 0.8686277615091745, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1059.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 972.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5214180206794683, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47858197932053176, \"precision\": 1.0, \"recall\": 0.5214180206794683, \"specificity\": 1.0, \"npv\": 0.540859707132735, \"accuracy\": 0.6939546599496221, \"f1\": 0.6854368932038835, \"f2\": 0.576608951323097, \"f0_5\": 0.8449018669219722, \"p4\": 0.6936309547304057, \"phi\": 0.531049901570867}, {\"truth_threshold\": 2.763174219681781, \"match_probability\": 0.8716118856283597, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1057.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 974.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5204332840965041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4795667159034958, \"precision\": 1.0, \"recall\": 0.5204332840965041, \"specificity\": 1.0, \"npv\": 0.5403492213308164, \"accuracy\": 0.6933249370277078, \"f1\": 0.6845854922279793, \"f2\": 0.5756453545365429, \"f0_5\": 0.8443840869148427, \"p4\": 0.6929849775430416, \"phi\": 0.5302977652377819}, {\"truth_threshold\": 2.792630872007984, \"match_probability\": 0.8738794471112633, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1055.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 976.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5194485475135401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48055145248645986, \"precision\": 1.0, \"recall\": 0.5194485475135401, \"specificity\": 1.0, \"npv\": 0.5398396982555398, \"accuracy\": 0.6926952141057935, \"f1\": 0.6837329876863253, \"f2\": 0.5746813378363657, \"f0_5\": 0.8438649816029435, \"p4\": 0.6923385536817068, \"phi\": 0.5295459820912514}, {\"truth_threshold\": 2.8091281808508493, \"match_probability\": 0.8751343740677077, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1052.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 979.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.517971442639094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48202855736090594, \"precision\": 1.0, \"recall\": 0.517971442639094, \"specificity\": 1.0, \"npv\": 0.5390772128060264, \"accuracy\": 0.6917506297229219, \"f1\": 0.6824521569899449, \"f2\": 0.5732345248474281, \"f0_5\": 0.8430838275364642, \"p4\": 0.6913680726839329, \"phi\": 0.5284189640909941}, {\"truth_threshold\": 2.810576645115675, \"match_probability\": 0.8752440439333644, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1051.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 980.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.517479074347612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48252092565238797, \"precision\": 1.0, \"recall\": 0.517479074347612, \"specificity\": 1.0, \"npv\": 0.5388235294117647, \"accuracy\": 0.6914357682619647, \"f1\": 0.682024659312135, \"f2\": 0.5727520435967303, \"f0_5\": 0.842822774659182, \"p4\": 0.6910443518632836, \"phi\": 0.5280434652911759}, {\"truth_threshold\": 2.8306911728532724, \"match_probability\": 0.8767584855919144, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1050.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 981.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.51698670605613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48301329394387, \"precision\": 1.0, \"recall\": 0.51698670605613, \"specificity\": 1.0, \"npv\": 0.5385700846660395, \"accuracy\": 0.6911209068010076, \"f1\": 0.6815968841285297, \"f2\": 0.5722694571615435, \"f0_5\": 0.8425613866153105, \"p4\": 0.6907205167261657, \"phi\": 0.5276680529005587}, {\"truth_threshold\": 2.840621788533264, \"match_probability\": 0.8775003287589078, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1043.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 988.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5135401280157558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48645987198424423, \"precision\": 1.0, \"recall\": 0.5135401280157558, \"specificity\": 1.0, \"npv\": 0.5368026254102204, \"accuracy\": 0.6889168765743073, \"f1\": 0.6785946649316851, \"f2\": 0.5688884040580342, \"f0_5\": 0.840722231178462, \"p4\": 0.6884504323874672, \"phi\": 0.5250425592010217}, {\"truth_threshold\": 2.898244420869207, \"match_probability\": 0.8817293960450647, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1038.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 993.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5110782865583456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48892171344165436, \"precision\": 1.0, \"recall\": 0.5110782865583456, \"specificity\": 1.0, \"npv\": 0.5355472404115996, \"accuracy\": 0.6873425692695214, \"f1\": 0.6764418377321603, \"f2\": 0.5664702030124427, \"f0_5\": 0.8393983503153809, \"p4\": 0.6868254153315653, \"phi\": 0.5231697296295064}, {\"truth_threshold\": 2.8988966966606067, \"match_probability\": 0.8817765365142566, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1037.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 994.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5105859182668636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4894140817331364, \"precision\": 1.0, \"recall\": 0.5105859182668636, \"specificity\": 1.0, \"npv\": 0.5352968676951847, \"accuracy\": 0.6870277078085643, \"f1\": 0.6760104302477183, \"f2\": 0.5659862460430084, \"f0_5\": 0.839132545719372, \"p4\": 0.6865000531917353, \"phi\": 0.5227954119323559}, {\"truth_threshold\": 2.9590558407980763, \"match_probability\": 0.8860548044954626, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1035.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 996.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5096011816838996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49039881831610044, \"precision\": 1.0, \"recall\": 0.5096011816838996, \"specificity\": 1.0, \"npv\": 0.5347968239140588, \"accuracy\": 0.6863979848866498, \"f1\": 0.675146771037182, \"f2\": 0.5650180150671471, \"f0_5\": 0.8385999027710258, \"p4\": 0.6858489665170626, \"phi\": 0.5220470222378447}, {\"truth_threshold\": 2.9970141394790293, \"match_probability\": 0.8886843153407171, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1034.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 997.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5091088133924175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49089118660758246, \"precision\": 1.0, \"recall\": 0.5091088133924175, \"specificity\": 1.0, \"npv\": 0.534547152194211, \"accuracy\": 0.6860831234256927, \"f1\": 0.6747145187601957, \"f2\": 0.5645337409914829, \"f0_5\": 0.8383330630776715, \"p4\": 0.6855232410606378, \"phi\": 0.5216729496110478}, {\"truth_threshold\": 3.005783835831936, \"match_probability\": 0.8892842275030561, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1033.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 998.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5086164451009355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4913835548990645, \"precision\": 1.0, \"recall\": 0.5086164451009355, \"specificity\": 1.0, \"npv\": 0.5342977134857676, \"accuracy\": 0.6857682619647355, \"f1\": 0.6742819843342036, \"f2\": 0.5640493611444797, \"f0_5\": 0.8380658770079507, \"p4\": 0.6851973935752371, \"phi\": 0.5212989580448912}, {\"truth_threshold\": 3.080220442293204, \"match_probability\": 0.8942631019936234, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1032.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 999.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5081240768094535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4918759231905465, \"precision\": 1.0, \"recall\": 0.5081240768094535, \"specificity\": 1.0, \"npv\": 0.5340485074626866, \"accuracy\": 0.6854534005037783, \"f1\": 0.67384916748286, \"f2\": 0.563564875491481, \"f0_5\": 0.8377983438869946, \"p4\": 0.6848714235972703, \"phi\": 0.5209250472245927}, {\"truth_threshold\": 3.1073265727291064, \"match_probability\": 0.896026567404893, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1031.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1000.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5076317085179715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49236829148202854, \"precision\": 1.0, \"recall\": 0.5076317085179715, \"specificity\": 1.0, \"npv\": 0.5337995337995338, \"accuracy\": 0.6851385390428212, \"f1\": 0.6734160679294579, \"f2\": 0.5630802839978154, \"f0_5\": 0.8375304630381804, \"p4\": 0.68454533066202, \"phi\": 0.5205512168353408}, {\"truth_threshold\": 3.12534251257939, \"match_probability\": 0.8971842181205371, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1030.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1001.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5071393402264894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49286065977351057, \"precision\": 1.0, \"recall\": 0.5071393402264894, \"specificity\": 1.0, \"npv\": 0.5335507921714818, \"accuracy\": 0.684823677581864, \"f1\": 0.6729826853969291, \"f2\": 0.5625955866287962, \"f0_5\": 0.8372622337831247, \"p4\": 0.6842191143036372, \"phi\": 0.5201774665622936}, {\"truth_threshold\": 3.174435246964142, \"match_probability\": 0.9002810121209376, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1029.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1002.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5066469719350074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4933530280649926, \"precision\": 1.0, \"recall\": 0.5066469719350074, \"specificity\": 1.0, \"npv\": 0.5333022822543083, \"accuracy\": 0.6845088161209067, \"f1\": 0.6725490196078432, \"f2\": 0.5621107833497214, \"f0_5\": 0.8369936554416789, \"p4\": 0.6838927740551384, \"phi\": 0.5198037960905768}, {\"truth_threshold\": 3.244952177673058, \"match_probability\": 0.9045840485737268, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1028.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1003.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5061546036435254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4938453963564746, \"precision\": 1.0, \"recall\": 0.5061546036435254, \"specificity\": 1.0, \"npv\": 0.5330540037243948, \"accuracy\": 0.6841939546599496, \"f1\": 0.6721150702844066, \"f2\": 0.5616258741258742, \"f0_5\": 0.8367247273319225, \"p4\": 0.6835663094483997, \"phi\": 0.519430205105282}, {\"truth_threshold\": 3.256556527711427, \"match_probability\": 0.9052760433824671, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1027.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1004.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5056622353520434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49433776464795665, \"precision\": 1.0, \"recall\": 0.5056622353520434, \"specificity\": 1.0, \"npv\": 0.532805956258725, \"accuracy\": 0.6838790931989924, \"f1\": 0.671680837148463, \"f2\": 0.5611408589225221, \"f0_5\": 0.836455448770158, \"p4\": 0.6832397200141539, \"phi\": 0.5190566932914649}, {\"truth_threshold\": 3.2725517007149962, \"match_probability\": 0.906222506703176, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1026.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1005.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5051698670605613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4948301329394387, \"precision\": 1.0, \"recall\": 0.5051698670605613, \"specificity\": 1.0, \"npv\": 0.5325581395348837, \"accuracy\": 0.6835642317380353, \"f1\": 0.6712463199214916, \"f2\": 0.5606557377049181, \"f0_5\": 0.8361858190709046, \"p4\": 0.6829130052819856, \"phi\": 0.5186832603341437}, {\"truth_threshold\": 3.283252572922325, \"match_probability\": 0.906850954961338, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1019.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1012.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5017232890201871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4982767109798129, \"precision\": 1.0, \"recall\": 0.5017232890201871, \"specificity\": 1.0, \"npv\": 0.530829856281873, \"accuracy\": 0.681360201511335, \"f1\": 0.6681967213114755, \"f2\": 0.5572569178606585, \"f0_5\": 0.834288521368921, \"p4\": 0.6806224540570874, \"phi\": 0.51607141114758}, {\"truth_threshold\": 3.3793495547489907, \"match_probability\": 0.9123271697155491, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1018.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1013.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5012309207287051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49876907927129494, \"precision\": 1.0, \"recall\": 0.5012309207287051, \"specificity\": 1.0, \"npv\": 0.530583873957368, \"accuracy\": 0.6810453400503779, \"f1\": 0.6677599212856674, \"f2\": 0.5567709472763072, \"f0_5\": 0.8340160576765525, \"p4\": 0.680294719867444, \"phi\": 0.515698597697778}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import splink.duckdb.comparison_library as cl\n",
    "import splink.duckdb.comparison_template_library as ctl\n",
    "from splink.duckdb.blocking_rule_library import block_on\n",
    "from splink.datasets import splink_datasets, splink_dataset_labels\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "df = splink_datasets.fake_1000\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on(\"first_name\"),\n",
    "        block_on(\"surname\"),\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True),\n",
    "        cl.exact_match(\"city\", term_frequency_adjustments=True),\n",
    "        ctl.email_comparison(\"email\", include_username_fuzzy_level=False),\n",
    "    ],\n",
    "}\n",
    "\n",
    "linker = DuckDBLinker(df, settings)\n",
    "linker.estimate_u_using_random_sampling(max_pairs=1e6)\n",
    "\n",
    "blocking_rule_for_training = block_on([\"first_name\", \"surname\"])\n",
    "\n",
    "linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n",
    "\n",
    "blocking_rule_for_training = block_on(\"dob\")\n",
    "linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n",
    "\n",
    "\n",
    "df_labels = splink_dataset_labels.fake_1000_labels\n",
    "labels_table = linker.register_labels_table(df_labels)\n",
    "\n",
    "linker.accuracy_analysis_from_labels_table(labels_table, add_metrics=['f1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the chart shows\n",
    "\n",
    "For a given match weight threshold, a record pair with a score above this threshold will be labelled a match and below the threshold will be labelled a non-match. Lowering the threshold to the extreme ensures many more matches are generated - this maximises the True Positives (high recall) but at the expense of some False Positives (low precision).\n",
    "\n",
    "You can then see the effect on the confusion matrix of raising the match threshold. As more predicted matches become non-matches at the higher threshold, True Positives become False Negatives, but False Positives become True Negatives.\n",
    "\n",
    "This demonstrates the trade-off between Type 1 (FP) and Type 2 (FN) errors when selecting a match threshold, or precision vs recall.\n",
    "\n",
    "This chart adds further context to [accuracy_chart_from_labels_table](accuracy_chart_from_labels_table.ipynb) showing:\n",
    "\n",
    "-  the relationship between match weight and match probability\n",
    "-  various accuracy metrics comparing the Splink scores against clerical labels\n",
    "-  the confusion matrix of the predictions and the labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to interpret the chart\n",
    "\n",
    "**Precision** can be maximised by **increasing** the match threshold (reducing false positives).\n",
    "\n",
    "**Recall** can be maximised by **decreasing** the match threshold (reducing false negatives). \n",
    "\n",
    "Additional metrics can be used to find the optimal compromise between these two, looking for the threshold at which peak accuracy is achieved. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions to take as a result of the chart\n",
    "\n",
    "Having identified an optimal match weight threshold, this can be applied when generating linked clusters using [cluster_pairwise_predictions_at_thresholds()](../linker.md#splink.linker.Linker.cluster_pairwise_predictions_at_thresholds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
