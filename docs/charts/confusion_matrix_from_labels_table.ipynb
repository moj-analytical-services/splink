{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `confusion_matrix_from_labels_table`\n",
    "\n",
    "!!! info \"At a glance\"\n",
    "    **Useful for:** Summarising how Splink predictions compare with labelled data\n",
    "\n",
    "    **API Documentation:** [confusion_matrix_from_labels_table_chart()](../linker.md#splink.linker.Linker.confusion_matrix_from_labels_table)\n",
    "\n",
    "    **What is needed to generate the chart?** A `linker` with some data and a corresponding labelled dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-785defe6d8094089962bcdbcc60415c8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-785defe6d8094089962bcdbcc60415c8.vega-embed details,\n",
       "  #altair-viz-785defe6d8094089962bcdbcc60415c8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-785defe6d8094089962bcdbcc60415c8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-785defe6d8094089962bcdbcc60415c8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-785defe6d8094089962bcdbcc60415c8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"rule\", \"clip\": true}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 0.3, \"empty\": false}, \"value\": 0}}, \"params\": [{\"name\": \"threshold\", \"select\": {\"type\": \"point\", \"fields\": [\"truth_threshold\"], \"nearest\": true, \"on\": \"mouseover\"}}]}, {\"layer\": [{\"mark\": {\"type\": \"text\", \"clip\": true, \"fontSize\": 14, \"xOffset\": {\"expr\": \"50*(toNumber(datum.truth_threshold>0)-0.5)\"}, \"yOffset\": {\"expr\": \"25*(toNumber(datum.truth_threshold>0)-0.5)\"}}, \"encoding\": {\"text\": {\"aggregate\": \"min\", \"field\": \"truth_threshold\", \"format\": \"+.2f\"}}, \"transform\": [{\"filter\": {\"param\": \"threshold\", \"empty\": false}}]}, {\"mark\": {\"type\": \"line\", \"clip\": true, \"color\": \"red\", \"opacity\": 0.5}}, {\"mark\": {\"type\": \"line\", \"clip\": true, \"color\": \"green\", \"opacity\": 0.5, \"strokeWidth\": 3}, \"transform\": [{\"filter\": \"datum.truth_threshold >= threshold.truth_threshold\"}]}, {\"mark\": {\"type\": \"point\", \"clip\": true, \"color\": \"green\", \"size\": 100}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"threshold\", \"value\": 1, \"empty\": false}, \"value\": 0}}}], \"encoding\": {\"y\": {\"field\": \"match_probability\", \"type\": \"quantitative\", \"axis\": {\"labelFontSize\": 12, \"title\": \"Match probability\", \"titleFontSize\": 16, \"titlePadding\": 5}}}}], \"encoding\": {\"x\": {\"field\": \"truth_threshold\", \"type\": \"quantitative\", \"title\": \"Match weight threshold\", \"axis\": {\"labelFontSize\": 12, \"titleFontSize\": 16}, \"scale\": {\"domain\": [-15, 15]}}}, \"height\": 300, \"title\": {\"text\": \"Interactive Confusion Matrix\", \"baseline\": \"line-bottom\", \"fontSize\": 20, \"offset\": -20, \"subtitle\": [\"Hover over the line graph to view the confusion\", \"matrix for the selected match threshold\"], \"subtitlePadding\": 10}, \"width\": 250}, {\"layer\": [{\"mark\": {\"type\": \"rect\", \"opacity\": 0.5}, \"encoding\": {\"color\": {\"field\": \"count\", \"legend\": null, \"scale\": {\"scheme\": \"reds\", \"zero\": true}, \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": \"datum.predicted == 0\"}]}, {\"mark\": {\"type\": \"rect\", \"opacity\": 0.5}, \"encoding\": {\"color\": {\"field\": \"count\", \"legend\": null, \"scale\": {\"scheme\": \"greens\", \"zero\": true}, \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": \"datum.predicted == 1\"}]}, {\"mark\": {\"type\": \"text\", \"fontSize\": 14, \"yOffset\": -40}, \"encoding\": {\"color\": {\"condition\": [{\"test\": \"datum.predicted==1 && datum.actual==1\", \"value\": \"darkgreen\"}, {\"test\": \"datum.predicted==0 && datum.actual==0\", \"value\": \"darkred\"}], \"value\": \"black\"}, \"opacity\": {\"condition\": {\"test\": \"datum.predicted != datum.actual\", \"value\": 1}, \"value\": 0.5}, \"text\": {\"field\": \"confusion_label\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"fontSize\": 28, \"fontWeight\": \"bold\", \"yOffset\": 10}, \"encoding\": {\"color\": {\"condition\": [{\"test\": \"datum.predicted==1 && datum.actual==1\", \"value\": \"darkgreen\"}, {\"test\": \"datum.predicted==0 && datum.actual==0\", \"value\": \"darkred\"}], \"value\": \"black\"}, \"text\": {\"field\": \"count\", \"format\": \",\", \"type\": \"nominal\"}}}], \"encoding\": {\"x\": {\"field\": \"actual\", \"type\": \"nominal\", \"title\": \"Actual\", \"axis\": {\"domain\": false, \"labelAngle\": 0, \"labelExpr\": \"datum.label == 1 ? 'Match' : 'Non-match'\", \"labelFontSize\": 18, \"labelPadding\": 10, \"orient\": \"top\", \"ticks\": false, \"titleAngle\": 0, \"titleFontSize\": 20}, \"sort\": \"-x\"}, \"y\": {\"field\": \"predicted\", \"type\": \"nominal\", \"title\": \"Predicted\", \"axis\": {\"domain\": false, \"labelExpr\": \"datum.label == 1 ? 'Match' : 'Non-match'\", \"labelFontSize\": 18, \"labelPadding\": 10, \"ticks\": false, \"titleAngle\": 0, \"titleFontSize\": 20, \"titlePadding\": -30}, \"sort\": \"-y\"}}, \"height\": {\"step\": 150}, \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"transform\": [{\"filter\": {\"or\": [{\"param\": \"threshold\", \"empty\": false}, {\"and\": [{\"param\": \"threshold\", \"empty\": true}, \"datum.truth_threshold == datum.max_threshold\"]}]}}], \"width\": {\"step\": 150}}], \"data\": {\"name\": \"data-55dfee1d2bff3caa759294ce10d12c08\"}, \"transform\": [{\"fold\": [\"tp\", \"tn\", \"fp\", \"fn\"], \"as\": [\"label\", \"count\"]}, {\"calculate\": \"datum.label === 'tp' ? 'True Positive (TP)' : datum.label === 'tn' ? 'True Negative (TN)' : datum.label === 'fp' ? 'False Positive (FP)' : 'False Negative (FN)'\", \"as\": \"confusion_label\"}, {\"calculate\": \"datum.label === 'tp' || datum.label === 'fp' ? 1 : 0\", \"as\": \"predicted\"}, {\"calculate\": \"datum.label === 'tp' || datum.label === 'fn' ? 1 : 0\", \"as\": \"actual\"}, {\"joinaggregate\": [{\"op\": \"max\", \"field\": \"truth_threshold\", \"as\": \"max_threshold\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-55dfee1d2bff3caa759294ce10d12c08\": [{\"truth_threshold\": -14.733948595922948, \"match_probability\": 3.669641010969825e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1990.0, \"tn\": 1109.0, \"fp\": 36.0, \"fn\": 41.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9798129200935364, \"tn_rate\": 0.9685589671134949, \"fp_rate\": 0.03144104778766632, \"fn_rate\": 0.020187100395560265, \"precision\": 0.9822310209274292, \"recall\": 0.9798129200935364, \"specificity\": 0.9685589671134949, \"npv\": 0.9643478393554688, \"accuracy\": 0.9757556915283203, \"f1\": 0.9810204584668474, \"f2\": 0.9802955665024631, \"f0_5\": 0.9817464232856438, \"p4\": 0.9736801149492355, \"phi\": 0.9474749134225178}, {\"truth_threshold\": -14.730010713762097, \"match_probability\": 3.679670726650674e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1988.0, \"tn\": 1109.0, \"fp\": 36.0, \"fn\": 43.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9788281917572021, \"tn_rate\": 0.9685589671134949, \"fp_rate\": 0.03144104778766632, \"fn_rate\": 0.02117183618247509, \"precision\": 0.9822134375572205, \"recall\": 0.9788281917572021, \"specificity\": 0.9685589671134949, \"npv\": 0.9626736044883728, \"accuracy\": 0.9751259684562683, \"f1\": 0.980517879161529, \"f2\": 0.9795033504138747, \"f0_5\": 0.9815345117013923, \"p4\": 0.9730054766235877, \"phi\": 0.9461362568691166}, {\"truth_threshold\": -14.729217892456285, \"match_probability\": 3.681693340975503e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1987.0, \"tn\": 1112.0, \"fp\": 33.0, \"fn\": 44.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9783357977867126, \"tn_rate\": 0.9711790680885315, \"fp_rate\": 0.028820959851145744, \"fn_rate\": 0.021664204075932503, \"precision\": 0.9836633801460266, \"recall\": 0.9783357977867126, \"specificity\": 0.9711790680885315, \"npv\": 0.9619377255439758, \"accuracy\": 0.9757556915283203, \"f1\": 0.9809923475685016, \"f2\": 0.9793966876971609, \"f0_5\": 0.9825932153100584, \"p4\": 0.9737106660619014, \"phi\": 0.9475559378870411}, {\"truth_threshold\": -14.305995724144662, \"match_probability\": 4.936790849772458e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1986.0, \"tn\": 1117.0, \"fp\": 28.0, \"fn\": 45.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9778434038162231, \"tn_rate\": 0.9755458235740662, \"fp_rate\": 0.0244541484862566, \"fn_rate\": 0.022156573832035065, \"precision\": 0.9860973358154297, \"recall\": 0.9778434038162231, \"specificity\": 0.9755458235740662, \"npv\": 0.9612736701965332, \"accuracy\": 0.9770151376724243, \"f1\": 0.9819530284301607, \"f2\": 0.9794831327678043, \"f0_5\": 0.984435411916328, \"p4\": 0.9751077119290652, \"phi\": 0.9503753677602026}, {\"truth_threshold\": -14.12888215034865, \"match_probability\": 5.581596354257043e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1985.0, \"tn\": 1117.0, \"fp\": 28.0, \"fn\": 46.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9773510694503784, \"tn_rate\": 0.9755458235740662, \"fp_rate\": 0.0244541484862566, \"fn_rate\": 0.022648941725492477, \"precision\": 0.9860904216766357, \"recall\": 0.9773510694503784, \"specificity\": 0.9755458235740662, \"npv\": 0.9604471325874329, \"accuracy\": 0.9767002463340759, \"f1\": 0.9817012858555886, \"f2\": 0.979086514747953, \"f0_5\": 0.9843300604978676, \"p4\": 0.9747708640342702, \"phi\": 0.9497118981046985}, {\"truth_threshold\": -14.053486900342577, \"match_probability\": 5.881029495991135e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1984.0, \"tn\": 1117.0, \"fp\": 28.0, \"fn\": 47.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9768586754798889, \"tn_rate\": 0.9755458235740662, \"fp_rate\": 0.0244541484862566, \"fn_rate\": 0.02314130961894989, \"precision\": 0.9860835075378418, \"recall\": 0.9768586754798889, \"specificity\": 0.9755458235740662, \"npv\": 0.9596219658851624, \"accuracy\": 0.9763854146003723, \"f1\": 0.9814494187484541, \"f2\": 0.978689818468824, \"f0_5\": 0.9842246254588749, \"p4\": 0.9744341238024875, \"phi\": 0.9490491061794165}, {\"truth_threshold\": -13.75042549606056, \"match_probability\": 7.255677323116187e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1981.0, \"tn\": 1124.0, \"fp\": 21.0, \"fn\": 50.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.97538161277771, \"tn_rate\": 0.9816594123840332, \"fp_rate\": 0.018340611830353737, \"fn_rate\": 0.024618415161967278, \"precision\": 0.9895104765892029, \"recall\": 0.97538161277771, \"specificity\": 0.9816594123840332, \"npv\": 0.9574105739593506, \"accuracy\": 0.9776448607444763, \"f1\": 0.9823952392759733, \"f2\": 0.9781749950622161, \"f0_5\": 0.9866520569777867, \"p4\": 0.9758459240469327, \"phi\": 0.9519675654558195}, {\"truth_threshold\": -13.629471910725142, \"match_probability\": 7.890160941467188e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1978.0, \"tn\": 1124.0, \"fp\": 21.0, \"fn\": 53.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9739044904708862, \"tn_rate\": 0.9816594123840332, \"fp_rate\": 0.018340611830353737, \"fn_rate\": 0.026095518842339516, \"precision\": 0.9894947409629822, \"recall\": 0.9739044904708862, \"specificity\": 0.9816594123840332, \"npv\": 0.9549702405929565, \"accuracy\": 0.9767002463340759, \"f1\": 0.9816377171215881, \"f2\": 0.9769831077743751, \"f0_5\": 0.986336890395931, \"p4\": 0.9748375359928863, \"phi\": 0.9499982315768232}, {\"truth_threshold\": -13.624741207258479, \"match_probability\": 7.916073774999232e-05, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1978.0, \"tn\": 1125.0, \"fp\": 20.0, \"fn\": 53.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9739044904708862, \"tn_rate\": 0.9825327396392822, \"fp_rate\": 0.017467249184846878, \"fn_rate\": 0.026095518842339516, \"precision\": 0.9899899959564209, \"recall\": 0.9739044904708862, \"specificity\": 0.9825327396392822, \"npv\": 0.9550085067749023, \"accuracy\": 0.9770151376724243, \"f1\": 0.9818813601389923, \"f2\": 0.9770796285319107, \"f0_5\": 0.9867305198044498, \"p4\": 0.9751828508929973, \"phi\": 0.9507006516869957}, {\"truth_threshold\": -12.65522783576295, \"match_probability\": 0.00015499921509957678, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1976.0, \"tn\": 1136.0, \"fp\": 9.0, \"fn\": 55.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.972919762134552, \"tn_rate\": 0.9921397566795349, \"fp_rate\": 0.00786026194691658, \"fn_rate\": 0.02708025649189949, \"precision\": 0.9954659938812256, \"recall\": 0.972919762134552, \"specificity\": 0.9921397566795349, \"npv\": 0.9538203477859497, \"accuracy\": 0.9798488616943359, \"f1\": 0.9840637450199203, \"f2\": 0.9773469185873974, \"f0_5\": 0.9908735332464146, \"p4\": 0.978299676447618, \"phi\": 0.9571404068585719}, {\"truth_threshold\": -12.645948810862754, \"match_probability\": 0.0001559991849966168, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1973.0, \"tn\": 1136.0, \"fp\": 9.0, \"fn\": 58.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9714426398277283, \"tn_rate\": 0.9921397566795349, \"fp_rate\": 0.00786026194691658, \"fn_rate\": 0.02855736017227173, \"precision\": 0.9954591393470764, \"recall\": 0.9714426398277283, \"specificity\": 0.9921397566795349, \"npv\": 0.9514237642288208, \"accuracy\": 0.9789043068885803, \"f1\": 0.9833042611512585, \"f2\": 0.97615278052642, \"f0_5\": 0.9905613013354755, \"p4\": 0.9772932480815906, \"phi\": 0.9551961540647628}, {\"truth_threshold\": -12.394316821094906, \"match_probability\": 0.0001857197953850478, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1971.0, \"tn\": 1137.0, \"fp\": 8.0, \"fn\": 60.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.970457911491394, \"tn_rate\": 0.9930130839347839, \"fp_rate\": 0.006986899767071009, \"fn_rate\": 0.029542097821831703, \"precision\": 0.9959575533866882, \"recall\": 0.970457911491394, \"specificity\": 0.9930130839347839, \"npv\": 0.9498746991157532, \"accuracy\": 0.9785894155502319, \"f1\": 0.9830423940149626, \"f2\": 0.9754528357913491, \"f0_5\": 0.9907509801950337, \"p4\": 0.9769663663435872, \"phi\": 0.9546108829739978}, {\"truth_threshold\": -12.227274963984662, \"match_probability\": 0.00020851288880033682, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1971.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 60.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.970457911491394, \"tn_rate\": 0.9956331849098206, \"fp_rate\": 0.0043668122962117195, \"fn_rate\": 0.029542097821831703, \"precision\": 0.9974696636199951, \"recall\": 0.970457911491394, \"specificity\": 0.9956331849098206, \"npv\": 0.949999988079071, \"accuracy\": 0.9795340299606323, \"f1\": 0.9837783878213127, \"f2\": 0.9757425742574257, \"f0_5\": 0.9919476597886261, \"p4\": 0.9779961316543299, \"phi\": 0.9567350590912768}, {\"truth_threshold\": -12.181458168342974, \"match_probability\": 0.0002152396181778499, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1969.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 62.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9694731831550598, \"tn_rate\": 0.9956331849098206, \"fp_rate\": 0.0043668122962117195, \"fn_rate\": 0.03052683360874653, \"precision\": 0.9974671006202698, \"recall\": 0.9694731831550598, \"specificity\": 0.9956331849098206, \"npv\": 0.9484192728996277, \"accuracy\": 0.9789043068885803, \"f1\": 0.983270911360799, \"f2\": 0.9749455337690632, \"f0_5\": 0.9917396998086028, \"p4\": 0.9773261900068391, \"phi\": 0.955448035508959}, {\"truth_threshold\": -12.043367931448072, \"match_probability\": 0.00023685476538593174, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1968.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 63.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9689807891845703, \"tn_rate\": 0.9956331849098206, \"fp_rate\": 0.0043668122962117195, \"fn_rate\": 0.03101920150220394, \"precision\": 0.9974657893180847, \"recall\": 0.9689807891845703, \"specificity\": 0.9956331849098206, \"npv\": 0.9476309418678284, \"accuracy\": 0.9785894155502319, \"f1\": 0.983016983016983, \"f2\": 0.9745468951173616, \"f0_5\": 0.9916355940743726, \"p4\": 0.9769913724178655, \"phi\": 0.9548054801027457}, {\"truth_threshold\": -11.671704735900562, \"match_probability\": 0.0003064316869015956, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1966.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 65.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9679960608482361, \"tn_rate\": 0.9956331849098206, \"fp_rate\": 0.0043668122962117195, \"fn_rate\": 0.032003939151763916, \"precision\": 0.9974632263183594, \"recall\": 0.9679960608482361, \"specificity\": 0.9956331849098206, \"npv\": 0.9460580945014954, \"accuracy\": 0.9779596924781799, \"f1\": 0.9825087456271864, \"f2\": 0.9737493808816245, \"f0_5\": 0.9914271306101866, \"p4\": 0.9763220428690601, \"phi\": 0.9535222751515374}, {\"truth_threshold\": -11.576939262108983, \"match_probability\": 0.00032722907679536294, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1965.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 66.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9675036668777466, \"tn_rate\": 0.9956331849098206, \"fp_rate\": 0.0043668122962117195, \"fn_rate\": 0.03249630704522133, \"precision\": 0.9974619150161743, \"recall\": 0.9675036668777466, \"specificity\": 0.9956331849098206, \"npv\": 0.9452736377716064, \"accuracy\": 0.9776448607444763, \"f1\": 0.9822544363909023, \"f2\": 0.9733505052506439, \"f0_5\": 0.9913227726768238, \"p4\": 0.9759875305731329, \"phi\": 0.9528816228546788}, {\"truth_threshold\": -11.550751150565143, \"match_probability\": 0.00033322125134931086, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1964.0, \"tn\": 1140.0, \"fp\": 5.0, \"fn\": 67.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9670113325119019, \"tn_rate\": 0.9956331849098206, \"fp_rate\": 0.0043668122962117195, \"fn_rate\": 0.03298867493867874, \"precision\": 0.997460663318634, \"recall\": 0.9670113325119019, \"specificity\": 0.9956331849098206, \"npv\": 0.9444904923439026, \"accuracy\": 0.9773299694061279, \"f1\": 0.982, \"f2\": 0.9729515505796096, \"f0_5\": 0.9912183304734027, \"p4\": 0.9756531197054947, \"phi\": 0.9522416021821541}, {\"truth_threshold\": -11.436202193789667, \"match_probability\": 0.0003607475615997379, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1962.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 69.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9660266041755676, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.03397341072559357, \"precision\": 0.997965395450592, \"recall\": 0.9660266041755676, \"specificity\": 0.9965065717697144, \"npv\": 0.9429752230644226, \"accuracy\": 0.9770151376724243, \"f1\": 0.98173630222667, \"f2\": 0.9722497522299306, \"f0_5\": 0.9914098029307731, \"p4\": 0.975327649111701, \"phi\": 0.9516756413860702}, {\"truth_threshold\": -11.424803449599377, \"match_probability\": 0.0003636080799792259, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1958.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 73.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9640570878982544, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.035942886024713516, \"precision\": 0.9979612827301025, \"recall\": 0.9640570878982544, \"specificity\": 0.9965065717697144, \"npv\": 0.9398682117462158, \"accuracy\": 0.9757556915283203, \"f1\": 0.9807162534435262, \"f2\": 0.9706523894507237, \"f0_5\": 0.990990990990991, \"p4\": 0.9739918593428727, \"phi\": 0.9491285008674043}, {\"truth_threshold\": -11.330588644928445, \"match_probability\": 0.00038813638008317503, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1956.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 75.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9630723595619202, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.03692762181162834, \"precision\": 0.9979591965675354, \"recall\": 0.9630723595619202, \"specificity\": 0.9965065717697144, \"npv\": 0.9383223652839661, \"accuracy\": 0.9751259684562683, \"f1\": 0.9802054622901528, \"f2\": 0.9698532328441095, \"f0_5\": 0.990781075878837, \"p4\": 0.9733245659243989, \"phi\": 0.947858664780497}, {\"truth_threshold\": -11.107468111649638, \"match_probability\": 0.0004530249610438168, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1951.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 80.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9606105089187622, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.039389465004205704, \"precision\": 0.9979539513587952, \"recall\": 0.9606105089187622, \"specificity\": 0.9965065717697144, \"npv\": 0.9344799518585205, \"accuracy\": 0.9735516309738159, \"f1\": 0.9789262418464626, \"f2\": 0.9678539537652545, \"f0_5\": 0.9902547964673637, \"p4\": 0.9716580758901154, \"phi\": 0.9446948802792131}, {\"truth_threshold\": -10.938891246250266, \"match_probability\": 0.0005091484651345755, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1950.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 81.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9601181745529175, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.039881832897663116, \"precision\": 0.997952938079834, \"recall\": 0.9601181745529175, \"specificity\": 0.9965065717697144, \"npv\": 0.9337152242660522, \"accuracy\": 0.9732367992401123, \"f1\": 0.9786700125470514, \"f2\": 0.9674538598928358, \"f0_5\": 0.9901492840459023, \"p4\": 0.9713250754294527, \"phi\": 0.9440639652010514}, {\"truth_threshold\": -10.830597076280574, \"match_probability\": 0.0005488162926872147, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1946.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 85.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.958148717880249, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.04185130447149277, \"precision\": 0.9979487061500549, \"recall\": 0.958148717880249, \"specificity\": 0.9965065717697144, \"npv\": 0.930668830871582, \"accuracy\": 0.9719773530960083, \"f1\": 0.97764380808842, \"f2\": 0.9658526900933095, \"f0_5\": 0.989726375750178, \"p4\": 0.9699940598192258, \"phi\": 0.9415464005494172}, {\"truth_threshold\": -10.742221666609483, \"match_probability\": 0.0005834660463926012, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1945.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 86.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9576563239097595, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.04234367236495018, \"precision\": 0.9979476928710938, \"recall\": 0.9576563239097595, \"specificity\": 0.9965065717697144, \"npv\": 0.9299103617668152, \"accuracy\": 0.9716624617576599, \"f1\": 0.9773869346733668, \"f2\": 0.965452198947682, \"f0_5\": 0.9896204334995421, \"p4\": 0.9696615516367513, \"phi\": 0.9409185267894152}, {\"truth_threshold\": -10.630905946259881, \"match_probability\": 0.0006302380705481763, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1932.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 99.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9512555599212646, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.04874446243047714, \"precision\": 0.9979338645935059, \"recall\": 0.9512555599212646, \"specificity\": 0.9965065717697144, \"npv\": 0.9201613068580627, \"accuracy\": 0.9675692915916443, \"f1\": 0.9740357953113183, \"f2\": 0.9602385685884692, \"f0_5\": 0.9882352941176471, \"p4\": 0.9653477979984382, \"phi\": 0.9328106994083892}, {\"truth_threshold\": -10.567228050702756, \"match_probability\": 0.0006586599230816077, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1931.0, \"tn\": 1141.0, \"fp\": 4.0, \"fn\": 100.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9507631659507751, \"tn_rate\": 0.9965065717697144, \"fp_rate\": 0.0034934498835355043, \"fn_rate\": 0.049236830323934555, \"precision\": 0.9979327917098999, \"recall\": 0.9507631659507751, \"specificity\": 0.9965065717697144, \"npv\": 0.9194198250770569, \"accuracy\": 0.9672544002532959, \"f1\": 0.9737771053958648, \"f2\": 0.9598369619246446, \"f0_5\": 0.9881281342748951, \"p4\": 0.9650166459131119, \"phi\": 0.9321911706918252}, {\"truth_threshold\": -10.472462576911175, \"match_probability\": 0.0007033460763833586, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1930.0, \"tn\": 1142.0, \"fp\": 3.0, \"fn\": 101.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9502708315849304, \"tn_rate\": 0.9973798990249634, \"fp_rate\": 0.0026200872380286455, \"fn_rate\": 0.04972919821739197, \"precision\": 0.9984480142593384, \"recall\": 0.9502708315849304, \"specificity\": 0.9973798990249634, \"npv\": 0.9187449812889099, \"accuracy\": 0.9672544002532959, \"f1\": 0.9737638748738647, \"f2\": 0.9595306751516357, \"f0_5\": 0.9884256888251562, \"p4\": 0.9650287311531166, \"phi\": 0.9322974759210934}, {\"truth_threshold\": -10.465307487567683, \"match_probability\": 0.0007068405349787463, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1929.0, \"tn\": 1142.0, \"fp\": 3.0, \"fn\": 102.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9497784376144409, \"tn_rate\": 0.9973798990249634, \"fp_rate\": 0.0026200872380286455, \"fn_rate\": 0.05022156611084938, \"precision\": 0.9984471797943115, \"recall\": 0.9497784376144409, \"specificity\": 0.9973798990249634, \"npv\": 0.918006420135498, \"accuracy\": 0.9669395685195923, \"f1\": 0.9735049205147616, \"f2\": 0.959128878281623, \"f0_5\": 0.988318475253612, \"p4\": 0.9646977757151833, \"phi\": 0.9316795107545506}, {\"truth_threshold\": -10.456329997229092, \"match_probability\": 0.0007112495827092601, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1929.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 102.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9497784376144409, \"tn_rate\": 0.9982532858848572, \"fp_rate\": 0.0017467249417677522, \"fn_rate\": 0.05022156611084938, \"precision\": 0.998964250087738, \"recall\": 0.9497784376144409, \"specificity\": 0.9982532858848572, \"npv\": 0.9180722832679749, \"accuracy\": 0.9672544002532959, \"f1\": 0.9737506309944473, \"f2\": 0.9592242665340627, \"f0_5\": 0.9887237314197848, \"p4\": 0.9650407774435281, \"phi\": 0.9324053486027188}, {\"truth_threshold\": -10.33172550859186, \"match_probability\": 0.0007753608158132234, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1928.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 103.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9492860436439514, \"tn_rate\": 0.9982532858848572, \"fp_rate\": 0.0017467249417677522, \"fn_rate\": 0.05071393400430679, \"precision\": 0.9989637136459351, \"recall\": 0.9492860436439514, \"specificity\": 0.9982532858848572, \"npv\": 0.9173354506492615, \"accuracy\": 0.9669395685195923, \"f1\": 0.9734915425397627, \"f2\": 0.958822359259996, \"f0_5\": 0.9886165521484976, \"p4\": 0.9647099226891706, \"phi\": 0.9317883579853267}, {\"truth_threshold\": -10.22611195973064, \"match_probability\": 0.0008342017962744337, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1925.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 106.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9478089809417725, \"tn_rate\": 0.9982532858848572, \"fp_rate\": 0.0017467249417677522, \"fn_rate\": 0.05219103768467903, \"precision\": 0.9989621043205261, \"recall\": 0.9478089809417725, \"specificity\": 0.9982532858848572, \"npv\": 0.9151321053504944, \"accuracy\": 0.9659949541091919, \"f1\": 0.9727134916624558, \"f2\": 0.9576161575962591, \"f0_5\": 0.9882944860868672, \"p4\": 0.9637179269864672, \"phi\": 0.9299408716080212}, {\"truth_threshold\": -10.1932955913953, \"match_probability\": 0.0008533781062867135, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1922.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 109.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9463318586349487, \"tn_rate\": 0.9982532858848572, \"fp_rate\": 0.0017467249417677522, \"fn_rate\": 0.05366814509034157, \"precision\": 0.9989604949951172, \"recall\": 0.9463318586349487, \"specificity\": 0.9982532858848572, \"npv\": 0.9129393100738525, \"accuracy\": 0.9650503993034363, \"f1\": 0.9719342604298357, \"f2\": 0.9564092356687898, \"f0_5\": 0.987971625372674, \"p4\": 0.9627267806133902, \"phi\": 0.9280985877867722}, {\"truth_threshold\": -9.969377874754736, \"match_probability\": 0.0009965181737949496, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1921.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 110.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9458394646644592, \"tn_rate\": 0.9982532858848572, \"fp_rate\": 0.0017467249417677522, \"fn_rate\": 0.05416051298379898, \"precision\": 0.9989599585533142, \"recall\": 0.9458394646644592, \"specificity\": 0.9982532858848572, \"npv\": 0.9122107028961182, \"accuracy\": 0.9647355079650879, \"f1\": 0.9716742539200809, \"f2\": 0.9560067681895094, \"f0_5\": 0.9878638280366142, \"p4\": 0.9623965864487978, \"phi\": 0.9274856436324254}, {\"truth_threshold\": -9.921816767208316, \"match_probability\": 0.0010298833534097493, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1919.0, \"tn\": 1143.0, \"fp\": 2.0, \"fn\": 112.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.944854736328125, \"tn_rate\": 0.9982532858848572, \"fp_rate\": 0.0017467249417677522, \"fn_rate\": 0.055145248770713806, \"precision\": 0.9989588856697083, \"recall\": 0.944854736328125, \"specificity\": 0.9982532858848572, \"npv\": 0.9107569456100464, \"accuracy\": 0.9641057848930359, \"f1\": 0.9711538461538461, \"f2\": 0.9552015928322548, \"f0_5\": 0.9876479670612455, \"p4\": 0.9617364790562831, \"phi\": 0.9262614737556426}, {\"truth_threshold\": -9.880344986846527, \"match_probability\": 0.0010598862171977289, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1919.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 112.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.944854736328125, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.055145248770713806, \"precision\": 0.9994791746139526, \"recall\": 0.944854736328125, \"specificity\": 0.9991266131401062, \"npv\": 0.9108280539512634, \"accuracy\": 0.9644206762313843, \"f1\": 0.9713996456593268, \"f2\": 0.9552966945440063, \"f0_5\": 0.9880547832355061, \"p4\": 0.9620793861339125, \"phi\": 0.9269913956310123}, {\"truth_threshold\": -9.726120391082766, \"match_probability\": 0.0011793251063204845, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1918.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 113.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9443624019622803, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.05563761666417122, \"precision\": 0.9994788765907288, \"recall\": 0.9443624019622803, \"specificity\": 0.9991266131401062, \"npv\": 0.910103440284729, \"accuracy\": 0.9641057848930359, \"f1\": 0.9711392405063292, \"f2\": 0.9548939559892462, \"f0_5\": 0.9879468424848048, \"p4\": 0.9617494769794241, \"phi\": 0.9263805527908022}, {\"truth_threshold\": -9.637744981411675, \"match_probability\": 0.001253732371039733, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1916.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 115.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.943377673625946, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.056622352451086044, \"precision\": 0.9994783401489258, \"recall\": 0.943377673625946, \"specificity\": 0.9991266131401062, \"npv\": 0.9086576700210571, \"accuracy\": 0.9634760618209839, \"f1\": 0.9706180344478217, \"f2\": 0.9540882382232845, \"f0_5\": 0.9877306938859677, \"p4\": 0.9610899377544238, \"phi\": 0.9251605730611465}, {\"truth_threshold\": -9.597714679207227, \"match_probability\": 0.0012889611922700193, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1900.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 131.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9354997277259827, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06450024247169495, \"precision\": 0.9994739890098572, \"recall\": 0.9354997277259827, \"specificity\": 0.9991266131401062, \"npv\": 0.8972548842430115, \"accuracy\": 0.9584382772445679, \"f1\": 0.9664292980671414, \"f2\": 0.9476309226932669, \"f0_5\": 0.9859885832900882, \"p4\": 0.9558268676353927, \"phi\": 0.9154815461248219}, {\"truth_threshold\": -9.357481433629669, \"match_probability\": 0.0015221443574108086, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1898.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 133.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9345149993896484, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06548498570919037, \"precision\": 0.9994733929634094, \"recall\": 0.9345149993896484, \"specificity\": 0.9991266131401062, \"npv\": 0.8958496451377869, \"accuracy\": 0.9578085541725159, \"f1\": 0.9659033078880407, \"f2\": 0.9468223086900129, \"f0_5\": 0.9857691908174925, \"p4\": 0.9551706192848115, \"phi\": 0.9142816296577047}, {\"truth_threshold\": -9.251867884768446, \"match_probability\": 0.001637564754883093, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1897.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 134.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9340226650238037, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06597734987735748, \"precision\": 0.9994731545448303, \"recall\": 0.9340226650238037, \"specificity\": 0.9991266131401062, \"npv\": 0.8951486945152283, \"accuracy\": 0.9574937224388123, \"f1\": 0.9656401119877831, \"f2\": 0.9464178806625424, \"f0_5\": 0.9856593577886315, \"p4\": 0.9548426298070212, \"phi\": 0.9136824906936208}, {\"truth_threshold\": -9.1932955913953, \"match_probability\": 0.001705300946081411, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1896.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 135.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9335302710533142, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.0664697214961052, \"precision\": 0.9994728565216064, \"recall\": 0.9335302710533142, \"specificity\": 0.9991266131401062, \"npv\": 0.8944488167762756, \"accuracy\": 0.9571788311004639, \"f1\": 0.9653767820773931, \"f2\": 0.9460133719189702, \"f0_5\": 0.9855494334130367, \"p4\": 0.9545147299048048, \"phi\": 0.9130838964009184}, {\"truth_threshold\": -9.074203512331549, \"match_probability\": 0.001851772353844814, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1895.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 136.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9330379366874695, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06696208566427231, \"precision\": 0.9994725584983826, \"recall\": 0.9330379366874695, \"specificity\": 0.9991266131401062, \"npv\": 0.893750011920929, \"accuracy\": 0.9568639993667603, \"f1\": 0.9651133180544945, \"f2\": 0.9456087824351297, \"f0_5\": 0.9854394175767031, \"p4\": 0.954186919411087, \"phi\": 0.9124858456520881}, {\"truth_threshold\": -9.02874735148964, \"match_probability\": 0.0019109332721339533, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1894.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 137.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.93254554271698, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06745445728302002, \"precision\": 0.9994723200798035, \"recall\": 0.93254554271698, \"specificity\": 0.9991266131401062, \"npv\": 0.8930522799491882, \"accuracy\": 0.9565491080284119, \"f1\": 0.9648497198166073, \"f2\": 0.945204112186845, \"f0_5\": 0.9853293101654355, \"p4\": 0.9538591981587878, \"phi\": 0.9118883373225621}, {\"truth_threshold\": -8.967302441256914, \"match_probability\": 0.001993912863511404, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1893.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 138.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9320531487464905, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06794682145118713, \"precision\": 0.9994720220565796, \"recall\": 0.9320531487464905, \"specificity\": 0.9991266131401062, \"npv\": 0.8923556804656982, \"accuracy\": 0.9562342762947083, \"f1\": 0.9645859872611465, \"f2\": 0.9447993611499301, \"f0_5\": 0.9852191110648485, \"p4\": 0.9535315659808217, \"phi\": 0.9112913702907031}, {\"truth_threshold\": -8.952303395712788, \"match_probability\": 0.0020147088218047046, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1892.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 139.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9315608143806458, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06843919306993484, \"precision\": 0.9994717240333557, \"recall\": 0.9315608143806458, \"specificity\": 0.9991266131401062, \"npv\": 0.8916601538658142, \"accuracy\": 0.9559193849563599, \"f1\": 0.9643221202854231, \"f2\": 0.9443945293001896, \"f0_5\": 0.9851088201603666, \"p4\": 0.9532040227100975, \"phi\": 0.9106949434377939}, {\"truth_threshold\": -8.933466444012232, \"match_probability\": 0.002041132869425174, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1891.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 140.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9310684204101562, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06893155723810196, \"precision\": 0.9994714856147766, \"recall\": 0.9310684204101562, \"specificity\": 0.9991266131401062, \"npv\": 0.8909657597541809, \"accuracy\": 0.9556045532226562, \"f1\": 0.9640581187866428, \"f2\": 0.9439896166134185, \"f0_5\": 0.9849984373372226, \"p4\": 0.9528765681795183, \"phi\": 0.9100990556480278}, {\"truth_threshold\": -8.867460447955292, \"match_probability\": 0.002136483603520625, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1889.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 142.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.930083692073822, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.06991630047559738, \"precision\": 0.9994708895683289, \"recall\": 0.930083692073822, \"specificity\": 0.9991266131401062, \"npv\": 0.8895800709724426, \"accuracy\": 0.9549748301506042, \"f1\": 0.9635297118082122, \"f2\": 0.9431795486319153, \"f0_5\": 0.9847773954749244, \"p4\": 0.9522219246703738, \"phi\": 0.908908892809184}, {\"truth_threshold\": -8.86490118955693, \"match_probability\": 0.0021402688478976604, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1888.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 143.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9295913577079773, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.0704086646437645, \"precision\": 0.999470591545105, \"recall\": 0.9295913577079773, \"specificity\": 0.9991266131401062, \"npv\": 0.8888888955116272, \"accuracy\": 0.9546599388122559, \"f1\": 0.963265306122449, \"f2\": 0.9427743932887247, \"f0_5\": 0.984666736205278, \"p4\": 0.9518947353575811, \"phi\": 0.908314615542949}, {\"truth_threshold\": -8.828645716456823, \"match_probability\": 0.0021946166056728044, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1887.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 144.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9290989637374878, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.07090103626251221, \"precision\": 0.9994703531265259, \"recall\": 0.9290989637374878, \"specificity\": 0.9991266131401062, \"npv\": 0.888198733329773, \"accuracy\": 0.9543451070785522, \"f1\": 0.9630007655014035, \"f2\": 0.9423691570115861, \"f0_5\": 0.9845559845559846, \"p4\": 0.9515676341164773, \"phi\": 0.907720872905522}, {\"truth_threshold\": -8.827852895151011, \"match_probability\": 0.0021958203218311522, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1881.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 150.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9261447787284851, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.07385524362325668, \"precision\": 0.9994686245918274, \"recall\": 0.9261447787284851, \"specificity\": 0.9991266131401062, \"npv\": 0.8840803503990173, \"accuracy\": 0.9524559378623962, \"f1\": 0.9614106823409149, \"f2\": 0.9399360383769738, \"f0_5\": 0.9838895281933256, \"p4\": 0.9496068668152875, \"phi\": 0.904169582805711}, {\"truth_threshold\": -8.792646736347939, \"match_probability\": 0.002249942154883597, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1879.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 152.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9251599907875061, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.07483997941017151, \"precision\": 0.9994680881500244, \"recall\": 0.9251599907875061, \"specificity\": 0.9991266131401062, \"npv\": 0.8827160596847534, \"accuracy\": 0.9518262147903442, \"f1\": 0.9608795704423421, \"f2\": 0.939124350259896, \"f0_5\": 0.9836666317663072, \"p4\": 0.9489539747106858, \"phi\": 0.9029900468694608}, {\"truth_threshold\": -8.756607019587237, \"match_probability\": 0.0023067242010360186, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1878.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 153.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9246676564216614, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.07533235102891922, \"precision\": 0.9994677901268005, \"recall\": 0.9246676564216614, \"specificity\": 0.9991266131401062, \"npv\": 0.882035493850708, \"accuracy\": 0.9515113234519958, \"f1\": 0.960613810741688, \"f2\": 0.9387183844846546, \"f0_5\": 0.9835550434691526, \"p4\": 0.9486276585927369, \"phi\": 0.9024010666675019}, {\"truth_threshold\": -8.668231609916146, \"match_probability\": 0.0024520879323333125, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1872.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 159.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9217134714126587, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.0782865583896637, \"precision\": 0.9994661211967468, \"recall\": 0.9217134714126587, \"specificity\": 0.9991266131401062, \"npv\": 0.8779739141464233, \"accuracy\": 0.9496221542358398, \"f1\": 0.9590163934426229, \"f2\": 0.9362808842652796, \"f0_5\": 0.9828835451013336, \"p4\": 0.9466715704303053, \"phi\": 0.8988781465588541}, {\"truth_threshold\": -8.663500906449483, \"match_probability\": 0.002460121893530931, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1867.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 164.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9192516207695007, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.08074840158224106, \"precision\": 0.9994646906852722, \"recall\": 0.9192516207695007, \"specificity\": 0.9991266131401062, \"npv\": 0.8746177554130554, \"accuracy\": 0.9480478763580322, \"f1\": 0.9576814567837907, \"f2\": 0.9342473979183347, \"f0_5\": 0.9823213721982532, \"p4\": 0.9450438468942138, \"phi\": 0.8959566166075553}, {\"truth_threshold\": -8.49323799400942, \"match_probability\": 0.0027674326259274243, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1861.0, \"tn\": 1144.0, \"fp\": 1.0, \"fn\": 170.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9162973761558533, \"tn_rate\": 0.9991266131401062, \"fp_rate\": 0.0008733624708838761, \"fn_rate\": 0.08370260894298553, \"precision\": 0.9994629621505737, \"recall\": 0.9162973761558533, \"specificity\": 0.9991266131401062, \"npv\": 0.8706240653991699, \"accuracy\": 0.9461587071418762, \"f1\": 0.9560750064217827, \"f2\": 0.9318045263368716, \"f0_5\": 0.9816436332946513, \"p4\": 0.9430933672772714, \"phi\": 0.8924676681686041}, {\"truth_threshold\": -8.456329997229092, \"match_probability\": 0.00283894074457729, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1859.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 172.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.915312647819519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08468734472990036, \"precision\": 1.0, \"recall\": 0.915312647819519, \"specificity\": 1.0, \"npv\": 0.869400143623352, \"accuracy\": 0.9458438158035278, \"f1\": 0.9557840616966581, \"f2\": 0.93108284082941, \"f0_5\": 0.9818316256469842, \"p4\": 0.9427867053899786, \"phi\": 0.8920610742936573}, {\"truth_threshold\": -8.443445458337857, \"match_probability\": 0.0028643355961717534, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1857.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 174.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9143279194831848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08567208051681519, \"precision\": 1.0, \"recall\": 0.9143279194831848, \"specificity\": 1.0, \"npv\": 0.8680818676948547, \"accuracy\": 0.9452140927314758, \"f1\": 0.9552469135802469, \"f2\": 0.9302675082657048, \"f0_5\": 0.981604820805582, \"p4\": 0.9421375437999479, \"phi\": 0.8909048757105602}, {\"truth_threshold\": -8.386559541411758, \"match_probability\": 0.0029791902677590554, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1856.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 175.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9138355255126953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0861644521355629, \"precision\": 1.0, \"recall\": 0.9138355255126953, \"specificity\": 1.0, \"npv\": 0.8674242496490479, \"accuracy\": 0.9448992609977722, \"f1\": 0.9549781322356573, \"f2\": 0.9298597194388778, \"f0_5\": 0.9814912744579588, \"p4\": 0.9418130872496234, \"phi\": 0.8903275289372737}, {\"truth_threshold\": -8.265831603259679, \"match_probability\": 0.003238381835174974, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1855.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 176.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9133431911468506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08665681630373001, \"precision\": 1.0, \"recall\": 0.9133431911468506, \"specificity\": 1.0, \"npv\": 0.8667675852775574, \"accuracy\": 0.9445843696594238, \"f1\": 0.9547092125579002, \"f2\": 0.9294518488826535, \"f0_5\": 0.9813776319966141, \"p4\": 0.9414887133057769, \"phi\": 0.8897506824878196}, {\"truth_threshold\": -8.257735451898524, \"match_probability\": 0.00325654680532825, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1854.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 177.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9128507971763611, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08714918792247772, \"precision\": 1.0, \"recall\": 0.9128507971763611, \"specificity\": 1.0, \"npv\": 0.8661119341850281, \"accuracy\": 0.9442695379257202, \"f1\": 0.9544401544401544, \"f2\": 0.9290438965724594, \"f0_5\": 0.9812638932994602, \"p4\": 0.9411644218008959, \"phi\": 0.8891743353491296}, {\"truth_threshold\": -8.24027873813786, \"match_probability\": 0.0032960599503189425, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1853.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 178.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9123584628105164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08764155954122543, \"precision\": 1.0, \"recall\": 0.9123584628105164, \"specificity\": 1.0, \"npv\": 0.86545729637146, \"accuracy\": 0.9439546465873718, \"f1\": 0.9541709577754892, \"f2\": 0.9286358624837125, \"f0_5\": 0.9811500582442021, \"p4\": 0.9408402125674472, \"phi\": 0.8885984865106743}, {\"truth_threshold\": -8.152121903037303, \"match_probability\": 0.0035030211965550767, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1850.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 181.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9108813405036926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08911865949630737, \"precision\": 1.0, \"recall\": 0.9108813405036926, \"specificity\": 1.0, \"npv\": 0.8634992241859436, \"accuracy\": 0.9430100917816162, \"f1\": 0.9533625354290132, \"f2\": 0.9274112693001805, \"f0_5\": 0.980807973703743, \"p4\": 0.9398680768200446, \"phi\": 0.8868739197293399}, {\"truth_threshold\": -7.983779341394526, \"match_probability\": 0.003934872593998914, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1848.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 183.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9098966121673584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0901033952832222, \"precision\": 1.0, \"recall\": 0.9098966121673584, \"specificity\": 1.0, \"npv\": 0.8621987700462341, \"accuracy\": 0.9423803687095642, \"f1\": 0.9528228924980665, \"f2\": 0.9265944645006017, \"f0_5\": 0.9805794333014963, \"p4\": 0.9392203946065271, \"phi\": 0.8857266816300843}, {\"truth_threshold\": -7.9697268271337425, \"match_probability\": 0.003973234308681651, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1847.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 184.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9094042181968689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09059576690196991, \"precision\": 1.0, \"recall\": 0.9094042181968689, \"specificity\": 1.0, \"npv\": 0.8615500330924988, \"accuracy\": 0.9420654773712158, \"f1\": 0.9525528623001547, \"f2\": 0.9261859392237489, \"f0_5\": 0.9804650175177833, \"p4\": 0.9388966754822644, \"phi\": 0.8851538015130517}, {\"truth_threshold\": -7.967302441256913, \"match_probability\": 0.003979890172811879, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1846.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 185.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9089118838310242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09108813107013702, \"precision\": 1.0, \"recall\": 0.9089118838310242, \"specificity\": 1.0, \"npv\": 0.8609022498130798, \"accuracy\": 0.9417506456375122, \"f1\": 0.9522826928037142, \"f2\": 0.925777331995988, \"f0_5\": 0.9803505045140732, \"p4\": 0.9385730374560877, \"phi\": 0.8845814126929296}, {\"truth_threshold\": -7.962571737790251, \"match_probability\": 0.003992909751815418, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1845.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 186.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9084194898605347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09158050268888474, \"precision\": 1.0, \"recall\": 0.9084194898605347, \"specificity\": 1.0, \"npv\": 0.8602554202079773, \"accuracy\": 0.9414357542991638, \"f1\": 0.9520123839009288, \"f2\": 0.9253686427926573, \"f0_5\": 0.980235894166401, \"p4\": 0.9382494803602835, \"phi\": 0.8840095141791932}, {\"truth_threshold\": -7.890657114594738, \"match_probability\": 0.004196133831016723, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1844.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 187.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9079271554946899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09207286685705185, \"precision\": 1.0, \"recall\": 0.9079271554946899, \"specificity\": 1.0, \"npv\": 0.8596096038818359, \"accuracy\": 0.9411209225654602, \"f1\": 0.951741935483871, \"f2\": 0.9249598715890851, \"f0_5\": 0.98012118635059, \"p4\": 0.9379260040271141, \"phi\": 0.8834381049837795}, {\"truth_threshold\": -7.828989758814427, \"match_probability\": 0.00437858190096816, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1843.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 188.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9074347615242004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09256523847579956, \"precision\": 1.0, \"recall\": 0.9074347615242004, \"specificity\": 1.0, \"npv\": 0.858964741230011, \"accuracy\": 0.9408060312271118, \"f1\": 0.9514713474445018, \"f2\": 0.92455101836059, \"f0_5\": 0.9800063809422525, \"p4\": 0.937602608288817, \"phi\": 0.8828671841210791}, {\"truth_threshold\": -7.817591014624138, \"match_probability\": 0.004413160859157262, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1841.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 190.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9064500331878662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09354997426271439, \"precision\": 1.0, \"recall\": 0.9064500331878662, \"specificity\": 1.0, \"npv\": 0.8576778769493103, \"accuracy\": 0.9401763081550598, \"f1\": 0.9509297520661157, \"f2\": 0.9237330657300552, \"f0_5\": 0.979776476849388, \"p4\": 0.9369560579256638, \"phi\": 0.881726803463596}, {\"truth_threshold\": -7.762983762757487, \"match_probability\": 0.0045826242502146515, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1839.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 192.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.905465304851532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09453471004962921, \"precision\": 1.0, \"recall\": 0.905465304851532, \"specificity\": 1.0, \"npv\": 0.85639488697052, \"accuracy\": 0.9395465850830078, \"f1\": 0.9503875968992248, \"f2\": 0.9229147847034026, \"f0_5\": 0.9795461808884628, \"p4\": 0.9363098279282152, \"phi\": 0.8805883643706148}, {\"truth_threshold\": -7.723376209953205, \"match_probability\": 0.004709577176107294, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1831.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 200.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9015263319015503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09847366064786911, \"precision\": 1.0, \"recall\": 0.9015263319015503, \"specificity\": 1.0, \"npv\": 0.8513011336326599, \"accuracy\": 0.9370276927947998, \"f1\": 0.9482133609528741, \"f2\": 0.9196383726770467, \"f0_5\": 0.9786210582576162, \"p4\": 0.9337280847282874, \"phi\": 0.876053868270657}, {\"truth_threshold\": -7.652130334389431, \"match_probability\": 0.004946813455800196, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1829.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 202.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.9005416035652161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09945839643478394, \"precision\": 1.0, \"recall\": 0.9005416035652161, \"specificity\": 1.0, \"npv\": 0.8500370979309082, \"accuracy\": 0.9363979697227478, \"f1\": 0.9476683937823834, \"f2\": 0.9188184466994876, \"f0_5\": 0.9783887878463678, \"p4\": 0.9330834364050486, \"phi\": 0.8749250208040935}, {\"truth_threshold\": -7.584577086373497, \"match_probability\": 0.005182724351357307, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1820.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 211.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8961102962493896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10388971120119095, \"precision\": 1.0, \"recall\": 0.8961102962493896, \"specificity\": 1.0, \"npv\": 0.8443952798843384, \"accuracy\": 0.9335642457008362, \"f1\": 0.9452090366138666, \"f2\": 0.915124698310539, \"f0_5\": 0.9773386317259156, \"p4\": 0.9301863642374388, \"phi\": 0.8698685532118136}, {\"truth_threshold\": -7.56375492471834, \"match_probability\": 0.005257671963616819, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1812.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 219.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.892171323299408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10782865434885025, \"precision\": 1.0, \"recall\": 0.892171323299408, \"specificity\": 1.0, \"npv\": 0.839442789554596, \"accuracy\": 0.9310453534126282, \"f1\": 0.9430132708821234, \"f2\": 0.9118357487922706, \"f0_5\": 0.9763983187843518, \"p4\": 0.9276163988704911, \"phi\": 0.8654055840072653}, {\"truth_threshold\": -7.559024221251677, \"match_probability\": 0.005274849465643759, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1806.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 225.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8892171382904053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11078286916017532, \"precision\": 1.0, \"recall\": 0.8892171382904053, \"specificity\": 1.0, \"npv\": 0.8357664346694946, \"accuracy\": 0.9291561841964722, \"f1\": 0.9413604378420641, \"f2\": 0.9093655589123867, \"f0_5\": 0.9756888168557536, \"p4\": 0.9256920884275059, \"phi\": 0.8620776206465783}, {\"truth_threshold\": -7.424228445255649, \"match_probability\": 0.0057884640622339, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1803.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 228.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8877400159835815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11225996911525726, \"precision\": 1.0, \"recall\": 0.8877400159835815, \"specificity\": 1.0, \"npv\": 0.8339402675628662, \"accuracy\": 0.9282115697860718, \"f1\": 0.9405320813771518, \"f2\": 0.908129344212753, \"f0_5\": 0.9753326841934437, \"p4\": 0.9247309371543908, \"phi\": 0.8604197614727223}, {\"truth_threshold\": -7.286891422024203, \"match_probability\": 0.0063628971989131596, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1801.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 230.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8867552876472473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11324470490217209, \"precision\": 1.0, \"recall\": 0.8867552876472473, \"specificity\": 1.0, \"npv\": 0.8327272534370422, \"accuracy\": 0.9275818467140198, \"f1\": 0.9399791231732777, \"f2\": 0.9073047858942066, \"f0_5\": 0.9750947482403898, \"p4\": 0.9240905383726037, \"phi\": 0.859316773188056}, {\"truth_threshold\": -7.283491376936333, \"match_probability\": 0.006377814772263548, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1799.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 232.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8857705593109131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11422944068908691, \"precision\": 1.0, \"recall\": 0.8857705593109131, \"specificity\": 1.0, \"npv\": 0.8315178155899048, \"accuracy\": 0.9269521236419678, \"f1\": 0.9394255874673629, \"f2\": 0.906479895192986, \"f0_5\": 0.9748563996965428, \"p4\": 0.9234504329987309, \"phi\": 0.8582155775352254}, {\"truth_threshold\": -7.2233846413053335, \"match_probability\": 0.006647341810259093, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1797.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 234.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8847858309745789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11521418392658234, \"precision\": 1.0, \"recall\": 0.8847858309745789, \"specificity\": 1.0, \"npv\": 0.8303118348121643, \"accuracy\": 0.9263224005699158, \"f1\": 0.9388714733542319, \"f2\": 0.9056546719080738, \"f0_5\": 0.974617637487797, \"p4\": 0.9228106196785895, \"phi\": 0.8571161674381387}, {\"truth_threshold\": -7.1699480091414065, \"match_probability\": 0.006896442499221208, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1795.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 236.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8838011026382446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11619891971349716, \"precision\": 1.0, \"recall\": 0.8838011026382446, \"specificity\": 1.0, \"npv\": 0.8291093707084656, \"accuracy\": 0.9256926774978638, \"f1\": 0.9383167799268165, \"f2\": 0.9048291158382902, \"f0_5\": 0.9743784605363153, \"p4\": 0.9221710970572993, \"phi\": 0.8560185358542695}, {\"truth_threshold\": -7.1605620967560615, \"match_probability\": 0.006941143325604217, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1793.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 238.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8828163743019104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11718365550041199, \"precision\": 1.0, \"recall\": 0.8828163743019104, \"specificity\": 1.0, \"npv\": 0.8279103636741638, \"accuracy\": 0.9250629544258118, \"f1\": 0.9377615062761506, \"f2\": 0.9040032267822931, \"f0_5\": 0.9741388677605128, \"p4\": 0.9215318637792689, \"phi\": 0.8549226757744313}, {\"truth_threshold\": -7.1145748312353, \"match_probability\": 0.0071643522636525726, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1792.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 239.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8823239803314209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1176760196685791, \"precision\": 1.0, \"recall\": 0.8823239803314209, \"specificity\": 1.0, \"npv\": 0.8273121118545532, \"accuracy\": 0.9247481226921082, \"f1\": 0.9374836515825268, \"f2\": 0.9035901573215006, \"f0_5\": 0.9740189150994674, \"p4\": 0.9212123552201559, \"phi\": 0.8543754078672149}, {\"truth_threshold\": -7.095771750735604, \"match_probability\": 0.007257656457229457, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1791.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 240.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8818315863609314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11816839128732681, \"precision\": 1.0, \"recall\": 0.8818315863609314, \"specificity\": 1.0, \"npv\": 0.826714813709259, \"accuracy\": 0.9244332313537598, \"f1\": 0.9372056514913658, \"f2\": 0.903177004538578, \"f0_5\": 0.9738988580750407, \"p4\": 0.9208929184881818, \"phi\": 0.8538285802225557}, {\"truth_threshold\": -7.070247626280196, \"match_probability\": 0.007386244456299417, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1789.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 242.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8808468580245972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11915312707424164, \"precision\": 1.0, \"recall\": 0.8808468580245972, \"specificity\": 1.0, \"npv\": 0.8255227208137512, \"accuracy\": 0.9238035082817078, \"f1\": 0.9366492146596859, \"f2\": 0.9023504489054777, \"f0_5\": 0.9736584303907696, \"p4\": 0.9202542598269833, \"phi\": 0.8527362422554705}, {\"truth_threshold\": -7.05235234077408, \"match_probability\": 0.00747774513518201, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1788.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 243.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8803545236587524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11964549124240875, \"precision\": 1.0, \"recall\": 0.8803545236587524, \"specificity\": 1.0, \"npv\": 0.8249279260635376, \"accuracy\": 0.9234886765480042, \"f1\": 0.9363707776904949, \"f2\": 0.9019370460048426, \"f0_5\": 0.9735380594576936, \"p4\": 0.9199350375583073, \"phi\": 0.8521907302054237}, {\"truth_threshold\": -6.989093298137943, \"match_probability\": 0.007810304875558106, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1787.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 244.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8798621296882629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12013786286115646, \"precision\": 1.0, \"recall\": 0.8798621296882629, \"specificity\": 1.0, \"npv\": 0.8243340253829956, \"accuracy\": 0.9231737852096558, \"f1\": 0.9360921948664223, \"f2\": 0.9015235596811624, \"f0_5\": 0.9734175836147728, \"p4\": 0.9196158864378663, \"phi\": 0.8516456549626794}, {\"truth_threshold\": -6.859476387318898, \"match_probability\": 0.008538229535440275, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1786.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 245.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8793697953224182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12063023447990417, \"precision\": 1.0, \"recall\": 0.8793697953224182, \"specificity\": 1.0, \"npv\": 0.8237410187721252, \"accuracy\": 0.9228589534759521, \"f1\": 0.9358134660728321, \"f2\": 0.9011099899091827, \"f0_5\": 0.9732970027247957, \"p4\": 0.9192968062958145, \"phi\": 0.8511010156684959}, {\"truth_threshold\": -6.855538505158046, \"match_probability\": 0.008561366942429106, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1784.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 247.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8783850073814392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.121614970266819, \"precision\": 1.0, \"recall\": 0.8783850073814392, \"specificity\": 1.0, \"npv\": 0.8225574493408203, \"accuracy\": 0.9222292304039001, \"f1\": 0.9352555701179555, \"f2\": 0.9002825999192572, \"f0_5\": 0.9730555252536272, \"p4\": 0.9186588582672518, \"phi\": 0.8500130415009118}, {\"truth_threshold\": -6.854745683852235, \"match_probability\": 0.008566032752069483, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1783.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 248.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8778926730155945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12210733443498611, \"precision\": 1.0, \"recall\": 0.8778926730155945, \"specificity\": 1.0, \"npv\": 0.8219670057296753, \"accuracy\": 0.9219143390655518, \"f1\": 0.934976402726796, \"f2\": 0.899868779650752, \"f0_5\": 0.9729346283968132, \"p4\": 0.9183399900408039, \"phi\": 0.8494697049200762}, {\"truth_threshold\": -6.784258402617332, \"match_probability\": 0.00899108870160703, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1782.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 249.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.877400279045105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12259970605373383, \"precision\": 1.0, \"recall\": 0.877400279045105, \"specificity\": 1.0, \"npv\": 0.8213773369789124, \"accuracy\": 0.9215995073318481, \"f1\": 0.9346970889063729, \"f2\": 0.8994548758328286, \"f0_5\": 0.9728136259416967, \"p4\": 0.9180211921128707, \"phi\": 0.8489268008729182}, {\"truth_threshold\": -6.7538628384576755, \"match_probability\": 0.009180770386687832, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1781.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 250.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8769079446792603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12309207022190094, \"precision\": 1.0, \"recall\": 0.8769079446792603, \"specificity\": 1.0, \"npv\": 0.8207885026931763, \"accuracy\": 0.9212846159934998, \"f1\": 0.934417628541448, \"f2\": 0.8990408884401817, \"f0_5\": 0.9726925177498634, \"p4\": 0.9177024643133584, \"phi\": 0.8483843285107042}, {\"truth_threshold\": -6.749924956296825, \"match_probability\": 0.00920563282260519, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1780.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 251.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8764155507087708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12358444184064865, \"precision\": 1.0, \"recall\": 0.8764155507087708, \"specificity\": 1.0, \"npv\": 0.8202005624771118, \"accuracy\": 0.9209697842597961, \"f1\": 0.9341380215166623, \"f2\": 0.898626817447496, \"f0_5\": 0.9725713036826577, \"p4\": 0.9173838064721223, \"phi\": 0.8478422869866835}, {\"truth_threshold\": -6.749132134991013, \"match_probability\": 0.009210646485045264, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1779.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 252.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.875923216342926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12407680600881577, \"precision\": 1.0, \"recall\": 0.875923216342926, \"specificity\": 1.0, \"npv\": 0.8196134567260742, \"accuracy\": 0.9206548929214478, \"f1\": 0.9338582677165355, \"f2\": 0.8982126628294457, \"f0_5\": 0.9724499836011807, \"p4\": 0.9170652184189663, \"phi\": 0.8473006754560798}, {\"truth_threshold\": -6.589510849756149, \"match_probability\": 0.010277161223550295, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1778.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 253.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8754308223724365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12456917762756348, \"precision\": 1.0, \"recall\": 0.8754308223724365, \"specificity\": 1.0, \"npv\": 0.8190271854400635, \"accuracy\": 0.9203400611877441, \"f1\": 0.933578367025466, \"f2\": 0.8977984245606948, \"f0_5\": 0.9723285573662912, \"p4\": 0.9167466999836424, \"phi\": 0.8467594930760858}, {\"truth_threshold\": -6.572260583859927, \"match_probability\": 0.010399496960517127, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1763.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 268.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8680452704429626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13195469975471497, \"precision\": 1.0, \"recall\": 0.8680452704429626, \"specificity\": 1.0, \"npv\": 0.8103325963020325, \"accuracy\": 0.9156171083450317, \"f1\": 0.9293621507643648, \"f2\": 0.8915747951855972, \"f0_5\": 0.9704943300671585, \"p4\": 0.911977161661481, \"phi\": 0.8386926882892364}, {\"truth_threshold\": -6.526011601712208, \"match_probability\": 0.010734641799224388, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1762.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 269.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8675529360771179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13244706392288208, \"precision\": 1.0, \"recall\": 0.8675529360771179, \"specificity\": 1.0, \"npv\": 0.8097595572471619, \"accuracy\": 0.9153022766113281, \"f1\": 0.9290798839968363, \"f2\": 0.8911592150515881, \"f0_5\": 0.9703711862539928, \"p4\": 0.911659733913786, \"phi\": 0.8381582592786062}, {\"truth_threshold\": -6.450360467241166, \"match_probability\": 0.011306024039730288, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1760.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 271.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8665682077407837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1334318071603775, \"precision\": 1.0, \"recall\": 0.8665682077407837, \"specificity\": 1.0, \"npv\": 0.8086158037185669, \"accuracy\": 0.9146725535392761, \"f1\": 0.9285149037193353, \"f2\": 0.8903278025091056, \"f0_5\": 0.9701245728144636, \"p4\": 0.9110250783929349, \"phi\": 0.8370906458024485}, {\"truth_threshold\": -6.449567645935354, \"match_probability\": 0.011312168577302254, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1759.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 272.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8660758137702942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13392417132854462, \"precision\": 1.0, \"recall\": 0.8660758137702942, \"specificity\": 1.0, \"npv\": 0.8080451488494873, \"accuracy\": 0.9143576622009277, \"f1\": 0.9282321899736148, \"f2\": 0.8899119700495801, \"f0_5\": 0.9700011029006287, \"p4\": 0.9107078502772067, \"phi\": 0.8365574597218397}, {\"truth_threshold\": -6.440912769489744, \"match_probability\": 0.011379460846066189, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1757.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 274.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.86509108543396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13490891456604004, \"precision\": 1.0, \"recall\": 0.86509108543396, \"specificity\": 1.0, \"npv\": 0.8069062829017639, \"accuracy\": 0.9137279391288757, \"f1\": 0.9276663146779303, \"f2\": 0.8890800526262524, \"f0_5\": 0.9697538359642345, \"p4\": 0.9100735924782588, \"phi\": 0.8354923248516871}, {\"truth_threshold\": -6.419096397795695, \"match_probability\": 0.01155084546158717, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1756.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 275.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8645986914634705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13540127873420715, \"precision\": 1.0, \"recall\": 0.8645986914634705, \"specificity\": 1.0, \"npv\": 0.8063380122184753, \"accuracy\": 0.9134131073951721, \"f1\": 0.9273831528914708, \"f2\": 0.888663967611336, \"f0_5\": 0.969630038652678, \"p4\": 0.9097565624521012, \"phi\": 0.8349603744580988}, {\"truth_threshold\": -6.405408496744225, \"match_probability\": 0.011659674419447857, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1755.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 276.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8641063570976257, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13589364290237427, \"precision\": 1.0, \"recall\": 0.8641063570976257, \"specificity\": 1.0, \"npv\": 0.8057705760002136, \"accuracy\": 0.9130982160568237, \"f1\": 0.9270998415213946, \"f2\": 0.8882477983601579, \"f0_5\": 0.9695061319191249, \"p4\": 0.9094395981127592, \"phi\": 0.8344288343591847}, {\"truth_threshold\": -6.350088681471034, \"match_probability\": 0.012109925014980294, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1754.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 277.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8636139631271362, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13638602197170258, \"precision\": 1.0, \"recall\": 0.8636139631271362, \"specificity\": 1.0, \"npv\": 0.805203914642334, \"accuracy\": 0.9127833843231201, \"f1\": 0.9268163804491414, \"f2\": 0.887831544847135, \"f0_5\": 0.969382115618437, \"p4\": 0.9091226992886084, \"phi\": 0.8338977037574806}, {\"truth_threshold\": -6.325909966679389, \"match_probability\": 0.012312070579072958, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1753.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 278.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8631216287612915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1368783861398697, \"precision\": 1.0, \"recall\": 0.8631216287612915, \"specificity\": 1.0, \"npv\": 0.8046380877494812, \"accuracy\": 0.9124684929847717, \"f1\": 0.9265327695560254, \"f2\": 0.8874152070466741, \"f0_5\": 0.9692579896052195, \"p4\": 0.9088058658079613, \"phi\": 0.8333669818573352}, {\"truth_threshold\": -6.319751760057843, \"match_probability\": 0.012364086335669322, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1752.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 279.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.862629234790802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1373707503080368, \"precision\": 1.0, \"recall\": 0.862629234790802, \"specificity\": 1.0, \"npv\": 0.8040730357170105, \"accuracy\": 0.9121536612510681, \"f1\": 0.9262490087232356, \"f2\": 0.8869987849331713, \"f0_5\": 0.9691337537338202, \"p4\": 0.9084890974990668, \"phi\": 0.8328366678649031}, {\"truth_threshold\": -6.2546640911156155, \"match_probability\": 0.01292729438411004, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1749.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 282.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8611521124839783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13884785771369934, \"precision\": 1.0, \"recall\": 0.8611521124839783, \"specificity\": 1.0, \"npv\": 0.8023826479911804, \"accuracy\": 0.9112090468406677, \"f1\": 0.9253968253968254, \"f2\": 0.8857490124582194, \"f0_5\": 0.9687603855101362, \"p4\": 0.9075391818844284, \"phi\": 0.831248165422413}, {\"truth_threshold\": -6.253871269809804, \"match_probability\": 0.012934308514037356, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1745.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 286.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8591826558113098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.140817329287529, \"precision\": 1.0, \"recall\": 0.8591826558113098, \"specificity\": 1.0, \"npv\": 0.8001397848129272, \"accuracy\": 0.9099496006965637, \"f1\": 0.9242584745762712, \"f2\": 0.8840814672205898, \"f0_5\": 0.9682610143158362, \"p4\": 0.9062735297052606, \"phi\": 0.829135825027529}, {\"truth_threshold\": -6.221392429432036, \"match_probability\": 0.013224901479391689, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1742.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 289.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8577055931091309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14229443669319153, \"precision\": 1.0, \"recall\": 0.8577055931091309, \"specificity\": 1.0, \"npv\": 0.7984658479690552, \"accuracy\": 0.9090050458908081, \"f1\": 0.9234031274847602, \"f2\": 0.8828299209406041, \"f0_5\": 0.9678853205911768, \"p4\": 0.9053249610250113, \"phi\": 0.8275557894988181}, {\"truth_threshold\": -6.187110843099681, \"match_probability\": 0.013538611952504415, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1741.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 290.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8572131991386414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14278680086135864, \"precision\": 1.0, \"recall\": 0.8572131991386414, \"specificity\": 1.0, \"npv\": 0.7979093790054321, \"accuracy\": 0.9086901545524597, \"f1\": 0.9231177094379639, \"f2\": 0.8824125696908262, \"f0_5\": 0.9677598665925514, \"p4\": 0.9050088982512212, \"phi\": 0.827029910608251}, {\"truth_threshold\": -6.18631802179387, \"match_probability\": 0.013545953221032556, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1740.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 291.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8567208051681519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14327917993068695, \"precision\": 1.0, \"recall\": 0.8567208051681519, \"specificity\": 1.0, \"npv\": 0.7973537445068359, \"accuracy\": 0.9083753228187561, \"f1\": 0.9228321400159109, \"f2\": 0.8819951338199513, \"f0_5\": 0.9676343009676343, \"p4\": 0.9046928985830542, \"phi\": 0.8265044302380331}, {\"truth_threshold\": -6.1790146917385265, \"match_probability\": 0.01361376461750863, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1734.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 297.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8537666201591492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14623337984085083, \"precision\": 1.0, \"recall\": 0.8537666201591492, \"specificity\": 1.0, \"npv\": 0.7940360903739929, \"accuracy\": 0.9064861536026001, \"f1\": 0.9211155378486056, \"f2\": 0.8794887401095557, \"f0_5\": 0.9668785547005687, \"p4\": 0.9027982161205977, \"phi\": 0.8233598738946298}, {\"truth_threshold\": -6.166288681444525, \"match_probability\": 0.013732726397725012, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1732.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 299.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8527818918228149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14721812307834625, \"precision\": 1.0, \"recall\": 0.8527818918228149, \"specificity\": 1.0, \"npv\": 0.7929362654685974, \"accuracy\": 0.9058564305305481, \"f1\": 0.9205421206484188, \"f2\": 0.8786525974025974, \"f0_5\": 0.9666257394798526, \"p4\": 0.9021671523111625, \"phi\": 0.8223148418628785}, {\"truth_threshold\": -6.161557977977862, \"match_probability\": 0.013777209516174891, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1730.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 301.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8517971634864807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14820285141468048, \"precision\": 1.0, \"recall\": 0.8517971634864807, \"specificity\": 1.0, \"npv\": 0.7918395400047302, \"accuracy\": 0.9052267074584961, \"f1\": 0.9199680935921297, \"f2\": 0.8778161152831337, \"f0_5\": 0.9663724723494581, \"p4\": 0.9015363346996595, \"phi\": 0.8212713764087255}, {\"truth_threshold\": -6.073401142877305, \"match_probability\": 0.014632625545163466, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1729.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 302.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8513047695159912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1486952304840088, \"precision\": 1.0, \"recall\": 0.8513047695159912, \"specificity\": 1.0, \"npv\": 0.7912923097610474, \"accuracy\": 0.9049118161201477, \"f1\": 0.9196808510638298, \"f2\": 0.8773977468791231, \"f0_5\": 0.9662456689393093, \"p4\": 0.9012210177849239, \"phi\": 0.8207502292603889}, {\"truth_threshold\": -6.009508080436406, \"match_probability\": 0.015285101165909434, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1726.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 305.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8498276472091675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15017232298851013, \"precision\": 1.0, \"recall\": 0.8498276472091675, \"specificity\": 1.0, \"npv\": 0.7896551489830017, \"accuracy\": 0.9039672613143921, \"f1\": 0.9188182060154378, \"f2\": 0.8761421319796955, \"f0_5\": 0.965864577504197, \"p4\": 0.9002754325235871, \"phi\": 0.8191891211087271}, {\"truth_threshold\": -5.895736770440407, \"match_probability\": 0.016518573797404873, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1725.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 306.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8493353128433228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15066470205783844, \"precision\": 1.0, \"recall\": 0.8493353128433228, \"specificity\": 1.0, \"npv\": 0.7891109585762024, \"accuracy\": 0.9036523699760437, \"f1\": 0.9185303514376997, \"f2\": 0.8757234236978373, \"f0_5\": 0.9657373194491098, \"p4\": 0.8999603586855487, \"phi\": 0.8186695269929782}, {\"truth_threshold\": -5.883823791634325, \"match_probability\": 0.016653258842737825, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1724.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 307.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8488429188728333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15115706622600555, \"precision\": 1.0, \"recall\": 0.8488429188728333, \"specificity\": 1.0, \"npv\": 0.7885674834251404, \"accuracy\": 0.9033375382423401, \"f1\": 0.9182423435419441, \"f2\": 0.8753046303818034, \"f0_5\": 0.9656099473507337, \"p4\": 0.8996453451825817, \"phi\": 0.8181503192672758}, {\"truth_threshold\": -5.813854339952213, \"match_probability\": 0.01746637876014616, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1722.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 309.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.847858190536499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15214180946350098, \"precision\": 1.0, \"recall\": 0.847858190536499, \"specificity\": 1.0, \"npv\": 0.7874827980995178, \"accuracy\": 0.9027078151702881, \"f1\": 0.9176658673061551, \"f2\": 0.874466788543571, \"f0_5\": 0.9653548604103599, \"p4\": 0.8990154984866054, \"phi\": 0.817113060011865}, {\"truth_threshold\": -5.810293107442948, \"match_probability\": 0.01750879122044747, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1721.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 310.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8473658561706543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1526341736316681, \"precision\": 1.0, \"recall\": 0.8473658561706543, \"specificity\": 1.0, \"npv\": 0.7869415879249573, \"accuracy\": 0.9023929238319397, \"f1\": 0.9173773987206824, \"f2\": 0.8740477399695277, \"f0_5\": 0.9652271452607964, \"p4\": 0.8987006649457736, \"phi\": 0.8165950069991748}, {\"truth_threshold\": -5.807236493480818, \"match_probability\": 0.017545274587372144, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1720.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 311.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8468734622001648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1531265377998352, \"precision\": 1.0, \"recall\": 0.8468734622001648, \"specificity\": 1.0, \"npv\": 0.786401093006134, \"accuracy\": 0.9020780920982361, \"f1\": 0.917088776326313, \"f2\": 0.8736286062576188, \"f0_5\": 0.9650993154528111, \"p4\": 0.8983858910443667, \"phi\": 0.8160773374105551}, {\"truth_threshold\": -5.770339738595288, \"match_probability\": 0.01799160281453789, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1719.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 312.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8463810682296753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15361890196800232, \"precision\": 1.0, \"recall\": 0.8463810682296753, \"specificity\": 1.0, \"npv\": 0.7858613729476929, \"accuracy\": 0.9017632007598877, \"f1\": 0.9168, \"f2\": 0.8732093873818958, \"f0_5\": 0.96497137083193, \"p4\": 0.8980711766082768, \"phi\": 0.815560050508581}, {\"truth_threshold\": -5.763095853482246, \"match_probability\": 0.018080529787847743, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1718.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 313.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8458887338638306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15411128103733063, \"precision\": 1.0, \"recall\": 0.8458887338638306, \"specificity\": 1.0, \"npv\": 0.785322368144989, \"accuracy\": 0.9014483690261841, \"f1\": 0.916511069618565, \"f2\": 0.8727900833163991, \"f0_5\": 0.9648433112434011, \"p4\": 0.8977565214633161, \"phi\": 0.8150431455574445}, {\"truth_threshold\": -5.754999702121091, \"match_probability\": 0.01818042992357411, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1717.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 314.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8453963398933411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15460364520549774, \"precision\": 1.0, \"recall\": 0.8453963398933411, \"specificity\": 1.0, \"npv\": 0.7847840785980225, \"accuracy\": 0.9011334776878357, \"f1\": 0.916221985058698, \"f2\": 0.872370694035159, \"f0_5\": 0.9647151365321947, \"p4\": 0.8974419254352168, \"phi\": 0.8145266218229484}, {\"truth_threshold\": -5.750268998654429, \"match_probability\": 0.018239053637023994, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1716.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 315.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8449040055274963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15509600937366486, \"precision\": 1.0, \"recall\": 0.8449040055274963, \"specificity\": 1.0, \"npv\": 0.784246563911438, \"accuracy\": 0.9008186459541321, \"f1\": 0.9159327461969575, \"f2\": 0.8719512195121951, \"f0_5\": 0.9645868465430016, \"p4\": 0.8971273883496309, \"phi\": 0.814010478572503}, {\"truth_threshold\": -5.6493861532598695, \"match_probability\": 0.0195342939496806, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1715.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 316.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8444116115570068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15558837354183197, \"precision\": 1.0, \"recall\": 0.8444116115570068, \"specificity\": 1.0, \"npv\": 0.7837097644805908, \"accuracy\": 0.9005037546157837, \"f1\": 0.9156433529097704, \"f2\": 0.8715316597215164, \"f0_5\": 0.9644584411202339, \"p4\": 0.8968129100321289, \"phi\": 0.8134947150751188}, {\"truth_threshold\": -5.644655449793207, \"match_probability\": 0.01959719612820446, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1714.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 317.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8439192771911621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15608075261116028, \"precision\": 1.0, \"recall\": 0.8439192771911621, \"specificity\": 1.0, \"npv\": 0.7831737399101257, \"accuracy\": 0.9001889228820801, \"f1\": 0.9153538050734312, \"f2\": 0.8711120146371214, \"f0_5\": 0.964329920108023, \"p4\": 0.8964984903082001, \"phi\": 0.8129793306014036}, {\"truth_threshold\": -5.485034164558343, \"match_probability\": 0.021839874781482978, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1713.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 318.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8434268832206726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1565731167793274, \"precision\": 1.0, \"recall\": 0.8434268832206726, \"specificity\": 1.0, \"npv\": 0.782638430595398, \"accuracy\": 0.8998740315437317, \"f1\": 0.9150641025641025, \"f2\": 0.8706922842329978, \"f0_5\": 0.9642012833502195, \"p4\": 0.8961841290032514, \"phi\": 0.8124643244235554}, {\"truth_threshold\": -5.481480330070438, \"match_probability\": 0.021892560678661466, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1703.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 328.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8385031819343567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16149680316448212, \"precision\": 1.0, \"recall\": 0.8385031819343567, \"specificity\": 1.0, \"npv\": 0.7773252129554749, \"accuracy\": 0.8967254161834717, \"f1\": 0.9121585431173005, \"f2\": 0.8664902818764628, \"f0_5\": 0.9629085152097704, \"p4\": 0.8930436905276049, \"phi\": 0.807334909928681}, {\"truth_threshold\": -5.475797824635623, \"match_probability\": 0.02197706258493462, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1701.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 330.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8375184535980225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16248153150081635, \"precision\": 1.0, \"recall\": 0.8375184535980225, \"specificity\": 1.0, \"npv\": 0.7762711644172668, \"accuracy\": 0.8960956931114197, \"f1\": 0.9115755627009646, \"f2\": 0.8656488549618321, \"f0_5\": 0.9626485568760611, \"p4\": 0.8924162863583879, \"phi\": 0.8063134945965403}, {\"truth_threshold\": -5.303619180375759, \"match_probability\": 0.024694055083665633, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1700.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 331.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8370261192321777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16297391057014465, \"precision\": 1.0, \"recall\": 0.8370261192321777, \"specificity\": 1.0, \"npv\": 0.7757452726364136, \"accuracy\": 0.8957808613777161, \"f1\": 0.9112838381131064, \"f2\": 0.865228013029316, \"f0_5\": 0.9625184010870796, \"p4\": 0.8921026685740049, \"phi\": 0.805803340749626}, {\"truth_threshold\": -5.260248012980052, \"match_probability\": 0.02542853012806467, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1698.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 333.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8360413312911987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16395863890647888, \"precision\": 1.0, \"recall\": 0.8360413312911987, \"specificity\": 1.0, \"npv\": 0.7746955156326294, \"accuracy\": 0.8951511383056641, \"f1\": 0.910699919549477, \"f2\": 0.8643860720830788, \"f0_5\": 0.9622577354641279, \"p4\": 0.8914756007267217, \"phi\": 0.8047841371638093}, {\"truth_threshold\": -5.207525625398145, \"match_probability\": 0.026350049162013795, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1697.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 334.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.835548996925354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.164451003074646, \"precision\": 1.0, \"recall\": 0.835548996925354, \"specificity\": 1.0, \"npv\": 0.7741717100143433, \"accuracy\": 0.8948362469673157, \"f1\": 0.9104077253218884, \"f2\": 0.8639649730170044, \"f0_5\": 0.962127225308992, \"p4\": 0.8911621503119651, \"phi\": 0.8042750860173319}, {\"truth_threshold\": -5.149394584611998, \"match_probability\": 0.027403772363291383, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1696.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 335.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8350566029548645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1649433821439743, \"precision\": 1.0, \"recall\": 0.8350566029548645, \"specificity\": 1.0, \"npv\": 0.7736486196517944, \"accuracy\": 0.8945214152336121, \"f1\": 0.9101153742956801, \"f2\": 0.8635437881873728, \"f0_5\": 0.9619965967101531, \"p4\": 0.8908487553350769, \"phi\": 0.8037664010326047}, {\"truth_threshold\": -5.081841336596064, \"match_probability\": 0.02867977605226471, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1694.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 337.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8340718746185303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16592811048030853, \"precision\": 1.0, \"recall\": 0.8340718746185303, \"specificity\": 1.0, \"npv\": 0.7726045846939087, \"accuracy\": 0.8938916921615601, \"f1\": 0.9095302013422819, \"f2\": 0.8627011611326135, \"f0_5\": 0.9617349835358238, \"p4\": 0.890222130990195, \"phi\": 0.8027501267498}, {\"truth_threshold\": -4.983071617986242, \"match_probability\": 0.030649733760699554, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1689.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 342.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8316100239753723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1683899611234665, \"precision\": 1.0, \"recall\": 0.8316100239753723, \"specificity\": 1.0, \"npv\": 0.7700067162513733, \"accuracy\": 0.8923173546791077, \"f1\": 0.9080645161290323, \"f2\": 0.8605930907979211, \"f0_5\": 0.9610788665073404, \"p4\": 0.8886565279485639, \"phi\": 0.8002158000544144}, {\"truth_threshold\": -4.978979989541254, \"match_probability\": 0.030734107497564202, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1688.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 343.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8311176896095276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1688823252916336, \"precision\": 1.0, \"recall\": 0.8311176896095276, \"specificity\": 1.0, \"npv\": 0.7694892287254333, \"accuracy\": 0.892002522945404, \"f1\": 0.9077709061575693, \"f2\": 0.8601712189156135, \"f0_5\": 0.960947284526927, \"p4\": 0.8883435701252902, \"phi\": 0.7997100192879079}, {\"truth_threshold\": -4.975575511943448, \"match_probability\": 0.030804482831756172, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1687.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 344.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8306252956390381, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16937468945980072, \"precision\": 1.0, \"recall\": 0.8306252956390381, \"specificity\": 1.0, \"npv\": 0.7689724564552307, \"accuracy\": 0.8916876316070557, \"f1\": 0.907477138246369, \"f2\": 0.8597492610335338, \"f0_5\": 0.9608155826403918, \"p4\": 0.8880306661511507, \"phi\": 0.7992045984364035}, {\"truth_threshold\": -4.930340770508478, \"match_probability\": 0.03175448213548337, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1686.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 345.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8301329612731934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16986705362796783, \"precision\": 1.0, \"recall\": 0.8301329612731934, \"specificity\": 1.0, \"npv\": 0.7684563994407654, \"accuracy\": 0.891372799873352, \"f1\": 0.9071832122679581, \"f2\": 0.8593272171253823, \"f0_5\": 0.9606837606837607, \"p4\": 0.8877178158491477, \"phi\": 0.7986995368131737}, {\"truth_threshold\": -4.922285516784027, \"match_probability\": 0.03192660200442167, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1684.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 347.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8291481733322144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17085179686546326, \"precision\": 1.0, \"recall\": 0.8291481733322144, \"specificity\": 1.0, \"npv\": 0.7674262523651123, \"accuracy\": 0.8907430768013, \"f1\": 0.9065948855989233, \"f2\": 0.8584828711256117, \"f0_5\": 0.9604197559028174, \"p4\": 0.8870922755530783, \"phi\": 0.7976904885118942}, {\"truth_threshold\": -4.921492695478215, \"match_probability\": 0.03194359122572122, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1683.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 348.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8286558389663696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17134416103363037, \"precision\": 1.0, \"recall\": 0.8286558389663696, \"specificity\": 1.0, \"npv\": 0.7669122815132141, \"accuracy\": 0.8904281854629517, \"f1\": 0.9063004846526656, \"f2\": 0.8580605689813399, \"f0_5\": 0.9602875727490585, \"p4\": 0.8867795852045331, \"phi\": 0.7971865004676407}, {\"truth_threshold\": -4.91415169739733, \"match_probability\": 0.03210131588921209, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1677.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 354.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8257016539573669, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17429837584495544, \"precision\": 1.0, \"recall\": 0.8257016539573669, \"specificity\": 1.0, \"npv\": 0.7638425827026367, \"accuracy\": 0.8885390162467957, \"f1\": 0.9045307443365695, \"f2\": 0.8555249464340373, \"f0_5\": 0.9594919327154137, \"p4\": 0.8849045491245728, \"phi\": 0.7941700348824948}, {\"truth_threshold\": -4.912213670578019, \"match_probability\": 0.0321430807437345, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1676.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 355.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8252092599868774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17479074001312256, \"precision\": 1.0, \"recall\": 0.8252092599868774, \"specificity\": 1.0, \"npv\": 0.7633333206176758, \"accuracy\": 0.888224184513092, \"f1\": 0.9042352306447262, \"f2\": 0.8551020408163266, \"f0_5\": 0.9593589009730967, \"p4\": 0.8845922257876229, \"phi\": 0.7936685280895892}, {\"truth_threshold\": -4.805650510501136, \"match_probability\": 0.034522113703364284, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1674.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 357.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8242245316505432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17577548325061798, \"precision\": 1.0, \"recall\": 0.8242245316505432, \"specificity\": 1.0, \"npv\": 0.762316882610321, \"accuracy\": 0.88759446144104, \"f1\": 0.9036437246963562, \"f2\": 0.8542559706062461, \"f0_5\": 0.9590924716397388, \"p4\": 0.8839677340916142, \"phi\": 0.7926665691418547}, {\"truth_threshold\": -4.781548448464711, \"match_probability\": 0.035083290414010065, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1671.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 360.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8227474093437195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17725259065628052, \"precision\": 1.0, \"recall\": 0.8227474093437195, \"specificity\": 1.0, \"npv\": 0.7607973217964172, \"accuracy\": 0.8866498470306396, \"f1\": 0.9027552674230146, \"f2\": 0.8529862174578867, \"f0_5\": 0.9586919104991394, \"p4\": 0.8830313813179738, \"phi\": 0.791166257292661}, {\"truth_threshold\": -4.780755627158899, \"match_probability\": 0.03510189850757074, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1669.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 362.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8217626810073853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17823731899261475, \"precision\": 1.0, \"recall\": 0.8217626810073853, \"specificity\": 1.0, \"npv\": 0.7597876787185669, \"accuracy\": 0.8860201239585876, \"f1\": 0.9021621621621622, \"f2\": 0.8521392831614418, \"f0_5\": 0.9584242563454691, \"p4\": 0.8824074005666601, \"phi\": 0.7901677926784536}, {\"truth_threshold\": -4.771476602258704, \"match_probability\": 0.03532039219115339, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1666.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 365.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8202855587005615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17971442639827728, \"precision\": 1.0, \"recall\": 0.8202855587005615, \"specificity\": 1.0, \"npv\": 0.7582781314849854, \"accuracy\": 0.885075569152832, \"f1\": 0.9012713010549094, \"f2\": 0.8508682328907048, \"f0_5\": 0.9580218516388729, \"p4\": 0.8814718075111811, \"phi\": 0.788672697446118}, {\"truth_threshold\": -4.760077858068414, \"match_probability\": 0.035590592745242886, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1662.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 369.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8183161020278931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18168389797210693, \"precision\": 1.0, \"recall\": 0.8183161020278931, \"specificity\": 1.0, \"npv\": 0.7562747597694397, \"accuracy\": 0.883816123008728, \"f1\": 0.9000812347684809, \"f2\": 0.8491722869405273, \"f0_5\": 0.9574835810577256, \"p4\": 0.8802250483160751, \"phi\": 0.7866840659933549}, {\"truth_threshold\": -4.675934899603489, \"match_probability\": 0.037647614652134495, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1660.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 371.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8173313736915588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18266864120960236, \"precision\": 1.0, \"recall\": 0.8173313736915588, \"specificity\": 1.0, \"npv\": 0.7552770376205444, \"accuracy\": 0.883186399936676, \"f1\": 0.8994852343538337, \"f2\": 0.848323793949305, \"f0_5\": 0.9572137008418867, \"p4\": 0.8796019647235972, \"phi\": 0.7856918080033143}, {\"truth_threshold\": -4.675142078297678, \"match_probability\": 0.03766752976237664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1658.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 373.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8163466453552246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18365336954593658, \"precision\": 1.0, \"recall\": 0.8163466453552246, \"specificity\": 1.0, \"npv\": 0.7542819380760193, \"accuracy\": 0.882556676864624, \"f1\": 0.8988885876931417, \"f2\": 0.8474749539971376, \"f0_5\": 0.9569433221747663, \"p4\": 0.8789790765513171, \"phi\": 0.7847009148999347}, {\"truth_threshold\": -4.665863053397482, \"match_probability\": 0.037901366056843744, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1656.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 375.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8153619170188904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.184638112783432, \"precision\": 1.0, \"recall\": 0.8153619170188904, \"specificity\": 1.0, \"npv\": 0.7532894611358643, \"accuracy\": 0.881926953792572, \"f1\": 0.8982912937347437, \"f2\": 0.8466257668711656, \"f0_5\": 0.9566724436741768, \"p4\": 0.8783563823596343, \"phi\": 0.7837113815067549}, {\"truth_threshold\": -4.547219205316482, \"match_probability\": 0.04101678607773685, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1654.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 377.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8143771290779114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18562284111976624, \"precision\": 1.0, \"recall\": 0.8143771290779114, \"specificity\": 1.0, \"npv\": 0.7522996068000793, \"accuracy\": 0.88129723072052, \"f1\": 0.8976933514246948, \"f2\": 0.8457762323583555, \"f0_5\": 0.956401063952816, \"p4\": 0.8777338807071583, \"phi\": 0.7827232026685234}, {\"truth_threshold\": -4.506090228642227, \"match_probability\": 0.042152937976962616, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1653.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 378.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8138847947120667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18611522018909454, \"precision\": 1.0, \"recall\": 0.8138847947120667, \"specificity\": 1.0, \"npv\": 0.7518056631088257, \"accuracy\": 0.8809823393821716, \"f1\": 0.8973941368078175, \"f2\": 0.8453513347652655, \"f0_5\": 0.9562651856994099, \"p4\": 0.8774227016321944, \"phi\": 0.782229619602263}, {\"truth_threshold\": -4.486357548360509, \"match_probability\": 0.042708659183521305, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1652.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 379.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8133924007415771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18660758435726166, \"precision\": 1.0, \"recall\": 0.8133924007415771, \"specificity\": 1.0, \"npv\": 0.7513123154640198, \"accuracy\": 0.880667507648468, \"f1\": 0.8970947597067608, \"f2\": 0.8449263502454992, \"f0_5\": 0.9561291816182429, \"p4\": 0.8771115701506905, \"phi\": 0.7817363732510626}, {\"truth_threshold\": -4.390613011222292, \"match_probability\": 0.04550583243070602, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1651.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 380.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8129000663757324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18709994852542877, \"precision\": 1.0, \"recall\": 0.8129000663757324, \"specificity\": 1.0, \"npv\": 0.7508196830749512, \"accuracy\": 0.8803526163101196, \"f1\": 0.8967952199891364, \"f2\": 0.8445012787723786, \"f0_5\": 0.9559930515344528, \"p4\": 0.8768004860819614, \"phi\": 0.7812434629764206}, {\"truth_threshold\": -4.364421551485216, \"match_probability\": 0.04630091414601171, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1650.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 381.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8124076724052429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1875923126935959, \"precision\": 1.0, \"recall\": 0.8124076724052429, \"specificity\": 1.0, \"npv\": 0.7503276467323303, \"accuracy\": 0.880037784576416, \"f1\": 0.8964955175224124, \"f2\": 0.8440761203192142, \"f0_5\": 0.9558567952728537, \"p4\": 0.8764894492452066, \"phi\": 0.7807508881411364}, {\"truth_threshold\": -4.3615678608751605, \"match_probability\": 0.04638833661367583, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1648.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 383.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8114229440689087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1885770559310913, \"precision\": 1.0, \"recall\": 0.8114229440689087, \"specificity\": 1.0, \"npv\": 0.7493455410003662, \"accuracy\": 0.879408061504364, \"f1\": 0.8958956238108181, \"f2\": 0.8432255423659435, \"f0_5\": 0.9555839035138582, \"p4\": 0.875867516543838, \"phi\": 0.7797667422463175}, {\"truth_threshold\": -4.281455616584328, \"match_probability\": 0.04890757794012093, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1647.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 384.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8109305500984192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18906942009925842, \"precision\": 1.0, \"recall\": 0.8109305500984192, \"specificity\": 1.0, \"npv\": 0.748855471611023, \"accuracy\": 0.8790931701660156, \"f1\": 0.8955954323001631, \"f2\": 0.842800122812404, \"f0_5\": 0.9554472676644622, \"p4\": 0.8755566203170421, \"phi\": 0.7792751699188473}, {\"truth_threshold\": -4.16587148474961, \"match_probability\": 0.05277185020145301, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1646.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 385.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8104382157325745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18956179916858673, \"precision\": 1.0, \"recall\": 0.8104382157325745, \"specificity\": 1.0, \"npv\": 0.7483659982681274, \"accuracy\": 0.878778338432312, \"f1\": 0.8952950775088387, \"f2\": 0.842374616171955, \"f0_5\": 0.955310504933256, \"p4\": 0.8752457705978546, \"phi\": 0.7787839304948556}, {\"truth_threshold\": -4.157496978653732, \"match_probability\": 0.053062767319424664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1645.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 386.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.809945821762085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19005416333675385, \"precision\": 1.0, \"recall\": 0.809945821762085, \"specificity\": 1.0, \"npv\": 0.7478771805763245, \"accuracy\": 0.8784634470939636, \"f1\": 0.8949945593035908, \"f2\": 0.8419490224178524, \"f0_5\": 0.9551736151434213, \"p4\": 0.8749349672048905, \"phi\": 0.7782930233435834}, {\"truth_threshold\": -4.127578605388498, \"match_probability\": 0.054114493898563126, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1644.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 387.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8094534873962402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19054652750492096, \"precision\": 1.0, \"recall\": 0.8094534873962402, \"specificity\": 1.0, \"npv\": 0.747389018535614, \"accuracy\": 0.87814861536026, \"f1\": 0.8946938775510204, \"f2\": 0.8415233415233415, \"f0_5\": 0.955036598117811, \"p4\": 0.8746242099566458, \"phi\": 0.7778024478355472}, {\"truth_threshold\": -4.087567921284527, \"match_probability\": 0.05555173404099292, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1643.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 388.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8089610934257507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19103889167308807, \"precision\": 1.0, \"recall\": 0.8089610934257507, \"specificity\": 1.0, \"npv\": 0.7469015121459961, \"accuracy\": 0.8778337240219116, \"f1\": 0.894393032117583, \"f2\": 0.8410975734616566, \"f0_5\": 0.9548994536789492, \"p4\": 0.8743134986714977, \"phi\": 0.7773122033425358}, {\"truth_threshold\": -4.074410710350319, \"match_probability\": 0.05603215946237368, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1642.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 389.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.808468759059906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19153127074241638, \"precision\": 1.0, \"recall\": 0.808468759059906, \"specificity\": 1.0, \"npv\": 0.7464146018028259, \"accuracy\": 0.877518892288208, \"f1\": 0.8940920228695889, \"f2\": 0.8406717182060209, \"f0_5\": 0.9547621816490289, \"p4\": 0.874002833167703, \"phi\": 0.7768222892376055}, {\"truth_threshold\": -4.0488578452285, \"match_probability\": 0.05697638720754645, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1641.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 390.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8079763650894165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1920236349105835, \"precision\": 1.0, \"recall\": 0.8079763650894165, \"specificity\": 1.0, \"npv\": 0.7459283471107483, \"accuracy\": 0.8772040009498596, \"f1\": 0.8937908496732027, \"f2\": 0.8402457757296466, \"f0_5\": 0.9546247818499127, \"p4\": 0.8736922132633987, \"phi\": 0.7763327048950771}, {\"truth_threshold\": -4.02982362681648, \"match_probability\": 0.05768943323329183, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1640.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 391.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.807483971118927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1925159990787506, \"precision\": 1.0, \"recall\": 0.807483971118927, \"specificity\": 1.0, \"npv\": 0.7454426884651184, \"accuracy\": 0.876889169216156, \"f1\": 0.893489512394443, \"f2\": 0.8398197460057354, \"f0_5\": 0.9544872541031312, \"p4\": 0.8733816387766006, \"phi\": 0.7758434496905313}, {\"truth_threshold\": -3.9356758584011184, \"match_probability\": 0.06134106765366529, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1638.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 393.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8064992427825928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19350074231624603, \"precision\": 1.0, \"recall\": 0.8064992427825928, \"specificity\": 1.0, \"npv\": 0.7444733381271362, \"accuracy\": 0.876259446144104, \"f1\": 0.892886345053148, \"f2\": 0.8389674247080516, \"f0_5\": 0.9542118140510311, \"p4\": 0.8727606253269781, \"phi\": 0.7748659242039853}, {\"truth_threshold\": -3.840161640703994, \"match_probability\": 0.06526560686487597, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1637.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 394.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.806006908416748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19399310648441315, \"precision\": 1.0, \"recall\": 0.806006908416748, \"specificity\": 1.0, \"npv\": 0.7439895868301392, \"accuracy\": 0.8759445548057556, \"f1\": 0.8925845147219194, \"f2\": 0.8385411330806269, \"f0_5\": 0.954073901387108, \"p4\": 0.8724501859995755, \"phi\": 0.7743776526794105}, {\"truth_threshold\": -3.8170160102804087, \"match_probability\": 0.0662511992401967, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1636.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 395.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8055145144462585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19448547065258026, \"precision\": 1.0, \"recall\": 0.8055145144462585, \"specificity\": 1.0, \"npv\": 0.7435064911842346, \"accuracy\": 0.875629723072052, \"f1\": 0.8922825197709299, \"f2\": 0.8381147540983607, \"f0_5\": 0.953935860058309, \"p4\": 0.8721397913605214, \"phi\": 0.773889707807661}, {\"truth_threshold\": -3.797232527296512, \"match_probability\": 0.06710456662357826, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1632.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 399.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8035450577735901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1964549422264099, \"precision\": 1.0, \"recall\": 0.8035450577735901, \"specificity\": 1.0, \"npv\": 0.7415803074836731, \"accuracy\": 0.874370276927948, \"f1\": 0.8910728910728911, \"f2\": 0.8364083640836408, \"f0_5\": 0.9533824044865055, \"p4\": 0.8708986560339702, \"phi\": 0.7719411825038563}, {\"truth_threshold\": -3.679678987048963, \"match_probability\": 0.07238893248088431, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1630.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 401.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8025603294372559, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19743968546390533, \"precision\": 1.0, \"recall\": 0.8025603294372559, \"specificity\": 1.0, \"npv\": 0.7406209707260132, \"accuracy\": 0.873740553855896, \"f1\": 0.8904670854957661, \"f2\": 0.8355546442485134, \"f0_5\": 0.9531049000116946, \"p4\": 0.8702783517473123, \"phi\": 0.7709688637547925}, {\"truth_threshold\": -3.6762789419610935, \"match_probability\": 0.07254734369301873, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1629.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 402.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8020679354667664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19793204963207245, \"precision\": 1.0, \"recall\": 0.8020679354667664, \"specificity\": 1.0, \"npv\": 0.7401422262191772, \"accuracy\": 0.8734257221221924, \"f1\": 0.8901639344262295, \"f2\": 0.8351276530298369, \"f0_5\": 0.952965952965953, \"p4\": 0.8699682648069582, \"phi\": 0.7704831882127677}, {\"truth_threshold\": -3.5706653930998717, \"match_probability\": 0.07762970243088008, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1627.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 404.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.8010832071304321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19891679286956787, \"precision\": 1.0, \"recall\": 0.8010832071304321, \"specificity\": 1.0, \"npv\": 0.7391865849494934, \"accuracy\": 0.8727959990501404, \"f1\": 0.8895571350464735, \"f2\": 0.8342734078556046, \"f0_5\": 0.9526876683452394, \"p4\": 0.8693482204147955, \"phi\": 0.7695128017456969}, {\"truth_threshold\": -3.514218306814257, \"match_probability\": 0.08047797065231085, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1624.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 407.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7996060848236084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2003939002752304, \"precision\": 1.0, \"recall\": 0.7996060848236084, \"specificity\": 1.0, \"npv\": 0.7377577424049377, \"accuracy\": 0.87185138463974, \"f1\": 0.8886456908344733, \"f2\": 0.8329913828477636, \"f0_5\": 0.9522692623431454, \"p4\": 0.8684184747918336, \"phi\": 0.7680596244796367}, {\"truth_threshold\": -3.4447176921341054, \"match_probability\": 0.08411573531897502, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1623.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 408.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7991137504577637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20088626444339752, \"precision\": 1.0, \"recall\": 0.7991137504577637, \"specificity\": 1.0, \"npv\": 0.7372826933860779, \"accuracy\": 0.8715365529060364, \"f1\": 0.8883415435139573, \"f2\": 0.8325638658048631, \"f0_5\": 0.9521295318549806, \"p4\": 0.8681086444390568, \"phi\": 0.7675758702864567}, {\"truth_threshold\": -3.4161658763441105, \"match_probability\": 0.08565301201035606, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1620.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 411.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7976366281509399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20236337184906006, \"precision\": 1.0, \"recall\": 0.7976366281509399, \"specificity\": 1.0, \"npv\": 0.7358611822128296, \"accuracy\": 0.870591938495636, \"f1\": 0.8874281018898932, \"f2\": 0.8312807881773399, \"f0_5\": 0.9517095523440254, \"p4\": 0.8671794053656988, \"phi\": 0.7661265139596987}, {\"truth_threshold\": -3.205156105965531, \"match_probability\": 0.09782353747407155, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1619.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 412.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7971442341804504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20285573601722717, \"precision\": 1.0, \"recall\": 0.7971442341804504, \"specificity\": 1.0, \"npv\": 0.7353885769844055, \"accuracy\": 0.8702771067619324, \"f1\": 0.8871232876712328, \"f2\": 0.8308529200451606, \"f0_5\": 0.9515692958739861, \"p4\": 0.866869742387817, \"phi\": 0.7656440286015744}, {\"truth_threshold\": -3.1963581132540813, \"match_probability\": 0.09836305930458443, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1618.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 413.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7966518998146057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2033481001853943, \"precision\": 1.0, \"recall\": 0.7966518998146057, \"specificity\": 1.0, \"npv\": 0.7349165678024292, \"accuracy\": 0.869962215423584, \"f1\": 0.886818306385311, \"f2\": 0.8304249640730856, \"f0_5\": 0.9514289074444314, \"p4\": 0.86656012079201, \"phi\": 0.7651618589550606}, {\"truth_threshold\": -3.144800038241717, \"match_probability\": 0.10157833172175239, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1616.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 415.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7956671714782715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2043328434228897, \"precision\": 1.0, \"recall\": 0.7956671714782715, \"specificity\": 1.0, \"npv\": 0.7339743375778198, \"accuracy\": 0.869332492351532, \"f1\": 0.8862078420619688, \"f2\": 0.8295687885010267, \"f0_5\": 0.9511477339611536, \"p4\": 0.8659410010067748, \"phi\": 0.7641984644119829}, {\"truth_threshold\": -3.137632356223202, \"match_probability\": 0.10203263420563378, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1615.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 416.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.795174777507782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20482520759105682, \"precision\": 1.0, \"recall\": 0.795174777507782, \"specificity\": 1.0, \"npv\": 0.7335041761398315, \"accuracy\": 0.8690176606178284, \"f1\": 0.8859023587493143, \"f2\": 0.8291405688469042, \"f0_5\": 0.9510069485337416, \"p4\": 0.8656315024470852, \"phi\": 0.7637172383258942}, {\"truth_threshold\": -3.128804865238147, \"match_probability\": 0.10259461291475495, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1613.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 418.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7941900491714478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20580995082855225, \"precision\": 1.0, \"recall\": 0.7941900491714478, \"specificity\": 1.0, \"npv\": 0.7325655817985535, \"accuracy\": 0.8683879375457764, \"f1\": 0.8852908891328211, \"f2\": 0.8282838656670433, \"f0_5\": 0.9507249793705057, \"p4\": 0.865012627066886, \"phi\": 0.762755725559516}, {\"truth_threshold\": -3.1275786053884977, \"match_probability\": 0.10267289599334653, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1610.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 421.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.792712926864624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2072870433330536, \"precision\": 1.0, \"recall\": 0.792712926864624, \"specificity\": 1.0, \"npv\": 0.7311621904373169, \"accuracy\": 0.867443323135376, \"f1\": 0.8843724251579237, \"f2\": 0.8269981508115882, \"f0_5\": 0.9503010270334081, \"p4\": 0.86408461556039, \"phi\": 0.7613157960637859}, {\"truth_threshold\": -3.0968619359958387, \"match_probability\": 0.10465113702325655, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1609.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 422.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7922205924987793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2077794224023819, \"precision\": 1.0, \"recall\": 0.7922205924987793, \"specificity\": 1.0, \"npv\": 0.7306956052780151, \"accuracy\": 0.8671284914016724, \"f1\": 0.884065934065934, \"f2\": 0.8265694030617486, \"f0_5\": 0.9501594425416322, \"p4\": 0.8637753580651635, \"phi\": 0.7608364411180943}, {\"truth_threshold\": -3.0644190376462155, \"match_probability\": 0.10677702920587288, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1608.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 423.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7917281985282898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.208271786570549, \"precision\": 1.0, \"recall\": 0.7917281985282898, \"specificity\": 1.0, \"npv\": 0.7302296161651611, \"accuracy\": 0.866813600063324, \"f1\": 0.8837592745259687, \"f2\": 0.8261405672009864, \"f0_5\": 0.9500177242112726, \"p4\": 0.8634661400965793, \"phi\": 0.7603573959710088}, {\"truth_threshold\": -3.061206740484977, \"match_probability\": 0.10698957823445567, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1607.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 424.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7912358641624451, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20876415073871613, \"precision\": 1.0, \"recall\": 0.7912358641624451, \"specificity\": 1.0, \"npv\": 0.7297641634941101, \"accuracy\": 0.8664987683296204, \"f1\": 0.8834524463991204, \"f2\": 0.8257116432021375, \"f0_5\": 0.9498758718524648, \"p4\": 0.8631569614683307, \"phi\": 0.7598786600375329}, {\"truth_threshold\": -3.0434253038319117, \"match_probability\": 0.10817287474191059, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1606.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 425.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7907434701919556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20925652980804443, \"precision\": 1.0, \"recall\": 0.7907434701919556, \"specificity\": 1.0, \"npv\": 0.7292993664741516, \"accuracy\": 0.866183876991272, \"f1\": 0.8831454495463293, \"f2\": 0.8252826310380267, \"f0_5\": 0.9497338852749853, \"p4\": 0.8628478219939693, \"phi\": 0.7594002327338012}, {\"truth_threshold\": -3.0183521330972853, \"match_probability\": 0.10986094415575685, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1605.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 426.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7902511358261108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20974889397621155, \"precision\": 1.0, \"recall\": 0.7902511358261108, \"specificity\": 1.0, \"npv\": 0.7288351655006409, \"accuracy\": 0.8658690452575684, \"f1\": 0.8828382838283828, \"f2\": 0.8248535306814678, \"f0_5\": 0.9495917642882499, \"p4\": 0.8625387214869051, \"phi\": 0.7589221134770772}, {\"truth_threshold\": -3.0167648203558186, \"match_probability\": 0.10996858462019438, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1604.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 427.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7897587418556213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21024125814437866, \"precision\": 1.0, \"recall\": 0.7897587418556213, \"specificity\": 1.0, \"npv\": 0.7283715009689331, \"accuracy\": 0.86555415391922, \"f1\": 0.8825309491059147, \"f2\": 0.8244243421052632, \"f0_5\": 0.9494495087013141, \"p4\": 0.8622296597604054, \"phi\": 0.7584443016857485}, {\"truth_threshold\": -3.008486526324748, \"match_probability\": 0.11053145985275803, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1603.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 428.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7892663478851318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21073362231254578, \"precision\": 1.0, \"recall\": 0.7892663478851318, \"specificity\": 1.0, \"npv\": 0.7279084324836731, \"accuracy\": 0.8652393221855164, \"f1\": 0.8822234452394057, \"f2\": 0.8239950652822041, \"f0_5\": 0.9493071183228711, \"p4\": 0.8619206366275943, \"phi\": 0.7579667967793241}, {\"truth_threshold\": -2.8563507138151425, \"match_probability\": 0.12133254270578255, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1600.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 431.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7877892851829529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2122107297182083, \"precision\": 1.0, \"recall\": 0.7877892851829529, \"specificity\": 1.0, \"npv\": 0.7265228629112244, \"accuracy\": 0.864294707775116, \"f1\": 0.8812999173781327, \"f2\": 0.8227067050596463, \"f0_5\": 0.9488791365199858, \"p4\": 0.8609937969203728, \"phi\": 0.7565361175813073}, {\"truth_threshold\": -2.8505113188153017, \"match_probability\": 0.12176471876654896, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1599.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 432.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7872968912124634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21270310878753662, \"precision\": 1.0, \"recall\": 0.7872968912124634, \"specificity\": 1.0, \"npv\": 0.7260621190071106, \"accuracy\": 0.8639798760414124, \"f1\": 0.8809917355371901, \"f2\": 0.822277074976859, \"f0_5\": 0.9487362050551797, \"p4\": 0.8606849262906713, \"phi\": 0.7560598344318872}, {\"truth_threshold\": -2.833492910418021, \"match_probability\": 0.12303182710341205, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1598.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 433.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7868045568466187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21319547295570374, \"precision\": 1.0, \"recall\": 0.7868045568466187, \"specificity\": 1.0, \"npv\": 0.7256020307540894, \"accuracy\": 0.863664984703064, \"f1\": 0.8806833838523009, \"f2\": 0.8218473565110059, \"f0_5\": 0.9485931378368753, \"p4\": 0.860376093318109, \"phi\": 0.7555838552816091}, {\"truth_threshold\": -2.814392591591477, \"match_probability\": 0.12446742864091155, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1597.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 434.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7863121628761292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21368783712387085, \"precision\": 1.0, \"recall\": 0.7863121628761292, \"specificity\": 1.0, \"npv\": 0.7251424789428711, \"accuracy\": 0.8633501529693604, \"f1\": 0.880374862183021, \"f2\": 0.8214175496348113, \"f0_5\": 0.9484499346715762, \"p4\": 0.8600672978149376, \"phi\": 0.7551081795566347}, {\"truth_threshold\": -2.7970746866513747, \"match_probability\": 0.12578146007489846, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1595.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 436.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7853274345397949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21467258036136627, \"precision\": 1.0, \"recall\": 0.7853274345397949, \"specificity\": 1.0, \"npv\": 0.7242251634597778, \"accuracy\": 0.8627204298973083, \"f1\": 0.8797573083287369, \"f2\": 0.8205576705422368, \"f0_5\": 0.9481631197241708, \"p4\": 0.8594498184650354, \"phi\": 0.7541577360927235}, {\"truth_threshold\": -2.762135909144211, \"match_probability\": 0.12846867388529332, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1592.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 439.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7838503122329712, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21614967286586761, \"precision\": 1.0, \"recall\": 0.7838503122329712, \"specificity\": 1.0, \"npv\": 0.7228535413742065, \"accuracy\": 0.861775815486908, \"f1\": 0.8788296991443555, \"f2\": 0.8192671881432688, \"f0_5\": 0.947731872842005, \"p4\": 0.8585238757583832, \"phi\": 0.752734332303551}, {\"truth_threshold\": -2.73824421390455, \"match_probability\": 0.1303342932228472, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1589.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 442.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7823731899261475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21762678027153015, \"precision\": 1.0, \"recall\": 0.7823731899261475, \"specificity\": 1.0, \"npv\": 0.7214871048927307, \"accuracy\": 0.8608312606811523, \"f1\": 0.8779005524861878, \"f2\": 0.8179759085761351, \"f0_5\": 0.9472993919160606, \"p4\": 0.857598260108828, \"phi\": 0.7513136285674854}, {\"truth_threshold\": -2.7316604538078, \"match_probability\": 0.13085242832114446, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1588.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 443.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7818808555603027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21811915934085846, \"precision\": 1.0, \"recall\": 0.7818808555603027, \"specificity\": 1.0, \"npv\": 0.7210327386856079, \"accuracy\": 0.860516369342804, \"f1\": 0.8775904946117712, \"f2\": 0.8175453047775947, \"f0_5\": 0.9471549564595013, \"p4\": 0.8572897933569306, \"phi\": 0.7508406580273359}, {\"truth_threshold\": -2.6974865455653685, \"match_probability\": 0.13357005120780743, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1587.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 444.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7813884615898132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21861152350902557, \"precision\": 1.0, \"recall\": 0.7813884615898132, \"specificity\": 1.0, \"npv\": 0.7205789685249329, \"accuracy\": 0.8602015376091003, \"f1\": 0.8772802653399668, \"f2\": 0.8171146122953352, \"f0_5\": 0.9470103831006087, \"p4\": 0.8569813621887155, \"phi\": 0.7503679852338574}, {\"truth_threshold\": -2.631564562236853, \"match_probability\": 0.13894723170021506, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1585.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 446.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.780403733253479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2195962518453598, \"precision\": 1.0, \"recall\": 0.780403733253479, \"specificity\": 1.0, \"npv\": 0.7196731567382812, \"accuracy\": 0.8595718145370483, \"f1\": 0.8766592920353983, \"f2\": 0.8162529611700484, \"f0_5\": 0.9467208218850794, \"p4\": 0.856364605845547, \"phi\": 0.7494235306401207}, {\"truth_threshold\": -2.627390785536495, \"match_probability\": 0.13929371946981753, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1584.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 447.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7799113988876343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2200886309146881, \"precision\": 1.0, \"recall\": 0.7799113988876343, \"specificity\": 1.0, \"npv\": 0.7192211151123047, \"accuracy\": 0.8592569231987, \"f1\": 0.8763485477178423, \"f2\": 0.8158220024721878, \"f0_5\": 0.9465758336321262, \"p4\": 0.8560562802913134, \"phi\": 0.7489517477191111}, {\"truth_threshold\": -2.603774532937518, \"match_probability\": 0.14126789212547547, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1582.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 449.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7789266109466553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22107335925102234, \"precision\": 1.0, \"recall\": 0.7789266109466553, \"specificity\": 1.0, \"npv\": 0.7183187007904053, \"accuracy\": 0.858627200126648, \"f1\": 0.8757265430390258, \"f2\": 0.8149598186688646, \"f0_5\": 0.946285440842206, \"p4\": 0.8554397334681781, \"phi\": 0.7480090678348302}, {\"truth_threshold\": -2.5918729967041467, \"match_probability\": 0.14227161615708125, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1581.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 450.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7784342765808105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22156573832035065, \"precision\": 1.0, \"recall\": 0.7784342765808105, \"specificity\": 1.0, \"npv\": 0.7178683280944824, \"accuracy\": 0.8583123683929443, \"f1\": 0.8754152823920266, \"f2\": 0.8145285935085008, \"f0_5\": 0.9461400359066428, \"p4\": 0.8551315118190579, \"phi\": 0.7475381697571134}, {\"truth_threshold\": -2.5743980519718397, \"match_probability\": 0.14375614930264252, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1580.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 451.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.777941882610321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22205810248851776, \"precision\": 1.0, \"recall\": 0.777941882610321, \"specificity\": 1.0, \"npv\": 0.7174185514450073, \"accuracy\": 0.857997477054596, \"f1\": 0.8751038493492107, \"f2\": 0.8140972794723825, \"f0_5\": 0.9459944916776434, \"p4\": 0.8548233244244939, \"phi\": 0.7470675655144556}, {\"truth_threshold\": -2.559837537520561, \"match_probability\": 0.14500292021739583, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1579.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 452.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7774495482444763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22255046665668488, \"precision\": 1.0, \"recall\": 0.7774495482444763, \"specificity\": 1.0, \"npv\": 0.7169693112373352, \"accuracy\": 0.8576826453208923, \"f1\": 0.874792243767313, \"f2\": 0.813665876533031, \"f0_5\": 0.9458488079549539, \"p4\": 0.8545151710939816, \"phi\": 0.7465972545522392}, {\"truth_threshold\": -2.539015375865404, \"match_probability\": 0.14680144303808207, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1577.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 454.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7764648199081421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2235352098941803, \"precision\": 1.0, \"recall\": 0.7764648199081421, \"specificity\": 1.0, \"npv\": 0.7160725593566895, \"accuracy\": 0.8570529222488403, \"f1\": 0.8741685144124168, \"f2\": 0.8128028038346562, \"f0_5\": 0.9455570212255666, \"p4\": 0.8538989658622953, \"phi\": 0.7456575102558387}, {\"truth_threshold\": -2.520475581619983, \"match_probability\": 0.1484183331473721, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1574.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 457.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7749876976013184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22501230239868164, \"precision\": 1.0, \"recall\": 0.7749876976013184, \"specificity\": 1.0, \"npv\": 0.7147315740585327, \"accuracy\": 0.8561083078384399, \"f1\": 0.8732316227461858, \"f2\": 0.8115075273252217, \"f0_5\": 0.9451182899003242, \"p4\": 0.8529749087233359, \"phi\": 0.7442500796085201}, {\"truth_threshold\": -2.468498445156484, \"match_probability\": 0.15302981294673795, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1573.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 458.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7744953036308289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22550468146800995, \"precision\": 1.0, \"recall\": 0.7744953036308289, \"specificity\": 1.0, \"npv\": 0.7142857313156128, \"accuracy\": 0.8557934761047363, \"f1\": 0.8729189789123196, \"f2\": 0.8110755903887801, \"f0_5\": 0.9449717649885858, \"p4\": 0.8526669557675629, \"phi\": 0.7437815167397859}, {\"truth_threshold\": -2.4661038820021473, \"match_probability\": 0.15324506435842597, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1572.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 459.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7740029692649841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22599704563617706, \"precision\": 1.0, \"recall\": 0.7740029692649841, \"specificity\": 1.0, \"npv\": 0.7138404250144958, \"accuracy\": 0.8554785847663879, \"f1\": 0.8726061615320566, \"f2\": 0.8106435643564357, \"f0_5\": 0.9448250991705733, \"p4\": 0.8523590355378086, \"phi\": 0.743313243298003}, {\"truth_threshold\": -2.4531578858528635, \"match_probability\": 0.154413098939667, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1570.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 461.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7730182409286499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22698178887367249, \"precision\": 1.0, \"recall\": 0.7730182409286499, \"specificity\": 1.0, \"npv\": 0.7129514217376709, \"accuracy\": 0.8548488616943359, \"f1\": 0.8719800055540128, \"f2\": 0.8097792448937488, \"f0_5\": 0.9445313440019252, \"p4\": 0.8517432924889973, \"phi\": 0.7423775625106276}, {\"truth_threshold\": -2.4515988221809746, \"match_probability\": 0.15455425316384594, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1568.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 463.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7720334529876709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2279665172100067, \"precision\": 1.0, \"recall\": 0.7720334529876709, \"specificity\": 1.0, \"npv\": 0.7120646834373474, \"accuracy\": 0.8542191386222839, \"f1\": 0.8713531536537927, \"f2\": 0.8089145687164672, \"f0_5\": 0.9442370227628568, \"p4\": 0.8511276780405328, \"phi\": 0.741443032887153}, {\"truth_threshold\": -2.4321001719488917, \"match_probability\": 0.15632853446809272, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1560.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 471.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.768094539642334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23190546035766602, \"precision\": 1.0, \"recall\": 0.768094539642334, \"specificity\": 1.0, \"npv\": 0.708539605140686, \"accuracy\": 0.8517002463340759, \"f1\": 0.8688387635756056, \"f2\": 0.80545229244114, \"f0_5\": 0.9430540442509975, \"p4\": 0.8486664754292597, \"phi\": 0.7377163394076073}, {\"truth_threshold\": -2.4195497670065933, \"match_probability\": 0.1574793147772889, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1559.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 472.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7676021456718445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23239783942699432, \"precision\": 1.0, \"recall\": 0.7676021456718445, \"specificity\": 1.0, \"npv\": 0.7081014513969421, \"accuracy\": 0.8513854146003723, \"f1\": 0.8685236768802228, \"f2\": 0.8050191056490758, \"f0_5\": 0.9429055280029031, \"p4\": 0.8483589631234236, \"phi\": 0.7372517791567487}, {\"truth_threshold\": -2.394341468577947, \"match_probability\": 0.15981153188722882, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1558.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 473.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7671098113059998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23289020359516144, \"precision\": 1.0, \"recall\": 0.7671098113059998, \"specificity\": 1.0, \"npv\": 0.7076637744903564, \"accuracy\": 0.8510705232620239, \"f1\": 0.8682084146001672, \"f2\": 0.8045858293740963, \"f0_5\": 0.94275686796563, \"p4\": 0.8480514808431835, \"phi\": 0.7367875007737852}, {\"truth_threshold\": -2.3777284723310563, \"match_probability\": 0.16136376901855948, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1557.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 474.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7666174173355103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23338256776332855, \"precision\": 1.0, \"recall\": 0.7666174173355103, \"specificity\": 1.0, \"npv\": 0.7072266936302185, \"accuracy\": 0.8507556915283203, \"f1\": 0.8678929765886287, \"f2\": 0.8041524635884723, \"f0_5\": 0.9426080639302579, \"p4\": 0.8477440283943714, \"phi\": 0.736323503726159}, {\"truth_threshold\": -2.3500041100670894, \"match_probability\": 0.16398128096151293, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1556.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 475.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7661250829696655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23387493193149567, \"precision\": 1.0, \"recall\": 0.7661250829696655, \"specificity\": 1.0, \"npv\": 0.7067901492118835, \"accuracy\": 0.8504408001899719, \"f1\": 0.867577362698634, \"f2\": 0.8037190082644629, \"f0_5\": 0.9424591156874621, \"p4\": 0.8474366055826448, \"phi\": 0.7358597874822784}, {\"truth_threshold\": -2.2876972056181577, \"match_probability\": 0.16998820375749943, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1555.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 476.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.765632688999176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23436731100082397, \"precision\": 1.0, \"recall\": 0.765632688999176, \"specificity\": 1.0, \"npv\": 0.7063540816307068, \"accuracy\": 0.8501259684562683, \"f1\": 0.8672615727830452, \"f2\": 0.8032854633743155, \"f0_5\": 0.9423100230275118, \"p4\": 0.8471292122134862, \"phi\": 0.7353963515115162}, {\"truth_threshold\": -2.287577804181825, \"match_probability\": 0.16999988125877274, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1546.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 485.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7612013816833496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2387986183166504, \"precision\": 1.0, \"recall\": 0.7612013816833496, \"specificity\": 1.0, \"npv\": 0.7024539709091187, \"accuracy\": 0.8472921848297119, \"f1\": 0.8644115180318703, \"f2\": 0.7993795243019648, \"f0_5\": 0.9409616555082166, \"p4\": 0.8443639646235935, \"phi\": 0.7312379529846068}, {\"truth_threshold\": -2.2788126986872776, \"match_probability\": 0.17085885451324637, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1545.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 486.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7607089877128601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2392909824848175, \"precision\": 1.0, \"recall\": 0.7607089877128601, \"specificity\": 1.0, \"npv\": 0.7020233273506165, \"accuracy\": 0.8469773530960083, \"f1\": 0.8640939597315436, \"f2\": 0.7989450822215327, \"f0_5\": 0.9408111070515163, \"p4\": 0.8440568549426011, \"phi\": 0.730777290770382}, {\"truth_threshold\": -2.199321795947067, \"match_probability\": 0.17880662514970547, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1544.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 487.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7602166533470154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2397833615541458, \"precision\": 1.0, \"recall\": 0.7602166533470154, \"specificity\": 1.0, \"npv\": 0.7015931606292725, \"accuracy\": 0.8466624617576599, \"f1\": 0.8637762237762238, \"f2\": 0.7985105502689285, \"f0_5\": 0.9406604118435482, \"p4\": 0.843749772552718, \"phi\": 0.730316903055119}, {\"truth_threshold\": -2.181839732482668, \"match_probability\": 0.180592847339811, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1543.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 488.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7597242593765259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24027572572231293, \"precision\": 1.0, \"recall\": 0.7597242593765259, \"specificity\": 1.0, \"npv\": 0.7011635303497314, \"accuracy\": 0.8463476300239563, \"f1\": 0.863458310016788, \"f2\": 0.7980759284162615, \"f0_5\": 0.9405095696696331, \"p4\": 0.8434427172572686, \"phi\": 0.7298567893195214}, {\"truth_threshold\": -2.1808993515841633, \"match_probability\": 0.18068932349084327, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1541.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 490.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7587395310401917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24126046895980835, \"precision\": 1.0, \"recall\": 0.7587395310401917, \"specificity\": 1.0, \"npv\": 0.7003058195114136, \"accuracy\": 0.8457179069519043, \"f1\": 0.8628219484882419, \"f2\": 0.7972064148991206, \"f0_5\": 0.9402074435631482, \"p4\": 0.842828687162046, \"phi\": 0.7289373817147581}, {\"truth_threshold\": -2.173199149826056, \"match_probability\": 0.1814808189540905, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1540.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 491.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7582471966743469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24175283312797546, \"precision\": 1.0, \"recall\": 0.7582471966743469, \"specificity\": 1.0, \"npv\": 0.6998777389526367, \"accuracy\": 0.8454030156135559, \"f1\": 0.8625035004200504, \"f2\": 0.796771523178808, \"f0_5\": 0.940056159199121, \"p4\": 0.8425217119679963, \"phi\": 0.7284780868116124}, {\"truth_threshold\": -2.166820289346199, \"match_probability\": 0.1821385366214765, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1539.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 492.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7577548027038574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24224519729614258, \"precision\": 1.0, \"recall\": 0.7577548027038574, \"specificity\": 1.0, \"npv\": 0.6994501948356628, \"accuracy\": 0.8450881838798523, \"f1\": 0.8621848739495799, \"f2\": 0.7963365414467557, \"f0_5\": 0.9399047270062294, \"p4\": 0.842214763079826, \"phi\": 0.7280190638201667}, {\"truth_threshold\": -2.1167520635404418, \"match_probability\": 0.18736541770480097, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1537.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 494.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7567700743675232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.243229940533638, \"precision\": 1.0, \"recall\": 0.7567700743675232, \"specificity\": 1.0, \"npv\": 0.698596715927124, \"accuracy\": 0.8444584608078003, \"f1\": 0.8615470852017937, \"f2\": 0.7954663078356278, \"f0_5\": 0.9396014182662917, \"p4\": 0.8416009434305138, \"phi\": 0.7271018315144822}, {\"truth_threshold\": -2.1159592422346303, \"match_probability\": 0.18744910511323426, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1536.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 495.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7562776803970337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24372230470180511, \"precision\": 1.0, \"recall\": 0.7562776803970337, \"specificity\": 1.0, \"npv\": 0.6981707215309143, \"accuracy\": 0.8441435694694519, \"f1\": 0.8612279226240538, \"f2\": 0.7950310559006211, \"f0_5\": 0.9394495412844037, \"p4\": 0.8412940722735957, \"phi\": 0.7266436211735708}, {\"truth_threshold\": -2.0918814280562747, \"match_probability\": 0.19000438027628322, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1535.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 496.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.755785346031189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24421466886997223, \"precision\": 1.0, \"recall\": 0.755785346031189, \"specificity\": 1.0, \"npv\": 0.6977452635765076, \"accuracy\": 0.8438287377357483, \"f1\": 0.8609085810431857, \"f2\": 0.7945957138420127, \"f0_5\": 0.9392975156039652, \"p4\": 0.840987226631003, \"phi\": 0.7261856806910075}, {\"truth_threshold\": -2.0411026641633527, \"match_probability\": 0.19548050278252616, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1531.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 500.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7538158297538757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24618414044380188, \"precision\": 1.0, \"recall\": 0.7538158297538757, \"specificity\": 1.0, \"npv\": 0.6960486173629761, \"accuracy\": 0.8425692915916443, \"f1\": 0.8596294216732173, \"f2\": 0.7928534438114966, \"f0_5\": 0.9386879215205396, \"p4\": 0.839760095233761, \"phi\": 0.7243566071361862}, {\"truth_threshold\": -2.0106034817091407, \"match_probability\": 0.1988266287338049, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1530.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 501.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.753323495388031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2466765195131302, \"precision\": 1.0, \"recall\": 0.753323495388031, \"specificity\": 1.0, \"npv\": 0.6956257820129395, \"accuracy\": 0.8422544002532959, \"f1\": 0.8593091828138163, \"f2\": 0.7924176507147297, \"f0_5\": 0.9385351490614648, \"p4\": 0.8394533741835204, \"phi\": 0.7239000082971623}, {\"truth_threshold\": -1.9748677885351642, \"match_probability\": 0.2028018231862612, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1529.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 502.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7528311014175415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2471688836812973, \"precision\": 1.0, \"recall\": 0.7528311014175415, \"specificity\": 1.0, \"npv\": 0.695203423500061, \"accuracy\": 0.8419395685195923, \"f1\": 0.8589887640449438, \"f2\": 0.7919817673262198, \"f0_5\": 0.9383822265864735, \"p4\": 0.8391466774545462, \"phi\": 0.7234436762634593}, {\"truth_threshold\": -1.9389486186341054, \"match_probability\": 0.20685684113500383, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1527.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 504.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7518463730812073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24815361201763153, \"precision\": 1.0, \"recall\": 0.7518463730812073, \"specificity\": 1.0, \"npv\": 0.6943601965904236, \"accuracy\": 0.8413098454475403, \"f1\": 0.8583473861720068, \"f2\": 0.7911097295617034, \"f0_5\": 0.9380759307040177, \"p4\": 0.838533356162117, \"phi\": 0.7225318105900003}, {\"truth_threshold\": -1.935489115302131, \"match_probability\": 0.20725054154572878, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1526.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 505.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7513540387153625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24864599108695984, \"precision\": 1.0, \"recall\": 0.7513540387153625, \"specificity\": 1.0, \"npv\": 0.6939393877983093, \"accuracy\": 0.8409949541091919, \"f1\": 0.8580264267641271, \"f2\": 0.7906735751295336, \"f0_5\": 0.9379225568531039, \"p4\": 0.8382267311990319, \"phi\": 0.7220762759414389}, {\"truth_threshold\": -1.9295627062487606, \"match_probability\": 0.20792626763800293, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1525.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 506.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.750861644744873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24913835525512695, \"precision\": 1.0, \"recall\": 0.750861644744873, \"specificity\": 1.0, \"npv\": 0.6935190558433533, \"accuracy\": 0.8406801223754883, \"f1\": 0.8577052868391452, \"f2\": 0.7902373302932947, \"f0_5\": 0.9377690320993728, \"p4\": 0.8379201297579515, \"phi\": 0.7216210060805823}, {\"truth_threshold\": -1.9049899328479187, \"match_probability\": 0.21074536423131582, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1524.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 507.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7503692507743835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24963071942329407, \"precision\": 1.0, \"recall\": 0.7503692507743835, \"specificity\": 1.0, \"npv\": 0.6930992603302002, \"accuracy\": 0.8403652310371399, \"f1\": 0.8573839662447258, \"f2\": 0.7898009950248757, \"f0_5\": 0.9376153562200074, \"p4\": 0.8376135516385673, \"phi\": 0.7211660005052176}, {\"truth_threshold\": -1.9040098411269413, \"match_probability\": 0.21085838355024664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1522.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 509.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7493845224380493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2506154477596283, \"precision\": 1.0, \"recall\": 0.7493845224380493, \"specificity\": 1.0, \"npv\": 0.6922611594200134, \"accuracy\": 0.8397355079650879, \"f1\": 0.8567407824373768, \"f2\": 0.7889280530789965, \"f0_5\": 0.9373075501909102, \"p4\": 0.8370004645626585, \"phi\": 0.7202567802064647}, {\"truth_threshold\": -1.8639795389224918, \"match_probability\": 0.21551242625353073, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1521.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 510.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7488921880722046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2511078417301178, \"precision\": 1.0, \"recall\": 0.7488921880722046, \"specificity\": 1.0, \"npv\": 0.6918429136276245, \"accuracy\": 0.8394206762313843, \"f1\": 0.856418918918919, \"f2\": 0.7884914463452566, \"f0_5\": 0.9371534195933456, \"p4\": 0.83669395520452, \"phi\": 0.7198025644829947}, {\"truth_threshold\": -1.8616858017077826, \"match_probability\": 0.2157813467434966, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1519.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 512.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7479074597358704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.252092570066452, \"precision\": 1.0, \"recall\": 0.7479074597358704, \"specificity\": 1.0, \"npv\": 0.6910078525543213, \"accuracy\": 0.8387909531593323, \"f1\": 0.8557746478873239, \"f2\": 0.7876179612153894, \"f0_5\": 0.9368447021092883, \"p4\": 0.8360810038423322, \"phi\": 0.7188949193941375}, {\"truth_threshold\": -1.8569550982411198, \"match_probability\": 0.2163367479322753, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1518.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 513.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7474150657653809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25258493423461914, \"precision\": 1.0, \"recall\": 0.7474150657653809, \"specificity\": 1.0, \"npv\": 0.6905910968780518, \"accuracy\": 0.8384760618209839, \"f1\": 0.8554522400676247, \"f2\": 0.7871810827629122, \"f0_5\": 0.9366901147723066, \"p4\": 0.8357745614354601, \"phi\": 0.7184414890338364}, {\"truth_threshold\": -1.8516481824787168, \"match_probability\": 0.21696102925818742, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1517.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 514.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7469226717948914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25307729840278625, \"precision\": 1.0, \"recall\": 0.7469226717948914, \"specificity\": 1.0, \"npv\": 0.6901748180389404, \"accuracy\": 0.8381612300872803, \"f1\": 0.855129650507328, \"f2\": 0.7867441136811534, \"f0_5\": 0.9365353747376219, \"p4\": 0.8354681409425155, \"phi\": 0.7179883194677703}, {\"truth_threshold\": -1.8076898626917153, \"match_probability\": 0.2221820978447469, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1516.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 515.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7464303374290466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25356966257095337, \"precision\": 1.0, \"recall\": 0.7464303374290466, \"specificity\": 1.0, \"npv\": 0.6897590160369873, \"accuracy\": 0.8378463387489319, \"f1\": 0.8548068790527206, \"f2\": 0.7863070539419087, \"f0_5\": 0.9363804817788759, \"p4\": 0.835161742161578, \"phi\": 0.7175354102006172}, {\"truth_threshold\": -1.8056505105011356, \"match_probability\": 0.2224264832170944, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1515.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 516.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7459379434585571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2540620267391205, \"precision\": 1.0, \"recall\": 0.7459379434585571, \"specificity\": 1.0, \"npv\": 0.6893437504768372, \"accuracy\": 0.8375315070152283, \"f1\": 0.8544839255499154, \"f2\": 0.7858699035169623, \"f0_5\": 0.9362254356692622, \"p4\": 0.834855364890522, \"phi\": 0.7170827607379041}, {\"truth_threshold\": -1.7632727728076258, \"match_probability\": 0.22754819593822617, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1514.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 517.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7454456090927124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25455442070961, \"precision\": 1.0, \"recall\": 0.7454456090927124, \"specificity\": 1.0, \"npv\": 0.68892902135849, \"accuracy\": 0.8372166156768799, \"f1\": 0.8541607898448519, \"f2\": 0.7854326623780867, \"f0_5\": 0.936070236181526, \"p4\": 0.8345490089270164, \"phi\": 0.7166303705860044}, {\"truth_threshold\": -1.7426376886946164, \"match_probability\": 0.23007205312616275, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1507.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 524.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7419990301132202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2580009698867798, \"precision\": 1.0, \"recall\": 0.7419990301132202, \"specificity\": 1.0, \"npv\": 0.6860395669937134, \"accuracy\": 0.8350126147270203, \"f1\": 0.8518937252685133, \"f2\": 0.7823694320423632, \"f0_5\": 0.9349795259957812, \"p4\": 0.8324050967544926, \"phi\": 0.7134708589373455}, {\"truth_threshold\": -1.7232424706031766, \"match_probability\": 0.23246209972217055, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1505.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 526.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.741014301776886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2589857280254364, \"precision\": 1.0, \"recall\": 0.741014301776886, \"specificity\": 1.0, \"npv\": 0.6852184534072876, \"accuracy\": 0.8343828916549683, \"f1\": 0.8512443438914027, \"f2\": 0.7814934053380413, \"f0_5\": 0.9346665010557694, \"p4\": 0.8317927306077135, \"phi\": 0.7125704471726241}, {\"truth_threshold\": -1.6925980014535682, \"match_probability\": 0.23627353174560783, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1504.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 527.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7405219078063965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2594780921936035, \"precision\": 1.0, \"recall\": 0.7405219078063965, \"specificity\": 1.0, \"npv\": 0.684808611869812, \"accuracy\": 0.8340680003166199, \"f1\": 0.850919377652051, \"f2\": 0.7810552555047777, \"f0_5\": 0.934509755188269, \"p4\": 0.8314865765456597, \"phi\": 0.7121206231636821}, {\"truth_threshold\": -1.657659223946404, \"match_probability\": 0.24067145240362955, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1503.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 528.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.740029513835907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25997045636177063, \"precision\": 1.0, \"recall\": 0.740029513835907, \"specificity\": 1.0, \"npv\": 0.6843993067741394, \"accuracy\": 0.8337531685829163, \"f1\": 0.8505942275042445, \"f2\": 0.7806170146463073, \"f0_5\": 0.9343528534129056, \"p4\": 0.8311804415517049, \"phi\": 0.711671053090757}, {\"truth_threshold\": -1.641955527014125, \"match_probability\": 0.24266627843067295, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1481.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 550.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7291974425315857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2708025574684143, \"precision\": 1.0, \"recall\": 0.7291974425315857, \"specificity\": 1.0, \"npv\": 0.6755162477493286, \"accuracy\": 0.8268262147903442, \"f1\": 0.8433940774487472, \"f2\": 0.7709526288391463, \"f0_5\": 0.9308610936517914, \"p4\": 0.8244498789393335, \"phi\": 0.7018437868529338}, {\"truth_threshold\": -1.627390785536495, \"match_probability\": 0.2445264414072946, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1480.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 551.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7287050485610962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2712949216365814, \"precision\": 1.0, \"recall\": 0.7287050485610962, \"specificity\": 1.0, \"npv\": 0.6751179099082947, \"accuracy\": 0.8265113234519958, \"f1\": 0.8430646539447451, \"f2\": 0.770512286547272, \"f0_5\": 0.9307005408124764, \"p4\": 0.8241441255231906, \"phi\": 0.7013999254293956}, {\"truth_threshold\": -1.6176289217419548, \"match_probability\": 0.24577858180974552, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1479.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 552.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7282127141952515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27178728580474854, \"precision\": 1.0, \"recall\": 0.7282127141952515, \"specificity\": 1.0, \"npv\": 0.6747201085090637, \"accuracy\": 0.8261964917182922, \"f1\": 0.8427350427350427, \"f2\": 0.7700718525460793, \"f0_5\": 0.9305398263495659, \"p4\": 0.823838386197093, \"phi\": 0.7009563065525244}, {\"truth_threshold\": -1.6001539770096478, \"match_probability\": 0.2480308402932506, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1474.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 557.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7257508635520935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2742491364479065, \"precision\": 1.0, \"recall\": 0.7257508635520935, \"specificity\": 1.0, \"npv\": 0.6727379560470581, \"accuracy\": 0.8246221542358398, \"f1\": 0.8410841654778888, \"f2\": 0.7678683058970619, \"f0_5\": 0.929733821117699, \"p4\": 0.8223098935491333, \"phi\": 0.6987418341231602}, {\"truth_threshold\": -1.5751201303976414, \"match_probability\": 0.2512813450393361, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1473.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 558.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.725258469581604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2747415006160736, \"precision\": 1.0, \"recall\": 0.725258469581604, \"specificity\": 1.0, \"npv\": 0.6723428964614868, \"accuracy\": 0.8243073225021362, \"f1\": 0.8407534246575342, \"f2\": 0.7674273210378243, \"f0_5\": 0.9295721317682696, \"p4\": 0.8220042343390863, \"phi\": 0.6982996607897517}, {\"truth_threshold\": -1.5716749605728857, \"match_probability\": 0.251730889669115, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1471.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 560.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7242737412452698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27572622895240784, \"precision\": 1.0, \"recall\": 0.7242737412452698, \"specificity\": 1.0, \"npv\": 0.6715542674064636, \"accuracy\": 0.8236775994300842, \"f1\": 0.8400913763563678, \"f2\": 0.7665450755601876, \"f0_5\": 0.9292482627921668, \"p4\": 0.8213929535462696, \"phi\": 0.6974160315875885}, {\"truth_threshold\": -1.5573235729298913, \"match_probability\": 0.2536092719919542, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1470.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 561.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.723781406879425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27621862292289734, \"precision\": 1.0, \"recall\": 0.723781406879425, \"specificity\": 1.0, \"npv\": 0.6711606383323669, \"accuracy\": 0.8233627080917358, \"f1\": 0.8397600685518424, \"f2\": 0.7661038148843027, \"f0_5\": 0.9290860826697004, \"p4\": 0.8210873315393467, \"phi\": 0.6969745748002024}, {\"truth_threshold\": -1.489300548641593, \"match_probability\": 0.26263757735543086, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1469.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 562.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7232890129089355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27671098709106445, \"precision\": 1.0, \"recall\": 0.7232890129089355, \"specificity\": 1.0, \"npv\": 0.6707674264907837, \"accuracy\": 0.8230478763580322, \"f1\": 0.8394285714285714, \"f2\": 0.7656624622120296, \"f0_5\": 0.9289237384595928, \"p4\": 0.8207817215089066, \"phi\": 0.6965333559440808}, {\"truth_threshold\": -1.4876572891473019, \"match_probability\": 0.2628582186827173, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1464.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 567.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7208271622657776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2791728079319, \"precision\": 1.0, \"recall\": 0.7208271622657776, \"specificity\": 1.0, \"npv\": 0.6688084006309509, \"accuracy\": 0.8214735388755798, \"f1\": 0.8377682403433476, \"f2\": 0.7634543178973717, \"f0_5\": 0.9281095473564093, \"p4\": 0.8192538435513413, \"phi\": 0.6943308146458437}, {\"truth_threshold\": -1.4343830620783258, \"match_probability\": 0.2700756930491003, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1463.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 568.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7203348278999329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2796652019023895, \"precision\": 1.0, \"recall\": 0.7203348278999329, \"specificity\": 1.0, \"npv\": 0.6684179902076721, \"accuracy\": 0.8211587071418762, \"f1\": 0.8374356038923869, \"f2\": 0.7630124126421195, \"f0_5\": 0.9279462133705442, \"p4\": 0.8189483009047794, \"phi\": 0.6938910137954826}, {\"truth_threshold\": -1.4217473006256587, \"match_probability\": 0.2718057598718079, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1462.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 569.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7198424339294434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28015756607055664, \"precision\": 1.0, \"recall\": 0.7198424339294434, \"specificity\": 1.0, \"npv\": 0.6680279970169067, \"accuracy\": 0.8208438158035278, \"f1\": 0.8371027769825365, \"f2\": 0.7625704151888171, \"f0_5\": 0.9277827135423277, \"p4\": 0.8186427687407167, \"phi\": 0.6934514476891785}, {\"truth_threshold\": -1.3789168965459015, \"match_probability\": 0.27772142508429126, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1460.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 571.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7188577055931091, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28114229440689087, \"precision\": 1.0, \"recall\": 0.7188577055931091, \"specificity\": 1.0, \"npv\": 0.6672494411468506, \"accuracy\": 0.8202140927314758, \"f1\": 0.836436551131481, \"f2\": 0.761686143572621, \"f0_5\": 0.9274552153474781, \"p4\": 0.8180317350021501, \"phi\": 0.692573017899682}, {\"truth_threshold\": -1.3616271968043412, \"match_probability\": 0.2801317759130472, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1459.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 572.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7183653116226196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.281634658575058, \"precision\": 1.0, \"recall\": 0.7183653116226196, \"specificity\": 1.0, \"npv\": 0.666860818862915, \"accuracy\": 0.8198992609977722, \"f1\": 0.8361031518624642, \"f2\": 0.7612438693519774, \"f0_5\": 0.9272912164738782, \"p4\": 0.8177262329980465, \"phi\": 0.6921341533137343}, {\"truth_threshold\": -1.3486812006550575, \"match_probability\": 0.28194491489369217, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1458.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 573.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7178729772567749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2821270227432251, \"precision\": 1.0, \"recall\": 0.7178729772567749, \"specificity\": 1.0, \"npv\": 0.6664726138114929, \"accuracy\": 0.8195843696594238, \"f1\": 0.8357695614789338, \"f2\": 0.7608015028177834, \"f0_5\": 0.9271270507439908, \"p4\": 0.817420740617241, \"phi\": 0.6916955216663294}, {\"truth_threshold\": -1.347122136983168, \"match_probability\": 0.2821637483147712, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1457.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 574.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7173805832862854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2826193869113922, \"precision\": 1.0, \"recall\": 0.7173805832862854, \"specificity\": 1.0, \"npv\": 0.6660849452018738, \"accuracy\": 0.8192695379257202, \"f1\": 0.8354357798165137, \"f2\": 0.7603590439411335, \"f0_5\": 0.9269627179030411, \"p4\": 0.8171152576442998, \"phi\": 0.691257122507855}, {\"truth_threshold\": -1.3469202208279865, \"match_probability\": 0.2821920972252265, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1454.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 577.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7159035205841064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28409650921821594, \"precision\": 1.0, \"recall\": 0.7159035205841064, \"specificity\": 1.0, \"npv\": 0.6649245023727417, \"accuracy\": 0.8183249235153198, \"f1\": 0.8344332855093257, \"f2\": 0.7590311129672166, \"f0_5\": 0.926468714158277, \"p4\": 0.8161988630144861, \"phi\": 0.6899433154804018}, {\"truth_threshold\": -1.3287695132171042, \"match_probability\": 0.28474749243329367, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1453.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 578.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7154111266136169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28458887338638306, \"precision\": 1.0, \"recall\": 0.7154111266136169, \"specificity\": 1.0, \"npv\": 0.6645386219024658, \"accuracy\": 0.8180100917816162, \"f1\": 0.8340987370838117, \"f2\": 0.7585882844314503, \"f0_5\": 0.9263037103149305, \"p4\": 0.8158934155135413, \"phi\": 0.6895058417955253}, {\"truth_threshold\": -1.2952895988248896, \"match_probability\": 0.2894973912623797, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1452.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 579.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7149187326431274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28508123755455017, \"precision\": 1.0, \"recall\": 0.7149187326431274, \"specificity\": 1.0, \"npv\": 0.6641531586647034, \"accuracy\": 0.8176952004432678, \"f1\": 0.8337639965546942, \"f2\": 0.7581453634085213, \"f0_5\": 0.9261385380788366, \"p4\": 0.8155879763394422, \"phi\": 0.6890685983619979}, {\"truth_threshold\": -1.2732517871332498, \"match_probability\": 0.29264945159455713, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1450.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 581.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7139340043067932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2860659658908844, \"precision\": 1.0, \"recall\": 0.7139340043067932, \"specificity\": 1.0, \"npv\": 0.6633835434913635, \"accuracy\": 0.8170654773712158, \"f1\": 0.8330939385234128, \"f2\": 0.7572592437852518, \"f0_5\": 0.9258076873962456, \"p4\": 0.8149771221036006, \"phi\": 0.6881948004679341}, {\"truth_threshold\": -1.218568255428053, \"match_probability\": 0.3005569439949336, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1449.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 582.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7134416699409485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2865583598613739, \"precision\": 1.0, \"recall\": 0.7134416699409485, \"specificity\": 1.0, \"npv\": 0.6629993915557861, \"accuracy\": 0.8167506456375122, \"f1\": 0.8327586206896552, \"f2\": 0.7568160451269195, \"f0_5\": 0.9256420084323496, \"p4\": 0.8146717066071144, \"phi\": 0.6877582451185876}, {\"truth_threshold\": -1.1944067534303309, \"match_probability\": 0.3040893562171928, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1448.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 583.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.712949275970459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.287050724029541, \"precision\": 1.0, \"recall\": 0.712949275970459, \"specificity\": 1.0, \"npv\": 0.6626157164573669, \"accuracy\": 0.8164357542991638, \"f1\": 0.8324231100891061, \"f2\": 0.7563727538654409, \"f0_5\": 0.925476160040905, \"p4\": 0.8143662985679848, \"phi\": 0.6873219182429656}, {\"truth_threshold\": -1.160542530237874, \"match_probability\": 0.3090793843381318, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1447.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 584.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7124569416046143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28754308819770813, \"precision\": 1.0, \"recall\": 0.7124569416046143, \"specificity\": 1.0, \"npv\": 0.662232518196106, \"accuracy\": 0.8161209225654602, \"f1\": 0.8320874065554916, \"f2\": 0.7559293699717898, \"f0_5\": 0.9253101419618877, \"p4\": 0.8140608977681825, \"phi\": 0.6868858193983706}, {\"truth_threshold\": -1.1576676552985323, \"match_probability\": 0.3095050883302143, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1446.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 585.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7119645476341248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28803545236587524, \"precision\": 1.0, \"recall\": 0.7119645476341248, \"specificity\": 1.0, \"npv\": 0.6618497371673584, \"accuracy\": 0.8158060312271118, \"f1\": 0.8317515099223468, \"f2\": 0.7554858934169278, \"f0_5\": 0.9251439539347409, \"p4\": 0.8137555039894132, \"phi\": 0.6864499481427844}, {\"truth_threshold\": -1.137632356223202, \"match_probability\": 0.3124808148032423, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1445.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 586.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7114721536636353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28852781653404236, \"precision\": 1.0, \"recall\": 0.7114721536636353, \"specificity\": 1.0, \"npv\": 0.6614673733711243, \"accuracy\": 0.8154911994934082, \"f1\": 0.8314154200230149, \"f2\": 0.7550423241718048, \"f0_5\": 0.9249775956983741, \"p4\": 0.8134501170131173, \"phi\": 0.6860143040348656}, {\"truth_threshold\": -1.133725307670558, \"match_probability\": 0.3130629217583312, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1444.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 587.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7109798192977905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2890201807022095, \"precision\": 1.0, \"recall\": 0.7109798192977905, \"specificity\": 1.0, \"npv\": 0.6610854268074036, \"accuracy\": 0.8151763081550598, \"f1\": 0.8310791366906475, \"f2\": 0.7545986622073578, \"f0_5\": 0.9248110669911618, \"p4\": 0.8131447366204683, \"phi\": 0.6855788866339472}, {\"truth_threshold\": -1.126435345805533, \"match_probability\": 0.31415062096560004, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1442.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 589.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7099950909614563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2900049090385437, \"precision\": 1.0, \"recall\": 0.7099950909614563, \"specificity\": 1.0, \"npv\": 0.6603229641914368, \"accuracy\": 0.8145465850830078, \"f1\": 0.8304059890584509, \"f2\": 0.7537110600041814, \"f0_5\": 0.9244774971150147, \"p4\": 0.8125339947094666, \"phi\": 0.6847087301938041}, {\"truth_threshold\": -1.1192530704661139, \"match_probability\": 0.3152242525840914, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1441.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 590.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7095026969909668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2904973030090332, \"precision\": 1.0, \"recall\": 0.7095026969909668, \"specificity\": 1.0, \"npv\": 0.6599423885345459, \"accuracy\": 0.8142317533493042, \"f1\": 0.8300691244239631, \"f2\": 0.7532671197072661, \"f0_5\": 0.9243104554201411, \"p4\": 0.8122286327521192, \"phi\": 0.6842739902765982}, {\"truth_threshold\": -1.1042310231346055, \"match_probability\": 0.3174761833109747, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1440.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 591.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7090103626251221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2909896671772003, \"precision\": 1.0, \"recall\": 0.7090103626251221, \"specificity\": 1.0, \"npv\": 0.6595622301101685, \"accuracy\": 0.8139168620109558, \"f1\": 0.8297320656871219, \"f2\": 0.7528230865746549, \"f0_5\": 0.9241432422025414, \"p4\": 0.8119232765004275, \"phi\": 0.6838394753104262}, {\"truth_threshold\": -1.0928302326528632, \"match_probability\": 0.31919098535991663, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1439.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 592.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7085179686546326, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29148203134536743, \"precision\": 1.0, \"recall\": 0.7085179686546326, \"specificity\": 1.0, \"npv\": 0.6591824889183044, \"accuracy\": 0.8136020302772522, \"f1\": 0.8293948126801153, \"f2\": 0.7523789605772248, \"f0_5\": 0.9239758571978939, \"p4\": 0.8116179257342173, \"phi\": 0.6834051848579609}, {\"truth_threshold\": -1.0778311871087376, \"match_probability\": 0.3214544735411157, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1438.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 593.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7080255746841431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29197439551353455, \"precision\": 1.0, \"recall\": 0.7080255746841431, \"specificity\": 1.0, \"npv\": 0.6588032245635986, \"accuracy\": 0.8132871389389038, \"f1\": 0.829057365234938, \"f2\": 0.7519347416858397, \"f0_5\": 0.9238083001413336, \"p4\": 0.8113125802330422, \"phi\": 0.6829711184825358}, {\"truth_threshold\": -1.072619789868458, \"match_probability\": 0.3222428938868678, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1437.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 594.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7075332403182983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29246675968170166, \"precision\": 1.0, \"recall\": 0.7075332403182983, \"specificity\": 1.0, \"npv\": 0.6584243774414062, \"accuracy\": 0.8129723072052002, \"f1\": 0.828719723183391, \"f2\": 0.7514904298713524, \"f0_5\": 0.9236405707674509, \"p4\": 0.811007239776182, \"phi\": 0.6825372757481436}, {\"truth_threshold\": -1.0488578452284998, \"match_probability\": 0.32585057709414306, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1436.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 595.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7070408463478088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2929591238498688, \"precision\": 1.0, \"recall\": 0.7070408463478088, \"specificity\": 1.0, \"npv\": 0.6580459475517273, \"accuracy\": 0.8126574158668518, \"f1\": 0.8283818863570811, \"f2\": 0.7510460251046025, \"f0_5\": 0.9234726688102894, \"p4\": 0.8107019041426428, \"phi\": 0.6821036562194343}, {\"truth_threshold\": -1.0486615940243689, \"match_probability\": 0.32588045999407356, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1435.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 596.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7065485119819641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2934514880180359, \"precision\": 1.0, \"recall\": 0.7065485119819641, \"specificity\": 1.0, \"npv\": 0.6576679944992065, \"accuracy\": 0.8123425841331482, \"f1\": 0.8280438545874207, \"f2\": 0.750601527356418, \"f0_5\": 0.9233045940033457, \"p4\": 0.8103965731111544, \"phi\": 0.6816702594617118}, {\"truth_threshold\": -1.045257116426562, \"match_probability\": 0.32639908023153524, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1434.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 597.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7060561180114746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2939438819885254, \"precision\": 1.0, \"recall\": 0.7060561180114746, \"specificity\": 1.0, \"npv\": 0.6572904586791992, \"accuracy\": 0.8120276927947998, \"f1\": 0.8277056277056277, \"f2\": 0.7501569365976145, \"f0_5\": 0.9231363460795674, \"p4\": 0.8100912464601709, \"phi\": 0.6812370850409329}, {\"truth_threshold\": -1.022871879302503, \"match_probability\": 0.32981967346094077, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1433.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 598.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7055637836456299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2944362461566925, \"precision\": 1.0, \"recall\": 0.7055637836456299, \"specificity\": 1.0, \"npv\": 0.6569133400917053, \"accuracy\": 0.8117128610610962, \"f1\": 0.8273672055427251, \"f2\": 0.7497122527989954, \"f0_5\": 0.9229679247713513, \"p4\": 0.8097859239678689, \"phi\": 0.6808041325237048}, {\"truth_threshold\": -0.9722176382475161, \"match_probability\": 0.33762637174282245, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1430.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 601.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7040866613388062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29591333866119385, \"precision\": 1.0, \"recall\": 0.7040866613388062, \"specificity\": 1.0, \"npv\": 0.6557846665382385, \"accuracy\": 0.8107682466506958, \"f1\": 0.8263507656746605, \"f2\": 0.7483776428720954, \"f0_5\": 0.9224616178557605, \"p4\": 0.8088699792206349, \"phi\": 0.6795066020691028}, {\"truth_threshold\": -0.9553186312865689, \"match_probability\": 0.34025087952174227, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1426.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 605.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7021172046661377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2978828251361847, \"precision\": 1.0, \"recall\": 0.7021172046661377, \"specificity\": 1.0, \"npv\": 0.654285728931427, \"accuracy\": 0.8095088005065918, \"f1\": 0.8249927682962106, \"f2\": 0.7465968586387435, \"f0_5\": 0.9217840982546864, \"p4\": 0.807648764272955, \"phi\": 0.6777796419330703}, {\"truth_threshold\": -0.9427747636624831, \"match_probability\": 0.3422053805567697, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1425.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 606.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7016248106956482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2983751893043518, \"precision\": 1.0, \"recall\": 0.7016248106956482, \"specificity\": 1.0, \"npv\": 0.6539120674133301, \"accuracy\": 0.8091939687728882, \"f1\": 0.8246527777777778, \"f2\": 0.7461514294690543, \"f0_5\": 0.9216142801707412, \"p4\": 0.8073434670308465, \"phi\": 0.6773484491194175}, {\"truth_threshold\": -0.9417463901078564, \"match_probability\": 0.3423658536945228, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1424.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 607.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.7011324763298035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2988675534725189, \"precision\": 1.0, \"recall\": 0.7011324763298035, \"specificity\": 1.0, \"npv\": 0.6535388231277466, \"accuracy\": 0.8088790774345398, \"f1\": 0.8243125904486251, \"f2\": 0.7457059069962296, \"f0_5\": 0.9214442862689272, \"p4\": 0.8070381719383619, \"phi\": 0.6769174743376838}, {\"truth_threshold\": -0.9344964696314119, \"match_probability\": 0.34349819343988264, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1423.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 608.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.700640082359314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29935991764068604, \"precision\": 1.0, \"recall\": 0.700640082359314, \"specificity\": 1.0, \"npv\": 0.6531659960746765, \"accuracy\": 0.8085642457008362, \"f1\": 0.8239722061378112, \"f2\": 0.74526029119095, \"f0_5\": 0.9212741162760585, \"p4\": 0.8067328787708493, \"phi\": 0.6764867171608602}, {\"truth_threshold\": -0.9297657661647496, \"match_probability\": 0.3442380271393253, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1419.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 612.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6986706256866455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3013294041156769, \"precision\": 1.0, \"recall\": 0.6986706256866455, \"specificity\": 1.0, \"npv\": 0.6516789793968201, \"accuracy\": 0.8073047995567322, \"f1\": 0.8226086956521739, \"f2\": 0.7434768940584722, \"f0_5\": 0.920591669910471, \"p4\": 0.8055117208473576, \"phi\": 0.6747658559843733}, {\"truth_threshold\": -0.9225834908253306, \"match_probability\": 0.34536270614140363, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1418.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 613.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.698178231716156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.301821768283844, \"precision\": 1.0, \"recall\": 0.698178231716156, \"specificity\": 1.0, \"npv\": 0.6513082981109619, \"accuracy\": 0.8069899082183838, \"f1\": 0.822267323861989, \"f2\": 0.7430308111507021, \"f0_5\": 0.9204206153446709, \"p4\": 0.8052064339247906, \"phi\": 0.6743361804488228}, {\"truth_threshold\": -0.9089146414077053, \"match_probability\": 0.34750790277153404, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1416.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 615.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6971935033798218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3028064966201782, \"precision\": 1.0, \"recall\": 0.6971935033798218, \"specificity\": 1.0, \"npv\": 0.6505681872367859, \"accuracy\": 0.8063601851463318, \"f1\": 0.8215839860748477, \"f2\": 0.7421383647798742, \"f0_5\": 0.9200779727095516, \"p4\": 0.8045958615658608, \"phi\": 0.6734774741228791}, {\"truth_threshold\": -0.9026727469667912, \"match_probability\": 0.3484895778623742, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1415.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 616.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6967011094093323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30329886078834534, \"precision\": 1.0, \"recall\": 0.6967011094093323, \"specificity\": 1.0, \"npv\": 0.650198757648468, \"accuracy\": 0.8060453534126282, \"f1\": 0.8212420197330238, \"f2\": 0.7416920012579935, \"f0_5\": 0.9199063840852945, \"p4\": 0.8042905756758165, \"phi\": 0.6730484424877639}, {\"truth_threshold\": -0.8873746904900209, \"match_probability\": 0.3509009658870291, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1414.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 617.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6962087750434875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30379122495651245, \"precision\": 1.0, \"recall\": 0.6962087750434875, \"specificity\": 1.0, \"npv\": 0.6498297452926636, \"accuracy\": 0.8057304620742798, \"f1\": 0.820899854862119, \"f2\": 0.7412455441392325, \"f0_5\": 0.9197346168856511, \"p4\": 0.8039852896757712, \"phi\": 0.672619624642423}, {\"truth_threshold\": -0.8821348109831875, \"match_probability\": 0.3517286737043222, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1412.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 619.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6952240467071533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30477598309516907, \"precision\": 1.0, \"recall\": 0.6952240467071533, \"specificity\": 1.0, \"npv\": 0.649092972278595, \"accuracy\": 0.8051007390022278, \"f1\": 0.8202149288411269, \"f2\": 0.7403523489932886, \"f0_5\": 0.919390545643964, \"p4\": 0.8033747164350464, \"phi\": 0.6717626286383197}, {\"truth_threshold\": -0.8781627018453952, \"match_probability\": 0.3523567151060015, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1408.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 623.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6932545304298401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3067454397678375, \"precision\": 1.0, \"recall\": 0.6932545304298401, \"specificity\": 1.0, \"npv\": 0.6476244330406189, \"accuracy\": 0.8038412928581238, \"f1\": 0.8188426868275661, \"f2\": 0.7385648342425514, \"f0_5\": 0.9187002479446692, \"p4\": 0.8021535585998486, \"phi\": 0.6700511836310209}, {\"truth_threshold\": -0.8095853840346642, \"match_probability\": 0.36327867815690584, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1407.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 624.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6927621960639954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30723780393600464, \"precision\": 1.0, \"recall\": 0.6927621960639954, \"specificity\": 1.0, \"npv\": 0.6472583413124084, \"accuracy\": 0.8035264611244202, \"f1\": 0.8184991273996509, \"f2\": 0.738117721120554, \"f0_5\": 0.918527222875049, \"p4\": 0.8018482654406616, \"phi\": 0.669623850564424}, {\"truth_threshold\": -0.8052686131505139, \"match_probability\": 0.3639710687203058, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1406.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 625.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6922698020935059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30773016810417175, \"precision\": 1.0, \"recall\": 0.6922698020935059, \"specificity\": 1.0, \"npv\": 0.6468926668167114, \"accuracy\": 0.8032115697860718, \"f1\": 0.8181553680535351, \"f2\": 0.7376705141657922, \"f0_5\": 0.9183540169823645, \"p4\": 0.8015429703423823, \"phi\": 0.6691967279377447}, {\"truth_threshold\": -0.7937594013120964, \"match_probability\": 0.36581984354294195, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1405.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 626.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6917774677276611, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30822256207466125, \"precision\": 1.0, \"recall\": 0.6917774677276611, \"specificity\": 1.0, \"npv\": 0.6465274095535278, \"accuracy\": 0.8028967380523682, \"f1\": 0.8178114086146682, \"f2\": 0.737223213348725, \"f0_5\": 0.9181806299830088, \"p4\": 0.8012376730750075, \"phi\": 0.6687698153349331}, {\"truth_threshold\": -0.7890286978454343, \"match_probability\": 0.3665809086869392, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1404.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 627.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6912850737571716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30871492624282837, \"precision\": 1.0, \"recall\": 0.6912850737571716, \"specificity\": 1.0, \"npv\": 0.6461625099182129, \"accuracy\": 0.8025818467140198, \"f1\": 0.8174672489082969, \"f2\": 0.7367758186397985, \"f0_5\": 0.9180070615927814, \"p4\": 0.8009323734082261, \"phi\": 0.6683431123405287}, {\"truth_threshold\": -0.7765212621219658, \"match_probability\": 0.36859627798622285, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1402.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 629.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6903003454208374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3096996545791626, \"precision\": 1.0, \"recall\": 0.6903003454208374, \"specificity\": 1.0, \"npv\": 0.6454340219497681, \"accuracy\": 0.8019521236419678, \"f1\": 0.816778327993009, \"f2\": 0.7358807474280915, \"f0_5\": 0.9176593794999346, \"p4\": 0.8003217659536572, \"phi\": 0.6674903335180326}, {\"truth_threshold\": -0.7595028537246856, \"match_probability\": 0.37134588832437104, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1399.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 632.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6888232231140137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31117674708366394, \"precision\": 1.0, \"recall\": 0.6888232231140137, \"specificity\": 1.0, \"npv\": 0.6443443894386292, \"accuracy\": 0.8010075688362122, \"f1\": 0.8157434402332362, \"f2\": 0.734537435682033, \"f0_5\": 0.9171364887898256, \"p4\": 0.7994058310006902, \"phi\": 0.6662127269944811}, {\"truth_threshold\": -0.7089680141060317, \"match_probability\": 0.37955930212876116, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1397.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 634.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6878384947776794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31216150522232056, \"precision\": 1.0, \"recall\": 0.6878384947776794, \"specificity\": 1.0, \"npv\": 0.6436200141906738, \"accuracy\": 0.8003778457641602, \"f1\": 0.8150525087514586, \"f2\": 0.7336414242201449, \"f0_5\": 0.9167869799186245, \"p4\": 0.7987951891462153, \"phi\": 0.6653620256392038}, {\"truth_threshold\": -0.6881458524508749, \"match_probability\": 0.38296400510831513, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1395.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 636.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6868537664413452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3131462335586548, \"precision\": 1.0, \"recall\": 0.6868537664413452, \"specificity\": 1.0, \"npv\": 0.6428972482681274, \"accuracy\": 0.7997481226921082, \"f1\": 0.8143607705779334, \"f2\": 0.7327450362433029, \"f0_5\": 0.9164367363027197, \"p4\": 0.7981845302790667, \"phi\": 0.6645121495072613}, {\"truth_threshold\": -0.6834151489842124, \"match_probability\": 0.3837391554713636, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1393.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 638.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.685869038105011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.314130961894989, \"precision\": 1.0, \"recall\": 0.685869038105011, \"specificity\": 1.0, \"npv\": 0.64217609167099, \"accuracy\": 0.7991183996200562, \"f1\": 0.8136682242990654, \"f2\": 0.7318482715141326, \"f0_5\": 0.9160857556227805, \"p4\": 0.7975738525329583, \"phi\": 0.6636630953189379}, {\"truth_threshold\": -0.6688483157153488, \"match_probability\": 0.38612970483530323, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1391.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 640.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6848843097686768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31511572003364563, \"precision\": 1.0, \"recall\": 0.6848843097686768, \"specificity\": 1.0, \"npv\": 0.6414566040039062, \"accuracy\": 0.7984886765480042, \"f1\": 0.8129748684979544, \"f2\": 0.7309511297950604, \"f0_5\": 0.9157340355497038, \"p4\": 0.7969631540364932, \"phi\": 0.6628148598035907}, {\"truth_threshold\": -0.6529396936478021, \"match_probability\": 0.38874673733253107, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1390.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 641.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6843919157981873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31560808420181274, \"precision\": 1.0, \"recall\": 0.6843919157981873, \"specificity\": 1.0, \"npv\": 0.6410974264144897, \"accuracy\": 0.7981737852096558, \"f1\": 0.8126278865828706, \"f2\": 0.7305024174900148, \"f0_5\": 0.9155578975102094, \"p4\": 0.7966577964206586, \"phi\": 0.6623910480286727}, {\"truth_threshold\": -0.649878315330451, \"match_probability\": 0.38925108821695736, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1389.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 642.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6838995814323425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31610044836997986, \"precision\": 1.0, \"recall\": 0.6838995814323425, \"specificity\": 1.0, \"npv\": 0.6407386660575867, \"accuracy\": 0.7978589534759521, \"f1\": 0.8122807017543859, \"f2\": 0.7300536108483129, \"f0_5\": 0.9153815737445631, \"p4\": 0.7963524329131265, \"phi\": 0.6619674396995868}, {\"truth_threshold\": -0.6486048002510222, \"match_probability\": 0.38946096505918315, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1388.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 643.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.683407187461853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.316592812538147, \"precision\": 1.0, \"recall\": 0.683407187461853, \"specificity\": 1.0, \"npv\": 0.640380322933197, \"accuracy\": 0.7975440621376038, \"f1\": 0.8119333138344546, \"f2\": 0.7296047098402019, \"f0_5\": 0.9152050639588554, \"p4\": 0.7960470632785187, \"phi\": 0.6615440344100268}, {\"truth_threshold\": -0.6268619367665249, \"match_probability\": 0.3930504773701661, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1387.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 644.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6829147934913635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3170851767063141, \"precision\": 1.0, \"recall\": 0.6829147934913635, \"specificity\": 1.0, \"npv\": 0.640022337436676, \"accuracy\": 0.7972292304039001, \"f1\": 0.8115857226448215, \"f2\": 0.7291557144359163, \"f0_5\": 0.9150283678585566, \"p4\": 0.7957416872811305, \"phi\": 0.6611208317542412}, {\"truth_threshold\": -0.6187657854053702, \"match_probability\": 0.39439004478809336, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1386.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 645.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6824224591255188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3175775408744812, \"precision\": 1.0, \"recall\": 0.6824224591255188, \"specificity\": 1.0, \"npv\": 0.6396648287773132, \"accuracy\": 0.7969143390655518, \"f1\": 0.8112379280070237, \"f2\": 0.7287066246056783, \"f0_5\": 0.9148514851485149, \"p4\": 0.7954363046849302, \"phi\": 0.6606978313270317}, {\"truth_threshold\": -0.5877367321847978, \"match_probability\": 0.3995385806987032, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1385.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 646.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6819300651550293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3180699050426483, \"precision\": 1.0, \"recall\": 0.6819300651550293, \"specificity\": 1.0, \"npv\": 0.6393076777458191, \"accuracy\": 0.7965995073318481, \"f1\": 0.8108899297423887, \"f2\": 0.7282574403196971, \"f0_5\": 0.9146744155329547, \"p4\": 0.7951309152535574, \"phi\": 0.6602750327237519}, {\"truth_threshold\": -0.5697660710396188, \"match_probability\": 0.4025306491994291, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1384.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 647.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6814377307891846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3185622990131378, \"precision\": 1.0, \"recall\": 0.6814377307891846, \"specificity\": 1.0, \"npv\": 0.6389508843421936, \"accuracy\": 0.7962846159934998, \"f1\": 0.8105417276720351, \"f2\": 0.72780816154817, \"f0_5\": 0.9144971587154751, \"p4\": 0.7948255187503221, \"phi\": 0.6598524355403044}, {\"truth_threshold\": -0.5390484592075476, \"match_probability\": 0.4076617823174536, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1383.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 648.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6809453368186951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31905466318130493, \"precision\": 1.0, \"recall\": 0.6809453368186951, \"specificity\": 1.0, \"npv\": 0.6385945081710815, \"accuracy\": 0.7959697842597961, \"f1\": 0.8101933216168717, \"f2\": 0.7273587882612812, \"f0_5\": 0.914319714399048, \"p4\": 0.7945201149382034, \"phi\": 0.6594300393731392}, {\"truth_threshold\": -0.5131522365441484, \"match_probability\": 0.4120032880454098, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1382.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 649.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6804530024528503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31954702734947205, \"precision\": 1.0, \"recall\": 0.6804530024528503, \"specificity\": 1.0, \"npv\": 0.6382385492324829, \"accuracy\": 0.7956548929214478, \"f1\": 0.8098447113975974, \"f2\": 0.7269093204292026, \"f0_5\": 0.9141420822860167, \"p4\": 0.7942147035798486, \"phi\": 0.6590078438192518}, {\"truth_threshold\": -0.5129964898270077, \"match_probability\": 0.41202944119917007, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1379.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 652.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6789758801460266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3210241198539734, \"precision\": 1.0, \"recall\": 0.6789758801460266, \"specificity\": 1.0, \"npv\": 0.637173056602478, \"accuracy\": 0.7947103381156921, \"f1\": 0.8087976539589443, \"f2\": 0.7255603493633589, \"f0_5\": 0.9136080561812641, \"p4\": 0.7932984218488349, \"phi\": 0.6577424568153551}, {\"truth_threshold\": -0.49567729181184167, \"match_probability\": 0.4149407664871107, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1378.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 653.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6784834861755371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3215164840221405, \"precision\": 1.0, \"recall\": 0.6784834861755371, \"specificity\": 1.0, \"npv\": 0.6368187069892883, \"accuracy\": 0.7943954467773438, \"f1\": 0.8084482252860077, \"f2\": 0.7251105030519891, \"f0_5\": 0.9134296698926156, \"p4\": 0.7929929779253273, \"phi\": 0.6573210596953777}, {\"truth_threshold\": -0.481041275105017, \"match_probability\": 0.41740570162005186, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1375.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 656.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6770064234733582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32299360632896423, \"precision\": 1.0, \"recall\": 0.6770064234733582, \"specificity\": 1.0, \"npv\": 0.6357579231262207, \"accuracy\": 0.7934508919715881, \"f1\": 0.8073987081620669, \"f2\": 0.7237603958311402, \"f0_5\": 0.9128933740539105, \"p4\": 0.7920765927688658, \"phi\": 0.6560580583751121}, {\"truth_threshold\": -0.3848238634437868, \"match_probability\": 0.43370769880734145, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1373.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 658.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6760216355323792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32397833466529846, \"precision\": 1.0, \"recall\": 0.6760216355323792, \"specificity\": 1.0, \"npv\": 0.6350526809692383, \"accuracy\": 0.7928211688995361, \"f1\": 0.8066980023501763, \"f2\": 0.7228598504790986, \"f0_5\": 0.9125348929948159, \"p4\": 0.7914656224449931, \"phi\": 0.655217045203576}, {\"truth_threshold\": -0.3838506599285532, \"match_probability\": 0.4338733850021727, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1370.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 661.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6745445728302002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3254554271697998, \"precision\": 1.0, \"recall\": 0.6745445728302002, \"specificity\": 1.0, \"npv\": 0.6339977979660034, \"accuracy\": 0.7918765544891357, \"f1\": 0.8056453984122317, \"f2\": 0.7215083210448704, \"f0_5\": 0.9119957395819465, \"p4\": 0.7905490918185237, \"phi\": 0.6539569990508374}, {\"truth_threshold\": -0.3658065295338101, \"match_probability\": 0.4369480065841115, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1363.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 668.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.671097993850708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.328902006149292, \"precision\": 1.0, \"recall\": 0.671097993850708, \"specificity\": 1.0, \"npv\": 0.6315498948097229, \"accuracy\": 0.7896725535392761, \"f1\": 0.803182086034178, \"f2\": 0.7183514282702645, \"f0_5\": 0.9107309902445543, \"p4\": 0.7884101358393227, \"phi\": 0.6510237127477586}, {\"truth_threshold\": -0.33720970693586294, \"match_probability\": 0.4418305980816297, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1362.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 669.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6706055998802185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3293944001197815, \"precision\": 1.0, \"recall\": 0.6706055998802185, \"specificity\": 1.0, \"npv\": 0.6312017440795898, \"accuracy\": 0.7893576622009277, \"f1\": 0.8028293545534925, \"f2\": 0.7179000632511069, \"f0_5\": 0.9105495387083835, \"p4\": 0.7881045231905476, \"phi\": 0.6506054456515225}, {\"truth_threshold\": -0.3173001137014576, \"match_probability\": 0.44523665213630964, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1361.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 670.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6701132655143738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3298867642879486, \"precision\": 1.0, \"recall\": 0.6701132655143738, \"specificity\": 1.0, \"npv\": 0.6308540105819702, \"accuracy\": 0.7890428304672241, \"f1\": 0.8024764150943396, \"f2\": 0.7174486030574592, \"f0_5\": 0.9103678929765886, \"p4\": 0.7877988979323594, \"phi\": 0.6501873708280803}, {\"truth_threshold\": -0.3172706154278524, \"match_probability\": 0.44524170248327455, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1360.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 671.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6696208715438843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3303791284561157, \"precision\": 1.0, \"recall\": 0.6696208715438843, \"specificity\": 1.0, \"npv\": 0.6305066347122192, \"accuracy\": 0.7887279391288757, \"f1\": 0.8021232674727219, \"f2\": 0.7169970476592156, \"f0_5\": 0.9101860527372507, \"p4\": 0.7874932598198026, \"phi\": 0.6497694878859451}, {\"truth_threshold\": -0.29900771217105826, \"match_probability\": 0.4483705922693665, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1359.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 672.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6691285371780396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33087149262428284, \"precision\": 1.0, \"recall\": 0.6691285371780396, \"specificity\": 1.0, \"npv\": 0.6301596164703369, \"accuracy\": 0.7884131073951721, \"f1\": 0.8017699115044248, \"f2\": 0.7165453970262575, \"f0_5\": 0.9100040176777823, \"p4\": 0.7871876086075619, \"phi\": 0.6493517964341311}, {\"truth_threshold\": -0.2601929806725884, \"match_probability\": 0.4550338102986572, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1357.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 674.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6681437492370605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33185622096061707, \"precision\": 1.0, \"recall\": 0.6681437492370605, \"specificity\": 1.0, \"npv\": 0.629466712474823, \"accuracy\": 0.7877833843231201, \"f1\": 0.8010625737898465, \"f2\": 0.7156418099356608, \"f0_5\": 0.9096393618447514, \"p4\": 0.7865762659009635, \"phi\": 0.6485169864400239}, {\"truth_threshold\": -0.18815428380300314, \"match_probability\": 0.4674414831136764, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1350.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 681.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6646971702575684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33530279994010925, \"precision\": 1.0, \"recall\": 0.6646971702575684, \"specificity\": 1.0, \"npv\": 0.6270536780357361, \"accuracy\": 0.7855793237686157, \"f1\": 0.7985803016858918, \"f2\": 0.7124762507916402, \"f0_5\": 0.9083568833266048, \"p4\": 0.7844361175550408, \"phi\": 0.6456011261657096}, {\"truth_threshold\": -0.16758204091781836, \"match_probability\": 0.4709928537937489, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1339.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 692.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6592811346054077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3407188653945923, \"precision\": 1.0, \"recall\": 0.6592811346054077, \"specificity\": 1.0, \"npv\": 0.6232988834381104, \"accuracy\": 0.7821158766746521, \"f1\": 0.7946587537091988, \"f2\": 0.7074923385818451, \"f0_5\": 0.9063219168810072, \"p4\": 0.7810714524065827, \"phi\": 0.6410375826134372}, {\"truth_threshold\": -0.15906450835026398, \"match_probability\": 0.4724641097715426, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1338.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 693.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.658788800239563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3412112295627594, \"precision\": 1.0, \"recall\": 0.658788800239563, \"specificity\": 1.0, \"npv\": 0.6229597330093384, \"accuracy\": 0.7818009853363037, \"f1\": 0.7943009795191451, \"f2\": 0.7070386810399493, \"f0_5\": 0.9061357171881349, \"p4\": 0.7807654687830268, \"phi\": 0.6406238230099892}, {\"truth_threshold\": -0.15692197431000374, \"match_probability\": 0.47283427166415054, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1336.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 695.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.657804012298584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34219595789909363, \"precision\": 1.0, \"recall\": 0.657804012298584, \"specificity\": 1.0, \"npv\": 0.6222826242446899, \"accuracy\": 0.7811712622642517, \"f1\": 0.7935847935847936, \"f2\": 0.7061310782241015, \"f0_5\": 0.9057627118644068, \"p4\": 0.7801534455115435, \"phi\": 0.639796852458844}, {\"truth_threshold\": -0.1246550357590617, \"match_probability\": 0.4784123572577697, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1334.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 697.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6568192839622498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34318068623542786, \"precision\": 1.0, \"recall\": 0.6568192839622498, \"specificity\": 1.0, \"npv\": 0.6216069459915161, \"accuracy\": 0.7805415391921997, \"f1\": 0.7928677563150074, \"f2\": 0.7052230915626982, \"f0_5\": 0.9053888964300257, \"p4\": 0.7795413458460344, \"phi\": 0.6389706109180103}, {\"truth_threshold\": -0.12060103578706893, \"match_probability\": 0.4791135944545649, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1332.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 699.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6558345556259155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3441654443740845, \"precision\": 1.0, \"recall\": 0.6558345556259155, \"specificity\": 1.0, \"npv\": 0.6209327578544617, \"accuracy\": 0.7799118161201477, \"f1\": 0.792149866190901, \"f2\": 0.7043147208121827, \"f0_5\": 0.9050142682429678, \"p4\": 0.778929167747172, \"phi\": 0.6381450953570468}, {\"truth_threshold\": -0.11409157023024666, \"match_probability\": 0.48023973476439047, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1324.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 707.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6518956422805786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3481043875217438, \"precision\": 1.0, \"recall\": 0.6518956422805786, \"specificity\": 1.0, \"npv\": 0.6182505488395691, \"accuracy\": 0.7773929238319397, \"f1\": 0.7892697466467958, \"f2\": 0.7006773920406435, \"f0_5\": 0.903507574723625, \"p4\": 0.7764796300097458, \"phi\": 0.6348502325555829}, {\"truth_threshold\": -0.11395724350377975, \"match_probability\": 0.48026297549928704, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1323.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 708.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6514032483100891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3485967516899109, \"precision\": 1.0, \"recall\": 0.6514032483100891, \"specificity\": 1.0, \"npv\": 0.6179168820381165, \"accuracy\": 0.7770780920982361, \"f1\": 0.7889087656529516, \"f2\": 0.7002222927913624, \"f0_5\": 0.9033183121671446, \"p4\": 0.7761733406911309, \"phi\": 0.6344391784423217}, {\"truth_threshold\": -0.09795899054816376, \"match_probability\": 0.48303151927594257, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1322.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 709.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6509108543395996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.349089115858078, \"precision\": 1.0, \"recall\": 0.6509108543395996, \"specificity\": 1.0, \"npv\": 0.6175836324691772, \"accuracy\": 0.7767632007598877, \"f1\": 0.7885475693408888, \"f2\": 0.6997670971839932, \"f0_5\": 0.9031288427380789, \"p4\": 0.775867028931697, \"phi\": 0.6340283016890773}, {\"truth_threshold\": -0.08385587433940267, \"match_probability\": 0.4854729739582383, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1321.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 710.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6504185199737549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3495814800262451, \"precision\": 1.0, \"recall\": 0.6504185199737549, \"specificity\": 1.0, \"npv\": 0.6172506809234619, \"accuracy\": 0.7764483690261841, \"f1\": 0.7881861575178998, \"f2\": 0.6993118051879301, \"f0_5\": 0.9029391660970608, \"p4\": 0.7755606944715063, \"phi\": 0.6336176019225929}, {\"truth_threshold\": -0.08011919966747892, \"match_probability\": 0.4861199677255348, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1320.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 711.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6499261260032654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35007384419441223, \"precision\": 1.0, \"recall\": 0.6499261260032654, \"specificity\": 1.0, \"npv\": 0.6169180870056152, \"accuracy\": 0.7761334776878357, \"f1\": 0.7878245299910475, \"f2\": 0.6988564167725541, \"f0_5\": 0.9027492819039803, \"p4\": 0.7752543370502095, \"phi\": 0.6332070787700438}, {\"truth_threshold\": -0.06407239135550613, \"match_probability\": 0.48889892522246375, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1318.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 713.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6489413976669312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35105860233306885, \"precision\": 1.0, \"recall\": 0.6489413976669312, \"specificity\": 1.0, \"npv\": 0.6162540316581726, \"accuracy\": 0.7755037546157837, \"f1\": 0.7871006270528516, \"f2\": 0.6979453505613218, \"f0_5\": 0.9023688894974667, \"p4\": 0.7746415522808361, \"phi\": 0.6323865608176021}, {\"truth_threshold\": -0.029248622472751697, \"match_probability\": 0.4949317735429722, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1317.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 714.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6484490633010864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35155096650123596, \"precision\": 1.0, \"recall\": 0.6484490633010864, \"specificity\": 1.0, \"npv\": 0.6159225106239319, \"accuracy\": 0.7751889228820801, \"f1\": 0.7867383512544803, \"f2\": 0.6974896727041627, \"f0_5\": 0.9021783806000822, \"p4\": 0.7743351244099922, \"phi\": 0.6319765652742048}, {\"truth_threshold\": -0.01623187762874135, \"match_probability\": 0.4971872596178668, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1316.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 715.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6479566693305969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3520433306694031, \"precision\": 1.0, \"recall\": 0.6479566693305969, \"specificity\": 1.0, \"npv\": 0.6155914068222046, \"accuracy\": 0.7748740315437317, \"f1\": 0.7863758589781894, \"f2\": 0.6970338983050848, \"f0_5\": 0.9019876627827279, \"p4\": 0.774028672532505, \"phi\": 0.6315667448577293}, {\"truth_threshold\": -0.013116042790668398, \"match_probability\": 0.49772717863441607, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1315.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 716.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6474642753601074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3525356948375702, \"precision\": 1.0, \"recall\": 0.6474642753601074, \"specificity\": 1.0, \"npv\": 0.6152606010437012, \"accuracy\": 0.7745591998100281, \"f1\": 0.7860131500298865, \"f2\": 0.696578027333404, \"f0_5\": 0.9017967357015498, \"p4\": 0.7737221963859477, \"phi\": 0.6311570991974859}, {\"truth_threshold\": 0.018549346727914043, \"match_probability\": 0.5032143125657873, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1314.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 717.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6469719409942627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3530280590057373, \"precision\": 1.0, \"recall\": 0.6469719409942627, \"specificity\": 1.0, \"npv\": 0.6149301528930664, \"accuracy\": 0.7742443084716797, \"f1\": 0.7856502242152467, \"f2\": 0.6961220597584233, \"f0_5\": 0.901605599011939, \"p4\": 0.7734156957074743, \"phi\": 0.6307476279232052}, {\"truth_threshold\": 0.026645498089068863, \"match_probability\": 0.5046171817210153, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1311.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 720.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.645494818687439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35450518131256104, \"precision\": 1.0, \"recall\": 0.645494818687439, \"specificity\": 1.0, \"npv\": 0.6139410138130188, \"accuracy\": 0.7732997536659241, \"f1\": 0.7845601436265709, \"f2\": 0.6947535771065183, \"f0_5\": 0.9010309278350516, \"p4\": 0.7724960438457679, \"phi\": 0.6295202567197429}, {\"truth_threshold\": 0.03663186777528578, \"match_probability\": 0.5063474779432486, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1309.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 722.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6445100903511047, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35548990964889526, \"precision\": 1.0, \"recall\": 0.6445100903511047, \"specificity\": 1.0, \"npv\": 0.6132833361625671, \"accuracy\": 0.7726700305938721, \"f1\": 0.7838323353293413, \"f2\": 0.6938407717587194, \"f0_5\": 0.9006467593229668, \"p4\": 0.7718828151071816, \"phi\": 0.6287028744111437}, {\"truth_threshold\": 0.05688119397991253, \"match_probability\": 0.5098554831529214, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1305.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 726.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6425406336784363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3574593663215637, \"precision\": 1.0, \"recall\": 0.6425406336784363, \"specificity\": 1.0, \"npv\": 0.6119722127914429, \"accuracy\": 0.7714105844497681, \"f1\": 0.7823741007194245, \"f2\": 0.6920139993636653, \"f0_5\": 0.8998758791890774, \"p4\": 0.7706560420857187, \"phi\": 0.6270701729352143}, {\"truth_threshold\": 0.08160480589530315, \"match_probability\": 0.5141372661315924, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1304.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 727.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6420482397079468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3579517602920532, \"precision\": 1.0, \"recall\": 0.6420482397079468, \"specificity\": 1.0, \"npv\": 0.6116452813148499, \"accuracy\": 0.7710956931114197, \"f1\": 0.7820089955022489, \"f2\": 0.6915570640644888, \"f0_5\": 0.8996826272940527, \"p4\": 0.7703492815381601, \"phi\": 0.6266624252473364}, {\"truth_threshold\": 0.0894286428705334, \"match_probability\": 0.5154918427277512, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1301.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 730.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6405711770057678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35942885279655457, \"precision\": 1.0, \"recall\": 0.6405711770057678, \"specificity\": 1.0, \"npv\": 0.6106666922569275, \"accuracy\": 0.7701511383056641, \"f1\": 0.7809123649459784, \"f2\": 0.6901856763925729, \"f0_5\": 0.899101589495508, \"p4\": 0.7694288341149976, \"phi\": 0.6254402027648458}, {\"truth_threshold\": 0.09773738557738643, \"match_probability\": 0.5169301236363302, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1300.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 731.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6400787830352783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3599212169647217, \"precision\": 1.0, \"recall\": 0.6400787830352783, \"specificity\": 1.0, \"npv\": 0.6103411316871643, \"accuracy\": 0.7698362469673157, \"f1\": 0.7805463824677275, \"f2\": 0.6897283531409168, \"f0_5\": 0.8989074816761167, \"p4\": 0.7691219621523272, \"phi\": 0.6250331342479231}, {\"truth_threshold\": 0.11148844584656366, \"match_probability\": 0.5193098667577489, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1299.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 732.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6395863890647888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3604135811328888, \"precision\": 1.0, \"recall\": 0.6395863890647888, \"specificity\": 1.0, \"npv\": 0.6100159883499146, \"accuracy\": 0.7695214152336121, \"f1\": 0.7801801801801802, \"f2\": 0.6892709328239415, \"f0_5\": 0.8987131589871316, \"p4\": 0.7688150616636867, \"phi\": 0.6246262346123782}, {\"truth_threshold\": 0.1242144561405659, \"match_probability\": 0.5215114379284995, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1298.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 733.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6390940546989441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3609059453010559, \"precision\": 1.0, \"recall\": 0.6390940546989441, \"specificity\": 1.0, \"npv\": 0.6096911430358887, \"accuracy\": 0.7692065238952637, \"f1\": 0.7798137578852509, \"f2\": 0.6888134154107408, \"f0_5\": 0.8985186210715769, \"p4\": 0.7685081323793148, \"phi\": 0.6242195034944581}, {\"truth_threshold\": 0.1322590469502903, \"match_probability\": 0.5229027085121778, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1297.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 734.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6386016607284546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3613983392715454, \"precision\": 1.0, \"recall\": 0.6386016607284546, \"specificity\": 1.0, \"npv\": 0.6093666553497314, \"accuracy\": 0.7688916921615601, \"f1\": 0.7794471153846154, \"f2\": 0.6883558008703959, \"f0_5\": 0.8983238675716858, \"p4\": 0.7682011740290052, \"phi\": 0.6238129405308033}, {\"truth_threshold\": 0.14915805391123757, \"match_probability\": 0.5258241220073328, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1292.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 739.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6361398100852966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.363860160112381, \"precision\": 1.0, \"recall\": 0.6361398100852966, \"specificity\": 1.0, \"npv\": 0.6077494621276855, \"accuracy\": 0.7673173546791077, \"f1\": 0.7776105928377972, \"f2\": 0.6860662701784197, \"f0_5\": 0.8973468537296847, \"p4\": 0.766665936799838, \"phi\": 0.6217826353362074}, {\"truth_threshold\": 0.16998021556639442, \"match_probability\": 0.5294212994669107, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1291.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 740.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6356474757194519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3643525242805481, \"precision\": 1.0, \"recall\": 0.6356474757194519, \"specificity\": 1.0, \"npv\": 0.6074270606040955, \"accuracy\": 0.767002522945404, \"f1\": 0.7772426249247442, \"f2\": 0.6856080722251726, \"f0_5\": 0.8971507991660875, \"p4\": 0.7663587983544642, \"phi\": 0.6213770736893809}, {\"truth_threshold\": 0.17471091903305666, \"match_probability\": 0.5302381499637203, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1290.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 741.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6351550817489624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3648449182510376, \"precision\": 1.0, \"recall\": 0.6351550817489624, \"specificity\": 1.0, \"npv\": 0.6071049571037292, \"accuracy\": 0.7666876316070557, \"f1\": 0.7768744354110207, \"f2\": 0.6851497769279796, \"f0_5\": 0.8969545264914477, \"p4\": 0.7660516289391232, \"phi\": 0.6209716776641626}, {\"truth_threshold\": 0.17713530490988597, \"match_probability\": 0.5306567061375795, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1287.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 744.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6336780190467834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36632201075553894, \"precision\": 1.0, \"recall\": 0.6336780190467834, \"specificity\": 1.0, \"npv\": 0.6061407923698425, \"accuracy\": 0.7657430768013, \"f1\": 0.7757685352622061, \"f2\": 0.6837743066624163, \"f0_5\": 0.8963643961554534, \"p4\": 0.7651299321327936, \"phi\": 0.6197564797172807}, {\"truth_threshold\": 0.18189319437247567, \"match_probability\": 0.5314780022801161, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1286.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 745.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.633185625076294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36681437492370605, \"precision\": 1.0, \"recall\": 0.633185625076294, \"specificity\": 1.0, \"npv\": 0.6058201193809509, \"accuracy\": 0.7654281854629517, \"f1\": 0.7753994573409707, \"f2\": 0.6833156216790648, \"f0_5\": 0.8961672473867596, \"p4\": 0.7648226360947802, \"phi\": 0.6193517425795022}, {\"truth_threshold\": 0.1874390211173332, \"match_probability\": 0.5324350948756217, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1285.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 746.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6326932311058044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36730673909187317, \"precision\": 1.0, \"recall\": 0.6326932311058044, \"specificity\": 1.0, \"npv\": 0.6054997444152832, \"accuracy\": 0.765113353729248, \"f1\": 0.7750301568154403, \"f2\": 0.682856839196514, \"f0_5\": 0.8959698786780086, \"p4\": 0.7645153077130921, \"phi\": 0.6189471692657128}, {\"truth_threshold\": 0.21424572285346405, \"match_probability\": 0.5370578754078179, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1284.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 747.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6322008967399597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3677991032600403, \"precision\": 1.0, \"recall\": 0.6322008967399597, \"specificity\": 1.0, \"npv\": 0.6051797270774841, \"accuracy\": 0.7647984623908997, \"f1\": 0.7746606334841629, \"f2\": 0.6823979591836735, \"f0_5\": 0.895772289660946, \"p4\": 0.7642079467115986, \"phi\": 0.6185427594175095}, {\"truth_threshold\": 0.21503854415927584, \"match_probability\": 0.537194503406969, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1278.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 753.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6292466521263123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37075331807136536, \"precision\": 1.0, \"recall\": 0.6292466521263123, \"specificity\": 1.0, \"npv\": 0.6032665967941284, \"accuracy\": 0.7629092931747437, \"f1\": 0.772438803263826, \"f2\": 0.6796426292278238, \"f0_5\": 0.8945821083578328, \"p4\": 0.7623630801644073, \"phi\": 0.6161197130813998}, {\"truth_threshold\": 0.21710199470778543, \"match_probability\": 0.5375500744762383, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1274.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 757.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6272771954536438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3727228045463562, \"precision\": 1.0, \"recall\": 0.6272771954536438, \"specificity\": 1.0, \"npv\": 0.6019979119300842, \"accuracy\": 0.7616498470306396, \"f1\": 0.7709531013615734, \"f2\": 0.6778037880400085, \"f0_5\": 0.8937842009260558, \"p4\": 0.7611324815228807, \"phi\": 0.6145075729562648}, {\"truth_threshold\": 0.22234187421461868, \"match_probability\": 0.5384528311303428, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1273.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 758.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6267848610877991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3732151687145233, \"precision\": 1.0, \"recall\": 0.6267848610877991, \"specificity\": 1.0, \"npv\": 0.6016815304756165, \"accuracy\": 0.761335015296936, \"f1\": 0.7705811138014528, \"f2\": 0.6773438331382357, \"f0_5\": 0.8935841639758528, \"p4\": 0.760824743344281, \"phi\": 0.614104937679472}, {\"truth_threshold\": 0.2739055633821699, \"match_probability\": 0.5473221561584802, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1270.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 761.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6253077387809753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37469226121902466, \"precision\": 1.0, \"recall\": 0.6253077387809753, \"specificity\": 1.0, \"npv\": 0.600734531879425, \"accuracy\": 0.7603904008865356, \"f1\": 0.7694637988488336, \"f2\": 0.6759633808814137, \"f0_5\": 0.8929827028547321, \"p4\": 0.7599013118572745, \"phi\": 0.6128979855932608}, {\"truth_threshold\": 0.28989512223055286, \"match_probability\": 0.5500666486667866, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1269.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 762.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6248153448104858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3751846253871918, \"precision\": 1.0, \"recall\": 0.6248153448104858, \"specificity\": 1.0, \"npv\": 0.6004195213317871, \"accuracy\": 0.760075569152832, \"f1\": 0.769090909090909, \"f2\": 0.6755030341743852, \"f0_5\": 0.8927817644575771, \"p4\": 0.7595934281018281, \"phi\": 0.6124959849679925}, {\"truth_threshold\": 0.2932352201392101, \"match_probability\": 0.5506395734740643, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1268.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 763.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6243230104446411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3756770193576813, \"precision\": 1.0, \"recall\": 0.6243230104446411, \"specificity\": 1.0, \"npv\": 0.600104808807373, \"accuracy\": 0.7597606778144836, \"f1\": 0.7687177932706881, \"f2\": 0.6750425894378195, \"f0_5\": 0.892580599746586, \"p4\": 0.7592855072439135, \"phi\": 0.6120941421230318}, {\"truth_threshold\": 0.31544798735237206, \"match_probability\": 0.5544462267086541, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1267.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 764.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6238306164741516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3761693835258484, \"precision\": 1.0, \"recall\": 0.6238306164741516, \"specificity\": 1.0, \"npv\": 0.5997904539108276, \"accuracy\": 0.75944584608078, \"f1\": 0.7683444511825349, \"f2\": 0.6745820466404003, \"f0_5\": 0.8923792083392027, \"p4\": 0.7589775489992451, \"phi\": 0.6116924567060388}, {\"truth_threshold\": 0.32089601729476536, \"match_probability\": 0.5553789110924038, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1262.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 769.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6213687658309937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37863120436668396, \"precision\": 1.0, \"recall\": 0.6213687658309937, \"specificity\": 1.0, \"npv\": 0.5982236266136169, \"accuracy\": 0.7578715085983276, \"f1\": 0.7664743395080473, \"f2\": 0.6722778606435116, \"f0_5\": 0.8913688374064134, \"p4\": 0.7574371869898648, \"phi\": 0.6096863787325622}, {\"truth_threshold\": 0.32183639819327, \"match_probability\": 0.5555398618445954, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1261.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 770.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6208764314651489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37912359833717346, \"precision\": 1.0, \"recall\": 0.6208764314651489, \"specificity\": 1.0, \"npv\": 0.5979112386703491, \"accuracy\": 0.757556676864624, \"f1\": 0.7660996354799514, \"f2\": 0.6718167288225892, \"f0_5\": 0.8911660777385159, \"p4\": 0.7571289984268484, \"phi\": 0.6092856305032893}, {\"truth_threshold\": 0.32795542307584036, \"match_probability\": 0.5565868765461811, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1260.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 771.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6203840374946594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3796159625053406, \"precision\": 1.0, \"recall\": 0.6203840374946594, \"specificity\": 1.0, \"npv\": 0.5975991487503052, \"accuracy\": 0.7572417855262756, \"f1\": 0.7657247037374658, \"f2\": 0.6713554987212276, \"f0_5\": 0.8909630886720408, \"p4\": 0.756820770473131, \"phi\": 0.6088850372450958}, {\"truth_threshold\": 0.39550867109177457, \"match_probability\": 0.5681103887750473, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1257.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 774.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6189069151878357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3810930550098419, \"precision\": 1.0, \"recall\": 0.6189069151878357, \"specificity\": 1.0, \"npv\": 0.5966649055480957, \"accuracy\": 0.75629723072052, \"f1\": 0.7645985401459854, \"f2\": 0.669971218420211, \"f0_5\": 0.8903527411814705, \"p4\": 0.7558958473823194, \"phi\": 0.6076841838021575}, {\"truth_threshold\": 0.4163308327469314, \"match_probability\": 0.5716481011395121, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1254.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 777.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6174298524856567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38257017731666565, \"precision\": 1.0, \"recall\": 0.6174298524856567, \"specificity\": 1.0, \"npv\": 0.5957335829734802, \"accuracy\": 0.7553526163101196, \"f1\": 0.7634703196347032, \"f2\": 0.6685860524632118, \"f0_5\": 0.8897403150276714, \"p4\": 0.7549705593661282, \"phi\": 0.6064847125312826}, {\"truth_threshold\": 0.4210615362135938, \"match_probability\": 0.5724508473034701, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1252.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 779.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6164451241493225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3835549056529999, \"precision\": 1.0, \"recall\": 0.6164451241493225, \"specificity\": 1.0, \"npv\": 0.5951143503189087, \"accuracy\": 0.7547228932380676, \"f1\": 0.7627170271093512, \"f2\": 0.6676621160409556, \"f0_5\": 0.8893308708623384, \"p4\": 0.7543534940760434, \"phi\": 0.605685828249412}, {\"truth_threshold\": 0.5175327743188202, \"match_probability\": 0.5887320924609704, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1248.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 783.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6144756078720093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38552436232566833, \"precision\": 1.0, \"recall\": 0.6144756078720093, \"specificity\": 1.0, \"npv\": 0.5938796401023865, \"accuracy\": 0.7534634470939636, \"f1\": 0.7612076852698993, \"f2\": 0.6658130601792573, \"f0_5\": 0.888509184109355, \"p4\": 0.7531188571035551, \"phi\": 0.6040898789455763}, {\"truth_threshold\": 0.5610047400343883, \"match_probability\": 0.5960079614330138, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1247.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 784.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6139832735061646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38601672649383545, \"precision\": 1.0, \"recall\": 0.6139832735061646, \"specificity\": 1.0, \"npv\": 0.5935717821121216, \"accuracy\": 0.75314861536026, \"f1\": 0.760829774252593, \"f2\": 0.6653505495678156, \"f0_5\": 0.8883031770907537, \"p4\": 0.7528100906494462, \"phi\": 0.6036912686117273}, {\"truth_threshold\": 0.5803281328721646, \"match_probability\": 0.5992288011690644, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1246.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 785.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.613490879535675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38650912046432495, \"precision\": 1.0, \"recall\": 0.613490879535675, \"specificity\": 1.0, \"npv\": 0.5932642221450806, \"accuracy\": 0.7528337240219116, \"f1\": 0.7604516325907843, \"f2\": 0.6648879402347919, \"f0_5\": 0.8880969351389879, \"p4\": 0.7525012807216611, \"phi\": 0.6032928083832734}, {\"truth_threshold\": 0.6379633895491302, \"match_probability\": 0.6087837229873874, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1245.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 786.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6129985451698303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38700148463249207, \"precision\": 1.0, \"recall\": 0.6129985451698303, \"specificity\": 1.0, \"npv\": 0.5929570198059082, \"accuracy\": 0.752518892288208, \"f1\": 0.76007326007326, \"f2\": 0.6644252321485751, \"f0_5\": 0.887890457851947, \"p4\": 0.7521924270246312, \"phi\": 0.6028944979150324}, {\"truth_threshold\": 0.6510875672987168, \"match_probability\": 0.6109481600087479, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1243.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 788.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6120137572288513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3879862129688263, \"precision\": 1.0, \"recall\": 0.6120137572288513, \"specificity\": 1.0, \"npv\": 0.5923435091972351, \"accuracy\": 0.751889169216156, \"f1\": 0.7593158216249236, \"f2\": 0.6634995195900502, \"f0_5\": 0.8874767956590033, \"p4\": 0.7515745871378925, \"phi\": 0.6020983248799923}, {\"truth_threshold\": 0.6796485881153881, \"match_probability\": 0.615643250999868, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1242.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 789.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6115214228630066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3884785771369934, \"precision\": 1.0, \"recall\": 0.6115214228630066, \"specificity\": 1.0, \"npv\": 0.5920372009277344, \"accuracy\": 0.7515742778778076, \"f1\": 0.7589367552703942, \"f2\": 0.6630365150544523, \"f0_5\": 0.8872696099442777, \"p4\": 0.7512656003543721, \"phi\": 0.6017004616243574}, {\"truth_threshold\": 0.7139101118479885, \"match_probability\": 0.621247073027357, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1241.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 790.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6110290288925171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3889709413051605, \"precision\": 1.0, \"recall\": 0.6110290288925171, \"specificity\": 1.0, \"npv\": 0.5917312502861023, \"accuracy\": 0.751259446144104, \"f1\": 0.758557457212714, \"f2\": 0.6625734116390817, \"f0_5\": 0.8870621872766261, \"p4\": 0.7509565686139796, \"phi\": 0.6013027467512604}, {\"truth_threshold\": 0.720626025269253, \"match_probability\": 0.6223417980984108, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1239.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 792.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6100443005561829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38995569944381714, \"precision\": 1.0, \"recall\": 0.6100443005561829, \"specificity\": 1.0, \"npv\": 0.5911203026771545, \"accuracy\": 0.750629723072052, \"f1\": 0.7577981651376147, \"f2\": 0.6616469080422941, \"f0_5\": 0.8866466294547016, \"p4\": 0.750338369069021, \"phi\": 0.6005077607783276}, {\"truth_threshold\": 0.7446418421467917, \"match_probability\": 0.6262462235868641, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1235.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 796.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6080748438835144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3919251561164856, \"precision\": 1.0, \"recall\": 0.6080748438835144, \"specificity\": 1.0, \"npv\": 0.5899021029472351, \"accuracy\": 0.749370276927948, \"f1\": 0.7562767911818739, \"f2\": 0.659792712896677, \"f0_5\": 0.8858126524171568, \"p4\": 0.7491014173370169, \"phi\": 0.5989195543217117}, {\"truth_threshold\": 0.7787004578684454, \"match_probability\": 0.6317551962626217, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1234.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 797.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6075824499130249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3924175202846527, \"precision\": 1.0, \"recall\": 0.6075824499130249, \"specificity\": 1.0, \"npv\": 0.5895983576774597, \"accuracy\": 0.7490554451942444, \"f1\": 0.755895865237366, \"f2\": 0.6593289164351357, \"f0_5\": 0.8856035596382948, \"p4\": 0.7487920625169007, \"phi\": 0.5985228685204671}, {\"truth_threshold\": 0.8054689730267481, \"match_probability\": 0.6360610805962968, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1233.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 798.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6070901155471802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3929098844528198, \"precision\": 1.0, \"recall\": 0.6070901155471802, \"specificity\": 1.0, \"npv\": 0.5892949104309082, \"accuracy\": 0.748740553855896, \"f1\": 0.7555147058823529, \"f2\": 0.6588650208400129, \"f0_5\": 0.8853942266264541, \"p4\": 0.7484826603385862, \"phi\": 0.5981263283607483}, {\"truth_threshold\": 0.8195236607092102, \"match_probability\": 0.6383132200402309, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1230.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 801.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6056129932403564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39438700675964355, \"precision\": 1.0, \"recall\": 0.6056129932403564, \"specificity\": 1.0, \"npv\": 0.5883864164352417, \"accuracy\": 0.7477959990501404, \"f1\": 0.7543698252069917, \"f2\": 0.6574727389352149, \"f0_5\": 0.8847647820457488, \"p4\": 0.7475541666251978, \"phi\": 0.5969375783190497}, {\"truth_threshold\": 0.8451534591878195, \"match_probability\": 0.6424045066882679, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1229.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 802.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6051206588745117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39487937092781067, \"precision\": 1.0, \"recall\": 0.6051206588745117, \"specificity\": 1.0, \"npv\": 0.5880842208862305, \"accuracy\": 0.747481107711792, \"f1\": 0.7539877300613497, \"f2\": 0.6570084464877579, \"f0_5\": 0.8845544839499064, \"p4\": 0.747244571982039, \"phi\": 0.5965416173151645}, {\"truth_threshold\": 0.8753449642409383, \"match_probability\": 0.6471974546332282, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1228.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 803.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6046282649040222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3953717350959778, \"precision\": 1.0, \"recall\": 0.6046282649040222, \"specificity\": 1.0, \"npv\": 0.5877823233604431, \"accuracy\": 0.7471662759780884, \"f1\": 0.7536054004295796, \"f2\": 0.6565440547476475, \"f0_5\": 0.8843439435402564, \"p4\": 0.7469349284618538, \"phi\": 0.5961458002490926}, {\"truth_threshold\": 0.8843140067296673, \"match_probability\": 0.6486156674671224, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1227.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 804.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6041358709335327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3958640992641449, \"precision\": 1.0, \"recall\": 0.6041358709335327, \"specificity\": 1.0, \"npv\": 0.5874807834625244, \"accuracy\": 0.74685138463974, \"f1\": 0.7532228360957642, \"f2\": 0.6560795636830286, \"f0_5\": 0.8841331603977518, \"p4\": 0.7466252357591884, \"phi\": 0.5957501267809385}, {\"truth_threshold\": 0.9163224013948031, \"match_probability\": 0.6536554500134303, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1223.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 808.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.6021664142608643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39783358573913574, \"precision\": 1.0, \"recall\": 0.6021664142608643, \"specificity\": 1.0, \"npv\": 0.5862775444984436, \"accuracy\": 0.745591938495636, \"f1\": 0.7516902274124155, \"f2\": 0.6542206055418851, \"f0_5\": 0.8832875920843565, \"p4\": 0.7453859669947532, \"phi\": 0.5941688620993372}, {\"truth_threshold\": 0.9454121768475423, \"match_probability\": 0.6582060110265273, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1212.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 819.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5967503786087036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4032496213912964, \"precision\": 1.0, \"recall\": 0.5967503786087036, \"specificity\": 1.0, \"npv\": 0.5829938650131226, \"accuracy\": 0.7421284914016724, \"f1\": 0.7474560592044404, \"f2\": 0.6491002570694088, \"f0_5\": 0.8809419973833406, \"p4\": 0.741973733860351, \"phi\": 0.5898320262205444}, {\"truth_threshold\": 0.9475547108878026, \"match_probability\": 0.658540034779286, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1211.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 820.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5962579846382141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4037419855594635, \"precision\": 1.0, \"recall\": 0.5962579846382141, \"specificity\": 1.0, \"npv\": 0.5826972126960754, \"accuracy\": 0.741813600063324, \"f1\": 0.7470697100555213, \"f2\": 0.648634172469202, \"f0_5\": 0.8807272727272727, \"p4\": 0.7416632122273779, \"phi\": 0.589438604316244}, {\"truth_threshold\": 0.9838756494107374, \"match_probability\": 0.6641783801264525, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1209.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 822.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5952732563018799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4047267436981201, \"precision\": 1.0, \"recall\": 0.5952732563018799, \"specificity\": 1.0, \"npv\": 0.5821047425270081, \"accuracy\": 0.741183876991272, \"f1\": 0.7462962962962963, \"f2\": 0.6477017036322725, \"f0_5\": 0.8802970729576234, \"p4\": 0.7410420052546717, \"phi\": 0.5886521737558853}, {\"truth_threshold\": 0.9858905275071348, \"match_probability\": 0.6644898155320148, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1198.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 833.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5898572206497192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41014277935028076, \"precision\": 1.0, \"recall\": 0.5898572206497192, \"specificity\": 1.0, \"npv\": 0.5788675546646118, \"accuracy\": 0.7377204298973083, \"f1\": 0.7420253948590895, \"f2\": 0.6425659729671744, \"f0_5\": 0.8779129415213249, \"p4\": 0.7376213591906712, \"phi\": 0.5843365431899546}, {\"truth_threshold\": 1.123818853231532, \"match_probability\": 0.6854584860028754, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1197.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 834.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5893648266792297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4106351435184479, \"precision\": 1.0, \"recall\": 0.5893648266792297, \"specificity\": 1.0, \"npv\": 0.5785750150680542, \"accuracy\": 0.73740553855896, \"f1\": 0.741635687732342, \"f2\": 0.6420984872867718, \"f0_5\": 0.8776946766388033, \"p4\": 0.737310046092469, \"phi\": 0.5839450209360738}, {\"truth_threshold\": 1.1411085529730922, \"match_probability\": 0.6880366032731676, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1195.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 836.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5883800983428955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4116199016571045, \"precision\": 1.0, \"recall\": 0.5883800983428955, \"specificity\": 1.0, \"npv\": 0.5779908895492554, \"accuracy\": 0.736775815486908, \"f1\": 0.7408555486670799, \"f2\": 0.6411632149372251, \"f0_5\": 0.8772573777712523, \"p4\": 0.7366872427429624, \"phi\": 0.5831623756721471}, {\"truth_threshold\": 1.144224290528586, \"match_probability\": 0.6884999701818812, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1189.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 842.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5854259133338928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4145740866661072, \"precision\": 1.0, \"recall\": 0.5854259133338928, \"specificity\": 1.0, \"npv\": 0.5762456059455872, \"accuracy\": 0.734886646270752, \"f1\": 0.7385093167701864, \"f2\": 0.6383549876516698, \"f0_5\": 0.8759392957123914, \"p4\": 0.7348173920177556, \"phi\": 0.5808176099748659}, {\"truth_threshold\": 1.1939053280683396, \"match_probability\": 0.6958370881351029, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1185.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 846.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5834563970565796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.416543573141098, \"precision\": 1.0, \"recall\": 0.5834563970565796, \"specificity\": 1.0, \"npv\": 0.5750879049301147, \"accuracy\": 0.733627200126648, \"f1\": 0.7369402985074627, \"f2\": 0.6364808250080567, \"f0_5\": 0.8750553832521045, \"p4\": 0.7335695980796055, \"phi\": 0.5792570481403251}, {\"truth_threshold\": 1.2499183630431252, \"match_probability\": 0.7039913493733277, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1184.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 847.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5829640626907349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41703593730926514, \"precision\": 1.0, \"recall\": 0.5829640626907349, \"specificity\": 1.0, \"npv\": 0.5747991800308228, \"accuracy\": 0.7333123683929443, \"f1\": 0.736547433903577, \"f2\": 0.6360120326600773, \"f0_5\": 0.8748337520319196, \"p4\": 0.7332574932224606, \"phi\": 0.5788672315698303}, {\"truth_threshold\": 1.2849613588479014, \"match_probability\": 0.7090278695373892, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1183.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 848.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5824716687202454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41752830147743225, \"precision\": 1.0, \"recall\": 0.5824716687202454, \"specificity\": 1.0, \"npv\": 0.5745108127593994, \"accuracy\": 0.732997477054596, \"f1\": 0.7361543248288737, \"f2\": 0.6355431395723649, \"f0_5\": 0.8746118586426143, \"p4\": 0.732945325152551, \"phi\": 0.578477543896111}, {\"truth_threshold\": 1.319515229357082, \"match_probability\": 0.7139442713968629, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1176.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 855.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5790250897407532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42097488045692444, \"precision\": 1.0, \"recall\": 0.5790250897407532, \"specificity\": 1.0, \"npv\": 0.5724999904632568, \"accuracy\": 0.7307934761047363, \"f1\": 0.7333956969130028, \"f2\": 0.632258064516129, \"f0_5\": 0.8730512249443207, \"p4\": 0.7307583506489014, \"phi\": 0.5757533116910319}, {\"truth_threshold\": 1.3690104421068756, \"match_probability\": 0.7208990819562515, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1174.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 857.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.578040361404419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42195963859558105, \"precision\": 1.0, \"recall\": 0.578040361404419, \"specificity\": 1.0, \"npv\": 0.571928083896637, \"accuracy\": 0.7301637530326843, \"f1\": 0.7326053042121685, \"f2\": 0.6313185631318563, \"f0_5\": 0.8726029433625687, \"p4\": 0.7301329127821058, \"phi\": 0.5749761009926682}, {\"truth_threshold\": 1.3905749077091232, \"match_probability\": 0.7238965890807605, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1172.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 859.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5770556330680847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4229443669319153, \"precision\": 1.0, \"recall\": 0.5770556330680847, \"specificity\": 1.0, \"npv\": 0.5713573098182678, \"accuracy\": 0.7295340299606323, \"f1\": 0.731813924445832, \"f2\": 0.6303786574870912, \"f0_5\": 0.8721535942848638, \"p4\": 0.7295072086227041, \"phi\": 0.5741993927638691}, {\"truth_threshold\": 1.4182849479669029, \"match_probability\": 0.7277189701801086, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1170.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 861.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5760709047317505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4239290952682495, \"precision\": 1.0, \"recall\": 0.5760709047317505, \"specificity\": 1.0, \"npv\": 0.5707876086235046, \"accuracy\": 0.7289043068885803, \"f1\": 0.7310215557638238, \"f2\": 0.6294383473208521, \"f0_5\": 0.8717031738936075, \"p4\": 0.7288812354500215, \"phi\": 0.5734231843906902}, {\"truth_threshold\": 1.4249045626686956, \"match_probability\": 0.7286271774066678, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1169.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 862.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.575578510761261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4244214594364166, \"precision\": 1.0, \"recall\": 0.575578510761261, \"specificity\": 1.0, \"npv\": 0.5705032348632812, \"accuracy\": 0.7285894155502319, \"f1\": 0.730625, \"f2\": 0.6289680404605618, \"f0_5\": 0.8714775607574177, \"p4\": 0.728568147130481, \"phi\": 0.5730352668339465}, {\"truth_threshold\": 1.4301159599089752, \"match_probability\": 0.7293408390678932, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1168.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 863.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5750861763954163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42491382360458374, \"precision\": 1.0, \"recall\": 0.5750861763954163, \"specificity\": 1.0, \"npv\": 0.570219099521637, \"accuracy\": 0.7282745838165283, \"f1\": 0.7302281963113473, \"f2\": 0.6284976323719328, \"f0_5\": 0.8712516783529762, \"p4\": 0.7282549905323747, \"phi\": 0.5726474732622752}, {\"truth_threshold\": 1.4540741557530643, \"match_probability\": 0.7326065068153376, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1167.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 864.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5745937824249268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42540621757507324, \"precision\": 1.0, \"recall\": 0.5745937824249268, \"specificity\": 1.0, \"npv\": 0.5699352622032166, \"accuracy\": 0.7279596924781799, \"f1\": 0.7298311444652908, \"f2\": 0.6280271230222796, \"f0_5\": 0.8710255261979399, \"p4\": 0.7279417653125098, \"phi\": 0.5722598033497938}, {\"truth_threshold\": 1.500122547370262, \"match_probability\": 0.7388125167692863, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1165.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 866.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5736090540885925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42639094591140747, \"precision\": 1.0, \"recall\": 0.5736090540885925, \"specificity\": 1.0, \"npv\": 0.5693684816360474, \"accuracy\": 0.7273299694061279, \"f1\": 0.7290362953692116, \"f2\": 0.627085800409086, \"f0_5\": 0.8705724107009416, \"p4\": 0.7273151076312403, \"phi\": 0.571484833199803}, {\"truth_threshold\": 1.5089546891203793, \"match_probability\": 0.7399921371455234, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1164.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 867.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5731167197227478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4268833100795746, \"precision\": 1.0, \"recall\": 0.5731167197227478, \"specificity\": 1.0, \"npv\": 0.5690854787826538, \"accuracy\": 0.7270151376724243, \"f1\": 0.7286384976525822, \"f2\": 0.6266149870801033, \"f0_5\": 0.8703454463885151, \"p4\": 0.7270016744799519, \"phi\": 0.571097532311457}, {\"truth_threshold\": 1.5097475104261908, \"match_probability\": 0.7400978571264178, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1163.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 868.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5726243257522583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4273756742477417, \"precision\": 1.0, \"recall\": 0.5726243257522583, \"specificity\": 1.0, \"npv\": 0.5688027739524841, \"accuracy\": 0.7267002463340759, \"f1\": 0.728240450845335, \"f2\": 0.6261440723592118, \"f0_5\": 0.8701182103845578, \"p4\": 0.7266881713271315, \"phi\": 0.570710353780624}, {\"truth_threshold\": 1.5466242971850532, \"match_probability\": 0.7449843453180763, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1162.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 869.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5721319317817688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4278680384159088, \"precision\": 1.0, \"recall\": 0.5721319317817688, \"specificity\": 1.0, \"npv\": 0.5685203671455383, \"accuracy\": 0.7263854146003723, \"f1\": 0.7278421547134356, \"f2\": 0.625673056213655, \"f0_5\": 0.8698907022009282, \"p4\": 0.7263745978260736, \"phi\": 0.5703232972823407}, {\"truth_threshold\": 1.5474171184908645, \"match_probability\": 0.7450887346903722, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1161.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 870.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5716395974159241, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4283604025840759, \"precision\": 1.0, \"recall\": 0.5716395974159241, \"specificity\": 1.0, \"npv\": 0.5682381987571716, \"accuracy\": 0.7260705232620239, \"f1\": 0.7274436090225563, \"f2\": 0.6252019386106623, \"f0_5\": 0.8696629213483146, \"p4\": 0.7260609536293626, \"phi\": 0.5699363624918229}, {\"truth_threshold\": 1.5609893596695767, \"match_probability\": 0.7468714034968195, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1160.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 871.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5711472034454346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42885279655456543, \"precision\": 1.0, \"recall\": 0.5711472034454346, \"specificity\": 1.0, \"npv\": 0.5679563283920288, \"accuracy\": 0.7257556915283203, \"f1\": 0.7270448135380758, \"f2\": 0.6247307195174494, \"f0_5\": 0.8694348673362314, \"p4\": 0.7257472383888707, \"phi\": 0.5695495490844643}, {\"truth_threshold\": 1.5708530282282909, \"match_probability\": 0.7481617812819491, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1158.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 873.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5701624751091003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42983752489089966, \"precision\": 1.0, \"recall\": 0.5701624751091003, \"specificity\": 1.0, \"npv\": 0.5673934817314148, \"accuracy\": 0.7251259684562683, \"f1\": 0.7262464722483537, \"f2\": 0.6237879767291532, \"f0_5\": 0.8689779378658262, \"p4\": 0.7251195933804556, \"phi\": 0.5687762851216785}, {\"truth_threshold\": 1.5793594376462914, \"match_probability\": 0.7492710905587684, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1157.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 874.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5696701407432556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4303298890590668, \"precision\": 1.0, \"recall\": 0.5696701407432556, \"specificity\": 1.0, \"npv\": 0.5671124458312988, \"accuracy\": 0.7248110771179199, \"f1\": 0.7258469259723965, \"f2\": 0.6233164529684301, \"f0_5\": 0.8687490614206337, \"p4\": 0.7248056629126928, \"phi\": 0.5683898339179133}, {\"truth_threshold\": 1.6062841377137593, \"match_probability\": 0.7527608178008853, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1155.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 876.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5686853528022766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.431314617395401, \"precision\": 1.0, \"recall\": 0.5686853528022766, \"specificity\": 1.0, \"npv\": 0.5665512084960938, \"accuracy\": 0.7241813540458679, \"f1\": 0.7250470809792844, \"f2\": 0.6223731005496282, \"f0_5\": 0.8682904826341904, \"p4\": 0.7241775842950429, \"phi\": 0.5676172914460832}, {\"truth_threshold\": 1.6198081174884345, \"match_probability\": 0.7545013148902536, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1154.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 877.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5681930184364319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4318069815635681, \"precision\": 1.0, \"recall\": 0.5681930184364319, \"specificity\": 1.0, \"npv\": 0.5662710070610046, \"accuracy\": 0.7238665223121643, \"f1\": 0.7246467817896389, \"f2\": 0.6219012718258246, \"f0_5\": 0.8680607792989319, \"p4\": 0.7238634354409746, \"phi\": 0.5672311995307053}, {\"truth_threshold\": 1.6873613655043687, \"match_probability\": 0.7630708572793375, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1153.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 878.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5677006244659424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43229934573173523, \"precision\": 1.0, \"recall\": 0.5677006244659424, \"specificity\": 1.0, \"npv\": 0.5659911036491394, \"accuracy\": 0.7235516309738159, \"f1\": 0.7242462311557789, \"f2\": 0.6214293413819123, \"f0_5\": 0.8678307993376486, \"p4\": 0.7235492130860749, \"phi\": 0.5668452267310902}, {\"truth_threshold\": 1.68815418681018, \"match_probability\": 0.7631701966335926, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1152.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 879.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5672082901000977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43279173970222473, \"precision\": 1.0, \"recall\": 0.5672082901000977, \"specificity\": 1.0, \"npv\": 0.5657114386558533, \"accuracy\": 0.7232367992401123, \"f1\": 0.7238454288407163, \"f2\": 0.6209573091849935, \"f0_5\": 0.8676005422503389, \"p4\": 0.7232349168764273, \"phi\": 0.5664593727239978}, {\"truth_threshold\": 1.7088319559006657, \"match_probability\": 0.7657509377255277, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1151.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 880.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5667158961296082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43328410387039185, \"precision\": 1.0, \"recall\": 0.5667158961296082, \"specificity\": 1.0, \"npv\": 0.565432071685791, \"accuracy\": 0.7229219079017639, \"f1\": 0.7234443746071653, \"f2\": 0.6204851752021563, \"f0_5\": 0.8673700075357951, \"p4\": 0.7229205464573797, \"phi\": 0.5660736371863528}, {\"truth_threshold\": 1.7254216663496562, \"match_probability\": 0.7678073006161239, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1150.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 881.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5662235617637634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43377646803855896, \"precision\": 1.0, \"recall\": 0.5662235617637634, \"specificity\": 1.0, \"npv\": 0.5651530027389526, \"accuracy\": 0.7226070761680603, \"f1\": 0.7230430682175416, \"f2\": 0.6200129394004744, \"f0_5\": 0.8671391946916001, \"p4\": 0.722606101473543, \"phi\": 0.5656880197952422}, {\"truth_threshold\": 1.7262144876554677, \"match_probability\": 0.7679052581063437, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1148.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 883.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5652387738227844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4347611963748932, \"precision\": 1.0, \"recall\": 0.5652387738227844, \"specificity\": 1.0, \"npv\": 0.564595639705658, \"accuracy\": 0.7219773530960083, \"f1\": 0.7222396980182447, \"f2\": 0.6190681622088007, \"f0_5\": 0.8666767325985203, \"p4\": 0.7219769863862414, \"phi\": 0.5649171381617742}, {\"truth_threshold\": 1.7432839322686084, \"match_probability\": 0.7700072852185416, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1137.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 894.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5598227381706238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4401772618293762, \"precision\": 1.0, \"recall\": 0.5598227381706238, \"specificity\": 1.0, \"npv\": 0.5615497827529907, \"accuracy\": 0.7185138463973999, \"f1\": 0.7178030303030303, \"f2\": 0.6138645934564302, \"f0_5\": 0.8641130870953032, \"p4\": 0.7185113682272454, \"phi\": 0.5606855984061428}, {\"truth_threshold\": 1.7929749143655904, \"match_probability\": 0.7760502377991485, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1136.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 895.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.559330403804779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44066962599754333, \"precision\": 1.0, \"recall\": 0.559330403804779, \"specificity\": 1.0, \"npv\": 0.561274528503418, \"accuracy\": 0.7181990146636963, \"f1\": 0.7173981686138301, \"f2\": 0.6133909287257019, \"f0_5\": 0.8638783269961977, \"p4\": 0.7181958416012424, \"phi\": 0.560301601247963}, {\"truth_threshold\": 1.7937677356714017, \"match_probability\": 0.7761457316323652, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1135.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 896.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5588380098342896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44116199016571045, \"precision\": 1.0, \"recall\": 0.5588380098342896, \"specificity\": 1.0, \"npv\": 0.5609995126724243, \"accuracy\": 0.7178841233253479, \"f1\": 0.7169930511686671, \"f2\": 0.612917161680527, \"f0_5\": 0.8636432810835489, \"p4\": 0.717880234989325, \"phi\": 0.5599177174110734}, {\"truth_threshold\": 1.8137970760207471, \"match_probability\": 0.7785486111374764, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1134.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 897.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5583456158638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44165435433387756, \"precision\": 1.0, \"recall\": 0.5583456158638, \"specificity\": 1.0, \"npv\": 0.5607247948646545, \"accuracy\": 0.7175692915916443, \"f1\": 0.7165876777251184, \"f2\": 0.6124432922877512, \"f0_5\": 0.8634079488350845, \"p4\": 0.7175645480239453, \"phi\": 0.5595339465749515}, {\"truth_threshold\": 1.8185277794874097, \"match_probability\": 0.7791134420350182, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1132.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 899.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5573608875274658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4426390826702118, \"precision\": 1.0, \"recall\": 0.5573608875274658, \"specificity\": 1.0, \"npv\": 0.5601761341094971, \"accuracy\": 0.7169395685195923, \"f1\": 0.7157761618716408, \"f2\": 0.611495246326707, \"f0_5\": 0.8629364232352493, \"p4\": 0.7169329315586919, \"phi\": 0.5587667426236015}, {\"truth_threshold\": 1.8209656039031759, \"match_probability\": 0.7794041071981351, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1130.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 901.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5563761591911316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4436238408088684, \"precision\": 1.0, \"recall\": 0.5563761591911316, \"specificity\": 1.0, \"npv\": 0.5596285462379456, \"accuracy\": 0.7163098454475403, \"f1\": 0.7149636191078772, \"f2\": 0.6105467905770477, \"f0_5\": 0.8624637459929781, \"p4\": 0.7163009892493953, \"phi\": 0.5579999868324339}, {\"truth_threshold\": 1.8239458555835444, \"match_probability\": 0.7797590740237091, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1129.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 902.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5558838248252869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4441162049770355, \"precision\": 1.0, \"recall\": 0.5558838248252869, \"specificity\": 1.0, \"npv\": 0.5593551397323608, \"accuracy\": 0.7159949541091919, \"f1\": 0.7145569620253165, \"f2\": 0.6100724089484492, \"f0_5\": 0.8622269741866504, \"p4\": 0.7159848949759955, \"phi\": 0.557616776197034}, {\"truth_threshold\": 1.9959480692089206, \"match_probability\": 0.799550247840987, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1128.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 903.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5553914308547974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44460856914520264, \"precision\": 1.0, \"recall\": 0.5553914308547974, \"specificity\": 1.0, \"npv\": 0.55908203125, \"accuracy\": 0.7156801223754883, \"f1\": 0.7141500474833808, \"f2\": 0.6095979247730221, \"f0_5\": 0.8619899128839982, \"p4\": 0.7156687181273125, \"phi\": 0.5572336766420773}, {\"truth_threshold\": 2.0150784606301313, \"match_probability\": 0.8016670127395736, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1127.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 904.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5548990368843079, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44510093331336975, \"precision\": 1.0, \"recall\": 0.5548990368843079, \"specificity\": 1.0, \"npv\": 0.5588091611862183, \"accuracy\": 0.7153652310371399, \"f1\": 0.7137428752374921, \"f2\": 0.6091233380175116, \"f0_5\": 0.8617525615537543, \"p4\": 0.7153524583302613, \"phi\": 0.5568506878479639}, {\"truth_threshold\": 2.0358263229347506, \"match_probability\": 0.8039436837467253, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1126.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 905.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5544067025184631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44559329748153687, \"precision\": 1.0, \"recall\": 0.5544067025184631, \"specificity\": 1.0, \"npv\": 0.5585365891456604, \"accuracy\": 0.7150503993034363, \"f1\": 0.7133354450427621, \"f2\": 0.6086486486486486, \"f0_5\": 0.8615149196633511, \"p4\": 0.7150361152109546, \"phi\": 0.5564678094952189}, {\"truth_threshold\": 2.043358025239624, \"match_probability\": 0.8047652366074677, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1125.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 906.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5539143085479736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.446085661649704, \"precision\": 1.0, \"recall\": 0.5539143085479736, \"specificity\": 1.0, \"npv\": 0.5582642555236816, \"accuracy\": 0.7147355079650879, \"f1\": 0.7129277566539924, \"f2\": 0.6081738566331495, \"f0_5\": 0.861276986678916, \"p4\": 0.7147196883947, \"phi\": 0.5560850412644919}, {\"truth_threshold\": 2.0471450840948324, \"match_probability\": 0.8051773401290916, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1124.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 907.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5534219741821289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4465780258178711, \"precision\": 1.0, \"recall\": 0.5534219741821289, \"specificity\": 1.0, \"npv\": 0.5579922199249268, \"accuracy\": 0.7144206762313843, \"f1\": 0.7125198098256735, \"f2\": 0.6076989619377162, \"f0_5\": 0.8610387620652673, \"p4\": 0.7144031775059975, \"phi\": 0.5557023828365546}, {\"truth_threshold\": 2.115531214199051, \"match_probability\": 0.8125057018117979, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1123.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 908.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5529295802116394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4470704197883606, \"precision\": 1.0, \"recall\": 0.5529295802116394, \"specificity\": 1.0, \"npv\": 0.557720422744751, \"accuracy\": 0.7141057848930359, \"f1\": 0.7121116043119848, \"f2\": 0.6072239645290365, \"f0_5\": 0.8608002452859114, \"p4\": 0.714086582168536, \"phi\": 0.5553198338922999}, {\"truth_threshold\": 2.118092268543069, \"match_probability\": 0.8127759842094027, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1122.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 909.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5524372458457947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4475627839565277, \"precision\": 1.0, \"recall\": 0.5524372458457947, \"specificity\": 1.0, \"npv\": 0.5574488639831543, \"accuracy\": 0.7137909531593323, \"f1\": 0.7117031398667936, \"f2\": 0.6067488643737833, \"f0_5\": 0.8605614358030372, \"p4\": 0.7137699020051912, \"phi\": 0.5549373941127399}, {\"truth_threshold\": 2.1300411276056828, \"match_probability\": 0.814033050709298, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1121.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 910.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5519448518753052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4480551481246948, \"precision\": 1.0, \"recall\": 0.5519448518753052, \"specificity\": 1.0, \"npv\": 0.5571776032447815, \"accuracy\": 0.7134760618209839, \"f1\": 0.7112944162436549, \"f2\": 0.6062736614386155, \"f0_5\": 0.8603223330775134, \"p4\": 0.7134531366380221, \"phi\": 0.5545550631790046}, {\"truth_threshold\": 2.148539179218837, \"match_probability\": 0.815966256800298, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1115.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 916.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5489906668663025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4510093629360199, \"precision\": 1.0, \"recall\": 0.5489906668663025, \"specificity\": 1.0, \"npv\": 0.5555555820465088, \"accuracy\": 0.7115868926048279, \"f1\": 0.7088366179275271, \"f2\": 0.6034202835804741, \"f0_5\": 0.8588815282699122, \"p4\": 0.7115507338864071, \"phi\": 0.5522633454966439}, {\"truth_threshold\": 2.166231417513058, \"match_probability\": 0.8178006520942674, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1114.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 917.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.548498272895813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.451501727104187, \"precision\": 1.0, \"recall\": 0.548498272895813, \"specificity\": 1.0, \"npv\": 0.5552861094474792, \"accuracy\": 0.7112720608711243, \"f1\": 0.7084260731319555, \"f2\": 0.6029443602511366, \"f0_5\": 0.8586403576383537, \"p4\": 0.7112333614409344, \"phi\": 0.5518817675648915}, {\"truth_threshold\": 2.1838260690887825, \"match_probability\": 0.8196108041484638, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1113.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 918.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5480058789253235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4519940912723541, \"precision\": 1.0, \"recall\": 0.5480058789253235, \"specificity\": 1.0, \"npv\": 0.5550169944763184, \"accuracy\": 0.7109571695327759, \"f1\": 0.7080152671755725, \"f2\": 0.6024683338746346, \"f0_5\": 0.8583988894030541, \"p4\": 0.7109159007383705, \"phi\": 0.5515002959320586}, {\"truth_threshold\": 2.216989903983026, \"match_probability\": 0.8229845340417228, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1112.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 919.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5475135445594788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45248645544052124, \"precision\": 1.0, \"recall\": 0.5475135445594788, \"specificity\": 1.0, \"npv\": 0.5547480583190918, \"accuracy\": 0.7106423377990723, \"f1\": 0.7076041998090996, \"f2\": 0.6019922044174968, \"f0_5\": 0.8581571230128107, \"p4\": 0.7105983513932957, \"phi\": 0.5511189302802658}, {\"truth_threshold\": 2.2303767786221957, \"match_probability\": 0.8243322699642314, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1111.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 920.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5470211505889893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45297881960868835, \"precision\": 1.0, \"recall\": 0.5470211505889893, \"specificity\": 1.0, \"npv\": 0.5544794201850891, \"accuracy\": 0.7103274464607239, \"f1\": 0.7071928707829408, \"f2\": 0.6015159718462372, \"f0_5\": 0.857915057915058, \"p4\": 0.7102807130194447, \"phi\": 0.5507376702917357}, {\"truth_threshold\": 2.2487009757263925, \"match_probability\": 0.8261639664277828, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1110.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 921.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5465288162231445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45347118377685547, \"precision\": 1.0, \"recall\": 0.5465288162231445, \"specificity\": 1.0, \"npv\": 0.5542110204696655, \"accuracy\": 0.7100126147270203, \"f1\": 0.7067812798471824, \"f2\": 0.6010396361273554, \"f0_5\": 0.8576726935558646, \"p4\": 0.7099629852297031, \"phi\": 0.5503565156487915}, {\"truth_threshold\": 2.2614290778106687, \"match_probability\": 0.8274273768040151, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1105.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 926.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5440669655799866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4559330344200134, \"precision\": 1.0, \"recall\": 0.5440669655799866, \"specificity\": 1.0, \"npv\": 0.5528730154037476, \"accuracy\": 0.7084382772445679, \"f1\": 0.704719387755102, \"f2\": 0.5986564091450861, \"f0_5\": 0.8564563633545187, \"p4\": 0.7083729914338502, \"phi\": 0.5484523115060287}, {\"truth_threshold\": 2.313788644668619, \"match_probability\": 0.83254827054887, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1104.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 927.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5435745716094971, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45642539858818054, \"precision\": 1.0, \"recall\": 0.5435745716094971, \"specificity\": 1.0, \"npv\": 0.5526061654090881, \"accuracy\": 0.7081234455108643, \"f1\": 0.7043062200956938, \"f2\": 0.5981794538361509, \"f0_5\": 0.8562121917170777, \"p4\": 0.7080547189714588, \"phi\": 0.5480717822708321}, {\"truth_threshold\": 2.326945855602826, \"match_probability\": 0.8338158354992302, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1099.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 932.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5411127805709839, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4588872492313385, \"precision\": 1.0, \"recall\": 0.5411127805709839, \"specificity\": 1.0, \"npv\": 0.5512758493423462, \"accuracy\": 0.7065491080284119, \"f1\": 0.7022364217252396, \"f2\": 0.5957931258809498, \"f0_5\": 0.8549867745448888, \"p4\": 0.7064619665204549, \"phi\": 0.5461706766256442}, {\"truth_threshold\": 2.327253003287568, \"match_probability\": 0.833845334113736, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1096.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 935.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5396356582641602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46036434173583984, \"precision\": 1.0, \"recall\": 0.5396356582641602, \"specificity\": 1.0, \"npv\": 0.5504807829856873, \"accuracy\": 0.7056045532226562, \"f1\": 0.7009913655260633, \"f2\": 0.5943600867678959, \"f0_5\": 0.8542478565861262, \"p4\": 0.7055051886749361, \"phi\": 0.5450312342613898}, {\"truth_threshold\": 2.381341892684553, \"match_probability\": 0.8389748841756043, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1095.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 936.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5391432642936707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46085673570632935, \"precision\": 1.0, \"recall\": 0.5391432642936707, \"specificity\": 1.0, \"npv\": 0.5502162575721741, \"accuracy\": 0.7052896618843079, \"f1\": 0.7005758157389635, \"f2\": 0.5938821998047511, \"f0_5\": 0.8540009358914366, \"p4\": 0.7051860726067039, \"phi\": 0.5446516217447076}, {\"truth_threshold\": 2.3886441795471867, \"match_probability\": 0.8396575081022344, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1094.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 937.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5386509299278259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46134909987449646, \"precision\": 1.0, \"recall\": 0.5386509299278259, \"specificity\": 1.0, \"npv\": 0.54995197057724, \"accuracy\": 0.7049748301506042, \"f1\": 0.70016, \"f2\": 0.5934042091559991, \"f0_5\": 0.8537537068830966, \"p4\": 0.7048668608108392, \"phi\": 0.544272109503198}, {\"truth_threshold\": 2.3894380440457077, \"match_probability\": 0.8397315779535042, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1093.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 938.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5381585359573364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4618414640426636, \"precision\": 1.0, \"recall\": 0.5381585359573364, \"specificity\": 1.0, \"npv\": 0.549687922000885, \"accuracy\": 0.7046599388122559, \"f1\": 0.6997439180537772, \"f2\": 0.5929261147878919, \"f0_5\": 0.8535061689832891, \"p4\": 0.7045475528853299, \"phi\": 0.5438926972206558}, {\"truth_threshold\": 2.4154488680914397, \"match_probability\": 0.8421431726961238, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1086.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 945.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5347119569778442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46528804302215576, \"precision\": 1.0, \"recall\": 0.5347119569778442, \"specificity\": 1.0, \"npv\": 0.5478469133377075, \"accuracy\": 0.7024559378623962, \"f1\": 0.6968238691049086, \"f2\": 0.5895765472312704, \"f0_5\": 0.851764705882353, \"p4\": 0.7023096718169206, \"phi\": 0.5412395835474714}, {\"truth_threshold\": 2.426073154747746, \"match_probability\": 0.8431196894736593, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1084.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 947.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.53372722864151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46627277135849, \"precision\": 1.0, \"recall\": 0.53372722864151, \"specificity\": 1.0, \"npv\": 0.5473231077194214, \"accuracy\": 0.7018262147903442, \"f1\": 0.6959871589085073, \"f2\": 0.5886185925282363, \"f0_5\": 0.8512643317103816, \"p4\": 0.701669388939399, \"phi\": 0.5404824326919393}, {\"truth_threshold\": 2.445314026121606, \"match_probability\": 0.8448756656449684, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1083.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 948.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5332348346710205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4667651355266571, \"precision\": 1.0, \"recall\": 0.5332348346710205, \"specificity\": 1.0, \"npv\": 0.5470616221427917, \"accuracy\": 0.7015113234519958, \"f1\": 0.6955684007707129, \"f2\": 0.588139459107201, \"f0_5\": 0.851013672795851, \"p4\": 0.7013490974061563, \"phi\": 0.5401040026228908}, {\"truth_threshold\": 2.452915102808031, \"match_probability\": 0.8455649269420747, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1082.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 949.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5327425003051758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4672574996948242, \"precision\": 1.0, \"recall\": 0.5327425003051758, \"specificity\": 1.0, \"npv\": 0.5468003749847412, \"accuracy\": 0.7011964917182922, \"f1\": 0.6951493735946033, \"f2\": 0.5876602215946122, \"f0_5\": 0.8507626985375059, \"p4\": 0.7010287052607143, \"phi\": 0.5397256690389717}, {\"truth_threshold\": 2.470569245676737, \"match_probability\": 0.8471561350846748, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1081.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 950.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5322501063346863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46774986386299133, \"precision\": 1.0, \"recall\": 0.5322501063346863, \"specificity\": 1.0, \"npv\": 0.5465393662452698, \"accuracy\": 0.7008816003799438, \"f1\": 0.6947300771208226, \"f2\": 0.5871808799565453, \"f0_5\": 0.8505114083398898, \"p4\": 0.7007082120899899, \"phi\": 0.5393474316247386}, {\"truth_threshold\": 2.4950515929069295, \"match_probability\": 0.8493405172309029, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1080.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 951.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5317577719688416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46824225783348083, \"precision\": 1.0, \"recall\": 0.5317577719688416, \"specificity\": 1.0, \"npv\": 0.5462786555290222, \"accuracy\": 0.7005667686462402, \"f1\": 0.6943105110896818, \"f2\": 0.5867014341590613, \"f0_5\": 0.8502598016060463, \"p4\": 0.7003876174799554, \"phi\": 0.5389692900648018}, {\"truth_threshold\": 2.5202831058332196, \"match_probability\": 0.8515648038158021, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1072.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 959.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5278187990188599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47218120098114014, \"precision\": 1.0, \"recall\": 0.5278187990188599, \"specificity\": 1.0, \"npv\": 0.5442014932632446, \"accuracy\": 0.6980478763580322, \"f1\": 0.690944247502417, \"f2\": 0.5828621139625925, \"f0_5\": 0.8482354802975154, \"p4\": 0.6978191587869178, \"phi\": 0.5359475705094053}, {\"truth_threshold\": 2.584340555672737, \"match_probability\": 0.8570900613264302, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1071.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 960.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5273264646530151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47267356514930725, \"precision\": 1.0, \"recall\": 0.5273264646530151, \"specificity\": 1.0, \"npv\": 0.5439429879188538, \"accuracy\": 0.6977329850196838, \"f1\": 0.690522243713733, \"f2\": 0.5823817292006526, \"f0_5\": 0.8479809976247031, \"p4\": 0.6974976324343694, \"phi\": 0.5355702774535427}, {\"truth_threshold\": 2.613907065474892, \"match_probability\": 0.85958197303604, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1069.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 962.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5263416767120361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4736582934856415, \"precision\": 1.0, \"recall\": 0.5263416767120361, \"specificity\": 1.0, \"npv\": 0.5434266924858093, \"accuracy\": 0.6971032619476318, \"f1\": 0.6896774193548387, \"f2\": 0.5814206461438051, \"f0_5\": 0.847471063897257, \"p4\": 0.6968542624078266, \"phi\": 0.5348159691357846}, {\"truth_threshold\": 2.6349947967277236, \"match_probability\": 0.8613369892372469, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1068.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 963.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5258493423461914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4741506576538086, \"precision\": 1.0, \"recall\": 0.5258493423461914, \"specificity\": 1.0, \"npv\": 0.5431689023971558, \"accuracy\": 0.6967884302139282, \"f1\": 0.6892545982575025, \"f2\": 0.5809399477806788, \"f0_5\": 0.8472156116135173, \"p4\": 0.6965324178835663, \"phi\": 0.5344389532440967}, {\"truth_threshold\": 2.648611478933581, \"match_probability\": 0.8624604260798696, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1067.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 964.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5253569483757019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4746430218219757, \"precision\": 1.0, \"recall\": 0.5253569483757019, \"specificity\": 1.0, \"npv\": 0.5429113507270813, \"accuracy\": 0.6964735388755798, \"f1\": 0.6888315041962556, \"f2\": 0.5804591448155805, \"f0_5\": 0.8469598348944277, \"p4\": 0.6962104664501566, \"phi\": 0.5340620291107292}, {\"truth_threshold\": 2.651893803688671, \"match_probability\": 0.8627300855530032, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1066.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 965.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5248646140098572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4751354157924652, \"precision\": 1.0, \"recall\": 0.5248646140098572, \"specificity\": 1.0, \"npv\": 0.5426540374755859, \"accuracy\": 0.6961587071418762, \"f1\": 0.6884081369066839, \"f2\": 0.5799782372143635, \"f0_5\": 0.846703733121525, \"p4\": 0.6958884076799895, \"phi\": 0.5336851964208649}, {\"truth_threshold\": 2.672840832632326, \"match_probability\": 0.8644405314881776, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1065.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 966.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5243722200393677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4756277799606323, \"precision\": 1.0, \"recall\": 0.5243722200393677, \"specificity\": 1.0, \"npv\": 0.5423969626426697, \"accuracy\": 0.6958438158035278, \"f1\": 0.687984496124031, \"f2\": 0.5794972249428665, \"f0_5\": 0.8464473056747734, \"p4\": 0.6955662411444608, \"phi\": 0.5333084548597151}, {\"truth_threshold\": 2.7097375875178553, \"match_probability\": 0.8674096398956379, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1064.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 967.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.523879885673523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47612014412879944, \"precision\": 1.0, \"recall\": 0.523879885673523, \"specificity\": 1.0, \"npv\": 0.5421401262283325, \"accuracy\": 0.6955289840698242, \"f1\": 0.6875605815831987, \"f2\": 0.5790161079669134, \"f0_5\": 0.8461905519325592, \"p4\": 0.6952439664139662, \"phi\": 0.5329318041125186}, {\"truth_threshold\": 2.7169814726308976, \"match_probability\": 0.8679860503558712, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1063.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 968.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5233874917030334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47661250829696655, \"precision\": 1.0, \"recall\": 0.5233874917030334, \"specificity\": 1.0, \"npv\": 0.5418835878372192, \"accuracy\": 0.6952140927314758, \"f1\": 0.687136393018746, \"f2\": 0.5785348862523131, \"f0_5\": 0.8459334712716855, \"p4\": 0.6949215830578982, \"phi\": 0.5325552438645393}, {\"truth_threshold\": 2.719837744485219, \"match_probability\": 0.8682127449385982, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1060.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 971.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5219103693962097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4780896008014679, \"precision\": 1.0, \"recall\": 0.5219103693962097, \"specificity\": 1.0, \"npv\": 0.5411152839660645, \"accuracy\": 0.6942695379257202, \"f1\": 0.6858621805241022, \"f2\": 0.5770905923344948, \"f0_5\": 0.8451602615212884, \"p4\": 0.6939537769150447, \"phi\": 0.5314261029688891}, {\"truth_threshold\": 2.725077623992052, \"match_probability\": 0.8686277615091748, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1059.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 972.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.521418035030365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.478581964969635, \"precision\": 1.0, \"recall\": 0.521418035030365, \"specificity\": 1.0, \"npv\": 0.5408596992492676, \"accuracy\": 0.6939546465873718, \"f1\": 0.6854368932038835, \"f2\": 0.576608951323097, \"f0_5\": 0.8449018669219722, \"p4\": 0.6936309547304057, \"phi\": 0.531049901570867}, {\"truth_threshold\": 2.763174219681782, \"match_probability\": 0.8716118856283598, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1057.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 974.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5204333066940308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4795667231082916, \"precision\": 1.0, \"recall\": 0.5204333066940308, \"specificity\": 1.0, \"npv\": 0.5403492450714111, \"accuracy\": 0.6933249235153198, \"f1\": 0.6845854922279793, \"f2\": 0.5756453545365429, \"f0_5\": 0.8443840869148427, \"p4\": 0.6929849775430416, \"phi\": 0.5302977652377819}, {\"truth_threshold\": 2.792630872007986, \"match_probability\": 0.8738794471112635, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1055.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 976.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5194485187530518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48055145144462585, \"precision\": 1.0, \"recall\": 0.5194485187530518, \"specificity\": 1.0, \"npv\": 0.5398396849632263, \"accuracy\": 0.6926952004432678, \"f1\": 0.6837329876863253, \"f2\": 0.5746813378363657, \"f0_5\": 0.8438649816029435, \"p4\": 0.6923385536817068, \"phi\": 0.5295459820912514}, {\"truth_threshold\": 2.8091281808508515, \"match_probability\": 0.8751343740677079, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1052.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 979.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5179714560508728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4820285439491272, \"precision\": 1.0, \"recall\": 0.5179714560508728, \"specificity\": 1.0, \"npv\": 0.5390772223472595, \"accuracy\": 0.6917506456375122, \"f1\": 0.6824521569899449, \"f2\": 0.5732345248474281, \"f0_5\": 0.8430838275364642, \"p4\": 0.6913680726839329, \"phi\": 0.5284189640909941}, {\"truth_threshold\": 2.8105766451156753, \"match_probability\": 0.8752440439333643, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1051.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 980.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5174790620803833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4825209379196167, \"precision\": 1.0, \"recall\": 0.5174790620803833, \"specificity\": 1.0, \"npv\": 0.5388235449790955, \"accuracy\": 0.6914357542991638, \"f1\": 0.682024659312135, \"f2\": 0.5727520435967303, \"f0_5\": 0.842822774659182, \"p4\": 0.6910443518632836, \"phi\": 0.5280434652911759}, {\"truth_threshold\": 2.8306911728532738, \"match_probability\": 0.8767584855919145, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1050.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 981.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5169867277145386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4830133020877838, \"precision\": 1.0, \"recall\": 0.5169867277145386, \"specificity\": 1.0, \"npv\": 0.5385701060295105, \"accuracy\": 0.6911209225654602, \"f1\": 0.6815968841285297, \"f2\": 0.5722694571615435, \"f0_5\": 0.8425613866153105, \"p4\": 0.6907205167261657, \"phi\": 0.5276680529005587}, {\"truth_threshold\": 2.8406217885332596, \"match_probability\": 0.8775003287589074, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1043.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 988.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5135401487350464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.486459881067276, \"precision\": 1.0, \"recall\": 0.5135401487350464, \"specificity\": 1.0, \"npv\": 0.5368026494979858, \"accuracy\": 0.6889168620109558, \"f1\": 0.6785946649316851, \"f2\": 0.5688884040580342, \"f0_5\": 0.840722231178462, \"p4\": 0.6884504323874672, \"phi\": 0.5250425592010217}, {\"truth_threshold\": 2.898244420869208, \"match_probability\": 0.8817293960450648, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1038.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 993.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5110782980918884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4889217019081116, \"precision\": 1.0, \"recall\": 0.5110782980918884, \"specificity\": 1.0, \"npv\": 0.5355472564697266, \"accuracy\": 0.6873425841331482, \"f1\": 0.6764418377321603, \"f2\": 0.5664702030124427, \"f0_5\": 0.8393983503153809, \"p4\": 0.6868254153315653, \"phi\": 0.5231697296295064}, {\"truth_threshold\": 2.8988966966606022, \"match_probability\": 0.8817765365142564, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1037.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 994.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5105859041213989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4894140958786011, \"precision\": 1.0, \"recall\": 0.5105859041213989, \"specificity\": 1.0, \"npv\": 0.5352968573570251, \"accuracy\": 0.6870276927947998, \"f1\": 0.6760104302477183, \"f2\": 0.5659862460430084, \"f0_5\": 0.839132545719372, \"p4\": 0.6865000531917353, \"phi\": 0.5227954119323559}, {\"truth_threshold\": 2.959055840798078, \"match_probability\": 0.8860548044954626, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1035.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 996.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5096011757850647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4903988242149353, \"precision\": 1.0, \"recall\": 0.5096011757850647, \"specificity\": 1.0, \"npv\": 0.5347968339920044, \"accuracy\": 0.6863979697227478, \"f1\": 0.675146771037182, \"f2\": 0.5650180150671471, \"f0_5\": 0.8385999027710258, \"p4\": 0.6858489665170626, \"phi\": 0.5220470222378447}, {\"truth_threshold\": 2.9970141394790293, \"match_probability\": 0.8886843153407171, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1034.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 997.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.50910884141922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4908911883831024, \"precision\": 1.0, \"recall\": 0.50910884141922, \"specificity\": 1.0, \"npv\": 0.5345471501350403, \"accuracy\": 0.6860831379890442, \"f1\": 0.6747145187601957, \"f2\": 0.5645337409914829, \"f0_5\": 0.8383330630776715, \"p4\": 0.6855232410606378, \"phi\": 0.5216729496110478}, {\"truth_threshold\": 3.005783835831938, \"match_probability\": 0.8892842275030562, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1033.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 998.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5086164474487305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49138355255126953, \"precision\": 1.0, \"recall\": 0.5086164474487305, \"specificity\": 1.0, \"npv\": 0.5342977046966553, \"accuracy\": 0.6857682466506958, \"f1\": 0.6742819843342036, \"f2\": 0.5640493611444797, \"f0_5\": 0.8380658770079507, \"p4\": 0.6851973935752371, \"phi\": 0.5212989580448912}, {\"truth_threshold\": 3.080220442293204, \"match_probability\": 0.8942631019936234, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1032.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 999.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.508124053478241, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49187591671943665, \"precision\": 1.0, \"recall\": 0.508124053478241, \"specificity\": 1.0, \"npv\": 0.5340484976768494, \"accuracy\": 0.6854534149169922, \"f1\": 0.67384916748286, \"f2\": 0.563564875491481, \"f0_5\": 0.8377983438869946, \"p4\": 0.6848714235972703, \"phi\": 0.5209250472245927}, {\"truth_threshold\": 3.1073265727291077, \"match_probability\": 0.8960265674048931, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1031.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1000.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5076317191123962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49236828088760376, \"precision\": 1.0, \"recall\": 0.5076317191123962, \"specificity\": 1.0, \"npv\": 0.5337995290756226, \"accuracy\": 0.6851385235786438, \"f1\": 0.6734160679294579, \"f2\": 0.5630802839978154, \"f0_5\": 0.8375304630381804, \"p4\": 0.68454533066202, \"phi\": 0.5205512168353408}, {\"truth_threshold\": 3.125342512579391, \"match_probability\": 0.8971842181205371, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1030.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1001.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5071393251419067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4928606450557709, \"precision\": 1.0, \"recall\": 0.5071393251419067, \"specificity\": 1.0, \"npv\": 0.5335507988929749, \"accuracy\": 0.6848236918449402, \"f1\": 0.6729826853969291, \"f2\": 0.5625955866287962, \"f0_5\": 0.8372622337831247, \"p4\": 0.6842191143036372, \"phi\": 0.5201774665622936}, {\"truth_threshold\": 3.174435246964136, \"match_probability\": 0.9002810121209373, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1029.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1002.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.506646990776062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4933530390262604, \"precision\": 1.0, \"recall\": 0.506646990776062, \"specificity\": 1.0, \"npv\": 0.5333023071289062, \"accuracy\": 0.6845088005065918, \"f1\": 0.6725490196078432, \"f2\": 0.5621107833497214, \"f0_5\": 0.8369936554416789, \"p4\": 0.6838927740551384, \"phi\": 0.5198037960905768}, {\"truth_threshold\": 3.2449521776730568, \"match_probability\": 0.9045840485737267, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1028.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1003.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5061545968055725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4938454031944275, \"precision\": 1.0, \"recall\": 0.5061545968055725, \"specificity\": 1.0, \"npv\": 0.533053994178772, \"accuracy\": 0.6841939687728882, \"f1\": 0.6721150702844066, \"f2\": 0.5616258741258742, \"f0_5\": 0.8367247273319225, \"p4\": 0.6835663094483997, \"phi\": 0.519430205105282}, {\"truth_threshold\": 3.2565565277114286, \"match_probability\": 0.9052760433824673, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1027.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1004.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5056622624397278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4943377673625946, \"precision\": 1.0, \"recall\": 0.5056622624397278, \"specificity\": 1.0, \"npv\": 0.5328059792518616, \"accuracy\": 0.6838790774345398, \"f1\": 0.671680837148463, \"f2\": 0.5611408589225221, \"f0_5\": 0.836455448770158, \"p4\": 0.6832397200141539, \"phi\": 0.5190566932914649}, {\"truth_threshold\": 3.272551700714999, \"match_probability\": 0.9062225067031762, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1026.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1005.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5051698684692383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4948301315307617, \"precision\": 1.0, \"recall\": 0.5051698684692383, \"specificity\": 1.0, \"npv\": 0.5325581431388855, \"accuracy\": 0.6835642457008362, \"f1\": 0.6712463199214916, \"f2\": 0.5606557377049181, \"f0_5\": 0.8361858190709046, \"p4\": 0.6829130052819856, \"phi\": 0.5186832603341437}, {\"truth_threshold\": 3.2832525729223265, \"match_probability\": 0.9068509549613382, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1019.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1012.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5017232894897461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4982767105102539, \"precision\": 1.0, \"recall\": 0.5017232894897461, \"specificity\": 1.0, \"npv\": 0.5308298468589783, \"accuracy\": 0.6813601851463318, \"f1\": 0.6681967213114755, \"f2\": 0.5572569178606585, \"f0_5\": 0.834288521368921, \"p4\": 0.6806224540570874, \"phi\": 0.51607141114758}, {\"truth_threshold\": 3.3793495547489933, \"match_probability\": 0.9123271697155492, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1018.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1013.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.5012308955192566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.498769074678421, \"precision\": 1.0, \"recall\": 0.5012308955192566, \"specificity\": 1.0, \"npv\": 0.5305838584899902, \"accuracy\": 0.6810453534126282, \"f1\": 0.6677599212856674, \"f2\": 0.5567709472763072, \"f0_5\": 0.8340160576765525, \"p4\": 0.680294719867444, \"phi\": 0.515698597697778}, {\"truth_threshold\": 3.4341524237699477, \"match_probability\": 0.9153183556648734, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1015.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1016.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.49975380301475525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5002461671829224, \"precision\": 1.0, \"recall\": 0.49975380301475525, \"specificity\": 1.0, \"npv\": 0.529847264289856, \"accuracy\": 0.6801007390022278, \"f1\": 0.6664478003939593, \"f2\": 0.5553123974176606, \"f0_5\": 0.8331965194549336, \"p4\": 0.6793107378647019, \"phi\": 0.5145806122045326}, {\"truth_threshold\": 3.4381479247361, \"match_probability\": 0.9155327723780841, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1013.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1018.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.498769074678421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5012308955192566, \"precision\": 1.0, \"recall\": 0.498769074678421, \"specificity\": 1.0, \"npv\": 0.529357373714447, \"accuracy\": 0.6794710159301758, \"f1\": 0.6655716162943496, \"f2\": 0.5543394987413812, \"f0_5\": 0.832648364293934, \"p4\": 0.6786540954984389, \"phi\": 0.5138356644338858}, {\"truth_threshold\": 3.5678636555351244, \"match_probability\": 0.9222311286082826, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1012.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1019.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4982767105102539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5017232894897461, \"precision\": 1.0, \"recall\": 0.4982767105102539, \"specificity\": 1.0, \"npv\": 0.5291127562522888, \"accuracy\": 0.6791561841964722, \"f1\": 0.6651330923430825, \"f2\": 0.5538528896672504, \"f0_5\": 0.8323737456818555, \"p4\": 0.6783255765487872, \"phi\": 0.5134633023691171}, {\"truth_threshold\": 3.5712177573890727, \"match_probability\": 0.9223977078858835, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1011.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1020.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4977843463420868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5022156834602356, \"precision\": 1.0, \"recall\": 0.4977843463420868, \"specificity\": 1.0, \"npv\": 0.5288683772087097, \"accuracy\": 0.6788412928581238, \"f1\": 0.6646942800788954, \"f2\": 0.5533661740558292, \"f0_5\": 0.8320987654320988, \"p4\": 0.6779969251043269, \"phi\": 0.5130910144303928}, {\"truth_threshold\": 3.58947274624298, \"match_probability\": 0.9232986129185319, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1010.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1021.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4972919821739197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5027080178260803, \"precision\": 1.0, \"recall\": 0.4972919821739197, \"specificity\": 1.0, \"npv\": 0.5286241769790649, \"accuracy\": 0.6785264611244202, \"f1\": 0.6642551792173627, \"f2\": 0.5528793518721261, \"f0_5\": 0.8318234228298468, \"p4\": 0.6776681406756905, \"phi\": 0.5127188003018871}, {\"truth_threshold\": 3.593016592019722, \"match_probability\": 0.9234723906468314, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1006.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1025.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.49532249569892883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5046774744987488, \"precision\": 1.0, \"recall\": 0.49532249569892883, \"specificity\": 1.0, \"npv\": 0.5276497602462769, \"accuracy\": 0.6772670149803162, \"f1\": 0.6624958840961476, \"f2\": 0.5509309967141293, \"f0_5\": 0.8307184145334434, \"p4\": 0.6763516632891752, \"phi\": 0.5112306755711034}, {\"truth_threshold\": 3.612559100153937, \"match_probability\": 0.9244242156354207, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1005.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1026.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4948301315307617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5051698684692383, \"precision\": 1.0, \"recall\": 0.4948301315307617, \"specificity\": 1.0, \"npv\": 0.5274067521095276, \"accuracy\": 0.6769521236419678, \"f1\": 0.6620553359683794, \"f2\": 0.5504436411436083, \"f0_5\": 0.8304412493802678, \"p4\": 0.6760222065562214, \"phi\": 0.5108588257538497}, {\"truth_threshold\": 3.6185178965901112, \"match_probability\": 0.9247122714957313, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1004.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1027.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4943377673625946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5056622624397278, \"precision\": 1.0, \"recall\": 0.4943377673625946, \"specificity\": 1.0, \"npv\": 0.5271639227867126, \"accuracy\": 0.6766372919082642, \"f1\": 0.6616144975288303, \"f2\": 0.5499561787905346, \"f0_5\": 0.8301637175458906, \"p4\": 0.6756926138770669, \"phi\": 0.5104870478503633}, {\"truth_threshold\": 3.62832052596078, \"match_probability\": 0.9251839496045419, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1003.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1028.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4938454031944275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5061545968055725, \"precision\": 1.0, \"recall\": 0.4938454031944275, \"specificity\": 1.0, \"npv\": 0.5269213318824768, \"accuracy\": 0.6763224005699158, \"f1\": 0.6611733684904416, \"f2\": 0.5494686096198094, \"f0_5\": 0.8298858183021678, \"p4\": 0.6753628847536947, \"phi\": 0.5101153415443024}, {\"truth_threshold\": 3.6293596144862104, \"match_probability\": 0.9252337884396565, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1002.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1029.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4933530390262604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.506646990776062, \"precision\": 1.0, \"recall\": 0.4933530390262604, \"specificity\": 1.0, \"npv\": 0.5266789197921753, \"accuracy\": 0.6760075688362122, \"f1\": 0.6607319485657764, \"f2\": 0.5489809335963182, \"f0_5\": 0.8296075509190264, \"p4\": 0.6750330186868337, \"phi\": 0.5097437065192449}, {\"truth_threshold\": 3.630686200084396, \"match_probability\": 0.9252973724312, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1001.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1030.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4928606450557709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5071393251419067, \"precision\": 1.0, \"recall\": 0.4928606450557709, \"specificity\": 1.0, \"npv\": 0.5264368057250977, \"accuracy\": 0.6756926774978638, \"f1\": 0.6602902374670184, \"f2\": 0.5484931506849315, \"f0_5\": 0.8293289146644574, \"p4\": 0.674703015175954, \"phi\": 0.5093721424586857}, {\"truth_threshold\": 3.6593244299344154, \"match_probability\": 0.9266579509598108, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 1000.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1031.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.49236828088760376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5076317191123962, \"precision\": 1.0, \"recall\": 0.49236828088760376, \"specificity\": 1.0, \"npv\": 0.5261948704719543, \"accuracy\": 0.6753778457641602, \"f1\": 0.6598482349059717, \"f2\": 0.5480052608505042, \"f0_5\": 0.82904990880451, \"p4\": 0.6743728737192621, \"phi\": 0.5090006490460345}, {\"truth_threshold\": 3.663112352048595, \"match_probability\": 0.926836193971499, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 999.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1032.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.49187591671943665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.508124053478241, \"precision\": 1.0, \"recall\": 0.49187591671943665, \"specificity\": 1.0, \"npv\": 0.5259531736373901, \"accuracy\": 0.6750629544258118, \"f1\": 0.6594059405940594, \"f2\": 0.5475172640578757, \"f0_5\": 0.8287705326032853, \"p4\": 0.6740425938136967, \"phi\": 0.5086292259646149}, {\"truth_threshold\": 3.754061367646621, \"match_probability\": 0.9309977053446036, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 998.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1033.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.49138355255126953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5086164474487305, \"precision\": 1.0, \"recall\": 0.49138355255126953, \"specificity\": 1.0, \"npv\": 0.5257116556167603, \"accuracy\": 0.6747481226921082, \"f1\": 0.6589633542423242, \"f2\": 0.5470291602718702, \"f0_5\": 0.8284907853229287, \"p4\": 0.6737121749549234, \"phi\": 0.508257872897662}, {\"truth_threshold\": 3.7620373560183666, \"match_probability\": 0.9313520186111618, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 997.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1034.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4908911883831024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.50910884141922, \"precision\": 1.0, \"recall\": 0.4908911883831024, \"specificity\": 1.0, \"npv\": 0.5254703760147095, \"accuracy\": 0.6744332313537598, \"f1\": 0.6585204755614267, \"f2\": 0.5465409494572964, \"f0_5\": 0.8282106662236252, \"p4\": 0.6733816166373302, \"phi\": 0.5078865895283203}, {\"truth_threshold\": 3.7869042873195236, \"match_probability\": 0.9324458782305853, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 996.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1035.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4903988242149353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5096011757850647, \"precision\": 1.0, \"recall\": 0.4903988242149353, \"specificity\": 1.0, \"npv\": 0.5252293348312378, \"accuracy\": 0.6741183996200562, \"f1\": 0.6580773042616452, \"f2\": 0.5460526315789473, \"f0_5\": 0.827930174563591, \"p4\": 0.6730509183540228, \"phi\": 0.5075153755396427}, {\"truth_threshold\": 3.802947820008326, \"match_probability\": 0.9331430069396818, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 994.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1037.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4894140958786011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5105859041213989, \"precision\": 1.0, \"recall\": 0.4894140958786011, \"specificity\": 1.0, \"npv\": 0.524747908115387, \"accuracy\": 0.6734886765480042, \"f1\": 0.6571900826446281, \"f2\": 0.5450756744900197, \"f0_5\": 0.8273680705843183, \"p4\": 0.6723890998562475, \"phi\": 0.5067731544360166}, {\"truth_threshold\": 3.8077662908701995, \"match_probability\": 0.9333510731317527, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 993.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1038.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4889217019081116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5110782980918884, \"precision\": 1.0, \"recall\": 0.4889217019081116, \"specificity\": 1.0, \"npv\": 0.5245075821876526, \"accuracy\": 0.6731737852096558, \"f1\": 0.6567460317460317, \"f2\": 0.5445870352089504, \"f0_5\": 0.8270864567716142, \"p4\": 0.6720579786215359, \"phi\": 0.5064021466866954}, {\"truth_threshold\": 3.81761121763854, \"match_probability\": 0.9337743183605033, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 991.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1040.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.48793697357177734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5120630264282227, \"precision\": 1.0, \"recall\": 0.48793697357177734, \"specificity\": 1.0, \"npv\": 0.5240274667739868, \"accuracy\": 0.6725440621376038, \"f1\": 0.6558570483123759, \"f2\": 0.5436094349972572, \"f0_5\": 0.8265221017514596, \"p4\": 0.6713953096201011, \"phi\": 0.5056603352063587}, {\"truth_threshold\": 3.8225887788115394, \"match_probability\": 0.9339873580497218, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 990.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1041.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.48744460940361023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5125554203987122, \"precision\": 1.0, \"recall\": 0.48744460940361023, \"specificity\": 1.0, \"npv\": 0.5237877368927002, \"accuracy\": 0.6722292304039001, \"f1\": 0.6554121151936445, \"f2\": 0.54312047399605, \"f0_5\": 0.8262393590385578, \"p4\": 0.6710637608253098, \"phi\": 0.505289530840366}, {\"truth_threshold\": 3.8415190284325846, \"match_probability\": 0.9347917683531026, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 988.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1043.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.486459881067276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5135401487350464, \"precision\": 1.0, \"recall\": 0.486459881067276, \"specificity\": 1.0, \"npv\": 0.5233089327812195, \"accuracy\": 0.6715995073318481, \"f1\": 0.6545213646902948, \"f2\": 0.5421422300263389, \"f0_5\": 0.8256727394283804, \"p4\": 0.670400232067545, \"phi\": 0.5045481232685004}, {\"truth_threshold\": 3.851140594601534, \"match_probability\": 0.9351971176549556, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 987.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1044.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4859675168991089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5140324831008911, \"precision\": 1.0, \"recall\": 0.4859675168991089, \"specificity\": 1.0, \"npv\": 0.5230699181556702, \"accuracy\": 0.6712846159934998, \"f1\": 0.6540755467196819, \"f2\": 0.5416529469871584, \"f0_5\": 0.8253888610135475, \"p4\": 0.6700682510685908, \"phi\": 0.5041775194270115}, {\"truth_threshold\": 3.8925178361807453, \"match_probability\": 0.9369137128952849, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 985.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1046.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.48498275876045227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5150172114372253, \"precision\": 1.0, \"recall\": 0.48498275876045227, \"specificity\": 1.0, \"npv\": 0.5225924253463745, \"accuracy\": 0.6706548929214478, \"f1\": 0.653183023872679, \"f2\": 0.5406740586233395, \"f0_5\": 0.8248199631552504, \"p4\": 0.6694038532306121, \"phi\": 0.5034365100430503}, {\"truth_threshold\": 3.910295440850892, \"match_probability\": 0.9376381420007058, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 981.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1050.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4830133020877838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5169867277145386, \"precision\": 1.0, \"recall\": 0.4830133020877838, \"specificity\": 1.0, \"npv\": 0.5216400623321533, \"accuracy\": 0.6693954467773438, \"f1\": 0.651394422310757, \"f2\": 0.5387149917627677, \"f0_5\": 0.8236775818639799, \"p4\": 0.6680732995503533, \"phi\": 0.501955275560685}, {\"truth_threshold\": 3.9199593985023773, \"match_probability\": 0.9380286787284521, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 980.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1051.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4825209379196167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5174790620803833, \"precision\": 1.0, \"recall\": 0.4825209379196167, \"specificity\": 1.0, \"npv\": 0.5214025378227234, \"accuracy\": 0.6690806150436401, \"f1\": 0.6509465293922285, \"f2\": 0.5382249560632689, \"f0_5\": 0.8233910267181986, \"p4\": 0.6677402918128024, \"phi\": 0.5015851284751782}, {\"truth_threshold\": 3.9266248115876317, \"match_probability\": 0.9382967070089888, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 977.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1054.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.48104381561279297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.518956184387207, \"precision\": 1.0, \"recall\": 0.48104381561279297, \"specificity\": 1.0, \"npv\": 0.5206912159919739, \"accuracy\": 0.6681360006332397, \"f1\": 0.6496010638297872, \"f2\": 0.5367542028348533, \"f0_5\": 0.8225290452938205, \"p4\": 0.6667403737725085, \"phi\": 0.5004750698024271}, {\"truth_threshold\": 3.9484342323490966, \"match_probability\": 0.9391661514932094, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 975.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1056.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.48005908727645874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5199409127235413, \"precision\": 1.0, \"recall\": 0.48005908727645874, \"specificity\": 1.0, \"npv\": 0.5202180743217468, \"accuracy\": 0.6675062775611877, \"f1\": 0.6487025948103793, \"f2\": 0.5357731618859215, \"f0_5\": 0.8219524532119373, \"p4\": 0.6660730107305548, \"phi\": 0.4997353463161058}, {\"truth_threshold\": 3.949757743772171, \"match_probability\": 0.9392185436060059, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 974.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1057.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4795667231082916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5204333066940308, \"precision\": 1.0, \"recall\": 0.4795667231082916, \"specificity\": 1.0, \"npv\": 0.519981861114502, \"accuracy\": 0.6671914458274841, \"f1\": 0.648252911813644, \"f2\": 0.5352824796658606, \"f0_5\": 0.8216635734773072, \"p4\": 0.6657391023001616, \"phi\": 0.4993655783036174}, {\"truth_threshold\": 3.9818067989465527, \"match_probability\": 0.9404744111706063, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 972.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1059.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.478581964969635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.521418035030365, \"precision\": 1.0, \"recall\": 0.478581964969635, \"specificity\": 1.0, \"npv\": 0.5195099711418152, \"accuracy\": 0.6665617227554321, \"f1\": 0.6473526473526473, \"f2\": 0.5343007915567283, \"f0_5\": 0.8210846426761277, \"p4\": 0.6650708289317822, \"phi\": 0.4986262281419932}, {\"truth_threshold\": 4.002925333403265, \"match_probability\": 0.9412886296816947, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 970.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1061.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4775972366333008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5224027633666992, \"precision\": 1.0, \"recall\": 0.4775972366333008, \"specificity\": 1.0, \"npv\": 0.5190389752388, \"accuracy\": 0.6659319996833801, \"f1\": 0.6464511829390204, \"f2\": 0.5333186716516385, \"f0_5\": 0.8205041448147522, \"p4\": 0.6644019432852049, \"phi\": 0.4978871236658882}, {\"truth_threshold\": 4.013256991816112, \"match_probability\": 0.9416831490912403, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 967.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1064.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.47612014412879944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.523879885673523, \"precision\": 1.0, \"recall\": 0.47612014412879944, \"specificity\": 1.0, \"npv\": 0.5183340907096863, \"accuracy\": 0.6649873852729797, \"f1\": 0.6450967311541027, \"f2\": 0.5318446815531844, \"f0_5\": 0.8196304458382777, \"p4\": 0.6633974572904727, \"phi\": 0.49677892200980617}, {\"truth_threshold\": 4.0324610400015395, \"match_probability\": 0.9424098652969306, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 966.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1065.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4756277799606323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5243722200393677, \"precision\": 1.0, \"recall\": 0.4756277799606323, \"specificity\": 1.0, \"npv\": 0.5180995464324951, \"accuracy\": 0.6646725535392761, \"f1\": 0.6446446446446447, \"f2\": 0.5313531353135313, \"f0_5\": 0.8193384223918575, \"p4\": 0.6630623177686907, \"phi\": 0.4964096415249014}, {\"truth_threshold\": 4.081795429252678, \"match_probability\": 0.944237967050559, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 965.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1066.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4751354157924652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5248646140098572, \"precision\": 1.0, \"recall\": 0.4751354157924652, \"specificity\": 1.0, \"npv\": 0.5178652405738831, \"accuracy\": 0.6643576622009277, \"f1\": 0.644192256341789, \"f2\": 0.5308614809109913, \"f0_5\": 0.8190460023765065, \"p4\": 0.6627270219044649, \"phi\": 0.4960404205390772}, {\"truth_threshold\": 4.12866880703278, \"match_probability\": 0.9459241728930081, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 964.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1067.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4746430218219757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5253569483757019, \"precision\": 1.0, \"recall\": 0.4746430218219757, \"specificity\": 1.0, \"npv\": 0.5176311135292053, \"accuracy\": 0.6640428304672241, \"f1\": 0.6437395659432388, \"f2\": 0.5303697183098591, \"f0_5\": 0.8187531849838627, \"p4\": 0.6623915691472244, \"phi\": 0.4956712587314137}, {\"truth_threshold\": 4.1459564752832305, \"match_probability\": 0.9465338526110589, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 961.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1070.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.47316592931747437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5268340706825256, \"precision\": 1.0, \"recall\": 0.47316592931747437, \"specificity\": 1.0, \"npv\": 0.5169300436973572, \"accuracy\": 0.6630982160568237, \"f1\": 0.642379679144385, \"f2\": 0.5288937809576224, \"f0_5\": 0.8178723404255319, \"p4\": 0.661384263989902, \"phi\": 0.49456412516582227}, {\"truth_threshold\": 4.16304423904001, \"match_probability\": 0.9471301045416083, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 960.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1071.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.47267356514930725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5273264646530151, \"precision\": 1.0, \"recall\": 0.47267356514930725, \"specificity\": 1.0, \"npv\": 0.5166967511177063, \"accuracy\": 0.6627833843231201, \"f1\": 0.641925777331996, \"f2\": 0.5284015852047557, \"f0_5\": 0.8175779253960143, \"p4\": 0.6610481781257823, \"phi\": 0.49419519685843255}, {\"truth_threshold\": 4.164111390090864, \"match_probability\": 0.9471671321631224, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 959.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1072.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.47218120098114014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5278187990188599, \"precision\": 1.0, \"recall\": 0.47218120098114014, \"specificity\": 1.0, \"npv\": 0.5164636969566345, \"accuracy\": 0.6624684929847717, \"f1\": 0.6414715719063545, \"f2\": 0.5279092810745348, \"f0_5\": 0.8172831089142663, \"p4\": 0.6607119325939106, \"phi\": 0.49382632612220784}, {\"truth_threshold\": 4.164557525664242, \"match_probability\": 0.9471826047548284, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 956.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1075.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4707040786743164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5292959213256836, \"precision\": 1.0, \"recall\": 0.4707040786743164, \"specificity\": 1.0, \"npv\": 0.5157657861709595, \"accuracy\": 0.6615239381790161, \"f1\": 0.6401071309005691, \"f2\": 0.526431718061674, \"f0_5\": 0.816396242527754, \"p4\": 0.6597022323907215, \"phi\": 0.4927200561207447}, {\"truth_threshold\": 4.198621709528815, \"match_probability\": 0.94835143826399, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 955.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1076.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4702117145061493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5297882556915283, \"precision\": 1.0, \"recall\": 0.4702117145061493, \"specificity\": 1.0, \"npv\": 0.5155335664749146, \"accuracy\": 0.6612090468406677, \"f1\": 0.6396517079705292, \"f2\": 0.5259389800638837, \"f0_5\": 0.8160998119979491, \"p4\": 0.6593653425793322, \"phi\": 0.49235141244854475}, {\"truth_threshold\": 4.22815741612709, \"match_probability\": 0.9493450510390068, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 952.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1079.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.46873462200164795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.531265377998352, \"precision\": 1.0, \"recall\": 0.46873462200164795, \"specificity\": 1.0, \"npv\": 0.5148381590843201, \"accuracy\": 0.6602644920349121, \"f1\": 0.6382836071069393, \"f2\": 0.5244601145879242, \"f0_5\": 0.8152080835759548, \"p4\": 0.6583536959994251, \"phi\": 0.491245815900624}, {\"truth_threshold\": 4.260202105636668, \"match_probability\": 0.9504025908951476, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 948.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1083.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4667651355266571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5332348346710205, \"precision\": 1.0, \"recall\": 0.4667651355266571, \"specificity\": 1.0, \"npv\": 0.5139138102531433, \"accuracy\": 0.6590050458908081, \"f1\": 0.6364551863041289, \"f2\": 0.5224867724867724, \"f0_5\": 0.8140133951571354, \"p4\": 0.6570025326247371, \"phi\": 0.4897724555353377}, {\"truth_threshold\": 4.270171074525464, \"match_probability\": 0.9507272974383177, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 947.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1084.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.46627277135849, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.53372722864151, \"precision\": 1.0, \"recall\": 0.46627277135849, \"specificity\": 1.0, \"npv\": 0.5136832594871521, \"accuracy\": 0.6586901545524597, \"f1\": 0.6359973136333109, \"f2\": 0.5219931650314188, \"f0_5\": 0.8137136965114281, \"p4\": 0.6566643270207304, \"phi\": 0.48940425049545894}, {\"truth_threshold\": 4.2728655202356, \"match_probability\": 0.9508147135901612, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 946.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1085.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4657804071903229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5342196226119995, \"precision\": 1.0, \"recall\": 0.4657804071903229, \"specificity\": 1.0, \"npv\": 0.5134528875350952, \"accuracy\": 0.6583753228187561, \"f1\": 0.6355391333557272, \"f2\": 0.5214994487320838, \"f0_5\": 0.8134135855546002, \"p4\": 0.656325954359785, \"phi\": 0.48903609882831217}, {\"truth_threshold\": 4.295710664143024, \"match_probability\": 0.951549992610941, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 945.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1086.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.46528804302215576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5347119569778442, \"precision\": 1.0, \"recall\": 0.46528804302215576, \"specificity\": 1.0, \"npv\": 0.5132227540016174, \"accuracy\": 0.6580604314804077, \"f1\": 0.6350806451612904, \"f2\": 0.5210056235527621, \"f0_5\": 0.8131130614352091, \"p4\": 0.6559874140627842, \"phi\": 0.48866800020963597}, {\"truth_threshold\": 4.315635349049926, \"match_probability\": 0.9521827475833161, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 939.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1092.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4623338282108307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5376662015914917, \"precision\": 1.0, \"recall\": 0.4623338282108307, \"specificity\": 1.0, \"npv\": 0.5118462443351746, \"accuracy\": 0.6561712622642517, \"f1\": 0.6323232323232323, \"f2\": 0.5180403839788149, \"f0_5\": 0.8113011923276309, \"p4\": 0.6539526192956943, \"phi\": 0.48646050433168353}, {\"truth_threshold\": 4.3364171790986985, \"match_probability\": 0.9528343565527647, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 937.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1094.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.46134909987449646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5386509299278259, \"precision\": 1.0, \"recall\": 0.46134909987449646, \"specificity\": 1.0, \"npv\": 0.5113890171051025, \"accuracy\": 0.6555415391921997, \"f1\": 0.6314016172506739, \"f2\": 0.517051098112791, \"f0_5\": 0.8106938916767606, \"p4\": 0.6532729867770165, \"phi\": 0.4857250820276769}, {\"truth_threshold\": 4.426523598662599, \"match_probability\": 0.9555631746160959, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 935.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1096.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.46036434173583984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5396356582641602, \"precision\": 1.0, \"recall\": 0.46036434173583984, \"specificity\": 1.0, \"npv\": 0.5109326243400574, \"accuracy\": 0.6549118161201477, \"f1\": 0.6304787592717465, \"f2\": 0.5160613754277514, \"f0_5\": 0.8100849072950962, \"p4\": 0.6525926625805016, \"phi\": 0.48498986020736484}, {\"truth_threshold\": 4.511587312308788, \"match_probability\": 0.9580006383672386, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 933.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1098.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4593796133995056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5406203866004944, \"precision\": 1.0, \"recall\": 0.4593796133995056, \"specificity\": 1.0, \"npv\": 0.5104770660400391, \"accuracy\": 0.6542820930480957, \"f1\": 0.6295546558704453, \"f2\": 0.515071215634316, \"f0_5\": 0.8094742321707444, \"p4\": 0.6519116419396886, \"phi\": 0.48425483625920296}, {\"truth_threshold\": 4.5373770270306535, \"match_probability\": 0.9587140296776768, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 931.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1100.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4583948850631714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5416051149368286, \"precision\": 1.0, \"recall\": 0.4583948850631714, \"specificity\": 1.0, \"npv\": 0.5100222826004028, \"accuracy\": 0.6536523699760437, \"f1\": 0.6286293045239703, \"f2\": 0.5140806184428492, \"f0_5\": 0.8088618592528236, \"p4\": 0.6512299200620687, \"phi\": 0.4835200075681016}, {\"truth_threshold\": 4.548077899237982, \"match_probability\": 0.9590066194179039, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 929.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1102.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.45741015672683716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5425898432731628, \"precision\": 1.0, \"recall\": 0.45741015672683716, \"specificity\": 1.0, \"npv\": 0.5095683336257935, \"accuracy\": 0.6530226469039917, \"f1\": 0.6277027027027027, \"f2\": 0.5130895835634596, \"f0_5\": 0.8082477814511919, \"p4\": 0.6505474921288833, \"phi\": 0.48278537151535283}, {\"truth_threshold\": 4.5579384463336226, \"match_probability\": 0.9592744744321506, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 928.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1103.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.45691776275634766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5430822372436523, \"precision\": 1.0, \"recall\": 0.45691776275634766, \"specificity\": 1.0, \"npv\": 0.5093416571617126, \"accuracy\": 0.6527078151702881, \"f1\": 0.6272389320716458, \"f2\": 0.5125939019001325, \"f0_5\": 0.8079401009925127, \"p4\": 0.6502060118783636, \"phi\": 0.48241812490900726}, {\"truth_threshold\": 4.588031268085641, \"match_probability\": 0.960081601051044, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 927.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1104.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.45642539858818054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5435745716094971, \"precision\": 1.0, \"recall\": 0.45642539858818054, \"specificity\": 1.0, \"npv\": 0.5091151595115662, \"accuracy\": 0.6523929238319397, \"f1\": 0.6267748478701826, \"f2\": 0.5120981107059993, \"f0_5\": 0.8076319916361735, \"p4\": 0.64986435329492, \"phi\": 0.482050925478558}, {\"truth_threshold\": 4.589096171822081, \"match_probability\": 0.9601098804119849, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 926.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1105.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4559330344200134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5440669655799866, \"precision\": 1.0, \"recall\": 0.4559330344200134, \"specificity\": 1.0, \"npv\": 0.5088889002799988, \"accuracy\": 0.6520780920982361, \"f1\": 0.6263104497801826, \"f2\": 0.5116022099447514, \"f0_5\": 0.8073234524847428, \"p4\": 0.6495225157687339, \"phi\": 0.48168377289561637}, {\"truth_threshold\": 4.604930275046588, \"match_probability\": 0.9605281085605459, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 925.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1106.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4554406702518463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5445593595504761, \"precision\": 1.0, \"recall\": 0.4554406702518463, \"specificity\": 1.0, \"npv\": 0.5086628198623657, \"accuracy\": 0.6517632007598877, \"f1\": 0.6258457374830853, \"f2\": 0.5111061995800641, \"f0_5\": 0.807014482638283, \"p4\": 0.6491804986883075, \"phi\": 0.48131666683155405}, {\"truth_threshold\": 4.605506212817947, \"match_probability\": 0.9605432413572035, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 923.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1108.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4544559419155121, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5455440878868103, \"precision\": 1.0, \"recall\": 0.4544559419155121, \"specificity\": 1.0, \"npv\": 0.5082112550735474, \"accuracy\": 0.6511334776878357, \"f1\": 0.6249153689911984, \"f2\": 0.5101138498949929, \"f0_5\": 0.8063952472479469, \"p4\": 0.6484959234103079, \"phi\": 0.4805825929443398}, {\"truth_threshold\": 4.662118922346399, \"match_probability\": 0.9620038855482212, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 921.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1110.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.45347118377685547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5465288162231445, \"precision\": 1.0, \"recall\": 0.45347118377685547, \"specificity\": 1.0, \"npv\": 0.5077605247497559, \"accuracy\": 0.6505037546157837, \"f1\": 0.6239837398373984, \"f2\": 0.5091210613598673, \"f0_5\": 0.8057742782152231, \"p4\": 0.6478106225351075, \"phi\": 0.47984870118300166}, {\"truth_threshold\": 4.663112352048595, \"match_probability\": 0.9620290472758354, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 920.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1111.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.45297881960868835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5470211505889893, \"precision\": 1.0, \"recall\": 0.45297881960868835, \"specificity\": 1.0, \"npv\": 0.507535457611084, \"accuracy\": 0.6501889228820801, \"f1\": 0.6235174517112844, \"f2\": 0.508624502432552, \"f0_5\": 0.8054631413062511, \"p4\": 0.6474676984517845, \"phi\": 0.47948182277534984}, {\"truth_threshold\": 4.670698263654289, \"match_probability\": 0.9622206572516385, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 919.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1112.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.45248645544052124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5475135445594788, \"precision\": 1.0, \"recall\": 0.45248645544052124, \"specificity\": 1.0, \"npv\": 0.5073105692863464, \"accuracy\": 0.6498740315437317, \"f1\": 0.6230508474576271, \"f2\": 0.5081278336835121, \"f0_5\": 0.8051515682495182, \"p4\": 0.6471245911096051, \"phi\": 0.4791149889096385}, {\"truth_threshold\": 4.672874215843136, \"match_probability\": 0.9622754472314372, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 917.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1114.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.451501727104187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.548498272895813, \"precision\": 1.0, \"recall\": 0.451501727104187, \"specificity\": 1.0, \"npv\": 0.5068614482879639, \"accuracy\": 0.6492443084716797, \"f1\": 0.6221166892808684, \"f2\": 0.507134166574494, \"f0_5\": 0.8045271100193017, \"p4\": 0.6464378241531998, \"phi\": 0.4783814534822862}, {\"truth_threshold\": 4.680714846828809, \"match_probability\": 0.9624722400244782, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 916.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1115.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4510093629360199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5489906668663025, \"precision\": 1.0, \"recall\": 0.4510093629360199, \"specificity\": 1.0, \"npv\": 0.5066371560096741, \"accuracy\": 0.6489294767379761, \"f1\": 0.6216491347132678, \"f2\": 0.5066371681415929, \"f0_5\": 0.8042142230026339, \"p4\": 0.6460941632868983, \"phi\": 0.4780147512591208}, {\"truth_threshold\": 4.70402275294689, \"match_probability\": 0.9630514384616587, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 915.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1116.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4505169987678528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5494830012321472, \"precision\": 1.0, \"recall\": 0.4505169987678528, \"specificity\": 1.0, \"npv\": 0.5064131021499634, \"accuracy\": 0.6486145853996277, \"f1\": 0.6211812627291242, \"f2\": 0.5061400597411218, \"f0_5\": 0.8039008961518187, \"p4\": 0.6457503166575753, \"phi\": 0.477648092254842}, {\"truth_threshold\": 4.717035785351744, \"match_probability\": 0.9633710613853324, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 913.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1118.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44953224062919617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5504677295684814, \"precision\": 1.0, \"recall\": 0.44953224062919617, \"specificity\": 1.0, \"npv\": 0.505965530872345, \"accuracy\": 0.6479848623275757, \"f1\": 0.6202445652173914, \"f2\": 0.5051455128914463, \"f0_5\": 0.8032729192327995, \"p4\": 0.645062063586483, \"phi\": 0.4769149025769879}, {\"truth_threshold\": 4.745667343365903, \"match_probability\": 0.9640649643213819, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 911.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1120.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44854751229286194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5514524579048157, \"precision\": 1.0, \"recall\": 0.44854751229286194, \"specificity\": 1.0, \"npv\": 0.5055187344551086, \"accuracy\": 0.6473551392555237, \"f1\": 0.619306594153637, \"f2\": 0.5041505257332596, \"f0_5\": 0.8026431718061674, \"p4\": 0.6443730598755232, \"phi\": 0.47618188179411347}, {\"truth_threshold\": 4.76773247120762, \"match_probability\": 0.9645910740449112, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 909.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1122.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4475627839565277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5524372458457947, \"precision\": 1.0, \"recall\": 0.4475627839565277, \"specificity\": 1.0, \"npv\": 0.5050727725028992, \"accuracy\": 0.6467254161834717, \"f1\": 0.6183673469387755, \"f2\": 0.503155097974095, \"f0_5\": 0.8020116463737427, \"p4\": 0.6436833004319238, \"phi\": 0.4754490272472384}, {\"truth_threshold\": 4.7763118125155115, \"match_probability\": 0.9647936257512386, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 906.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1125.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.446085661649704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5539143085479736, \"precision\": 1.0, \"recall\": 0.446085661649704, \"specificity\": 1.0, \"npv\": 0.5044052600860596, \"accuracy\": 0.6457808613777161, \"f1\": 0.616956077630235, \"f2\": 0.5016611295681063, \"f0_5\": 0.8010610079575596, \"p4\": 0.6426472330569604, \"phi\": 0.47435005129193997}, {\"truth_threshold\": 4.78372764421119, \"match_probability\": 0.9649678079371918, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 905.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1126.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44559329748153687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5544067025184631, \"precision\": 1.0, \"recall\": 0.44559329748153687, \"specificity\": 1.0, \"npv\": 0.5041831731796265, \"accuracy\": 0.6454659700393677, \"f1\": 0.6164850136239782, \"f2\": 0.5011629194816701, \"f0_5\": 0.8007432312864979, \"p4\": 0.6423014938325172, \"phi\": 0.47398380620324704}, {\"truth_threshold\": 4.783912889201937, \"match_probability\": 0.9649721483011046, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 903.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1128.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44460856914520264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5553914308547974, \"precision\": 1.0, \"recall\": 0.44460856914520264, \"specificity\": 1.0, \"npv\": 0.5037395358085632, \"accuracy\": 0.6448362469673157, \"f1\": 0.6155419222903885, \"f2\": 0.5001661681621802, \"f0_5\": 0.8001063264221159, \"p4\": 0.6416094363472876, \"phi\": 0.47325143436561484}, {\"truth_threshold\": 4.8012025889434975, \"match_probability\": 0.9653749791234288, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 902.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1129.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4441162049770355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5558838248252869, \"precision\": 1.0, \"recall\": 0.4441162049770355, \"specificity\": 1.0, \"npv\": 0.5035180449485779, \"accuracy\": 0.6445214152336121, \"f1\": 0.6150698943061712, \"f2\": 0.49966762685575006, \"f0_5\": 0.7997871963114027, \"p4\": 0.6412631167843771, \"phi\": 0.4728853069473651}, {\"truth_threshold\": 4.851280892227125, \"match_probability\": 0.9665166968376807, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 901.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1130.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4436238408088684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5563761591911316, \"precision\": 1.0, \"recall\": 0.4436238408088684, \"specificity\": 1.0, \"npv\": 0.5032967329025269, \"accuracy\": 0.6442065238952637, \"f1\": 0.6145975443383356, \"f2\": 0.49916897506925206, \"f0_5\": 0.7994676131322094, \"p4\": 0.6409166024701175, \"phi\": 0.47251921808279124}, {\"truth_threshold\": 4.877384426469592, \"match_probability\": 0.9670973278146049, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 897.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1134.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44165435433387756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5583456158638, \"precision\": 1.0, \"recall\": 0.44165435433387756, \"specificity\": 1.0, \"npv\": 0.5024133324623108, \"accuracy\": 0.6429470777511597, \"f1\": 0.6127049180327869, \"f2\": 0.4971732623877619, \"f0_5\": 0.798184730379071, \"p4\": 0.6395285845581368, \"phi\": 0.471055241448671}, {\"truth_threshold\": 4.890406096808852, \"match_probability\": 0.9673833261089764, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 896.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1135.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44116199016571045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5588380098342896, \"precision\": 1.0, \"recall\": 0.44116199016571045, \"specificity\": 1.0, \"npv\": 0.5021929740905762, \"accuracy\": 0.642632246017456, \"f1\": 0.612230953194397, \"f2\": 0.49667405764966743, \"f0_5\": 0.7978628673196795, \"p4\": 0.6391810866147006, \"phi\": 0.47068934031536125}, {\"truth_threshold\": 4.9669735038748195, \"match_probability\": 0.9690170057493972, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 895.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1136.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.44066962599754333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.559330403804779, \"precision\": 1.0, \"recall\": 0.44066962599754333, \"specificity\": 1.0, \"npv\": 0.5019727945327759, \"accuracy\": 0.6423173546791077, \"f1\": 0.6117566643882434, \"f2\": 0.49617474221088814, \"f0_5\": 0.7975405453573338, \"p4\": 0.6388333899578278, \"phi\": 0.47032347571872485}, {\"truth_threshold\": 4.979609265327487, \"match_probability\": 0.969278883458899, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 892.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1139.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4391925036907196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.560807466506958, \"precision\": 1.0, \"recall\": 0.4391925036907196, \"specificity\": 1.0, \"npv\": 0.5013135075569153, \"accuracy\": 0.641372799873352, \"f1\": 0.61033185083818, \"f2\": 0.49467613132209404, \"f0_5\": 0.7965708162171816, \"p4\": 0.6377891010276633, \"phi\": 0.46922609777468816}, {\"truth_threshold\": 5.054234428969977, \"match_probability\": 0.9707823224938937, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 888.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1143.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.43722304701805115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5627769827842712, \"precision\": 1.0, \"recall\": 0.43722304701805115, \"specificity\": 1.0, \"npv\": 0.5004370808601379, \"accuracy\": 0.640113353729248, \"f1\": 0.6084275436793423, \"f2\": 0.49267643142476697, \"f0_5\": 0.7952713594841483, \"p4\": 0.6363938931197374, \"phi\": 0.4677634181990659}, {\"truth_threshold\": 5.063911449769033, \"match_probability\": 0.9709719772770619, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 886.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1145.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4362383186817169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5637617111206055, \"precision\": 1.0, \"recall\": 0.4362383186817169, \"specificity\": 1.0, \"npv\": 0.5, \"accuracy\": 0.639483630657196, \"f1\": 0.6074734316078162, \"f2\": 0.4916759156492786, \"f0_5\": 0.7946188340807175, \"p4\": 0.635695067264574, \"phi\": 0.4670322827455707}, {\"truth_threshold\": 5.071934882157037, \"match_probability\": 0.971128318190059, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 884.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1147.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4352535605430603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5647464394569397, \"precision\": 1.0, \"recall\": 0.4352535605430603, \"specificity\": 1.0, \"npv\": 0.49956369400024414, \"accuracy\": 0.638853907585144, \"f1\": 0.6065180102915952, \"f2\": 0.49067495559502666, \"f0_5\": 0.793964433267469, \"p4\": 0.63499541952982, \"phi\": 0.4663012798895679}, {\"truth_threshold\": 5.0725916171858545, \"match_probability\": 0.9711410787932916, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 883.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1148.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4347611963748932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5652387738227844, \"precision\": 1.0, \"recall\": 0.4347611963748932, \"specificity\": 1.0, \"npv\": 0.4993458390235901, \"accuracy\": 0.6385390162467957, \"f1\": 0.6060398078242965, \"f2\": 0.4901743088708782, \"f0_5\": 0.793636527053748, \"p4\": 0.6346452857405602, \"phi\": 0.4659358273340107}, {\"truth_threshold\": 5.12373504365013, \"match_probability\": 0.9721181794997231, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 882.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1149.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4342688322067261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5657311677932739, \"precision\": 1.0, \"recall\": 0.4342688322067261, \"specificity\": 1.0, \"npv\": 0.49912816286087036, \"accuracy\": 0.638224184513092, \"f1\": 0.6055612770339855, \"f2\": 0.48967355096602266, \"f0_5\": 0.7933081489476524, \"p4\": 0.634294944416992, \"phi\": 0.4655704069051963}, {\"truth_threshold\": 5.156998595803227, \"match_probability\": 0.9727363571756616, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 880.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1151.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.43328410387039185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5667158961296082, \"precision\": 1.0, \"recall\": 0.43328410387039185, \"specificity\": 1.0, \"npv\": 0.4986933767795563, \"accuracy\": 0.63759446144104, \"f1\": 0.6046032291308828, \"f2\": 0.48867170146601513, \"f0_5\": 0.7926499729778418, \"p4\": 0.6335936363957917, \"phi\": 0.4648396610610332}, {\"truth_threshold\": 5.186272114450485, \"match_probability\": 0.9732693466886054, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 879.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1152.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.43279173970222473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5672082901000977, \"precision\": 1.0, \"recall\": 0.43279173970222473, \"specificity\": 1.0, \"npv\": 0.4984762668609619, \"accuracy\": 0.6372795701026917, \"f1\": 0.6041237113402061, \"f2\": 0.48817060979673443, \"f0_5\": 0.7923201730665225, \"p4\": 0.6332426683075715, \"phi\": 0.4644743349614181}, {\"truth_threshold\": 5.241841543560722, \"match_probability\": 0.974253370710768, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 878.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1153.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.43229934573173523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5677006244659424, \"precision\": 1.0, \"recall\": 0.43229934573173523, \"specificity\": 1.0, \"npv\": 0.49825936555862427, \"accuracy\": 0.636964738368988, \"f1\": 0.603643863870746, \"f2\": 0.48766940679848925, \"f0_5\": 0.7919898971675988, \"p4\": 0.6328914899038506, \"phi\": 0.46410903962000705}, {\"truth_threshold\": 5.245246021158528, \"match_probability\": 0.9743124972242545, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 877.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1154.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4318069815635681, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5681930184364319, \"precision\": 1.0, \"recall\": 0.4318069815635681, \"specificity\": 1.0, \"npv\": 0.49804261326789856, \"accuracy\": 0.6366498470306396, \"f1\": 0.6031636863823934, \"f2\": 0.48716809243417397, \"f0_5\": 0.7916591442498646, \"p4\": 0.6325401004842798, \"phi\": 0.46374377469376926}, {\"truth_threshold\": 5.248425303657472, \"match_probability\": 0.9743675933239726, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 876.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1155.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.431314617395401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5686853528022766, \"precision\": 1.0, \"recall\": 0.431314617395401, \"specificity\": 1.0, \"npv\": 0.49782609939575195, \"accuracy\": 0.636335015296936, \"f1\": 0.6026831785345718, \"f2\": 0.4866666666666667, \"f0_5\": 0.7913279132791328, \"p4\": 0.6321884993464733, \"phi\": 0.46337853983930954}, {\"truth_threshold\": 5.274770897980649, \"match_probability\": 0.9748197487973456, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 875.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1156.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4308222532272339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5691777467727661, \"precision\": 1.0, \"recall\": 0.4308222532272339, \"specificity\": 1.0, \"npv\": 0.4976097345352173, \"accuracy\": 0.6360201239585876, \"f1\": 0.6022023399862354, \"f2\": 0.4861651294588288, \"f0_5\": 0.7909962032182245, \"p4\": 0.631836685786, \"phi\": 0.463013334712866}, {\"truth_threshold\": 5.281671238520309, \"match_probability\": 0.9749368858668245, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 874.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1157.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4303298890590668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5696701407432556, \"precision\": 1.0, \"recall\": 0.4303298890590668, \"specificity\": 1.0, \"npv\": 0.49739357829093933, \"accuracy\": 0.635705292224884, \"f1\": 0.6017211703958691, \"f2\": 0.48566348077350524, \"f0_5\": 0.7906640130269585, \"p4\": 0.6314846590963767, \"phi\": 0.46264815897030703}, {\"truth_threshold\": 5.28213631810376, \"match_probability\": 0.9749447617230292, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 873.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1158.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42983752489089966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5701624751091003, \"precision\": 1.0, \"recall\": 0.42983752489089966, \"specificity\": 1.0, \"npv\": 0.4971776008605957, \"accuracy\": 0.6353904008865356, \"f1\": 0.6012396694214877, \"f2\": 0.4851617205735245, \"f0_5\": 0.7903313416621401, \"p4\": 0.6311324185690581, \"phi\": 0.46228301226712853}, {\"truth_threshold\": 5.318125631068763, \"match_probability\": 0.9755469607702548, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 872.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1159.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42934516072273254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5706548690795898, \"precision\": 1.0, \"recall\": 0.42934516072273254, \"specificity\": 1.0, \"npv\": 0.4969618022441864, \"accuracy\": 0.635075569152832, \"f1\": 0.6007578367206339, \"f2\": 0.48465984882169855, \"f0_5\": 0.7899981880775503, \"p4\": 0.6307799634934296, \"phi\": 0.4619178942584512}, {\"truth_threshold\": 5.318285499337574, \"match_probability\": 0.9755496040667028, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 871.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1160.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42885279655456543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5711472034454346, \"precision\": 1.0, \"recall\": 0.42885279655456543, \"specificity\": 1.0, \"npv\": 0.4967462122440338, \"accuracy\": 0.6347606778144836, \"f1\": 0.600275671950379, \"f2\": 0.4841578654808227, \"f0_5\": 0.7896645512239348, \"p4\": 0.6304272931567985, \"phi\": 0.46155280459901765}, {\"truth_threshold\": 5.333739382423115, \"match_probability\": 0.9758038110779913, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 870.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1161.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4283604025840759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5716395974159241, \"precision\": 1.0, \"recall\": 0.4283604025840759, \"specificity\": 1.0, \"npv\": 0.49653080105781555, \"accuracy\": 0.63444584608078, \"f1\": 0.5997931747673216, \"f2\": 0.4836557705136758, \"f0_5\": 0.789330430048993, \"p4\": 0.6300744068443861, \"phi\": 0.4611877429431893}, {\"truth_threshold\": 5.391078626860343, \"match_probability\": 0.9767246734348792, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 869.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1162.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4278680384159088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5721319317817688, \"precision\": 1.0, \"recall\": 0.4278680384159088, \"specificity\": 1.0, \"npv\": 0.4963155686855316, \"accuracy\": 0.6341309547424316, \"f1\": 0.5993103448275862, \"f2\": 0.4831535638830201, \"f0_5\": 0.788995823497367, \"p4\": 0.6297213038393187, \"phi\": 0.46082270894494415}, {\"truth_threshold\": 5.42024821994471, \"match_probability\": 0.9771799162324788, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 867.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1164.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4268833100795746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5731167197227478, \"precision\": 1.0, \"recall\": 0.4268833100795746, \"specificity\": 1.0, \"npv\": 0.4958856701850891, \"accuracy\": 0.6335012316703796, \"f1\": 0.598343685300207, \"f2\": 0.48214881548214883, \"f0_5\": 0.7883251500272777, \"p4\": 0.629014444873201, \"phi\": 0.4600927225351777}, {\"truth_threshold\": 5.422873386423075, \"match_probability\": 0.9772204574725164, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 866.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1165.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42639094591140747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5736090540885925, \"precision\": 1.0, \"recall\": 0.42639094591140747, \"specificity\": 1.0, \"npv\": 0.49567100405693054, \"accuracy\": 0.633186399936676, \"f1\": 0.597859855022437, \"f2\": 0.48164627363737483, \"f0_5\": 0.7879890809827116, \"p4\": 0.628660687467854, \"phi\": 0.45972776942966703}, {\"truth_threshold\": 5.446037934666577, \"match_probability\": 0.9775751585472915, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 865.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1166.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42589858174324036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.574101448059082, \"precision\": 1.0, \"recall\": 0.42589858174324036, \"specificity\": 1.0, \"npv\": 0.4954565167427063, \"accuracy\": 0.6328715085983276, \"f1\": 0.5973756906077348, \"f2\": 0.4811436199799755, \"f0_5\": 0.7876525223092333, \"p4\": 0.6283067104812413, \"phi\": 0.4593628425937549}, {\"truth_threshold\": 5.446157336102909, \"match_probability\": 0.9775769727983488, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 864.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1167.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42540621757507324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5745937824249268, \"precision\": 1.0, \"recall\": 0.42540621757507324, \"specificity\": 1.0, \"npv\": 0.4952422082424164, \"accuracy\": 0.632556676864624, \"f1\": 0.5968911917098445, \"f2\": 0.48064085447263016, \"f0_5\": 0.7873154729360307, \"p4\": 0.6279525131858887, \"phi\": 0.45899794167945684}, {\"truth_threshold\": 5.4787730751278145, \"match_probability\": 0.9780672206769047, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 863.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1168.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42491382360458374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5750861763954163, \"precision\": 1.0, \"recall\": 0.42491382360458374, \"specificity\": 1.0, \"npv\": 0.4950281083583832, \"accuracy\": 0.6322417855262756, \"f1\": 0.5964063579820318, \"f2\": 0.48013797707800154, \"f0_5\": 0.7869779317891665, \"p4\": 0.6275980948521758, \"phi\": 0.458633066338387}, {\"truth_threshold\": 5.496692175721564, \"match_probability\": 0.9783320873603596, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 860.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1171.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4234367311000824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.57656329870224, \"precision\": 1.0, \"recall\": 0.4234367311000824, \"specificity\": 1.0, \"npv\": 0.4943868815898895, \"accuracy\": 0.63129723072052, \"f1\": 0.5949498443445175, \"f2\": 0.4786286731967943, \"f0_5\": 0.7859623469201243, \"p4\": 0.626533506292297, \"phi\": 0.4575385902646104}, {\"truth_threshold\": 5.5139818754631245, \"match_probability\": 0.9785846846245907, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 857.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1174.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.42195963859558105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.578040361404419, \"precision\": 1.0, \"recall\": 0.42195963859558105, \"specificity\": 1.0, \"npv\": 0.4937472939491272, \"accuracy\": 0.6303526163101196, \"f1\": 0.5934903047091413, \"f2\": 0.4771183609843002, \"f0_5\": 0.7849422971240154, \"p4\": 0.6254669019129911, \"phi\": 0.45644433176886934}, {\"truth_threshold\": 5.526927871612408, \"match_probability\": 0.9787719337539391, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 854.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1177.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4204825162887573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5795174837112427, \"precision\": 1.0, \"recall\": 0.4204825162887573, \"specificity\": 1.0, \"npv\": 0.4931093752384186, \"accuracy\": 0.629408061504364, \"f1\": 0.5920277296360485, \"f2\": 0.4756070394297171, \"f0_5\": 0.7839177528914999, \"p4\": 0.6243982616616511, \"phi\": 0.45535028137799755}, {\"truth_threshold\": 5.528486935284297, \"match_probability\": 0.9787943754962429, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 853.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1178.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4199901521205902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5800098180770874, \"precision\": 1.0, \"recall\": 0.4199901521205902, \"specificity\": 1.0, \"npv\": 0.4928971230983734, \"accuracy\": 0.6290931701660156, \"f1\": 0.5915395284327323, \"f2\": 0.47510304110504625, \"f0_5\": 0.7835752342458203, \"p4\": 0.6240415923368279, \"phi\": 0.45498564251761797}, {\"truth_threshold\": 5.531000283860405, \"match_probability\": 0.9788305047096785, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 850.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1181.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.41851305961608887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5814869403839111, \"precision\": 1.0, \"recall\": 0.41851305961608887, \"specificity\": 1.0, \"npv\": 0.4922613799571991, \"accuracy\": 0.62814861536026, \"f1\": 0.5900728913571677, \"f2\": 0.473590372186316, \"f0_5\": 0.7825446510771497, \"p4\": 0.6229702060858412, \"phi\": 0.45389185480425387}, {\"truth_threshold\": 5.5344133443376675, \"match_probability\": 0.9788794708140333, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 847.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1184.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.41703593730926514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5829640626907349, \"precision\": 1.0, \"recall\": 0.41703593730926514, \"specificity\": 1.0, \"npv\": 0.4916273057460785, \"accuracy\": 0.6272040009498596, \"f1\": 0.5886031966643502, \"f2\": 0.4720766915616988, \"f0_5\": 0.78150950359845, \"p4\": 0.621896736471326, \"phi\": 0.4527982529565263}, {\"truth_threshold\": 5.552720496179793, \"match_probability\": 0.9791402322409615, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 846.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1185.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.416543573141098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5834563970565796, \"precision\": 1.0, \"recall\": 0.416543573141098, \"specificity\": 1.0, \"npv\": 0.4914163053035736, \"accuracy\": 0.626889169216156, \"f1\": 0.5881126173096975, \"f2\": 0.47157190635451507, \"f0_5\": 0.7811634349030471, \"p4\": 0.6215384467313602, \"phi\": 0.4524337586541401}, {\"truth_threshold\": 5.5625799575417565, \"match_probability\": 0.9792793592883601, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 844.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1187.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4155588448047638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5844411849975586, \"precision\": 1.0, \"recall\": 0.4155588448047638, \"specificity\": 1.0, \"npv\": 0.4909948408603668, \"accuracy\": 0.626259446144104, \"f1\": 0.5871304347826087, \"f2\": 0.4705619982158787, \"f0_5\": 0.7804697614203809, \"p4\": 0.620821162833538, \"phi\": 0.45170482738359996}, {\"truth_threshold\": 5.578491870863031, \"match_probability\": 0.9795019789831987, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 843.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1188.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4150664806365967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5849335193634033, \"precision\": 1.0, \"recall\": 0.4150664806365967, \"specificity\": 1.0, \"npv\": 0.4907844066619873, \"accuracy\": 0.6259445548057556, \"f1\": 0.5866388308977035, \"f2\": 0.47005687520910006, \"f0_5\": 0.7801221543586896, \"p4\": 0.620462167129168, \"phi\": 0.45134038970182133}, {\"truth_threshold\": 5.586775002985892, \"match_probability\": 0.9796169377590003, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 842.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1189.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4145740866661072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5854259133338928, \"precision\": 1.0, \"recall\": 0.4145740866661072, \"specificity\": 1.0, \"npv\": 0.4905741214752197, \"accuracy\": 0.625629723072052, \"f1\": 0.5861468847894187, \"f2\": 0.4695516395271024, \"f0_5\": 0.7797740322281904, \"p4\": 0.6201029345529268, \"phi\": 0.45097597017918}, {\"truth_threshold\": 5.586894404422225, \"match_probability\": 0.9796185902666911, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 834.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1197.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4106351435184479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5893648266792297, \"precision\": 1.0, \"recall\": 0.4106351435184479, \"specificity\": 1.0, \"npv\": 0.488898366689682, \"accuracy\": 0.623110830783844, \"f1\": 0.5821989528795811, \"f2\": 0.4655056932350971, \"f0_5\": 0.7769703745108999, \"p4\": 0.6172204525656357, \"phi\": 0.44806122466967707}, {\"truth_threshold\": 5.637563443937288, \"match_probability\": 0.9803081324320962, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 833.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1198.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.41014277935028076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5898572206497192, \"precision\": 1.0, \"recall\": 0.41014277935028076, \"specificity\": 1.0, \"npv\": 0.48868972063064575, \"accuracy\": 0.6227959990501404, \"f1\": 0.5817039106145251, \"f2\": 0.46499944177738084, \"f0_5\": 0.7766175647958232, \"p4\": 0.6168590527979635, \"phi\": 0.44769695241292806}, {\"truth_threshold\": 5.638034574945436, \"match_probability\": 0.9803144354500439, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 832.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1199.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.40965041518211365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.590349555015564, \"precision\": 1.0, \"recall\": 0.40965041518211365, \"specificity\": 1.0, \"npv\": 0.48848122358322144, \"accuracy\": 0.622481107711792, \"f1\": 0.5812085225288159, \"f2\": 0.4644930772666369, \"f0_5\": 0.7762642284008211, \"p4\": 0.6164974082601424, \"phi\": 0.44733269471390064}, {\"truth_threshold\": 5.642425422973468, \"match_probability\": 0.9803730833410346, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 831.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1200.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.40915805101394653, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5908419489860535, \"precision\": 1.0, \"recall\": 0.40915805101394653, \"specificity\": 1.0, \"npv\": 0.48827293515205383, \"accuracy\": 0.6221662759780884, \"f1\": 0.5807127882599581, \"f2\": 0.4639865996649916, \"f0_5\": 0.7759103641456583, \"p4\": 0.6161355181490583, \"phi\": 0.44696845120974843}, {\"truth_threshold\": 5.65074245294013, \"match_probability\": 0.9804837036708776, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 830.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1201.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4086656868457794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.591334342956543, \"precision\": 1.0, \"recall\": 0.4086656868457794, \"specificity\": 1.0, \"npv\": 0.48806479573249817, \"accuracy\": 0.62185138463974, \"f1\": 0.5802167074449494, \"f2\": 0.4634800089345544, \"f0_5\": 0.7755559708465707, \"p4\": 0.6157733816591411, \"phi\": 0.4466042215371196}, {\"truth_threshold\": 5.663462802936316, \"match_probability\": 0.9806517091782724, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 829.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1202.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4081733226776123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5918266773223877, \"precision\": 1.0, \"recall\": 0.4081733226776123, \"specificity\": 1.0, \"npv\": 0.48785683512687683, \"accuracy\": 0.6215365529060364, \"f1\": 0.5797202797202797, \"f2\": 0.4629733050374176, \"f0_5\": 0.7752010473162521, \"p4\": 0.6154109979823547, \"phi\": 0.44624000533215374}, {\"truth_threshold\": 5.668193506402978, \"match_probability\": 0.9807138281481892, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 828.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1203.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4076809585094452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5923190712928772, \"precision\": 1.0, \"recall\": 0.4076809585094452, \"specificity\": 1.0, \"npv\": 0.4876490533351898, \"accuracy\": 0.621221661567688, \"f1\": 0.5792235047219307, \"f2\": 0.4624664879356568, \"f0_5\": 0.7748455923638405, \"p4\": 0.6150483663081868, \"phi\": 0.4458758022304786}, {\"truth_threshold\": 5.692388551847114, \"match_probability\": 0.9810284891545363, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 827.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1204.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4071885645389557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5928114056587219, \"precision\": 1.0, \"recall\": 0.4071885645389557, \"specificity\": 1.0, \"npv\": 0.48744145035743713, \"accuracy\": 0.6209068298339844, \"f1\": 0.5787263820853744, \"f2\": 0.46195955759133056, \"f0_5\": 0.7744896047949054, \"p4\": 0.6146854858236389, \"phi\": 0.4455116118672065}, {\"truth_threshold\": 5.692507953283447, \"match_probability\": 0.9810300294401546, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 825.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1206.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.40620383620262146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5937961339950562, \"precision\": 1.0, \"recall\": 0.40620383620262146, \"specificity\": 1.0, \"npv\": 0.48702681064605713, \"accuracy\": 0.6202771067619324, \"f1\": 0.5777310924369747, \"f2\": 0.46094535702313105, \"f0_5\": 0.7737760270118177, \"p4\": 0.6139589751589127, \"phi\": 0.44478326789372186}, {\"truth_threshold\": 5.709406960244394, \"match_probability\": 0.981246795100395, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 820.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1211.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4037419855594635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5962579846382141, \"precision\": 1.0, \"recall\": 0.4037419855594635, \"specificity\": 1.0, \"npv\": 0.4859932065010071, \"accuracy\": 0.61870276927948, \"f1\": 0.5752367590319186, \"f2\": 0.45840787119856885, \"f0_5\": 0.7719826774618715, \"p4\": 0.6121382869223002, \"phi\": 0.44296260523916714}, {\"truth_threshold\": 5.745365574122189, \"match_probability\": 0.9816999864567789, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 819.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1212.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4032496213912964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5967503786087036, \"precision\": 1.0, \"recall\": 0.4032496213912964, \"specificity\": 1.0, \"npv\": 0.4857870042324066, \"accuracy\": 0.6183879375457764, \"f1\": 0.5747368421052632, \"f2\": 0.45790003354579, \"f0_5\": 0.7716223855285472, \"p4\": 0.6117733863849425, \"phi\": 0.44259850358416075}, {\"truth_threshold\": 5.748416872305343, \"match_probability\": 0.9817379439841741, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 817.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1214.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.40226489305496216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5977351069450378, \"precision\": 1.0, \"recall\": 0.40226489305496216, \"specificity\": 1.0, \"npv\": 0.48537516593933105, \"accuracy\": 0.6177582144737244, \"f1\": 0.5737359550561798, \"f2\": 0.4568840174477128, \"f0_5\": 0.7709001698433666, \"p4\": 0.611042815748838, \"phi\": 0.4418703281958464}, {\"truth_threshold\": 5.774494629186621, \"match_probability\": 0.9820592093104373, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 814.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1217.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4007878005504608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5992122292518616, \"precision\": 1.0, \"recall\": 0.4007878005504608, \"specificity\": 1.0, \"npv\": 0.4847586750984192, \"accuracy\": 0.616813600063324, \"f1\": 0.572231985940246, \"f2\": 0.45535914074737077, \"f0_5\": 0.7698127482504256, \"p4\": 0.6099450232754924, \"phi\": 0.4407781293557703}, {\"truth_threshold\": 5.777350901040942, \"match_probability\": 0.9820940582705666, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 813.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1218.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.4002954065799713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5997045636177063, \"precision\": 1.0, \"recall\": 0.4002954065799713, \"specificity\": 1.0, \"npv\": 0.4845535457134247, \"accuracy\": 0.6164987683296204, \"f1\": 0.5717299578059072, \"f2\": 0.454850621013763, \"f0_5\": 0.7694491766042022, \"p4\": 0.6095785726634082, \"phi\": 0.44041407871997507}, {\"truth_threshold\": 5.780763961518205, \"match_probability\": 0.9821356133824078, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 812.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1219.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3998030424118042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6001969575881958, \"precision\": 1.0, \"recall\": 0.3998030424118042, \"specificity\": 1.0, \"npv\": 0.4843485653400421, \"accuracy\": 0.616183876991272, \"f1\": 0.5712275765036933, \"f2\": 0.45434198746642795, \"f0_5\": 0.7690850539874976, \"p4\": 0.6092118607404354, \"phi\": 0.4400500352850316}, {\"truth_threshold\": 5.782590780547775, \"match_probability\": 0.9821578165757004, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 811.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1220.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3993106782436371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6006892919540405, \"precision\": 1.0, \"recall\": 0.3993106782436371, \"specificity\": 1.0, \"npv\": 0.48414376378059387, \"accuracy\": 0.6158690452575684, \"f1\": 0.5707248416608023, \"f2\": 0.45383324006715164, \"f0_5\": 0.7687203791469195, \"p4\": 0.6088448866523514, \"phi\": 0.43968599867732555}, {\"truth_threshold\": 5.782742320068166, \"match_probability\": 0.982159657172454, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 810.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1221.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.39881831407546997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.60118168592453, \"precision\": 1.0, \"recall\": 0.39881831407546997, \"specificity\": 1.0, \"npv\": 0.48393914103507996, \"accuracy\": 0.61555415391922, \"f1\": 0.5702217529039071, \"f2\": 0.45332437877770315, \"f0_5\": 0.7683551508252704, \"p4\": 0.608477649542264, \"phi\": 0.439321968522666}, {\"truth_threshold\": 5.844062663840703, \"match_probability\": 0.9828893514276467, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 808.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1223.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.39783358573913574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6021664142608643, \"precision\": 1.0, \"recall\": 0.39783358573913574, \"specificity\": 1.0, \"npv\": 0.4835304021835327, \"accuracy\": 0.614924430847168, \"f1\": 0.5692145121521662, \"f2\": 0.4523063143752799, \"f0_5\": 0.7676230286908607, \"p4\": 0.6077423828150981, \"phi\": 0.43859392607281994}, {\"truth_threshold\": 5.852280778038701, \"match_probability\": 0.9829848890841376, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 807.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1224.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.39734122157096863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6026588082313538, \"precision\": 1.0, \"recall\": 0.39734122157096863, \"specificity\": 1.0, \"npv\": 0.4833262860774994, \"accuracy\": 0.6146095991134644, \"f1\": 0.5687103594080338, \"f2\": 0.4517971111857575, \"f0_5\": 0.7672561323445521, \"p4\": 0.6073743514707883, \"phi\": 0.43822991302633685}, {\"truth_threshold\": 5.888204329408997, \"match_probability\": 0.9833963914214449, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 806.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1225.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3968488574028015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6031511425971985, \"precision\": 1.0, \"recall\": 0.3968488574028015, \"specificity\": 1.0, \"npv\": 0.4831223487854004, \"accuracy\": 0.614294707775116, \"f1\": 0.5682058512513218, \"f2\": 0.45128779395296753, \"f0_5\": 0.7668886774500476, \"p4\": 0.60700605364999, \"phi\": 0.4378659049302997}, {\"truth_threshold\": 5.888389574399743, \"match_probability\": 0.9833984878307315, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 805.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1226.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.396356463432312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.603643536567688, \"precision\": 1.0, \"recall\": 0.396356463432312, \"specificity\": 1.0, \"npv\": 0.4829185903072357, \"accuracy\": 0.6139798760414124, \"f1\": 0.5677009873060649, \"f2\": 0.45077836263859333, \"f0_5\": 0.7665206627309084, \"p4\": 0.6066374884822956, \"phi\": 0.43750190140758005}, {\"truth_threshold\": 5.905675047114952, \"match_probability\": 0.9835929659111178, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 804.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1227.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3958640992641449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6041358709335327, \"precision\": 1.0, \"recall\": 0.3958640992641449, \"specificity\": 1.0, \"npv\": 0.48271501064300537, \"accuracy\": 0.613664984703064, \"f1\": 0.5671957671957671, \"f2\": 0.45026881720430106, \"f0_5\": 0.7661520869068039, \"p4\": 0.6062686550945603, \"phi\": 0.4371379020804506}, {\"truth_threshold\": 5.905679274141304, \"match_probability\": 0.9835930131941474, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 803.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1228.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3953717350959778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6046282649040222, \"precision\": 1.0, \"recall\": 0.3953717350959778, \"specificity\": 1.0, \"npv\": 0.48251157999038696, \"accuracy\": 0.6133501529693604, \"f1\": 0.5666901905434015, \"f2\": 0.4497591576117397, \"f0_5\": 0.7657829486934961, \"p4\": 0.6058995526108901, \"phi\": 0.436773906570581}, {\"truth_threshold\": 5.906652477656537, \"match_probability\": 0.9836038957705666, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 801.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1230.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.39438700675964355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6056129932403564, \"precision\": 1.0, \"recall\": 0.39438700675964355, \"specificity\": 1.0, \"npv\": 0.4821052551269531, \"accuracy\": 0.6127204298973083, \"f1\": 0.565677966101695, \"f2\": 0.44873949579831934, \"f0_5\": 0.7650429799426934, \"p4\": 0.6051605368383547, \"phi\": 0.43604592548626425}, {\"truth_threshold\": 5.9410619502477395, \"match_probability\": 0.9839841406711266, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 798.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1233.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3929098844528198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6070901155471802, \"precision\": 1.0, \"recall\": 0.3929098844528198, \"specificity\": 1.0, \"npv\": 0.48149704933166504, \"accuracy\": 0.611775815486908, \"f1\": 0.5641569459172853, \"f2\": 0.44720914593140554, \"f0_5\": 0.7639287765651924, \"p4\": 0.6040499729033301, \"phi\": 0.4349539729958948}, {\"truth_threshold\": 5.955757577424931, \"match_probability\": 0.9841438801979803, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 797.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1234.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3924175202846527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6075824499130249, \"precision\": 1.0, \"recall\": 0.3924175202846527, \"specificity\": 1.0, \"npv\": 0.4812946617603302, \"accuracy\": 0.6114609837532043, \"f1\": 0.5636492220650636, \"f2\": 0.4466988005828943, \"f0_5\": 0.7635562368269784, \"p4\": 0.603679237294863, \"phi\": 0.434589992410407}, {\"truth_threshold\": 5.967757995458637, \"match_probability\": 0.9842731596212501, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 795.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1236.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3914327919483185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6085672378540039, \"precision\": 1.0, \"recall\": 0.3914327919483185, \"specificity\": 1.0, \"npv\": 0.4808903932571411, \"accuracy\": 0.6108312606811523, \"f1\": 0.5626326963906582, \"f2\": 0.44567776656575847, \"f0_5\": 0.7628094415659182, \"p4\": 0.6029369392641755, \"phi\": 0.4338620343113708}, {\"truth_threshold\": 5.981861111667398, \"match_probability\": 0.9844237659121775, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 794.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1237.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.39094042778015137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6090595722198486, \"precision\": 1.0, \"recall\": 0.39094042778015137, \"specificity\": 1.0, \"npv\": 0.4806884825229645, \"accuracy\": 0.610516369342804, \"f1\": 0.5621238938053097, \"f2\": 0.44516707782013903, \"f0_5\": 0.7624351834069522, \"p4\": 0.6025653750424809, \"phi\": 0.43349805603059816}, {\"truth_threshold\": 5.994882782006658, \"match_probability\": 0.984561562675688, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 790.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1241.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3889709413051605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6110290288925171, \"precision\": 1.0, \"recall\": 0.3889709413051605, \"specificity\": 1.0, \"npv\": 0.4798826575279236, \"accuracy\": 0.6092569231987, \"f1\": 0.5600850762141085, \"f2\": 0.44312317702490467, \"f0_5\": 0.7609323829705259, \"p4\": 0.6010763289855445, \"phi\": 0.4320421390515126}, {\"truth_threshold\": 6.005217968930108, \"match_probability\": 0.9846700760338538, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 789.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1242.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3884785771369934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6115214228630066, \"precision\": 1.0, \"recall\": 0.3884785771369934, \"specificity\": 1.0, \"npv\": 0.4796816110610962, \"accuracy\": 0.6089420914649963, \"f1\": 0.5595744680851064, \"f2\": 0.44261191518007403, \"f0_5\": 0.7605552342394447, \"p4\": 0.6007033656224566, \"phi\": 0.4316781569117463}, {\"truth_threshold\": 6.008615198263674, \"match_probability\": 0.9847055807048699, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 788.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1243.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3879862129688263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6120137572288513, \"precision\": 1.0, \"recall\": 0.3879862129688263, \"specificity\": 1.0, \"npv\": 0.4794807434082031, \"accuracy\": 0.608627200126648, \"f1\": 0.5590634976942178, \"f2\": 0.44210053859964094, \"f0_5\": 0.7601775033764229, \"p4\": 0.6003301196870999, \"phi\": 0.431314172839281}, {\"truth_threshold\": 6.013987665283016, \"match_probability\": 0.9847615635433524, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 787.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1244.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3874938488006592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6125061511993408, \"precision\": 1.0, \"recall\": 0.3874938488006592, \"specificity\": 1.0, \"npv\": 0.479280024766922, \"accuracy\": 0.6083123683929443, \"f1\": 0.5585521646557843, \"f2\": 0.4415890472449781, \"f0_5\": 0.7597991890326318, \"p4\": 0.5999565902579751, \"phi\": 0.43095018644560334}, {\"truth_threshold\": 6.052600943216132, \"match_probability\": 0.9851580328109889, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 786.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1245.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.38700148463249207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6129985451698303, \"precision\": 1.0, \"recall\": 0.38700148463249207, \"specificity\": 1.0, \"npv\": 0.4790794849395752, \"accuracy\": 0.607997477054596, \"f1\": 0.5580404685835996, \"f2\": 0.44107744107744107, \"f0_5\": 0.7594202898550725, \"p4\": 0.599582776410628, \"phi\": 0.43058619734152903}, {\"truth_threshold\": 6.063911449769033, \"match_probability\": 0.9852722296117873, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 783.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1248.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.38552436232566833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6144756078720093, \"precision\": 1.0, \"recall\": 0.38552436232566833, \"specificity\": 1.0, \"npv\": 0.47847890853881836, \"accuracy\": 0.6070529222488403, \"f1\": 0.5565031982942431, \"f2\": 0.4395419333108791, \"f0_5\": 0.758280069726903, \"p4\": 0.5984596190701241, \"phi\": 0.429494209864926}, {\"truth_threshold\": 6.07850030221516, \"match_probability\": 0.9854182488934292, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 782.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1249.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3850319981575012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6149680018424988, \"precision\": 1.0, \"recall\": 0.3850319981575012, \"specificity\": 1.0, \"npv\": 0.4782790243625641, \"accuracy\": 0.6067380309104919, \"f1\": 0.5559900462140064, \"f2\": 0.4390298675050528, \"f0_5\": 0.7578988176003102, \"p4\": 0.5980846582458069, \"phi\": 0.42913020601385005}, {\"truth_threshold\": 6.083231005681822, \"match_probability\": 0.9854652913891205, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 781.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1250.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3845396339893341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6154603362083435, \"precision\": 1.0, \"recall\": 0.3845396339893341, \"specificity\": 1.0, \"npv\": 0.47807931900024414, \"accuracy\": 0.6064231991767883, \"f1\": 0.5554765291607396, \"f2\": 0.43851768669286917, \"f0_5\": 0.7575169738118331, \"p4\": 0.5977094083362298, \"phi\": 0.4287661974962401}, {\"truth_threshold\": 6.084085950525293, \"match_probability\": 0.985473777061976, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 780.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1251.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.384047269821167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.615952730178833, \"precision\": 1.0, \"recall\": 0.384047269821167, \"specificity\": 1.0, \"npv\": 0.4778797924518585, \"accuracy\": 0.6061083078384399, \"f1\": 0.5549626467449307, \"f2\": 0.4380053908355795, \"f0_5\": 0.7571345369831101, \"p4\": 0.5973338683989415, \"phi\": 0.4284021839187959}, {\"truth_threshold\": 6.085059154040526, \"match_probability\": 0.9854834305594722, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 773.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1258.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3806006908416748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6193993091583252, \"precision\": 1.0, \"recall\": 0.3806006908416748, \"specificity\": 1.0, \"npv\": 0.4764877259731293, \"accuracy\": 0.6039043068885803, \"f1\": 0.551355206847361, \"f2\": 0.4344160953130269, \"f0_5\": 0.7544407573687293, \"p4\": 0.5946968882534119, \"phi\": 0.4258539140157708}, {\"truth_threshold\": 6.102348853782087, \"match_probability\": 0.98565388235676, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 771.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1260.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3796159625053406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6203840374946594, \"precision\": 1.0, \"recall\": 0.3796159625053406, \"specificity\": 1.0, \"npv\": 0.4760914742946625, \"accuracy\": 0.6032745838165283, \"f1\": 0.550321199143469, \"f2\": 0.433389544688027, \"f0_5\": 0.7536656891495601, \"p4\": 0.5939408006943253, \"phi\": 0.42512576878419933}, {\"truth_threshold\": 6.11450202862556, \"match_probability\": 0.9857725133996632, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 769.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1262.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.37863120436668396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6213687658309937, \"precision\": 1.0, \"recall\": 0.37863120436668396, \"specificity\": 1.0, \"npv\": 0.4756958782672882, \"accuracy\": 0.6026448607444763, \"f1\": 0.5492857142857143, \"f2\": 0.43236253232879795, \"f0_5\": 0.7528881926767182, \"p4\": 0.593183514644577, \"phi\": 0.42439758742339123}, {\"truth_threshold\": 6.115530402180186, \"match_probability\": 0.9857825072047981, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 768.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1263.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.37813884019851685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6218611598014832, \"precision\": 1.0, \"recall\": 0.37813884019851685, \"specificity\": 1.0, \"npv\": 0.47549834847450256, \"accuracy\": 0.6023299694061279, \"f1\": 0.5487674169346195, \"f2\": 0.4318488529014845, \"f0_5\": 0.7524985302763081, \"p4\": 0.5928044197420131, \"phi\": 0.4240334821909139}, {\"truth_threshold\": 6.1225981799867135, \"match_probability\": 0.9858510054234091, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 766.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1265.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3771541118621826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6228458881378174, \"precision\": 1.0, \"recall\": 0.3771541118621826, \"specificity\": 1.0, \"npv\": 0.4751037359237671, \"accuracy\": 0.6017002463340759, \"f1\": 0.5477297104040043, \"f2\": 0.43082114735658045, \"f0_5\": 0.7517173699705594, \"p4\": 0.5920453212661131, \"phi\": 0.42330524060800423}, {\"truth_threshold\": 6.173778055789327, \"match_probability\": 0.9863374072610417, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 765.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1266.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3766617476940155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6233382821083069, \"precision\": 1.0, \"recall\": 0.3766617476940155, \"specificity\": 1.0, \"npv\": 0.47490668296813965, \"accuracy\": 0.6013854146003723, \"f1\": 0.5472103004291845, \"f2\": 0.43030712116098546, \"f0_5\": 0.7513258691809075, \"p4\": 0.591665315716949, \"phi\": 0.42294110344976693}, {\"truth_threshold\": 6.176411567354844, \"match_probability\": 0.9863619845410229, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 763.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1268.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3756770193576813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6243230104446411, \"precision\": 1.0, \"recall\": 0.3756770193576813, \"specificity\": 1.0, \"npv\": 0.47451305389404297, \"accuracy\": 0.6007556915283203, \"f1\": 0.5461703650680029, \"f2\": 0.4292787217283673, \"f0_5\": 0.7505410190832186, \"p4\": 0.5909043870322787, \"phi\": 0.42221279437445536}, {\"truth_threshold\": 6.199330920911146, \"match_probability\": 0.9865740468816856, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 762.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1269.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3751846253871918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6248153448104858, \"precision\": 1.0, \"recall\": 0.3751846253871918, \"specificity\": 1.0, \"npv\": 0.47431647777557373, \"accuracy\": 0.6004408001899719, \"f1\": 0.5456498388829216, \"f2\": 0.4287643484132343, \"f0_5\": 0.7501476668635558, \"p4\": 0.5905234619014093, \"phi\": 0.42184862164494835}, {\"truth_threshold\": 6.199450467885993, \"match_probability\": 0.9865751444242058, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 761.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1270.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.37469226121902466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6253077387809753, \"precision\": 1.0, \"recall\": 0.37469226121902466, \"specificity\": 1.0, \"npv\": 0.4741200804710388, \"accuracy\": 0.6001259684562683, \"f1\": 0.5451289398280802, \"f2\": 0.4282498593134496, \"f0_5\": 0.7497536945812808, \"p4\": 0.5901422282424653, \"phi\": 0.4214844362446167}, {\"truth_threshold\": 6.206647263245688, \"match_probability\": 0.9866410543229265, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 760.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1271.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.37419989705085754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6258000731468201, \"precision\": 1.0, \"recall\": 0.37419989705085754, \"specificity\": 1.0, \"npv\": 0.47392383217811584, \"accuracy\": 0.5998110771179199, \"f1\": 0.5446076675026872, \"f2\": 0.42773525438991444, \"f0_5\": 0.7493591007690791, \"p4\": 0.5897606850495294, \"phi\": 0.4211202377652835}, {\"truth_threshold\": 6.244434591643142, \"match_probability\": 0.9869819157692996, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 759.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1272.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.37370753288269043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6262924671173096, \"precision\": 1.0, \"recall\": 0.37370753288269043, \"specificity\": 1.0, \"npv\": 0.4737277626991272, \"accuracy\": 0.5994962453842163, \"f1\": 0.5440860215053763, \"f2\": 0.4272205336035123, \"f0_5\": 0.7489638839550029, \"p4\": 0.5893788313133635, \"phi\": 0.42075602579797955}, {\"truth_threshold\": 6.247081423067555, \"match_probability\": 0.987005467349517, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 758.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1273.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3732151687145233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6267848610877991, \"precision\": 1.0, \"recall\": 0.3732151687145233, \"specificity\": 1.0, \"npv\": 0.4735318422317505, \"accuracy\": 0.5991813540458679, \"f1\": 0.5435640014342058, \"f2\": 0.42670569691510923, \"f0_5\": 0.7485680426624531, \"p4\": 0.5889966660213951, \"phi\": 0.42039179993293757}, {\"truth_threshold\": 6.2807555301660765, \"match_probability\": 0.9873014548641021, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 757.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1274.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3727228045463562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6272771954536438, \"precision\": 1.0, \"recall\": 0.3727228045463562, \"specificity\": 1.0, \"npv\": 0.4733361005783081, \"accuracy\": 0.5988665223121643, \"f1\": 0.5430416068866571, \"f2\": 0.4261907442855534, \"f0_5\": 0.7481715754101601, \"p4\": 0.5886141881577017, \"phi\": 0.420027559759588}, {\"truth_threshold\": 6.282751944459016, \"match_probability\": 0.9873187923869406, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 741.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1290.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3648449182510376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6351550817489624, \"precision\": 1.0, \"recall\": 0.3648449182510376, \"specificity\": 1.0, \"npv\": 0.47022587060928345, \"accuracy\": 0.5938287377357483, \"f1\": 0.5346320346320347, \"f2\": 0.4179357021996616, \"f0_5\": 0.7417417417417418, \"p4\": 0.5824511903781201, \"phi\": 0.4141974328437107}, {\"truth_threshold\": 6.311987839659076, \"match_probability\": 0.9875700257781701, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 740.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1291.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3643525242805481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6356474757194519, \"precision\": 1.0, \"recall\": 0.3643525242805481, \"specificity\": 1.0, \"npv\": 0.47003284096717834, \"accuracy\": 0.5935138463973999, \"f1\": 0.534103211836882, \"f2\": 0.4174187725631769, \"f0_5\": 0.7413344019234622, \"p4\": 0.5820632400409773, \"phi\": 0.41383288581016014}, {\"truth_threshold\": 6.335423749396503, \"match_probability\": 0.9877678637802646, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 738.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1293.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.36336779594421387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6366322040557861, \"precision\": 1.0, \"recall\": 0.36336779594421387, \"specificity\": 1.0, \"npv\": 0.46964725852012634, \"accuracy\": 0.5928841233253479, \"f1\": 0.5330444203683641, \"f2\": 0.4163845633039946, \"f0_5\": 0.74051776038531, \"p4\": 0.5812863439396199, \"phi\": 0.41310372579173665}, {\"truth_threshold\": 6.3442547782100185, \"match_probability\": 0.987841602884887, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 737.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1294.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.36287543177604675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6371245980262756, \"precision\": 1.0, \"recall\": 0.36287543177604675, \"specificity\": 1.0, \"npv\": 0.46945470571517944, \"accuracy\": 0.5925692915916443, \"f1\": 0.5325144508670521, \"f2\": 0.41586728360230224, \"f0_5\": 0.7401084555131553, \"p4\": 0.5808973960068617, \"phi\": 0.41273911195239665}, {\"truth_threshold\": 6.354818243738833, \"match_probability\": 0.9879292313188806, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 734.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1297.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3613983392715454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6386016607284546, \"precision\": 1.0, \"recall\": 0.3613983392715454, \"specificity\": 1.0, \"npv\": 0.46887797117233276, \"accuracy\": 0.5916246771812439, \"f1\": 0.5309222423146474, \"f2\": 0.4143147437344773, \"f0_5\": 0.7388765854640628, \"p4\": 0.5797285395918419, \"phi\": 0.4116451299679213}, {\"truth_threshold\": 6.372107943480393, \"match_probability\": 0.9880713124381604, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 733.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1298.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3609059453010559, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6390940546989441, \"precision\": 1.0, \"recall\": 0.3609059453010559, \"specificity\": 1.0, \"npv\": 0.468686044216156, \"accuracy\": 0.5913098454475403, \"f1\": 0.5303907380607815, \"f2\": 0.41379699672575365, \"f0_5\": 0.7384646383235945, \"p4\": 0.5793382462573238, \"phi\": 0.41128042104948137}, {\"truth_threshold\": 6.379931780455624, \"match_probability\": 0.9881350619926674, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 732.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1299.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3604135811328888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6395863890647888, \"precision\": 1.0, \"recall\": 0.3604135811328888, \"specificity\": 1.0, \"npv\": 0.4684942662715912, \"accuracy\": 0.5909949541091919, \"f1\": 0.5298588490770901, \"f2\": 0.4132791327913279, \"f0_5\": 0.7380520266182699, \"p4\": 0.5789476138201, \"phi\": 0.41091568728284633}, {\"truth_threshold\": 6.385171659962457, \"match_probability\": 0.9881775688291579, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 730.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1301.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.35942885279655457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6405711770057678, \"precision\": 1.0, \"recall\": 0.35942885279655457, \"specificity\": 1.0, \"npv\": 0.46811118721961975, \"accuracy\": 0.5903652310371399, \"f1\": 0.5287939152480985, \"f2\": 0.4122430539868986, \"f0_5\": 0.7372248030700869, \"p4\": 0.5781653272001764, \"phi\": 0.4101861434710932}, {\"truth_threshold\": 6.386613003301567, \"match_probability\": 0.9881892348539081, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 729.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1302.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.35893648862838745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6410635113716125, \"precision\": 1.0, \"recall\": 0.35893648862838745, \"specificity\": 1.0, \"npv\": 0.4679199159145355, \"accuracy\": 0.5900503993034363, \"f1\": 0.5282608695652173, \"f2\": 0.41172483903761437, \"f0_5\": 0.7368101879927229, \"p4\": 0.5777736707893447, \"phi\": 0.40982133255665837}, {\"truth_threshold\": 6.42276218453538, \"match_probability\": 0.9884781294324336, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 727.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1304.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3579517602920532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6420482397079468, \"precision\": 1.0, \"recall\": 0.3579517602920532, \"specificity\": 1.0, \"npv\": 0.4675377607345581, \"accuracy\": 0.5894206762313843, \"f1\": 0.5271936185641769, \"f2\": 0.41068805784657103, \"f0_5\": 0.7359789431058918, \"p4\": 0.5769893261670758, \"phi\": 0.40909163053021563}, {\"truth_threshold\": 6.426488777417981, \"match_probability\": 0.9885075113130479, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 724.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1307.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3564746379852295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6435253620147705, \"precision\": 1.0, \"recall\": 0.3564746379852295, \"specificity\": 1.0, \"npv\": 0.4669657349586487, \"accuracy\": 0.5884760618209839, \"f1\": 0.5255898366606171, \"f2\": 0.40913200723327303, \"f0_5\": 0.7347270144103917, \"p4\": 0.575810212820491, \"phi\": 0.40799687042628097}, {\"truth_threshold\": 6.452724907978391, \"match_probability\": 0.988712281304175, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 723.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1308.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3559822738170624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6440176963806152, \"precision\": 1.0, \"recall\": 0.3559822738170624, \"specificity\": 1.0, \"npv\": 0.46677538752555847, \"accuracy\": 0.5881612300872803, \"f1\": 0.5250544662309368, \"f2\": 0.40861308918277384, \"f0_5\": 0.7343083485679464, \"p4\": 0.5754164781246025, \"phi\": 0.40763189341557404}, {\"truth_threshold\": 6.467638442494976, \"match_probability\": 0.9888270675339752, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 722.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1309.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.35548990964889526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6445100903511047, \"precision\": 1.0, \"recall\": 0.35548990964889526, \"specificity\": 1.0, \"npv\": 0.4665851593017578, \"accuracy\": 0.5878463387489319, \"f1\": 0.5245187068652379, \"f2\": 0.4080940538096315, \"f0_5\": 0.7338890018296401, \"p4\": 0.5750223930701556, \"phi\": 0.40726688718107673}, {\"truth_threshold\": 6.490785208823679, \"match_probability\": 0.9890029413828526, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 720.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1311.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.35450518131256104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.645494818687439, \"precision\": 1.0, \"recall\": 0.35450518131256104, \"specificity\": 1.0, \"npv\": 0.4662052094936371, \"accuracy\": 0.5872166156768799, \"f1\": 0.5234460196292258, \"f2\": 0.40705563093622793, \"f0_5\": 0.7330482590103848, \"p4\": 0.5742331672939941, \"phi\": 0.406536785267915}, {\"truth_threshold\": 6.495555312058149, \"match_probability\": 0.9890388439376299, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 713.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1318.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.35105860233306885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6489413976669312, \"precision\": 1.0, \"recall\": 0.35105860233306885, \"specificity\": 1.0, \"npv\": 0.46488022804260254, \"accuracy\": 0.5850126147270203, \"f1\": 0.5196793002915452, \"f2\": 0.4034174493606428, \"f0_5\": 0.7300839647757527, \"p4\": 0.5714596708936607, \"phi\": 0.4039804425796222}, {\"truth_threshold\": 6.512845011799709, \"match_probability\": 0.9891680073692461, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 711.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1320.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.35007384419441223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6499261260032654, \"precision\": 1.0, \"recall\": 0.35007384419441223, \"specificity\": 1.0, \"npv\": 0.46450304985046387, \"accuracy\": 0.5843828916549683, \"f1\": 0.5185995623632386, \"f2\": 0.40237691001697795, \"f0_5\": 0.7292307692307692, \"p4\": 0.5706640029441143, \"phi\": 0.40324976242292176}, {\"truth_threshold\": 6.550514619864383, \"match_probability\": 0.9894442296675333, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 710.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1321.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3495814800262451, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6504185199737549, \"precision\": 1.0, \"recall\": 0.3495814800262451, \"specificity\": 1.0, \"npv\": 0.46431466937065125, \"accuracy\": 0.5840680003166199, \"f1\": 0.5180591025173295, \"f2\": 0.4018564636631198, \"f0_5\": 0.7288031205091356, \"p4\": 0.5702656229859941, \"phi\": 0.4028843706616135}, {\"truth_threshold\": 6.558338456839613, \"match_probability\": 0.989500720012648, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 707.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1324.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3481043875217438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6518956422805786, \"precision\": 1.0, \"recall\": 0.3481043875217438, \"specificity\": 1.0, \"npv\": 0.4637505114078522, \"accuracy\": 0.5831234455108643, \"f1\": 0.5164353542731921, \"f2\": 0.4002944173932737, \"f0_5\": 0.7275159497839061, \"p4\": 0.5690682848199015, \"phi\": 0.40178798317783665}, {\"truth_threshold\": 6.566647199546466, \"match_probability\": 0.9895603840446868, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 706.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1325.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.34761202335357666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6523879766464233, \"precision\": 1.0, \"recall\": 0.34761202335357666, \"specificity\": 1.0, \"npv\": 0.4635627567768097, \"accuracy\": 0.5828085541725159, \"f1\": 0.515893313847278, \"f2\": 0.39977349943374857, \"f0_5\": 0.7270854788877446, \"p4\": 0.5686684353211497, \"phi\": 0.4014224484247522}, {\"truth_threshold\": 6.5832497603256215, \"match_probability\": 0.9896786017988793, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 704.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1327.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.34662726521492004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6533727049827576, \"precision\": 1.0, \"recall\": 0.34662726521492004, \"specificity\": 1.0, \"npv\": 0.46318769454956055, \"accuracy\": 0.5821788311004639, \"f1\": 0.5148080438756856, \"f2\": 0.3987313094698686, \"f0_5\": 0.7262224056117186, \"p4\": 0.5678676238912578, \"phi\": 0.4006912677739821}, {\"truth_threshold\": 6.60116886091937, \"match_probability\": 0.989804707701605, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 702.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1329.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3456425368785858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6543574333190918, \"precision\": 1.0, \"recall\": 0.3456425368785858, \"specificity\": 1.0, \"npv\": 0.46281325817108154, \"accuracy\": 0.5815491080284119, \"f1\": 0.5137211855104281, \"f2\": 0.39768864717878993, \"f0_5\": 0.7253564786112833, \"p4\": 0.5670653210867429, \"phi\": 0.3999599358524826}, {\"truth_threshold\": 6.618391524405361, \"match_probability\": 0.9899244748833029, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 699.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1332.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3441654443740845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6558345556259155, \"precision\": 1.0, \"recall\": 0.3441654443740845, \"specificity\": 1.0, \"npv\": 0.46225273609161377, \"accuracy\": 0.5806045532226562, \"f1\": 0.512087912087912, \"f2\": 0.39612376742604555, \"f0_5\": 0.7240522063393412, \"p4\": 0.5658590490573081, \"phi\": 0.39886264621882994}, {\"truth_threshold\": 6.6184585606609305, \"match_probability\": 0.9899249383249664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 698.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1333.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.34367308020591736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.656326949596405, \"precision\": 1.0, \"recall\": 0.34367308020591736, \"specificity\": 1.0, \"npv\": 0.4620661735534668, \"accuracy\": 0.5802896618843079, \"f1\": 0.511542689629901, \"f2\": 0.3956019043300839, \"f0_5\": 0.7236160066348746, \"p4\": 0.5654562020136342, \"phi\": 0.39849680334245263}, {\"truth_threshold\": 6.632963620482103, \"match_probability\": 0.9900247215044495, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 693.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1338.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3412112295627594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.658788800239563, \"precision\": 1.0, \"recall\": 0.3412112295627594, \"specificity\": 1.0, \"npv\": 0.46113571524620056, \"accuracy\": 0.5787153840065002, \"f1\": 0.5088105726872246, \"f2\": 0.3929908132017693, \"f0_5\": 0.7214241099312929, \"p4\": 0.563436237836364, \"phi\": 0.3966669703506249}, {\"truth_threshold\": 6.646045118878965, \"match_probability\": 0.9901138723885253, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 691.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1340.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.34022650122642517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6597735285758972, \"precision\": 1.0, \"recall\": 0.34022650122642517, \"specificity\": 1.0, \"npv\": 0.4607645869255066, \"accuracy\": 0.5780856609344482, \"f1\": 0.5077149155033064, \"f2\": 0.39194554736245035, \"f0_5\": 0.7205422314911366, \"p4\": 0.5626255551091374, \"phi\": 0.39593473964784837}, {\"truth_threshold\": 6.652817886437953, \"match_probability\": 0.990159718667661, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 689.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1342.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33924174308776855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6607582569122314, \"precision\": 1.0, \"recall\": 0.33924174308776855, \"specificity\": 1.0, \"npv\": 0.4603940546512604, \"accuracy\": 0.5774559378623962, \"f1\": 0.5066176470588235, \"f2\": 0.3908998071031431, \"f0_5\": 0.7196574054731565, \"p4\": 0.5618133159380493, \"phi\": 0.39520233323509507}, {\"truth_threshold\": 6.685944772421295, \"match_probability\": 0.9903809462702999, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 688.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1343.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33874937891960144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6612505912780762, \"precision\": 1.0, \"recall\": 0.33874937891960144, \"specificity\": 1.0, \"npv\": 0.4602090120315552, \"accuracy\": 0.5771410465240479, \"f1\": 0.5060684075027584, \"f2\": 0.39037675896504764, \"f0_5\": 0.7192138825005226, \"p4\": 0.5614066094767297, \"phi\": 0.394836062941099}, {\"truth_threshold\": 6.688478023858172, \"match_probability\": 0.9903976596576374, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 687.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1344.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3382570147514343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6617429852485657, \"precision\": 1.0, \"recall\": 0.3382570147514343, \"specificity\": 1.0, \"npv\": 0.4600241184234619, \"accuracy\": 0.5768262147903442, \"f1\": 0.5055187637969095, \"f2\": 0.38985359210078313, \"f0_5\": 0.7187696170747018, \"p4\": 0.560999510044096, \"phi\": 0.39446974728151696}, {\"truth_threshold\": 6.77962709785479, \"match_probability\": 0.9909802627002239, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 686.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1345.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3377646505832672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6622353792190552, \"precision\": 1.0, \"recall\": 0.3377646505832672, \"specificity\": 1.0, \"npv\": 0.4598393440246582, \"accuracy\": 0.5765113234519958, \"f1\": 0.5049687154950313, \"f2\": 0.38933030646992056, \"f0_5\": 0.7183246073298429, \"p4\": 0.5605920163437905, \"phi\": 0.3941033857744324}, {\"truth_threshold\": 6.79686523704492, \"match_probability\": 0.9910864394072483, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 685.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1346.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3372722864151001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6627277135848999, \"precision\": 1.0, \"recall\": 0.3372722864151001, \"specificity\": 1.0, \"npv\": 0.4596547484397888, \"accuracy\": 0.5761964917182922, \"f1\": 0.5044182621502209, \"f2\": 0.38880690203201274, \"f0_5\": 0.7178788513938378, \"p4\": 0.5601841270748221, \"phi\": 0.3937369779366904}, {\"truth_threshold\": 6.822418102166739, \"match_probability\": 0.9912415549698486, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 681.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1350.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33530279994010925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6646971702575684, \"precision\": 1.0, \"recall\": 0.33530279994010925, \"specificity\": 1.0, \"npv\": 0.4589178264141083, \"accuracy\": 0.5749370455741882, \"f1\": 0.5022123893805309, \"f2\": 0.38671209540034074, \"f0_5\": 0.7160883280757098, \"p4\": 0.5585485881291099, \"phi\": 0.39227087357229073}, {\"truth_threshold\": 6.82968160538026, \"match_probability\": 0.9912851567678299, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 680.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1351.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33481043577194214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6651895642280579, \"precision\": 1.0, \"recall\": 0.33481043577194214, \"specificity\": 1.0, \"npv\": 0.4587339758872986, \"accuracy\": 0.5746221542358398, \"f1\": 0.5016599040944301, \"f2\": 0.3861880963198546, \"f0_5\": 0.7156388128814987, \"p4\": 0.5581387013382676, \"phi\": 0.3919042267900723}, {\"truth_threshold\": 6.875854734330666, \"match_probability\": 0.9915573397489872, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 679.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1352.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.334318071603775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6656819581985474, \"precision\": 1.0, \"recall\": 0.334318071603775, \"specificity\": 1.0, \"npv\": 0.45855027437210083, \"accuracy\": 0.5743073225021362, \"f1\": 0.5011070110701107, \"f2\": 0.3856639781892537, \"f0_5\": 0.7151885401306088, \"p4\": 0.5577284110742937, \"phi\": 0.39153753075184106}, {\"truth_threshold\": 6.885240646716011, \"match_probability\": 0.9916116286344927, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 677.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1354.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3333333432674408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6666666865348816, \"precision\": 1.0, \"recall\": 0.3333333432674408, \"specificity\": 1.0, \"npv\": 0.45818325877189636, \"accuracy\": 0.5736775994300842, \"f1\": 0.5, \"f2\": 0.38461538461538464, \"f0_5\": 0.7142857142857143, \"p4\": 0.5569066147859922, \"phi\": 0.39080398893790036}, {\"truth_threshold\": 6.910870445194621, \"match_probability\": 0.991758116653839, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 676.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1355.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3328409790992737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6671590209007263, \"precision\": 1.0, \"recall\": 0.3328409790992737, \"specificity\": 1.0, \"npv\": 0.4580000042915344, \"accuracy\": 0.5733627080917358, \"f1\": 0.4994458810491319, \"f2\": 0.3840909090909091, \"f0_5\": 0.7138331573389651, \"p4\": 0.5564951060791385, \"phi\": 0.3904371421742146}, {\"truth_threshold\": 6.9410619502477395, \"match_probability\": 0.9919274257285869, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 675.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1356.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3323485851287842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6676514148712158, \"precision\": 1.0, \"recall\": 0.3323485851287842, \"specificity\": 1.0, \"npv\": 0.45781686902046204, \"accuracy\": 0.5730478763580322, \"f1\": 0.49889135254988914, \"f2\": 0.38356631435390387, \"f0_5\": 0.7133798351299937, \"p4\": 0.5560831885340557, \"phi\": 0.3900702441785476}, {\"truth_threshold\": 7.011129162854343, \"match_probability\": 0.992307173293645, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 674.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1357.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33185622096061707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6681437492370605, \"precision\": 1.0, \"recall\": 0.33185622096061707, \"specificity\": 1.0, \"npv\": 0.4576338827610016, \"accuracy\": 0.5727329850196838, \"f1\": 0.4983364140480592, \"f2\": 0.38304160036371904, \"f0_5\": 0.712925745716099, \"p4\": 0.5556708607973319, \"phi\": 0.38970329445361884}, {\"truth_threshold\": 7.02599979897888, \"match_probability\": 0.9923854594585588, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 673.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1358.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33136385679244995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.66863614320755, \"precision\": 1.0, \"recall\": 0.33136385679244995, \"specificity\": 1.0, \"npv\": 0.4574510455131531, \"accuracy\": 0.5724181532859802, \"f1\": 0.4977810650887574, \"f2\": 0.38251676707968624, \"f0_5\": 0.7124708871479991, \"p4\": 0.5552581215106543, \"phi\": 0.3893362925008169}, {\"truth_threshold\": 7.0326969451124075, \"match_probability\": 0.9924204577639999, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 672.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1359.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.33087149262428284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6691285371780396, \"precision\": 1.0, \"recall\": 0.33087149262428284, \"specificity\": 1.0, \"npv\": 0.4572683572769165, \"accuracy\": 0.5721032619476318, \"f1\": 0.4972253052164262, \"f2\": 0.3819918144611187, \"f0_5\": 0.7120152574698029, \"p4\": 0.5548449693107866, \"phi\": 0.38896923782019077}, {\"truth_threshold\": 7.057502266639941, \"match_probability\": 0.9925487017184996, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 671.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1360.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3303791284561157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6696208715438843, \"precision\": 1.0, \"recall\": 0.3303791284561157, \"specificity\": 1.0, \"npv\": 0.45708581805229187, \"accuracy\": 0.5717884302139282, \"f1\": 0.4966691339748335, \"f2\": 0.381466742467311, \"f0_5\": 0.711558854718982, \"p4\": 0.5544314028295453, \"phi\": 0.3886021299104422}, {\"truth_threshold\": 7.100640885908955, \"match_probability\": 0.9927666201612914, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 670.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1361.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3298867642879486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6701132655143738, \"precision\": 1.0, \"recall\": 0.3298867642879486, \"specificity\": 1.0, \"npv\": 0.4569034278392792, \"accuracy\": 0.5714735388755798, \"f1\": 0.49611255090707146, \"f2\": 0.38094155105753924, \"f0_5\": 0.7111016769263426, \"p4\": 0.5540174206937766, \"phi\": 0.38823496826891707}, {\"truth_threshold\": 7.10687320351821, \"match_probability\": 0.9927975757664401, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 669.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1362.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3293944001197815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6706055998802185, \"precision\": 1.0, \"recall\": 0.3293944001197815, \"specificity\": 1.0, \"npv\": 0.4567211866378784, \"accuracy\": 0.5711587071418762, \"f1\": 0.4955555555555556, \"f2\": 0.3804162401910611, \"f0_5\": 0.7106437221159975, \"p4\": 0.5536030215253326, \"phi\": 0.3878677523915976}, {\"truth_threshold\": 7.153214900715398, \"match_probability\": 0.9930236646676727, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 668.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1363.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.328902006149292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.671097993850708, \"precision\": 1.0, \"recall\": 0.328902006149292, \"specificity\": 1.0, \"npv\": 0.4565390646457672, \"accuracy\": 0.5708438158035278, \"f1\": 0.494998147462023, \"f2\": 0.37989080982711554, \"f0_5\": 0.710184988305337, \"p4\": 0.5531882039410483, \"phi\": 0.3875004817730937}, {\"truth_threshold\": 7.1748171443147575, \"match_probability\": 0.9931266342361191, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 667.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1364.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3284096419811249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6715903282165527, \"precision\": 1.0, \"recall\": 0.3284096419811249, \"specificity\": 1.0, \"npv\": 0.45635712146759033, \"accuracy\": 0.5705289840698242, \"f1\": 0.49444032616753153, \"f2\": 0.3793652599249232, \"f0_5\": 0.709725473505001, \"p4\": 0.5527729665527172, \"phi\": 0.387133155906635}, {\"truth_threshold\": 7.189535839238332, \"match_probability\": 0.9931959266433391, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 666.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1365.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.32791727781295776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6720827221870422, \"precision\": 1.0, \"recall\": 0.32791727781295776, \"specificity\": 1.0, \"npv\": 0.456175297498703, \"accuracy\": 0.5702140927314758, \"f1\": 0.4938820912124583, \"f2\": 0.378839590443686, \"f0_5\": 0.7092651757188498, \"p4\": 0.5523573079670681, \"phi\": 0.386765774284062}, {\"truth_threshold\": 7.206825538979893, \"match_probability\": 0.9932764370967425, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 662.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1369.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3259478211402893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6740521788597107, \"precision\": 1.0, \"recall\": 0.3259478211402893, \"specificity\": 1.0, \"npv\": 0.45544949173927307, \"accuracy\": 0.5689546465873718, \"f1\": 0.4916450055699963, \"f2\": 0.37673571591167765, \"f0_5\": 0.707416114554392, \"p4\": 0.5506904336072352, \"phi\": 0.38529568002035525}, {\"truth_threshold\": 7.220738650457727, \"match_probability\": 0.993340536636019, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 658.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1373.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.32397833466529846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6760216355323792, \"precision\": 1.0, \"recall\": 0.32397833466529846, \"specificity\": 1.0, \"npv\": 0.454725980758667, \"accuracy\": 0.5676952004432678, \"f1\": 0.48940126441056153, \"f2\": 0.3746299248462765, \"f0_5\": 0.7055543641432555, \"p4\": 0.5490167072952341, \"phi\": 0.383824652639171}, {\"truth_threshold\": 7.246510025140965, \"match_probability\": 0.9934576694138745, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 657.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1374.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.32348597049713135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6765140295028687, \"precision\": 1.0, \"recall\": 0.32348597049713135, \"specificity\": 1.0, \"npv\": 0.4545454680919647, \"accuracy\": 0.5673803687095642, \"f1\": 0.4888392857142857, \"f2\": 0.37410317731465664, \"f0_5\": 0.7050869285254346, \"p4\": 0.5485971943887775, \"phi\": 0.38345674611100816}, {\"truth_threshold\": 7.247610271837525, \"match_probability\": 0.9934626243032131, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 656.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1375.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.32299360632896423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6770064234733582, \"precision\": 1.0, \"recall\": 0.32299360632896423, \"specificity\": 1.0, \"npv\": 0.454365074634552, \"accuracy\": 0.5670654773712158, \"f1\": 0.48827688872348346, \"f2\": 0.3735763097949886, \"f0_5\": 0.7046186895810956, \"p4\": 0.5481772460683598, \"phi\": 0.38308877866686303}, {\"truth_threshold\": 7.263254540154565, \"match_probability\": 0.9935326752076237, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 652.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1379.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3210241198539734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6789758801460266, \"precision\": 1.0, \"recall\": 0.3210241198539734, \"specificity\": 1.0, \"npv\": 0.4536450207233429, \"accuracy\": 0.5658060312271118, \"f1\": 0.48602310846067837, \"f2\": 0.3714676390154968, \"f0_5\": 0.702737658978228, \"p4\": 0.5464930695544453, \"phi\": 0.381616289227856}, {\"truth_threshold\": 7.2704682209850535, \"match_probability\": 0.9935647244601621, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 651.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1380.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3205317556858063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6794682145118713, \"precision\": 1.0, \"recall\": 0.3205317556858063, \"specificity\": 1.0, \"npv\": 0.4534653425216675, \"accuracy\": 0.5654911994934082, \"f1\": 0.4854586129753915, \"f2\": 0.37094017094017095, \"f0_5\": 0.7022653721682848, \"p4\": 0.5460709222975572, \"phi\": 0.3812480093136779}, {\"truth_threshold\": 7.279047562292945, \"match_probability\": 0.9936026357542103, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 648.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1383.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.31905466318130493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6809453368186951, \"precision\": 1.0, \"recall\": 0.31905466318130493, \"specificity\": 1.0, \"npv\": 0.45292720198631287, \"accuracy\": 0.5645465850830078, \"f1\": 0.48376259798432253, \"f2\": 0.3693570451436389, \"f0_5\": 0.7008436080467229, \"p4\": 0.5448018093975668, \"phi\": 0.38014278294145043}, {\"truth_threshold\": 7.315635349049926, \"match_probability\": 0.993761838158445, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 647.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1384.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3185622990131378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6814377307891846, \"precision\": 1.0, \"recall\": 0.3185622990131378, \"specificity\": 1.0, \"npv\": 0.4527481198310852, \"accuracy\": 0.5642317533493042, \"f1\": 0.4831964152352502, \"f2\": 0.36882909588416374, \"f0_5\": 0.700368045031392, \"p4\": 0.5443778764254908, \"phi\": 0.379774243491937}, {\"truth_threshold\": 7.3442547782100185, \"match_probability\": 0.9938836187463488, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 646.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1385.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3180699050426483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6819300651550293, \"precision\": 1.0, \"recall\": 0.3180699050426483, \"specificity\": 1.0, \"npv\": 0.4525691568851471, \"accuracy\": 0.5639168620109558, \"f1\": 0.4826298094882331, \"f2\": 0.36830102622576966, \"f0_5\": 0.6998916576381365, \"p4\": 0.5439534932890132, \"phi\": 0.3794056378180318}, {\"truth_threshold\": 7.349884480356181, \"match_probability\": 0.9939072945225745, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 645.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1386.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3175775408744812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6824224591255188, \"precision\": 1.0, \"recall\": 0.3175775408744812, \"specificity\": 1.0, \"npv\": 0.4523903727531433, \"accuracy\": 0.5636020302772522, \"f1\": 0.4820627802690583, \"f2\": 0.3677728361272665, \"f0_5\": 0.6994144437215355, \"p4\": 0.5435286584827342, \"phi\": 0.37903696538036896}, {\"truth_threshold\": 7.353223820698747, \"match_probability\": 0.9939212950952971, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 644.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1387.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3170851767063141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6829147934913635, \"precision\": 1.0, \"recall\": 0.3170851767063141, \"specificity\": 1.0, \"npv\": 0.4522116780281067, \"accuracy\": 0.5632871389389038, \"f1\": 0.48149532710280374, \"f2\": 0.36724452554744524, \"f0_5\": 0.6989364011287171, \"p4\": 0.5431033704956284, \"phi\": 0.37866822563799446}, {\"truth_threshold\": 7.3787949167922084, \"match_probability\": 0.9940274502518517, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 643.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1388.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.316592812538147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.683407187461853, \"precision\": 1.0, \"recall\": 0.316592812538147, \"specificity\": 1.0, \"npv\": 0.4520331621170044, \"accuracy\": 0.5629723072052002, \"f1\": 0.4809274495138369, \"f2\": 0.36671609444507813, \"f0_5\": 0.6984575276993266, \"p4\": 0.5426776278110168, \"phi\": 0.37829941804835615}, {\"truth_threshold\": 7.3852322153638825, \"match_probability\": 0.9940538822664702, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 642.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1389.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.31610044836997986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6838995814323425, \"precision\": 1.0, \"recall\": 0.31610044836997986, \"specificity\": 1.0, \"npv\": 0.45185476541519165, \"accuracy\": 0.5626574158668518, \"f1\": 0.48035914702581367, \"f2\": 0.3661875427789186, \"f0_5\": 0.6979778212654925, \"p4\": 0.54225142890654, \"phi\": 0.3779305420672941}, {\"truth_threshold\": 7.416435026583277, \"match_probability\": 0.9941803645924744, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 629.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1402.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3096996545791626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6903003454208374, \"precision\": 1.0, \"recall\": 0.3096996545791626, \"specificity\": 1.0, \"npv\": 0.44954848289489746, \"accuracy\": 0.5585642457008362, \"f1\": 0.47293233082706765, \"f2\": 0.35930538101222437, \"f0_5\": 0.6916648339564548, \"p4\": 0.5366686239560295, \"phi\": 0.37312868011261374}, {\"truth_threshold\": 7.416464524856882, \"match_probability\": 0.9941804828908091, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 627.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1404.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.30871492624282837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6912850737571716, \"precision\": 1.0, \"recall\": 0.30871492624282837, \"specificity\": 1.0, \"npv\": 0.4491957724094391, \"accuracy\": 0.5579345226287842, \"f1\": 0.4717832957110609, \"f2\": 0.35824477202605415, \"f0_5\": 0.6906807666886979, \"p4\": 0.535802646044032, \"phi\": 0.3723888203144958}, {\"truth_threshold\": 7.434727428113677, \"match_probability\": 0.9942532664542074, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 626.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1405.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.30822256207466125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6917774677276611, \"precision\": 1.0, \"recall\": 0.30822256207466125, \"specificity\": 1.0, \"npv\": 0.4490196108818054, \"accuracy\": 0.5576196312904358, \"f1\": 0.47120812946932633, \"f2\": 0.3577142857142857, \"f0_5\": 0.6901874310915105, \"p4\": 0.5353689358368804, \"phi\": 0.3720187747136435}, {\"truth_threshold\": 7.486330492433031, \"match_probability\": 0.9944540660608364, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 623.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1408.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3067454397678375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6932545304298401, \"precision\": 1.0, \"recall\": 0.3067454397678375, \"specificity\": 1.0, \"npv\": 0.4484919607639313, \"accuracy\": 0.5566750764846802, \"f1\": 0.4694800301431801, \"f2\": 0.3561220990053733, \"f0_5\": 0.6887021888127349, \"p4\": 0.5340649007128252, \"phi\": 0.3709081682216741}, {\"truth_threshold\": 7.490621548675497, \"match_probability\": 0.9944704459339391, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 621.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1410.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3057607114315033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6942393183708191, \"precision\": 1.0, \"recall\": 0.3057607114315033, \"specificity\": 1.0, \"npv\": 0.4481408894062042, \"accuracy\": 0.5560453534126282, \"f1\": 0.4683257918552036, \"f2\": 0.35506003430531735, \"f0_5\": 0.6877076411960132, \"p4\": 0.5331931071717808, \"phi\": 0.37016736671452755}, {\"truth_threshold\": 7.492860642321502, \"match_probability\": 0.9944789739195546, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 613.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1418.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.301821768283844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.698178231716156, \"precision\": 1.0, \"recall\": 0.301821768283844, \"specificity\": 1.0, \"npv\": 0.44674208760261536, \"accuracy\": 0.5535264611244202, \"f1\": 0.4636913767019667, \"f2\": 0.350806913128076, \"f0_5\": 0.6836939549408878, \"p4\": 0.5296861510411321, \"phi\": 0.3672008820983914}, {\"truth_threshold\": 7.519791141759866, \"match_probability\": 0.9945805245162321, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 612.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1419.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.3013294041156769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6986706256866455, \"precision\": 1.0, \"recall\": 0.3013294041156769, \"specificity\": 1.0, \"npv\": 0.4465678632259369, \"accuracy\": 0.5532115697860718, \"f1\": 0.46311010215664017, \"f2\": 0.35027472527472525, \"f0_5\": 0.6831882116543871, \"p4\": 0.5292455283023891, \"phi\": 0.366829692942734}, {\"truth_threshold\": 7.545580856481732, \"match_probability\": 0.9946760314608684, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 610.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1421.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.30034464597702026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6996553540229797, \"precision\": 1.0, \"recall\": 0.30034464597702026, \"specificity\": 1.0, \"npv\": 0.446219801902771, \"accuracy\": 0.5525818467140198, \"f1\": 0.46194623248769406, \"f2\": 0.34920998397068925, \"f0_5\": 0.6821740102885261, \"p4\": 0.528362761942676, \"phi\": 0.3660870556854762}, {\"truth_threshold\": 7.57467063193447, \"match_probability\": 0.9947817516739716, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 603.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1428.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2968980669975281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7031019330024719, \"precision\": 1.0, \"recall\": 0.2968980669975281, \"specificity\": 1.0, \"npv\": 0.4450058341026306, \"accuracy\": 0.5503778457641602, \"f1\": 0.45785876993166286, \"f2\": 0.3454795462358199, \"f0_5\": 0.6785955435516543, \"p4\": 0.5252569284525866, \"phi\": 0.36348504280445315}, {\"truth_threshold\": 7.575464496432992, \"match_probability\": 0.9947846073317336, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 602.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1429.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.29640570282936096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7035942673683167, \"precision\": 1.0, \"recall\": 0.29640570282936096, \"specificity\": 1.0, \"npv\": 0.4448329508304596, \"accuracy\": 0.5500629544258118, \"f1\": 0.45727307254082794, \"f2\": 0.3449461379784552, \"f0_5\": 0.6780806487947736, \"p4\": 0.5248111636484003, \"phi\": 0.3631129652043212}, {\"truth_threshold\": 7.595261894021485, \"match_probability\": 0.9948553211206286, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 599.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1432.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2949286103248596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7050713896751404, \"precision\": 1.0, \"recall\": 0.2949286103248596, \"specificity\": 1.0, \"npv\": 0.444315105676651, \"accuracy\": 0.5491183996200562, \"f1\": 0.4555133079847909, \"f2\": 0.34334517941075315, \"f0_5\": 0.6765303817483623, \"p4\": 0.5234707187490221, \"phi\": 0.3619961766094538}, {\"truth_threshold\": 7.596235097536718, \"match_probability\": 0.9948587725767974, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 596.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1435.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2934514880180359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7065485119819641, \"precision\": 1.0, \"recall\": 0.2934514880180359, \"specificity\": 1.0, \"npv\": 0.4437984526157379, \"accuracy\": 0.5481737852096558, \"f1\": 0.4537495241720594, \"f2\": 0.34174311926605505, \"f0_5\": 0.6749716874292185, \"p4\": 0.5221255103514432, \"phi\": 0.3608785412035843}, {\"truth_threshold\": 7.613134104497665, \"match_probability\": 0.9949183387673067, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 592.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1439.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.29148203134536743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7085179686546326, \"precision\": 1.0, \"recall\": 0.29148203134536743, \"specificity\": 1.0, \"npv\": 0.44311144948005676, \"accuracy\": 0.5469143390655518, \"f1\": 0.45139153640869234, \"f2\": 0.33960532354290957, \"f0_5\": 0.6728802000454649, \"p4\": 0.5203244044266416, \"phi\": 0.3593870139723867}, {\"truth_threshold\": 7.625677972121751, \"match_probability\": 0.9949621093675901, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 585.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1446.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.28803545236587524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7119645476341248, \"precision\": 1.0, \"recall\": 0.28803545236587524, \"specificity\": 1.0, \"npv\": 0.44191431999206543, \"accuracy\": 0.5447103381156921, \"f1\": 0.44724770642201833, \"f2\": 0.33585945573544607, \"f0_5\": 0.6691832532601235, \"p4\": 0.5171515263816185, \"phi\": 0.35677302294913593}, {\"truth_threshold\": 7.662815142037419, \"match_probability\": 0.9950895087838049, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 584.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1447.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.28754308819770813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7124569416046143, \"precision\": 1.0, \"recall\": 0.28754308819770813, \"specificity\": 1.0, \"npv\": 0.4417438209056854, \"accuracy\": 0.5443954467773438, \"f1\": 0.44665391969407264, \"f2\": 0.3353238401469913, \"f0_5\": 0.6686512479963361, \"p4\": 0.5166960522027755, \"phi\": 0.35639918857345765}, {\"truth_threshold\": 7.681078045294213, \"match_probability\": 0.9951509787892422, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 583.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1448.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.287050724029541, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.712949275970459, \"precision\": 1.0, \"recall\": 0.287050724029541, \"specificity\": 1.0, \"npv\": 0.44157347083091736, \"accuracy\": 0.5440806150436401, \"f1\": 0.44605967865340473, \"f2\": 0.3347881015275066, \"f0_5\": 0.6681182672473069, \"p4\": 0.5162400208495899, \"phi\": 0.35602525045888256}, {\"truth_threshold\": 7.686317924801047, \"match_probability\": 0.9951684735904823, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 582.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1449.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2865583598613739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7134416699409485, \"precision\": 1.0, \"recall\": 0.2865583598613739, \"specificity\": 1.0, \"npv\": 0.44140323996543884, \"accuracy\": 0.5437657237052917, \"f1\": 0.4454649827784156, \"f2\": 0.33425223983459684, \"f0_5\": 0.6675843083275981, \"p4\": 0.5157834304021511, \"phi\": 0.3556512079438443}, {\"truth_threshold\": 7.730338891779748, \"match_probability\": 0.9953129909777977, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 573.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1458.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2821270227432251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7178729772567749, \"precision\": 1.0, \"recall\": 0.2821270227432251, \"specificity\": 1.0, \"npv\": 0.43987706303596497, \"accuracy\": 0.5409319996833801, \"f1\": 0.4400921658986175, \"f2\": 0.32942393928941016, \"f0_5\": 0.6627342123525329, \"p4\": 0.5116486365082633, \"phi\": 0.3522800169478189}, {\"truth_threshold\": 7.737962482200878, \"match_probability\": 0.9953375779045585, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 572.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1459.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.281634658575058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7183653116226196, \"precision\": 1.0, \"recall\": 0.281634658575058, \"specificity\": 1.0, \"npv\": 0.4397081434726715, \"accuracy\": 0.5406171083450317, \"f1\": 0.4394928928159816, \"f2\": 0.32888684452621897, \"f0_5\": 0.6621903218337578, \"p4\": 0.5111863478106634, \"phi\": 0.35190489351468984}, {\"truth_threshold\": 7.742183563096313, \"match_probability\": 0.9953511360990649, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 571.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1460.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.28114229440689087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7188577055931091, \"precision\": 1.0, \"recall\": 0.28114229440689087, \"specificity\": 1.0, \"npv\": 0.4395393431186676, \"accuracy\": 0.5403022766113281, \"f1\": 0.4388931591083782, \"f2\": 0.3283496262219667, \"f0_5\": 0.6616454229432214, \"p4\": 0.5107234783831393, \"phi\": 0.35152965824454285}, {\"truth_threshold\": 7.753871172816981, \"match_probability\": 0.9953884725151737, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 570.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1461.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.28064993023872375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7193500995635986, \"precision\": 1.0, \"recall\": 0.28064993023872375, \"specificity\": 1.0, \"npv\": 0.43937069177627563, \"accuracy\": 0.5399873852729797, \"f1\": 0.43829296424452135, \"f2\": 0.3278122843340235, \"f0_5\": 0.6610995128740431, \"p4\": 0.5102600262107828, \"phi\": 0.35115431044642736}, {\"truth_threshold\": 7.785019627473887, \"match_probability\": 0.9954865258298237, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 564.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1467.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2776957154273987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7223042845726013, \"precision\": 1.0, \"recall\": 0.2776957154273987, \"specificity\": 1.0, \"npv\": 0.43836140632629395, \"accuracy\": 0.5380982160568237, \"f1\": 0.4346820809248555, \"f2\": 0.324585635359116, \"f0_5\": 0.6578026592022393, \"p4\": 0.5074669616635656, \"phi\": 0.34889982155313615}, {\"truth_threshold\": 7.790625684955352, \"match_probability\": 0.9955039516582921, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 563.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1468.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.27720335125923157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7227966785430908, \"precision\": 1.0, \"recall\": 0.27720335125923157, \"specificity\": 1.0, \"npv\": 0.4381936490535736, \"accuracy\": 0.5377833843231201, \"f1\": 0.43407864302235927, \"f2\": 0.3240474271900541, \"f0_5\": 0.6572495914078916, \"p4\": 0.5069993731669853, \"phi\": 0.3485236664958884}, {\"truth_threshold\": 7.7919314736622685, \"match_probability\": 0.9955080009360721, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 561.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1470.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.27621862292289734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.723781406879425, \"precision\": 1.0, \"recall\": 0.27621862292289734, \"specificity\": 1.0, \"npv\": 0.437858521938324, \"accuracy\": 0.5371536612510681, \"f1\": 0.43287037037037035, \"f2\": 0.3229706390328152, \"f0_5\": 0.656140350877193, \"p4\": 0.5060623965965493, \"phi\": 0.34777100121990157}, {\"truth_threshold\": 7.821021249115008, \"match_probability\": 0.995597273517924, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 552.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1479.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.27178728580474854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7282127141952515, \"precision\": 1.0, \"recall\": 0.27178728580474854, \"specificity\": 1.0, \"npv\": 0.43635669350624084, \"accuracy\": 0.5343198776245117, \"f1\": 0.4274099883855981, \"f2\": 0.318118948824343, \"f0_5\": 0.6510969568294409, \"p4\": 0.5018158908762426, \"phi\": 0.3443780044733605}, {\"truth_threshold\": 7.831472525862121, \"match_probability\": 0.9956289139125147, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 550.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1481.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2708025574684143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7291974425315857, \"precision\": 1.0, \"recall\": 0.2708025574684143, \"specificity\": 1.0, \"npv\": 0.43602436780929565, \"accuracy\": 0.5336901545524597, \"f1\": 0.42619139868268113, \"f2\": 0.31703942817615866, \"f0_5\": 0.6499645473883243, \"p4\": 0.5008654294488591, \"phi\": 0.3436226363432227}, {\"truth_threshold\": 7.857949596425301, \"match_probability\": 0.9957080614989341, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 549.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1482.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2703101933002472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7296898365020752, \"precision\": 1.0, \"recall\": 0.2703101933002472, \"specificity\": 1.0, \"npv\": 0.4358583986759186, \"accuracy\": 0.5333753228187561, \"f1\": 0.4255813953488372, \"f2\": 0.31649948114839155, \"f0_5\": 0.6493967352732435, \"p4\": 0.5003892593087901, \"phi\": 0.34324476116970176}, {\"truth_threshold\": 7.859484721678203, \"match_probability\": 0.9957126064136066, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 548.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1483.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2698178291320801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7301821708679199, \"precision\": 1.0, \"recall\": 0.2698178291320801, \"specificity\": 1.0, \"npv\": 0.43569254875183105, \"accuracy\": 0.5330604314804077, \"f1\": 0.42497091896083755, \"f2\": 0.31595940959409596, \"f0_5\": 0.648827847501776, \"p4\": 0.49991245994718914, \"phi\": 0.34286675758983254}, {\"truth_threshold\": 7.91562833465721, \"match_probability\": 0.9958755739878387, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 544.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1487.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.26784834265708923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7321516275405884, \"precision\": 1.0, \"recall\": 0.26784834265708923, \"specificity\": 1.0, \"npv\": 0.43503040075302124, \"accuracy\": 0.5318009853363037, \"f1\": 0.4225242718446602, \"f2\": 0.3137978772496539, \"f0_5\": 0.6465414784882338, \"p4\": 0.49799892585801936, \"phi\": 0.3413534440774818}, {\"truth_threshold\": 7.9242856247774345, \"match_probability\": 0.9959001484683947, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 543.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1488.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2673559784889221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7326440215110779, \"precision\": 1.0, \"recall\": 0.2673559784889221, \"specificity\": 1.0, \"npv\": 0.43486517667770386, \"accuracy\": 0.5314861536026001, \"f1\": 0.4219114219114219, \"f2\": 0.31325718241606093, \"f0_5\": 0.6459671663097787, \"p4\": 0.49751894698684695, \"phi\": 0.3409747870925449}, {\"truth_threshold\": 7.9479808631381985, \"match_probability\": 0.9959666662671326, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 542.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1489.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.266863614320755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7331364154815674, \"precision\": 1.0, \"recall\": 0.266863614320755, \"specificity\": 1.0, \"npv\": 0.434700071811676, \"accuracy\": 0.5311712622642517, \"f1\": 0.4212980956082394, \"f2\": 0.3127163627971382, \"f0_5\": 0.6453917599428435, \"p4\": 0.4970383254680383, \"phi\": 0.34059599713078775}, {\"truth_threshold\": 7.94877368444401, \"match_probability\": 0.9959688732114306, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 540.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1491.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2658788859844208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7341211438179016, \"precision\": 1.0, \"recall\": 0.2658788859844208, \"specificity\": 1.0, \"npv\": 0.4343702495098114, \"accuracy\": 0.5305415391921997, \"f1\": 0.4200700116686114, \"f2\": 0.31163434903047094, \"f0_5\": 0.6442376521116678, \"p4\": 0.4960751453956296, \"phi\": 0.3398380151840589}, {\"truth_threshold\": 7.972209594181436, \"match_probability\": 0.9960335703437415, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 539.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1492.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.26538652181625366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7346134781837463, \"precision\": 1.0, \"recall\": 0.26538652181625366, \"specificity\": 1.0, \"npv\": 0.4342055320739746, \"accuracy\": 0.5302267074584961, \"f1\": 0.41945525291828795, \"f2\": 0.31109315479625993, \"f0_5\": 0.6436589443515643, \"p4\": 0.4955925822721991, \"phi\": 0.33945882164492946}, {\"truth_threshold\": 7.9807160035994364, \"match_probability\": 0.9960567964222327, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 538.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1493.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.26489412784576416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7351058721542358, \"precision\": 1.0, \"recall\": 0.26489412784576416, \"specificity\": 1.0, \"npv\": 0.43404093384742737, \"accuracy\": 0.5299118161201477, \"f1\": 0.4188400155702608, \"f2\": 0.31055183560378663, \"f0_5\": 0.6430791298111403, \"p4\": 0.4951093673613691, \"phi\": 0.33907949202062193}, {\"truth_threshold\": 7.998635104193186, \"match_probability\": 0.9961052807979991, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 537.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1494.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.26440176367759705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7355982065200806, \"precision\": 1.0, \"recall\": 0.26440176367759705, \"specificity\": 1.0, \"npv\": 0.4338764548301697, \"accuracy\": 0.5295969843864441, \"f1\": 0.4182242990654206, \"f2\": 0.31001039140976794, \"f0_5\": 0.6424982053122756, \"p4\": 0.49462549835410413, \"phi\": 0.33870002552618034}, {\"truth_threshold\": 7.998686664744616, \"match_probability\": 0.9961054194469885, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 535.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1496.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2634170353412628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7365829348564148, \"precision\": 1.0, \"recall\": 0.2634170353412628, \"specificity\": 1.0, \"npv\": 0.43354788422584534, \"accuracy\": 0.5289672613143921, \"f1\": 0.4169914263445051, \"f2\": 0.3089271278438619, \"f0_5\": 0.6413330136657875, \"p4\": 0.4936557887653669, \"phi\": 0.3379406787710988}, {\"truth_threshold\": 7.999427925498997, \"match_probability\": 0.9961074121921573, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 534.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1497.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2629246711730957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7370753288269043, \"precision\": 1.0, \"recall\": 0.2629246711730957, \"specificity\": 1.0, \"npv\": 0.4333837926387787, \"accuracy\": 0.5286523699760437, \"f1\": 0.41637426900584795, \"f2\": 0.30838530838530837, \"f0_5\": 0.640748740100792, \"p4\": 0.4931699435169059, \"phi\": 0.3375607969245083}, {\"truth_threshold\": 8.016717625240558, \"match_probability\": 0.9961536053743496, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 531.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1500.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.261447548866272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.738552451133728, \"precision\": 1.0, \"recall\": 0.261447548866272, \"specificity\": 1.0, \"npv\": 0.4328922629356384, \"accuracy\": 0.5277078151702881, \"f1\": 0.41451990632318503, \"f2\": 0.30675909878682844, \"f0_5\": 0.6389891696750902, \"p4\": 0.4917084177453204, \"phi\": 0.3364203079244411}, {\"truth_threshold\": 8.040127571358152, \"match_probability\": 0.996215281080419, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 530.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1501.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.26095518469810486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7390447854995728, \"precision\": 1.0, \"recall\": 0.26095518469810486, \"specificity\": 1.0, \"npv\": 0.43272864818573, \"accuracy\": 0.5273929238319397, \"f1\": 0.4139008199921905, \"f2\": 0.30621677836838457, \"f0_5\": 0.6384003854492893, \"p4\": 0.49121990458507664, \"phi\": 0.3360398610895279}, {\"truth_threshold\": 8.088717931457515, \"match_probability\": 0.9963401699685042, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 529.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1502.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.26046282052993774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7395371794700623, \"precision\": 1.0, \"recall\": 0.26046282052993774, \"specificity\": 1.0, \"npv\": 0.43256518244743347, \"accuracy\": 0.5270780920982361, \"f1\": 0.41328125, \"f2\": 0.3056743326014099, \"f0_5\": 0.6378104653966723, \"p4\": 0.4907307185009706, \"phi\": 0.33565927098811493}, {\"truth_threshold\": 8.157221062375157, \"match_probability\": 0.9965092951213239, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 526.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1505.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2589857280254364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.741014301776886, \"precision\": 1.0, \"recall\": 0.2589857280254364, \"specificity\": 1.0, \"npv\": 0.43207547068595886, \"accuracy\": 0.5261334776878357, \"f1\": 0.4114196323816973, \"f2\": 0.3040462427745665, \"f0_5\": 0.6360338573155986, \"p4\": 0.48925909866803685, \"phi\": 0.33451663292311695}, {\"truth_threshold\": 8.161978951837748, \"match_probability\": 0.9965207482291818, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 525.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1506.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2584933638572693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7415066361427307, \"precision\": 1.0, \"recall\": 0.2584933638572693, \"specificity\": 1.0, \"npv\": 0.43191248178482056, \"accuracy\": 0.5258186459541321, \"f1\": 0.4107981220657277, \"f2\": 0.3035032951786334, \"f0_5\": 0.635439360929557, \"p4\": 0.4887671967996878, \"phi\": 0.33413546157687174}, {\"truth_threshold\": 8.195124301624547, \"match_probability\": 0.9965995027094589, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 524.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1507.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2580009698867798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7419990301132202, \"precision\": 1.0, \"recall\": 0.2580009698867798, \"specificity\": 1.0, \"npv\": 0.4317496120929718, \"accuracy\": 0.5255037546157837, \"f1\": 0.4101761252446184, \"f2\": 0.30296022201665124, \"f0_5\": 0.6348437121395687, \"p4\": 0.4882746099115319, \"phi\": 0.3337541428575539}, {\"truth_threshold\": 8.39003917878057, \"match_probability\": 0.9970279652554603, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 520.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1511.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.25603151321411133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7439684867858887, \"precision\": 1.0, \"recall\": 0.25603151321411133, \"specificity\": 1.0, \"npv\": 0.43109938502311707, \"accuracy\": 0.5242443084716797, \"f1\": 0.40768326146609174, \"f2\": 0.3007866728366497, \"f0_5\": 0.6324495256628557, \"p4\": 0.48629736299660126, \"phi\": 0.33222737756280557}, {\"truth_threshold\": 8.416435026583278, \"match_probability\": 0.9970816905477279, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 519.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1512.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2555391490459442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7444608807563782, \"precision\": 1.0, \"recall\": 0.2555391490459442, \"specificity\": 1.0, \"npv\": 0.43093714118003845, \"accuracy\": 0.5239294767379761, \"f1\": 0.40705882352941175, \"f2\": 0.3002429711905588, \"f0_5\": 0.6318480642804967, \"p4\": 0.48580131404368865, \"phi\": 0.3318453094320319}, {\"truth_threshold\": 8.454361165553987, \"match_probability\": 0.9971571933575609, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 518.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1513.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2550467848777771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7449532151222229, \"precision\": 1.0, \"recall\": 0.2550467848777771, \"specificity\": 1.0, \"npv\": 0.4307750165462494, \"accuracy\": 0.5236145853996277, \"f1\": 0.4064338956453511, \"f2\": 0.29969914371673223, \"f0_5\": 0.6312454301730441, \"p4\": 0.48530456521032067, \"phi\": 0.3314630888847838}, {\"truth_threshold\": 8.47882747930691, \"match_probability\": 0.9972048637106271, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 517.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1514.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.25455442070961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7454456090927124, \"precision\": 1.0, \"recall\": 0.25455442070961, \"specificity\": 1.0, \"npv\": 0.4306130111217499, \"accuracy\": 0.5232997536659241, \"f1\": 0.40580847723704866, \"f2\": 0.2991551903714848, \"f0_5\": 0.6306416199072945, \"p4\": 0.4848071139822707, \"phi\": 0.331080715067894}, {\"truth_threshold\": 8.539204113311483, \"match_probability\": 0.9973191188107783, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 516.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1515.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2540620267391205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7459379434585571, \"precision\": 1.0, \"recall\": 0.2540620267391205, \"specificity\": 1.0, \"npv\": 0.4304511249065399, \"accuracy\": 0.5229848623275757, \"f1\": 0.40518256772673733, \"f2\": 0.2986111111111111, \"f0_5\": 0.63003663003663, \"p4\": 0.4843089578344548, \"phi\": 0.33069818712452625}, {\"truth_threshold\": 8.551932215395759, \"match_probability\": 0.9973426041419174, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 513.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1518.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.25258493423461914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7474150657653809, \"precision\": 1.0, \"recall\": 0.25258493423461914, \"specificity\": 1.0, \"npv\": 0.4299662113189697, \"accuracy\": 0.5220403075218201, \"f1\": 0.4033018867924528, \"f2\": 0.29697811740187563, \"f0_5\": 0.6282145481263777, \"p4\": 0.4828102344574534, \"phi\": 0.32954966991161616}, {\"truth_threshold\": 8.56844585516456, \"match_probability\": 0.9973727688306604, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 512.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1519.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.252092570066452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7479074597358704, \"precision\": 1.0, \"recall\": 0.252092570066452, \"specificity\": 1.0, \"npv\": 0.42980480194091797, \"accuracy\": 0.5217254161834717, \"f1\": 0.402674007078254, \"f2\": 0.29643353404353867, \"f0_5\": 0.6276048050992891, \"p4\": 0.48230923316048746, \"phi\": 0.32916651681968556}, {\"truth_threshold\": 8.587002082512148, \"match_probability\": 0.9974062573175582, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 511.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1520.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2516002058982849, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7483997941017151, \"precision\": 1.0, \"recall\": 0.2516002058982849, \"specificity\": 1.0, \"npv\": 0.42964354157447815, \"accuracy\": 0.5214105844497681, \"f1\": 0.4020456333595594, \"f2\": 0.29588882455124493, \"f0_5\": 0.6269938650306749, \"p4\": 0.4818075141533711, \"phi\": 0.32878320526114574}, {\"truth_threshold\": 8.604291782253709, \"match_probability\": 0.9974370768147253, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 509.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1522.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2506154477596283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7493845224380493, \"precision\": 1.0, \"recall\": 0.2506154477596283, \"specificity\": 1.0, \"npv\": 0.4293213486671448, \"accuracy\": 0.5207808613777161, \"f1\": 0.40078740157480314, \"f2\": 0.29479902698945903, \"f0_5\": 0.6257683796410131, \"p4\": 0.48080191263141914, \"phi\": 0.3280161032227643}, {\"truth_threshold\": 8.650057541679537, \"match_probability\": 0.9975169041743673, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 506.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1525.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24913835525512695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.750861644744873, \"precision\": 1.0, \"recall\": 0.24913835525512695, \"specificity\": 1.0, \"npv\": 0.42883893847465515, \"accuracy\": 0.5198362469673157, \"f1\": 0.39889633425305476, \"f2\": 0.2931633835457706, \"f0_5\": 0.623921085080148, \"p4\": 0.4792880623669279, \"phi\": 0.3268642395545956}, {\"truth_threshold\": 8.662785643763813, \"match_probability\": 0.9975386611219473, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 503.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1528.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24766124784946442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7523387670516968, \"precision\": 1.0, \"recall\": 0.24766124784946442, \"specificity\": 1.0, \"npv\": 0.42835766077041626, \"accuracy\": 0.5188916921615601, \"f1\": 0.39700078926598265, \"f2\": 0.2915266025269503, \"f0_5\": 0.6220628246351719, \"p4\": 0.4777676111660919, \"phi\": 0.3257109016494715}, {\"truth_threshold\": 8.679147317132276, \"match_probability\": 0.9975663500429647, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 502.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1529.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2471688836812973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7528311014175415, \"precision\": 1.0, \"recall\": 0.2471688836812973, \"specificity\": 1.0, \"npv\": 0.42819744348526, \"accuracy\": 0.5185768008232117, \"f1\": 0.3963679431504145, \"f2\": 0.2909807558543937, \"f0_5\": 0.6214409507303789, \"p4\": 0.4772593147830282, \"phi\": 0.3253261238495857}, {\"truth_threshold\": 8.679941181630799, \"match_probability\": 0.9975676855704895, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 500.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1531.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24618414044380188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7538158297538757, \"precision\": 1.0, \"recall\": 0.24618414044380188, \"specificity\": 1.0, \"npv\": 0.42787742614746094, \"accuracy\": 0.5179470777511597, \"f1\": 0.3951007506914263, \"f2\": 0.2898886827458256, \"f0_5\": 0.6201935003721161, \"p4\": 0.4762404868883091, \"phi\": 0.3245560650178309}, {\"truth_threshold\": 8.694893760308991, \"match_probability\": 0.9975927043370202, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 498.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1533.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24519941210746765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7548006176948547, \"precision\": 1.0, \"recall\": 0.24519941210746765, \"specificity\": 1.0, \"npv\": 0.42755788564682007, \"accuracy\": 0.5173173546791077, \"f1\": 0.39383155397390274, \"f2\": 0.28879610299234515, \"f0_5\": 0.6189410887397464, \"p4\": 0.4752186607144531, \"phi\": 0.3237853290610129}, {\"truth_threshold\": 8.700711782734524, \"match_probability\": 0.9976023695705544, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 497.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1534.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24470704793930054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7552929520606995, \"precision\": 1.0, \"recall\": 0.24470704793930054, \"specificity\": 1.0, \"npv\": 0.42739829421043396, \"accuracy\": 0.517002522945404, \"f1\": 0.39319620253164556, \"f2\": 0.2882496230135715, \"f0_5\": 0.6183130131873601, \"p4\": 0.4747066164374877, \"phi\": 0.32339970483913755}, {\"truth_threshold\": 8.717610789695472, \"match_probability\": 0.9976302242018749, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 495.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1536.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24372230470180511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7562776803970337, \"precision\": 1.0, \"recall\": 0.24372230470180511, \"specificity\": 1.0, \"npv\": 0.427079439163208, \"accuracy\": 0.516372799873352, \"f1\": 0.3919239904988123, \"f2\": 0.28715628263139575, \"f0_5\": 0.6170531039640987, \"p4\": 0.4736802517268613, \"phi\": 0.3226279392283468}, {\"truth_threshold\": 8.725943295660814, \"match_probability\": 0.9976438395990851, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 493.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1538.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2427375614643097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7572624087333679, \"precision\": 1.0, \"recall\": 0.2427375614643097, \"specificity\": 1.0, \"npv\": 0.42676109075546265, \"accuracy\": 0.5157430768013, \"f1\": 0.3906497622820919, \"f2\": 0.28606243472206105, \"f0_5\": 0.6157881588808394, \"p4\": 0.47265083362918403, \"phi\": 0.32185547777140927}, {\"truth_threshold\": 8.782698458637698, \"match_probability\": 0.997734524752208, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 492.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1539.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24224519729614258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7577548027038574, \"precision\": 1.0, \"recall\": 0.24224519729614258, \"specificity\": 1.0, \"npv\": 0.4266020953655243, \"accuracy\": 0.5154281854629517, \"f1\": 0.39001189060642094, \"f2\": 0.28551532033426186, \"f0_5\": 0.6151537884471118, \"p4\": 0.4721349725721462, \"phi\": 0.32146898372560456}, {\"truth_threshold\": 8.78555473049202, \"match_probability\": 0.9977389954100062, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 489.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1542.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.24076808989048004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7592319250106812, \"precision\": 1.0, \"recall\": 0.24076808989048004, \"specificity\": 1.0, \"npv\": 0.42612579464912415, \"accuracy\": 0.514483630657196, \"f1\": 0.3880952380952381, \"f2\": 0.2838732149076977, \"f0_5\": 0.6132430398796087, \"p4\": 0.4705827475265, \"phi\": 0.3203084368133342}, {\"truth_threshold\": 8.790794609998853, \"match_probability\": 0.997747174034522, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 476.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1555.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.23436731100082397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.765632688999176, \"precision\": 1.0, \"recall\": 0.23436731100082397, \"specificity\": 1.0, \"npv\": 0.42407408356666565, \"accuracy\": 0.5103904008865356, \"f1\": 0.37973673713601913, \"f2\": 0.27674418604651163, \"f0_5\": 0.6048284625158831, \"p4\": 0.4637742821069471, \"phi\": 0.31526036636613447}, {\"truth_threshold\": 8.792269871510209, \"match_probability\": 0.9977494713550457, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 471.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1560.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.23190546035766602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.768094539642334, \"precision\": 1.0, \"recall\": 0.23190546035766602, \"specificity\": 1.0, \"npv\": 0.4232901930809021, \"accuracy\": 0.508816123008728, \"f1\": 0.3764988009592326, \"f2\": 0.27399650959860383, \"f0_5\": 0.6015325670498084, \"p4\": 0.46111916274416753, \"phi\": 0.3133102480839957}, {\"truth_threshold\": 8.816805434044586, \"match_probability\": 0.997787337952055, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 470.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1561.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2314130961894989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7685868740081787, \"precision\": 1.0, \"recall\": 0.2314130961894989, \"specificity\": 1.0, \"npv\": 0.4231337904930115, \"accuracy\": 0.5085012316703796, \"f1\": 0.3758496601359456, \"f2\": 0.2734465906446358, \"f0_5\": 0.600869342879059, \"p4\": 0.46058564943838975, \"phi\": 0.3129196346210279}, {\"truth_threshold\": 8.857553993516266, \"match_probability\": 0.9978488271355261, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 468.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1563.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.23042836785316467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7695716619491577, \"precision\": 1.0, \"recall\": 0.23042836785316467, \"specificity\": 1.0, \"npv\": 0.4228212833404541, \"accuracy\": 0.5078715085983276, \"f1\": 0.3745498199279712, \"f2\": 0.2723463687150838, \"f0_5\": 0.5995388162951576, \"p4\": 0.45951610859676123, \"phi\": 0.31213780941367647}, {\"truth_threshold\": 8.858347858014787, \"match_probability\": 0.9978500079806345, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 465.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1566.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.22895126044750214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7710487246513367, \"precision\": 1.0, \"recall\": 0.22895126044750214, \"specificity\": 1.0, \"npv\": 0.4223533868789673, \"accuracy\": 0.506926953792572, \"f1\": 0.37259615384615385, \"f2\": 0.2706950750960531, \"f0_5\": 0.5975327679259831, \"p4\": 0.45790546467826, \"phi\": 0.3109635597929673}, {\"truth_threshold\": 8.881874708927246, \"match_probability\": 0.9978847112304389, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 463.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1568.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2279665172100067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7720334529876709, \"precision\": 1.0, \"recall\": 0.2279665172100067, \"specificity\": 1.0, \"npv\": 0.42204201221466064, \"accuracy\": 0.50629723072052, \"f1\": 0.37129109863672816, \"f2\": 0.2695935716781181, \"f0_5\": 0.5961885140355395, \"p4\": 0.45682744333981634, \"phi\": 0.3101797061878598}, {\"truth_threshold\": 8.882126766917107, \"match_probability\": 0.9978850799856654, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 462.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1569.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2274741530418396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7725258469581604, \"precision\": 1.0, \"recall\": 0.2274741530418396, \"specificity\": 1.0, \"npv\": 0.42188650369644165, \"accuracy\": 0.5059823393821716, \"f1\": 0.37063778580024065, \"f2\": 0.2690426275331936, \"f0_5\": 0.5955143078112916, \"p4\": 0.45628714546239085, \"phi\": 0.30978746994220124}, {\"truth_threshold\": 8.896408158860075, \"match_probability\": 0.9979058688963204, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 461.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1570.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.22698178887367249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7730182409286499, \"precision\": 1.0, \"recall\": 0.22698178887367249, \"specificity\": 1.0, \"npv\": 0.4217311143875122, \"accuracy\": 0.505667507648468, \"f1\": 0.36998394863563405, \"f2\": 0.2684915550378567, \"f0_5\": 0.5948387096774194, \"p4\": 0.4557459851493697, \"phi\": 0.3093950259280176}, {\"truth_threshold\": 8.96396140687601, \"match_probability\": 0.9980014734642725, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 452.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1579.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.22255046665668488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7774495482444763, \"precision\": 1.0, \"recall\": 0.22255046665668488, \"specificity\": 1.0, \"npv\": 0.4203377366065979, \"accuracy\": 0.5028337240219116, \"f1\": 0.36407571486105517, \"f2\": 0.2635261194029851, \"f0_5\": 0.5886949726491274, \"p4\": 0.45083619294559046, \"phi\": 0.30585349490031105}, {\"truth_threshold\": 8.972209594181436, \"match_probability\": 0.9980128442150522, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 447.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1584.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2200886309146881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7799113988876343, \"precision\": 1.0, \"recall\": 0.2200886309146881, \"specificity\": 1.0, \"npv\": 0.41956761479377747, \"accuracy\": 0.501259446144104, \"f1\": 0.36077481840193704, \"f2\": 0.2607630381519076, \"f0_5\": 0.5852317360565593, \"p4\": 0.4480773422911157, \"phi\": 0.30387836102876703}, {\"truth_threshold\": 9.053250369641816, \"match_probability\": 0.9981211878706531, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 446.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1585.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2195962518453598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.780403733253479, \"precision\": 1.0, \"recall\": 0.2195962518453598, \"specificity\": 1.0, \"npv\": 0.4194139242172241, \"accuracy\": 0.5009445548057556, \"f1\": 0.3601130399677029, \"f2\": 0.2602100350058343, \"f0_5\": 0.5845347313237221, \"p4\": 0.44752284794436964, \"phi\": 0.3034826638488981}, {\"truth_threshold\": 9.097060780445403, \"match_probability\": 0.9981772818675431, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 443.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1588.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.21811915934085846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7818808555603027, \"precision\": 1.0, \"recall\": 0.21811915934085846, \"specificity\": 1.0, \"npv\": 0.418953537940979, \"accuracy\": 0.5, \"f1\": 0.3581244947453517, \"f2\": 0.25855025096299755, \"f0_5\": 0.5824349198001578, \"p4\": 0.4458538540579834, \"phi\": 0.30229420994007733}, {\"truth_threshold\": 9.103904610696803, \"match_probability\": 0.9981858923193401, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 442.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1589.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.21762678027153015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7823731899261475, \"precision\": 1.0, \"recall\": 0.21762678027153015, \"specificity\": 1.0, \"npv\": 0.4188002943992615, \"accuracy\": 0.499685138463974, \"f1\": 0.35746057420137484, \"f2\": 0.2579967312631333, \"f0_5\": 0.5817320347459858, \"p4\": 0.4452956741191302, \"phi\": 0.3018976004691563}, {\"truth_threshold\": 9.121194310438364, \"match_probability\": 0.998207464647958, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 438.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1593.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2156573086977005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7843427062034607, \"precision\": 1.0, \"recall\": 0.2156573086977005, \"specificity\": 1.0, \"npv\": 0.4181884527206421, \"accuracy\": 0.49842569231987, \"f1\": 0.35479951397326853, \"f2\": 0.255781359495445, \"f0_5\": 0.5789056304520223, \"p4\": 0.443053616590459, \"phi\": 0.3003088389983756}, {\"truth_threshold\": 9.156033522364082, \"match_probability\": 0.9982501587250251, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 435.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1596.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.21418020129203796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7858197689056396, \"precision\": 1.0, \"recall\": 0.21418020129203796, \"specificity\": 1.0, \"npv\": 0.41773074865341187, \"accuracy\": 0.497481107711792, \"f1\": 0.35279805352798055, \"f2\": 0.2541184717840869, \"f0_5\": 0.5767700875099443, \"p4\": 0.44136216819746654, \"phi\": 0.29911479323661816}, {\"truth_threshold\": 9.193987437961132, \"match_probability\": 0.9982955152439281, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 434.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1597.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.21368783712387085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7863121628761292, \"precision\": 1.0, \"recall\": 0.21368783712387085, \"specificity\": 1.0, \"npv\": 0.41757839918136597, \"accuracy\": 0.497166246175766, \"f1\": 0.35212981744421906, \"f2\": 0.25356391680299134, \"f0_5\": 0.5760552163525352, \"p4\": 0.4407964459882871, \"phi\": 0.29871629989231974}, {\"truth_threshold\": 9.202674329306625, \"match_probability\": 0.9983057302748262, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 433.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1598.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.21319547295570374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7868045568466187, \"precision\": 1.0, \"recall\": 0.21319547295570374, \"specificity\": 1.0, \"npv\": 0.4174261689186096, \"accuracy\": 0.49685138463974, \"f1\": 0.351461038961039, \"f2\": 0.2530092322075494, \"f0_5\": 0.5753388254052617, \"p4\": 0.4402297646235646, \"phi\": 0.2983175653750679}, {\"truth_threshold\": 9.299600986822353, \"match_probability\": 0.998415644875394, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 432.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1599.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.21270310878753662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7872968912124634, \"precision\": 1.0, \"recall\": 0.21270310878753662, \"specificity\": 1.0, \"npv\": 0.4172740578651428, \"accuracy\": 0.496536523103714, \"f1\": 0.3507917174177832, \"f2\": 0.25245441795231416, \"f0_5\": 0.5746209098164405, \"p4\": 0.43966212040710345, \"phi\": 0.29791858839778124}, {\"truth_threshold\": 9.309352781904286, \"match_probability\": 0.998426301302267, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 424.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1607.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20876415073871613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7912358641624451, \"precision\": 1.0, \"recall\": 0.20876415073871613, \"specificity\": 1.0, \"npv\": 0.41606104373931885, \"accuracy\": 0.494017630815506, \"f1\": 0.34541751527494907, \"f2\": 0.24801123069723913, \"f0_5\": 0.5688221089348001, \"p4\": 0.4350858545789968, \"phi\": 0.2947178872213523}, {\"truth_threshold\": 9.398370705432175, \"match_probability\": 0.9985203281281476, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 423.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1608.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.208271786570549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7917281985282898, \"precision\": 1.0, \"recall\": 0.208271786570549, \"specificity\": 1.0, \"npv\": 0.41590991616249084, \"accuracy\": 0.49370276927948, \"f1\": 0.34474327628361856, \"f2\": 0.24745524745524747, \"f0_5\": 0.5680902497985496, \"p4\": 0.4345093754121171, \"phi\": 0.29431666900557957}, {\"truth_threshold\": 9.408410796892387, \"match_probability\": 0.9985305747240126, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 422.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1609.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2077794224023819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7922205924987793, \"precision\": 1.0, \"recall\": 0.2077794224023819, \"specificity\": 1.0, \"npv\": 0.4157589077949524, \"accuracy\": 0.493387907743454, \"f1\": 0.3440684875662454, \"f2\": 0.24689913409782355, \"f0_5\": 0.5673568163484808, \"p4\": 0.43393189544018573, \"phi\": 0.29391519506245145}, {\"truth_threshold\": 9.508683138682253, \"match_probability\": 0.9986291012710476, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 421.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1610.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2072870433330536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.792712926864624, \"precision\": 1.0, \"recall\": 0.2072870433330536, \"specificity\": 1.0, \"npv\": 0.4156079888343811, \"accuracy\": 0.493073046207428, \"f1\": 0.3433931484502447, \"f2\": 0.24634289057928613, \"f0_5\": 0.566621803499327, \"p4\": 0.4333534107662987, \"phi\": 0.29351346402423234}, {\"truth_threshold\": 9.534578263810406, \"match_probability\": 0.9986534553597176, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 419.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1612.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20630231499671936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.793697714805603, \"precision\": 1.0, \"recall\": 0.20630231499671936, \"specificity\": 1.0, \"npv\": 0.4153064787387848, \"accuracy\": 0.492443323135376, \"f1\": 0.3420408163265306, \"f2\": 0.24523001287603885, \"f0_5\": 0.5651470191529538, \"p4\": 0.4321934116303184, \"phi\": 0.2927092251529637}, {\"truth_threshold\": 9.549130256262284, \"match_probability\": 0.9986669512302524, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 418.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1613.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20580995082855225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7941900491714478, \"precision\": 1.0, \"recall\": 0.20580995082855225, \"specificity\": 1.0, \"npv\": 0.41515591740608215, \"accuracy\": 0.49212846159935, \"f1\": 0.34136382196815024, \"f2\": 0.24467337859985952, \"f0_5\": 0.5644072373751012, \"p4\": 0.4316118892793445, \"phi\": 0.2923067145456299}, {\"truth_threshold\": 9.61712245332404, \"match_probability\": 0.998728240472344, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 417.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1614.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20531757175922394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7946824431419373, \"precision\": 1.0, \"recall\": 0.20531757175922394, \"specificity\": 1.0, \"npv\": 0.4150054454803467, \"accuracy\": 0.491813600063324, \"f1\": 0.34068627450980393, \"f2\": 0.24411661397962767, \"f0_5\": 0.5636658556366586, \"p4\": 0.43102934644841895, \"phi\": 0.29190394129450276}, {\"truth_threshold\": 9.87178630207738, \"match_probability\": 0.9989338141200835, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 416.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1615.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20482520759105682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.795174777507782, \"precision\": 1.0, \"recall\": 0.20482520759105682, \"specificity\": 1.0, \"npv\": 0.41485506296157837, \"accuracy\": 0.491498738527298, \"f1\": 0.340008173273396, \"f2\": 0.24355971896955503, \"f0_5\": 0.5629228687415426, \"p4\": 0.43044577914486043, \"phi\": 0.29150090399263207}, {\"truth_threshold\": 9.96104888545993, \"match_probability\": 0.9989977178560234, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 415.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1616.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2043328434228897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7956671714782715, \"precision\": 1.0, \"recall\": 0.2043328434228897, \"specificity\": 1.0, \"npv\": 0.414704829454422, \"accuracy\": 0.491183876991272, \"f1\": 0.339329517579722, \"f2\": 0.24300269352383183, \"f0_5\": 0.5621782714711461, \"p4\": 0.429861183356477, \"phi\": 0.29109760122502143}, {\"truth_threshold\": 9.970777331992185, \"match_probability\": 0.999004447047992, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 414.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1617.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2038404792547226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7961595058441162, \"precision\": 1.0, \"recall\": 0.2038404792547226, \"specificity\": 1.0, \"npv\": 0.4145546853542328, \"accuracy\": 0.49086901545524597, \"f1\": 0.33865030674846625, \"f2\": 0.24244553759662685, \"f0_5\": 0.5614320585842149, \"p4\": 0.42927555505144527, \"phi\": 0.29069403156855866}, {\"truth_threshold\": 9.992564477147118, \"match_probability\": 0.9990193540012281, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 413.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1618.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2033481001853943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7966518998146057, \"precision\": 1.0, \"recall\": 0.2033481001853943, \"specificity\": 1.0, \"npv\": 0.41440463066101074, \"accuracy\": 0.49055415391921997, \"f1\": 0.33797054009819966, \"f2\": 0.2418882511420874, \"f0_5\": 0.5606842248167255, \"p4\": 0.4286888901781894, \"phi\": 0.29029019359194574}, {\"truth_threshold\": 10.015912080400023, \"match_probability\": 0.9990350811987044, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 411.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1620.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20236337184906006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7976366281509399, \"precision\": 1.0, \"recall\": 0.20236337184906006, \"specificity\": 1.0, \"npv\": 0.4141048789024353, \"accuracy\": 0.48992443084716797, \"f1\": 0.3366093366093366, \"f2\": 0.24077328646748683, \"f0_5\": 0.5591836734693878, \"p4\": 0.42751243442120324, \"phi\": 0.2894817069117195}, {\"truth_threshold\": 10.023443782704895, \"match_probability\": 0.9990401006836434, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 410.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1621.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20187099277973175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7981290221214294, \"precision\": 1.0, \"recall\": 0.20187099277973175, \"specificity\": 1.0, \"npv\": 0.4139551818370819, \"accuracy\": 0.48960956931114197, \"f1\": 0.33592789840229414, \"f2\": 0.24021560815561285, \"f0_5\": 0.5584309452465268, \"p4\": 0.4269226353344527, \"phi\": 0.2890770553039368}, {\"truth_threshold\": 10.02611635698417, \"match_probability\": 0.9990418755367695, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 409.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1622.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20137862861156464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7986213564872742, \"precision\": 1.0, \"recall\": 0.20137862861156464, \"specificity\": 1.0, \"npv\": 0.4138055741786957, \"accuracy\": 0.48929470777511597, \"f1\": 0.33524590163934426, \"f2\": 0.23965779913277863, \"f0_5\": 0.5576765748568312, \"p4\": 0.4263317832731881, \"phi\": 0.28867212956751886}, {\"truth_threshold\": 10.047523784953354, \"match_probability\": 0.9990559743821557, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 408.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1623.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.20088626444339752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7991137504577637, \"precision\": 1.0, \"recall\": 0.20088626444339752, \"specificity\": 1.0, \"npv\": 0.4136560559272766, \"accuracy\": 0.48897984623908997, \"f1\": 0.33456334563345635, \"f2\": 0.2390998593530239, \"f0_5\": 0.556920556920557, \"p4\": 0.4257398740852177, \"phi\": 0.28826692822915634}, {\"truth_threshold\": 10.077407424904614, \"match_probability\": 0.9990753096766196, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 407.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1624.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.2003939002752304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7996060848236084, \"precision\": 1.0, \"recall\": 0.2003939002752304, \"specificity\": 1.0, \"npv\": 0.4135066866874695, \"accuracy\": 0.48866498470306396, \"f1\": 0.3338802296964725, \"f2\": 0.23854178877036689, \"f0_5\": 0.5561628860344356, \"p4\": 0.4251469035978495, \"phi\": 0.28786144980691586}, {\"truth_threshold\": 10.078973977822914, \"match_probability\": 0.999076312281323, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 406.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1625.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1999015212059021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8000984787940979, \"precision\": 1.0, \"recall\": 0.1999015212059021, \"specificity\": 1.0, \"npv\": 0.4133574068546295, \"accuracy\": 0.48835012316703796, \"f1\": 0.33319655313910546, \"f2\": 0.23798358733880423, \"f0_5\": 0.5554035567715458, \"p4\": 0.4245528676177636, \"phi\": 0.287455692810164}, {\"truth_threshold\": 10.093416136348798, \"match_probability\": 0.9990855043539675, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 405.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1626.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19940915703773499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8005908131599426, \"precision\": 1.0, \"recall\": 0.19940915703773499, \"specificity\": 1.0, \"npv\": 0.4132082164287567, \"accuracy\": 0.48803526163101196, \"f1\": 0.33251231527093594, \"f2\": 0.23742525501231093, \"f0_5\": 0.5546425636811833, \"p4\": 0.42395776193088314, \"phi\": 0.2870496557394907}, {\"truth_threshold\": 10.098178026008341, \"match_probability\": 0.9990885150981718, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 404.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1627.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19891679286956787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8010832071304321, \"precision\": 1.0, \"recall\": 0.19891679286956787, \"specificity\": 1.0, \"npv\": 0.41305917501449585, \"accuracy\": 0.48772040009498596, \"f1\": 0.33182751540041067, \"f2\": 0.23686679174484052, \"f0_5\": 0.5538799012887304, \"p4\": 0.4233615823022448, \"phi\": 0.28664333708663187}, {\"truth_threshold\": 10.115077032969287, \"match_probability\": 0.9990991199262035, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 401.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1630.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19743968546390533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8025603294372559, \"precision\": 1.0, \"recall\": 0.19743968546390533, \"specificity\": 1.0, \"npv\": 0.4126126170158386, \"accuracy\": 0.48677581548690796, \"f1\": 0.32976973684210525, \"f2\": 0.23519061583577713, \"f0_5\": 0.5515818431911967, \"p4\": 0.4215665571000973, \"phi\": 0.2854226764178335}, {\"truth_threshold\": 10.153408355885716, \"match_probability\": 0.9991227197315097, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 400.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1631.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19694732129573822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8030526638031006, \"precision\": 1.0, \"recall\": 0.19694732129573822, \"specificity\": 1.0, \"npv\": 0.4124639630317688, \"accuracy\": 0.48646095395088196, \"f1\": 0.3290826820238585, \"f2\": 0.2346316283435007, \"f0_5\": 0.5508124483613329, \"p4\": 0.42096603893246504, \"phi\": 0.2850152161737426}, {\"truth_threshold\": 10.157669932113139, \"match_probability\": 0.9991253050423605, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 399.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1632.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1964549422264099, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8035450577735901, \"precision\": 1.0, \"recall\": 0.1964549422264099, \"specificity\": 1.0, \"npv\": 0.4123154580593109, \"accuracy\": 0.48614609241485596, \"f1\": 0.32839506172839505, \"f2\": 0.23407250967969026, \"f0_5\": 0.5500413564929694, \"p4\": 0.42036442533034846, \"phi\": 0.28460746667055603}, {\"truth_threshold\": 10.183020973765835, \"match_probability\": 0.9991405278354277, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 398.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1633.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1959625780582428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8040373921394348, \"precision\": 1.0, \"recall\": 0.1959625780582428, \"specificity\": 1.0, \"npv\": 0.4121670126914978, \"accuracy\": 0.48583123087882996, \"f1\": 0.3277068752573075, \"f2\": 0.23351325979816945, \"f0_5\": 0.5492685619652222, \"p4\": 0.4197617119306842, \"phi\": 0.28419942634520623}, {\"truth_threshold\": 10.188260853272668, \"match_probability\": 0.9991436411145858, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 397.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1634.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19547021389007568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8045297861099243, \"precision\": 1.0, \"recall\": 0.19547021389007568, \"specificity\": 1.0, \"npv\": 0.41201871633529663, \"accuracy\": 0.48551636934280396, \"f1\": 0.3270181219110379, \"f2\": 0.23295387865274028, \"f0_5\": 0.548494059132357, \"p4\": 0.41915789434858625, \"phi\": 0.2837910936252034}, {\"truth_threshold\": 10.255814101288603, \"match_probability\": 0.9991827832345642, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 395.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1636.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19448547065258026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8055145144462585, \"precision\": 1.0, \"recall\": 0.19448547065258026, \"specificity\": 1.0, \"npv\": 0.4117223918437958, \"accuracy\": 0.48488664627075195, \"f1\": 0.325638911788953, \"f2\": 0.2318347223852565, \"f0_5\": 0.5469399058432567, \"p4\": 0.4179469289876032, \"phi\": 0.2829735446636596}, {\"truth_threshold\": 10.260510207561888, \"match_probability\": 0.9991854368629131, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 394.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1637.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19399310648441315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.806006908416748, \"precision\": 1.0, \"recall\": 0.19399310648441315, \"specificity\": 1.0, \"npv\": 0.4115743935108185, \"accuracy\": 0.48457178473472595, \"f1\": 0.3249484536082474, \"f2\": 0.23127494717069735, \"f0_5\": 0.5461602439700582, \"p4\": 0.4173397723285867, \"phi\": 0.28256432522926045}, {\"truth_threshold\": 10.293874402133891, \"match_probability\": 0.9992040437151066, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 393.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1638.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19350074231624603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8064992427825928, \"precision\": 1.0, \"recall\": 0.19350074231624603, \"specificity\": 1.0, \"npv\": 0.41142651438713074, \"accuracy\": 0.48425692319869995, \"f1\": 0.32425742574257427, \"f2\": 0.23071504050722086, \"f0_5\": 0.5453788509575354, \"p4\": 0.4167314937265928, \"phi\": 0.2821548070143172}, {\"truth_threshold\": 10.336560718848668, \"match_probability\": 0.9992272314609512, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 392.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1639.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.19300836324691772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8069916367530823, \"precision\": 1.0, \"recall\": 0.19300836324691772, \"specificity\": 1.0, \"npv\": 0.41127872467041016, \"accuracy\": 0.48394206166267395, \"f1\": 0.32356582748658685, \"f2\": 0.23015500234852043, \"f0_5\": 0.5445957210336204, \"p4\": 0.4161220886855334, \"phi\": 0.2817449883979377}, {\"truth_threshold\": 10.361427650149825, \"match_probability\": 0.9992404270753056, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 391.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1640.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1925159990787506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.807483971118927, \"precision\": 1.0, \"recall\": 0.1925159990787506, \"specificity\": 1.0, \"npv\": 0.4111310541629791, \"accuracy\": 0.48362720012664795, \"f1\": 0.3228736581337737, \"f2\": 0.22959483264826777, \"f0_5\": 0.5438108484005564, \"p4\": 0.41551155268665513, \"phi\": 0.2813348677492837}, {\"truth_threshold\": 10.406158912213018, \"match_probability\": 0.9992635994651266, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 384.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1647.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18906942009925842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8109305500984192, \"precision\": 1.0, \"recall\": 0.18906942009925842, \"specificity\": 1.0, \"npv\": 0.4101002812385559, \"accuracy\": 0.48142316937446594, \"f1\": 0.31801242236024846, \"f2\": 0.22566995768688294, \"f0_5\": 0.5382674516400336, \"p4\": 0.41120574947340216, \"phi\": 0.27845542718349653}, {\"truth_threshold\": 10.434659830138438, \"match_probability\": 0.9992779941437758, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 381.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1650.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1875923126935959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8124076724052429, \"precision\": 1.0, \"recall\": 0.1875923126935959, \"specificity\": 1.0, \"npv\": 0.40966010093688965, \"accuracy\": 0.48047858476638794, \"f1\": 0.31592039800995025, \"f2\": 0.2239858906525573, \"f0_5\": 0.5358649789029536, \"p4\": 0.4093429793942124, \"phi\": 0.27721668340679234}, {\"truth_threshold\": 10.48461481431855, \"match_probability\": 0.9993025494143464, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 379.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1652.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18660758435726166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8133924007415771, \"precision\": 1.0, \"recall\": 0.18660758435726166, \"specificity\": 1.0, \"npv\": 0.409367173910141, \"accuracy\": 0.47984886169433594, \"f1\": 0.3145228215767635, \"f2\": 0.22286251911090205, \"f0_5\": 0.5342542994079503, \"p4\": 0.40809522958677485, \"phi\": 0.27638925384126056}, {\"truth_threshold\": 10.547313041236377, \"match_probability\": 0.9993321909837453, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 378.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1653.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18611522018909454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8138847947120667, \"precision\": 1.0, \"recall\": 0.18611522018909454, \"specificity\": 1.0, \"npv\": 0.4092208743095398, \"accuracy\": 0.47953400015830994, \"f1\": 0.3138231631382316, \"f2\": 0.22230063514467185, \"f0_5\": 0.5334462320067739, \"p4\": 0.4074695693495442, \"phi\": 0.2759750536712865}, {\"truth_threshold\": 10.591453681234947, \"match_probability\": 0.9993523007995541, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 377.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1654.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18562284111976624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8143771290779114, \"precision\": 1.0, \"recall\": 0.18562284111976624, \"specificity\": 1.0, \"npv\": 0.40907466411590576, \"accuracy\": 0.47921913862228394, \"f1\": 0.3131229235880399, \"f2\": 0.22173861898600164, \"f0_5\": 0.532636337948573, \"p4\": 0.4068427124292656, \"phi\": 0.27556052754011884}, {\"truth_threshold\": 10.628697236398853, \"match_probability\": 0.9993687969300661, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 376.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1655.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18513047695159912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8148695230484009, \"precision\": 1.0, \"recall\": 0.18513047695159912, \"specificity\": 1.0, \"npv\": 0.4089285731315613, \"accuracy\": 0.47890427708625793, \"f1\": 0.3124221022019111, \"f2\": 0.2211764705882353, \"f0_5\": 0.5318246110325319, \"p4\": 0.40621465394926326, \"phi\": 0.27514567365621}, {\"truth_threshold\": 10.69706723009617, \"match_probability\": 0.9993979946209873, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 373.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1658.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18365336954593658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8163466453552246, \"precision\": 1.0, \"recall\": 0.18365336954593658, \"specificity\": 1.0, \"npv\": 0.4084908962249756, \"accuracy\": 0.47795969247817993, \"f1\": 0.3103161397670549, \"f2\": 0.21948923149346827, \"f0_5\": 0.529378370706784, \"p4\": 0.40432322000651333, \"phi\": 0.27389912739888156}, {\"truth_threshold\": 10.71699191500307, \"match_probability\": 0.9994062467088258, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 371.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1660.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18266864120960236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8173313736915588, \"precision\": 1.0, \"recall\": 0.18266864120960236, \"specificity\": 1.0, \"npv\": 0.40819963812828064, \"accuracy\": 0.47732996940612793, \"f1\": 0.3089092422980849, \"f2\": 0.2183637433784579, \"f0_5\": 0.5277382645803699, \"p4\": 0.4030561657028185, \"phi\": 0.27306642442777773}, {\"truth_threshold\": 10.717247502136383, \"match_probability\": 0.9994063518261057, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 370.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1661.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18217626214027405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8178237080574036, \"precision\": 1.0, \"recall\": 0.18217626214027405, \"specificity\": 1.0, \"npv\": 0.4080541729927063, \"accuracy\": 0.47701510787010193, \"f1\": 0.3082049146189088, \"f2\": 0.21780080056510479, \"f0_5\": 0.5269154087154657, \"p4\": 0.40242079403659214, \"phi\": 0.2726495657512296}, {\"truth_threshold\": 10.802090449893878, \"match_probability\": 0.9994402377726677, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 369.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1662.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.18168389797210693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8183161020278931, \"precision\": 1.0, \"recall\": 0.18168389797210693, \"specificity\": 1.0, \"npv\": 0.4079087972640991, \"accuracy\": 0.4767002463340759, \"f1\": 0.3075, \"f2\": 0.21723772518544684, \"f0_5\": 0.5260906757912746, \"p4\": 0.40178418596158894, \"phi\": 0.27223236645190135}, {\"truth_threshold\": 10.807330329400711, \"match_probability\": 0.9994422660139606, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 367.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1664.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1806991696357727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8193008303642273, \"precision\": 1.0, \"recall\": 0.1806991696357727, \"specificity\": 1.0, \"npv\": 0.40761837363243103, \"accuracy\": 0.4760705232620239, \"f1\": 0.3060884070058382, \"f2\": 0.21611117653986575, \"f0_5\": 0.5244355530151472, \"p4\": 0.4005072402300023, \"phi\": 0.2713969384245707}, {\"truth_threshold\": 10.827880164615744, \"match_probability\": 0.9994501497607049, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 366.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1665.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1802067905664444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8197932243347168, \"precision\": 1.0, \"recall\": 0.1802067905664444, \"specificity\": 1.0, \"npv\": 0.40747329592704773, \"accuracy\": 0.4757556617259979, \"f1\": 0.3053817271589487, \"f2\": 0.21554770318021202, \"f0_5\": 0.5236051502145923, \"p4\": 0.3998668923294916, \"phi\": 0.2709787058851553}, {\"truth_threshold\": 10.878534405670731, \"match_probability\": 0.999469110407717, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 365.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1666.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17971442639827728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8202855587005615, \"precision\": 1.0, \"recall\": 0.17971442639827728, \"specificity\": 1.0, \"npv\": 0.40732836723327637, \"accuracy\": 0.4754408001899719, \"f1\": 0.3046744574290484, \"f2\": 0.2149840970667923, \"f0_5\": 0.5227728444571756, \"p4\": 0.3992252875320011, \"phi\": 0.27056012509989086}, {\"truth_threshold\": 10.89539859138706, \"match_probability\": 0.9994752768016286, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 364.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1667.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17922206223011017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.820777952671051, \"precision\": 1.0, \"recall\": 0.17922206223011017, \"specificity\": 1.0, \"npv\": 0.4071834981441498, \"accuracy\": 0.4751259386539459, \"f1\": 0.30396659707724427, \"f2\": 0.21442035815268615, \"f0_5\": 0.5219386291941497, \"p4\": 0.39858242064847826, \"phi\": 0.2701411941312753}, {\"truth_threshold\": 10.912943878261933, \"match_probability\": 0.9994816162702662, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 363.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1668.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17872968316078186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8212702870368958, \"precision\": 1.0, \"recall\": 0.17872968316078186, \"specificity\": 1.0, \"npv\": 0.40703874826431274, \"accuracy\": 0.4748110771179199, \"f1\": 0.3032581453634085, \"f2\": 0.21385648639095087, \"f0_5\": 0.5211024978466839, \"p4\": 0.3979382864627165, \"phi\": 0.2697219110288642}, {\"truth_threshold\": 11.006286840999733, \"match_probability\": 0.999514078141626, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 360.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1671.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17725259065628052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8227474093437195, \"precision\": 1.0, \"recall\": 0.17725259065628052, \"specificity\": 1.0, \"npv\": 0.4066051244735718, \"accuracy\": 0.4738664925098419, \"f1\": 0.30112923462986196, \"f2\": 0.21216407355021216, \"f0_5\": 0.5185825410544511, \"p4\": 0.3959982275188506, \"phi\": 0.268461929217603}, {\"truth_threshold\": 11.019622330859594, \"match_probability\": 0.9995185468918627, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 359.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1672.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1767602115869522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.823239803314209, \"precision\": 1.0, \"recall\": 0.1767602115869522, \"specificity\": 1.0, \"npv\": 0.4064607620239258, \"accuracy\": 0.4735516309738159, \"f1\": 0.300418410041841, \"f2\": 0.21159966992809148, \"f0_5\": 0.5177386789731756, \"p4\": 0.39534897141268815, \"phi\": 0.2680412178122442}, {\"truth_threshold\": 11.034277412948622, \"match_probability\": 0.9995234104794263, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 358.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1673.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1762678474187851, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8237321376800537, \"precision\": 1.0, \"recall\": 0.1762678474187851, \"specificity\": 1.0, \"npv\": 0.4063165485858917, \"accuracy\": 0.4732367694377899, \"f1\": 0.29970699037254084, \"f2\": 0.2110351332232964, \"f0_5\": 0.5168928674559631, \"p4\": 0.3946984215096245, \"phi\": 0.2676201443222353}, {\"truth_threshold\": 11.074230781796281, \"match_probability\": 0.9995364218269017, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 357.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1674.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17577548325061798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8242245316505432, \"precision\": 1.0, \"recall\": 0.17577548325061798, \"specificity\": 1.0, \"npv\": 0.40617239475250244, \"accuracy\": 0.4729219079017639, \"f1\": 0.2989949748743719, \"f2\": 0.21047046338875133, \"f0_5\": 0.5160450997398092, \"p4\": 0.39404657242671726, \"phi\": 0.26719870671675655}, {\"truth_threshold\": 11.108825499378229, \"match_probability\": 0.9995474008830364, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 356.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1675.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17528311908245087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8247168660163879, \"precision\": 1.0, \"recall\": 0.17528311908245087, \"specificity\": 1.0, \"npv\": 0.4060283601284027, \"accuracy\": 0.4726070463657379, \"f1\": 0.29828236279849185, \"f2\": 0.2099056603773585, \"f0_5\": 0.5151953690303908, \"p4\": 0.39339341875258615, \"phi\": 0.26677690295112333}, {\"truth_threshold\": 11.14702390931905, \"match_probability\": 0.9995592219378437, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 355.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1676.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17479074001312256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8252092599868774, \"precision\": 1.0, \"recall\": 0.17479074001312256, \"specificity\": 1.0, \"npv\": 0.40588444471359253, \"accuracy\": 0.4722921848297119, \"f1\": 0.297569153394803, \"f2\": 0.20934072414199786, \"f0_5\": 0.5143436685018835, \"p4\": 0.39273895504722334, \"phi\": 0.2663547309666478}, {\"truth_threshold\": 11.215740703294742, \"match_probability\": 0.9995797158042299, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 353.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1678.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17380601167678833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8261939883232117, \"precision\": 1.0, \"recall\": 0.17380601167678833, \"specificity\": 1.0, \"npv\": 0.40559688210487366, \"accuracy\": 0.4716624617576599, \"f1\": 0.2961409395973154, \"f2\": 0.20821045181078213, \"f0_5\": 0.5126343305257043, \"p4\": 0.39142607563848786, \"phi\": 0.265509274035558}, {\"truth_threshold\": 11.25263745818027, \"match_probability\": 0.9995903238908109, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 352.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1679.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17331363260746002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8266863822937012, \"precision\": 1.0, \"recall\": 0.17331363260746002, \"specificity\": 1.0, \"npv\": 0.40545326471328735, \"accuracy\": 0.4713476002216339, \"f1\": 0.2954259336970206, \"f2\": 0.20764511562057575, \"f0_5\": 0.5117766792672288, \"p4\": 0.3907676489102373, \"phi\": 0.26508598490027957}, {\"truth_threshold\": 11.290361729117205, \"match_probability\": 0.9996008932314312, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 350.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1681.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1723289042711258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8276711106300354, \"precision\": 1.0, \"recall\": 0.1723289042711258, \"specificity\": 1.0, \"npv\": 0.40516629815101624, \"accuracy\": 0.4707178771495819, \"f1\": 0.2939941201175976, \"f2\": 0.20651404295492093, \"f0_5\": 0.5100553774409793, \"p4\": 0.389446793623568, \"phi\": 0.26423827470949746}, {\"truth_threshold\": 11.346294240438672, \"match_probability\": 0.9996160644553082, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 349.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1682.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17183654010295868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8281634449958801, \"precision\": 1.0, \"recall\": 0.17183654010295868, \"specificity\": 1.0, \"npv\": 0.4050229787826538, \"accuracy\": 0.4704030156135559, \"f1\": 0.29327731092436976, \"f2\": 0.2059483063849876, \"f0_5\": 0.509191712868398, \"p4\": 0.38878435386327725, \"phi\": 0.26381384937743096}, {\"truth_threshold\": 11.359435312214265, \"match_probability\": 0.9996195444043231, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 348.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1683.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17134416103363037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8286558389663696, \"precision\": 1.0, \"recall\": 0.17134416103363037, \"specificity\": 1.0, \"npv\": 0.40487977862358093, \"accuracy\": 0.4700881540775299, \"f1\": 0.29255989911727615, \"f2\": 0.20538243626062322, \"f0_5\": 0.5083260297984225, \"p4\": 0.38812056517390836, \"phi\": 0.2633890410116}, {\"truth_threshold\": 11.395975277978426, \"match_probability\": 0.999629055887398, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 346.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1685.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.17035943269729614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8296405673027039, \"precision\": 1.0, \"recall\": 0.17035943269729614, \"specificity\": 1.0, \"npv\": 0.40459364652633667, \"accuracy\": 0.4694584310054779, \"f1\": 0.29112326461926796, \"f2\": 0.20425029515938606, \"f0_5\": 0.5065885797950219, \"p4\": 0.3867889182734259, \"phi\": 0.262538266459636}, {\"truth_threshold\": 11.41423818123522, \"match_probability\": 0.9996337203188891, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 344.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1687.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16937468945980072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8306252956390381, \"precision\": 1.0, \"recall\": 0.16937468945980072, \"specificity\": 1.0, \"npv\": 0.40430790185928345, \"accuracy\": 0.4688287079334259, \"f1\": 0.28968421052631577, \"f2\": 0.2031176192725555, \"f0_5\": 0.5048429703551511, \"p4\": 0.38545180714785676, \"phi\": 0.26168593346131325}, {\"truth_threshold\": 11.473948183139, \"match_probability\": 0.999648565191192, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 343.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1688.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1688823252916336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8311176896095276, \"precision\": 1.0, \"recall\": 0.1688823252916336, \"specificity\": 1.0, \"npv\": 0.40416520833969116, \"accuracy\": 0.4685138463973999, \"f1\": 0.2889637742207245, \"f2\": 0.20255108066611552, \"f0_5\": 0.5039670878636497, \"p4\": 0.38478118806157907, \"phi\": 0.26125917697884493}, {\"truth_threshold\": 11.487031308757988, \"match_probability\": 0.9996517366768654, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 342.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1689.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1683899611234665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8316100239753723, \"precision\": 1.0, \"recall\": 0.1683899611234665, \"specificity\": 1.0, \"npv\": 0.40402257442474365, \"accuracy\": 0.4681989848613739, \"f1\": 0.28824273072060685, \"f2\": 0.20198440822111977, \"f0_5\": 0.5030891438658429, \"p4\": 0.38410918552991574, \"phi\": 0.26083202417392587}, {\"truth_threshold\": 11.554347054158452, \"match_probability\": 0.9996676079894979, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 339.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1692.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16691285371780396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.833087146282196, \"precision\": 1.0, \"recall\": 0.16691285371780396, \"specificity\": 1.0, \"npv\": 0.40359535813331604, \"accuracy\": 0.4672544002532959, \"f1\": 0.28607594936708863, \"f2\": 0.20028358738036156, \"f0_5\": 0.5004428697962799, \"p4\": 0.3820848184886705, \"phi\": 0.2595481650395528}, {\"truth_threshold\": 11.56704973182694, \"match_probability\": 0.9996705208364086, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 338.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1693.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16642048954963684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8335795402526855, \"precision\": 1.0, \"recall\": 0.16642048954963684, \"specificity\": 1.0, \"npv\": 0.40345314145088196, \"accuracy\": 0.4669395387172699, \"f1\": 0.28535246939636977, \"f2\": 0.19971637910659418, \"f0_5\": 0.4995566065622229, \"p4\": 0.3814072232423753, \"phi\": 0.25911940407768985}, {\"truth_threshold\": 11.627560372735438, \"match_probability\": 0.9996840500329527, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 336.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1695.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16543574631214142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8345642685890198, \"precision\": 1.0, \"recall\": 0.16543574631214142, \"specificity\": 1.0, \"npv\": 0.40316900610923767, \"accuracy\": 0.4663098156452179, \"f1\": 0.28390367553865653, \"f2\": 0.19858156028368795, \"f0_5\": 0.49777777777777776, \"p4\": 0.38004778751227103, \"phi\": 0.2582606562838075}, {\"truth_threshold\": 11.643198109513866, \"match_probability\": 0.9996874551365419, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 335.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1696.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1649433821439743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8350566029548645, \"precision\": 1.0, \"recall\": 0.1649433821439743, \"specificity\": 1.0, \"npv\": 0.40302711725234985, \"accuracy\": 0.4659949541091919, \"f1\": 0.28317836010143704, \"f2\": 0.19801394963943728, \"f0_5\": 0.4968851972708395, \"p4\": 0.3793659349517108, \"phi\": 0.2578306647274206}, {\"truth_threshold\": 11.651461274894125, \"match_probability\": 0.9996892395938104, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 334.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1697.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.164451003074646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.835548996925354, \"precision\": 1.0, \"recall\": 0.164451003074646, \"specificity\": 1.0, \"npv\": 0.4028852880001068, \"accuracy\": 0.4656800925731659, \"f1\": 0.2824524312896406, \"f2\": 0.19744620477654293, \"f0_5\": 0.495990495990496, \"p4\": 0.37868265115483457, \"phi\": 0.25740025821966944}, {\"truth_threshold\": 11.73317392159666, \"match_probability\": 0.9997063465182843, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 333.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1698.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16395863890647888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8360413312911987, \"precision\": 1.0, \"recall\": 0.16395863890647888, \"specificity\": 1.0, \"npv\": 0.4027435779571533, \"accuracy\": 0.4653652310371399, \"f1\": 0.2817258883248731, \"f2\": 0.1968783256473927, \"f0_5\": 0.4950936663693131, \"p4\": 0.3779979300007138, \"phi\": 0.2569694343548615}, {\"truth_threshold\": 11.734147125111893, \"match_probability\": 0.999706544484165, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 332.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1699.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16346627473831177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8365337252616882, \"precision\": 1.0, \"recall\": 0.16346627473831177, \"specificity\": 1.0, \"npv\": 0.402601957321167, \"accuracy\": 0.4650503695011139, \"f1\": 0.2809987304274228, \"f2\": 0.19631031220435194, \"f0_5\": 0.49419470080381067, \"p4\": 0.3773117653349902, \"phi\": 0.25653819070956685}, {\"truth_threshold\": 11.774482041810266, \"match_probability\": 0.9997146329859533, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 330.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1701.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16248153150081635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8375184535980225, \"precision\": 1.0, \"recall\": 0.16248153150081635, \"specificity\": 1.0, \"npv\": 0.4023190438747406, \"accuracy\": 0.4644206464290619, \"f1\": 0.2795425667090216, \"f2\": 0.19517388218594747, \"f0_5\": 0.4923903312444047, \"p4\": 0.37593508068277215, \"phi\": 0.255674434293968}, {\"truth_threshold\": 11.928519989814369, \"match_probability\": 0.9997435242674628, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 329.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1702.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.16198916733264923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.838010847568512, \"precision\": 1.0, \"recall\": 0.16198916733264923, \"specificity\": 1.0, \"npv\": 0.40217772126197815, \"accuracy\": 0.4641057848930359, \"f1\": 0.2788135593220339, \"f2\": 0.1946054655152017, \"f0_5\": 0.4914849118613684, \"p4\": 0.37524454821833425, \"phi\": 0.255241916586396}, {\"truth_threshold\": 11.93041882299424, \"match_probability\": 0.999743861524893, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 327.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1704.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1610044240951538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8389955759048462, \"precision\": 1.0, \"recall\": 0.1610044240951538, \"specificity\": 1.0, \"npv\": 0.4018954038619995, \"accuracy\": 0.4634760618209839, \"f1\": 0.27735368956743, \"f2\": 0.19346822861199858, \"f0_5\": 0.48966756513926324, \"p4\": 0.3738590715605894, \"phi\": 0.254375589689992}, {\"truth_threshold\": 11.93235684981355, \"match_probability\": 0.9997442052864357, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 326.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1705.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1605120599269867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8394879102706909, \"precision\": 1.0, \"recall\": 0.1605120599269867, \"specificity\": 1.0, \"npv\": 0.40175437927246094, \"accuracy\": 0.4631612002849579, \"f1\": 0.2766228256257955, \"f2\": 0.19289940828402366, \"f0_5\": 0.48875562218890556, \"p4\": 0.37316411468245886, \"phi\": 0.2539417754522155}, {\"truth_threshold\": 11.949679303389834, \"match_probability\": 0.9997472574793033, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 324.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1707.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15952733159065247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8404726982116699, \"precision\": 1.0, \"recall\": 0.15952733159065247, \"specificity\": 1.0, \"npv\": 0.40147265791893005, \"accuracy\": 0.4625314772129059, \"f1\": 0.2751592356687898, \"f2\": 0.19176136363636365, \"f0_5\": 0.48692515779981965, \"p4\": 0.3717697318528885, \"phi\": 0.25307283263205194}, {\"truth_threshold\": 11.983011090868537, \"match_probability\": 0.9997530284362101, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 323.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1708.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15903495252132416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8409650325775146, \"precision\": 1.0, \"recall\": 0.15903495252132416, \"specificity\": 1.0, \"npv\": 0.40133193135261536, \"accuracy\": 0.4622166156768799, \"f1\": 0.27442650807136787, \"f2\": 0.1911921392210252, \"f0_5\": 0.48600662052362326, \"p4\": 0.37107029300541505, \"phi\": 0.25263769888536397}, {\"truth_threshold\": 12.055804218391305, \"match_probability\": 0.9997651777124806, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 322.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1709.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15854258835315704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8414574265480042, \"precision\": 1.0, \"recall\": 0.15854258835315704, \"specificity\": 1.0, \"npv\": 0.4011913239955902, \"accuracy\": 0.4619017541408539, \"f1\": 0.27369315767105823, \"f2\": 0.1906227800142079, \"f0_5\": 0.4850858692377222, \"p4\": 0.37036934721259873, \"phi\": 0.2522021201052885}, {\"truth_threshold\": 12.073093918132866, \"match_probability\": 0.9997679744498631, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 321.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1710.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15805022418498993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8419497609138489, \"precision\": 1.0, \"recall\": 0.15805022418498993, \"specificity\": 1.0, \"npv\": 0.40105077624320984, \"accuracy\": 0.4615868926048279, \"f1\": 0.2729591836734694, \"f2\": 0.19005328596802842, \"f0_5\": 0.4841628959276018, \"p4\": 0.369666887936757, \"phi\": 0.2517660936601759}, {\"truth_threshold\": 12.11076352619754, \"match_probability\": 0.9997739530111761, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 320.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1711.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15755786001682281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8424421548843384, \"precision\": 1.0, \"recall\": 0.15755786001682281, \"specificity\": 1.0, \"npv\": 0.4009103775024414, \"accuracy\": 0.4612720310688019, \"f1\": 0.27222458528285837, \"f2\": 0.18948365703458075, \"f0_5\": 0.48323769254001814, \"p4\": 0.36896290860388975, \"phi\": 0.25132961689818295}, {\"truth_threshold\": 12.126046439945254, \"match_probability\": 0.9997763344252977, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 319.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1712.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1570654809474945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8429344892501831, \"precision\": 1.0, \"recall\": 0.1570654809474945, \"specificity\": 1.0, \"npv\": 0.40077003836631775, \"accuracy\": 0.4609571695327759, \"f1\": 0.2714893617021277, \"f2\": 0.1889138931659363, \"f0_5\": 0.4823102509827638, \"p4\": 0.3682574026034257, \"phi\": 0.2508926871470492}, {\"truth_threshold\": 12.152020088251637, \"match_probability\": 0.9997803242938613, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 318.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1713.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1565731167793274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8434268832206726, \"precision\": 1.0, \"recall\": 0.1565731167793274, \"specificity\": 1.0, \"npv\": 0.40062981843948364, \"accuracy\": 0.4606423079967499, \"f1\": 0.2707535121328225, \"f2\": 0.18834399431414356, \"f0_5\": 0.48138056312443234, \"p4\": 0.3675503632879662, \"phi\": 0.25045530171386976}, {\"truth_threshold\": 12.157712567754496, \"match_probability\": 0.9997811891769537, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 317.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1714.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15608075261116028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8439192771911621, \"precision\": 1.0, \"recall\": 0.15608075261116028, \"specificity\": 1.0, \"npv\": 0.4004896879196167, \"accuracy\": 0.4603274464607239, \"f1\": 0.27001703577512776, \"f2\": 0.18777396043122851, \"f0_5\": 0.48044862079418005, \"p4\": 0.36684178397302697, \"phi\": 0.2500174578848653}, {\"truth_threshold\": 12.161417767252527, \"match_probability\": 0.9997817502940402, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 316.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1715.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15558837354183197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8444116115570068, \"precision\": 1.0, \"recall\": 0.15558837354183197, \"specificity\": 1.0, \"npv\": 0.4003496468067169, \"accuracy\": 0.4600125849246979, \"f1\": 0.26927993182786536, \"f2\": 0.1872037914691943, \"f0_5\": 0.4795144157814871, \"p4\": 0.366131657936778, \"phi\": 0.2495791529251488}, {\"truth_threshold\": 12.178707466994087, \"match_probability\": 0.9997843496942733, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 315.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1716.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15509600937366486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8449040055274963, \"precision\": 1.0, \"recall\": 0.15509600937366486, \"specificity\": 1.0, \"npv\": 0.4002097249031067, \"accuracy\": 0.4596977233886719, \"f1\": 0.26854219948849106, \"f2\": 0.18663348738002133, \"f0_5\": 0.4785779398359161, \"p4\": 0.36541997841978086, \"phi\": 0.2491403840784887}, {\"truth_threshold\": 12.217326686274424, \"match_probability\": 0.9997900446195762, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 314.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1717.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15460364520549774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8453963398933411, \"precision\": 1.0, \"recall\": 0.15460364520549774, \"specificity\": 1.0, \"npv\": 0.4000698924064636, \"accuracy\": 0.4593828618526459, \"f1\": 0.2678038379530917, \"f2\": 0.1860630481156672, \"f0_5\": 0.4776391846668695, \"p4\": 0.36470673862472397, \"phi\": 0.2487011485670688}, {\"truth_threshold\": 12.219647855110612, \"match_probability\": 0.9997903820768793, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 313.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1718.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15411128103733063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8458887338638306, \"precision\": 1.0, \"recall\": 0.15411128103733063, \"specificity\": 1.0, \"npv\": 0.3999301493167877, \"accuracy\": 0.4590680003166199, \"f1\": 0.26706484641638223, \"f2\": 0.18549247362806684, \"f0_5\": 0.4766981419433445, \"p4\": 0.3639919317161557, \"phi\": 0.24826144359124447}, {\"truth_threshold\": 12.22777716571865, \"match_probability\": 0.9997915596667187, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 312.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1719.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15361890196800232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8463810682296753, \"precision\": 1.0, \"recall\": 0.15361890196800232, \"specificity\": 1.0, \"npv\": 0.399790495634079, \"accuracy\": 0.45875313878059387, \"f1\": 0.26632522407170295, \"f2\": 0.18492176386913228, \"f0_5\": 0.4757548032936871, \"p4\": 0.36327555082021473, \"phi\": 0.2478212663292959}, {\"truth_threshold\": 12.231565087832829, \"match_probability\": 0.9997921061135975, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 311.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1720.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1531265377998352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8468734622001648, \"precision\": 1.0, \"recall\": 0.1531265377998352, \"specificity\": 1.0, \"npv\": 0.3996509611606598, \"accuracy\": 0.45843827724456787, \"f1\": 0.2655849701110162, \"f2\": 0.18435091879075283, \"f0_5\": 0.47480916030534354, \"p4\": 0.3625575890243592, \"phi\": 0.2473806139371772}, {\"truth_threshold\": 12.300960986022032, \"match_probability\": 0.9998018675036866, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 310.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1721.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1526341736316681, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8473658561706543, \"precision\": 1.0, \"recall\": 0.1526341736316681, \"specificity\": 1.0, \"npv\": 0.39951151609420776, \"accuracy\": 0.45812341570854187, \"f1\": 0.26484408372490387, \"f2\": 0.1837799383447949, \"f0_5\": 0.4738612045246102, \"p4\": 0.3618380393770922, \"phi\": 0.24693948354826198}, {\"truth_threshold\": 12.339893523681686, \"match_probability\": 0.9998071417859297, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 309.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1722.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15214180946350098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.847858190536499, \"precision\": 1.0, \"recall\": 0.15214180946350098, \"specificity\": 1.0, \"npv\": 0.3993721604347229, \"accuracy\": 0.45780855417251587, \"f1\": 0.2641025641025641, \"f2\": 0.1832088224831021, \"f0_5\": 0.472910927456382, \"p4\": 0.3611168948876859, \"phi\": 0.24649787227308553}, {\"truth_threshold\": 12.357114143378077, \"match_probability\": 0.9998094297027056, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 308.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1723.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.15164943039417267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8483505845069885, \"precision\": 1.0, \"recall\": 0.15164943039417267, \"specificity\": 1.0, \"npv\": 0.3992329239845276, \"accuracy\": 0.45749369263648987, \"f1\": 0.26336041043180847, \"f2\": 0.18263757115749527, \"f0_5\": 0.47195832056389825, \"p4\": 0.360394148525903, \"phi\": 0.24605577719908284}, {\"truth_threshold\": 12.406574534883253, \"match_probability\": 0.9998158511803913, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 304.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1727.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14967995882034302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.850320041179657, \"precision\": 1.0, \"recall\": 0.14967995882034302, \"specificity\": 1.0, \"npv\": 0.39867687225341797, \"accuracy\": 0.45623424649238586, \"f1\": 0.26038543897216276, \"f2\": 0.18035121025154247, \"f0_5\": 0.46812442254388664, \"p4\": 0.35748700235163144, \"phi\": 0.24428249984001416}, {\"truth_threshold\": 12.409971764216818, \"match_probability\": 0.9998162842206146, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 303.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1728.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1491875946521759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8508124351501465, \"precision\": 1.0, \"recall\": 0.1491875946521759, \"specificity\": 1.0, \"npv\": 0.39853811264038086, \"accuracy\": 0.45591938495635986, \"f1\": 0.2596401028277635, \"f2\": 0.17977928088287648, \"f0_5\": 0.4671600370027752, \"p4\": 0.3567561397717773, \"phi\": 0.24383794125607963}, {\"truth_threshold\": 12.415344231236162, \"match_probability\": 0.9998169669644622, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 302.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1729.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1486952304840088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8513047695159912, \"precision\": 1.0, \"recall\": 0.1486952304840088, \"specificity\": 1.0, \"npv\": 0.3983994424343109, \"accuracy\": 0.45560452342033386, \"f1\": 0.25889412773253323, \"f2\": 0.17920721576074056, \"f0_5\": 0.46619326952763196, \"p4\": 0.3560236322925244, \"phi\": 0.243392880897669}, {\"truth_threshold\": 12.424305066748872, \"match_probability\": 0.9998181000857573, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 301.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1730.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14820285141468048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8517971634864807, \"precision\": 1.0, \"recall\": 0.14820285141468048, \"specificity\": 1.0, \"npv\": 0.39826086163520813, \"accuracy\": 0.45528966188430786, \"f1\": 0.258147512864494, \"f2\": 0.17863501483679525, \"f0_5\": 0.4652241112828439, \"p4\": 0.35528947259906807, \"phi\": 0.24294731568285316}, {\"truth_threshold\": 12.450770925636478, \"match_probability\": 0.9998214059800263, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 300.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1731.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14771048724651337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8522894978523254, \"precision\": 1.0, \"recall\": 0.14771048724651337, \"specificity\": 1.0, \"npv\": 0.3981224000453949, \"accuracy\": 0.45497480034828186, \"f1\": 0.2574002574002574, \"f2\": 0.17806267806267806, \"f0_5\": 0.46425255338904364, \"p4\": 0.3545536533347784, \"phi\": 0.24250124250436372}, {\"truth_threshold\": 12.474127782899187, \"match_probability\": 0.9998242735870974, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 299.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1732.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14721812307834625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8527818918228149, \"precision\": 1.0, \"recall\": 0.14721812307834625, \"specificity\": 1.0, \"npv\": 0.39798399806022644, \"accuracy\": 0.45465993881225586, \"f1\": 0.25665236051502144, \"f2\": 0.17749020539000357, \"f0_5\": 0.4632785869228386, \"p4\": 0.3538161671008994, \"phi\": 0.2420546582292943}, {\"truth_threshold\": 12.494909612947959, \"match_probability\": 0.9998267863229663, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 297.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1734.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14623337984085083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8537666201591492, \"precision\": 1.0, \"recall\": 0.14623337984085083, \"specificity\": 1.0, \"npv\": 0.3977075517177582, \"accuracy\": 0.45403021574020386, \"f1\": 0.2551546391752577, \"f2\": 0.17634485215532597, \"f0_5\": 0.4613233923578751, \"p4\": 0.3523361639168977, \"phi\": 0.24115994372777358}, {\"truth_threshold\": 12.516886968133331, \"match_probability\": 0.9998294045376366, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 296.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1735.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14574101567268372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8542590141296387, \"precision\": 1.0, \"recall\": 0.14574101567268372, \"specificity\": 1.0, \"npv\": 0.3975694477558136, \"accuracy\": 0.45371535420417786, \"f1\": 0.25440481306403095, \"f2\": 0.17577197149643706, \"f0_5\": 0.4603421461897356, \"p4\": 0.35159363195589, \"phi\": 0.240711807104564}, {\"truth_threshold\": 12.517648029486672, \"match_probability\": 0.9998294944923664, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 294.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1737.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1447562724351883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8552437424659729, \"precision\": 1.0, \"recall\": 0.1447562724351883, \"specificity\": 1.0, \"npv\": 0.3972935378551483, \"accuracy\": 0.45308563113212585, \"f1\": 0.25290322580645164, \"f2\": 0.17462580185317178, \"f0_5\": 0.4583723105706268, \"p4\": 0.35010346944394827, \"phi\": 0.23981395892022075}, {\"truth_threshold\": 12.531220270665383, \"match_probability\": 0.9998310907421619, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 292.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1739.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14377154409885406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8562284708023071, \"precision\": 1.0, \"recall\": 0.14377154409885406, \"specificity\": 1.0, \"npv\": 0.39701804518699646, \"accuracy\": 0.45245590806007385, \"f1\": 0.2513990529487731, \"f2\": 0.17347908745247148, \"f0_5\": 0.4563926226945921, \"p4\": 0.3486064578319283, \"phi\": 0.2389139889090404}, {\"truth_threshold\": 12.585591970283218, \"match_probability\": 0.999837337046204, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 291.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1740.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14327917993068695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8567208051681519, \"precision\": 1.0, \"recall\": 0.14327917993068695, \"specificity\": 1.0, \"npv\": 0.3968804180622101, \"accuracy\": 0.45214104652404785, \"f1\": 0.25064599483204136, \"f2\": 0.17290552584670232, \"f0_5\": 0.45539906103286387, \"p4\": 0.3478553643296741, \"phi\": 0.2384631998977945}, {\"truth_threshold\": 12.591507993955794, \"match_probability\": 0.9998380026005326, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 290.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1741.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14278680086135864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8572131991386414, \"precision\": 1.0, \"recall\": 0.14278680086135864, \"specificity\": 1.0, \"npv\": 0.39674291014671326, \"accuracy\": 0.45182618498802185, \"f1\": 0.24989228780697975, \"f2\": 0.17233182790587118, \"f0_5\": 0.4544030084612974, \"p4\": 0.3471025353224262, \"phi\": 0.23801187038845348}, {\"truth_threshold\": 12.592273193129161, \"match_probability\": 0.9998380884865579, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 289.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1742.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14229443669319153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8577055931091309, \"precision\": 1.0, \"recall\": 0.14229443669319153, \"specificity\": 1.0, \"npv\": 0.3966054618358612, \"accuracy\": 0.45151132345199585, \"f1\": 0.24913793103448276, \"f2\": 0.17175799358136218, \"f0_5\": 0.45340445560087855, \"p4\": 0.346347962973042, \"phi\": 0.2375599969742467}, {\"truth_threshold\": 12.625908409772306, \"match_probability\": 0.9998418190630682, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 288.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1743.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14180207252502441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8581979274749756, \"precision\": 1.0, \"recall\": 0.14180207252502441, \"specificity\": 1.0, \"npv\": 0.3964681327342987, \"accuracy\": 0.45119646191596985, \"f1\": 0.24838292367399742, \"f2\": 0.17118402282453637, \"f0_5\": 0.4524033930254477, \"p4\": 0.34559163939876736, \"phi\": 0.2371075762191587}, {\"truth_threshold\": 12.632364185553268, \"match_probability\": 0.9998425251990117, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 287.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1744.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1413096934556961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8586903214454651, \"precision\": 1.0, \"recall\": 0.1413096934556961, \"specificity\": 1.0, \"npv\": 0.39633092284202576, \"accuracy\": 0.45088160037994385, \"f1\": 0.24762726488352027, \"f2\": 0.17060991558673166, \"f0_5\": 0.45139981126140294, \"p4\": 0.34483355667090254, \"phi\": 0.23665460465756968}, {\"truth_threshold\": 12.65614410566315, \"match_probability\": 0.9998450991799382, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 286.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1745.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.140817329287529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8591826558113098, \"precision\": 1.0, \"recall\": 0.140817329287529, \"specificity\": 1.0, \"npv\": 0.3961937725543976, \"accuracy\": 0.45056673884391785, \"f1\": 0.2468709538195943, \"f2\": 0.1700356718192628, \"f0_5\": 0.4503937007874016, \"p4\": 0.34407370681446553, \"phi\": 0.236201078793891}, {\"truth_threshold\": 12.65770316933504, \"match_probability\": 0.9998452664588459, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 285.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1746.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.14032496511936188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8596750497817993, \"precision\": 1.0, \"recall\": 0.14032496511936188, \"specificity\": 1.0, \"npv\": 0.39605674147605896, \"accuracy\": 0.45025187730789185, \"f1\": 0.24611398963730569, \"f2\": 0.16946129147342134, \"f0_5\": 0.44938505203405865, \"p4\": 0.34331208180785255, \"phi\": 0.2357469951021941}, {\"truth_threshold\": 12.688856345945647, \"match_probability\": 0.9998485714165872, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 284.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1747.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13983260095119476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.860167384147644, \"precision\": 1.0, \"recall\": 0.13983260095119476, \"specificity\": 1.0, \"npv\": 0.3959197700023651, \"accuracy\": 0.44993701577186584, \"f1\": 0.24535637149028078, \"f2\": 0.16888677450047573, \"f0_5\": 0.4483738553836438, \"p4\": 0.34254867358249524, \"phi\": 0.23529235002583448}, {\"truth_threshold\": 12.71334440561222, \"match_probability\": 0.9998511196688938, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 283.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1748.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13934022188186646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8606597781181335, \"precision\": 1.0, \"recall\": 0.13934022188186646, \"specificity\": 1.0, \"npv\": 0.3957829177379608, \"accuracy\": 0.44962215423583984, \"f1\": 0.2445980985306828, \"f2\": 0.16831212085167122, \"f0_5\": 0.44736010116977554, \"p4\": 0.3417834740225152, \"phi\": 0.23483713997706887}, {\"truth_threshold\": 12.71699191500307, \"match_probability\": 0.9998514955459502, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 282.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1749.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13884785771369934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8611521124839783, \"precision\": 1.0, \"recall\": 0.13884785771369934, \"specificity\": 1.0, \"npv\": 0.3956461548805237, \"accuracy\": 0.44930729269981384, \"f1\": 0.2438391699092088, \"f2\": 0.16773733047822983, \"f0_5\": 0.44634377967711303, \"p4\": 0.34101647496437515, \"phi\": 0.23438136133666665}, {\"truth_threshold\": 12.718534872444753, \"match_probability\": 0.9998516542625094, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 281.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1750.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13835549354553223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8616445064544678, \"precision\": 1.0, \"recall\": 0.13835549354553223, \"specificity\": 1.0, \"npv\": 0.3955095112323761, \"accuracy\": 0.44899243116378784, \"f1\": 0.2430795847750865, \"f2\": 0.16716240333135038, \"f0_5\": 0.44532488114104596, \"p4\": 0.34024766819652713, \"phi\": 0.23392501045351508}, {\"truth_threshold\": 12.763998646667208, \"match_probability\": 0.9998562555416155, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 280.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1751.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13786311447620392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8621369004249573, \"precision\": 1.0, \"recall\": 0.13786311447620392, \"specificity\": 1.0, \"npv\": 0.3953729271888733, \"accuracy\": 0.44867756962776184, \"f1\": 0.24231934227607096, \"f2\": 0.16658733936220846, \"f0_5\": 0.44430339574738176, \"p4\": 0.3394770454590577, \"phi\": 0.233468083644218}, {\"truth_threshold\": 12.781288346408768, \"match_probability\": 0.9998579676946296, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 279.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1752.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1373707503080368, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.862629234790802, \"precision\": 1.0, \"recall\": 0.1373707503080368, \"specificity\": 1.0, \"npv\": 0.39523646235466003, \"accuracy\": 0.44836270809173584, \"f1\": 0.24155844155844156, \"f2\": 0.16601213852195645, \"f0_5\": 0.4432793136320305, \"p4\": 0.3387045984433298, \"phi\": 0.23301057719268842}, {\"truth_threshold\": 12.821604785897856, \"match_probability\": 0.9998618813329017, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 278.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1753.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1368783861398697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8631216287612915, \"precision\": 1.0, \"recall\": 0.1368783861398697, \"specificity\": 1.0, \"npv\": 0.39510005712509155, \"accuracy\": 0.44804784655570984, \"f1\": 0.2407968817669987, \"f2\": 0.1654368007617234, \"f0_5\": 0.44225262488068723, \"p4\": 0.3379303187916212, \"phi\": 0.23255248734973388}, {\"truth_threshold\": 12.84239386421087, \"match_probability\": 0.9998638570676318, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 277.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1754.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13638602197170258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8636139631271362, \"precision\": 1.0, \"recall\": 0.13638602197170258, \"specificity\": 1.0, \"npv\": 0.3949637711048126, \"accuracy\": 0.44773298501968384, \"f1\": 0.24003466204506066, \"f2\": 0.16486132603261516, \"f0_5\": 0.4412233195285123, \"p4\": 0.3371541980967607, \"phi\": 0.23209381033263574}, {\"truth_threshold\": 12.854081473931537, \"match_probability\": 0.9998649553895148, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 276.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1755.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13589364290237427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8641063570976257, \"precision\": 1.0, \"recall\": 0.13589364290237427, \"specificity\": 1.0, \"npv\": 0.39482757449150085, \"accuracy\": 0.44741812348365784, \"f1\": 0.23927178153446033, \"f2\": 0.16428571428571428, \"f0_5\": 0.44019138755980863, \"p4\": 0.33637622790175986, \"phi\": 0.23163454232472105}, {\"truth_threshold\": 12.916180421435833, \"match_probability\": 0.9998706441477644, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 275.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1756.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13540127873420715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8645986914634705, \"precision\": 1.0, \"recall\": 0.13540127873420715, \"specificity\": 1.0, \"npv\": 0.39469149708747864, \"accuracy\": 0.44710326194763184, \"f1\": 0.23850823937554205, \"f2\": 0.16370996547208, \"f0_5\": 0.4391568189076972, \"p4\": 0.33559639969944205, \"phi\": 0.23117467947492792}, {\"truth_threshold\": 12.92000725473522, \"match_probability\": 0.9998709867728721, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 274.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1757.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13490891456604004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.86509108543396, \"precision\": 1.0, \"recall\": 0.13490891456604004, \"specificity\": 1.0, \"npv\": 0.3945554792881012, \"accuracy\": 0.44678840041160583, \"f1\": 0.23774403470715835, \"f2\": 0.16313407954274828, \"f0_5\": 0.4381196034537896, \"p4\": 0.33481470493206833, \"phi\": 0.23071421789736327}, {\"truth_threshold\": 12.952597931613631, \"match_probability\": 0.999873868163553, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 273.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1758.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13441655039787292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8655834794044495, \"precision\": 1.0, \"recall\": 0.13441655039787292, \"specificity\": 1.0, \"npv\": 0.3944195806980133, \"accuracy\": 0.44647353887557983, \"f1\": 0.23697916666666666, \"f2\": 0.1625580564487317, \"f0_5\": 0.43707973102785785, \"p4\": 0.33403113499095954, \"phi\": 0.23025315367085358}, {\"truth_threshold\": 12.959695022792758, \"match_probability\": 0.9998744870461508, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 272.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1759.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13392417132854462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8660758137702942, \"precision\": 1.0, \"recall\": 0.13392417132854462, \"specificity\": 1.0, \"npv\": 0.3942837417125702, \"accuracy\": 0.44615867733955383, \"f1\": 0.23621363438992618, \"f2\": 0.16198189614101954, \"f0_5\": 0.4360371914075024, \"p4\": 0.3332456812161156, \"phi\": 0.22979148283848821}, {\"truth_threshold\": 13.152811244330687, \"match_probability\": 0.9998902102984589, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 268.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1763.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13195469975471497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8680452704429626, \"precision\": 1.0, \"recall\": 0.13195469975471497, \"specificity\": 1.0, \"npv\": 0.3937413990497589, \"accuracy\": 0.44489923119544983, \"f1\": 0.23314484558503698, \"f2\": 0.15967588179218303, \"f0_5\": 0.43184015468901066, \"p4\": 0.3300848527615133, \"phi\": 0.22793865303523134}, {\"truth_threshold\": 13.157548907606314, \"match_probability\": 0.9998905702059071, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 267.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1764.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13146233558654785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8685376644134521, \"precision\": 1.0, \"recall\": 0.13146233558654785, \"specificity\": 1.0, \"npv\": 0.393606036901474, \"accuracy\": 0.44458436965942383, \"f1\": 0.23237597911227154, \"f2\": 0.1590990346800143, \"f0_5\": 0.430784123910939, \"p4\": 0.3292898480946395, \"phi\": 0.22747388853618164}, {\"truth_threshold\": 13.217326686274424, \"match_probability\": 0.9998950112883157, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 266.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1765.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13096997141838074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8690300583839417, \"precision\": 1.0, \"recall\": 0.13096997141838074, \"specificity\": 1.0, \"npv\": 0.39347079396247864, \"accuracy\": 0.4442695081233978, \"f1\": 0.23160644318676535, \"f2\": 0.15852205005959474, \"f0_5\": 0.4297253634894992, \"p4\": 0.32849290653450874, \"phi\": 0.2270084929127756}, {\"truth_threshold\": 13.230571658130634, \"match_probability\": 0.9998959706489278, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 265.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1766.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.13047759234905243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8695223927497864, \"precision\": 1.0, \"recall\": 0.13047759234905243, \"specificity\": 1.0, \"npv\": 0.39333561062812805, \"accuracy\": 0.4439546465873718, \"f1\": 0.2308362369337979, \"f2\": 0.1579449278817499, \"f0_5\": 0.4286638628275639, \"p4\": 0.32769401905091045, \"phi\": 0.22654246194449523}, {\"truth_threshold\": 13.231565087832829, \"match_probability\": 0.9998960422507085, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 264.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1767.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12998522818088531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8700147867202759, \"precision\": 1.0, \"recall\": 0.12998522818088531, \"specificity\": 1.0, \"npv\": 0.393200546503067, \"accuracy\": 0.4436397850513458, \"f1\": 0.23006535947712417, \"f2\": 0.15736766809728184, \"f0_5\": 0.42759961127308066, \"p4\": 0.32689317655913785, \"phi\": 0.22607579137114425}, {\"truth_threshold\": 13.331217920714677, \"match_probability\": 0.9999029799732962, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 263.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1768.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1294928640127182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8705071210861206, \"precision\": 1.0, \"recall\": 0.1294928640127182, \"specificity\": 1.0, \"npv\": 0.39306557178497314, \"accuracy\": 0.4433249235153198, \"f1\": 0.22929380993897122, \"f2\": 0.15679027065696913, \"f0_5\": 0.4265325981187155, \"p4\": 0.3260903699195752, \"phi\": 0.22560847689231753}, {\"truth_threshold\": 13.336185206991855, \"match_probability\": 0.999903313412463, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 262.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1769.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1290004849433899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8709995150566101, \"precision\": 1.0, \"recall\": 0.1290004849433899, \"specificity\": 1.0, \"npv\": 0.39293068647384644, \"accuracy\": 0.4430100619792938, \"f1\": 0.2285215874400349, \"f2\": 0.1562127355115669, \"f0_5\": 0.425462812601494, \"p4\": 0.32528558993728013, \"phi\": 0.22514051416686065}, {\"truth_threshold\": 13.344764548299747, \"match_probability\": 0.999903886621747, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 260.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1771.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12801575660705566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8719842433929443, \"precision\": 1.0, \"recall\": 0.12801575660705566, \"specificity\": 1.0, \"npv\": 0.3926611840724945, \"accuracy\": 0.4423803389072418, \"f1\": 0.22697512003491924, \"f2\": 0.15505725190839695, \"f0_5\": 0.42331488114620647, \"p4\": 0.3236700728855644, \"phi\": 0.2242026264043878}, {\"truth_threshold\": 13.409971764216818, \"match_probability\": 0.9999081336716603, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 258.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1773.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12703101336956024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8729689717292786, \"precision\": 1.0, \"recall\": 0.12703101336956024, \"specificity\": 1.0, \"npv\": 0.39239203929901123, \"accuracy\": 0.4417506158351898, \"f1\": 0.2254259501965924, \"f2\": 0.15390121689334288, \"f0_5\": 0.42115572967678744, \"p4\": 0.3220465507218412, \"phi\": 0.2232620925183917}, {\"truth_threshold\": 13.443718038300489, \"match_probability\": 0.999910257401424, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 257.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1774.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12653864920139313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8734613656997681, \"precision\": 1.0, \"recall\": 0.12653864920139313, \"specificity\": 1.0, \"npv\": 0.3922576308250427, \"accuracy\": 0.4414357542991638, \"f1\": 0.22465034965034966, \"f2\": 0.15332299248299724, \"f0_5\": 0.4200719189277542, \"p4\": 0.3212317641356604, \"phi\": 0.22279082197725322}, {\"truth_threshold\": 13.458858832593087, \"match_probability\": 0.9999111942238268, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 256.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1775.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.126046285033226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8739537000656128, \"precision\": 1.0, \"recall\": 0.126046285033226, \"specificity\": 1.0, \"npv\": 0.392123281955719, \"accuracy\": 0.4411208927631378, \"f1\": 0.22387407083515523, \"f2\": 0.15274463007159905, \"f0_5\": 0.41898527004909986, \"p4\": 0.3204149478514069, \"phi\": 0.22231887625538288}, {\"truth_threshold\": 13.462242419355674, \"match_probability\": 0.9999114022396312, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 255.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1776.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1255539208650589, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8744460940361023, \"precision\": 1.0, \"recall\": 0.1255539208650589, \"specificity\": 1.0, \"npv\": 0.3919890522956848, \"accuracy\": 0.4408060312271118, \"f1\": 0.2230971128608924, \"f2\": 0.15216612960973863, \"f0_5\": 0.41789577187807275, \"p4\": 0.3195960922748543, \"phi\": 0.2218462507104517}, {\"truth_threshold\": 13.512035652541337, \"match_probability\": 0.9999144076811725, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 254.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1777.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1250615417957306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.874938428401947, \"precision\": 1.0, \"recall\": 0.1250615417957306, \"specificity\": 1.0, \"npv\": 0.3918548822402954, \"accuracy\": 0.4404911696910858, \"f1\": 0.2223194748358862, \"f2\": 0.1515874910479828, \"f0_5\": 0.4168034131933049, \"p4\": 0.31877518775297364, \"phi\": 0.22137294065470842}, {\"truth_threshold\": 13.560971358570145, \"match_probability\": 0.999917262019437, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 253.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1778.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12456917762756348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8754308223724365, \"precision\": 1.0, \"recall\": 0.12456917762756348, \"specificity\": 1.0, \"npv\": 0.39172083139419556, \"accuracy\": 0.4401763081550598, \"f1\": 0.22154115586690018, \"f2\": 0.15100871433687477, \"f0_5\": 0.41570818271442656, \"p4\": 0.3179522245734807, \"phi\": 0.22089894135434782}, {\"truth_threshold\": 13.581941142029134, \"match_probability\": 0.9999184558328772, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 252.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1779.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12407680600881577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.875923216342926, \"precision\": 1.0, \"recall\": 0.12407680600881577, \"specificity\": 1.0, \"npv\": 0.39158686995506287, \"accuracy\": 0.4398614466190338, \"f1\": 0.22076215505913271, \"f2\": 0.1504297994269341, \"f0_5\": 0.4146100691016782, \"p4\": 0.31712719296437925, \"phi\": 0.2204242480288678}, {\"truth_threshold\": 13.61764920140256, \"match_probability\": 0.9999204491965882, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 250.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1781.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12309207022190094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8769079446792603, \"precision\": 1.0, \"recall\": 0.12309207022190094, \"specificity\": 1.0, \"npv\": 0.391319215297699, \"accuracy\": 0.4392317235469818, \"f1\": 0.21920210434020165, \"f2\": 0.14927155481251492, \"f0_5\": 0.41240514681623225, \"p4\": 0.3154708850680329, \"phi\": 0.219472759943121}, {\"truth_threshold\": 13.61983778272624, \"match_probability\": 0.999920569774803, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 249.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1782.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12259970605373383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.877400279045105, \"precision\": 1.0, \"recall\": 0.12259970605373383, \"specificity\": 1.0, \"npv\": 0.3911855220794678, \"accuracy\": 0.4389168620109558, \"f1\": 0.21842105263157896, \"f2\": 0.14869222500895737, \"f0_5\": 0.41129831516352827, \"p4\": 0.3146395889340626, \"phi\": 0.21899595538241903}, {\"truth_threshold\": 13.622124714684478, \"match_probability\": 0.9999206955763216, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 248.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1783.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12210733443498611, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8778926730155945, \"precision\": 1.0, \"recall\": 0.12210733443498611, \"specificity\": 1.0, \"npv\": 0.39105191826820374, \"accuracy\": 0.4386020004749298, \"f1\": 0.21763931548924967, \"f2\": 0.148112756808409, \"f0_5\": 0.4101885544161429, \"p4\": 0.313806184676089, \"phi\": 0.21851843719435904}, {\"truth_threshold\": 13.622889080909394, \"match_probability\": 0.9999207375787978, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 247.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1784.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.121614970266819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8783850073814392, \"precision\": 1.0, \"recall\": 0.121614970266819, \"specificity\": 1.0, \"npv\": 0.39091840386390686, \"accuracy\": 0.4382871389389038, \"f1\": 0.21685689201053557, \"f2\": 0.14753315016127105, \"f0_5\": 0.4090758529314342, \"p4\": 0.3129706622165514, \"phi\": 0.21804020035490176}, {\"truth_threshold\": 13.632364185553268, \"match_probability\": 0.9999212563994394, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 246.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1785.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12112259864807129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8788774013519287, \"precision\": 1.0, \"recall\": 0.12112259864807129, \"specificity\": 1.0, \"npv\": 0.39078497886657715, \"accuracy\": 0.4379722774028778, \"f1\": 0.2160737812911726, \"f2\": 0.14695340501792115, \"f0_5\": 0.4079601990049751, \"p4\": 0.31213301141534483, \"phi\": 0.2175612397892036}, {\"truth_threshold\": 13.640387617941272, \"match_probability\": 0.9999216930759494, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 245.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1786.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12063023447990417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8793697953224182, \"precision\": 1.0, \"recall\": 0.12063023447990417, \"specificity\": 1.0, \"npv\": 0.3906516432762146, \"accuracy\": 0.4376574158668518, \"f1\": 0.21528998242530756, \"f2\": 0.14637352132871312, \"f0_5\": 0.4068415808701428, \"p4\": 0.31129322206933285, \"phi\": 0.21708155037088758}, {\"truth_threshold\": 13.641039788520276, \"match_probability\": 0.99992172846384, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 244.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1787.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.12013786286115646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8798621296882629, \"precision\": 1.0, \"recall\": 0.12013786286115646, \"specificity\": 1.0, \"npv\": 0.3905184268951416, \"accuracy\": 0.4373425841331482, \"f1\": 0.2145054945054945, \"f2\": 0.14579349904397707, \"f0_5\": 0.40571998669770537, \"p4\": 0.31045128391185506, \"phi\": 0.21660112692130082}, {\"truth_threshold\": 13.687554690890355, \"match_probability\": 0.9999242116320329, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 243.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1788.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11964549124240875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8803545236587524, \"precision\": 1.0, \"recall\": 0.11964549124240875, \"specificity\": 1.0, \"npv\": 0.3903852701187134, \"accuracy\": 0.4370277225971222, \"f1\": 0.21372031662269128, \"f2\": 0.14521333811401937, \"f0_5\": 0.4045954045954046, \"p4\": 0.30960718661223074, \"phi\": 0.21611996420875845}, {\"truth_threshold\": 13.690068655481024, \"match_probability\": 0.999924343571881, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 241.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1790.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11866075545549393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8813392519950867, \"precision\": 1.0, \"recall\": 0.11866075545549393, \"specificity\": 1.0, \"npv\": 0.3901192545890808, \"accuracy\": 0.4363979995250702, \"f1\": 0.21214788732394366, \"f2\": 0.14405260011954574, \"f0_5\": 0.4023372287145242, \"p4\": 0.3079124729407039, \"phi\": 0.2151553997982709}, {\"truth_threshold\": 13.725451331587461, \"match_probability\": 0.9999261763722774, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 240.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1791.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11816839128732681, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8818315863609314, \"precision\": 1.0, \"recall\": 0.11816839128732681, \"specificity\": 1.0, \"npv\": 0.3899863660335541, \"accuracy\": 0.4360831379890442, \"f1\": 0.21136063408190225, \"f2\": 0.14347202295552366, \"f0_5\": 0.4012036108324975, \"p4\": 0.30706183558280153, \"phi\": 0.214671987364791}, {\"truth_threshold\": 13.728502629770615, \"match_probability\": 0.9999263323326681, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 238.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1793.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11718365550041199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8828163743019104, \"precision\": 1.0, \"recall\": 0.11718365550041199, \"specificity\": 1.0, \"npv\": 0.3897208869457245, \"accuracy\": 0.4354534149169922, \"f1\": 0.20978404583516969, \"f2\": 0.1423104520449653, \"f0_5\": 0.3989272544418371, \"p4\": 0.30535394686307954, \"phi\": 0.21370287478222277}, {\"truth_threshold\": 13.754580386651892, \"match_probability\": 0.999927651870994, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 236.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1795.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11619891971349716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8838011026382446, \"precision\": 1.0, \"recall\": 0.11619891971349716, \"specificity\": 1.0, \"npv\": 0.38945579528808594, \"accuracy\": 0.4348236918449402, \"f1\": 0.20820467578297308, \"f2\": 0.14114832535885166, \"f0_5\": 0.39663865546218485, \"p4\": 0.30363716807944324, \"phi\": 0.21273067489732173}, {\"truth_threshold\": 13.796055877786548, \"match_probability\": 0.9999297020229121, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 235.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1796.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11570654809474945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8842934370040894, \"precision\": 1.0, \"recall\": 0.11570654809474945, \"specificity\": 1.0, \"npv\": 0.389323353767395, \"accuracy\": 0.4345088303089142, \"f1\": 0.20741394527802295, \"f2\": 0.14056705347529608, \"f0_5\": 0.39548973409626387, \"p4\": 0.3027754178880268, \"phi\": 0.21224340311564244}, {\"truth_threshold\": 13.810294279344955, \"match_probability\": 0.9999303923548466, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 234.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1797.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11521418392658234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8847858309745789, \"precision\": 1.0, \"recall\": 0.11521418392658234, \"specificity\": 1.0, \"npv\": 0.38919103145599365, \"accuracy\": 0.4341939687728882, \"f1\": 0.20662251655629138, \"f2\": 0.1399856424982053, \"f0_5\": 0.3943377148634985, \"p4\": 0.30191141261310905, \"phi\": 0.21175534246740363}, {\"truth_threshold\": 13.81553415885179, \"match_probability\": 0.9999306446942894, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 231.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1800.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1137370765209198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8862629532814026, \"precision\": 1.0, \"recall\": 0.1137370765209198, \"specificity\": 1.0, \"npv\": 0.38879457116127014, \"accuracy\": 0.4332493841648102, \"f1\": 0.20424403183023873, \"f2\": 0.13824057450628366, \"f0_5\": 0.39086294416243655, \"p4\": 0.29930575594520736, \"phi\": 0.2102863689420492}, {\"truth_threshold\": 13.817821090810028, \"match_probability\": 0.9999307545402646, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 230.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1801.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11324470490217209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8867552876472473, \"precision\": 1.0, \"recall\": 0.11324470490217209, \"specificity\": 1.0, \"npv\": 0.3886626064777374, \"accuracy\": 0.4329345226287842, \"f1\": 0.2034498009730208, \"f2\": 0.13765860665549437, \"f0_5\": 0.3896984073195527, \"p4\": 0.2984326196428951, \"phi\": 0.2097950941307122}, {\"truth_threshold\": 13.818794294325262, \"match_probability\": 0.9999308012324183, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 226.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1805.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11127523332834244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8887247443199158, \"precision\": 1.0, \"recall\": 0.11127523332834244, \"specificity\": 1.0, \"npv\": 0.3881355822086334, \"accuracy\": 0.4316750764846802, \"f1\": 0.20026583961010191, \"f2\": 0.13532934131736526, \"f0_5\": 0.3850085178875639, \"p4\": 0.294916852696856, \"phi\": 0.20782174792543054}, {\"truth_threshold\": 13.885344840552357, \"match_probability\": 0.9999339206132295, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 225.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1806.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11078286916017532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8892171382904053, \"precision\": 1.0, \"recall\": 0.11078286916017532, \"specificity\": 1.0, \"npv\": 0.3880040645599365, \"accuracy\": 0.4313602149486542, \"f1\": 0.19946808510638298, \"f2\": 0.13474667624865252, \"f0_5\": 0.38382804503582396, \"p4\": 0.2940320482092721, \"phi\": 0.2073263184832979}, {\"truth_threshold\": 13.897189511868921, \"match_probability\": 0.9999344608752441, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 224.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1807.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.11029049754142761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8897095322608948, \"precision\": 1.0, \"recall\": 0.11029049754142761, \"specificity\": 1.0, \"npv\": 0.3878726363182068, \"accuracy\": 0.4310453534126282, \"f1\": 0.19866962305986696, \"f2\": 0.13416387158600862, \"f0_5\": 0.38264434574649814, \"p4\": 0.29314487543657275, \"phi\": 0.20683003918233825}, {\"truth_threshold\": 13.921147707713011, \"match_probability\": 0.9999355401975092, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 223.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1808.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1097981259226799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8902018666267395, \"precision\": 1.0, \"recall\": 0.1097981259226799, \"specificity\": 1.0, \"npv\": 0.3877412676811218, \"accuracy\": 0.4307304918766022, \"f1\": 0.19787045252883761, \"f2\": 0.13358092727926202, \"f0_5\": 0.3814574067738625, \"p4\": 0.2922553226557823, \"phi\": 0.2063329035471685}, {\"truth_threshold\": 13.927073151820181, \"match_probability\": 0.9999358043872165, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 222.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1809.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10930576175451279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.890694260597229, \"precision\": 1.0, \"recall\": 0.10930576175451279, \"specificity\": 1.0, \"npv\": 0.3876100182533264, \"accuracy\": 0.43041563034057617, \"f1\": 0.1970705725699068, \"f2\": 0.13299784327821712, \"f0_5\": 0.3802672147995889, \"p4\": 0.29136337806831203, \"phi\": 0.20583490502967935}, {\"truth_threshold\": 13.947843752923909, \"match_probability\": 0.9999367219374641, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 221.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1810.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10881339013576508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8911865949630737, \"precision\": 1.0, \"recall\": 0.10881339013576508, \"specificity\": 1.0, \"npv\": 0.38747885823249817, \"accuracy\": 0.43010076880455017, \"f1\": 0.19626998223801065, \"f2\": 0.1324146195326543, \"f0_5\": 0.379073756432247, \"p4\": 0.290469029799348, \"phi\": 0.20533603700788008}, {\"truth_threshold\": 13.953288781348904, \"match_probability\": 0.9999369602967668, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 220.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1811.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10832102596759796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8916789889335632, \"precision\": 1.0, \"recall\": 0.10832102596759796, \"specificity\": 1.0, \"npv\": 0.3873477578163147, \"accuracy\": 0.42978590726852417, \"f1\": 0.19546868058640604, \"f2\": 0.1318312559923298, \"f0_5\": 0.3778770182068018, \"p4\": 0.2895722658972329, \"phi\": 0.20483629278471924}, {\"truth_threshold\": 13.959531362644576, \"match_probability\": 0.9999372324649185, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 219.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1812.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10782865434885025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.892171323299408, \"precision\": 1.0, \"recall\": 0.10782865434885025, \"specificity\": 1.0, \"npv\": 0.3872167766094208, \"accuracy\": 0.42947104573249817, \"f1\": 0.19466666666666665, \"f2\": 0.1312477526069759, \"f0_5\": 0.3766769865841073, \"p4\": 0.2886730743328418, \"phi\": 0.20433566558688177}, {\"truth_threshold\": 13.961770456290582, \"match_probability\": 0.9999373297998216, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 217.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1814.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10684391856193542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8931560516357422, \"precision\": 1.0, \"recall\": 0.10684391856193542, \"specificity\": 1.0, \"npv\": 0.38695505261421204, \"accuracy\": 0.42884132266044617, \"f1\": 0.19306049822064056, \"f2\": 0.13008032609998801, \"f0_5\": 0.3742669886167644, \"p4\": 0.2868673597096055, \"phi\": 0.20333173478520547}, {\"truth_threshold\": 13.988700955728945, \"match_probability\": 0.9999384887295334, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 216.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1815.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10635155439376831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8936484456062317, \"precision\": 1.0, \"recall\": 0.10635155439376831, \"specificity\": 1.0, \"npv\": 0.3868243098258972, \"accuracy\": 0.42852646112442017, \"f1\": 0.19225634178905207, \"f2\": 0.12949640287769784, \"f0_5\": 0.37305699481865284, \"p4\": 0.2859608121994684, \"phi\": 0.20282841724223868}, {\"truth_threshold\": 13.990002610784236, \"match_probability\": 0.999938544198934, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 215.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1816.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.1058591827750206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8941408395767212, \"precision\": 1.0, \"recall\": 0.1058591827750206, \"specificity\": 1.0, \"npv\": 0.38669368624687195, \"accuracy\": 0.42821159958839417, \"f1\": 0.19145146927871773, \"f2\": 0.12891233960906584, \"f0_5\": 0.37184365271532344, \"p4\": 0.2850517881231799, \"phi\": 0.20232418884375344}, {\"truth_threshold\": 14.014490670450812, \"match_probability\": 0.9999395784735632, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 214.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1817.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10536681115627289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8946331739425659, \"precision\": 1.0, \"recall\": 0.10536681115627289, \"specificity\": 1.0, \"npv\": 0.38656312227249146, \"accuracy\": 0.42789673805236816, \"f1\": 0.19064587973273942, \"f2\": 0.12832813624370354, \"f0_5\": 0.37062694838933147, \"p4\": 0.2841402750546976, \"phi\": 0.20181904241617807}, {\"truth_threshold\": 14.032686700681404, \"match_probability\": 0.9999403357108556, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 212.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1819.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10438207536935806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8956179022789001, \"precision\": 1.0, \"recall\": 0.10438207536935806, \"specificity\": 1.0, \"npv\": 0.38630229234695435, \"accuracy\": 0.42726701498031616, \"f1\": 0.18903254569772626, \"f2\": 0.12715930902111325, \"f0_5\": 0.3681833970128517, \"p4\": 0.2823097318295965, \"phi\": 0.20080596635794612}, {\"truth_threshold\": 14.038920009890434, \"match_probability\": 0.9999405929250509, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 211.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1820.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10388971120119095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8961102962493896, \"precision\": 1.0, \"recall\": 0.10388971120119095, \"specificity\": 1.0, \"npv\": 0.38617199659347534, \"accuracy\": 0.42695215344429016, \"f1\": 0.18822479928635147, \"f2\": 0.1265746850629874, \"f0_5\": 0.36695652173913046, \"p4\": 0.2813906764114958, \"phi\": 0.2002980219544205}, {\"truth_threshold\": 14.043997207234304, \"match_probability\": 0.9999408016132995, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 210.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1821.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10339733958244324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8966026306152344, \"precision\": 1.0, \"recall\": 0.10339733958244324, \"specificity\": 1.0, \"npv\": 0.3860418200492859, \"accuracy\": 0.42663729190826416, \"f1\": 0.18741633199464525, \"f2\": 0.1259899208063355, \"f0_5\": 0.3657262277951933, \"p4\": 0.28046908147688054, \"phi\": 0.19978912997319528}, {\"truth_threshold\": 14.064171707990564, \"match_probability\": 0.9999416236283117, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 209.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1822.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.10290497541427612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8970950245857239, \"precision\": 1.0, \"recall\": 0.10290497541427612, \"specificity\": 1.0, \"npv\": 0.3859117031097412, \"accuracy\": 0.42632243037223816, \"f1\": 0.18660714285714286, \"f2\": 0.12540501620064803, \"f0_5\": 0.36449250087199164, \"p4\": 0.27954493418624105, \"phi\": 0.19927928280635765}, {\"truth_threshold\": 14.065144911505799, \"match_probability\": 0.9999416629918764, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 203.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1828.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09995076060295105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9000492095947266, \"precision\": 1.0, \"recall\": 0.09995076060295105, \"specificity\": 1.0, \"npv\": 0.3851328492164612, \"accuracy\": 0.42443326115608215, \"f1\": 0.18173679498657117, \"f2\": 0.12189263840518794, \"f0_5\": 0.3570172353148083, \"p4\": 0.2739457211855208, \"phi\": 0.19619970316467247}, {\"truth_threshold\": 14.08243461124736, \"match_probability\": 0.9999423579078103, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 200.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1831.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09847366064786911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9015263319015503, \"precision\": 1.0, \"recall\": 0.09847366064786911, \"specificity\": 1.0, \"npv\": 0.3847446143627167, \"accuracy\": 0.42348867654800415, \"f1\": 0.17929179740026893, \"f2\": 0.12013455069678039, \"f0_5\": 0.35323207347227126, \"p4\": 0.27111059151536315, \"phi\": 0.1946463732034884}, {\"truth_threshold\": 14.105479828204171, \"match_probability\": 0.9999432713000692, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 196.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1835.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09650418162345886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9034957885742188, \"precision\": 1.0, \"recall\": 0.09650418162345886, \"specificity\": 1.0, \"npv\": 0.3842281997203827, \"accuracy\": 0.42222923040390015, \"f1\": 0.1760215536596318, \"f2\": 0.11778846153846154, \"f0_5\": 0.3481349911190053, \"p4\": 0.2672927556600361, \"phi\": 0.19256071296951466}, {\"truth_threshold\": 14.131695457732894, \"match_probability\": 0.9999442927674878, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 195.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1836.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09601181745529175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9039881825447083, \"precision\": 1.0, \"recall\": 0.09601181745529175, \"specificity\": 1.0, \"npv\": 0.3840993046760559, \"accuracy\": 0.42191436886787415, \"f1\": 0.1752021563342318, \"f2\": 0.11720158672917418, \"f0_5\": 0.3468516542155816, \"p4\": 0.2663314784662456, \"phi\": 0.19203664028310077}, {\"truth_threshold\": 14.143540129049459, \"match_probability\": 0.9999447482319339, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 194.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1837.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09551944583654404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9044805765151978, \"precision\": 1.0, \"recall\": 0.09551944583654404, \"specificity\": 1.0, \"npv\": 0.3839704990386963, \"accuracy\": 0.42159950733184814, \"f1\": 0.17438202247191012, \"f2\": 0.11661457081029093, \"f0_5\": 0.3455646597791236, \"p4\": 0.2653674457472427, \"phi\": 0.19151148640622262}, {\"truth_threshold\": 14.155227738770126, \"match_probability\": 0.9999451940067879, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 191.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1840.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.0940423458814621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9059576392173767, \"precision\": 1.0, \"recall\": 0.0940423458814621, \"specificity\": 1.0, \"npv\": 0.383584588766098, \"accuracy\": 0.42065492272377014, \"f1\": 0.1719171917191719, \"f2\": 0.11485267588695129, \"f0_5\": 0.3416815742397138, \"p4\": 0.2624586711150848, \"phi\": 0.18992944427929537}, {\"truth_threshold\": 14.160223917702716, \"match_probability\": 0.9999453834661167, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 186.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1845.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09158050268888474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9084194898605347, \"precision\": 1.0, \"recall\": 0.09158050268888474, \"specificity\": 1.0, \"npv\": 0.38294315338134766, \"accuracy\": 0.41908061504364014, \"f1\": 0.16779431664411368, \"f2\": 0.11191335740072202, \"f0_5\": 0.33513513513513515, \"p4\": 0.2575542504705109, \"phi\": 0.1872701936518745}, {\"truth_threshold\": 14.190107557653976, \"match_probability\": 0.9999465030836359, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 185.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1846.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.09108813107013702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9089118838310242, \"precision\": 1.0, \"recall\": 0.09108813107013702, \"specificity\": 1.0, \"npv\": 0.3828151226043701, \"accuracy\": 0.41876575350761414, \"f1\": 0.16696750902527077, \"f2\": 0.11132506920207004, \"f0_5\": 0.33381450739805124, \"p4\": 0.25656476345049783, \"phi\": 0.18673487673784397}, {\"truth_threshold\": 14.201373582779711, \"match_probability\": 0.9999469191927903, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 182.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1849.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08961103111505508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9103889465332031, \"precision\": 1.0, \"recall\": 0.08961103111505508, \"specificity\": 1.0, \"npv\": 0.3824315369129181, \"accuracy\": 0.41782116889953613, \"f1\": 0.16448260280162674, \"f2\": 0.10955935468336142, \"f0_5\": 0.3298296484233418, \"p4\": 0.25357882417863564, \"phi\": 0.185121805630292}, {\"truth_threshold\": 14.218726986814069, \"match_probability\": 0.9999475538154151, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 180.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1851.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08862629532814026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9113737344741821, \"precision\": 1.0, \"recall\": 0.08862629532814026, \"specificity\": 1.0, \"npv\": 0.3821762204170227, \"accuracy\": 0.41719144582748413, \"f1\": 0.1628222523744912, \"f2\": 0.10838150289017341, \"f0_5\": 0.3271537622682661, \"p4\": 0.2515734785892477, \"phi\": 0.18404038354443372}, {\"truth_threshold\": 14.22777716571865, \"match_probability\": 0.9999478817690236, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 179.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1852.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08813392370939255, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9118660688400269, \"precision\": 1.0, \"recall\": 0.08813392370939255, \"specificity\": 1.0, \"npv\": 0.38204872608184814, \"accuracy\": 0.41687658429145813, \"f1\": 0.16199095022624435, \"f2\": 0.10779236420570878, \"f0_5\": 0.32580997451765564, \"p4\": 0.2505663431409825, \"phi\": 0.18349782699734024}, {\"truth_threshold\": 14.245423032024966, \"match_probability\": 0.9999485153213519, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 177.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1854.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08714918792247772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9128507971763611, \"precision\": 1.0, \"recall\": 0.08714918792247772, \"specificity\": 1.0, \"npv\": 0.38179394602775574, \"accuracy\": 0.41624686121940613, \"f1\": 0.16032608695652173, \"f2\": 0.10661366100469823, \"f0_5\": 0.3231106243154436, \"p4\": 0.24854306779885504, \"phi\": 0.18240896617595923}, {\"truth_threshold\": 14.260841287631349, \"match_probability\": 0.9999490625867303, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 176.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1855.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08665681630373001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9133431911468506, \"precision\": 1.0, \"recall\": 0.08665681630373001, \"specificity\": 1.0, \"npv\": 0.3816666603088379, \"accuracy\": 0.4159319996833801, \"f1\": 0.15949252378794743, \"f2\": 0.10602409638554217, \"f0_5\": 0.3217550274223035, \"p4\": 0.24752689591851462, \"phi\": 0.18186263873178055}, {\"truth_threshold\": 14.295721106515197, \"match_probability\": 0.999950279264621, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 165.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1866.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08124076575040817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9187592267990112, \"precision\": 1.0, \"recall\": 0.08124076575040817, \"specificity\": 1.0, \"npv\": 0.3802723288536072, \"accuracy\": 0.4124685227870941, \"f1\": 0.15027322404371585, \"f2\": 0.09952949692363373, \"f0_5\": 0.30657748049052397, \"p4\": 0.23614444277786112, \"phi\": 0.1757658003196868}, {\"truth_threshold\": 14.32434053567529, \"match_probability\": 0.9999512558321264, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 163.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1868.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.08025602996349335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9197439551353455, \"precision\": 1.0, \"recall\": 0.08025602996349335, \"specificity\": 1.0, \"npv\": 0.3800199031829834, \"accuracy\": 0.4118387997150421, \"f1\": 0.14858705560619873, \"f2\": 0.09834680825389164, \"f0_5\": 0.30376444278792397, \"p4\": 0.23403358868222168, \"phi\": 0.17463931450138853}, {\"truth_threshold\": 14.3797802591637, \"match_probability\": 0.999953093347652, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 162.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1869.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07976366579532623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.920236349105835, \"precision\": 1.0, \"recall\": 0.07976366579532623, \"specificity\": 1.0, \"npv\": 0.37989383935928345, \"accuracy\": 0.4115239381790161, \"f1\": 0.14774281805745554, \"f2\": 0.09775524981897175, \"f0_5\": 0.3023516237402016, \"p4\": 0.23297327288261566, \"phi\": 0.1740739021786681}, {\"truth_threshold\": 14.431255739591801, \"match_probability\": 0.9999547374008111, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 161.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1870.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07927129417657852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9207286834716797, \"precision\": 1.0, \"recall\": 0.07927129417657852, \"specificity\": 1.0, \"npv\": 0.37976783514022827, \"accuracy\": 0.4112090766429901, \"f1\": 0.1468978102189781, \"f2\": 0.0971635485817743, \"f0_5\": 0.30093457943925234, \"p4\": 0.23190967417285194, \"phi\": 0.17350702423950815}, {\"truth_threshold\": 14.441119408150517, \"match_probability\": 0.9999550457906877, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 160.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1871.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07877893000841141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9212210774421692, \"precision\": 1.0, \"recall\": 0.07877893000841141, \"specificity\": 1.0, \"npv\": 0.37964192032814026, \"accuracy\": 0.4108942151069641, \"f1\": 0.1460520310360566, \"f2\": 0.09657170449058426, \"f0_5\": 0.2995132909022838, \"p4\": 0.23084277458650382, \"phi\": 0.17293866589528342}, {\"truth_threshold\": 14.447724199960248, \"match_probability\": 0.9999552511156641, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 158.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1873.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07779418677091599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9222058057785034, \"precision\": 1.0, \"recall\": 0.07779418677091599, \"specificity\": 1.0, \"npv\": 0.37939032912254333, \"accuracy\": 0.4102644920349121, \"f1\": 0.14435815440840566, \"f2\": 0.09538758753924173, \"f0_5\": 0.29665790461885094, \"p4\": 0.22869900027147813, \"phi\": 0.1717974476697762}, {\"truth_threshold\": 14.474127782899187, \"match_probability\": 0.9999560626060539, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 157.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1874.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07730182260274887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9226981997489929, \"precision\": 1.0, \"recall\": 0.07730182260274887, \"specificity\": 1.0, \"npv\": 0.3792646527290344, \"accuracy\": 0.4099496304988861, \"f1\": 0.14351005484460694, \"f2\": 0.09479531457553436, \"f0_5\": 0.29522376833396013, \"p4\": 0.22762208895957212, \"phi\": 0.17122455702829323}, {\"truth_threshold\": 14.512035652541337, \"match_probability\": 0.9999572020089966, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 156.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1875.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07680945098400116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9231905341148376, \"precision\": 1.0, \"recall\": 0.07680945098400116, \"specificity\": 1.0, \"npv\": 0.3791390657424927, \"accuracy\": 0.4096347689628601, \"f1\": 0.14266117969821673, \"f2\": 0.09420289855072464, \"f0_5\": 0.2937853107344633, \"p4\": 0.2265418036022582, \"phi\": 0.1706501244506039}, {\"truth_threshold\": 14.563335517790893, \"match_probability\": 0.999958697034534, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 154.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1877.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07582471519708633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9241752624511719, \"precision\": 1.0, \"recall\": 0.07582471519708633, \"specificity\": 1.0, \"npv\": 0.37888815999031067, \"accuracy\": 0.4090050458908081, \"f1\": 0.14096109839816934, \"f2\": 0.09301763711041314, \"f0_5\": 0.29089535323007176, \"p4\": 0.22437103612070838, \"phi\": 0.16949656921167702}, {\"truth_threshold\": 14.706938164168367, \"match_probability\": 0.9999626101063662, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 153.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1878.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07533235102891922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9246676564216614, \"precision\": 1.0, \"recall\": 0.07533235102891922, \"specificity\": 1.0, \"npv\": 0.378762811422348, \"accuracy\": 0.4086901843547821, \"f1\": 0.1401098901098901, \"f2\": 0.09242479159115621, \"f0_5\": 0.28944381384790013, \"p4\": 0.22328051634216844, \"phi\": 0.16891741375778377}, {\"truth_threshold\": 14.842230204062687, \"match_probability\": 0.9999659569297449, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 152.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1879.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07483997941017151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9251599907875061, \"precision\": 1.0, \"recall\": 0.07483997941017151, \"specificity\": 1.0, \"npv\": 0.37863755226135254, \"accuracy\": 0.4083753228187561, \"f1\": 0.13925790196976637, \"f2\": 0.09183180280328661, \"f0_5\": 0.28798787419477073, \"p4\": 0.222186547207141, \"phi\": 0.16833665077032448}, {\"truth_threshold\": 14.885344840552357, \"match_probability\": 0.9999669592149574, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 151.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1880.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.0743476152420044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9256523847579956, \"precision\": 1.0, \"recall\": 0.0743476152420044, \"specificity\": 1.0, \"npv\": 0.3785123825073242, \"accuracy\": 0.4080604612827301, \"f1\": 0.1384051329055912, \"f2\": 0.09123867069486405, \"f0_5\": 0.286527514231499, \"p4\": 0.22108910954393457, \"phi\": 0.16775426317035838}, {\"truth_threshold\": 14.885601371458392, \"match_probability\": 0.9999669650893444, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 150.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1881.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07385524362325668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9261447787284851, \"precision\": 1.0, \"recall\": 0.07385524362325668, \"specificity\": 1.0, \"npv\": 0.37838730216026306, \"accuracy\": 0.4077455997467041, \"f1\": 0.1375515818431912, \"f2\": 0.09064539521392313, \"f0_5\": 0.28506271379703535, \"p4\": 0.21998818404076986, \"phi\": 0.16717023359441924}, {\"truth_threshold\": 14.923270979523068, \"match_probability\": 0.9999678164590993, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 149.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1882.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07336287200450897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9266371130943298, \"precision\": 1.0, \"recall\": 0.07336287200450897, \"specificity\": 1.0, \"npv\": 0.37826231122016907, \"accuracy\": 0.4074307382106781, \"f1\": 0.13669724770642203, \"f2\": 0.09005197630847335, \"f0_5\": 0.2835934526075371, \"p4\": 0.218883751244496, \"phi\": 0.16658454438783837}, {\"truth_threshold\": 14.940560679264628, \"match_probability\": 0.9999681998423766, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 148.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1883.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07287050783634186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9271295070648193, \"precision\": 1.0, \"recall\": 0.07287050783634186, \"specificity\": 1.0, \"npv\": 0.37813737988471985, \"accuracy\": 0.4071158766746521, \"f1\": 0.13584212941716384, \"f2\": 0.08945841392649903, \"f0_5\": 0.2821197102554327, \"p4\": 0.21777579155929253, \"phi\": 0.16599717759786536}, {\"truth_threshold\": 14.988700955728945, \"match_probability\": 0.9999692434188285, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 145.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1886.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07139340043067932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9286065697669983, \"precision\": 1.0, \"recall\": 0.07139340043067932, \"specificity\": 1.0, \"npv\": 0.37776312232017517, \"accuracy\": 0.4061712920665741, \"f1\": 0.1332720588235294, \"f2\": 0.08767686540089491, \"f0_5\": 0.27767139027192644, \"p4\": 0.21443055304419703, \"phi\": 0.16422482757845058}, {\"truth_threshold\": 14.991214920319615, \"match_probability\": 0.9999692969653184, \"row_count\": 3176.0, \"p\": 2031.0, \"n\": 1145.0, \"tp\": 144.0, \"tn\": 1145.0, \"fp\": 0.0, \"fn\": 1887.0, \"P_rate\": 0.6394836272040302, \"N_rate\": 0.36051636934280396, \"tp_rate\": 0.07090103626251221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9290989637374878, \"precision\": 1.0, \"recall\": 0.07090103626251221, \"specificity\": 1.0, \"npv\": 0.3776385188102722, \"accuracy\": 0.4058564305305481, \"f1\": 0.13241379310344828, \"f2\": 0.08708272859216255, \"f0_5\": 0.2761795166858458, \"p4\": 0.21330828694544357, \"phi\": 0.16363056471300563}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import splink.duckdb.comparison_library as cl\n",
    "import splink.duckdb.comparison_template_library as ctl\n",
    "import splink.duckdb.blocking_rule_library as brl\n",
    "from splink.datasets import splink_datasets, splink_dataset_labels\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "df = splink_datasets.fake_1000\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        brl.exact_match_rule(\"first_name\"),\n",
    "        brl.exact_match_rule(\"surname\"),\n",
    "        brl.exact_match_rule(\"city\"),\n",
    "        brl.exact_match_rule(\"dob\"),\n",
    "        brl.exact_match_rule(\"email\"),\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True),\n",
    "        cl.exact_match(\"city\", term_frequency_adjustments=True),\n",
    "        ctl.email_comparison(\"email\", include_username_fuzzy_level=False),\n",
    "    ],\n",
    "}\n",
    "\n",
    "linker = DuckDBLinker(df, settings)\n",
    "linker.estimate_u_using_random_sampling(max_pairs=1e6)\n",
    "\n",
    "blocking_rule_for_training = brl.and_(\n",
    "                            brl.exact_match_rule(\"first_name\"), \n",
    "                            brl.exact_match_rule(\"surname\")\n",
    "                            )\n",
    "\n",
    "linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n",
    "\n",
    "blocking_rule_for_training = brl.exact_match_rule(\"dob\")\n",
    "linker.estimate_parameters_using_expectation_maximisation(blocking_rule_for_training)\n",
    "\n",
    "\n",
    "df_labels = splink_dataset_labels.fake_1000_labels\n",
    "labels_table = linker.register_labels_table(df_labels)\n",
    "\n",
    "linker.confusion_matrix_from_labels_table(labels_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the chart shows\n",
    "\n",
    "The line chart on the left shows how **match probability** varies as a function of **match weight**. \n",
    "\n",
    "Hovering over this chart selects a match weight threshold and compares the results against labelled data by updating the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) shown on the right."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to interpret the chart\n",
    "\n",
    "Lowering the threshold to the extreme ensures many more matches are generated - this maximises the **True Positives** (high recall) but at the expense of some **False Positives** (low precision).\n",
    "\n",
    "You can then see the effect on the confusion matrix of raising the match threshold. As more predicted matches become non-matches at the higher threshold, **True Positives** become **False Negatives**, but **False Positives** become **True Negatives**. \n",
    "\n",
    "This demonstrates the trade-off between **Type 1 (FP)** and **Type 2 (FN)** errors when selecting a match threshold, or precision vs recall."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions to take as a result of the chart\n",
    "\n",
    "This chart is best used to _illustrate_ the effect of match threshold on linking performance against labelled data.\n",
    "\n",
    "In order to make a decision about the optimal threshold to use, see [accuracy_chart_from_labels_table_chart()](./accuracy_chart_from_labels_table.ipynb) to use this confusion matrix to calculate various performance metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
