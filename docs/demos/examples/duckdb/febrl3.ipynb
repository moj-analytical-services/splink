{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicating the febrl3 dataset\n",
    "\n",
    "See A.2  [here](https://arxiv.org/pdf/2008.04443.pdf) and [here](https://recordlinkage.readthedocs.io/en/latest/ref-datasets.html) for the source of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec-1496-org</td>\n",
       "      <td>mitchell</td>\n",
       "      <td>green</td>\n",
       "      <td>7</td>\n",
       "      <td>wallaby place</td>\n",
       "      <td>delmar</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>2119</td>\n",
       "      <td>sa</td>\n",
       "      <td>19560409</td>\n",
       "      <td>1804974</td>\n",
       "      <td>rec-1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec-552-dup-3</td>\n",
       "      <td>harley</td>\n",
       "      <td>mccarthy</td>\n",
       "      <td>177</td>\n",
       "      <td>pridhamstreet</td>\n",
       "      <td>milton</td>\n",
       "      <td>marsden</td>\n",
       "      <td>3165</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19080419</td>\n",
       "      <td>6089216</td>\n",
       "      <td>rec-552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rec_id given_name    surname street_number       address_1  \\\n",
       "0   rec-1496-org   mitchell      green             7   wallaby place   \n",
       "1  rec-552-dup-3     harley   mccarthy           177   pridhamstreet   \n",
       "\n",
       "  address_2      suburb  postcode state date_of_birth  soc_sec_id   cluster  \n",
       "0    delmar   cleveland      2119    sa      19560409     1804974  rec-1496  \n",
       "1    milton     marsden      3165   nsw      19080419     6089216   rec-552  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import altair as alt\n",
    "from splink.datasets import splink_datasets\n",
    "\n",
    "df = splink_datasets.febrl3\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "\n",
    "df[\"cluster\"] = df[\"rec_id\"].apply(lambda x: \"-\".join(x.split('-')[:2]))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.duckdb.linker import DuckDBLinker\n",
    "\n",
    "settings = {\n",
    "    \"unique_id_column_name\": \"rec_id\",\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "}\n",
    "\n",
    "linker = DuckDBLinker(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3c9c274da1fb44b5b2c3ed6797d2d887.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3c9c274da1fb44b5b2c3ed6797d2d887.vega-embed details,\n",
       "  #altair-viz-3c9c274da1fb44b5b2c3ed6797d2d887.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3c9c274da1fb44b5b2c3ed6797d2d887\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3c9c274da1fb44b5b2c3ed6797d2d887\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3c9c274da1fb44b5b2c3ed6797d2d887\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 11}}, \"layer\": [{\"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"null_proportion\", \"legend\": {\"format\": \".0%\", \"offset\": 30}, \"scale\": {\"domain\": [0, 1], \"range\": \"heatmap\"}, \"title\": \"Missingness\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Column\", \"type\": \"nominal\"}, {\"field\": \"null_count\", \"format\": \",.0f\", \"title\": \"Count of nulls\", \"type\": \"quantitative\"}, {\"field\": \"null_proportion\", \"format\": \".2%\", \"title\": \"Percentage of nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_record_count\", \"format\": \",.0f\", \"title\": \"Total record count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"format\": \"%\", \"labelAlign\": \"center\", \"title\": \"Percentage of nulls\"}, \"field\": \"null_proportion\", \"scale\": {\"domain\": [0, 1]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"\"}, \"field\": \"column_name\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"title\": \"Missingness per column out of 5,000 records\"}], \"data\": {\"values\": [{\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"rec_id\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"given_name\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"surname\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"street_number\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"address_1\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"address_2\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"suburb\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"postcode\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"state\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"date_of_birth\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"soc_sec_id\"}, {\"null_proportion\": 0.0, \"null_count\": 0, \"total_record_count\": 5000, \"column_name\": \"cluster\"}], \"name\": \"data-0e7bce5a1d2f132e282789d6ef7780fe\"}, \"title\": \"\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.missingness_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-259f37c3e152407e9910b716d4754d93.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-259f37c3e152407e9910b716d4754d93.vega-embed details,\n",
       "  #altair-viz-259f37c3e152407e9910b716d4754d93.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-259f37c3e152407e9910b716d4754d93\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-259f37c3e152407e9910b716d4754d93\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-259f37c3e152407e9910b716d4754d93\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"rec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 5000.0, \"distinct_value_count\": 5000}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 1, \"group_name\": \"rec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 5000.0, \"distinct_value_count\": 5000}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column rec_id\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 5000 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1496-org\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-552-dup-3\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-988-dup-1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1716-dup-1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1213-org\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-193-org\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-264-dup-0\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1695-dup-3\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-875-dup-0\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1778-dup-1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1496-org\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-552-dup-3\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-988-dup-1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1716-dup-1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1213-org\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-193-org\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-264-dup-0\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1695-dup-3\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-875-dup-0\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}, {\"value_count\": 1, \"group_name\": \"rec_id\", \"value\": \"rec-1778-dup-1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 5000}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9688000082969666, \"percentile_inc_nulls\": 0.9688000082969666, \"value_count\": 156, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9526000022888184, \"percentile_inc_nulls\": 0.9526000022888184, \"value_count\": 81, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9387999773025513, \"percentile_inc_nulls\": 0.9387999773025513, \"value_count\": 69, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9265999794006348, \"percentile_inc_nulls\": 0.9265999794006348, \"value_count\": 61, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 61.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9157999753952026, \"percentile_inc_nulls\": 0.9157999753952026, \"value_count\": 54, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9056000113487244, \"percentile_inc_nulls\": 0.9056000113487244, \"value_count\": 51, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 51.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.895799994468689, \"percentile_inc_nulls\": 0.895799994468689, \"value_count\": 49, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 49.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8863999843597412, \"percentile_inc_nulls\": 0.8863999843597412, \"value_count\": 47, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8772000074386597, \"percentile_inc_nulls\": 0.8772000074386597, \"value_count\": 46, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8682000041007996, \"percentile_inc_nulls\": 0.8682000041007996, \"value_count\": 45, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8597999811172485, \"percentile_inc_nulls\": 0.8597999811172485, \"value_count\": 42, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.836400032043457, \"percentile_inc_nulls\": 0.836400032043457, \"value_count\": 39, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 117.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8141999840736389, \"percentile_inc_nulls\": 0.8141999840736389, \"value_count\": 37, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8073999881744385, \"percentile_inc_nulls\": 0.8073999881744385, \"value_count\": 34, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7946000099182129, \"percentile_inc_nulls\": 0.7946000099182129, \"value_count\": 32, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7821999788284302, \"percentile_inc_nulls\": 0.7821999788284302, \"value_count\": 31, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7702000141143799, \"percentile_inc_nulls\": 0.7702000141143799, \"value_count\": 30, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7644000053405762, \"percentile_inc_nulls\": 0.7644000053405762, \"value_count\": 29, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7588000297546387, \"percentile_inc_nulls\": 0.7588000297546387, \"value_count\": 28, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7425999641418457, \"percentile_inc_nulls\": 0.7425999641418457, \"value_count\": 27, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7373999953269958, \"percentile_inc_nulls\": 0.7373999953269958, \"value_count\": 26, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.727400004863739, \"percentile_inc_nulls\": 0.727400004863739, \"value_count\": 25, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7081999778747559, \"percentile_inc_nulls\": 0.7081999778747559, \"value_count\": 24, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6759999990463257, \"percentile_inc_nulls\": 0.6759999990463257, \"value_count\": 23, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6540000438690186, \"percentile_inc_nulls\": 0.6540000438690186, \"value_count\": 22, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 110.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6288000345230103, \"percentile_inc_nulls\": 0.6288000345230103, \"value_count\": 21, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6208000183105469, \"percentile_inc_nulls\": 0.6208000183105469, \"value_count\": 20, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6094000339508057, \"percentile_inc_nulls\": 0.6094000339508057, \"value_count\": 19, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5914000272750854, \"percentile_inc_nulls\": 0.5914000272750854, \"value_count\": 18, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5845999717712402, \"percentile_inc_nulls\": 0.5845999717712402, \"value_count\": 17, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5717999935150146, \"percentile_inc_nulls\": 0.5717999935150146, \"value_count\": 16, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5478000044822693, \"percentile_inc_nulls\": 0.5478000044822693, \"value_count\": 15, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.522599995136261, \"percentile_inc_nulls\": 0.522599995136261, \"value_count\": 14, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.509600043296814, \"percentile_inc_nulls\": 0.509600043296814, \"value_count\": 13, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5024000406265259, \"percentile_inc_nulls\": 0.5024000406265259, \"value_count\": 12, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.48919999599456787, \"percentile_inc_nulls\": 0.48919999599456787, \"value_count\": 11, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 66.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.4631999731063843, \"percentile_inc_nulls\": 0.4631999731063843, \"value_count\": 10, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 130.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.4326000213623047, \"percentile_inc_nulls\": 0.4326000213623047, \"value_count\": 9, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 153.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.40380001068115234, \"percentile_inc_nulls\": 0.40380001068115234, \"value_count\": 8, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.3659999966621399, \"percentile_inc_nulls\": 0.3659999966621399, \"value_count\": 7, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.33240002393722534, \"percentile_inc_nulls\": 0.33240002393722534, \"value_count\": 6, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.2784000039100647, \"percentile_inc_nulls\": 0.2784000039100647, \"value_count\": 5, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 270.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.23680001497268677, \"percentile_inc_nulls\": 0.23680001497268677, \"value_count\": 4, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.1905999779701233, \"percentile_inc_nulls\": 0.1905999779701233, \"value_count\": 3, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 231.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.14020001888275146, \"percentile_inc_nulls\": 0.14020001888275146, \"value_count\": 2, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 252.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 701.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 156, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column given_name\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1214 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 156, \"group_name\": \"given_name\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 81, \"group_name\": \"given_name\", \"value\": \" joshua\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 69, \"group_name\": \"given_name\", \"value\": \" emiily\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 61, \"group_name\": \"given_name\", \"value\": \" jack\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 54, \"group_name\": \"given_name\", \"value\": \" benjamin\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 51, \"group_name\": \"given_name\", \"value\": \" isabella\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 49, \"group_name\": \"given_name\", \"value\": \" samuel\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 47, \"group_name\": \"given_name\", \"value\": \" thomas\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 46, \"group_name\": \"given_name\", \"value\": \" sophie\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 45, \"group_name\": \"given_name\", \"value\": \" james\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" braecon\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" rily\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" lary\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" katel byn\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" ebiny\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" feilcity\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" karfissa\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" shakiroh\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" wanders\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" nathab\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 156]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9753999710083008, \"percentile_inc_nulls\": 0.9753999710083008, \"value_count\": 123, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9581999778747559, \"percentile_inc_nulls\": 0.9581999778747559, \"value_count\": 86, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9423999786376953, \"percentile_inc_nulls\": 0.9423999786376953, \"value_count\": 79, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 79.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9277999997138977, \"percentile_inc_nulls\": 0.9277999997138977, \"value_count\": 73, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 73.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9139999747276306, \"percentile_inc_nulls\": 0.9139999747276306, \"value_count\": 69, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9025999903678894, \"percentile_inc_nulls\": 0.9025999903678894, \"value_count\": 57, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8925999999046326, \"percentile_inc_nulls\": 0.8925999999046326, \"value_count\": 50, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8831999897956848, \"percentile_inc_nulls\": 0.8831999897956848, \"value_count\": 47, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8740000128746033, \"percentile_inc_nulls\": 0.8740000128746033, \"value_count\": 46, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.847599983215332, \"percentile_inc_nulls\": 0.847599983215332, \"value_count\": 44, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 132.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8395999670028687, \"percentile_inc_nulls\": 0.8395999670028687, \"value_count\": 40, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8317999839782715, \"percentile_inc_nulls\": 0.8317999839782715, \"value_count\": 39, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 39.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8242000341415405, \"percentile_inc_nulls\": 0.8242000341415405, \"value_count\": 38, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8181999921798706, \"percentile_inc_nulls\": 0.8181999921798706, \"value_count\": 30, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 30.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8123999834060669, \"percentile_inc_nulls\": 0.8123999834060669, \"value_count\": 29, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8068000078201294, \"percentile_inc_nulls\": 0.8068000078201294, \"value_count\": 28, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7906000018119812, \"percentile_inc_nulls\": 0.7906000018119812, \"value_count\": 27, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7802000045776367, \"percentile_inc_nulls\": 0.7802000045776367, \"value_count\": 26, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7752000093460083, \"percentile_inc_nulls\": 0.7752000093460083, \"value_count\": 25, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 25.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7703999876976013, \"percentile_inc_nulls\": 0.7703999876976013, \"value_count\": 24, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 24.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7660000324249268, \"percentile_inc_nulls\": 0.7660000324249268, \"value_count\": 22, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 22.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7576000094413757, \"percentile_inc_nulls\": 0.7576000094413757, \"value_count\": 21, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.75, \"percentile_inc_nulls\": 0.75, \"value_count\": 19, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7427999973297119, \"percentile_inc_nulls\": 0.7427999973297119, \"value_count\": 18, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7394000291824341, \"percentile_inc_nulls\": 0.7394000291824341, \"value_count\": 17, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 17.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7265999913215637, \"percentile_inc_nulls\": 0.7265999913215637, \"value_count\": 16, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7175999879837036, \"percentile_inc_nulls\": 0.7175999879837036, \"value_count\": 15, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7120000123977661, \"percentile_inc_nulls\": 0.7120000123977661, \"value_count\": 14, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7015999555587769, \"percentile_inc_nulls\": 0.7015999555587769, \"value_count\": 13, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6872000098228455, \"percentile_inc_nulls\": 0.6872000098228455, \"value_count\": 12, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6762000322341919, \"percentile_inc_nulls\": 0.6762000322341919, \"value_count\": 11, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 55.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6582000255584717, \"percentile_inc_nulls\": 0.6582000255584717, \"value_count\": 10, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6402000188827515, \"percentile_inc_nulls\": 0.6402000188827515, \"value_count\": 9, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6161999702453613, \"percentile_inc_nulls\": 0.6161999702453613, \"value_count\": 8, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.5839999914169312, \"percentile_inc_nulls\": 0.5839999914169312, \"value_count\": 7, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.5371999740600586, \"percentile_inc_nulls\": 0.5371999740600586, \"value_count\": 6, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 234.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.46219998598098755, \"percentile_inc_nulls\": 0.46219998598098755, \"value_count\": 5, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 375.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.3845999836921692, \"percentile_inc_nulls\": 0.3845999836921692, \"value_count\": 4, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 388.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.3011999726295471, \"percentile_inc_nulls\": 0.3011999726295471, \"value_count\": 3, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 417.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.20959997177124023, \"percentile_inc_nulls\": 0.20959997177124023, \"value_count\": 2, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 458.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1048.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 123, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column surname\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1741 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 123, \"group_name\": \"surname\", \"value\": \" white\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 86, \"group_name\": \"surname\", \"value\": \" clarke\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 79, \"group_name\": \"surname\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 73, \"group_name\": \"surname\", \"value\": \" campbell\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 69, \"group_name\": \"surname\", \"value\": \" ryan\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 57, \"group_name\": \"surname\", \"value\": \" green\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 50, \"group_name\": \"surname\", \"value\": \" reid\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 47, \"group_name\": \"surname\", \"value\": \" dixon\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 46, \"group_name\": \"surname\", \"value\": \" nguyen\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 44, \"group_name\": \"surname\", \"value\": \" webb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" hathaway\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" mccattmhy\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" gredn\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" pitno\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" grifefn\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" daykin\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" slywka\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" colegte\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" hylnand\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" roussonuis\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 123]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9509999752044678, \"percentile_inc_nulls\": 0.9509999752044678, \"value_count\": 245, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 245.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.9178000092506409, \"percentile_inc_nulls\": 0.9178000092506409, \"value_count\": 166, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 166.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.8859999775886536, \"percentile_inc_nulls\": 0.8859999775886536, \"value_count\": 159, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 159.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.8560000061988831, \"percentile_inc_nulls\": 0.8560000061988831, \"value_count\": 150, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 150.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.829200029373169, \"percentile_inc_nulls\": 0.829200029373169, \"value_count\": 134, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 134.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.8027999997138977, \"percentile_inc_nulls\": 0.8027999997138977, \"value_count\": 132, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 132.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.7789999842643738, \"percentile_inc_nulls\": 0.7789999842643738, \"value_count\": 119, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 119.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.7555999755859375, \"percentile_inc_nulls\": 0.7555999755859375, \"value_count\": 117, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 117.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.7333999872207642, \"percentile_inc_nulls\": 0.7333999872207642, \"value_count\": 111, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.711400032043457, \"percentile_inc_nulls\": 0.711400032043457, \"value_count\": 110, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 110.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.6899999976158142, \"percentile_inc_nulls\": 0.6899999976158142, \"value_count\": 107, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 107.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.6687999963760376, \"percentile_inc_nulls\": 0.6687999963760376, \"value_count\": 106, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 106.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.6484000086784363, \"percentile_inc_nulls\": 0.6484000086784363, \"value_count\": 102, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 102.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.6281999945640564, \"percentile_inc_nulls\": 0.6281999945640564, \"value_count\": 101, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 101.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.6089999675750732, \"percentile_inc_nulls\": 0.6089999675750732, \"value_count\": 96, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.5734000205993652, \"percentile_inc_nulls\": 0.5734000205993652, \"value_count\": 89, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 178.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.5587999820709229, \"percentile_inc_nulls\": 0.5587999820709229, \"value_count\": 73, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 73.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.5180000066757202, \"percentile_inc_nulls\": 0.5180000066757202, \"value_count\": 68, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.5047999620437622, \"percentile_inc_nulls\": 0.5047999620437622, \"value_count\": 66, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 66.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4787999987602234, \"percentile_inc_nulls\": 0.4787999987602234, \"value_count\": 65, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 130.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4535999894142151, \"percentile_inc_nulls\": 0.4535999894142151, \"value_count\": 63, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4416000247001648, \"percentile_inc_nulls\": 0.4416000247001648, \"value_count\": 60, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4300000071525574, \"percentile_inc_nulls\": 0.4300000071525574, \"value_count\": 58, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 58.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4197999835014343, \"percentile_inc_nulls\": 0.4197999835014343, \"value_count\": 51, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 51.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4097999930381775, \"percentile_inc_nulls\": 0.4097999930381775, \"value_count\": 50, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.4002000093460083, \"percentile_inc_nulls\": 0.4002000093460083, \"value_count\": 48, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 48.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.39079999923706055, \"percentile_inc_nulls\": 0.39079999923706055, \"value_count\": 47, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3736000061035156, \"percentile_inc_nulls\": 0.3736000061035156, \"value_count\": 43, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3651999831199646, \"percentile_inc_nulls\": 0.3651999831199646, \"value_count\": 42, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3569999933242798, \"percentile_inc_nulls\": 0.3569999933242798, \"value_count\": 41, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 41.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3489999771118164, \"percentile_inc_nulls\": 0.3489999771118164, \"value_count\": 40, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.34200000762939453, \"percentile_inc_nulls\": 0.34200000762939453, \"value_count\": 35, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 35.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3352000117301941, \"percentile_inc_nulls\": 0.3352000117301941, \"value_count\": 34, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3285999894142151, \"percentile_inc_nulls\": 0.3285999894142151, \"value_count\": 33, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 33.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.3094000220298767, \"percentile_inc_nulls\": 0.3094000220298767, \"value_count\": 32, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.2978000044822693, \"percentile_inc_nulls\": 0.2978000044822693, \"value_count\": 29, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 58.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.2865999937057495, \"percentile_inc_nulls\": 0.2865999937057495, \"value_count\": 28, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 56.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.28119999170303345, \"percentile_inc_nulls\": 0.28119999170303345, \"value_count\": 27, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 27.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.2760000228881836, \"percentile_inc_nulls\": 0.2760000228881836, \"value_count\": 26, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.2616000175476074, \"percentile_inc_nulls\": 0.2616000175476074, \"value_count\": 24, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.24779999256134033, \"percentile_inc_nulls\": 0.24779999256134033, \"value_count\": 23, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.243399977684021, \"percentile_inc_nulls\": 0.243399977684021, \"value_count\": 22, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 22.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.23079997301101685, \"percentile_inc_nulls\": 0.23079997301101685, \"value_count\": 21, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 63.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.21480000019073486, \"percentile_inc_nulls\": 0.21480000019073486, \"value_count\": 20, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 80.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.21100002527236938, \"percentile_inc_nulls\": 0.21100002527236938, \"value_count\": 19, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 19.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.20020002126693726, \"percentile_inc_nulls\": 0.20020002126693726, \"value_count\": 18, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.19340002536773682, \"percentile_inc_nulls\": 0.19340002536773682, \"value_count\": 17, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.1844000220298767, \"percentile_inc_nulls\": 0.1844000220298767, \"value_count\": 15, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.17599999904632568, \"percentile_inc_nulls\": 0.17599999904632568, \"value_count\": 14, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.17079997062683105, \"percentile_inc_nulls\": 0.17079997062683105, \"value_count\": 13, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.16360002756118774, \"percentile_inc_nulls\": 0.16360002756118774, \"value_count\": 12, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.15700000524520874, \"percentile_inc_nulls\": 0.15700000524520874, \"value_count\": 11, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 33.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.14499998092651367, \"percentile_inc_nulls\": 0.14499998092651367, \"value_count\": 10, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.13779997825622559, \"percentile_inc_nulls\": 0.13779997825622559, \"value_count\": 9, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.12339997291564941, \"percentile_inc_nulls\": 0.12339997291564941, \"value_count\": 8, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.11220002174377441, \"percentile_inc_nulls\": 0.11220002174377441, \"value_count\": 7, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 56.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.0965999960899353, \"percentile_inc_nulls\": 0.0965999960899353, \"value_count\": 6, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.07359999418258667, \"percentile_inc_nulls\": 0.07359999418258667, \"value_count\": 5, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.052799999713897705, \"percentile_inc_nulls\": 0.052799999713897705, \"value_count\": 4, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 104.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.03780001401901245, \"percentile_inc_nulls\": 0.03780001401901245, \"value_count\": 3, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 75.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.02060002088546753, \"percentile_inc_nulls\": 0.02060002088546753, \"value_count\": 2, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 103.0, \"distinct_value_count\": 343}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 245, \"group_name\": \"street_number\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 245.0, \"distinct_value_count\": 343}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column street_number\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 343 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 245, \"group_name\": \"street_number\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 166, \"group_name\": \"street_number\", \"value\": \" 1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 159, \"group_name\": \"street_number\", \"value\": \" 3\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 150, \"group_name\": \"street_number\", \"value\": \" 5\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 134, \"group_name\": \"street_number\", \"value\": \" 8\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 132, \"group_name\": \"street_number\", \"value\": \" 4\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 119, \"group_name\": \"street_number\", \"value\": \" 16\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 117, \"group_name\": \"street_number\", \"value\": \" 7\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 111, \"group_name\": \"street_number\", \"value\": \" 11\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 110, \"group_name\": \"street_number\", \"value\": \" 12\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 106\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 431\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 560\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 318\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 464\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 415\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 299\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 220\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 187\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}, {\"value_count\": 1, \"group_name\": \"street_number\", \"value\": \" 426\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 343}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 245]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9692000150680542, \"percentile_inc_nulls\": 0.9692000150680542, \"value_count\": 154, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 154.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.9656000137329102, \"percentile_inc_nulls\": 0.9656000137329102, \"value_count\": 18, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 18.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.9621999859809875, \"percentile_inc_nulls\": 0.9621999859809875, \"value_count\": 17, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 17.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.9557999968528748, \"percentile_inc_nulls\": 0.9557999968528748, \"value_count\": 16, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 32.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.942799985408783, \"percentile_inc_nulls\": 0.942799985408783, \"value_count\": 13, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.9380000233650208, \"percentile_inc_nulls\": 0.9380000233650208, \"value_count\": 12, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 24.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.9247999787330627, \"percentile_inc_nulls\": 0.9247999787330627, \"value_count\": 11, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 66.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.9187999963760376, \"percentile_inc_nulls\": 0.9187999963760376, \"value_count\": 10, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 30.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.8845999836921692, \"percentile_inc_nulls\": 0.8845999836921692, \"value_count\": 9, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 171.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.849399983882904, \"percentile_inc_nulls\": 0.849399983882904, \"value_count\": 8, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 176.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.8073999881744385, \"percentile_inc_nulls\": 0.8073999881744385, \"value_count\": 7, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 210.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.7450000047683716, \"percentile_inc_nulls\": 0.7450000047683716, \"value_count\": 6, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 312.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.6510000228881836, \"percentile_inc_nulls\": 0.6510000228881836, \"value_count\": 5, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 470.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.5429999828338623, \"percentile_inc_nulls\": 0.5429999828338623, \"value_count\": 4, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 540.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.41759997606277466, \"percentile_inc_nulls\": 0.41759997606277466, \"value_count\": 3, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 627.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.2932000160217285, \"percentile_inc_nulls\": 0.2932000160217285, \"value_count\": 2, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 622.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1466.0, \"distinct_value_count\": 2359}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 154, \"group_name\": \"address_1\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 154.0, \"distinct_value_count\": 2359}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column address_1\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 2359 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 154, \"group_name\": \"address_1\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 18, \"group_name\": \"address_1\", \"value\": \" newman morris circuit\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 17, \"group_name\": \"address_1\", \"value\": \" ashburton circuit\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 16, \"group_name\": \"address_1\", \"value\": \" oxley street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 16, \"group_name\": \"address_1\", \"value\": \" endeavour street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 13, \"group_name\": \"address_1\", \"value\": \" sinclair street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 13, \"group_name\": \"address_1\", \"value\": \" tenison-woods circuit\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 13, \"group_name\": \"address_1\", \"value\": \" leahy close\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 13, \"group_name\": \"address_1\", \"value\": \" kitchener street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 13, \"group_name\": \"address_1\", \"value\": \" hilder street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" wallaby place\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" pridhamstreet\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" yuranigh court\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" kent street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" mckillop ecircuit\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" blameycrescent\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" wilshiredstreet\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" jarreah\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" bousteadcircuit\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}, {\"value_count\": 1, \"group_name\": \"address_1\", \"value\": \" clift crecent\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2359}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 154]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.8614000082015991, \"percentile_inc_nulls\": 0.8614000082015991, \"value_count\": 693, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 693.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.8550000190734863, \"percentile_inc_nulls\": 0.8550000190734863, \"value_count\": 32, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 32.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.849399983882904, \"percentile_inc_nulls\": 0.849399983882904, \"value_count\": 28, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.8452000021934509, \"percentile_inc_nulls\": 0.8452000021934509, \"value_count\": 21, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 21.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.8379999995231628, \"percentile_inc_nulls\": 0.8379999995231628, \"value_count\": 18, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.8348000049591064, \"percentile_inc_nulls\": 0.8348000049591064, \"value_count\": 16, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 16.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.8321999907493591, \"percentile_inc_nulls\": 0.8321999907493591, \"value_count\": 13, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 13.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.824999988079071, \"percentile_inc_nulls\": 0.824999988079071, \"value_count\": 12, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.8118000030517578, \"percentile_inc_nulls\": 0.8118000030517578, \"value_count\": 11, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 66.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.7997999787330627, \"percentile_inc_nulls\": 0.7997999787330627, \"value_count\": 10, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.7835999727249146, \"percentile_inc_nulls\": 0.7835999727249146, \"value_count\": 9, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.7675999999046326, \"percentile_inc_nulls\": 0.7675999999046326, \"value_count\": 8, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 80.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.7508000135421753, \"percentile_inc_nulls\": 0.7508000135421753, \"value_count\": 7, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 84.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.7111999988555908, \"percentile_inc_nulls\": 0.7111999988555908, \"value_count\": 6, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 198.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.6491999626159668, \"percentile_inc_nulls\": 0.6491999626159668, \"value_count\": 5, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 310.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.5523999929428101, \"percentile_inc_nulls\": 0.5523999929428101, \"value_count\": 4, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 484.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.4336000084877014, \"percentile_inc_nulls\": 0.4336000084877014, \"value_count\": 3, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 594.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.30080002546310425, \"percentile_inc_nulls\": 0.30080002546310425, \"value_count\": 2, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 664.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1504.0, \"distinct_value_count\": 2304}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 693, \"group_name\": \"address_2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 693.0, \"distinct_value_count\": 2304}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column address_2\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 2304 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 693, \"group_name\": \"address_2\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 32, \"group_name\": \"address_2\", \"value\": \" brentwood vlge\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 28, \"group_name\": \"address_2\", \"value\": \" rowethorpe\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 21, \"group_name\": \"address_2\", \"value\": \" villa 2\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 18, \"group_name\": \"address_2\", \"value\": \" john flynn medical centre\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 18, \"group_name\": \"address_2\", \"value\": \" rosedale\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 16, \"group_name\": \"address_2\", \"value\": \" st francis vlge\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 13, \"group_name\": \"address_2\", \"value\": \" mlc centre\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 12, \"group_name\": \"address_2\", \"value\": \" rosetta village\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 12, \"group_name\": \"address_2\", \"value\": \" glenlee\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" currin ga\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" kilvintonvillage\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" erinsavle\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" mackinnon street\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" newman medicajl centre\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" pinds\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" crown allot\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" bro okvale\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" sheep s tation\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}, {\"value_count\": 1, \"group_name\": \"address_2\", \"value\": \" rosehe ll\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2304}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 693]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9829999804496765, \"percentile_inc_nulls\": 0.9829999804496765, \"value_count\": 85, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9742000102996826, \"percentile_inc_nulls\": 0.9742000102996826, \"value_count\": 44, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 44.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9675999879837036, \"percentile_inc_nulls\": 0.9675999879837036, \"value_count\": 33, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 33.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9617999792098999, \"percentile_inc_nulls\": 0.9617999792098999, \"value_count\": 29, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9571999907493591, \"percentile_inc_nulls\": 0.9571999907493591, \"value_count\": 23, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 23.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.953000009059906, \"percentile_inc_nulls\": 0.953000009059906, \"value_count\": 21, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 21.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9491999745368958, \"percentile_inc_nulls\": 0.9491999745368958, \"value_count\": 19, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 19.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9384000301361084, \"percentile_inc_nulls\": 0.9384000301361084, \"value_count\": 18, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9214000105857849, \"percentile_inc_nulls\": 0.9214000105857849, \"value_count\": 17, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.9053999781608582, \"percentile_inc_nulls\": 0.9053999781608582, \"value_count\": 16, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 80.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.8844000101089478, \"percentile_inc_nulls\": 0.8844000101089478, \"value_count\": 15, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 105.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.8675999641418457, \"percentile_inc_nulls\": 0.8675999641418457, \"value_count\": 14, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 84.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.8519999980926514, \"percentile_inc_nulls\": 0.8519999980926514, \"value_count\": 13, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.823199987411499, \"percentile_inc_nulls\": 0.823199987411499, \"value_count\": 12, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.7813999652862549, \"percentile_inc_nulls\": 0.7813999652862549, \"value_count\": 11, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 209.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.7314000129699707, \"percentile_inc_nulls\": 0.7314000129699707, \"value_count\": 10, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 250.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.6953999996185303, \"percentile_inc_nulls\": 0.6953999996185303, \"value_count\": 9, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 180.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.6489999890327454, \"percentile_inc_nulls\": 0.6489999890327454, \"value_count\": 8, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 232.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.587399959564209, \"percentile_inc_nulls\": 0.587399959564209, \"value_count\": 7, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 308.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.5189999938011169, \"percentile_inc_nulls\": 0.5189999938011169, \"value_count\": 6, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 342.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.44199997186660767, \"percentile_inc_nulls\": 0.44199997186660767, \"value_count\": 5, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 385.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.34439998865127563, \"percentile_inc_nulls\": 0.34439998865127563, \"value_count\": 4, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 488.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.26340001821517944, \"percentile_inc_nulls\": 0.26340001821517944, \"value_count\": 3, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 405.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.18779999017715454, \"percentile_inc_nulls\": 0.18779999017715454, \"value_count\": 2, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 378.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 939.0, \"distinct_value_count\": 1707}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 85, \"group_name\": \"suburb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 1707}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column suburb\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1707 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 85, \"group_name\": \"suburb\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 44, \"group_name\": \"suburb\", \"value\": \" frankston\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 33, \"group_name\": \"suburb\", \"value\": \" mosman\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 29, \"group_name\": \"suburb\", \"value\": \" toowoomba\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 23, \"group_name\": \"suburb\", \"value\": \" coffs harbour\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 21, \"group_name\": \"suburb\", \"value\": \" dianella\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 19, \"group_name\": \"suburb\", \"value\": \" orange\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 18, \"group_name\": \"suburb\", \"value\": \" balwyn north\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 18, \"group_name\": \"suburb\", \"value\": \" sunshine\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 18, \"group_name\": \"suburb\", \"value\": \" belmont\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" towradgi\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" rose ay\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" winstonhills\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" prairei\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" murphys rceek\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" pottsville beach\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" cottles bridge\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" mount sophia\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" point lofsdale\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}, {\"value_count\": 1, \"group_name\": \"suburb\", \"value\": \" oakden\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1707}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 85]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9940000176429749, \"percentile_inc_nulls\": 0.9940000176429749, \"value_count\": 30, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 30.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9882000088691711, \"percentile_inc_nulls\": 0.9882000088691711, \"value_count\": 29, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9829999804496765, \"percentile_inc_nulls\": 0.9829999804496765, \"value_count\": 26, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9783999919891357, \"percentile_inc_nulls\": 0.9783999919891357, \"value_count\": 23, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 23.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9739999771118164, \"percentile_inc_nulls\": 0.9739999771118164, \"value_count\": 22, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 22.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9656000137329102, \"percentile_inc_nulls\": 0.9656000137329102, \"value_count\": 21, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9616000056266785, \"percentile_inc_nulls\": 0.9616000056266785, \"value_count\": 20, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 20.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.957800030708313, \"percentile_inc_nulls\": 0.957800030708313, \"value_count\": 19, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 19.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9470000267028809, \"percentile_inc_nulls\": 0.9470000267028809, \"value_count\": 18, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9300000071525574, \"percentile_inc_nulls\": 0.9300000071525574, \"value_count\": 17, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9107999801635742, \"percentile_inc_nulls\": 0.9107999801635742, \"value_count\": 16, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.9017999768257141, \"percentile_inc_nulls\": 0.9017999768257141, \"value_count\": 15, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.8709999918937683, \"percentile_inc_nulls\": 0.8709999918937683, \"value_count\": 14, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 154.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.8553999662399292, \"percentile_inc_nulls\": 0.8553999662399292, \"value_count\": 13, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.8242000341415405, \"percentile_inc_nulls\": 0.8242000341415405, \"value_count\": 12, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.771399974822998, \"percentile_inc_nulls\": 0.771399974822998, \"value_count\": 11, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 264.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.727400004863739, \"percentile_inc_nulls\": 0.727400004863739, \"value_count\": 10, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 220.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.6662000417709351, \"percentile_inc_nulls\": 0.6662000417709351, \"value_count\": 9, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 306.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.6022000312805176, \"percentile_inc_nulls\": 0.6022000312805176, \"value_count\": 8, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 320.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.5392000079154968, \"percentile_inc_nulls\": 0.5392000079154968, \"value_count\": 7, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 315.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.4408000111579895, \"percentile_inc_nulls\": 0.4408000111579895, \"value_count\": 6, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 492.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.3407999873161316, \"percentile_inc_nulls\": 0.3407999873161316, \"value_count\": 5, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 500.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.23839998245239258, \"percentile_inc_nulls\": 0.23839998245239258, \"value_count\": 4, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 512.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.15679997205734253, \"percentile_inc_nulls\": 0.15679997205734253, \"value_count\": 3, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 408.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.08560001850128174, \"percentile_inc_nulls\": 0.08560001850128174, \"value_count\": 2, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 356.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 428.0, \"distinct_value_count\": 1273}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 30, \"group_name\": \"postcode\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 30.0, \"distinct_value_count\": 1273}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column postcode\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1273 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 30, \"group_name\": \"postcode\", \"value\": \"2250\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 29, \"group_name\": \"postcode\", \"value\": \"6210\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 26, \"group_name\": \"postcode\", \"value\": \"2570\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 23, \"group_name\": \"postcode\", \"value\": \"2756\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 22, \"group_name\": \"postcode\", \"value\": \"4740\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 21, \"group_name\": \"postcode\", \"value\": \"2830\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 21, \"group_name\": \"postcode\", \"value\": \"2170\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 20, \"group_name\": \"postcode\", \"value\": \"4670\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 19, \"group_name\": \"postcode\", \"value\": \"2280\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 18, \"group_name\": \"postcode\", \"value\": \"3149\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"4881\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"3107\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"2028\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"4110\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"5091\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"6111\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"4365\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"3060\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"4153\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}, {\"value_count\": 1, \"group_name\": \"postcode\", \"value\": \"5158\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1273}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 30]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.6837999820709229, \"percentile_inc_nulls\": 0.6837999820709229, \"value_count\": 1581, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1581.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.4413999915122986, \"percentile_inc_nulls\": 0.4413999915122986, \"value_count\": 1212, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1212.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.27719998359680176, \"percentile_inc_nulls\": 0.27719998359680176, \"value_count\": 821, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 821.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.17799997329711914, \"percentile_inc_nulls\": 0.17799997329711914, \"value_count\": 496, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 496.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.08539998531341553, \"percentile_inc_nulls\": 0.08539998531341553, \"value_count\": 463, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 463.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.06180000305175781, \"percentile_inc_nulls\": 0.06180000305175781, \"value_count\": 118, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 118.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.04259997606277466, \"percentile_inc_nulls\": 0.04259997606277466, \"value_count\": 96, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.025600016117095947, \"percentile_inc_nulls\": 0.025600016117095947, \"value_count\": 85, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.014199972152709961, \"percentile_inc_nulls\": 0.014199972152709961, \"value_count\": 57, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.011600017547607422, \"percentile_inc_nulls\": 0.011600017547607422, \"value_count\": 13, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 13.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.009400010108947754, \"percentile_inc_nulls\": 0.009400010108947754, \"value_count\": 11, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 11.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.008199989795684814, \"percentile_inc_nulls\": 0.008199989795684814, \"value_count\": 6, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 6.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.007200002670288086, \"percentile_inc_nulls\": 0.007200002670288086, \"value_count\": 5, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 5.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.0055999755859375, \"percentile_inc_nulls\": 0.0055999755859375, \"value_count\": 4, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 8.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.00279998779296875, \"percentile_inc_nulls\": 0.00279998779296875, \"value_count\": 2, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 14.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 14.0, \"distinct_value_count\": 36}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 1581, \"group_name\": \"state\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1581.0, \"distinct_value_count\": 36}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column state\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 36 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1581, \"group_name\": \"state\", \"value\": \" nsw\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1212, \"group_name\": \"state\", \"value\": \" vic\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 821, \"group_name\": \"state\", \"value\": \" qld\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 496, \"group_name\": \"state\", \"value\": \" wa\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 463, \"group_name\": \"state\", \"value\": \" sa\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 118, \"group_name\": \"state\", \"value\": \" tas\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 96, \"group_name\": \"state\", \"value\": \" act\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 85, \"group_name\": \"state\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 57, \"group_name\": \"state\", \"value\": \" nt\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 13, \"group_name\": \"state\", \"value\": \" nws\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"state\", \"value\": \" nse\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" wq\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" nsy\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" nhw\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" nf\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" vkc\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" sct\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" qle\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" nsh\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}, {\"value_count\": 1, \"group_name\": \"state\", \"value\": \" ws\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 36}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 1581]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.968999981880188, \"percentile_inc_nulls\": 0.968999981880188, \"value_count\": 155, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 155.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.9666000008583069, \"percentile_inc_nulls\": 0.9666000008583069, \"value_count\": 12, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 12.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.9646000266075134, \"percentile_inc_nulls\": 0.9646000266075134, \"value_count\": 10, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 10.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.9610000252723694, \"percentile_inc_nulls\": 0.9610000252723694, \"value_count\": 9, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 18.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.9593999981880188, \"percentile_inc_nulls\": 0.9593999981880188, \"value_count\": 8, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 8.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.948199987411499, \"percentile_inc_nulls\": 0.948199987411499, \"value_count\": 7, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 56.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.8185999989509583, \"percentile_inc_nulls\": 0.8185999989509583, \"value_count\": 6, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 648.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.6466000080108643, \"percentile_inc_nulls\": 0.6466000080108643, \"value_count\": 5, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 860.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.4994000196456909, \"percentile_inc_nulls\": 0.4994000196456909, \"value_count\": 4, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 736.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.34460002183914185, \"percentile_inc_nulls\": 0.34460002183914185, \"value_count\": 3, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 774.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.19700002670288086, \"percentile_inc_nulls\": 0.19700002670288086, \"value_count\": 2, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 738.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 985.0, \"distinct_value_count\": 2090}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 155, \"group_name\": \"date_of_birth\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 155.0, \"distinct_value_count\": 2090}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column date_of_birth\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 2090 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 155, \"group_name\": \"date_of_birth\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 12, \"group_name\": \"date_of_birth\", \"value\": \" 19070923\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 10, \"group_name\": \"date_of_birth\", \"value\": \" 19811017\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 9, \"group_name\": \"date_of_birth\", \"value\": \" 19960904\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 9, \"group_name\": \"date_of_birth\", \"value\": \" 19940729\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 8, \"group_name\": \"date_of_birth\", \"value\": \" 19010927\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 7, \"group_name\": \"date_of_birth\", \"value\": \" 19110405\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 7, \"group_name\": \"date_of_birth\", \"value\": \" 19670227\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 7, \"group_name\": \"date_of_birth\", \"value\": \" 19100830\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 7, \"group_name\": \"date_of_birth\", \"value\": \" 19640105\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19560409\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19940503\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19930714\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19510605\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19420909\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19230322\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19820410\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19080101\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19810828\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}, {\"value_count\": 1, \"group_name\": \"date_of_birth\", \"value\": \" 19720909\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2090}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 155]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.8776000142097473, \"percentile_inc_nulls\": 0.8776000142097473, \"value_count\": 6, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 612.0, \"distinct_value_count\": 2291}, {\"percentile_ex_nulls\": 0.7186000347137451, \"percentile_inc_nulls\": 0.7186000347137451, \"value_count\": 5, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 795.0, \"distinct_value_count\": 2291}, {\"percentile_ex_nulls\": 0.5418000221252441, \"percentile_inc_nulls\": 0.5418000221252441, \"value_count\": 4, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 884.0, \"distinct_value_count\": 2291}, {\"percentile_ex_nulls\": 0.3888000249862671, \"percentile_inc_nulls\": 0.3888000249862671, \"value_count\": 3, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 765.0, \"distinct_value_count\": 2291}, {\"percentile_ex_nulls\": 0.23280000686645508, \"percentile_inc_nulls\": 0.23280000686645508, \"value_count\": 2, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 780.0, \"distinct_value_count\": 2291}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1164.0, \"distinct_value_count\": 2291}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 6, \"group_name\": \"soc_sec_id\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 612.0, \"distinct_value_count\": 2291}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column soc_sec_id\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 2291 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"9695933\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"1690126\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"3939901\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"9354762\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"8789539\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"6548135\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"6281502\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"2328993\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"8072193\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 6, \"group_name\": \"soc_sec_id\", \"value\": \"4409764\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"1804974\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"9144092\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"1232838\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"4892623\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"8871067\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"7442486\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"6408579\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"1615186\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"8671640\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}, {\"value_count\": 1, \"group_name\": \"soc_sec_id\", \"value\": \"9216585\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2291}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 6]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.7983999848365784, \"percentile_inc_nulls\": 0.7983999848365784, \"value_count\": 6, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1008.0, \"distinct_value_count\": 2000}, {\"percentile_ex_nulls\": 0.6374000310897827, \"percentile_inc_nulls\": 0.6374000310897827, \"value_count\": 5, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 805.0, \"distinct_value_count\": 2000}, {\"percentile_ex_nulls\": 0.4678000211715698, \"percentile_inc_nulls\": 0.4678000211715698, \"value_count\": 4, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 848.0, \"distinct_value_count\": 2000}, {\"percentile_ex_nulls\": 0.3141999840736389, \"percentile_inc_nulls\": 0.3141999840736389, \"value_count\": 3, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 768.0, \"distinct_value_count\": 2000}, {\"percentile_ex_nulls\": 0.16699999570846558, \"percentile_inc_nulls\": 0.16699999570846558, \"value_count\": 2, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 736.0, \"distinct_value_count\": 2000}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 835.0, \"distinct_value_count\": 2000}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 6, \"group_name\": \"cluster\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1008.0, \"distinct_value_count\": 2000}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column cluster\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 2000 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-459\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-1561\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-885\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-1128\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-642\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-421\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-1560\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-540\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-636\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 6, \"group_name\": \"cluster\", \"value\": \"rec-427\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-1496\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-1213\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-193\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-1688\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-462\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-1626\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-182\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-501\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-15\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}, {\"value_count\": 1, \"group_name\": \"cluster\", \"value\": \"rec-717\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 2000}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 6]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.profile_columns(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1d3969a1959a49e3ae955727b7259f43.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1d3969a1959a49e3ae955727b7259f43.vega-embed details,\n",
       "  #altair-viz-1d3969a1959a49e3ae955727b7259f43.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1d3969a1959a49e3ae955727b7259f43\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1d3969a1959a49e3ae955727b7259f43\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1d3969a1959a49e3ae955727b7259f43\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-999bdc94c4b979aee64dffff4ff408bd\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"rule\", \"legend\": null, \"scale\": {\"scheme\": \"category20c\"}}, \"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Cartesian Product of Input Data\", \"type\": \"quantitative\"}, {\"field\": \"reduction_ratio\", \"title\": \"Reduction Ratio (cumulative rows/cartesian product)\", \"type\": \"nominal\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-999bdc94c4b979aee64dffff4ff408bd\": [{\"row_count\": 5601, \"rule\": \"l.\\\"soc_sec_id\\\" = r.\\\"soc_sec_id\\\"\", \"cumulative_rows\": 5601, \"cartesian\": 12497500, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999552. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 0}, {\"row_count\": 48681, \"rule\": \"l.\\\"given_name\\\" = r.\\\"given_name\\\"\", \"cumulative_rows\": 54282, \"cartesian\": 12497500, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.995657. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 5601}, {\"row_count\": 36675, \"rule\": \"l.\\\"surname\\\" = r.\\\"surname\\\"\", \"cumulative_rows\": 90957, \"cartesian\": 12497500, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.992722. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 54282}, {\"row_count\": 12256, \"rule\": \"l.\\\"date_of_birth\\\" = r.\\\"date_of_birth\\\"\", \"cumulative_rows\": 103213, \"cartesian\": 12497500, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.991741. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 90957}, {\"row_count\": 11037, \"rule\": \"l.\\\"postcode\\\" = r.\\\"postcode\\\"\", \"cumulative_rows\": 114250, \"cartesian\": 12497500, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.990858. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 103213}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.duckdb.blocking_rule_library import block_on\n",
    "\n",
    "blocking_rules = [\n",
    "        block_on(\"soc_sec_id\"),\n",
    "        block_on(\"given_name\"),\n",
    "        block_on(\"surname\"),\n",
    "        block_on(\"date_of_birth\"),\n",
    "        block_on(\"postcode\"),\n",
    "]\n",
    "linker.cumulative_num_comparisons_from_blocking_rules_chart(blocking_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import splink.duckdb.comparison_library as cl\n",
    "import splink.duckdb.comparison_template_library as ctl\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"unique_id_column_name\": \"rec_id\",\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": blocking_rules,\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"given_name\", term_frequency_adjustments=True),\n",
    "        ctl.name_comparison(\"surname\", term_frequency_adjustments=True),\n",
    "        ctl.date_comparison(\"date_of_birth\", \n",
    "                            damerau_levenshtein_thresholds=[],\n",
    "                            cast_strings_to_date=True,\n",
    "                            invalid_dates_as_null=True,\n",
    "                            date_format=\"%Y%m%d\"),\n",
    "        cl.levenshtein_at_thresholds(\"soc_sec_id\", [2]),\n",
    "        cl.exact_match(\"street_number\", term_frequency_adjustments=True),\n",
    "        cl.exact_match(\"postcode\", term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "}\n",
    "\n",
    "linker = DuckDBLinker(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000528.\n",
      "This means that amongst all possible pairwise record comparisons, one in 1,893.56 are expected to match.  With 12,497,500 total possible comparisons, we expect a total of around 6,600.00 matching pairs\n"
     ]
    }
   ],
   "source": [
    "deterministic_rules = [\n",
    "    \"l.soc_sec_id = r.soc_sec_id\",\n",
    "    \"l.given_name = r.given_name and l.surname = r.surname and l.date_of_birth = r.date_of_birth\",\n",
    "    \"l.given_name = r.surname and l.surname = r.given_name and l.date_of_birth = r.date_of_birth\"\n",
    "]\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - given_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - date_of_birth (no m values are trained).\n",
      "    - soc_sec_id (no m values are trained).\n",
      "    - street_number (no m values are trained).\n",
      "    - postcode (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "SUBSTR(l.\"date_of_birth\", 1, 3) = SUBSTR(r.\"date_of_birth\", 1, 3)\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - given_name\n",
      "    - surname\n",
      "    - soc_sec_id\n",
      "    - street_number\n",
      "    - postcode\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - date_of_birth\n",
      "\n",
      "Iteration 1: Largest change in params was -0.494 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was -0.0375 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 3: Largest change in params was -0.00566 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was -0.00088 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 5: Largest change in params was -0.000141 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 6: Largest change in params was -2.28e-05 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "\n",
      "Iteration 1: Largest change in params was -0.497 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was -0.0575 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 3: Largest change in params was -0.0147 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was -0.00348 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 5: Largest change in params was -0.000813 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 6: Largest change in params was -0.00019 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 7: Largest change in params was -4.46e-05 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "\n",
      "EM converged after 7 iterations\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - date_of_birth (no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "SUBSTR(l.\"postcode\", 1, 2) = SUBSTR(r.\"postcode\", 1, 2)\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - given_name\n",
      "    - surname\n",
      "    - date_of_birth\n",
      "    - soc_sec_id\n",
      "    - street_number\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - postcode\n",
      "\n",
      "Iteration 1: Largest change in params was -0.223 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was -0.0153 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 3: Largest change in params was -0.000962 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was -6.7e-05 in the m_probability of soc_sec_id, level `All other comparisons`\n",
      "\n",
      "EM converged after 5 iterations\n",
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "em_blocking_rule_1 = block_on(\"substr(date_of_birth,1,3)\")\n",
    "em_blocking_rule_2 = block_on(\"substr(postcode,1,2)\")\n",
    "session_dob = linker.estimate_parameters_using_expectation_maximisation(em_blocking_rule_1)\n",
    "session_postcode = linker.estimate_parameters_using_expectation_maximisation(em_blocking_rule_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-440a28db4f3e4814b9d0115877ad1e98.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-440a28db4f3e4814b9d0115877ad1e98.vega-embed details,\n",
       "  #altair-viz-440a28db4f3e4814b9d0115877ad1e98.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-440a28db4f3e4814b9d0115877ad1e98\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-440a28db4f3e4814b9d0115877ad1e98\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-440a28db4f3e4814b9d0115877ad1e98\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"range\": [\"red\", \"orange\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"range\": [\"red\", \"orange\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 10]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-33815c81bf478554a71e2a1bb9c702de\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-33815c81bf478554a71e2a1bb9c702de\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.0005283846640354178, \"log2_bayes_factor\": -10.886123785487664, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.001 or one in  1,893.6 records.This is equivalent to a starting match weight of -10.886.\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": -1}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"\\\"given_name_l\\\" = \\\"given_name_r\\\"\", \"label_for_charts\": \"Exact match given_name\", \"m_probability\": 0.5813919597697081, \"u_probability\": 0.004150568430322443, \"m_probability_description\": \"Amongst matching record comparisons, 58.14% of records are in the exact match given_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.42% of records are in the exact match given_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"given_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 140.07526186588902, \"log2_bayes_factor\": 7.130058379414156, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `exact match given_name` then comparison is 140.08 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"damerau_levenshtein(\\\"given_name_l\\\", \\\"given_name_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.1669513410033733, \"u_probability\": 0.0013150510442271914, \"m_probability_description\": \"Amongst matching record comparisons, 16.70% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.13% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 126.95426670793958, \"log2_bayes_factor\": 6.988165071998784, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 126.95 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"given_name_l\\\", \\\"given_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro_winkler_similarity >= 0.9\", \"m_probability\": 0.010039002852472756, \"u_probability\": 0.0017288301844511432, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the jaro_winkler_similarity >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.17% of records are in the jaro_winkler_similarity >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 5.80681835773238, \"log2_bayes_factor\": 2.537747906005935, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `jaro_winkler_similarity >= 0.9` then comparison is 5.81 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"given_name_l\\\", \\\"given_name_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro_winkler_similarity >= 0.8\", \"m_probability\": 0.0061290212022069995, \"u_probability\": 0.015267565710781158, \"m_probability_description\": \"Amongst matching record comparisons, 0.61% of records are in the jaro_winkler_similarity >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.53% of records are in the jaro_winkler_similarity >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.4014406303081443, \"log2_bayes_factor\": -1.3167414538280573, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `jaro_winkler_similarity >= 0.8` then comparison is  2.49 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"m_probability_description\": \"Amongst matching record comparisons, 23.55% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 97.75% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.24089976949726316, \"log2_bayes_factor\": -2.053495081739847, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match surname\", \"m_probability\": 0.5656235819937037, \"u_probability\": 0.0027932549085901925, \"m_probability_description\": \"Amongst matching record comparisons, 56.56% of records are in the exact match surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.28% of records are in the exact match surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 202.49622769988594, \"log2_bayes_factor\": 7.661751222071448, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 202.50 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"damerau_levenshtein(\\\"surname_l\\\", \\\"surname_r\\\") <= 1\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"m_probability\": 0.21447793815090613, \"u_probability\": 0.0010703218140234764, \"m_probability_description\": \"Amongst matching record comparisons, 21.45% of records are in the damerau_levenshtein <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.11% of records are in the damerau_levenshtein <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 200.38640280034673, \"log2_bayes_factor\": 7.6466408076988825, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 200.39 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro_winkler_similarity >= 0.9\", \"m_probability\": 0.026738753200696318, \"u_probability\": 0.0004098477469676672, \"m_probability_description\": \"Amongst matching record comparisons, 2.67% of records are in the jaro_winkler_similarity >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.04% of records are in the jaro_winkler_similarity >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 65.24069828009993, \"log2_bayes_factor\": 6.027700318381766, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `jaro_winkler_similarity >= 0.9` then comparison is 65.24 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro_winkler_similarity >= 0.8\", \"m_probability\": 0.005008638175183641, \"u_probability\": 0.009397995579148284, \"m_probability_description\": \"Amongst matching record comparisons, 0.50% of records are in the jaro_winkler_similarity >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.94% of records are in the jaro_winkler_similarity >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.5329474921542324, \"log2_bayes_factor\": -0.9079346942486702, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `jaro_winkler_similarity >= 0.8` then comparison is  1.88 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"m_probability_description\": \"Amongst matching record comparisons, 18.82% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.63% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.1907590353802845, \"log2_bayes_factor\": -2.390176702364317, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.9262257653870517, \"u_probability\": 0.0005122622782864827, \"m_probability_description\": \"Amongst matching record comparisons, 92.62% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1808.1084722561982, \"log2_bayes_factor\": 10.820265515342092, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,808.11 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"\\n            abs(date_diff('month',\\n                strptime(\\\"date_of_birth_l\\\", '%Y%m%d'),\\n                strptime(\\\"date_of_birth_r\\\", '%Y%m%d'))\\n                ) <= 1\\n        \", \"label_for_charts\": \"Within 1 month\", \"m_probability\": 0.005528817339563685, \"u_probability\": 0.002555884884247175, \"m_probability_description\": \"Amongst matching record comparisons, 0.55% of records are in the within 1 month comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.26% of records are in the within 1 month comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 2.1631715002658165, \"log2_bayes_factor\": 1.1131480493843502, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `within 1 month` then comparison is 2.16 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"\\n            abs(date_diff('year',\\n                strptime(\\\"date_of_birth_l\\\", '%Y%m%d'),\\n                strptime(\\\"date_of_birth_r\\\", '%Y%m%d'))\\n                ) <= 1\\n        \", \"label_for_charts\": \"Within 1 year\", \"m_probability\": 0.005136368212969114, \"u_probability\": 0.026952375887640913, \"m_probability_description\": \"Amongst matching record comparisons, 0.51% of records are in the within 1 year comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.70% of records are in the within 1 year comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.19057200131007412, \"log2_bayes_factor\": -2.3915919197017224, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `within 1 year` then comparison is  5.25 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"\\n            abs(date_diff('year',\\n                strptime(\\\"date_of_birth_l\\\", '%Y%m%d'),\\n                strptime(\\\"date_of_birth_r\\\", '%Y%m%d'))\\n                ) <= 10\\n        \", \"label_for_charts\": \"Within 10 years\", \"m_probability\": 0.011854554810374894, \"u_probability\": 0.1695598994142628, \"m_probability_description\": \"Amongst matching record comparisons, 1.19% of records are in the within 10 years comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 16.96% of records are in the within 10 years comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06991366974930942, \"log2_bayes_factor\": -3.838281626142129, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `within 10 years` then comparison is  14.30 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.051254494250040666, \"u_probability\": 0.8004195775355626, \"m_probability_description\": \"Amongst matching record comparisons, 5.13% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 80.04% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06403453349785591, \"log2_bayes_factor\": -3.965006036701192, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.62 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"m_probability_description\": \"Amongst matching record comparisons, 86.10% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.04% of records are in the exact match comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1959.7283830283181, \"log2_bayes_factor\": 10.936437996343079, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"levenshtein(\\\"soc_sec_id_l\\\", \\\"soc_sec_id_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein <= 2\", \"m_probability\": 0.07956113317943049, \"u_probability\": 0.000258489106600711, \"m_probability_description\": \"Amongst matching record comparisons, 7.96% of records are in the levenshtein <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.03% of records are in the levenshtein <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 307.792982945037, \"log2_bayes_factor\": 8.26581653129857, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenshtein <= 2` then comparison is 307.79 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05946513224892112, \"u_probability\": 0.9993021776970095, \"m_probability_description\": \"Amongst matching record comparisons, 5.95% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.93% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.05950665732157653, \"log2_bayes_factor\": -4.070805110470917, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  16.80 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"street_number\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.7716767109813564, \"u_probability\": 0.015770784047585584, \"m_probability_description\": \"Amongst matching record comparisons, 77.17% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.58% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"street_number\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 48.930776596328805, \"log2_bayes_factor\": 5.612670275323986, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 48.93 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 4}, {\"comparison_name\": \"street_number\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"m_probability_description\": \"Amongst matching record comparisons, 22.83% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.42% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.23198182427220554, \"log2_bayes_factor\": -2.107916319963705, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 4}, {\"comparison_name\": \"postcode\", \"sql_condition\": \"\\\"postcode_l\\\" = \\\"postcode_r\\\"\", \"label_for_charts\": \"Exact match\", \"m_probability\": 0.7843383776729922, \"u_probability\": 0.0013386394037648987, \"m_probability_description\": \"Amongst matching record comparisons, 78.43% of records are in the exact match comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.13% of records are in the exact match comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"postcode\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 585.9220754051128, \"log2_bayes_factor\": 9.194564996227694, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 585.92 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 5}, {\"comparison_name\": \"postcode\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"m_probability_description\": \"Amongst matching record comparisons, 21.57% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.87% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.21595070244657347, \"log2_bayes_factor\": -2.2112260855221457, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = linker.predict(threshold_match_probability=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a2aa9385813b499d88d14072123fe4dd.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a2aa9385813b499d88d14072123fe4dd.vega-embed details,\n",
       "  #altair-viz-a2aa9385813b499d88d14072123fe4dd.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a2aa9385813b499d88d14072123fe4dd\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a2aa9385813b499d88d14072123fe4dd\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a2aa9385813b499d88d14072123fe4dd\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-da6c9a6bbf8881da5ae6995070e72511\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-da6c9a6bbf8881da5ae6995070e72511\": [{\"truth_threshold\": -27.684749122249787, \"match_probability\": 4.635110475135406e-09, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6538.0, \"tn\": 0.0, \"fp\": 107719.0, \"fn\": 0.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 1.0, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0, \"precision\": 0.057221878319978714, \"recall\": 1.0, \"specificity\": 0.0, \"npv\": 1.0, \"accuracy\": 0.057221878319978714, \"f1\": 0.10824951363880955, \"f2\": 0.23281983348645743, \"f0_5\": 0.07051854536355125, \"p4\": 0.0, \"phi\": 0.0}, {\"truth_threshold\": -23.719743085548597, \"match_probability\": 7.238453859064208e-08, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 0.0, \"fp\": 107719.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.0, \"fp_rate\": 1.0, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.05720537528395653, \"recall\": 0.9996941089630127, \"specificity\": 0.0, \"npv\": 0.0, \"accuracy\": 0.05720437318086624, \"f1\": 0.10821819145149139, \"f2\": 0.23275192832266198, \"f0_5\": 0.07049819008624594, \"p4\": 0.0, \"phi\": -0.01698247910435193}, {\"truth_threshold\": -22.982989457636805, \"match_probability\": 1.2062316811390288e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 11209.0, \"fp\": 96510.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.10405778139829636, \"fp_rate\": 0.895942211151123, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.06342798471450806, \"recall\": 0.9996941089630127, \"specificity\": 0.10405778139829636, \"npv\": 0.9998216032981873, \"accuracy\": 0.15530776977539062, \"f1\": 0.11928748722441232, \"f2\": 0.2529450920292884, \"f0_5\": 0.07804700971050005, \"p4\": 0.1461110260271792, \"phi\": 0.081007802517483}, {\"truth_threshold\": -22.23750107743295, \"match_probability\": 2.0222975664905863e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 11363.0, \"fp\": 96356.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.10548742860555649, \"fp_rate\": 0.8945125937461853, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.06352292001247406, \"recall\": 0.9996941089630127, \"specificity\": 0.10548742860555649, \"npv\": 0.999824047088623, \"accuracy\": 0.15665560960769653, \"f1\": 0.11945535959060587, \"f2\": 0.253246954527138, \"f0_5\": 0.07816199719688309, \"p4\": 0.14693654780932974, \"phi\": 0.0816267564523561}, {\"truth_threshold\": -21.411360854526933, \"match_probability\": 3.585403012857446e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 11487.0, \"fp\": 96232.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.10663856565952301, \"fp_rate\": 0.8933614492416382, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.06359956413507462, \"recall\": 0.9996941089630127, \"specificity\": 0.10663856565952301, \"npv\": 0.9998258948326111, \"accuracy\": 0.15774087607860565, \"f1\": 0.11959087332808813, \"f2\": 0.2534905367669873, \"f0_5\": 0.07825483106247456, \"p4\": 0.14759424060700468, \"phi\": 0.08212308318745111}, {\"truth_threshold\": -21.28463644396787, \"match_probability\": 3.91458577450094e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 20434.0, \"fp\": 87285.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.189697265625, \"fp_rate\": 0.810302734375, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.06966457515954971, \"recall\": 0.9996941089630127, \"specificity\": 0.189697265625, \"npv\": 0.9999021291732788, \"accuracy\": 0.23604680597782135, \"f1\": 0.1302523939058779, \"f2\": 0.27239462212331106, \"f0_5\": 0.08558962029427325, \"p4\": 0.18495861733341218, \"phi\": 0.11478385782573382}, {\"truth_threshold\": -20.771460370280685, \"match_probability\": 5.586851555512278e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 22223.0, \"fp\": 85496.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.20630529522895813, \"fp_rate\": 0.7936947345733643, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.0710187777876854, \"recall\": 0.9996941089630127, \"specificity\": 0.20630529522895813, \"npv\": 0.9999099969863892, \"accuracy\": 0.25170448422431946, \"f1\": 0.13261641473064828, \"f2\": 0.276517971975902, \"f0_5\": 0.08722435449173398, \"p4\": 0.1911281678229089, \"phi\": 0.12087714977842857}, {\"truth_threshold\": -20.644735959721622, \"match_probability\": 6.099791053655298e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 27548.0, \"fp\": 80171.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.2557394802570343, \"fp_rate\": 0.7442605495452881, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.07538030296564102, \"recall\": 0.9996941089630127, \"specificity\": 0.2557394802570343, \"npv\": 0.9999274015426636, \"accuracy\": 0.29830995202064514, \"f1\": 0.14018982251059037, \"f2\": 0.2895648552618754, \"f0_5\": 0.09248201581363233, \"p4\": 0.20858675660276454, \"phi\": 0.1386943323949761}, {\"truth_threshold\": -20.46580863854931, \"match_probability\": 6.90521832494855e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 28928.0, \"fp\": 78791.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.2685505747795105, \"fp_rate\": 0.7314494252204895, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.07659943401813507, \"recall\": 0.9996941089630127, \"specificity\": 0.2685505747795105, \"npv\": 0.9999308586120605, \"accuracy\": 0.3103879988193512, \"f1\": 0.1422957600827301, \"f2\": 0.2931493823948905, \"f0_5\": 0.09394962138417576, \"p4\": 0.21300394400218123, \"phi\": 0.14327890940458657}, {\"truth_threshold\": -20.339084227990245, \"match_probability\": 7.539199499701525e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 31227.0, \"fp\": 76492.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.28989315032958984, \"fp_rate\": 0.7101068496704102, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.07872042804956436, \"recall\": 0.9996941089630127, \"specificity\": 0.28989315032958984, \"npv\": 0.9999359846115112, \"accuracy\": 0.3305093050003052, \"f1\": 0.14594823928722953, \"f2\": 0.2993222201868474, \"f0_5\": 0.096500812047837, \"p4\": 0.22034804839884106, \"phi\": 0.15092344682711928}, {\"truth_threshold\": -20.25521061964354, \"match_probability\": 7.990495071554475e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 31714.0, \"fp\": 76005.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.2944141626358032, \"fp_rate\": 0.7055858373641968, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.079184889793396, \"recall\": 0.9996941089630127, \"specificity\": 0.2944141626358032, \"npv\": 0.9999369382858276, \"accuracy\": 0.33477160334587097, \"f1\": 0.14674614667879074, \"f2\": 0.3006633361854029, \"f0_5\": 0.09705912052794459, \"p4\": 0.22190641639380182, \"phi\": 0.15254633059570066}, {\"truth_threshold\": -20.234483092442854, \"match_probability\": 8.106124886251556e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 34420.0, \"fp\": 73299.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.3195350766181946, \"fp_rate\": 0.6804649233818054, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08186885714530945, \"recall\": 0.9996941089630127, \"specificity\": 0.3195350766181946, \"npv\": 0.999941885471344, \"accuracy\": 0.3584550619125366, \"f1\": 0.15134359116853646, \"f2\": 0.3083397020389293, \"f0_5\": 0.10028292796690787, \"p4\": 0.2306197515458101, \"phi\": 0.16160563398477615}, {\"truth_threshold\": -20.132726613118546, \"match_probability\": 8.698513006327688e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 36025.0, \"fp\": 71694.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.33443495631217957, \"fp_rate\": 0.665565013885498, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08354850858449936, \"recall\": 0.9996941089630127, \"specificity\": 0.33443495631217957, \"npv\": 0.9999445080757141, \"accuracy\": 0.37250232696533203, \"f1\": 0.1542091355228388, \"f2\": 0.31308079937153915, \"f0_5\": 0.10229826769090146, \"p4\": 0.23585498447073375, \"phi\": 0.167025260379891}, {\"truth_threshold\": -20.12848620908448, \"match_probability\": 8.72411747329088e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 38212.0, \"fp\": 69507.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.354737788438797, \"fp_rate\": 0.6452621817588806, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08595137298107147, \"recall\": 0.9996941089630127, \"specificity\": 0.354737788438797, \"npv\": 0.9999476671218872, \"accuracy\": 0.3916434049606323, \"f1\": 0.15829306983446556, \"f2\": 0.3197808111942854, \"f0_5\": 0.10517846223166297, \"p4\": 0.24310452510810535, \"phi\": 0.17448598127418455}, {\"truth_threshold\": -20.10775868188379, \"match_probability\": 8.850363469655595e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 38641.0, \"fp\": 69078.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.3587203621864319, \"fp_rate\": 0.6412796378135681, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08643902093172073, \"recall\": 0.9996941089630127, \"specificity\": 0.3587203621864319, \"npv\": 0.999948263168335, \"accuracy\": 0.3953980803489685, \"f1\": 0.15911968059207324, \"f2\": 0.32112886425721754, \"f0_5\": 0.10576257144151667, \"p4\": 0.2445452073237004, \"phi\": 0.17596149079693385}, {\"truth_threshold\": -20.05669597322757, \"match_probability\": 9.16922225721098e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 39123.0, \"fp\": 68596.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.3631949722766876, \"fp_rate\": 0.63680499792099, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08699356019496918, \"recall\": 0.9996941089630127, \"specificity\": 0.3631949722766876, \"npv\": 0.9999488592147827, \"accuracy\": 0.39961665868759155, \"f1\": 0.16005877311130157, \"f2\": 0.32265708305359186, \"f0_5\": 0.10642663140823146, \"p4\": 0.246171976812087, \"phi\": 0.17762449607458872}, {\"truth_threshold\": -20.034706742368893, \"match_probability\": 9.31004782415726e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 40436.0, \"fp\": 67283.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.3753840923309326, \"fp_rate\": 0.6246159076690674, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08854088932275772, \"recall\": 0.9996941089630127, \"specificity\": 0.3753840923309326, \"npv\": 0.9999505281448364, \"accuracy\": 0.4111082851886749, \"f1\": 0.16267406697611908, \"f2\": 0.32689479949185263, \"f0_5\": 0.10827860867951784, \"p4\": 0.25064996387280014, \"phi\": 0.182184544746618}, {\"truth_threshold\": -20.01877042382146, \"match_probability\": 9.413458607808652e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 40510.0, \"fp\": 67209.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.3760710656642914, \"fp_rate\": 0.6239289045333862, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.08862973749637604, \"recall\": 0.9996941089630127, \"specificity\": 0.3760710656642914, \"npv\": 0.999950647354126, \"accuracy\": 0.4117559492588043, \"f1\": 0.1628240100643972, \"f2\": 0.3271369510595914, \"f0_5\": 0.10838490571043852, \"p4\": 0.25090448024424566, \"phi\": 0.1824429173822033}, {\"truth_threshold\": -20.006002202559486, \"match_probability\": 9.49713980639367e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 42447.0, \"fp\": 65272.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.39405304193496704, \"fp_rate\": 0.605946958065033, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09102050215005875, \"recall\": 0.9996941089630127, \"specificity\": 0.39405304193496704, \"npv\": 0.9999529123306274, \"accuracy\": 0.4287089705467224, \"f1\": 0.1668496158068057, \"f2\": 0.33360555328705593, \"f0_5\": 0.11124348980494946, \"p4\": 0.2576552826330666, \"phi\": 0.18926306489656236}, {\"truth_threshold\": -19.937470321719612, \"match_probability\": 9.959165809709478e-07, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 42984.0, \"fp\": 64735.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.3990382254123688, \"fp_rate\": 0.6009617447853088, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.0917063057422638, \"recall\": 0.9996941089630127, \"specificity\": 0.3990382254123688, \"npv\": 0.9999534487724304, \"accuracy\": 0.4334088861942291, \"f1\": 0.16800113097456593, \"f2\": 0.33544440224587624, \"f0_5\": 0.11206287591471151, \"p4\": 0.2595590102000847, \"phi\": 0.1911745706628161}, {\"truth_threshold\": -19.92997156266851, \"match_probability\": 1.001106571352425e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 44344.0, \"fp\": 63375.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.411663681268692, \"fp_rate\": 0.5883363485336304, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09349029511213303, \"recall\": 0.9996941089630127, \"specificity\": 0.411663681268692, \"npv\": 0.999954879283905, \"accuracy\": 0.44531187415122986, \"f1\": 0.17098981020026424, \"f2\": 0.3401934147382447, \"f0_5\": 0.11419306595103815, \"p4\": 0.26444854372761717, \"phi\": 0.1960597028358656}, {\"truth_threshold\": -19.929118846411285, \"match_probability\": 1.0016984575792016e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 44680.0, \"fp\": 63039.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.41478291153907776, \"fp_rate\": 0.5852171182632446, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09394179284572601, \"recall\": 0.9996941089630127, \"specificity\": 0.41478291153907776, \"npv\": 0.9999552369117737, \"accuracy\": 0.4482526183128357, \"f1\": 0.1717446428336815, \"f2\": 0.34138748733377206, \"f0_5\": 0.11473188268419242, \"p4\": 0.2656723377727376, \"phi\": 0.1972768576040592}, {\"truth_threshold\": -19.90798233180983, \"match_probability\": 1.01648207261948e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 44745.0, \"fp\": 62974.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4153863191604614, \"fp_rate\": 0.5846136808395386, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09402963519096375, \"recall\": 0.9996941089630127, \"specificity\": 0.4153863191604614, \"npv\": 0.9999552965164185, \"accuracy\": 0.4488215148448944, \"f1\": 0.171891436987166, \"f2\": 0.3416194518199494, \"f0_5\": 0.11483670557808404, \"p4\": 0.2659098325005836, \"phi\": 0.1975127990394779}, {\"truth_threshold\": -19.892046013262398, \"match_probability\": 1.0277725837530162e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 44752.0, \"fp\": 62967.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.415451318025589, \"fp_rate\": 0.5845487117767334, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09403910487890244, \"recall\": 0.9996941089630127, \"specificity\": 0.415451318025589, \"npv\": 0.9999552965164185, \"accuracy\": 0.4488827884197235, \"f1\": 0.1719072605568049, \"f2\": 0.3416444514139355, \"f0_5\": 0.11484800562291338, \"p4\": 0.26593542345540966, \"phi\": 0.19753823590558117}, {\"truth_threshold\": -19.880846137828154, \"match_probability\": 1.035782391127104e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 45186.0, \"fp\": 62533.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4194803237915039, \"fp_rate\": 0.5805196762084961, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09463001042604446, \"recall\": 0.9996941089630127, \"specificity\": 0.4194803237915039, \"npv\": 0.9999557137489319, \"accuracy\": 0.4526812434196472, \"f1\": 0.1728940442022564, \"f2\": 0.3432016046880415, \"f0_5\": 0.11555297828254613, \"p4\": 0.2675276632008009, \"phi\": 0.19911786361839598}, {\"truth_threshold\": -19.837946737527464, \"match_probability\": 1.0670444621591832e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 46120.0, \"fp\": 61599.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.42815101146698, \"fp_rate\": 0.57184898853302, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09592720121145248, \"recall\": 0.9996941089630127, \"specificity\": 0.42815101146698, \"npv\": 0.9999566078186035, \"accuracy\": 0.46085578203201294, \"f1\": 0.17505658002223026, \"f2\": 0.3466013342242303, \"f0_5\": 0.11709987888690616, \"p4\": 0.2709926960749551, \"phi\": 0.20254242121991506}, {\"truth_threshold\": -19.810745911160552, \"match_probability\": 1.087353538315383e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 46391.0, \"fp\": 61328.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.43066683411598206, \"fp_rate\": 0.5693331956863403, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09631026536226273, \"recall\": 0.9996941089630127, \"specificity\": 0.43066683411598206, \"npv\": 0.9999569058418274, \"accuracy\": 0.46322762966156006, \"f1\": 0.17569420176876965, \"f2\": 0.3476004084411164, \"f0_5\": 0.1175564940250509, \"p4\": 0.27200820788238506, \"phi\": 0.20354268610154033}, {\"truth_threshold\": -19.80239443585222, \"match_probability\": 1.0936662592099019e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 46769.0, \"fp\": 60950.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.434175968170166, \"fp_rate\": 0.565824031829834, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.0968497171998024, \"recall\": 0.9996941089630127, \"specificity\": 0.434175968170166, \"npv\": 0.999957263469696, \"accuracy\": 0.4665359556674957, \"f1\": 0.17659137577002054, \"f2\": 0.3490036096456567, \"f0_5\": 0.11819937645126988, \"p4\": 0.2734325205875694, \"phi\": 0.20494301664259587}, {\"truth_threshold\": -19.79838397763618, \"match_probability\": 1.0967107002549549e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 46774.0, \"fp\": 60945.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.43422237038612366, \"fp_rate\": 0.565777599811554, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09685689210891724, \"recall\": 0.9996941089630127, \"specificity\": 0.43422237038612366, \"npv\": 0.999957263469696, \"accuracy\": 0.46657973527908325, \"f1\": 0.1766033045569381, \"f2\": 0.34902224643021157, \"f0_5\": 0.1182079273100824, \"p4\": 0.27345142266769507, \"phi\": 0.2049615681447955}, {\"truth_threshold\": -19.75412172726909, \"match_probability\": 1.13087949865892e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 47515.0, \"fp\": 60204.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4411013722419739, \"fp_rate\": 0.5588986277580261, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09793227165937424, \"recall\": 0.9996941089630127, \"specificity\": 0.4411013722419739, \"npv\": 0.9999579191207886, \"accuracy\": 0.4730651080608368, \"f1\": 0.17838914817544146, \"f2\": 0.35180639882874737, \"f0_5\": 0.11948899077872599, \"p4\": 0.27627097076734575, \"phi\": 0.20772469953255465}, {\"truth_threshold\": -19.74066847977989, \"match_probability\": 1.1414743512095615e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 47758.0, \"fp\": 59961.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4433572590351105, \"fp_rate\": 0.5566427707672119, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09829014539718628, \"recall\": 0.9996941089630127, \"specificity\": 0.4433572590351105, \"npv\": 0.9999580979347229, \"accuracy\": 0.4751918911933899, \"f1\": 0.1789826795372082, \"f2\": 0.35272911742166674, \"f0_5\": 0.11991516405774127, \"p4\": 0.27720364122106983, \"phi\": 0.20863611920522948}, {\"truth_threshold\": -19.68054748734232, \"match_probability\": 1.1900476700521442e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 48645.0, \"fp\": 59074.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4515916407108307, \"fp_rate\": 0.5484083294868469, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.09961896389722824, \"recall\": 0.9996941089630127, \"specificity\": 0.4515916407108307, \"npv\": 0.999958872795105, \"accuracy\": 0.48295509815216064, \"f1\": 0.18118312357930919, \"f2\": 0.3561387066541706, \"f0_5\": 0.12149692539910327, \"p4\": 0.28064293214169045, \"phi\": 0.21198599347162206}, {\"truth_threshold\": -19.671659567077118, \"match_probability\": 1.1974017424554989e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 49302.0, \"fp\": 58417.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4576908349990845, \"fp_rate\": 0.5423091650009155, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.10062661021947861, \"recall\": 0.9996941089630127, \"specificity\": 0.4576908349990845, \"npv\": 0.999959409236908, \"accuracy\": 0.48870527744293213, \"f1\": 0.1828481906813445, \"f2\": 0.3587069864442127, \"f0_5\": 0.12269570114510982, \"p4\": 0.2832268058328135, \"phi\": 0.21449134456234353}, {\"truth_threshold\": -19.661835879106185, \"match_probability\": 1.205582976825868e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 49412.0, \"fp\": 58307.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.45871201157569885, \"fp_rate\": 0.5412879586219788, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.10079731047153473, \"recall\": 0.9996941089630127, \"specificity\": 0.45871201157569885, \"npv\": 0.9999595284461975, \"accuracy\": 0.4896680414676666, \"f1\": 0.18312996455639455, \"f2\": 0.35914061212154513, \"f0_5\": 0.12289872513256365, \"p4\": 0.2836625322040082, \"phi\": 0.21491289288265608}, {\"truth_threshold\": -19.649520591721696, \"match_probability\": 1.2159182401184798e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 50384.0, \"fp\": 57335.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.46773549914360046, \"fp_rate\": 0.5322645306587219, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.1023312583565712, \"recall\": 0.9996941089630127, \"specificity\": 0.46773549914360046, \"npv\": 0.9999603033065796, \"accuracy\": 0.49817517399787903, \"f1\": 0.18565808348364557, \"f2\": 0.3630183397576175, \"f0_5\": 0.1247223515582661, \"p4\": 0.2875527546856965, \"phi\": 0.21866437756085066}, {\"truth_threshold\": -19.617811731994358, \"match_probability\": 1.2429386118697408e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 51160.0, \"fp\": 56559.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4749394357204437, \"fp_rate\": 0.5250605940818787, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.10358982533216476, \"recall\": 0.9996941089630127, \"specificity\": 0.4749394357204437, \"npv\": 0.9999608993530273, \"accuracy\": 0.5049668550491333, \"f1\": 0.18772708342308964, \"f2\": 0.3661747733817383, \"f0_5\": 0.126217566951699, \"p4\": 0.2907117340431223, \"phi\": 0.22169494506367932}, {\"truth_threshold\": -19.61394406922083, \"match_probability\": 1.2462752220540055e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 51939.0, \"fp\": 55780.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4821712076663971, \"fp_rate\": 0.5178288221359253, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.10488478094339371, \"recall\": 0.9996941089630127, \"specificity\": 0.4821712076663971, \"npv\": 0.9999614953994751, \"accuracy\": 0.5117848515510559, \"f1\": 0.1898509890492927, \"f2\": 0.36939910476104354, \"f0_5\": 0.12775506055464775, \"p4\": 0.2939324616923619, \"phi\": 0.22477049927926795}, {\"truth_threshold\": -19.569942547020947, \"match_probability\": 1.2848715765235286e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6536.0, \"tn\": 52093.0, \"fp\": 55626.0, \"fn\": 2.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9996941089630127, \"tn_rate\": 0.4836008548736572, \"fp_rate\": 0.5163991451263428, \"fn_rate\": 0.0003059039590880275, \"precision\": 0.10514461994171143, \"recall\": 0.9996941089630127, \"specificity\": 0.4836008548736572, \"npv\": 0.9999616146087646, \"accuracy\": 0.5131326913833618, \"f1\": 0.19027656477438137, \"f2\": 0.37004325475009625, \"f0_5\": 0.12806345175675782, \"p4\": 0.29457520645638474, \"phi\": 0.2253825941007136}, {\"truth_threshold\": -19.55382307678326, \"match_probability\": 1.2993081413203207e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 52093.0, \"fp\": 55626.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.4836008548736572, \"fp_rate\": 0.5163991451263428, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.10513022541999817, \"recall\": 0.999541163444519, \"specificity\": 0.4836008548736572, \"npv\": 0.999942421913147, \"accuracy\": 0.5131239295005798, \"f1\": 0.19025022198285274, \"f2\": 0.3699908280774065, \"f0_5\": 0.12804586530397913, \"p4\": 0.2945432206451167, \"phi\": 0.22531089885342725}, {\"truth_threshold\": -19.53511146854712, \"match_probability\": 1.3162697713816573e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 52226.0, \"fp\": 55493.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.48483553528785706, \"fp_rate\": 0.5151644349098206, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1053556427359581, \"recall\": 0.999541163444519, \"specificity\": 0.48483553528785706, \"npv\": 0.9999425411224365, \"accuracy\": 0.5142879486083984, \"f1\": 0.19061925735787416, \"f2\": 0.3705488772964391, \"f0_5\": 0.12831337129393286, \"p4\": 0.29509989902494443, \"phi\": 0.22584064481737784}, {\"truth_threshold\": -19.522796181162633, \"match_probability\": 1.3275539329815991e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 52460.0, \"fp\": 55259.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.48700785636901855, \"fp_rate\": 0.5129921436309814, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.10575460642576218, \"recall\": 0.999541163444519, \"specificity\": 0.48700785636901855, \"npv\": 0.9999428391456604, \"accuracy\": 0.5163359642028809, \"f1\": 0.1912720248199965, \"f2\": 0.37153480544879813, \"f0_5\": 0.12878674412921637, \"p4\": 0.2960830224581329, \"phi\": 0.2267751623747401}, {\"truth_threshold\": -19.518456991731753, \"match_probability\": 1.3315528182430072e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 52629.0, \"fp\": 55090.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.4885767698287964, \"fp_rate\": 0.5114232301712036, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.10604462772607803, \"recall\": 0.999541163444519, \"specificity\": 0.4885767698287964, \"npv\": 0.9999430179595947, \"accuracy\": 0.517815113067627, \"f1\": 0.19174625529979608, \"f2\": 0.3722501338619456, \"f0_5\": 0.12913080248816383, \"p4\": 0.29679601923860793, \"phi\": 0.22745210125431786}, {\"truth_threshold\": -19.518276058443444, \"match_probability\": 1.3317198230571513e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 52669.0, \"fp\": 55050.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.48894810676574707, \"fp_rate\": 0.5110518932342529, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.106113500893116, \"recall\": 0.999541163444519, \"specificity\": 0.48894810676574707, \"npv\": 0.9999430179595947, \"accuracy\": 0.5181651711463928, \"f1\": 0.1918588435623798, \"f2\": 0.37241984567514275, \"f0_5\": 0.1292125056351284, \"p4\": 0.2969651421893182, \"phi\": 0.22761255985164483}, {\"truth_threshold\": -19.491087321435295, \"match_probability\": 1.3570550914575496e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 53337.0, \"fp\": 54382.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.4951494038105011, \"fp_rate\": 0.5048505663871765, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.10727711766958237, \"recall\": 0.999541163444519, \"specificity\": 0.4951494038105011, \"npv\": 0.999943733215332, \"accuracy\": 0.5240116715431213, \"f1\": 0.1937588021644059, \"f2\": 0.3752770790981865, \"f0_5\": 0.13059239186909985, \"p4\": 0.2998105117661766, \"phi\": 0.23030664700535255}, {\"truth_threshold\": -19.47280205471617, \"match_probability\": 1.3743643616140495e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 53474.0, \"fp\": 54245.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.4964212477207184, \"fp_rate\": 0.503578782081604, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.10751891881227493, \"recall\": 0.999541163444519, \"specificity\": 0.4964212477207184, \"npv\": 0.9999439120292664, \"accuracy\": 0.5252107381820679, \"f1\": 0.19415312397872783, \"f2\": 0.3758684949155662, \"f0_5\": 0.1308790425301813, \"p4\": 0.3003990352751971, \"phi\": 0.23086255231078542}, {\"truth_threshold\": -19.411360854526933, \"match_probability\": 1.4341596625308658e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 54351.0, \"fp\": 53368.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5045627951622009, \"fp_rate\": 0.4954372048377991, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.10909303277730942, \"recall\": 0.999541163444519, \"specificity\": 0.5045627951622009, \"npv\": 0.999944806098938, \"accuracy\": 0.5328863859176636, \"f1\": 0.1967158832648515, \"f2\": 0.3796990296903143, \"f0_5\": 0.13274426162908795, \"p4\": 0.30420758036623213, \"phi\": 0.23444915149360596}, {\"truth_threshold\": -19.395972985206757, \"match_probability\": 1.449538339973932e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 55917.0, \"fp\": 51802.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5191006064414978, \"fp_rate\": 0.4808993637561798, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11202152818441391, \"recall\": 0.999541163444519, \"specificity\": 0.5191006064414978, \"npv\": 0.9999463558197021, \"accuracy\": 0.5465923547744751, \"f1\": 0.20146435452793834, \"f2\": 0.38673673495958055, \"f0_5\": 0.13621053333666824, \"p4\": 0.31119258038835473, \"phi\": 0.2409797004672464}, {\"truth_threshold\": -19.39173258117269, \"match_probability\": 1.4538051192421254e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 55934.0, \"fp\": 51785.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.519258439540863, \"fp_rate\": 0.48074156045913696, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11205418407917023, \"recall\": 0.999541163444519, \"specificity\": 0.519258439540863, \"npv\": 0.9999463558197021, \"accuracy\": 0.5467411279678345, \"f1\": 0.20151716056615993, \"f2\": 0.386814565773274, \"f0_5\": 0.13624915560967066, \"p4\": 0.3112697546927775, \"phi\": 0.24105153554406789}, {\"truth_threshold\": -19.39155164788438, \"match_probability\": 1.453987457051583e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 55939.0, \"fp\": 51780.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5193048715591431, \"fp_rate\": 0.48069512844085693, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11206378787755966, \"recall\": 0.999541163444519, \"specificity\": 0.5193048715591431, \"npv\": 0.9999463558197021, \"accuracy\": 0.5467848777770996, \"f1\": 0.20153269702249704, \"f2\": 0.38683746315128986, \"f0_5\": 0.1362605192703859, \"p4\": 0.31129245866208843, \"phi\": 0.2410726512588101}, {\"truth_threshold\": -19.38353471661908, \"match_probability\": 1.462089618135551e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 56032.0, \"fp\": 51687.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5201682448387146, \"fp_rate\": 0.4798317849636078, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11224279552698135, \"recall\": 0.999541163444519, \"specificity\": 0.5201682448387146, \"npv\": 0.9999464750289917, \"accuracy\": 0.5475988388061523, \"f1\": 0.20182211241507103, \"f2\": 0.3872638490530258, \"f0_5\": 0.13647222941535173, \"p4\": 0.31171522099901017, \"phi\": 0.24146594650258696}, {\"truth_threshold\": -19.352507820998458, \"match_probability\": 1.4938741275694133e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 56725.0, \"fp\": 50994.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5266016125679016, \"fp_rate\": 0.4733983874320984, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11359488219022751, \"recall\": 0.999541163444519, \"specificity\": 0.5266016125679016, \"npv\": 0.9999471306800842, \"accuracy\": 0.5536640882492065, \"f1\": 0.20400518207501522, \"f2\": 0.39047095517500985, \"f0_5\": 0.13807076998487244, \"p4\": 0.314893829585635, \"phi\": 0.24441624756401087}, {\"truth_threshold\": -19.346077644157106, \"match_probability\": 1.500547262857588e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 57423.0, \"fp\": 50296.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5330814719200134, \"fp_rate\": 0.46691855788230896, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11499005556106567, \"recall\": 0.999541163444519, \"specificity\": 0.5330814719200134, \"npv\": 0.9999477863311768, \"accuracy\": 0.5597731471061707, \"f1\": 0.20625226845934133, \"f2\": 0.3937553474808093, \"f0_5\": 0.1397191506101889, \"p4\": 0.3181470793899682, \"phi\": 0.24742367957386216}, {\"truth_threshold\": -19.335412001293633, \"match_probability\": 1.5116816892626489e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 57538.0, \"fp\": 50181.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5341490507125854, \"fp_rate\": 0.46585094928741455, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11522321403026581, \"recall\": 0.999541163444519, \"specificity\": 0.5341490507125854, \"npv\": 0.9999478459358215, \"accuracy\": 0.5607796311378479, \"f1\": 0.2066272488696367, \"f2\": 0.3943017811459188, \"f0_5\": 0.13999451589960668, \"p4\": 0.3186881696649116, \"phi\": 0.24792272004562074}, {\"truth_threshold\": -19.288377483578742, \"match_probability\": 1.5617773909544396e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 58961.0, \"fp\": 48758.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5473593473434448, \"fp_rate\": 0.4526406526565552, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.11818856000900269, \"recall\": 0.999541163444519, \"specificity\": 0.5473593473434448, \"npv\": 0.9999490976333618, \"accuracy\": 0.5732340216636658, \"f1\": 0.21138263977616406, \"f2\": 0.40119098778316653, \"f0_5\": 0.14349391770234068, \"p4\": 0.3255070795298199, \"phi\": 0.2541841017779143}, {\"truth_threshold\": -19.28463644396787, \"match_probability\": 1.565832470924721e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 60906.0, \"fp\": 46813.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5654155611991882, \"fp_rate\": 0.43458443880081177, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1224975660443306, \"recall\": 0.999541163444519, \"specificity\": 0.5654155611991882, \"npv\": 0.9999507665634155, \"accuracy\": 0.5902570486068726, \"f1\": 0.21824800454196305, \"f2\": 0.4110062893081761, \"f0_5\": 0.14856999954530986, \"p4\": 0.3352176288980777, \"phi\": 0.26301708981043304}, {\"truth_threshold\": -19.282016795909673, \"match_probability\": 1.5686782906134879e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 61240.0, \"fp\": 46479.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5685162544250488, \"fp_rate\": 0.43148377537727356, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12326932698488235, \"recall\": 0.999541163444519, \"specificity\": 0.5685162544250488, \"npv\": 0.9999510049819946, \"accuracy\": 0.5931802988052368, \"f1\": 0.21947205803331543, \"f2\": 0.41274031781320264, \"f0_5\": 0.14947802775922486, \"p4\": 0.33693315327656237, \"phi\": 0.26456799639301404}, {\"truth_threshold\": -19.269248574647694, \"match_probability\": 1.5826230904942278e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 61277.0, \"fp\": 46442.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5688596963882446, \"fp_rate\": 0.431140273809433, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12335541844367981, \"recall\": 0.999541163444519, \"specificity\": 0.5688596963882446, \"npv\": 0.9999510645866394, \"accuracy\": 0.5935041308403015, \"f1\": 0.21960850205830462, \"f2\": 0.41293331142817424, \"f0_5\": 0.14957930106296294, \"p4\": 0.3371240934961521, \"phi\": 0.26474042991506563}, {\"truth_threshold\": -19.256810306060018, \"match_probability\": 1.596326722484858e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 61282.0, \"fp\": 46437.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5689061284065247, \"fp_rate\": 0.43109387159347534, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1233670637011528, \"recall\": 0.999541163444519, \"specificity\": 0.5689061284065247, \"npv\": 0.9999510645866394, \"accuracy\": 0.5935478806495667, \"f1\": 0.21962695345320113, \"f2\": 0.4129594054901168, \"f0_5\": 0.1495929971706665, \"p4\": 0.3371499100328258, \"phi\": 0.264763752464351}, {\"truth_threshold\": -19.225783410439394, \"match_probability\": 1.6310294207202704e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 61547.0, \"fp\": 46172.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5713662505149841, \"fp_rate\": 0.42863374948501587, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12398732453584671, \"recall\": 0.999541163444519, \"specificity\": 0.5713662505149841, \"npv\": 0.9999512434005737, \"accuracy\": 0.5958672165870667, \"f1\": 0.22060933412102288, \"f2\": 0.41434712588290495, \"f0_5\": 0.15032249753871352, \"p4\": 0.3385229122827558, \"phi\": 0.26600273678441194}, {\"truth_threshold\": -19.213421476915023, \"match_probability\": 1.645065148302159e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 61687.0, \"fp\": 46032.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5726659297943115, \"fp_rate\": 0.4273340702056885, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12431753426790237, \"recall\": 0.999541163444519, \"specificity\": 0.5726659297943115, \"npv\": 0.9999513626098633, \"accuracy\": 0.5970925092697144, \"f1\": 0.22113188393536926, \"f2\": 0.4150840330796885, \"f0_5\": 0.15071077368707508, \"p4\": 0.3392520408715751, \"phi\": 0.266659992619461}, {\"truth_threshold\": -19.20868759073457, \"match_probability\": 1.6504719242524083e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 62042.0, \"fp\": 45677.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5759615302085876, \"fp_rate\": 0.42403846979141235, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12516279518604279, \"recall\": 0.999541163444519, \"specificity\": 0.5759615302085876, \"npv\": 0.9999516606330872, \"accuracy\": 0.6001995205879211, \"f1\": 0.22246808510638297, \"f2\": 0.416964422438875, \"f0_5\": 0.15170438190040206, \"p4\": 0.34111272209973903, \"phi\": 0.268335038242846}, {\"truth_threshold\": -19.200716693807824, \"match_probability\": 1.6596160116111632e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 62309.0, \"fp\": 45410.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5784401893615723, \"fp_rate\": 0.42155981063842773, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12580613791942596, \"recall\": 0.999541163444519, \"specificity\": 0.5784401893615723, \"npv\": 0.9999518394470215, \"accuracy\": 0.6025363802909851, \"f1\": 0.22348374741377836, \"f2\": 0.4183899509584235, \"f0_5\": 0.15246036263869578, \"p4\": 0.34252346762448926, \"phi\": 0.2696029987017581}, {\"truth_threshold\": -19.198046253281216, \"match_probability\": 1.662690814416916e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 62322.0, \"fp\": 45397.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5785608887672424, \"fp_rate\": 0.42143911123275757, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12583763897418976, \"recall\": 0.999541163444519, \"specificity\": 0.5785608887672424, \"npv\": 0.9999518394470215, \"accuracy\": 0.6026501655578613, \"f1\": 0.22353343595005987, \"f2\": 0.41845960760206957, \"f0_5\": 0.1524973630907377, \"p4\": 0.34259240581869527, \"phi\": 0.26966491249220564}, {\"truth_threshold\": -19.16165307301968, \"match_probability\": 1.7051669952449403e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 62495.0, \"fp\": 45224.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5801669359207153, \"fp_rate\": 0.41983309388160706, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1262582391500473, \"recall\": 0.999541163444519, \"specificity\": 0.5801669359207153, \"npv\": 0.9999520182609558, \"accuracy\": 0.6041643023490906, \"f1\": 0.22419678542635127, \"f2\": 0.4193887897729461, \"f0_5\": 0.15299146899903546, \"p4\": 0.3435120416443879, \"phi\": 0.2704904607937166}, {\"truth_threshold\": -19.15529238535061, \"match_probability\": 1.7127014778860063e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 62890.0, \"fp\": 44829.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5838338732719421, \"fp_rate\": 0.41616612672805786, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12722918391227722, \"recall\": 0.999541163444519, \"specificity\": 0.5838338732719421, \"npv\": 0.9999523162841797, \"accuracy\": 0.607621431350708, \"f1\": 0.2257262270733308, \"f2\": 0.4215258785283038, \"f0_5\": 0.15413172070907666, \"p4\": 0.3456274613383525, \"phi\": 0.27238666633887343}, {\"truth_threshold\": -19.150873959828807, \"match_probability\": 1.7179548617435771e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 62898.0, \"fp\": 44821.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5839081406593323, \"fp_rate\": 0.4160918593406677, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12724900245666504, \"recall\": 0.999541163444519, \"specificity\": 0.5839081406593323, \"npv\": 0.9999523162841797, \"accuracy\": 0.6076914072036743, \"f1\": 0.22575741873078384, \"f2\": 0.42156938638592145, \"f0_5\": 0.1541549900453855, \"p4\": 0.34567053253450125, \"phi\": 0.2724252452085245}, {\"truth_threshold\": -19.128500097802814, \"match_probability\": 1.744805175293216e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 63344.0, \"fp\": 44375.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.58804851770401, \"fp_rate\": 0.4119514524936676, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12836377322673798, \"recall\": 0.999541163444519, \"specificity\": 0.58804851770401, \"npv\": 0.9999526143074036, \"accuracy\": 0.6115949153900146, \"f1\": 0.22751009608689599, \"f2\": 0.4240092393137993, \"f0_5\": 0.15546346430168714, \"p4\": 0.3480862151685314, \"phi\": 0.27458587084698977}, {\"truth_threshold\": -19.125958635664684, \"match_probability\": 1.7478815403598556e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 63357.0, \"fp\": 44362.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5881692171096802, \"fp_rate\": 0.4118307828903198, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12839657068252563, \"recall\": 0.999541163444519, \"specificity\": 0.5881692171096802, \"npv\": 0.9999526739120483, \"accuracy\": 0.6117087006568909, \"f1\": 0.22756159136415077, \"f2\": 0.4240807797635271, \"f0_5\": 0.15550193693307826, \"p4\": 0.3481570567936009, \"phi\": 0.27464915827323094}, {\"truth_threshold\": -19.114348083803694, \"match_probability\": 1.7620049087871317e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 63960.0, \"fp\": 43759.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5937671065330505, \"fp_rate\": 0.40623289346694946, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.12993597984313965, \"recall\": 0.999541163444519, \"specificity\": 0.5937671065330505, \"npv\": 0.9999530911445618, \"accuracy\": 0.6169862747192383, \"f1\": 0.22997606981981983, \"f2\": 0.42742589540329123, \"f0_5\": 0.15730764416457244, \"p4\": 0.3514701946876054, \"phi\": 0.2776045075002265}, {\"truth_threshold\": -19.08669706635596, \"match_probability\": 1.7961015383556945e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 64452.0, \"fp\": 43267.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.598334550857544, \"fp_rate\": 0.40166544914245605, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13121962547302246, \"recall\": 0.999541163444519, \"specificity\": 0.598334550857544, \"npv\": 0.9999534487724304, \"accuracy\": 0.6212923526763916, \"f1\": 0.23198438054668086, \"f2\": 0.43019459146325406, \"f0_5\": 0.15881232198924888, \"p4\": 0.3542135613278239, \"phi\": 0.28004500567113794}, {\"truth_threshold\": -19.08015494605156, \"match_probability\": 1.8042647141249786e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 64521.0, \"fp\": 43198.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.5989751219749451, \"fp_rate\": 0.40102487802505493, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1314016878604889, \"recall\": 0.999541163444519, \"specificity\": 0.5989751219749451, \"npv\": 0.9999535083770752, \"accuracy\": 0.6218962669372559, \"f1\": 0.2322688418545965, \"f2\": 0.4305857547604929, \"f0_5\": 0.15902564851316495, \"p4\": 0.3546012369145138, \"phi\": 0.28038939880529334}, {\"truth_threshold\": -19.07687337838503, \"match_probability\": 1.8083733751667213e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 65151.0, \"fp\": 42568.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.604823648929596, \"fp_rate\": 0.39517635107040405, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13308759033679962, \"recall\": 0.999541163444519, \"specificity\": 0.604823648929596, \"npv\": 0.9999539256095886, \"accuracy\": 0.6274101138114929, \"f1\": 0.23489872575978146, \"f2\": 0.4341904192412464, \"f0_5\": 0.16100024636610002, \"p4\": 0.35817490968247107, \"phi\": 0.283558861784145}, {\"truth_threshold\": -19.032849231273204, \"match_probability\": 1.8644067591330343e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 65591.0, \"fp\": 42128.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6089083552360535, \"fp_rate\": 0.39109164476394653, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1342909336090088, \"recall\": 0.999541163444519, \"specificity\": 0.6089083552360535, \"npv\": 0.9999542832374573, \"accuracy\": 0.6312611103057861, \"f1\": 0.2367710729878082, \"f2\": 0.4367439684555236, \"f0_5\": 0.16240866842288385, \"p4\": 0.3607078490842592, \"phi\": 0.2857996393961004}, {\"truth_threshold\": -19.024149549269744, \"match_probability\": 1.8756833749340956e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66136.0, \"fp\": 41583.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6139678359031677, \"fp_rate\": 0.3860321640968323, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1358119696378708, \"recall\": 0.999541163444519, \"specificity\": 0.6139678359031677, \"npv\": 0.9999546408653259, \"accuracy\": 0.6360310316085815, \"f1\": 0.23913202576112413, \"f2\": 0.4399488353305507, \"f0_5\": 0.16418772925983618, \"p4\": 0.36388857384507683, \"phi\": 0.28860705213307397}, {\"truth_threshold\": -18.99923422510562, \"match_probability\": 1.9083576702776656e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66234.0, \"fp\": 41485.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6148775815963745, \"fp_rate\": 0.3851223886013031, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13608913123607635, \"recall\": 0.999541163444519, \"specificity\": 0.6148775815963745, \"npv\": 0.9999547004699707, \"accuracy\": 0.6368887424468994, \"f1\": 0.23956156750614024, \"f2\": 0.44053011918244084, \"f0_5\": 0.1645117763747495, \"p4\": 0.36446569588543815, \"phi\": 0.2891156824034676}, {\"truth_threshold\": -18.98762367324463, \"match_probability\": 1.923777727922202e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66397.0, \"fp\": 41322.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6163908243179321, \"fp_rate\": 0.38360920548439026, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13655264675617218, \"recall\": 0.999541163444519, \"specificity\": 0.6163908243179321, \"npv\": 0.9999548196792603, \"accuracy\": 0.6383153796195984, \"f1\": 0.24027943744829489, \"f2\": 0.44150035806455973, \"f0_5\": 0.16505359506177827, \"p4\": 0.3654291421963283, \"phi\": 0.28996431323661126}, {\"truth_threshold\": -18.983939630792257, \"match_probability\": 1.9286965233833176e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66500.0, \"fp\": 41219.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.617347002029419, \"fp_rate\": 0.38265302777290344, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13684716820716858, \"recall\": 0.999541163444519, \"specificity\": 0.617347002029419, \"npv\": 0.999954879283905, \"accuracy\": 0.6392168402671814, \"f1\": 0.2407352832829883, \"f2\": 0.4421156604335237, \"f0_5\": 0.16539781528088524, \"p4\": 0.3660402383320755, \"phi\": 0.2905022800996533}, {\"truth_threshold\": -18.98356663043366, \"match_probability\": 1.929195240085967e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66797.0, \"fp\": 40922.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6201041340827942, \"fp_rate\": 0.3798958361148834, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13770361244678497, \"recall\": 0.999541163444519, \"specificity\": 0.6201041340827942, \"npv\": 0.9999551177024841, \"accuracy\": 0.641816258430481, \"f1\": 0.24205944994906936, \"f2\": 0.4438995231561358, \"f0_5\": 0.1663984600185368, \"p4\": 0.3678123624606148, \"phi\": 0.2920608822554756}, {\"truth_threshold\": -18.953430535492497, \"match_probability\": 1.9699174738573584e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66818.0, \"fp\": 40901.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6202991008758545, \"fp_rate\": 0.3797008991241455, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.137764573097229, \"recall\": 0.999541163444519, \"specificity\": 0.6202991008758545, \"npv\": 0.9999551177024841, \"accuracy\": 0.6420000791549683, \"f1\": 0.242153629525327, \"f2\": 0.44402619992390063, \"f0_5\": 0.16646967118737327, \"p4\": 0.367938231880503, \"phi\": 0.2921715188540012}, {\"truth_threshold\": -18.950148967825967, \"match_probability\": 1.9744033576487556e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 66970.0, \"fp\": 40749.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6217101812362671, \"fp_rate\": 0.3782898187637329, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13820742070674896, \"recall\": 0.999541163444519, \"specificity\": 0.6217101812362671, \"npv\": 0.9999551773071289, \"accuracy\": 0.6433303952217102, \"f1\": 0.24283750139348223, \"f2\": 0.4449452584563429, \"f0_5\": 0.16698692723611722, \"p4\": 0.36885153918749597, \"phi\": 0.2929739142330966}, {\"truth_threshold\": -18.93331355772229, \"match_probability\": 1.9975784044783447e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 67053.0, \"fp\": 40666.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6224806904792786, \"fp_rate\": 0.37751927971839905, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13845045864582062, \"recall\": 0.999541163444519, \"specificity\": 0.6224806904792786, \"npv\": 0.9999552369117737, \"accuracy\": 0.6440567970275879, \"f1\": 0.24321256443179068, \"f2\": 0.4454487205703925, \"f0_5\": 0.16727073542812093, \"p4\": 0.36935193071210837, \"phi\": 0.29341332046295726}, {\"truth_threshold\": -18.925082251194397, \"match_probability\": 2.0090081542278073e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 67343.0, \"fp\": 40376.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6251729130744934, \"fp_rate\": 0.3748270869255066, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13930635154247284, \"recall\": 0.999541163444519, \"specificity\": 0.6251729130744934, \"npv\": 0.9999554753303528, \"accuracy\": 0.6465949416160583, \"f1\": 0.24453217085445939, \"f2\": 0.4472167855138716, \"f0_5\": 0.16826997352998732, \"p4\": 0.3711096697861665, \"phi\": 0.2949555938715885}, {\"truth_threshold\": -18.90612482071414, \"match_probability\": 2.035581255988368e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 67360.0, \"fp\": 40359.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6253307461738586, \"fp_rate\": 0.37466928362846375, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1393568515777588, \"recall\": 0.999541163444519, \"specificity\": 0.6253307461738586, \"npv\": 0.9999554753303528, \"accuracy\": 0.6467437148094177, \"f1\": 0.24460997155262765, \"f2\": 0.4473208663034252, \"f0_5\": 0.16832892011910527, \"p4\": 0.3712131652436607, \"phi\": 0.2950463358311767}, {\"truth_threshold\": -18.89239452154984, \"match_probability\": 2.0550465633935623e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 67462.0, \"fp\": 40257.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6262776255607605, \"fp_rate\": 0.3737223744392395, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13966062664985657, \"recall\": 0.999541163444519, \"specificity\": 0.6262776255607605, \"npv\": 0.9999555349349976, \"accuracy\": 0.6476364731788635, \"f1\": 0.24507781736358522, \"f2\": 0.44794636981794256, \"f0_5\": 0.16868346876193818, \"p4\": 0.3718352045773268, \"phi\": 0.29559162739582723}, {\"truth_threshold\": -18.880846137828154, \"match_probability\": 2.071562636566106e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 67518.0, \"fp\": 40201.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6267974972724915, \"fp_rate\": 0.37320250272750854, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.13982796669006348, \"recall\": 0.999541163444519, \"specificity\": 0.6267974972724915, \"npv\": 0.9999555945396423, \"accuracy\": 0.6481266021728516, \"f1\": 0.2453354356721853, \"f2\": 0.44829052793326746, \"f0_5\": 0.16887875874758376, \"p4\": 0.37217749606603745, \"phi\": 0.2958915952488818}, {\"truth_threshold\": -18.857215220233194, \"match_probability\": 2.1057735652819954e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 68100.0, \"fp\": 39619.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6322004199028015, \"fp_rate\": 0.3677995502948761, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14159119129180908, \"recall\": 0.999541163444519, \"specificity\": 0.6322004199028015, \"npv\": 0.999955952167511, \"accuracy\": 0.6532203555107117, \"f1\": 0.24804524405981931, \"f2\": 0.4518988742289713, \"f0_5\": 0.17093547610826873, \"p4\": 0.3757679995729739, \"phi\": 0.29903381599910356}, {\"truth_threshold\": -18.826398353805775, \"match_probability\": 2.1512379511869545e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 68137.0, \"fp\": 39582.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6325439214706421, \"fp_rate\": 0.3674560785293579, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14170479774475098, \"recall\": 0.999541163444519, \"specificity\": 0.6325439214706421, \"npv\": 0.999955952167511, \"accuracy\": 0.6535441875457764, \"f1\": 0.24821954230367488, \"f2\": 0.45213023564737304, \"f0_5\": 0.1710679245678146, \"p4\": 0.37599832703971253, \"phi\": 0.2992351168040764}, {\"truth_threshold\": -18.806589147163226, \"match_probability\": 2.18097960001888e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 68390.0, \"fp\": 39329.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6348926424980164, \"fp_rate\": 0.36510735750198364, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14248648285865784, \"recall\": 0.999541163444519, \"specificity\": 0.6348926424980164, \"npv\": 0.9999561309814453, \"accuracy\": 0.6557585000991821, \"f1\": 0.24941796114652112, \"f2\": 0.45371861808487, \"f0_5\": 0.17197911512995148, \"p4\": 0.3775799794228301, \"phi\": 0.30061670896225834}, {\"truth_threshold\": -18.798357840635333, \"match_probability\": 2.1934587329445316e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 68447.0, \"fp\": 39272.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6354218125343323, \"fp_rate\": 0.3645782172679901, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14266379177570343, \"recall\": 0.999541163444519, \"specificity\": 0.6354218125343323, \"npv\": 0.9999561905860901, \"accuracy\": 0.6562573909759521, \"f1\": 0.2496895596523068, \"f2\": 0.4540780166483692, \"f0_5\": 0.17218574454854926, \"p4\": 0.3779379453886263, \"phi\": 0.3009292050843244}, {\"truth_threshold\": -18.769814825439408, \"match_probability\": 2.2372872767169407e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 68451.0, \"fp\": 39268.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6354589462280273, \"fp_rate\": 0.36454108357429504, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1426762491464615, \"recall\": 0.999541163444519, \"specificity\": 0.6354589462280273, \"npv\": 0.9999561905860901, \"accuracy\": 0.6562923789024353, \"f1\": 0.2497086414092203, \"f2\": 0.45410325898130777, \"f0_5\": 0.17220026350461132, \"p4\": 0.37796308836614884, \"phi\": 0.30095114597367756}, {\"truth_threshold\": -18.75412172726909, \"match_probability\": 2.2617564395438512e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 68879.0, \"fp\": 38840.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6394322514533997, \"fp_rate\": 0.36056777834892273, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14402203261852264, \"recall\": 0.999541163444519, \"specificity\": 0.6394322514533997, \"npv\": 0.9999564290046692, \"accuracy\": 0.6600383520126343, \"f1\": 0.2517673800396818, \"f2\": 0.4568205013491409, \"f0_5\": 0.17376806815643647, \"p4\": 0.3806706191353893, \"phi\": 0.3033124098374896}, {\"truth_threshold\": -18.752241084327206, \"match_probability\": 2.2647066959163282e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 69006.0, \"fp\": 38713.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6406112313270569, \"fp_rate\": 0.3593887686729431, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14442627131938934, \"recall\": 0.999541163444519, \"specificity\": 0.6406112313270569, \"npv\": 0.9999565482139587, \"accuracy\": 0.6611498594284058, \"f1\": 0.25238481442861005, \"f2\": 0.4576330532212885, \"f0_5\": 0.174238788460513, \"p4\": 0.3814806516854301, \"phi\": 0.3040180828262438}, {\"truth_threshold\": -18.73604842680438, \"match_probability\": 2.290268651656124e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 69016.0, \"fp\": 38703.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6407040357589722, \"fp_rate\": 0.35929593443870544, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14445820450782776, \"recall\": 0.999541163444519, \"specificity\": 0.6407040357589722, \"npv\": 0.9999565482139587, \"accuracy\": 0.661237359046936, \"f1\": 0.2524335599505562, \"f2\": 0.45769715646449083, \"f0_5\": 0.1742759613846072, \"p4\": 0.38154456383669105, \"phi\": 0.30407374289574796}, {\"truth_threshold\": -18.73583646054996, \"match_probability\": 2.2906051706060093e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 69034.0, \"fp\": 38685.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6408711671829224, \"fp_rate\": 0.35912883281707764, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14451570808887482, \"recall\": 0.999541163444519, \"specificity\": 0.6408711671829224, \"npv\": 0.9999565482139587, \"accuracy\": 0.6613949537277222, \"f1\": 0.2525213493566212, \"f2\": 0.45781258756935495, \"f0_5\": 0.17434291263379184, \"p4\": 0.3816596536783131, \"phi\": 0.304173958731808}, {\"truth_threshold\": -18.710921136385842, \"match_probability\": 2.330507362662872e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 69261.0, \"fp\": 38458.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6429784893989563, \"fp_rate\": 0.3570215106010437, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14524482190608978, \"recall\": 0.999541163444519, \"specificity\": 0.6429784893989563, \"npv\": 0.9999566674232483, \"accuracy\": 0.6633816957473755, \"f1\": 0.25363373503328096, \"f2\": 0.45927331506079133, \"f0_5\": 0.17519167873036298, \"p4\": 0.383116380056482, \"phi\": 0.3054419936203216}, {\"truth_threshold\": -18.69967394324671, \"match_probability\": 2.348746867515029e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 70109.0, \"fp\": 37610.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6508508324623108, \"fp_rate\": 0.3491491675376892, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14803488552570343, \"recall\": 0.999541163444519, \"specificity\": 0.6508508324623108, \"npv\": 0.9999572038650513, \"accuracy\": 0.6708035469055176, \"f1\": 0.2578773947872068, \"f2\": 0.46481357668179296, \"f0_5\": 0.17843685492414726, \"p4\": 0.3886469713587427, \"phi\": 0.31024645923762967}, {\"truth_threshold\": -18.68692686006902, \"match_probability\": 2.3695913686338586e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 70150.0, \"fp\": 37569.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6512314677238464, \"fp_rate\": 0.34876856207847595, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1481724977493286, \"recall\": 0.999541163444519, \"specificity\": 0.6512314677238464, \"npv\": 0.999957263469696, \"accuracy\": 0.6711623668670654, \"f1\": 0.25808617353185104, \"f2\": 0.4650848326121612, \"f0_5\": 0.17859680575445194, \"p4\": 0.3889179839372455, \"phi\": 0.3104815130352586}, {\"truth_threshold\": -18.681796502644072, \"match_probability\": 2.378032835787755e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 70355.0, \"fp\": 37364.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6531345248222351, \"fp_rate\": 0.3468654453754425, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14886443316936493, \"recall\": 0.999541163444519, \"specificity\": 0.6531345248222351, \"npv\": 0.9999573826789856, \"accuracy\": 0.6729565858840942, \"f1\": 0.2591351587128497, \"f2\": 0.46644587514810637, \"f0_5\": 0.17940088067027574, \"p4\": 0.3902781383261197, \"phi\": 0.3116606597343705}, {\"truth_threshold\": -18.661068975443385, \"match_probability\": 2.412445103516437e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 70453.0, \"fp\": 37266.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6540443301200867, \"fp_rate\": 0.34595566987991333, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1491975039243698, \"recall\": 0.999541163444519, \"specificity\": 0.6540443301200867, \"npv\": 0.9999574422836304, \"accuracy\": 0.6738142967224121, \"f1\": 0.25963964321897537, \"f2\": 0.46709933812702814, \"f0_5\": 0.17978783110123142, \"p4\": 0.39093137371236075, \"phi\": 0.3122266699029084}, {\"truth_threshold\": -18.649520591721696, \"match_probability\": 2.4318335233262215e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 70531.0, \"fp\": 37188.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6547684073448181, \"fp_rate\": 0.3452315628528595, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.14946366846561432, \"recall\": 0.999541163444519, \"specificity\": 0.6547684073448181, \"npv\": 0.9999574422836304, \"accuracy\": 0.6744969487190247, \"f1\": 0.2600425777441754, \"f2\": 0.4676207513416816, \"f0_5\": 0.18009700711018023, \"p4\": 0.39145269865495397, \"phi\": 0.3126782300405925}, {\"truth_threshold\": -18.646781088707293, \"match_probability\": 2.4364556562211103e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 71749.0, \"fp\": 35970.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6660756468772888, \"fp_rate\": 0.33392438292503357, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1537466198205948, \"recall\": 0.999541163444519, \"specificity\": 0.6660756468772888, \"npv\": 0.9999582171440125, \"accuracy\": 0.6851571202278137, \"f1\": 0.26650082580592543, \"f2\": 0.47591651251875267, \"f0_5\": 0.1850666636459407, \"p4\": 0.39975854511223274, \"phi\": 0.3198569965207266}, {\"truth_threshold\": -18.643090414880344, \"match_probability\": 2.4426965127245985e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 71751.0, \"fp\": 35968.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.666094183921814, \"fp_rate\": 0.33390581607818604, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1537538468837738, \"recall\": 0.999541163444519, \"specificity\": 0.666094183921814, \"npv\": 0.9999582171440125, \"accuracy\": 0.6851746439933777, \"f1\": 0.266511694296609, \"f2\": 0.4759303765202826, \"f0_5\": 0.18507504956103088, \"p4\": 0.3997724445567163, \"phi\": 0.31986899454199835}, {\"truth_threshold\": -18.636300786999048, \"match_probability\": 2.454219424103031e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 71844.0, \"fp\": 35875.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6669575572013855, \"fp_rate\": 0.3330424427986145, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.154091015458107, \"recall\": 0.999541163444519, \"specificity\": 0.6669575572013855, \"npv\": 0.9999582171440125, \"accuracy\": 0.6859886050224304, \"f1\": 0.2670180599820217, \"f2\": 0.4765759458592223, \"f0_5\": 0.18546583568890554, \"p4\": 0.4004197347494713, \"phi\": 0.3204272716441527}, {\"truth_threshold\": -18.615754193086666, \"match_probability\": 2.4894219516744825e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 72070.0, \"fp\": 35649.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6690555810928345, \"fp_rate\": 0.33094438910484314, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.15491655468940735, \"recall\": 0.999541163444519, \"specificity\": 0.6690555810928345, \"npv\": 0.9999583959579468, \"accuracy\": 0.6879665851593018, \"f1\": 0.2682566397110135, \"f2\": 0.478152072114259, \"f0_5\": 0.18642240149708456, \"p4\": 0.4020006455961497, \"phi\": 0.3217901049739867}, {\"truth_threshold\": -18.6091120499909, \"match_probability\": 2.500909602940603e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 72076.0, \"fp\": 35643.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6691113114356995, \"fp_rate\": 0.33088868856430054, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.15493859350681305, \"recall\": 0.999541163444519, \"specificity\": 0.6691113114356995, \"npv\": 0.9999583959579468, \"accuracy\": 0.6880190968513489, \"f1\": 0.26828967895557926, \"f2\": 0.47819405824674377, \"f0_5\": 0.18644793152639086, \"p4\": 0.4020427705686915, \"phi\": 0.3218264094160726}, {\"truth_threshold\": -18.58539025430198, \"match_probability\": 2.5423711297218074e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 72118.0, \"fp\": 35601.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6695011854171753, \"fp_rate\": 0.3304987847805023, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1550930291414261, \"recall\": 0.999541163444519, \"specificity\": 0.6695011854171753, \"npv\": 0.9999583959579468, \"accuracy\": 0.6883866786956787, \"f1\": 0.2685211817397378, \"f2\": 0.47848816776007497, \"f0_5\": 0.18662683771033, \"p4\": 0.4023378692934315, \"phi\": 0.32208069330914113}, {\"truth_threshold\": -18.58419672582678, \"match_probability\": 2.544475275113915e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 72793.0, \"fp\": 34926.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6757674813270569, \"fp_rate\": 0.3242324888706207, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.15761800110340118, \"recall\": 0.999541163444519, \"specificity\": 0.6757674813270569, \"npv\": 0.9999588131904602, \"accuracy\": 0.6942944526672363, \"f1\": 0.27229733952790686, \"f2\": 0.4832650525786461, \"f0_5\": 0.1895499530113353, \"p4\": 0.4071349543007045, \"phi\": 0.32621000610193546}, {\"truth_threshold\": -18.583833367104912, \"match_probability\": 2.5451162084670823e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 72922.0, \"fp\": 34797.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.676965057849884, \"fp_rate\": 0.32303494215011597, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.15810993313789368, \"recall\": 0.999541163444519, \"specificity\": 0.676965057849884, \"npv\": 0.999958872795105, \"accuracy\": 0.6954234838485718, \"f1\": 0.27303112596615836, \"f2\": 0.4841888447632031, \"f0_5\": 0.1901190462336937, \"p4\": 0.40806356507477937, \"phi\": 0.32700843836191107}, {\"truth_threshold\": -18.574453965111925, \"match_probability\": 2.5617166492775686e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 73731.0, \"fp\": 33988.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6844753623008728, \"fp_rate\": 0.3155246376991272, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.16126644611358643, \"recall\": 0.999541163444519, \"specificity\": 0.6844753623008728, \"npv\": 0.9999592900276184, \"accuracy\": 0.7025039792060852, \"f1\": 0.2777246552346954, \"f2\": 0.49006374203224595, \"f0_5\": 0.19376741979481704, \"p4\": 0.4139762143534663, \"phi\": 0.33208593899762595}, {\"truth_threshold\": -18.560202449509955, \"match_probability\": 2.5871476419998526e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 73762.0, \"fp\": 33957.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6847631335258484, \"fp_rate\": 0.3152368664741516, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.16138990223407745, \"recall\": 0.999541163444519, \"specificity\": 0.6847631335258484, \"npv\": 0.9999593496322632, \"accuracy\": 0.7027752995491028, \"f1\": 0.2779077184775675, \"f2\": 0.4902916991777204, \"f0_5\": 0.19391000913914044, \"p4\": 0.4142058877967739, \"phi\": 0.3322829695213359}, {\"truth_threshold\": -18.559312496119077, \"match_probability\": 2.5887440605685866e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 73820.0, \"fp\": 33899.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6853015422821045, \"fp_rate\": 0.3146984279155731, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.16162140667438507, \"recall\": 0.999541163444519, \"specificity\": 0.6853015422821045, \"npv\": 0.9999593496322632, \"accuracy\": 0.7032829523086548, \"f1\": 0.2782508728604275, \"f2\": 0.49071876971135076, \"f0_5\": 0.19417735360186364, \"p4\": 0.4146362250295213, \"phi\": 0.3326520884567642}, {\"truth_threshold\": -18.551623855666953, \"match_probability\": 2.6025772004363704e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 73889.0, \"fp\": 33830.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6859421133995056, \"fp_rate\": 0.3140578866004944, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1618976891040802, \"recall\": 0.999541163444519, \"specificity\": 0.6859421133995056, \"npv\": 0.999959409236908, \"accuracy\": 0.703886866569519, \"f1\": 0.27866021363239024, \"f2\": 0.4912278064254251, \"f0_5\": 0.1944963630519411, \"p4\": 0.4151492429510031, \"phi\": 0.3330920719090552}, {\"truth_threshold\": -18.529385583082536, \"match_probability\": 2.6430050346867783e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 73927.0, \"fp\": 33792.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6862949132919312, \"fp_rate\": 0.31370511651039124, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.16205023229122162, \"recall\": 0.999541163444519, \"specificity\": 0.6862949132919312, \"npv\": 0.999959409236908, \"accuracy\": 0.7042194604873657, \"f1\": 0.27888616238130803, \"f2\": 0.4915085966997097, \"f0_5\": 0.19467249740833859, \"p4\": 0.4154322701483751, \"phi\": 0.3333347731181302}, {\"truth_threshold\": -18.522796181162633, \"match_probability\": 2.6551043411689875e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 74433.0, \"fp\": 33286.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6909922957420349, \"fp_rate\": 0.3090077042579651, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.16410939395427704, \"recall\": 0.999541163444519, \"specificity\": 0.6909922957420349, \"npv\": 0.9999597072601318, \"accuracy\": 0.7086480259895325, \"f1\": 0.2819301537996937, \"f2\": 0.49527837145498915, \"f0_5\": 0.19704864252029283, \"p4\": 0.41923491507788835, \"phi\": 0.3365935191230187}, {\"truth_threshold\": -18.518276058443444, \"match_probability\": 2.663436099163652e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 74714.0, \"fp\": 33005.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.6936009526252747, \"fp_rate\": 0.30639904737472534, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1652756631374359, \"recall\": 0.999541163444519, \"specificity\": 0.6936009526252747, \"npv\": 0.9999598264694214, \"accuracy\": 0.7111074328422546, \"f1\": 0.2836494639524285, \"f2\": 0.49739694331120987, \"f0_5\": 0.19839342311382044, \"p4\": 0.42137430637008866, \"phi\": 0.33842530237380697}, {\"truth_threshold\": -18.509576376439984, \"match_probability\": 2.6795455244862857e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 75486.0, \"fp\": 32233.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7007677555084229, \"fp_rate\": 0.29923227429389954, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.16856685280799866, \"recall\": 0.999541163444519, \"specificity\": 0.7007677555084229, \"npv\": 0.9999602437019348, \"accuracy\": 0.7178640961647034, \"f1\": 0.2884827616651216, \"f2\": 0.5033117683302526, \"f0_5\": 0.2021842707753233, \"p4\": 0.4273563932574825, \"phi\": 0.3435419075236601}, {\"truth_threshold\": -18.489029782527602, \"match_probability\": 2.717980047788929e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 75578.0, \"fp\": 32141.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7016218304634094, \"fp_rate\": 0.29837819933891296, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1689678281545639, \"recall\": 0.999541163444519, \"specificity\": 0.7016218304634094, \"npv\": 0.9999603033065796, \"accuracy\": 0.7186692953109741, \"f1\": 0.28906975715486355, \"f2\": 0.5040260381316715, \"f0_5\": 0.2026457126555116, \"p4\": 0.4280797100548002, \"phi\": 0.3441600628361294}, {\"truth_threshold\": -18.4832818562281, \"match_probability\": 2.7288304832361394e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 75580.0, \"fp\": 32139.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7016403675079346, \"fp_rate\": 0.29835963249206543, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1689765751361847, \"recall\": 0.999541163444519, \"specificity\": 0.7016403675079346, \"npv\": 0.9999603033065796, \"accuracy\": 0.7186868190765381, \"f1\": 0.28908254445722376, \"f2\": 0.5040415882516275, \"f0_5\": 0.20265576739397398, \"p4\": 0.42809545937463644, \"phi\": 0.34417353002391793}, {\"truth_threshold\": -18.47280205471617, \"match_probability\": 2.7487249454784946e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 75657.0, \"fp\": 32062.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7023552060127258, \"fp_rate\": 0.29764479398727417, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1693136841058731, \"recall\": 0.999541163444519, \"specificity\": 0.7023552060127258, \"npv\": 0.9999603629112244, \"accuracy\": 0.7193607687950134, \"f1\": 0.28957571729256676, \"f2\": 0.5046409983165763, \"f0_5\": 0.20304363496265365, \"p4\": 0.4287026209359299, \"phi\": 0.3446923527388226}, {\"truth_threshold\": -18.458665843742917, \"match_probability\": 2.775790567130597e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 75875.0, \"fp\": 31844.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7043789625167847, \"fp_rate\": 0.29562100768089294, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17027540504932404, \"recall\": 0.999541163444519, \"specificity\": 0.7043789625167847, \"npv\": 0.9999604821205139, \"accuracy\": 0.7212687134742737, \"f1\": 0.2909811429970835, \"f2\": 0.5063457872960283, \"f0_5\": 0.2041498494258188, \"p4\": 0.43043023630780514, \"phi\": 0.34616824543341435}, {\"truth_threshold\": -18.45710895654585, \"match_probability\": 2.7787876755454785e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76067.0, \"fp\": 31652.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.706161379814148, \"fp_rate\": 0.29383859038352966, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17113153636455536, \"recall\": 0.999541163444519, \"specificity\": 0.706161379814148, \"npv\": 0.9999605417251587, \"accuracy\": 0.7229491472244263, \"f1\": 0.292230296254891, \"f2\": 0.5078568209017859, \"f0_5\": 0.2051341611943297, \"p4\": 0.4319624731343931, \"phi\": 0.347476798931158}, {\"truth_threshold\": -18.447886730552046, \"match_probability\": 2.7966075316925625e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76171.0, \"fp\": 31548.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7071268558502197, \"fp_rate\": 0.2928731143474579, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.171598881483078, \"recall\": 0.999541163444519, \"specificity\": 0.7071268558502197, \"npv\": 0.9999606013298035, \"accuracy\": 0.7238593697547913, \"f1\": 0.292911409426055, \"f2\": 0.5086790690433565, \"f0_5\": 0.20567130358154465, \"p4\": 0.43279664514635235, \"phi\": 0.3481890441386249}, {\"truth_threshold\": -18.445356306821992, \"match_probability\": 2.8015169489103565e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76415.0, \"fp\": 31304.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7093920111656189, \"fp_rate\": 0.2906079590320587, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17270541191101074, \"recall\": 0.999541163444519, \"specificity\": 0.7093920111656189, \"npv\": 0.999960720539093, \"accuracy\": 0.725994884967804, \"f1\": 0.2945219370394574, \"f2\": 0.5106186807519808, \"f0_5\": 0.2069426323989512, \"p4\": 0.43476546875097777, \"phi\": 0.34986963654036884}, {\"truth_threshold\": -18.443153154466597, \"match_probability\": 2.8057984265234955e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76477.0, \"fp\": 31242.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7099676132202148, \"fp_rate\": 0.29003238677978516, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1729888617992401, \"recall\": 0.999541163444519, \"specificity\": 0.7099676132202148, \"npv\": 0.9999607801437378, \"accuracy\": 0.7265375256538391, \"f1\": 0.29493399526119823, \"f2\": 0.5111138919739086, \"f0_5\": 0.20726818314451365, \"p4\": 0.4352683835080693, \"phi\": 0.3502988271952928}, {\"truth_threshold\": -18.42489944510789, \"match_probability\": 2.8415242443608637e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76761.0, \"fp\": 30958.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7126041054725647, \"fp_rate\": 0.2873959243297577, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1742991954088211, \"recall\": 0.999541163444519, \"specificity\": 0.7126041054725647, \"npv\": 0.9999608993530273, \"accuracy\": 0.7290231585502625, \"f1\": 0.29683631986554926, \"f2\": 0.5133946107314007, \"f0_5\": 0.20877260238962367, \"p4\": 0.4375858783525194, \"phi\": 0.3522761881408899}, {\"truth_threshold\": -18.414120331917015, \"match_probability\": 2.862834175405319e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76775.0, \"fp\": 30944.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.712734043598175, \"fp_rate\": 0.28726595640182495, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17436431348323822, \"recall\": 0.999541163444519, \"specificity\": 0.712734043598175, \"npv\": 0.9999608993530273, \"accuracy\": 0.7291457056999207, \"f1\": 0.2969307313083581, \"f2\": 0.513507567066367, \"f0_5\": 0.20884732892735244, \"p4\": 0.4377007117109621, \"phi\": 0.35237416312660313}, {\"truth_threshold\": -18.4139083656626, \"match_probability\": 2.8632548236109347e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76790.0, \"fp\": 30929.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7128732800483704, \"fp_rate\": 0.28712669014930725, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1744341254234314, \"recall\": 0.999541163444519, \"specificity\": 0.7128732800483704, \"npv\": 0.9999609589576721, \"accuracy\": 0.7292769551277161, \"f1\": 0.2970319530930412, \"f2\": 0.5136286468812877, \"f0_5\": 0.20892745245981303, \"p4\": 0.4378238093903428, \"phi\": 0.3524791568172003}, {\"truth_threshold\": -18.402661172523473, \"match_probability\": 2.885663816195416e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 76999.0, \"fp\": 30720.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7148135304450989, \"fp_rate\": 0.2851864695549011, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17541269958019257, \"recall\": 0.999541163444519, \"specificity\": 0.7148135304450989, \"npv\": 0.9999610185623169, \"accuracy\": 0.731106162071228, \"f1\": 0.29844952389651314, \"f2\": 0.5153216521835129, \"f0_5\": 0.21005027063860426, \"p4\": 0.4395456654894477, \"phi\": 0.35394781803653114}, {\"truth_threshold\": -18.398604129712506, \"match_probability\": 2.8937900687859328e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77048.0, \"fp\": 30671.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7152684330940247, \"fp_rate\": 0.28473156690597534, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1756437122821808, \"recall\": 0.999541163444519, \"specificity\": 0.7152684330940247, \"npv\": 0.9999610781669617, \"accuracy\": 0.7315350770950317, \"f1\": 0.29878383321141183, \"f2\": 0.5157201931879163, \"f0_5\": 0.2103152637066979, \"p4\": 0.4399511712248727, \"phi\": 0.35429363406090925}, {\"truth_threshold\": -18.39424355398565, \"match_probability\": 2.902549815577075e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77070.0, \"fp\": 30649.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7154726386070251, \"fp_rate\": 0.28452733159065247, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17574763298034668, \"recall\": 0.999541163444519, \"specificity\": 0.7154726386070251, \"npv\": 0.9999610781669617, \"accuracy\": 0.7317276000976562, \"f1\": 0.29893417501486663, \"f2\": 0.515899330554503, \"f0_5\": 0.21043445779718434, \"p4\": 0.4401334606796847, \"phi\": 0.35444909081736475}, {\"truth_threshold\": -18.39155164788438, \"match_probability\": 2.9079706859502628e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77326.0, \"fp\": 30393.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7178491950035095, \"fp_rate\": 0.2821507751941681, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17696598172187805, \"recall\": 0.999541163444519, \"specificity\": 0.7178491950035095, \"npv\": 0.9999611973762512, \"accuracy\": 0.7339681386947632, \"f1\": 0.30069479593245296, \"f2\": 0.5179930247305009, \"f0_5\": 0.21183144246353322, \"p4\": 0.4422649904405505, \"phi\": 0.35626656792131556}, {\"truth_threshold\": -18.377594455891902, \"match_probability\": 2.936239964365245e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77475.0, \"fp\": 30244.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.719232439994812, \"fp_rate\": 0.280767560005188, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17768292129039764, \"recall\": 0.999541163444519, \"specificity\": 0.719232439994812, \"npv\": 0.999961256980896, \"accuracy\": 0.735272228717804, \"f1\": 0.3017291132811598, \"f2\": 0.5192194625860069, \"f0_5\": 0.21265310372655447, \"p4\": 0.4435144470514699, \"phi\": 0.35733171196360886}, {\"truth_threshold\": -18.37388614910827, \"match_probability\": 2.9437969684845504e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77476.0, \"fp\": 30243.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.719241738319397, \"fp_rate\": 0.280758261680603, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17768774926662445, \"recall\": 0.999541163444519, \"specificity\": 0.719241738319397, \"npv\": 0.999961256980896, \"accuracy\": 0.7352809906005859, \"f1\": 0.3017360790470034, \"f2\": 0.5192277133322739, \"f0_5\": 0.21265863976570126, \"p4\": 0.4435228548041809, \"phi\": 0.3573388945825904}, {\"truth_threshold\": -18.364056204720143, \"match_probability\": 2.9639232471961066e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77835.0, \"fp\": 29884.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7225744724273682, \"fp_rate\": 0.27742552757263184, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17943930625915527, \"recall\": 0.999541163444519, \"specificity\": 0.7225744724273682, \"npv\": 0.9999614357948303, \"accuracy\": 0.7384230494499207, \"f1\": 0.3042577461182112, \"f2\": 0.5222067731057519, \"f0_5\": 0.214664879708831, \"p4\": 0.4465604927226327, \"phi\": 0.3599279040961768}, {\"truth_threshold\": -18.355704729411816, \"match_probability\": 2.981130516256009e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77942.0, \"fp\": 29777.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.72356778383255, \"fp_rate\": 0.27643218636512756, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17996805906295776, \"recall\": 0.999541163444519, \"specificity\": 0.72356778383255, \"npv\": 0.9999614953994751, \"accuracy\": 0.7393594980239868, \"f1\": 0.30501750291715285, \"f2\": 0.523101306352459, \"f0_5\": 0.21527018302083195, \"p4\": 0.44747335444447134, \"phi\": 0.3607058013489371}, {\"truth_threshold\": -18.346077644157106, \"match_probability\": 3.0010900224377568e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77946.0, \"fp\": 29773.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7236049175262451, \"fp_rate\": 0.2763950526714325, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.17998787760734558, \"recall\": 0.999541163444519, \"specificity\": 0.7236049175262451, \"npv\": 0.9999614953994751, \"accuracy\": 0.7393945455551147, \"f1\": 0.30504597862110816, \"f2\": 0.5231348062760166, \"f0_5\": 0.21529287738024644, \"p4\": 0.44750754742567167, \"phi\": 0.36073493259796974}, {\"truth_threshold\": -18.34011975047324, \"match_probability\": 3.0135092042594326e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77976.0, \"fp\": 29743.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7238834500312805, \"fp_rate\": 0.2761165499687195, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18013672530651093, \"recall\": 0.999541163444519, \"specificity\": 0.7238834500312805, \"npv\": 0.9999615550041199, \"accuracy\": 0.7396571040153503, \"f1\": 0.3052597159940209, \"f2\": 0.5233861925356399, \"f0_5\": 0.2154632377184306, \"p4\": 0.44776414982077267, \"phi\": 0.3609536033355051}, {\"truth_threshold\": -18.321162319992983, \"match_probability\": 3.0533687762924314e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 77977.0, \"fp\": 29742.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7238927483558655, \"fp_rate\": 0.2761072814464569, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18014168739318848, \"recall\": 0.999541163444519, \"specificity\": 0.7238927483558655, \"npv\": 0.9999615550041199, \"accuracy\": 0.7396658658981323, \"f1\": 0.3052668457316361, \"f2\": 0.5233945762386071, \"f0_5\": 0.21546892103979004, \"p4\": 0.4477727079488987, \"phi\": 0.3609608887483051}, {\"truth_threshold\": -18.316428743907533, \"match_probability\": 3.0634035000624612e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78014.0, \"fp\": 29705.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7242361903190613, \"fp_rate\": 0.27576377987861633, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18032561242580414, \"recall\": 0.999541163444519, \"specificity\": 0.7242361903190613, \"npv\": 0.9999615550041199, \"accuracy\": 0.739989697933197, \"f1\": 0.30553088035906306, \"f2\": 0.5237049621746378, \"f0_5\": 0.21567941490976777, \"p4\": 0.4480895728069041, \"phi\": 0.3612309002930362}, {\"truth_threshold\": -18.316141969520533, \"match_probability\": 3.0640124924434046e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78048.0, \"fp\": 29671.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7245518565177917, \"fp_rate\": 0.27544814348220825, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18049494922161102, \"recall\": 0.999541163444519, \"specificity\": 0.7245518565177917, \"npv\": 0.9999615550041199, \"accuracy\": 0.7402872443199158, \"f1\": 0.3057739097885083, \"f2\": 0.5239905064306103, \"f0_5\": 0.2158732046352453, \"p4\": 0.44838111403767894, \"phi\": 0.3614793039369755}, {\"truth_threshold\": -18.30743202082868, \"match_probability\": 3.0825666776813182e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78049.0, \"fp\": 29670.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7245611548423767, \"fp_rate\": 0.2754388749599457, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18049992620944977, \"recall\": 0.999541163444519, \"specificity\": 0.7245611548423767, \"npv\": 0.9999615550041199, \"accuracy\": 0.7402960062026978, \"f1\": 0.305781063565964, \"f2\": 0.5239989095049473, \"f0_5\": 0.21587890960504236, \"p4\": 0.4483896941241871, \"phi\": 0.3614866304143908}, {\"truth_threshold\": -18.295883637106996, \"match_probability\": 3.1073407363236787e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78072.0, \"fp\": 29647.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7247746586799622, \"fp_rate\": 0.27522534132003784, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1806146651506424, \"recall\": 0.999541163444519, \"specificity\": 0.7247746586799622, \"npv\": 0.9999615550041199, \"accuracy\": 0.7404972910881042, \"f1\": 0.3059456928838951, \"f2\": 0.5241922546282928, \"f0_5\": 0.21601020718469452, \"p4\": 0.44858712049440247, \"phi\": 0.361654847158311}, {\"truth_threshold\": -18.288377483578742, \"match_probability\": 3.12354990361926e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78447.0, \"fp\": 29272.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7282559275627136, \"fp_rate\": 0.2717440724372864, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18250621855258942, \"recall\": 0.999541163444519, \"specificity\": 0.7282559275627136, \"npv\": 0.9999617338180542, \"accuracy\": 0.7437793612480164, \"f1\": 0.30865509505254457, \"f2\": 0.527364870317468, \"f0_5\": 0.2181736842808114, \"p4\": 0.4518290146833592, \"phi\": 0.3644168703860441}, {\"truth_threshold\": -18.287395921357955, \"match_probability\": 3.125675780628598e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78620.0, \"fp\": 29099.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7298619747161865, \"fp_rate\": 0.27013805508613586, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18339227139949799, \"recall\": 0.999541163444519, \"specificity\": 0.7298619747161865, \"npv\": 0.9999618530273438, \"accuracy\": 0.7452934980392456, \"f1\": 0.3099212747794745, \"f2\": 0.5288414851260803, \"f0_5\": 0.21918644431624562, \"p4\": 0.4533393664852141, \"phi\": 0.3657035054781366}, {\"truth_threshold\": -18.287183955103536, \"match_probability\": 3.1261350491304693e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78622.0, \"fp\": 29097.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7298805117607117, \"fp_rate\": 0.27011948823928833, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18340255320072174, \"recall\": 0.999541163444519, \"specificity\": 0.7298805117607117, \"npv\": 0.9999618530273438, \"accuracy\": 0.7453110218048096, \"f1\": 0.30993597344083473, \"f2\": 0.5288586041693643, \"f0_5\": 0.21919820750540028, \"p4\": 0.4533568822483381, \"phi\": 0.3657184348858203}, {\"truth_threshold\": -18.271879719153443, \"match_probability\": 3.159473777498854e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78665.0, \"fp\": 29054.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7302796840667725, \"fp_rate\": 0.26972028613090515, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18362414836883545, \"recall\": 0.999541163444519, \"specificity\": 0.7302796840667725, \"npv\": 0.9999618530273438, \"accuracy\": 0.7456873655319214, \"f1\": 0.3102523322334845, \"f2\": 0.5292269318605141, \"f0_5\": 0.219451421816863, \"p4\": 0.4537337767471223, \"phi\": 0.3660394816606602}, {\"truth_threshold\": -18.26751914342659, \"match_probability\": 3.169037768752836e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78666.0, \"fp\": 29053.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7302889823913574, \"fp_rate\": 0.2697110176086426, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18362931907176971, \"recall\": 0.999541163444519, \"specificity\": 0.7302889823913574, \"npv\": 0.9999618530273438, \"accuracy\": 0.7456961274147034, \"f1\": 0.31025969709917867, \"f2\": 0.5292355037252996, \"f0_5\": 0.21945731748270536, \"p4\": 0.4537425486903471, \"phi\": 0.36604694685144273}, {\"truth_threshold\": -18.247161738549206, \"match_probability\": 3.21407187958431e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78757.0, \"fp\": 28962.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.731133759021759, \"fp_rate\": 0.2688662111759186, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18410006165504456, \"recall\": 0.999541163444519, \"specificity\": 0.731133759021759, \"npv\": 0.9999619126319885, \"accuracy\": 0.7464925646781921, \"f1\": 0.31093136671821103, \"f2\": 0.5300167074891726, \"f0_5\": 0.21999515236389589, \"p4\": 0.45454212222229295, \"phi\": 0.36672806183280515}, {\"truth_threshold\": -18.23670227699917, \"match_probability\": 3.2374583254262654e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 78847.0, \"fp\": 28872.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7319692969322205, \"fp_rate\": 0.26803070306777954, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18456801772117615, \"recall\": 0.999541163444519, \"specificity\": 0.7319692969322205, \"npv\": 0.9999619722366333, \"accuracy\": 0.7472802400588989, \"f1\": 0.3115985218738825, \"f2\": 0.530791598304066, \"f0_5\": 0.22052967617402103, \"p4\": 0.45533549957230096, \"phi\": 0.367403868598947}, {\"truth_threshold\": -18.22496986063671, \"match_probability\": 3.2638935374761337e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79023.0, \"fp\": 28696.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7336031794548035, \"fp_rate\": 0.26639682054519653, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18549005687236786, \"recall\": 0.999541163444519, \"specificity\": 0.7336031794548035, \"npv\": 0.9999620318412781, \"accuracy\": 0.7488206624984741, \"f1\": 0.31291148938207763, \"f2\": 0.5323135069970513, \"f0_5\": 0.22158250939225022, \"p4\": 0.45689448789863596, \"phi\": 0.36873180554336277}, {\"truth_threshold\": -18.221263287720205, \"match_probability\": 3.272289888498235e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79046.0, \"fp\": 28673.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7338166832923889, \"fp_rate\": 0.2661833167076111, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18561121821403503, \"recall\": 0.999541163444519, \"specificity\": 0.7338166832923889, \"npv\": 0.9999620318412781, \"accuracy\": 0.7490219473838806, \"f1\": 0.3130838882767211, \"f2\": 0.532513037809648, \"f0_5\": 0.2217208387052996, \"p4\": 0.4570989560859344, \"phi\": 0.36890596394361336}, {\"truth_threshold\": -18.213421476915023, \"match_probability\": 3.290124884134538e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79335.0, \"fp\": 28384.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7364996075630188, \"fp_rate\": 0.2635003924369812, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18714739382266998, \"recall\": 0.999541163444519, \"specificity\": 0.7364996075630188, \"npv\": 0.9999622106552124, \"accuracy\": 0.7515513300895691, \"f1\": 0.3152664206286031, \"f2\": 0.5350329943835863, \"f0_5\": 0.22347381235722982, \"p4\": 0.45968279277492796, \"phi\": 0.37110683864505417}, {\"truth_threshold\": -18.198305479226676, \"match_probability\": 3.3247786460842626e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79510.0, \"fp\": 28209.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7381241917610168, \"fp_rate\": 0.26187580823898315, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1880900263786316, \"recall\": 0.999541163444519, \"specificity\": 0.7381241917610168, \"npv\": 0.9999622702598572, \"accuracy\": 0.7530829906463623, \"f1\": 0.31660287776755003, \"f2\": 0.5365705465055176, \"f0_5\": 0.22454884066137967, \"p4\": 0.4612607151735833, \"phi\": 0.3724508824153217}, {\"truth_threshold\": -18.169159226547933, \"match_probability\": 3.392630822663476e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79515.0, \"fp\": 28204.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7381706237792969, \"fp_rate\": 0.2618293762207031, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1881171017885208, \"recall\": 0.999541163444519, \"specificity\": 0.7381706237792969, \"npv\": 0.9999622702598572, \"accuracy\": 0.7531267404556274, \"f1\": 0.3166412287714708, \"f2\": 0.5366146064278793, \"f0_5\": 0.22457970775427166, \"p4\": 0.46130594757975585, \"phi\": 0.37248942148971914}, {\"truth_threshold\": -18.167278583606052, \"match_probability\": 3.397056197206529e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79617.0, \"fp\": 28102.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7391175031661987, \"fp_rate\": 0.2608824670314789, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1886710673570633, \"recall\": 0.999541163444519, \"specificity\": 0.7391175031661987, \"npv\": 0.999962329864502, \"accuracy\": 0.7540194392204285, \"f1\": 0.3174256223436551, \"f2\": 0.5375150109394792, \"f0_5\": 0.22521125401486014, \"p4\": 0.4622305041969285, \"phi\": 0.37327697147461775}, {\"truth_threshold\": -18.167254362780422, \"match_probability\": 3.3971132292989964e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79622.0, \"fp\": 28097.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7391639351844788, \"fp_rate\": 0.26083606481552124, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.18869830667972565, \"recall\": 0.999541163444519, \"specificity\": 0.7391639351844788, \"npv\": 0.999962329864502, \"accuracy\": 0.7540631890296936, \"f1\": 0.31746417294146223, \"f2\": 0.5375592261121348, \"f0_5\": 0.22524230350323302, \"p4\": 0.4622759147874071, \"phi\": 0.3733156402298396}, {\"truth_threshold\": -18.16165307301968, \"match_probability\": 3.410328175310833e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79650.0, \"fp\": 28069.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7394238710403442, \"fp_rate\": 0.26057612895965576, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.188850998878479, \"recall\": 0.999541163444519, \"specificity\": 0.7394238710403442, \"npv\": 0.999962329864502, \"accuracy\": 0.75430828332901, \"f1\": 0.31768022944922464, \"f2\": 0.5378069655671868, \"f0_5\": 0.2254163389765029, \"p4\": 0.4625303685291276, \"phi\": 0.37353239574968755}, {\"truth_threshold\": -18.131702061105184, \"match_probability\": 3.4818679383793e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79670.0, \"fp\": 28049.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7396095395088196, \"fp_rate\": 0.2603904604911804, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1889602094888687, \"recall\": 0.999541163444519, \"specificity\": 0.7396095395088196, \"npv\": 0.999962329864502, \"accuracy\": 0.7544833421707153, \"f1\": 0.31783473566460774, \"f2\": 0.537984062170706, \"f0_5\": 0.22554081477697863, \"p4\": 0.4627122818168942, \"phi\": 0.37368734903441264}, {\"truth_threshold\": -18.125958635664684, \"match_probability\": 3.4957569705506324e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79672.0, \"fp\": 28047.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7396281361579895, \"fp_rate\": 0.2603718936443329, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.188971146941185, \"recall\": 0.999541163444519, \"specificity\": 0.7396281361579895, \"npv\": 0.999962329864502, \"accuracy\": 0.7545008063316345, \"f1\": 0.31785019455252916, \"f2\": 0.5380017782461224, \"f0_5\": 0.22555326991840735, \"p4\": 0.4627304805142571, \"phi\": 0.37370285987304097}, {\"truth_threshold\": -18.109977866440108, \"match_probability\": 3.534694680349597e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 79967.0, \"fp\": 27752.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7423667311668396, \"fp_rate\": 0.2576332986354828, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19059701263904572, \"recall\": 0.999541163444519, \"specificity\": 0.7423667311668396, \"npv\": 0.9999625086784363, \"accuracy\": 0.7570827007293701, \"f1\": 0.32014696876913656, \"f2\": 0.5406277403663198, \"f0_5\": 0.2274055927508595, \"p4\": 0.46542955078430603, \"phi\": 0.3760021192639527}, {\"truth_threshold\": -18.10713337034285, \"match_probability\": 3.5416707270795306e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80003.0, \"fp\": 27716.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7427009344100952, \"fp_rate\": 0.2572990953922272, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1907973438501358, \"recall\": 0.999541163444519, \"specificity\": 0.7427009344100952, \"npv\": 0.9999625086784363, \"accuracy\": 0.7573977708816528, \"f1\": 0.32042952756870724, \"f2\": 0.540949952816913, \"f0_5\": 0.2276337239274916, \"p4\": 0.46576094950158414, \"phi\": 0.3762844410195507}, {\"truth_threshold\": -18.094538877161142, \"match_probability\": 3.5727241748893528e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80021.0, \"fp\": 27698.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7428680062294006, \"fp_rate\": 0.25713199377059937, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19089767336845398, \"recall\": 0.999541163444519, \"specificity\": 0.7428680062294006, \"npv\": 0.9999625086784363, \"accuracy\": 0.757555365562439, \"f1\": 0.32057099408893575, \"f2\": 0.5411112031133559, \"f0_5\": 0.22774796124625357, \"p4\": 0.4659268147969894, \"phi\": 0.37642575651646126}, {\"truth_threshold\": -18.088421762106716, \"match_probability\": 3.5879048499164245e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80066.0, \"fp\": 27653.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7432857751846313, \"fp_rate\": 0.25671422481536865, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19114893674850464, \"recall\": 0.999541163444519, \"specificity\": 0.7432857751846313, \"npv\": 0.9999625086784363, \"accuracy\": 0.75794917345047, \"f1\": 0.3209252074841625, \"f2\": 0.5415147497514087, \"f0_5\": 0.22803405680787214, \"p4\": 0.466341962943177, \"phi\": 0.3767794406185622}, {\"truth_threshold\": -18.08669706635596, \"match_probability\": 3.5921966247615048e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80095.0, \"fp\": 27624.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7435550093650818, \"fp_rate\": 0.2564450204372406, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19131122529506683, \"recall\": 0.999541163444519, \"specificity\": 0.7435550093650818, \"npv\": 0.999962568283081, \"accuracy\": 0.7582029700279236, \"f1\": 0.3211538934073765, \"f2\": 0.5417751322312679, \"f0_5\": 0.22821881067791638, \"p4\": 0.4666098705710351, \"phi\": 0.3770076872890161}, {\"truth_threshold\": -18.07687337838503, \"match_probability\": 3.6167402099167417e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80110.0, \"fp\": 27609.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7436942458152771, \"fp_rate\": 0.2563057541847229, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19139526784420013, \"recall\": 0.999541163444519, \"specificity\": 0.7436942458152771, \"npv\": 0.999962568283081, \"accuracy\": 0.7583342790603638, \"f1\": 0.321272307162873, \"f2\": 0.5419099111052142, \"f0_5\": 0.22831449054599828, \"p4\": 0.4667485567657945, \"phi\": 0.377125851700369}, {\"truth_threshold\": -18.076106474722227, \"match_probability\": 3.618663290361391e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80335.0, \"fp\": 27384.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7457830309867859, \"fp_rate\": 0.2542169988155365, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19266487658023834, \"recall\": 0.999541163444519, \"specificity\": 0.7457830309867859, \"npv\": 0.9999626874923706, \"accuracy\": 0.7603034973144531, \"f1\": 0.3230590503497541, \"f2\": 0.5439396713888566, \"f0_5\": 0.22975937671396626, \"p4\": 0.4688381667570088, \"phi\": 0.37890626093494356}, {\"truth_threshold\": -18.071581068667612, \"match_probability\": 3.630031993659612e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80356.0, \"fp\": 27363.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7459779381752014, \"fp_rate\": 0.2540220320224762, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19278423488140106, \"recall\": 0.999541163444519, \"specificity\": 0.7459779381752014, \"npv\": 0.9999626874923706, \"accuracy\": 0.7604873180389404, \"f1\": 0.3232268275793847, \"f2\": 0.5441298917568693, \"f0_5\": 0.22989516639696053, \"p4\": 0.4690340928726982, \"phi\": 0.3790732191464418}, {\"truth_threshold\": -18.059824514915093, \"match_probability\": 3.659733952885844e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80358.0, \"fp\": 27361.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7459965348243713, \"fp_rate\": 0.25400346517562866, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19279560446739197, \"recall\": 0.999541163444519, \"specificity\": 0.7459965348243713, \"npv\": 0.9999626874923706, \"accuracy\": 0.7605048418045044, \"f1\": 0.32324281545234207, \"f2\": 0.5441480149213962, \"f0_5\": 0.2299081071192356, \"p4\": 0.46905276051815337, \"phi\": 0.37908911147752156}, {\"truth_threshold\": -18.04439761499489, \"match_probability\": 3.6990777326868277e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80522.0, \"fp\": 27197.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7475190162658691, \"fp_rate\": 0.25248098373413086, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19373294711112976, \"recall\": 0.999541163444519, \"specificity\": 0.7475190162658691, \"npv\": 0.9999627470970154, \"accuracy\": 0.7619401812553406, \"f1\": 0.32455922522969954, \"f2\": 0.5456382339189099, \"f0_5\": 0.2309742270227475, \"p4\": 0.47058826843564955, \"phi\": 0.38039759408161705}, {\"truth_threshold\": -18.032849231273204, \"match_probability\": 3.7288065662539024e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 80556.0, \"fp\": 27163.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7478346228599548, \"fp_rate\": 0.2521653473377228, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19392842054367065, \"recall\": 0.999541163444519, \"specificity\": 0.7478346228599548, \"npv\": 0.9999627470970154, \"accuracy\": 0.7622377872467041, \"f1\": 0.3248334824535242, \"f2\": 0.5459482038429407, \"f0_5\": 0.23119649048326613, \"p4\": 0.47090778733679856, \"phi\": 0.3806699018991904}, {\"truth_threshold\": -17.99923422510562, \"match_probability\": 3.816708056911235e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 81113.0, \"fp\": 26606.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7530055046081543, \"fp_rate\": 0.2469944953918457, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19718776643276215, \"recall\": 0.999541163444519, \"specificity\": 0.7530055046081543, \"npv\": 0.9999630451202393, \"accuracy\": 0.7671127319335938, \"f1\": 0.32939338188966455, \"f2\": 0.551076855615334, \"f0_5\": 0.2348995700996391, \"p4\": 0.47620091115999463, \"phi\": 0.3851819870207858}, {\"truth_threshold\": -17.998870866383758, \"match_probability\": 3.817669454494415e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 81212.0, \"fp\": 26507.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.753924548625946, \"fp_rate\": 0.24607543647289276, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.197778582572937, \"recall\": 0.999541163444519, \"specificity\": 0.753924548625946, \"npv\": 0.9999630451202393, \"accuracy\": 0.7679792046546936, \"f1\": 0.33021728145528045, \"f2\": 0.5519985133628408, \"f0_5\": 0.23557019883782965, \"p4\": 0.477153428537903, \"phi\": 0.3859942322314428}, {\"truth_threshold\": -17.995694177495377, \"match_probability\": 3.826084859723715e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 81365.0, \"fp\": 26354.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7553449273109436, \"fp_rate\": 0.2446550726890564, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.19869865477085114, \"recall\": 0.999541163444519, \"specificity\": 0.7553449273109436, \"npv\": 0.999963104724884, \"accuracy\": 0.7693182826042175, \"f1\": 0.33149871915185025, \"f2\": 0.5534289730864992, \"f0_5\": 0.23661419033412023, \"p4\": 0.47863257538029336, \"phi\": 0.38725574827255016}, {\"truth_threshold\": -17.950148967825967, \"match_probability\": 3.948798918775667e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 81530.0, \"fp\": 26189.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7568767070770264, \"fp_rate\": 0.24312330782413483, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.1997005194425583, \"recall\": 0.999541163444519, \"specificity\": 0.7568767070770264, \"npv\": 0.9999632239341736, \"accuracy\": 0.7707623839378357, \"f1\": 0.33289185471957616, \"f2\": 0.5549799578775733, \"f0_5\": 0.23775048386862058, \"p4\": 0.48023744092524845, \"phi\": 0.38862475203346974}, {\"truth_threshold\": -17.944861941443975, \"match_probability\": 3.9632965235543195e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 81581.0, \"fp\": 26138.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7573501467704773, \"fp_rate\": 0.2426498532295227, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2000122368335724, \"recall\": 0.999541163444519, \"specificity\": 0.7573501467704773, \"npv\": 0.9999632239341736, \"accuracy\": 0.7712087631225586, \"f1\": 0.33332483231746196, \"f2\": 0.5554611134721632, \"f0_5\": 0.23810391313852655, \"p4\": 0.48073554321032186, \"phi\": 0.38904971899586754}, {\"truth_threshold\": -17.93331355772229, \"match_probability\": 3.995148828333667e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 81593.0, \"fp\": 26126.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7574615478515625, \"fp_rate\": 0.2425384521484375, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20008572936058044, \"recall\": 0.999541163444519, \"specificity\": 0.7574615478515625, \"npv\": 0.9999632239341736, \"accuracy\": 0.7713137865066528, \"f1\": 0.33342687313451874, \"f2\": 0.5555744478261608, \"f0_5\": 0.23818722572932308, \"p4\": 0.48085288527325215, \"phi\": 0.3891498419947228}, {\"truth_threshold\": -17.93310010435603, \"match_probability\": 3.995739970344654e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82038.0, \"fp\": 25681.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7615926861763, \"fp_rate\": 0.23840734362602234, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20284952223300934, \"recall\": 0.999541163444519, \"specificity\": 0.7615926861763, \"npv\": 0.9999634623527527, \"accuracy\": 0.7752085328102112, \"f1\": 0.33725550910873714, \"f2\": 0.5598101699561403, \"f0_5\": 0.241318444336125, \"p4\": 0.48524277777273384, \"phi\": 0.3928966627542944}, {\"truth_threshold\": -17.929118846411285, \"match_probability\": 4.00678178955539e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82070.0, \"fp\": 25649.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7618897557258606, \"fp_rate\": 0.2381102740764618, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20305120944976807, \"recall\": 0.999541163444519, \"specificity\": 0.7618897557258606, \"npv\": 0.9999634623527527, \"accuracy\": 0.7754886150360107, \"f1\": 0.3375342182738495, \"f2\": 0.5601172517827756, \"f0_5\": 0.24154678652216982, \"p4\": 0.4855613702293225, \"phi\": 0.39316869252501985}, {\"truth_threshold\": -17.92857998163684, \"match_probability\": 4.0082786465670226e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82086.0, \"fp\": 25633.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7620382905006409, \"fp_rate\": 0.23796173930168152, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20315219461917877, \"recall\": 0.999541163444519, \"specificity\": 0.7620382905006409, \"npv\": 0.9999634623527527, \"accuracy\": 0.7756286263465881, \"f1\": 0.3376737456725056, \"f2\": 0.5602709190672154, \"f0_5\": 0.24166111973966423, \"p4\": 0.4857208145621718, \"phi\": 0.39330483967062957}, {\"truth_threshold\": -17.916408706191785, \"match_probability\": 4.0422373381749095e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82328.0, \"fp\": 25391.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7642848491668701, \"fp_rate\": 0.23571515083312988, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20469209551811218, \"recall\": 0.999541163444519, \"specificity\": 0.7642848491668701, \"npv\": 0.9999635815620422, \"accuracy\": 0.7777466773986816, \"f1\": 0.33979825291181365, \"f2\": 0.5626054616205792, \"f0_5\": 0.2434037037588832, \"p4\": 0.48814452079731196, \"phi\": 0.39537488462923653}, {\"truth_threshold\": -17.90612482071414, \"match_probability\": 4.071154224811506e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82423.0, \"fp\": 25296.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7651667594909668, \"fp_rate\": 0.234833225607872, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20530301332473755, \"recall\": 0.999541163444519, \"specificity\": 0.7651667594909668, \"npv\": 0.9999635815620422, \"accuracy\": 0.7785781025886536, \"f1\": 0.34063957882665696, \"f2\": 0.5635272407429764, \"f0_5\": 0.24409466465464433, \"p4\": 0.4891022298580672, \"phi\": 0.3961931255849553}, {\"truth_threshold\": -17.89954715908726, \"match_probability\": 4.089758089879351e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82525.0, \"fp\": 25194.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7661136984825134, \"fp_rate\": 0.23388631641864777, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20596300065517426, \"recall\": 0.999541163444519, \"specificity\": 0.7661136984825134, \"npv\": 0.999963641166687, \"accuracy\": 0.7794708609580994, \"f1\": 0.34154754749523086, \"f2\": 0.5645203089096594, \"f0_5\": 0.24484091896833365, \"p4\": 0.490134467123182, \"phi\": 0.39707521289358777}, {\"truth_threshold\": -17.8993879377167, \"match_probability\": 4.0902094743651835e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82530.0, \"fp\": 25189.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7661601305007935, \"fp_rate\": 0.23383989930152893, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20599545538425446, \"recall\": 0.999541163444519, \"specificity\": 0.7661601305007935, \"npv\": 0.999963641166687, \"accuracy\": 0.7795146107673645, \"f1\": 0.34159218023103866, \"f2\": 0.5645690787200222, \"f0_5\": 0.24487761739886385, \"p4\": 0.49018517285818763, \"phi\": 0.3971185579189893}, {\"truth_threshold\": -17.87235842207911, \"match_probability\": 4.167563365354178e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82546.0, \"fp\": 25173.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7663086652755737, \"fp_rate\": 0.23369136452674866, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20609940588474274, \"recall\": 0.999541163444519, \"specificity\": 0.7663086652755737, \"npv\": 0.999963641166687, \"accuracy\": 0.7796546220779419, \"f1\": 0.34173508340741515, \"f2\": 0.564725198755617, \"f0_5\": 0.24499512634025644, \"p4\": 0.49034749786513926, \"phi\": 0.39725726547879847}, {\"truth_threshold\": -17.872146455824694, \"match_probability\": 4.168175722080549e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82547.0, \"fp\": 25172.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7663179039955139, \"fp_rate\": 0.2336820811033249, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20610590279102325, \"recall\": 0.999541163444519, \"specificity\": 0.7663179039955139, \"npv\": 0.999963641166687, \"accuracy\": 0.7796633839607239, \"f1\": 0.3417440188259903, \"f2\": 0.5647349591247688, \"f0_5\": 0.2450024743937735, \"p4\": 0.49035764655199465, \"phi\": 0.39726597898655197}, {\"truth_threshold\": -17.868969766936313, \"match_probability\": 4.177363755739442e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82615.0, \"fp\": 25104.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7669491767883301, \"fp_rate\": 0.23305080831050873, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20654888451099396, \"recall\": 0.999541163444519, \"specificity\": 0.7669491767883301, \"npv\": 0.9999637007713318, \"accuracy\": 0.7802585363388062, \"f1\": 0.34235272546297507, \"f2\": 0.5653994566628021, \"f0_5\": 0.24550317820487774, \"p4\": 0.4910486900613133, \"phi\": 0.39785660424288427}, {\"truth_threshold\": -17.858190653745442, \"match_probability\": 4.208691735414913e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82642.0, \"fp\": 25077.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7671998143196106, \"fp_rate\": 0.23280015587806702, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20672529935836792, \"recall\": 0.999541163444519, \"specificity\": 0.7671998143196106, \"npv\": 0.9999637007713318, \"accuracy\": 0.7804948687553406, \"f1\": 0.34259501965923983, \"f2\": 0.5656637351983934, \"f0_5\": 0.24570255515618186, \"p4\": 0.49132358591515474, \"phi\": 0.39809157937547757}, {\"truth_threshold\": -17.853169993177985, \"match_probability\": 4.223363674282892e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82760.0, \"fp\": 24959.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7682952880859375, \"fp_rate\": 0.2317047119140625, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20749984681606293, \"recall\": 0.999541163444519, \"specificity\": 0.7682952880859375, \"npv\": 0.9999637603759766, \"accuracy\": 0.7815276384353638, \"f1\": 0.3436579722339083, \"f2\": 0.5668216354994275, \"f0_5\": 0.24657772008995277, \"p4\": 0.4925284055333761, \"phi\": 0.39912167049163255}, {\"truth_threshold\": -17.847079739193124, \"match_probability\": 4.241229969296935e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82770.0, \"fp\": 24949.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7683880925178528, \"fp_rate\": 0.23161187767982483, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20756575465202332, \"recall\": 0.999541163444519, \"specificity\": 0.7683880925178528, \"npv\": 0.9999637603759766, \"accuracy\": 0.781615138053894, \"f1\": 0.34374835621482297, \"f2\": 0.5669199805677008, \"f0_5\": 0.24665217325663905, \"p4\": 0.49263076576512493, \"phi\": 0.3992091697237963}, {\"truth_threshold\": -17.837946737527464, \"match_probability\": 4.268164185673859e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82788.0, \"fp\": 24931.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.768555223941803, \"fp_rate\": 0.23144477605819702, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2076844871044159, \"recall\": 0.999541163444519, \"specificity\": 0.768555223941803, \"npv\": 0.9999637603759766, \"accuracy\": 0.7817726731300354, \"f1\": 0.3439111672455531, \"f2\": 0.5670970877156444, \"f0_5\": 0.2467863023217172, \"p4\": 0.49281511562617586, \"phi\": 0.39936681681071806}, {\"truth_threshold\": -17.828945864941446, \"match_probability\": 4.294876086754061e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 82836.0, \"fp\": 24883.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7690008282661438, \"fp_rate\": 0.2309991717338562, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2080017775297165, \"recall\": 0.999541163444519, \"specificity\": 0.7690008282661438, \"npv\": 0.9999637603759766, \"accuracy\": 0.7821927666664124, \"f1\": 0.3443460849404574, \"f2\": 0.5675699148862254, \"f0_5\": 0.24714469404734893, \"p4\": 0.4933073538873172, \"phi\": 0.39978778714439617}, {\"truth_threshold\": -17.826398353805775, \"match_probability\": 4.3024666467443745e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83091.0, \"fp\": 24628.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7713680863380432, \"fp_rate\": 0.2286318987607956, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.20970381796360016, \"recall\": 0.999541163444519, \"specificity\": 0.7713680863380432, \"npv\": 0.9999638795852661, \"accuracy\": 0.7844246029853821, \"f1\": 0.34667515450518555, \"f2\": 0.5700950885457559, \"f0_5\": 0.24906623980486317, \"p4\": 0.4959380474343216, \"phi\": 0.4020382943776642}, {\"truth_threshold\": -17.823448821598163, \"match_probability\": 4.311271827349202e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83283.0, \"fp\": 24436.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7731505036354065, \"fp_rate\": 0.2268494814634323, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.211003839969635, \"recall\": 0.999541163444519, \"specificity\": 0.7731505036354065, \"npv\": 0.9999639987945557, \"accuracy\": 0.7861050367355347, \"f1\": 0.34844970540403636, \"f2\": 0.5720112739176864, \"f0_5\": 0.25053288555611786, \"p4\": 0.4979363960463482, \"phi\": 0.4037487949408557}, {\"truth_threshold\": -17.810120599619612, \"match_probability\": 4.351285538835132e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83286.0, \"fp\": 24433.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7731783390045166, \"fp_rate\": 0.226821631193161, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21102428436279297, \"recall\": 0.999541163444519, \"specificity\": 0.7731783390045166, \"npv\": 0.9999639987945557, \"accuracy\": 0.7861312627792358, \"f1\": 0.348477576921026, \"f2\": 0.5720413165266106, \"f0_5\": 0.25055593896173606, \"p4\": 0.49796774125481214, \"phi\": 0.4037756096832206}, {\"truth_threshold\": -17.806589147163226, \"match_probability\": 4.361949686714477e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83313.0, \"fp\": 24406.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7734290361404419, \"fp_rate\": 0.2265709787607193, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21120843291282654, \"recall\": 0.999541163444519, \"specificity\": 0.7734290361404419, \"npv\": 0.9999639987945557, \"accuracy\": 0.7863675951957703, \"f1\": 0.3487286213612957, \"f2\": 0.5723118420822167, \"f0_5\": 0.25076361068901476, \"p4\": 0.49825001644763617, \"phi\": 0.40401728611743093}, {\"truth_threshold\": -17.80239443585222, \"match_probability\": 4.374650683616062e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83431.0, \"fp\": 24288.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.774524450302124, \"fp_rate\": 0.22547554969787598, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2120169997215271, \"recall\": 0.999541163444519, \"specificity\": 0.774524450302124, \"npv\": 0.9999640583992004, \"accuracy\": 0.7874003052711487, \"f1\": 0.34983003666925405, \"f2\": 0.5734971478718737, \"f0_5\": 0.25167526765770626, \"p4\": 0.4994872298262114, \"phi\": 0.4050768360358773}, {\"truth_threshold\": -17.801855571077777, \"match_probability\": 4.3762849688063555e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83438.0, \"fp\": 24281.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7745894193649292, \"fp_rate\": 0.2254105657339096, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21206516027450562, \"recall\": 0.999541163444519, \"specificity\": 0.7745894193649292, \"npv\": 0.9999640583992004, \"accuracy\": 0.7874615788459778, \"f1\": 0.3498955935107351, \"f2\": 0.5735676169077377, \"f0_5\": 0.2517295573257731, \"p4\": 0.49956080678610565, \"phi\": 0.40513985216623793}, {\"truth_threshold\": -17.792631955170748, \"match_probability\": 4.4043534804285076e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83498.0, \"fp\": 24221.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7751464247703552, \"fp_rate\": 0.22485356032848358, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2124788612127304, \"recall\": 0.999541163444519, \"specificity\": 0.7751464247703552, \"npv\": 0.9999640583992004, \"accuracy\": 0.7879867553710938, \"f1\": 0.3504585187965893, \"f2\": 0.5741723483517256, \"f0_5\": 0.25219585989719207, \"p4\": 0.5001923101465285, \"phi\": 0.40568078428804366}, {\"truth_threshold\": -17.78968429563272, \"match_probability\": 4.4133614471637564e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83504.0, \"fp\": 24215.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7752021551132202, \"fp_rate\": 0.22479785978794098, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21252033114433289, \"recall\": 0.999541163444519, \"specificity\": 0.7752021551132202, \"npv\": 0.9999640583992004, \"accuracy\": 0.7880392670631409, \"f1\": 0.3505149109633126, \"f2\": 0.5742328916382552, \"f0_5\": 0.25224258518735815, \"p4\": 0.5002555437185334, \"phi\": 0.40573495860412206}, {\"truth_threshold\": -17.784190072301666, \"match_probability\": 4.430200845418345e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83519.0, \"fp\": 24200.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7753413915634155, \"fp_rate\": 0.22465860843658447, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21262404322624207, \"recall\": 0.999541163444519, \"specificity\": 0.7753413915634155, \"npv\": 0.9999640583992004, \"accuracy\": 0.7881705164909363, \"f1\": 0.3506559708099697, \"f2\": 0.5743843057289012, \"f0_5\": 0.2523594741963886, \"p4\": 0.5004136939693222, \"phi\": 0.40587047905873747}, {\"truth_threshold\": -17.77909370399899, \"match_probability\": 4.445878282173156e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83635.0, \"fp\": 24084.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7764182686805725, \"fp_rate\": 0.2235817313194275, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21342957019805908, \"recall\": 0.999541163444519, \"specificity\": 0.7764182686805725, \"npv\": 0.9999641180038452, \"accuracy\": 0.7891857624053955, \"f1\": 0.35175067954894096, \"f2\": 0.5755579433161297, \"f0_5\": 0.2532670872928519, \"p4\": 0.5016399310138395, \"phi\": 0.4069212035321981}, {\"truth_threshold\": -17.772822748528196, \"match_probability\": 4.4652451336514735e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83661.0, \"fp\": 24058.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7766596674919128, \"fp_rate\": 0.22334036231040955, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2136109620332718, \"recall\": 0.999541163444519, \"specificity\": 0.7766596674919128, \"npv\": 0.9999641180038452, \"accuracy\": 0.789413332939148, \"f1\": 0.35199698365247367, \"f2\": 0.575821658295885, \"f0_5\": 0.25347141416492125, \"p4\": 0.5019155592911904, \"phi\": 0.40715742819084766}, {\"truth_threshold\": -17.761997884294164, \"match_probability\": 4.498874725335369e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83662.0, \"fp\": 24057.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.776668906211853, \"fp_rate\": 0.22333107888698578, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2136179357767105, \"recall\": 0.999541163444519, \"specificity\": 0.776668906211853, \"npv\": 0.9999641180038452, \"accuracy\": 0.7894220948219299, \"f1\": 0.35200646377592243, \"f2\": 0.5758318060059213, \"f0_5\": 0.25347927947496623, \"p4\": 0.5019261661148234, \"phi\": 0.4071665117002827}, {\"truth_threshold\": -17.73583646054996, \"match_probability\": 4.581199847491961e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83696.0, \"fp\": 24023.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7769845724105835, \"fp_rate\": 0.2230154424905777, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21385562419891357, \"recall\": 0.999541163444519, \"specificity\": 0.7769845724105835, \"npv\": 0.99996417760849, \"accuracy\": 0.7897196412086487, \"f1\": 0.35232909208540003, \"f2\": 0.5761770410862281, \"f0_5\": 0.2537469907587171, \"p4\": 0.5022870512475197, \"phi\": 0.4074758224286996}, {\"truth_threshold\": -17.73146624318638, \"match_probability\": 4.595098211773713e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83895.0, \"fp\": 23824.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.778831958770752, \"fp_rate\": 0.22116804122924805, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2152574211359024, \"recall\": 0.999541163444519, \"specificity\": 0.778831958770752, \"npv\": 0.9999642372131348, \"accuracy\": 0.7914613485336304, \"f1\": 0.35422934113884597, \"f2\": 0.5782060129886217, \"f0_5\": 0.25532530045165425, \"p4\": 0.5044092014351591, \"phi\": 0.4092954224067152}, {\"truth_threshold\": -17.72035532863406, \"match_probability\": 4.630623817235955e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83911.0, \"fp\": 23808.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7789804935455322, \"fp_rate\": 0.22101950645446777, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21537092328071594, \"recall\": 0.999541163444519, \"specificity\": 0.7789804935455322, \"npv\": 0.9999642372131348, \"accuracy\": 0.7916014194488525, \"f1\": 0.35438301564491204, \"f2\": 0.5783697672360386, \"f0_5\": 0.2554530529278399, \"p4\": 0.504580565656512, \"phi\": 0.40944242889018667}, {\"truth_threshold\": -17.714963366579273, \"match_probability\": 4.647962719350278e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83913.0, \"fp\": 23806.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7789990901947021, \"fp_rate\": 0.22100093960762024, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21538512408733368, \"recall\": 0.999541163444519, \"specificity\": 0.7789990901947021, \"npv\": 0.9999642372131348, \"accuracy\": 0.7916188836097717, \"f1\": 0.3544022343339028, \"f2\": 0.5783902430389606, \"f0_5\": 0.25546903097684165, \"p4\": 0.5046019939535468, \"phi\": 0.4094607939659512}, {\"truth_threshold\": -17.710921136385842, \"match_probability\": 4.661003862821924e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 83978.0, \"fp\": 23741.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7796024680137634, \"fp_rate\": 0.22039751708507538, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21584753692150116, \"recall\": 0.999541163444519, \"specificity\": 0.7796024680137634, \"npv\": 0.9999642968177795, \"accuracy\": 0.7921878099441528, \"f1\": 0.35502797848644535, \"f2\": 0.5790564967746509, \"f0_5\": 0.2559894078751508, \"p4\": 0.5052993551041374, \"phi\": 0.41005900833704834}, {\"truth_threshold\": -17.708602678910204, \"match_probability\": 4.668500233277471e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84115.0, \"fp\": 23604.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7808743119239807, \"fp_rate\": 0.2191256880760193, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21682868897914886, \"recall\": 0.999541163444519, \"specificity\": 0.7808743119239807, \"npv\": 0.9999643564224243, \"accuracy\": 0.7933868169784546, \"f1\": 0.35635411838481884, \"f2\": 0.5804657938213924, \"f0_5\": 0.25709317513021857, \"p4\": 0.506775186020856, \"phi\": 0.4113254734993162}, {\"truth_threshold\": -17.706187560300393, \"match_probability\": 4.67632196366128e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84124.0, \"fp\": 23595.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7809578776359558, \"fp_rate\": 0.21904213726520538, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21689346432685852, \"recall\": 0.999541163444519, \"specificity\": 0.7809578776359558, \"npv\": 0.9999643564224243, \"accuracy\": 0.7934656143188477, \"f1\": 0.3564415839424021, \"f2\": 0.5805586155431577, \"f0_5\": 0.25716601866863953, \"p4\": 0.5068724249470511, \"phi\": 0.41140891659241063}, {\"truth_threshold\": -17.702221454382382, \"match_probability\": 4.689195244166895e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84407.0, \"fp\": 23312.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7835850715637207, \"fp_rate\": 0.2164149284362793, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21894997358322144, \"recall\": 0.999541163444519, \"specificity\": 0.7835850715637207, \"npv\": 0.9999644756317139, \"accuracy\": 0.795942485332489, \"f1\": 0.359213961797444, \"f2\": 0.5834925623671852, \"f0_5\": 0.25947778854247733, \"p4\": 0.5099482304079834, \"phi\": 0.41405026710767123}, {\"truth_threshold\": -17.69967394324671, \"match_probability\": 4.697482701832276e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84464.0, \"fp\": 23255.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7841142416000366, \"fp_rate\": 0.21588577330112457, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.21936891973018646, \"recall\": 0.999541163444519, \"specificity\": 0.7841142416000366, \"npv\": 0.9999644756317139, \"accuracy\": 0.796441376209259, \"f1\": 0.3597775820303898, \"f2\": 0.5840870902005648, \"f0_5\": 0.2599484478671101, \"p4\": 0.5105720340820402, \"phi\": 0.4145862858484466}, {\"truth_threshold\": -17.67715473775081, \"match_probability\": 4.7713811858934415e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84547.0, \"fp\": 23172.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7848847508430481, \"fp_rate\": 0.2151152491569519, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2199818193912506, \"recall\": 0.999541163444519, \"specificity\": 0.7848847508430481, \"npv\": 0.9999645352363586, \"accuracy\": 0.7971677780151367, \"f1\": 0.36060146227065804, \"f2\": 0.5849549759215167, \"f0_5\": 0.2606368552877176, \"p4\": 0.511482977974833, \"phi\": 0.41536923139604304}, {\"truth_threshold\": -17.65748992607386, \"match_probability\": 4.8368629659826205e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84549.0, \"fp\": 23170.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7849032878875732, \"fp_rate\": 0.21509668231010437, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2199966311454773, \"recall\": 0.999541163444519, \"specificity\": 0.7849032878875732, \"npv\": 0.9999645352363586, \"accuracy\": 0.7971853017807007, \"f1\": 0.3606213613663328, \"f2\": 0.5849759206545285, \"f0_5\": 0.26065348840919605, \"p4\": 0.5115049665548169, \"phi\": 0.4153881182030049}, {\"truth_threshold\": -17.657465661742602, \"match_probability\": 4.836944316275793e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84552.0, \"fp\": 23167.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7849311828613281, \"fp_rate\": 0.21506883203983307, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22001884877681732, \"recall\": 0.999541163444519, \"specificity\": 0.7849311828613281, \"npv\": 0.9999645352363586, \"accuracy\": 0.7972115278244019, \"f1\": 0.3606512141280353, \"f2\": 0.5850073405664769, \"f0_5\": 0.26067844207234375, \"p4\": 0.5115379527949553, \"phi\": 0.4154164996946321}, {\"truth_threshold\": -17.643716627549036, \"match_probability\": 4.883261025922838e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84570.0, \"fp\": 23149.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7850982546806335, \"fp_rate\": 0.21490173041820526, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22015227377414703, \"recall\": 0.999541163444519, \"specificity\": 0.7850982546806335, \"npv\": 0.9999645352363586, \"accuracy\": 0.7973690629005432, \"f1\": 0.3608304345425432, \"f2\": 0.5851959309406118, \"f0_5\": 0.260828264444338, \"p4\": 0.5117359552049028, \"phi\": 0.41558672396292873}, {\"truth_threshold\": -17.640007359915554, \"match_probability\": 4.895832316476466e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84573.0, \"fp\": 23146.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7851260900497437, \"fp_rate\": 0.21487388014793396, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22017452120780945, \"recall\": 0.999541163444519, \"specificity\": 0.7851260900497437, \"npv\": 0.9999645352363586, \"accuracy\": 0.7973953485488892, \"f1\": 0.36086032193047846, \"f2\": 0.585227374491788, \"f0_5\": 0.26085325158467854, \"p4\": 0.5117689697752189, \"phi\": 0.4156150838967179}, {\"truth_threshold\": -17.636300786999048, \"match_probability\": 4.9084268018496626e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84581.0, \"fp\": 23138.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7852003574371338, \"fp_rate\": 0.21479961276054382, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22023388743400574, \"recall\": 0.999541163444519, \"specificity\": 0.7852003574371338, \"npv\": 0.9999645352363586, \"accuracy\": 0.7974653840065002, \"f1\": 0.36094004584242356, \"f2\": 0.5853112404836542, \"f0_5\": 0.2609199073704384, \"p4\": 0.5118570284325937, \"phi\": 0.41569077709478647}, {\"truth_threshold\": -17.634683853713806, \"match_probability\": 4.913931089762938e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84696.0, \"fp\": 23023.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7862679958343506, \"fp_rate\": 0.2137320190668106, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22109073400497437, \"recall\": 0.999541163444519, \"specificity\": 0.7862679958343506, \"npv\": 0.9999645948410034, \"accuracy\": 0.7984718680381775, \"f1\": 0.36208998226950356, \"f2\": 0.5865194758571172, \"f0_5\": 0.2618818626272341, \"p4\": 0.513126063216839, \"phi\": 0.4167820380215738}, {\"truth_threshold\": -17.62372540010842, \"match_probability\": 4.9513983642100076e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 84750.0, \"fp\": 22969.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7867692708969116, \"fp_rate\": 0.21323071420192719, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2214953899383545, \"recall\": 0.999541163444519, \"specificity\": 0.7867692708969116, \"npv\": 0.9999645948410034, \"accuracy\": 0.7989444732666016, \"f1\": 0.36263248432384443, \"f2\": 0.587088543912606, \"f0_5\": 0.26233601490116737, \"p4\": 0.5137240246244332, \"phi\": 0.4172964256981482}, {\"truth_threshold\": -17.6091120499909, \"match_probability\": 5.001806696814806e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85095.0, \"fp\": 22624.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7899720668792725, \"fp_rate\": 0.21002794802188873, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22411605715751648, \"recall\": 0.999541163444519, \"specificity\": 0.7899720668792725, \"npv\": 0.9999647736549377, \"accuracy\": 0.8019639849662781, \"f1\": 0.3661372104098384, \"f2\": 0.5907504836289346, \"f0_5\": 0.26527513923392926, \"p4\": 0.5175758492753643, \"phi\": 0.4206123620991993}, {\"truth_threshold\": -17.597912937935913, \"match_probability\": 5.0407847810988e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85140.0, \"fp\": 22579.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7903898358345032, \"fp_rate\": 0.2096101939678192, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22446246445178986, \"recall\": 0.999541163444519, \"specificity\": 0.7903898358345032, \"npv\": 0.9999647736549377, \"accuracy\": 0.8023578524589539, \"f1\": 0.3665993492651184, \"f2\": 0.5912314985705497, \"f0_5\": 0.26566336569263543, \"p4\": 0.5180823171065629, \"phi\": 0.4210487131622669}, {\"truth_threshold\": -17.58539025430198, \"match_probability\": 5.084729332174558e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85144.0, \"fp\": 22575.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7904269695281982, \"fp_rate\": 0.20957306027412415, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22449329495429993, \"recall\": 0.999541163444519, \"specificity\": 0.7904269695281982, \"npv\": 0.9999647736549377, \"accuracy\": 0.802392840385437, \"f1\": 0.36664048473967686, \"f2\": 0.5912742933661467, \"f0_5\": 0.2656979297110052, \"p4\": 0.5181273821454105, \"phi\": 0.42108751314895393}, {\"truth_threshold\": -17.58419672582678, \"match_probability\": 5.088937601551926e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85334.0, \"fp\": 22385.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7921907901763916, \"fp_rate\": 0.2078092098236084, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22596818208694458, \"recall\": 0.999541163444519, \"specificity\": 0.7921907901763916, \"npv\": 0.9999648332595825, \"accuracy\": 0.8040557503700256, \"f1\": 0.3686051102713069, \"f2\": 0.5933142068564788, \"f0_5\": 0.2673501448231848, \"p4\": 0.5202766051775995, \"phi\": 0.4229401773306492}, {\"truth_threshold\": -17.579675115995745, \"match_probability\": 5.104911988569499e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85363.0, \"fp\": 22356.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.792460024356842, \"fp_rate\": 0.20753999054431915, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22619500756263733, \"recall\": 0.999541163444519, \"specificity\": 0.792460024356842, \"npv\": 0.9999648332595825, \"accuracy\": 0.804309606552124, \"f1\": 0.368906827739987, \"f2\": 0.5936268008647785, \"f0_5\": 0.2676041342484153, \"p4\": 0.5206061391513381, \"phi\": 0.42322439681300006}, {\"truth_threshold\": -17.57946314974133, \"match_probability\": 5.105662072968717e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85378.0, \"fp\": 22341.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7925992608070374, \"fp_rate\": 0.20740073919296265, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22631250321865082, \"recall\": 0.999541163444519, \"specificity\": 0.7925992608070374, \"npv\": 0.9999648928642273, \"accuracy\": 0.8044408559799194, \"f1\": 0.36906308239679225, \"f2\": 0.5937886167042233, \"f0_5\": 0.2677356975467462, \"p4\": 0.5207767438612465, \"phi\": 0.42337152740364503}, {\"truth_threshold\": -17.577459842829338, \"match_probability\": 5.11275661489509e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85449.0, \"fp\": 22270.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7932583689689636, \"fp_rate\": 0.20674161612987518, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2268703281879425, \"recall\": 0.999541163444519, \"specificity\": 0.7932583689689636, \"npv\": 0.9999648928642273, \"accuracy\": 0.8050622940063477, \"f1\": 0.36980448745154626, \"f2\": 0.5945557435813454, \"f0_5\": 0.26836018988485355, \"p4\": 0.5215857205591976, \"phi\": 0.4240694028583564}, {\"truth_threshold\": -17.552544518665215, \"match_probability\": 5.201820244553765e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85485.0, \"fp\": 22234.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7935925722122192, \"fp_rate\": 0.20640741288661957, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2271542251110077, \"recall\": 0.999541163444519, \"specificity\": 0.7935925722122192, \"npv\": 0.9999648928642273, \"accuracy\": 0.8053773641586304, \"f1\": 0.3701815504007704, \"f2\": 0.5949454671255076, \"f0_5\": 0.26867794826253555, \"p4\": 0.521996821623218, \"phi\": 0.4244241512193883}, {\"truth_threshold\": -17.540933966804225, \"match_probability\": 5.243852250904184e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85489.0, \"fp\": 22230.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7936297059059143, \"fp_rate\": 0.2063702791929245, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.22718581557273865, \"recall\": 0.999541163444519, \"specificity\": 0.7936297059059143, \"npv\": 0.9999648928642273, \"accuracy\": 0.8054123520851135, \"f1\": 0.3702234937540719, \"f2\": 0.5949888012819345, \"f0_5\": 0.26871330120561193, \"p4\": 0.5220425376446831, \"phi\": 0.42446357176533056}, {\"truth_threshold\": -17.53626255885808, \"match_probability\": 5.2608591339350505e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85525.0, \"fp\": 22194.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7939639091491699, \"fp_rate\": 0.20603607594966888, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2274705022573471, \"recall\": 0.999541163444519, \"specificity\": 0.7939639091491699, \"npv\": 0.9999649524688721, \"accuracy\": 0.8057274222373962, \"f1\": 0.37060141208495195, \"f2\": 0.5953790929465571, \"f0_5\": 0.26903189684983614, \"p4\": 0.5224543255253329, \"phi\": 0.4248189775179931}, {\"truth_threshold\": -17.530765515514798, \"match_probability\": 5.28094250683925e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85974.0, \"fp\": 21745.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7981321811676025, \"fp_rate\": 0.20186781883239746, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2310820370912552, \"recall\": 0.999541163444519, \"specificity\": 0.7981321811676025, \"npv\": 0.9999651312828064, \"accuracy\": 0.8096571564674377, \"f1\": 0.37538055029007983, \"f2\": 0.6002902704291593, \"f0_5\": 0.27306991592705876, \"p4\": 0.5276427591777667, \"phi\": 0.4293019193079125}, {\"truth_threshold\": -17.529385583082536, \"match_probability\": 5.285996098459255e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 85979.0, \"fp\": 21740.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7981786131858826, \"fp_rate\": 0.20182140171527863, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23112289607524872, \"recall\": 0.999541163444519, \"specificity\": 0.7981786131858826, \"npv\": 0.9999651312828064, \"accuracy\": 0.8097009658813477, \"f1\": 0.37543446413696036, \"f2\": 0.6003454167968104, \"f0_5\": 0.2731155652886207, \"p4\": 0.5277010901450031, \"phi\": 0.4293523852607288}, {\"truth_threshold\": -17.509576376439984, \"match_probability\": 5.359076689082613e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86175.0, \"fp\": 21544.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.7999981641769409, \"fp_rate\": 0.20000185072422028, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23273621499538422, \"recall\": 0.999541163444519, \"specificity\": 0.7999981641769409, \"npv\": 0.9999651908874512, \"accuracy\": 0.8114163875579834, \"f1\": 0.3775601583037236, \"f2\": 0.6025151666021279, \"f0_5\": 0.27491712521244555, \"p4\": 0.5299974022389016, \"phi\": 0.43133969157527136}, {\"truth_threshold\": -17.506740829052088, \"match_probability\": 5.369619996578151e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86214.0, \"fp\": 21505.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8003602027893066, \"fp_rate\": 0.19963979721069336, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23305991291999817, \"recall\": 0.999541163444519, \"specificity\": 0.8003602027893066, \"npv\": 0.9999651908874512, \"accuracy\": 0.8117576837539673, \"f1\": 0.3779860026606513, \"f2\": 0.602948774726897, \"f0_5\": 0.275278437715884, \"p4\": 0.5304565987577242, \"phi\": 0.4317373289340789}, {\"truth_threshold\": -17.50345926138556, \"match_probability\": 5.381847620096039e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86226.0, \"fp\": 21493.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8004716038703918, \"fp_rate\": 0.19952839612960815, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23315969109535217, \"recall\": 0.999541163444519, \"specificity\": 0.8004716038703918, \"npv\": 0.9999651908874512, \"accuracy\": 0.8118627071380615, \"f1\": 0.3781172250188046, \"f2\": 0.6030823181985973, \"f0_5\": 0.2753898019384745, \"p4\": 0.5305980428769412, \"phi\": 0.43185978618686105}, {\"truth_threshold\": -17.499948649087383, \"match_probability\": 5.3949595280560005e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86237.0, \"fp\": 21482.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8005737066268921, \"fp_rate\": 0.19942627847194672, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23325124382972717, \"recall\": 0.999541163444519, \"specificity\": 0.8005737066268921, \"npv\": 0.9999651908874512, \"accuracy\": 0.8119590282440186, \"f1\": 0.3782375922442483, \"f2\": 0.6032047850246451, \"f0_5\": 0.2754919649933393, \"p4\": 0.530727763272837, \"phi\": 0.43197215343772716}, {\"truth_threshold\": -17.497000989549356, \"match_probability\": 5.405993512485933e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86247.0, \"fp\": 21472.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8006665706634521, \"fp_rate\": 0.19933344423770905, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2333345264196396, \"recall\": 0.999541163444519, \"specificity\": 0.8006665706634521, \"npv\": 0.9999651908874512, \"accuracy\": 0.8120465278625488, \"f1\": 0.3783470835142568, \"f2\": 0.6033161616721135, \"f0_5\": 0.2755849062969148, \"p4\": 0.5308457434735254, \"phi\": 0.4320743656136617}, {\"truth_threshold\": -17.484509659808413, \"match_probability\": 5.453003352684283e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86312.0, \"fp\": 21407.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8012699484825134, \"fp_rate\": 0.19873002171516418, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23387731611728668, \"recall\": 0.999541163444519, \"specificity\": 0.8012699484825134, \"npv\": 0.999965250492096, \"accuracy\": 0.8126153945922852, \"f1\": 0.37906032482598606, \"f2\": 0.604041113617037, \"f0_5\": 0.2761905566919683, \"p4\": 0.5316138373913342, \"phi\": 0.4327397892988468}, {\"truth_threshold\": -17.47118852737685, \"match_probability\": 5.503586582286317e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86314.0, \"fp\": 21405.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8012885451316833, \"fp_rate\": 0.19871145486831665, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23389406502246857, \"recall\": 0.999541163444519, \"specificity\": 0.8012885451316833, \"npv\": 0.999965250492096, \"accuracy\": 0.8126329183578491, \"f1\": 0.3790823133592436, \"f2\": 0.6040634474598832, \"f0_5\": 0.2762092343065817, \"p4\": 0.5316375047128397, \"phi\": 0.43276028159610547}, {\"truth_threshold\": -17.459435114273735, \"match_probability\": 5.54860633666716e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86315.0, \"fp\": 21404.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8012978434562683, \"fp_rate\": 0.19870217144489288, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23390242457389832, \"recall\": 0.999541163444519, \"specificity\": 0.8012978434562683, \"npv\": 0.999965250492096, \"accuracy\": 0.8126416802406311, \"f1\": 0.37909330858253326, \"f2\": 0.6040746150006471, \"f0_5\": 0.27621857406123723, \"p4\": 0.5316493391283454, \"phi\": 0.432770528481004}, {\"truth_threshold\": -17.458665843742917, \"match_probability\": 5.5515657242774246e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86332.0, \"fp\": 21387.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8014556169509888, \"fp_rate\": 0.19854436814785004, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23404483497142792, \"recall\": 0.999541163444519, \"specificity\": 0.8014556169509888, \"npv\": 0.999965250492096, \"accuracy\": 0.8127904534339905, \"f1\": 0.3792803250145096, \"f2\": 0.6042645263897621, \"f0_5\": 0.27637744658535346, \"p4\": 0.5318506012102664, \"phi\": 0.43294494802388106}, {\"truth_threshold\": -17.447886730552046, \"match_probability\": 5.593199421401496e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86392.0, \"fp\": 21327.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8020126223564148, \"fp_rate\": 0.197987362742424, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23454885184764862, \"recall\": 0.999541163444519, \"specificity\": 0.8020126223564148, \"npv\": 0.999965250492096, \"accuracy\": 0.8133155703544617, \"f1\": 0.3799418604651163, \"f2\": 0.6049357573962306, \"f0_5\": 0.2769396369060736, \"p4\": 0.5325621027723767, \"phi\": 0.43356160600299815}, {\"truth_threshold\": -17.44635481782574, \"match_probability\": 5.599141630824824e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 86704.0, \"fp\": 21015.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8049090504646301, \"fp_rate\": 0.19509093463420868, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.23720508813858032, \"recall\": 0.999541163444519, \"specificity\": 0.8049090504646301, \"npv\": 0.9999654293060303, \"accuracy\": 0.8160462975502014, \"f1\": 0.38341938512086365, \"f2\": 0.6084503370451753, \"f0_5\": 0.2799002895372544, \"p4\": 0.536291422907953, \"phi\": 0.43679725007834996}, {\"truth_threshold\": -17.443153154466597, \"match_probability\": 5.6115811080815475e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87302.0, \"fp\": 20417.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8104605674743652, \"fp_rate\": 0.18953944742679596, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24246808886528015, \"recall\": 0.999541163444519, \"specificity\": 0.8104605674743652, \"npv\": 0.9999656081199646, \"accuracy\": 0.8212801218032837, \"f1\": 0.3902657509704389, \"f2\": 0.6153020488098825, \"f0_5\": 0.2857555139663827, \"p4\": 0.5435806404525424, \"phi\": 0.4431385207145411}, {\"truth_threshold\": -17.42489944510789, \"match_probability\": 5.683032340247551e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87492.0, \"fp\": 20227.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8122243881225586, \"fp_rate\": 0.1877755969762802, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24418951570987701, \"recall\": 0.999541163444519, \"specificity\": 0.8122243881225586, \"npv\": 0.9999657273292542, \"accuracy\": 0.8229430317878723, \"f1\": 0.3924924924924925, \"f2\": 0.61751143364705, \"f0_5\": 0.2876674942334443, \"p4\": 0.5459364578703604, \"phi\": 0.4451929845639739}, {\"truth_threshold\": -17.4139083656626, \"match_probability\": 5.726493250812446e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87495.0, \"fp\": 20224.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8122522234916687, \"fp_rate\": 0.1877477467060089, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2442169040441513, \"recall\": 0.999541163444519, \"specificity\": 0.8122522234916687, \"npv\": 0.9999657273292542, \"accuracy\": 0.8229692578315735, \"f1\": 0.39252785536234497, \"f2\": 0.6175464459186181, \"f0_5\": 0.2876978886012644, \"p4\": 0.5459738117973086, \"phi\": 0.44522560786956583}, {\"truth_threshold\": -17.410525513792788, \"match_probability\": 5.739936491426443e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87728.0, \"fp\": 19991.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8144152760505676, \"fp_rate\": 0.18558470904827118, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24636206030845642, \"recall\": 0.999541163444519, \"specificity\": 0.8144152760505676, \"npv\": 0.9999657869338989, \"accuracy\": 0.8250085115432739, \"f1\": 0.39529397532059035, \"f2\": 0.6202779148790767, \"f0_5\": 0.2900783011665276, \"p4\": 0.5488900013690166, \"phi\": 0.4477724210170359}, {\"truth_threshold\": -17.409538148299017, \"match_probability\": 5.743866166309851e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87738.0, \"fp\": 19981.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8145081400871277, \"fp_rate\": 0.1854918748140335, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24645496904850006, \"recall\": 0.999541163444519, \"specificity\": 0.8145081400871277, \"npv\": 0.9999657869338989, \"accuracy\": 0.825096070766449, \"f1\": 0.39541356568040176, \"f2\": 0.6203956861851598, \"f0_5\": 0.2901813466901121, \"p4\": 0.549015827784919, \"phi\": 0.4478824235473455}, {\"truth_threshold\": -17.402661172523473, \"match_probability\": 5.7713109783275704e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87815.0, \"fp\": 19904.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8152229189872742, \"fp_rate\": 0.18477706611156464, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2471727430820465, \"recall\": 0.999541163444519, \"specificity\": 0.8152229189872742, \"npv\": 0.9999658465385437, \"accuracy\": 0.8257699608802795, \"f1\": 0.3963368408284562, \"f2\": 0.6213040254035862, \"f0_5\": 0.29097725613122694, \"p4\": 0.5499865461409503, \"phi\": 0.4487311512187608}, {\"truth_threshold\": -17.398604129712506, \"match_probability\": 5.787563389578406e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87840.0, \"fp\": 19879.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8154550194740295, \"fp_rate\": 0.18454498052597046, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24740667641162872, \"recall\": 0.999541163444519, \"specificity\": 0.8154550194740295, \"npv\": 0.9999658465385437, \"accuracy\": 0.82598876953125, \"f1\": 0.3966375333818888, \"f2\": 0.6215995129931895, \"f0_5\": 0.2912366080182541, \"p4\": 0.5503024223107801, \"phi\": 0.4490074348014537}, {\"truth_threshold\": -17.374973212117546, \"match_probability\": 5.883142044624577e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87844.0, \"fp\": 19875.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8154921531677246, \"fp_rate\": 0.1845078468322754, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24744415283203125, \"recall\": 0.999541163444519, \"specificity\": 0.8154921531677246, \"npv\": 0.9999658465385437, \"accuracy\": 0.8260238170623779, \"f1\": 0.3966856865363603, \"f2\": 0.6216468170921959, \"f0_5\": 0.2912781472302947, \"p4\": 0.550352994775921, \"phi\": 0.44905164087701877}, {\"truth_threshold\": -17.37322423852832, \"match_probability\": 5.890278437679722e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87846.0, \"fp\": 19873.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8155107498168945, \"fp_rate\": 0.18448927998542786, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24746288359165192, \"recall\": 0.999541163444519, \"specificity\": 0.8155107498168945, \"npv\": 0.9999658465385437, \"accuracy\": 0.8260412812232971, \"f1\": 0.3967097674983306, \"f2\": 0.6216704718417048, \"f0_5\": 0.2912989212801997, \"p4\": 0.5503782843499181, \"phi\": 0.44907379737408676}, {\"truth_threshold\": -17.359899440722817, \"match_probability\": 5.944933004565332e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87847.0, \"fp\": 19872.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8155199885368347, \"fp_rate\": 0.1844799965620041, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24747225642204285, \"recall\": 0.999541163444519, \"specificity\": 0.8155199885368347, \"npv\": 0.9999658465385437, \"accuracy\": 0.8260500431060791, \"f1\": 0.3967218090757323, \"f2\": 0.6216822998915504, \"f0_5\": 0.2913093094164007, \"p4\": 0.5503909299724048, \"phi\": 0.4490848514359993}, {\"truth_threshold\": -17.34415634569013, \"match_probability\": 6.01016064363197e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87853.0, \"fp\": 19866.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8155757188796997, \"fp_rate\": 0.1844242960214615, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.24752850830554962, \"recall\": 0.999541163444519, \"specificity\": 0.8155757188796997, \"npv\": 0.9999658465385437, \"accuracy\": 0.8261025547981262, \"f1\": 0.396794073894168, \"f2\": 0.6217532776435217, \"f0_5\": 0.29137165379608, \"p4\": 0.5504668154065238, \"phi\": 0.4491512377512868}, {\"truth_threshold\": -17.343617480915682, \"match_probability\": 6.012405920151409e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 87856.0, \"fp\": 19863.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8156035542488098, \"fp_rate\": 0.18439644575119019, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2475566267967224, \"recall\": 0.999541163444519, \"specificity\": 0.8156035542488098, \"npv\": 0.9999658465385437, \"accuracy\": 0.8261288404464722, \"f1\": 0.3968302161768278, \"f2\": 0.6217887725975262, \"f0_5\": 0.2914028359939356, \"p4\": 0.5505047656461879, \"phi\": 0.44918441350649946}, {\"truth_threshold\": -17.34011975047324, \"match_probability\": 6.0270002460981486e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 88422.0, \"fp\": 19297.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8208580017089844, \"fp_rate\": 0.179142028093338, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2529807984828949, \"recall\": 0.999541163444519, \"specificity\": 0.8208580017089844, \"npv\": 0.9999660849571228, \"accuracy\": 0.8310825824737549, \"f1\": 0.403768921841211, \"f2\": 0.6285587873191751, \"f0_5\": 0.2974077512606266, \"p4\": 0.5577556145598658, \"phi\": 0.4555407867481419}, {\"truth_threshold\": -17.321162319992983, \"match_probability\": 6.106718906520028e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 88434.0, \"fp\": 19285.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8209694027900696, \"fp_rate\": 0.1790306270122528, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.25309836864471436, \"recall\": 0.999541163444519, \"specificity\": 0.8209694027900696, \"npv\": 0.9999660849571228, \"accuracy\": 0.8311876058578491, \"f1\": 0.4039186599913468, \"f2\": 0.6287039174940352, \"f0_5\": 0.2975377442677885, \"p4\": 0.5579113264766347, \"phi\": 0.4556775410779074}, {\"truth_threshold\": -17.316428743907533, \"match_probability\": 6.126788231300409e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 88497.0, \"fp\": 19222.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8215542435646057, \"fp_rate\": 0.17844577133655548, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.25371742248535156, \"recall\": 0.999541163444519, \"specificity\": 0.8215542435646057, \"npv\": 0.9999660849571228, \"accuracy\": 0.8317389488220215, \"f1\": 0.4047066109304846, \"f2\": 0.6294669517810013, \"f0_5\": 0.29822207619151925, \"p4\": 0.5587301851219164, \"phi\": 0.45639715593376695}, {\"truth_threshold\": -17.30743202082868, \"match_probability\": 6.165114350986573e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 88531.0, \"fp\": 19188.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8218698501586914, \"fp_rate\": 0.1781301349401474, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2540527880191803, \"recall\": 0.999541163444519, \"specificity\": 0.8218698501586914, \"npv\": 0.9999660849571228, \"accuracy\": 0.832036554813385, \"f1\": 0.4051331328849075, \"f2\": 0.6298795180722891, \"f0_5\": 0.29859270766700174, \"p4\": 0.5591730682159491, \"phi\": 0.4567865410789623}, {\"truth_threshold\": -17.295883637106996, \"match_probability\": 6.2146621615744605e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 88569.0, \"fp\": 19150.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8222226500511169, \"fp_rate\": 0.17777736485004425, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2544286549091339, \"recall\": 0.999541163444519, \"specificity\": 0.8222226500511169, \"npv\": 0.9999661445617676, \"accuracy\": 0.8323691487312317, \"f1\": 0.4056108990472644, \"f2\": 0.6303412620329109, \"f0_5\": 0.2990080345540731, \"p4\": 0.5596688535529153, \"phi\": 0.4572225263768343}, {\"truth_threshold\": -17.288377483578742, \"match_probability\": 6.247080294171469e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 88902.0, \"fp\": 18817.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8253139853477478, \"fp_rate\": 0.1746859848499298, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2577705979347229, \"recall\": 0.999541163444519, \"specificity\": 0.8253139853477478, \"npv\": 0.9999662637710571, \"accuracy\": 0.835283637046814, \"f1\": 0.40984634681718407, \"f2\": 0.6344167443305374, \"f0_5\": 0.3026976451188557, \"p4\": 0.5640498837843759, \"phi\": 0.4610808873335411}, {\"truth_threshold\": -17.287572817323763, \"match_probability\": 6.25056556670112e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89045.0, \"fp\": 18674.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8266415596008301, \"fp_rate\": 0.17335845530033112, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2592328190803528, \"recall\": 0.999541163444519, \"specificity\": 0.8266415596008301, \"npv\": 0.9999663233757019, \"accuracy\": 0.8365351557731628, \"f1\": 0.4116924433804769, \"f2\": 0.6361830961235179, \"f0_5\": 0.3043101681971427, \"p4\": 0.5659515118319028, \"phi\": 0.4627589329851238}, {\"truth_threshold\": -17.287183955103536, \"match_probability\": 6.252250552881349e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89052.0, \"fp\": 18667.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8267065286636353, \"fp_rate\": 0.17329347133636475, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.25930482149124146, \"recall\": 0.999541163444519, \"specificity\": 0.8267065286636353, \"npv\": 0.9999663233757019, \"accuracy\": 0.8365964293479919, \"f1\": 0.41178323881537493, \"f2\": 0.6362698134517272, \"f0_5\": 0.30438954409107, \"p4\": 0.5660449149150815, \"phi\": 0.46284140289977405}, {\"truth_threshold\": -17.271879719153443, \"match_probability\": 6.318927590511683e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89123.0, \"fp\": 18596.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8273656368255615, \"fp_rate\": 0.17263434827327728, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2600373923778534, \"recall\": 0.999541163444519, \"specificity\": 0.8273656368255615, \"npv\": 0.9999663233757019, \"accuracy\": 0.8372178673744202, \"f1\": 0.4127064321576305, \"f2\": 0.6371507127118148, \"f0_5\": 0.305196988660776, \"p4\": 0.566993966330021, \"phi\": 0.4636796895385723}, {\"truth_threshold\": -17.25894054958359, \"match_probability\": 6.375855006342596e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89129.0, \"fp\": 18590.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8274213671684265, \"fp_rate\": 0.17257864773273468, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26009950041770935, \"recall\": 0.999541163444519, \"specificity\": 0.8274213671684265, \"npv\": 0.9999663233757019, \"accuracy\": 0.8372703790664673, \"f1\": 0.4127846382212677, \"f2\": 0.6372252666887689, \"f0_5\": 0.3052654197574693, \"p4\": 0.5670743080549995, \"phi\": 0.4637506816897422}, {\"truth_threshold\": -17.252984236806306, \"match_probability\": 6.402232615620817e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89132.0, \"fp\": 18587.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8274492025375366, \"fp_rate\": 0.17255079746246338, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26013055443763733, \"recall\": 0.999541163444519, \"specificity\": 0.8274492025375366, \"npv\": 0.9999663233757019, \"accuracy\": 0.8372966051101685, \"f1\": 0.41282375236891977, \"f2\": 0.6372625502203846, \"f0_5\": 0.30529964681479266, \"p4\": 0.5671144871259712, \"phi\": 0.4637862118866514}, {\"truth_threshold\": -17.23670227699917, \"match_probability\": 6.474895688647577e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89135.0, \"fp\": 18584.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8274770379066467, \"fp_rate\": 0.17252294719219208, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2601616382598877, \"recall\": 0.999541163444519, \"specificity\": 0.8274770379066467, \"npv\": 0.9999663233757019, \"accuracy\": 0.8373228907585144, \"f1\": 0.4128628739299365, \"f2\": 0.6372998381151138, \"f0_5\": 0.3053338815482086, \"p4\": 0.567154671670783, \"phi\": 0.4638216968819258}, {\"truth_threshold\": -17.228679128270194, \"match_probability\": 6.511004102919585e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89447.0, \"fp\": 18272.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8303734660148621, \"fp_rate\": 0.16962653398513794, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26343369483947754, \"recall\": 0.999541163444519, \"specificity\": 0.8303734660148621, \"npv\": 0.9999664425849915, \"accuracy\": 0.8400535583496094, \"f1\": 0.41697240389216783, \"f2\": 0.6412017504268137, \"f0_5\": 0.3089367093394853, \"p4\": 0.5713639728217352, \"phi\": 0.46754642770061405}, {\"truth_threshold\": -17.21689307035662, \"match_probability\": 6.564413089338376e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89455.0, \"fp\": 18264.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8304477334022522, \"fp_rate\": 0.1695522665977478, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26351869106292725, \"recall\": 0.999541163444519, \"specificity\": 0.8304477334022522, \"npv\": 0.9999664425849915, \"accuracy\": 0.8401235938072205, \"f1\": 0.4170788524747104, \"f2\": 0.6413024278228101, \"f0_5\": 0.30903020788015206, \"p4\": 0.5714726937870223, \"phi\": 0.46764275761313473}, {\"truth_threshold\": -17.19640070843994, \"match_probability\": 6.658320215121055e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89568.0, \"fp\": 18151.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8314967751502991, \"fp_rate\": 0.16850323975086212, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2647249400615692, \"recall\": 0.999541163444519, \"specificity\": 0.8314967751502991, \"npv\": 0.9999665021896362, \"accuracy\": 0.8411125540733337, \"f1\": 0.41858826543684347, \"f2\": 0.6427278807191471, \"f0_5\": 0.31035694610664694, \"p4\": 0.5730126403823168, \"phi\": 0.46900815217832104}, {\"truth_threshold\": -17.191826353725048, \"match_probability\": 6.679465121535061e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89581.0, \"fp\": 18138.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8316174745559692, \"fp_rate\": 0.16838255524635315, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26486441493034363, \"recall\": 0.999541163444519, \"specificity\": 0.8316174745559692, \"npv\": 0.9999665021896362, \"accuracy\": 0.84122633934021, \"f1\": 0.41876261574444906, \"f2\": 0.6428922774225283, \"f0_5\": 0.3105103107478856, \"p4\": 0.5731903146730061, \"phi\": 0.4691657752116549}, {\"truth_threshold\": -17.179655078279993, \"match_probability\": 6.736054322321337e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89586.0, \"fp\": 18133.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8316638469696045, \"fp_rate\": 0.16833613812923431, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26491811871528625, \"recall\": 0.999541163444519, \"specificity\": 0.8316638469696045, \"npv\": 0.9999665021896362, \"accuracy\": 0.8412701487541199, \"f1\": 0.4188297122348266, \"f2\": 0.6429555293191657, \"f0_5\": 0.3105693375154453, \"p4\": 0.5732586791727486, \"phi\": 0.46922639011869277}, {\"truth_threshold\": -17.178826967327737, \"match_probability\": 6.7399219200126915e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89587.0, \"fp\": 18132.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8316731452941895, \"fp_rate\": 0.16832685470581055, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2649288475513458, \"recall\": 0.999541163444519, \"specificity\": 0.8316731452941895, \"npv\": 0.9999665021896362, \"accuracy\": 0.8412788510322571, \"f1\": 0.4188431341131229, \"f2\": 0.6429681811920739, \"f0_5\": 0.3105811455620402, \"p4\": 0.5732723539558053, \"phi\": 0.46923856640973544}, {\"truth_threshold\": -17.169159226547933, \"match_probability\": 6.785238625517252e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89597.0, \"fp\": 18122.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8317660093307495, \"fp_rate\": 0.16823402047157288, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26503628492355347, \"recall\": 0.999541163444519, \"specificity\": 0.8317660093307495, \"npv\": 0.9999665021896362, \"accuracy\": 0.8413664102554321, \"f1\": 0.41897740022439495, \"f2\": 0.6430947273120904, \"f0_5\": 0.310699275431223, \"p4\": 0.5734091363229268, \"phi\": 0.46935990447883236}, {\"truth_threshold\": -17.167278583606052, \"match_probability\": 6.7940893145098485e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89699.0, \"fp\": 18020.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8327128887176514, \"fp_rate\": 0.16728711128234863, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2661372423171997, \"recall\": 0.999541163444519, \"specificity\": 0.8327128887176514, \"npv\": 0.999966561794281, \"accuracy\": 0.8422591090202332, \"f1\": 0.4203518476827582, \"f2\": 0.6443883487486934, \"f0_5\": 0.3119093529849749, \"p4\": 0.5748079127369908, \"phi\": 0.47060169334397023}, {\"truth_threshold\": -17.162422343550492, \"match_probability\": 6.816997201977616e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89707.0, \"fp\": 18012.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8327871561050415, \"fp_rate\": 0.1672128438949585, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2662239670753479, \"recall\": 0.999541163444519, \"specificity\": 0.8327871561050415, \"npv\": 0.999966561794281, \"accuracy\": 0.8423291444778442, \"f1\": 0.42046002895287116, \"f2\": 0.6444900293891398, \"f0_5\": 0.3120046597788515, \"p4\": 0.5749178984931822, \"phi\": 0.4706993726811423}, {\"truth_threshold\": -17.16165307301968, \"match_probability\": 6.8206330900244665e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89711.0, \"fp\": 18008.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8328242897987366, \"fp_rate\": 0.16717571020126343, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2662673592567444, \"recall\": 0.999541163444519, \"specificity\": 0.8328242897987366, \"npv\": 0.999966561794281, \"accuracy\": 0.8423641324043274, \"f1\": 0.4205141404716708, \"f2\": 0.6445408817437617, \"f0_5\": 0.3120523350205329, \"p4\": 0.5749729065645838, \"phi\": 0.4707482543210265}, {\"truth_threshold\": -17.150873959828807, \"match_probability\": 6.871784030729955e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89730.0, \"fp\": 17989.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.833000659942627, \"fp_rate\": 0.16699932515621185, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.266473650932312, \"recall\": 0.999541163444519, \"specificity\": 0.833000659942627, \"npv\": 0.999966561794281, \"accuracy\": 0.8425304293632507, \"f1\": 0.42077136050479685, \"f2\": 0.6447825400584103, \"f0_5\": 0.3122789915323891, \"p4\": 0.5752343333266103, \"phi\": 0.4709805005029279}, {\"truth_threshold\": -17.13750701938637, \"match_probability\": 6.935748299899723e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89928.0, \"fp\": 17791.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8348388075828552, \"fp_rate\": 0.16516120731830597, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2686426043510437, \"recall\": 0.999541163444519, \"specificity\": 0.8348388075828552, \"npv\": 0.9999666213989258, \"accuracy\": 0.8442633748054504, \"f1\": 0.42347071021254534, \"f2\": 0.6473117001465986, \"f0_5\": 0.31466073457753124, \"p4\": 0.5779723559662919, \"phi\": 0.47341543013752363}, {\"truth_threshold\": -17.135392827912902, \"match_probability\": 6.945919643883472e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89955.0, \"fp\": 17764.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8350894451141357, \"fp_rate\": 0.16491055488586426, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.26894110441207886, \"recall\": 0.999541163444519, \"specificity\": 0.8350894451141357, \"npv\": 0.9999666213989258, \"accuracy\": 0.8444997072219849, \"f1\": 0.42384148912021274, \"f2\": 0.6476581237240094, \"f0_5\": 0.31498833555054273, \"p4\": 0.5783476681181545, \"phi\": 0.47374954910278394}, {\"truth_threshold\": -17.125958635664684, \"match_probability\": 6.99148950055311e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 89956.0, \"fp\": 17763.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8350987434387207, \"fp_rate\": 0.1649012714624405, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2689521908760071, \"recall\": 0.999541163444519, \"specificity\": 0.8350987434387207, \"npv\": 0.9999666810035706, \"accuracy\": 0.8445084095001221, \"f1\": 0.42385523414191206, \"f2\": 0.6476709613478692, \"f0_5\": 0.31500048202063047, \"p4\": 0.5783615775825386, \"phi\": 0.4737619259669228}, {\"truth_threshold\": -17.121225059579235, \"match_probability\": 7.014466544539946e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90206.0, \"fp\": 17513.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8374195694923401, \"fp_rate\": 0.16258041560649872, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2717481851577759, \"recall\": 0.999541163444519, \"specificity\": 0.8374195694923401, \"npv\": 0.9999667406082153, \"accuracy\": 0.8466964960098267, \"f1\": 0.4273196887464853, \"f2\": 0.6508964143426295, \"f0_5\": 0.31806677698822156, \"p4\": 0.5818592784591194, \"phi\": 0.47688016761362073}, {\"truth_threshold\": -17.113512743069546, \"match_probability\": 7.052064413290523e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90641.0, \"fp\": 17078.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8414578437805176, \"fp_rate\": 0.15854212641716003, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27675431966781616, \"recall\": 0.999541163444519, \"specificity\": 0.8414578437805176, \"npv\": 0.9999669194221497, \"accuracy\": 0.85050368309021, \"f1\": 0.43348479320752215, \"f2\": 0.6565859539837235, \"f0_5\": 0.32354688583028024, \"p4\": 0.5880434253765242, \"phi\": 0.4824129636261588}, {\"truth_threshold\": -17.109977866440108, \"match_probability\": 7.069364372654553e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90667.0, \"fp\": 17052.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8416992425918579, \"fp_rate\": 0.1583007574081421, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.277059406042099, \"recall\": 0.999541163444519, \"specificity\": 0.8416992425918579, \"npv\": 0.9999669194221497, \"accuracy\": 0.8507312536239624, \"f1\": 0.43385892116182573, \"f2\": 0.6569291702688032, \"f0_5\": 0.32388041948337726, \"p4\": 0.5884170677341528, \"phi\": 0.4827480696304211}, {\"truth_threshold\": -17.103148246186336, \"match_probability\": 7.102909362542087e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90698.0, \"fp\": 17021.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8419870138168335, \"fp_rate\": 0.1580129712820053, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27742400765419006, \"recall\": 0.999541163444519, \"specificity\": 0.8419870138168335, \"npv\": 0.9999669194221497, \"accuracy\": 0.85100257396698, \"f1\": 0.43430584169601916, \"f2\": 0.6573388589361874, \"f0_5\": 0.324278994065223, \"p4\": 0.5888631632965304, \"phi\": 0.4831482930483475}, {\"truth_threshold\": -17.092192237029654, \"match_probability\": 7.15705470432209e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90714.0, \"fp\": 17005.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8421355485916138, \"fp_rate\": 0.15786443650722504, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.277612566947937, \"recall\": 0.999541163444519, \"specificity\": 0.8421355485916138, \"npv\": 0.9999669194221497, \"accuracy\": 0.8511425852775574, \"f1\": 0.43453687080257997, \"f2\": 0.6575505111486758, \"f0_5\": 0.32448509404357584, \"p4\": 0.589093661495549, \"phi\": 0.4833551642842253}, {\"truth_threshold\": -17.076106474722227, \"match_probability\": 7.2373003913695355e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90726.0, \"fp\": 16993.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.842246949672699, \"fp_rate\": 0.15775303542613983, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27775415778160095, \"recall\": 0.999541163444519, \"specificity\": 0.842246949672699, \"npv\": 0.9999669194221497, \"accuracy\": 0.8512476086616516, \"f1\": 0.43471030399787136, \"f2\": 0.6577093397745571, \"f0_5\": 0.32463984103328364, \"p4\": 0.5892666493889684, \"phi\": 0.4835104311218011}, {\"truth_threshold\": -17.07308534605816, \"match_probability\": 7.252471696255265e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90782.0, \"fp\": 16937.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8427668213844299, \"fp_rate\": 0.15723317861557007, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27841684222221375, \"recall\": 0.999541163444519, \"specificity\": 0.8427668213844299, \"npv\": 0.9999669790267944, \"accuracy\": 0.8517377376556396, \"f1\": 0.43552149283572145, \"f2\": 0.6584515556988554, \"f0_5\": 0.3253639495748113, \"p4\": 0.5900752236031455, \"phi\": 0.48423637744153875}, {\"truth_threshold\": -17.06288666999958, \"match_probability\": 7.30392201706059e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90801.0, \"fp\": 16918.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8429431915283203, \"fp_rate\": 0.1570567935705185, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2786423861980438, \"recall\": 0.999541163444519, \"specificity\": 0.8429431915283203, \"npv\": 0.9999669790267944, \"accuracy\": 0.851904034614563, \"f1\": 0.4357974058884332, \"f2\": 0.658703759701643, \"f0_5\": 0.3256103637269557, \"p4\": 0.590350047792191, \"phi\": 0.4844832351087974}, {\"truth_threshold\": -17.0360340503278, \"match_probability\": 7.441140624865642e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90809.0, \"fp\": 16910.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8430174589157104, \"fp_rate\": 0.15698252618312836, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27873748540878296, \"recall\": 0.999541163444519, \"specificity\": 0.8430174589157104, \"npv\": 0.9999669790267944, \"accuracy\": 0.8519740700721741, \"f1\": 0.435913684421172, \"f2\": 0.6588100086698793, \"f0_5\": 0.32571422875256684, \"p4\": 0.5904658371318068, \"phi\": 0.48458729571343484}, {\"truth_threshold\": -17.024149549269744, \"match_probability\": 7.502691281716469e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90822.0, \"fp\": 16897.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8431381583213806, \"fp_rate\": 0.15686184167861938, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2788920998573303, \"recall\": 0.999541163444519, \"specificity\": 0.8431381583213806, \"npv\": 0.9999669790267944, \"accuracy\": 0.8520878553390503, \"f1\": 0.43610276943610277, \"f2\": 0.6589827363665699, \"f0_5\": 0.3258831508188219, \"p4\": 0.5906540882892175, \"phi\": 0.4847564326861071}, {\"truth_threshold\": -17.01197613730251, \"match_probability\": 7.566266101916305e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90864.0, \"fp\": 16855.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8435280919075012, \"fp_rate\": 0.15647193789482117, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27939289808273315, \"recall\": 0.999541163444519, \"specificity\": 0.8435280919075012, \"npv\": 0.9999669790267944, \"accuracy\": 0.8524554371833801, \"f1\": 0.4367147821438118, \"f2\": 0.6595413992168261, \"f0_5\": 0.3264300985034666, \"p4\": 0.5912630765240396, \"phi\": 0.4853037314557579}, {\"truth_threshold\": -17.010928869995592, \"match_probability\": 7.571760485412094e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90880.0, \"fp\": 16839.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8436766266822815, \"fp_rate\": 0.1563234031200409, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.279584139585495, \"recall\": 0.999541163444519, \"specificity\": 0.8436766266822815, \"npv\": 0.9999669790267944, \"accuracy\": 0.8525954484939575, \"f1\": 0.43694838192029956, \"f2\": 0.6597544723983362, \"f0_5\": 0.32663894275946176, \"p4\": 0.5914953908326549, \"phi\": 0.48551261816132624}, {\"truth_threshold\": -17.010419250105443, \"match_probability\": 7.574435598318874e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90912.0, \"fp\": 16807.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.843973696231842, \"fp_rate\": 0.15602633357048035, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.27996742725372314, \"recall\": 0.999541163444519, \"specificity\": 0.843973696231842, \"npv\": 0.9999669790267944, \"accuracy\": 0.8528755307197571, \"f1\": 0.43741633199464525, \"f2\": 0.6601810320442882, \"f0_5\": 0.3270574339879487, \"p4\": 0.59196054824685, \"phi\": 0.48593092801629695}, {\"truth_threshold\": -17.001039848112455, \"match_probability\": 7.623839367347849e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90928.0, \"fp\": 16791.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8441222310066223, \"fp_rate\": 0.15587779879570007, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.28015947341918945, \"recall\": 0.999541163444519, \"specificity\": 0.8441222310066223, \"npv\": 0.9999669790267944, \"accuracy\": 0.8530155420303345, \"f1\": 0.4376506830967051, \"f2\": 0.6603945187760216, \"f0_5\": 0.32726708198954346, \"p4\": 0.5921933917600662, \"phi\": 0.4861403518090974}, {\"truth_threshold\": -16.99923422510562, \"match_probability\": 7.633386979412886e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90931.0, \"fp\": 16788.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8441500663757324, \"fp_rate\": 0.15584994852542877, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2801955044269562, \"recall\": 0.999541163444519, \"specificity\": 0.8441500663757324, \"npv\": 0.9999670386314392, \"accuracy\": 0.8530418276786804, \"f1\": 0.4376946518870768, \"f2\": 0.6604345629105609, \"f0_5\": 0.32730642091555645, \"p4\": 0.592237069596521, \"phi\": 0.4861796734357892}, {\"truth_threshold\": -16.999082832638173, \"match_probability\": 7.634188042056795e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90971.0, \"fp\": 16748.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8445214033126831, \"fp_rate\": 0.1554786115884781, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2806769013404846, \"recall\": 0.999541163444519, \"specificity\": 0.8445214033126831, \"npv\": 0.9999670386314392, \"accuracy\": 0.8533918857574463, \"f1\": 0.43828174776164447, \"f2\": 0.6609689491251138, \"f0_5\": 0.32783184508879304, \"p4\": 0.5928200353780831, \"phi\": 0.48670424115157096}, {\"truth_threshold\": -16.998870866383758, \"match_probability\": 7.635309759899983e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 90973.0, \"fp\": 16746.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8445399403572083, \"fp_rate\": 0.15546004474163055, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.28070101141929626, \"recall\": 0.999541163444519, \"specificity\": 0.8445399403572083, \"npv\": 0.9999670386314392, \"accuracy\": 0.8534094095230103, \"f1\": 0.4383111439015393, \"f2\": 0.6609956911374992, \"f0_5\": 0.3278581605827698, \"p4\": 0.5928492127386877, \"phi\": 0.48673048626561766}, {\"truth_threshold\": -16.995694177495377, \"match_probability\": 7.652140441708743e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91183.0, \"fp\": 16536.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8464894890785217, \"fp_rate\": 0.15351052582263947, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.28325602412223816, \"recall\": 0.999541163444519, \"specificity\": 0.8464894890785217, \"npv\": 0.999967098236084, \"accuracy\": 0.8552473783493042, \"f1\": 0.4414198385625992, \"f2\": 0.6638156959145115, \"f0_5\": 0.3306449980773512, \"p4\": 0.5959283376180685, \"phi\": 0.48950530626427624}, {\"truth_threshold\": -16.99450064902017, \"match_probability\": 7.658473558664091e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91838.0, \"fp\": 15881.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.852570116519928, \"fp_rate\": 0.14742988348007202, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29153284430503845, \"recall\": 0.999541163444519, \"specificity\": 0.852570116519928, \"npv\": 0.9999673366546631, \"accuracy\": 0.8609800934791565, \"f1\": 0.4514056779719555, \"f2\": 0.6727680777466645, \"f0_5\": 0.3396499033284131, \"p4\": 0.6057337699420429, \"phi\": 0.4983879573271135}, {\"truth_threshold\": -16.97820973866748, \"match_probability\": 7.745442463655853e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91947.0, \"fp\": 15772.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8535820245742798, \"fp_rate\": 0.1464179903268814, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2929573655128479, \"recall\": 0.999541163444519, \"specificity\": 0.8535820245742798, \"npv\": 0.9999673962593079, \"accuracy\": 0.8619340658187866, \"f1\": 0.453111457791645, \"f2\": 0.6742813512453827, \"f0_5\": 0.34119624919073577, \"p4\": 0.60739584180898, \"phi\": 0.4999008470505598}, {\"truth_threshold\": -16.976423835627273, \"match_probability\": 7.755036360284054e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91951.0, \"fp\": 15768.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8536191582679749, \"fp_rate\": 0.14638085663318634, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2930099070072174, \"recall\": 0.999541163444519, \"specificity\": 0.8536191582679749, \"npv\": 0.9999673962593079, \"accuracy\": 0.8619690537452698, \"f1\": 0.4531743004750182, \"f2\": 0.6743370137240738, \"f0_5\": 0.3412532637075718, \"p4\": 0.6074570030060433, \"phi\": 0.49995657972073826}, {\"truth_threshold\": -16.9694339323886, \"match_probability\": 7.79270063327889e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91954.0, \"fp\": 15765.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.853646993637085, \"fp_rate\": 0.14635300636291504, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29304933547973633, \"recall\": 0.999541163444519, \"specificity\": 0.853646993637085, \"npv\": 0.9999673962593079, \"accuracy\": 0.8619953393936157, \"f1\": 0.45322144392815034, \"f2\": 0.6743787666143812, \"f0_5\": 0.3412960371012555, \"p4\": 0.6075028817191093, \"phi\": 0.49999834832384094}, {\"truth_threshold\": -16.9656447224364, \"match_probability\": 7.813194749154882e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91962.0, \"fp\": 15757.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8537212610244751, \"fp_rate\": 0.1462787389755249, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2931545078754425, \"recall\": 0.999541163444519, \"specificity\": 0.8537212610244751, \"npv\": 0.9999673962593079, \"accuracy\": 0.862065315246582, \"f1\": 0.45334720776968435, \"f2\": 0.6744901329369994, \"f0_5\": 0.34141015192359936, \"p4\": 0.6076252577157764, \"phi\": 0.5001098756841447}, {\"truth_threshold\": -16.96546782647059, \"match_probability\": 7.814152814809214e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91963.0, \"fp\": 15756.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8537305593490601, \"fp_rate\": 0.14626945555210114, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2931676506996155, \"recall\": 0.999541163444519, \"specificity\": 0.8537305593490601, \"npv\": 0.9999673962593079, \"accuracy\": 0.862074077129364, \"f1\": 0.45336293315758436, \"f2\": 0.6745040563136057, \"f0_5\": 0.34142442164218095, \"p4\": 0.6076405580669937, \"phi\": 0.5001238071673664}, {\"truth_threshold\": -16.960911146350952, \"match_probability\": 7.838872249122965e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91968.0, \"fp\": 15751.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8537769317626953, \"fp_rate\": 0.1462230384349823, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2932334244251251, \"recall\": 0.999541163444519, \"specificity\": 0.8537769317626953, \"npv\": 0.9999673962593079, \"accuracy\": 0.8621178865432739, \"f1\": 0.45344157646405775, \"f2\": 0.6745736818200586, \"f0_5\": 0.341495788131519, \"p4\": 0.6077170709990549, \"phi\": 0.5001935307823702}, {\"truth_threshold\": -16.955971466083067, \"match_probability\": 7.865757752920535e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91975.0, \"fp\": 15744.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8538419604301453, \"fp_rate\": 0.14615805447101593, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2933255434036255, \"recall\": 0.999541163444519, \"specificity\": 0.8538419604301453, \"npv\": 0.9999673962593079, \"accuracy\": 0.8621791005134583, \"f1\": 0.45355172294131935, \"f2\": 0.6746711816811546, \"f0_5\": 0.3415957513538378, \"p4\": 0.6078242204067176, \"phi\": 0.500291158771529}, {\"truth_threshold\": -16.944861941443975, \"match_probability\": 7.92656163179448e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 91981.0, \"fp\": 15738.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8538976311683655, \"fp_rate\": 0.14610235393047333, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29340457916259766, \"recall\": 0.999541163444519, \"specificity\": 0.8538976311683655, \"npv\": 0.9999673962593079, \"accuracy\": 0.8622316122055054, \"f1\": 0.4536461768074694, \"f2\": 0.6747547754259163, \"f0_5\": 0.34168148070689114, \"p4\": 0.6079160918359303, \"phi\": 0.5003748811846898}, {\"truth_threshold\": -16.93331355772229, \"match_probability\": 7.990265734366547e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92024.0, \"fp\": 15695.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8542968034744263, \"fp_rate\": 0.14570316672325134, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29397210478782654, \"recall\": 0.999541163444519, \"specificity\": 0.8542968034744263, \"npv\": 0.9999673962593079, \"accuracy\": 0.8626079559326172, \"f1\": 0.4543242491657397, \"f2\": 0.6753544706709107, \"f0_5\": 0.34229713591317645, \"p4\": 0.6085752903600723, \"phi\": 0.500975741023013}, {\"truth_threshold\": -16.92686460520712, \"match_probability\": 8.026062468251457e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92312.0, \"fp\": 15407.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8569704294204712, \"fp_rate\": 0.14302955567836761, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29783064126968384, \"recall\": 0.999541163444519, \"specificity\": 0.8569704294204712, \"npv\": 0.9999675154685974, \"accuracy\": 0.8651286363601685, \"f1\": 0.4589185393258427, \"f2\": 0.6793986775897202, \"f0_5\": 0.34647848493202976, \"p4\": 0.6130262753072997, \"phi\": 0.5050421200584906}, {\"truth_threshold\": -16.912001545870005, \"match_probability\": 8.109175996789458e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92313.0, \"fp\": 15406.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8569797277450562, \"fp_rate\": 0.14302027225494385, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2978442311286926, \"recall\": 0.999541163444519, \"specificity\": 0.8569797277450562, \"npv\": 0.9999675154685974, \"accuracy\": 0.8651373386383057, \"f1\": 0.45893465360441027, \"f2\": 0.6794128043582226, \"f0_5\": 0.3464931814807745, \"p4\": 0.6130418398146238, \"phi\": 0.5050564128274122}, {\"truth_threshold\": -16.8993879377167, \"match_probability\": 8.180385489240133e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92317.0, \"fp\": 15402.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8570168614387512, \"fp_rate\": 0.14298313856124878, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.297898530960083, \"recall\": 0.999541163444519, \"specificity\": 0.8570168614387512, \"npv\": 0.9999675154685974, \"accuracy\": 0.8651723861694336, \"f1\": 0.45899912203687443, \"f2\": 0.6794693173074924, \"f0_5\": 0.3465519801455147, \"p4\": 0.613104105490904, \"phi\": 0.5051133785323235}, {\"truth_threshold\": -16.89164414099262, \"match_probability\": 8.224412143377062e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92325.0, \"fp\": 15394.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8570911288261414, \"fp_rate\": 0.14290887117385864, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29800719022750854, \"recall\": 0.999541163444519, \"specificity\": 0.8570911288261414, \"npv\": 0.9999675154685974, \"accuracy\": 0.8652424216270447, \"f1\": 0.45912811325394315, \"f2\": 0.679582371414904, \"f0_5\": 0.34666963736287054, \"p4\": 0.6132286735608695, \"phi\": 0.5052274065974388}, {\"truth_threshold\": -16.886971772196627, \"match_probability\": 8.251091005925758e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92326.0, \"fp\": 15393.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8571004271507263, \"fp_rate\": 0.14289958775043488, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.2980208098888397, \"recall\": 0.999541163444519, \"specificity\": 0.8571004271507263, \"npv\": 0.9999675154685974, \"accuracy\": 0.8652511239051819, \"f1\": 0.459144242253917, \"f2\": 0.6795965058236273, \"f0_5\": 0.346684350132626, \"p4\": 0.6132442480129866, \"phi\": 0.50524171104301}, {\"truth_threshold\": -16.874472613552577, \"match_probability\": 8.3228864147906e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92338.0, \"fp\": 15381.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8572118282318115, \"fp_rate\": 0.14278818666934967, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29818397760391235, \"recall\": 0.999541163444519, \"specificity\": 0.8572118282318115, \"npv\": 0.9999675154685974, \"accuracy\": 0.8653561472892761, \"f1\": 0.4593378786813805, \"f2\": 0.6797661646001498, \"f0_5\": 0.3468610008280079, \"p4\": 0.6134312011547228, \"phi\": 0.5054128449029128}, {\"truth_threshold\": -16.872146455824694, \"match_probability\": 8.33631669692823e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92344.0, \"fp\": 15375.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8572674989700317, \"fp_rate\": 0.14273248612880707, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29826563596725464, \"recall\": 0.999541163444519, \"specificity\": 0.8572674989700317, \"npv\": 0.9999675154685974, \"accuracy\": 0.8654086589813232, \"f1\": 0.4594347581552306, \"f2\": 0.6798510257583954, \"f0_5\": 0.346949393701289, \"p4\": 0.6135247190872404, \"phi\": 0.5054984871868032}, {\"truth_threshold\": -16.868969766936313, \"match_probability\": 8.35469261088878e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92367.0, \"fp\": 15352.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.857481062412262, \"fp_rate\": 0.14251896739006042, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.29857906699180603, \"recall\": 0.999541163444519, \"specificity\": 0.857481062412262, \"npv\": 0.9999675154685974, \"accuracy\": 0.8656100034713745, \"f1\": 0.459806508355321, \"f2\": 0.6801765232415329, \"f0_5\": 0.3472886508088345, \"p4\": 0.6138834602028364, \"phi\": 0.5058270918872794}, {\"truth_threshold\": -16.858190653745442, \"match_probability\": 8.417348044806675e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 92583.0, \"fp\": 15136.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8594862818717957, \"fp_rate\": 0.14051374793052673, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3015550673007965, \"recall\": 0.999541163444519, \"specificity\": 0.8594862818717957, \"npv\": 0.9999675750732422, \"accuracy\": 0.8675004839897156, \"f1\": 0.46332730688787266, \"f2\": 0.6832486460489723, \"f0_5\": 0.3505073909592156, \"p4\": 0.617272419825506, \"phi\": 0.5089363901340743}, {\"truth_threshold\": -16.84049424866313, \"match_probability\": 8.521231980168375e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93077.0, \"fp\": 14642.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8640722632408142, \"fp_rate\": 0.1359277367591858, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.30858951807022095, \"recall\": 0.999541163444519, \"specificity\": 0.8640722632408142, \"npv\": 0.9999677538871765, \"accuracy\": 0.8718240261077881, \"f1\": 0.4715857838715497, \"f2\": 0.6903801052209005, \"f0_5\": 0.35809788922254127, \"p4\": 0.6251609016062621, \"phi\": 0.5162113944330846}, {\"truth_threshold\": -16.828945864941446, \"match_probability\": 8.589715281745365e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93078.0, \"fp\": 14641.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8640815615653992, \"fp_rate\": 0.13591845333576202, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.30860409140586853, \"recall\": 0.999541163444519, \"specificity\": 0.8640815615653992, \"npv\": 0.9999677538871765, \"accuracy\": 0.8718327879905701, \"f1\": 0.4716028000288663, \"f2\": 0.6903946923597025, \"f0_5\": 0.35811358804059534, \"p4\": 0.6251770681872354, \"phi\": 0.5162263505254551}, {\"truth_threshold\": -16.81364162899135, \"match_probability\": 8.681319962522828e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93262.0, \"fp\": 14457.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8657897114753723, \"fp_rate\": 0.13421030342578888, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3113090693950653, \"recall\": 0.999541163444519, \"specificity\": 0.8657897114753723, \"npv\": 0.9999678134918213, \"accuracy\": 0.8734431862831116, \"f1\": 0.47475481293134764, \"f2\": 0.6930892584422196, \"f0_5\": 0.36102578834552407, \"p4\": 0.6281655703796816, \"phi\": 0.5189966394722333}, {\"truth_threshold\": -16.806589147163226, \"match_probability\": 8.7238613203848e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93267.0, \"fp\": 14452.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8658360838890076, \"fp_rate\": 0.13416388630867004, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3113832473754883, \"recall\": 0.999541163444519, \"specificity\": 0.8658360838890076, \"npv\": 0.9999678134918213, \"accuracy\": 0.8734869360923767, \"f1\": 0.4748410535876476, \"f2\": 0.6931627739239271, \"f0_5\": 0.36110558539442567, \"p4\": 0.6282471660730756, \"phi\": 0.519072400302494}, {\"truth_threshold\": -16.80645433357949, \"match_probability\": 8.724676558301297e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93316.0, \"fp\": 14403.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8662909865379333, \"fp_rate\": 0.13370899856090546, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3121119439601898, \"recall\": 0.999541163444519, \"specificity\": 0.8662909865379333, \"npv\": 0.9999678730964661, \"accuracy\": 0.8739158511161804, \"f1\": 0.4756878730528461, \"f2\": 0.6938840518156721, \"f0_5\": 0.3618894672721232, \"p4\": 0.6290478923459332, \"phi\": 0.5198160312934003}, {\"truth_threshold\": -16.804180338892433, \"match_probability\": 8.73843923039656e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93550.0, \"fp\": 14169.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8684633374214172, \"fp_rate\": 0.13153667747974396, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3156394958496094, \"recall\": 0.999541163444519, \"specificity\": 0.8684633374214172, \"npv\": 0.9999679327011108, \"accuracy\": 0.8759638071060181, \"f1\": 0.47977387856985537, \"f2\": 0.6973493255933072, \"f0_5\": 0.3656803276853862, \"p4\": 0.6328992118389349, \"phi\": 0.5234010495577671}, {\"truth_threshold\": -16.8004720321088, \"match_probability\": 8.760929230504897e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93554.0, \"fp\": 14165.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8685004711151123, \"fp_rate\": 0.1314995437860489, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3157004714012146, \"recall\": 0.999541163444519, \"specificity\": 0.8685004711151123, \"npv\": 0.9999679327011108, \"accuracy\": 0.875998854637146, \"f1\": 0.47984433512005287, \"f2\": 0.6974088619482626, \"f0_5\": 0.3657458192482482, \"p4\": 0.632965443785215, \"phi\": 0.5234627859261052}, {\"truth_threshold\": -16.79950893094629, \"match_probability\": 8.766779672827562e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93557.0, \"fp\": 14162.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8685283064842224, \"fp_rate\": 0.1314716935157776, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3157462477684021, \"recall\": 0.999541163444519, \"specificity\": 0.8685283064842224, \"npv\": 0.9999679327011108, \"accuracy\": 0.8760250806808472, \"f1\": 0.4798971911143749, \"f2\": 0.6974535208862516, \"f0_5\": 0.36579495331706335, \"p4\": 0.6330151265659086, \"phi\": 0.5235091538863401}, {\"truth_threshold\": -16.76413510516901, \"match_probability\": 8.984389675293681e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93575.0, \"fp\": 14144.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8686953783035278, \"fp_rate\": 0.13130459189414978, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3160210847854614, \"recall\": 0.999541163444519, \"specificity\": 0.8686953783035278, \"npv\": 0.9999679327011108, \"accuracy\": 0.8761826157569885, \"f1\": 0.48021457177499355, \"f2\": 0.6977215946701971, \"f0_5\": 0.3660900351804961, \"p4\": 0.633313382129752, \"phi\": 0.5237873933451409}, {\"truth_threshold\": -16.754460268883523, \"match_probability\": 9.044841687240587e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93607.0, \"fp\": 14112.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8689924478530884, \"fp_rate\": 0.13100752234458923, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3165108859539032, \"recall\": 0.999541163444519, \"specificity\": 0.8689924478530884, \"npv\": 0.9999679327011108, \"accuracy\": 0.8764626979827881, \"f1\": 0.4807798418245356, \"f2\": 0.6981986794589627, \"f0_5\": 0.36661580234723873, \"p4\": 0.6338442876662677, \"phi\": 0.5242828548061221}, {\"truth_threshold\": -16.74244003406969, \"match_probability\": 9.120515550036531e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93620.0, \"fp\": 14099.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8691131472587585, \"fp_rate\": 0.13088683784008026, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.31671029329299927, \"recall\": 0.999541163444519, \"specificity\": 0.8691131472587585, \"npv\": 0.9999679327011108, \"accuracy\": 0.8765764832496643, \"f1\": 0.48100986309436183, \"f2\": 0.6983926815714102, \"f0_5\": 0.3668298268855109, \"p4\": 0.6340602146597298, \"phi\": 0.5244844392071427}, {\"truth_threshold\": -16.73146624318638, \"match_probability\": 9.190154193886322e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93621.0, \"fp\": 14098.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8691224455833435, \"fp_rate\": 0.1308775544166565, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.31672564148902893, \"recall\": 0.999541163444519, \"specificity\": 0.8691224455833435, \"npv\": 0.9999679327011108, \"accuracy\": 0.8765852451324463, \"f1\": 0.48102756615509185, \"f2\": 0.6984076092764775, \"f0_5\": 0.36684630066240037, \"p4\": 0.6340768303374397, \"phi\": 0.5244999445680901}, {\"truth_threshold\": -16.731179468799375, \"match_probability\": 9.191981148640083e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93709.0, \"fp\": 14010.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.869939386844635, \"fp_rate\": 0.13006062805652618, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3180822730064392, \"recall\": 0.999541163444519, \"specificity\": 0.869939386844635, \"npv\": 0.9999679923057556, \"accuracy\": 0.8773554563522339, \"f1\": 0.48259055496067643, \"f2\": 0.6997237509904276, \"f0_5\": 0.3683018102301675, \"p4\": 0.6355423243210951, \"phi\": 0.5258692908573166}, {\"truth_threshold\": -16.722469520107527, \"match_probability\": 9.2476430200915e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93710.0, \"fp\": 14009.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.86994868516922, \"fp_rate\": 0.13005134463310242, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3180977404117584, \"recall\": 0.999541163444519, \"specificity\": 0.86994868516922, \"npv\": 0.9999679923057556, \"accuracy\": 0.8773641586303711, \"f1\": 0.4826083745661325, \"f2\": 0.6997387356518759, \"f0_5\": 0.36831841648443314, \"p4\": 0.6355590154122126, \"phi\": 0.5258848896990466}, {\"truth_threshold\": -16.714963366579273, \"match_probability\": 9.295882231786498e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93733.0, \"fp\": 13986.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8701621890068054, \"fp_rate\": 0.12983782589435577, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3184542655944824, \"recall\": 0.999541163444519, \"specificity\": 0.8701621890068054, \"npv\": 0.9999679923057556, \"accuracy\": 0.8775655031204224, \"f1\": 0.48301858900920214, \"f2\": 0.7000835600882738, \"f0_5\": 0.36870077407415763, \"p4\": 0.6359431453215822, \"phi\": 0.5262441197080479}, {\"truth_threshold\": -16.710921136385842, \"match_probability\": 9.32196427593235e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93747.0, \"fp\": 13972.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8702921271324158, \"fp_rate\": 0.12970785796642303, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.31867167353630066, \"recall\": 0.999541163444519, \"specificity\": 0.8702921271324158, \"npv\": 0.9999679923057556, \"accuracy\": 0.8776879906654358, \"f1\": 0.4832686263634683, \"f2\": 0.700293619666088, \"f0_5\": 0.3689339024004697, \"p4\": 0.6361771840938436, \"phi\": 0.5264631202330282}, {\"truth_threshold\": -16.706187560300393, \"match_probability\": 9.352600191552866e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 93935.0, \"fp\": 13784.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.872037410736084, \"fp_rate\": 0.12796257436275482, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3216201663017273, \"recall\": 0.999541163444519, \"specificity\": 0.872037410736084, \"npv\": 0.9999680519104004, \"accuracy\": 0.8793334364891052, \"f1\": 0.4866515247421529, \"f2\": 0.7031266811559898, \"f0_5\": 0.37209328808618214, \"p4\": 0.6393362551356957, \"phi\": 0.5294236524179347}, {\"truth_threshold\": -16.702221454382382, \"match_probability\": 9.37834651143593e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94580.0, \"fp\": 13139.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.878025233745575, \"fp_rate\": 0.12197476625442505, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33216428756713867, \"recall\": 0.999541163444519, \"specificity\": 0.878025233745575, \"npv\": 0.9999682903289795, \"accuracy\": 0.8849785923957825, \"f1\": 0.4986265832443156, \"f2\": 0.7130231746170297, \"f0_5\": 0.38335640706760216, \"p4\": 0.6504098089913277, \"phi\": 0.5398781149785782}, {\"truth_threshold\": -16.67715473775081, \"match_probability\": 9.542716839847292e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94619.0, \"fp\": 13100.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8783872723579407, \"fp_rate\": 0.12161271274089813, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33282405138015747, \"recall\": 0.999541163444519, \"specificity\": 0.8783872723579407, \"npv\": 0.9999682903289795, \"accuracy\": 0.8853199481964111, \"f1\": 0.4993695793374852, \"f2\": 0.7136305064756372, \"f0_5\": 0.38405933378781826, \"p4\": 0.6510913216520676, \"phi\": 0.5405255381699462}, {\"truth_threshold\": -16.647849170720736, \"match_probability\": 9.73853897957102e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94627.0, \"fp\": 13092.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8784615397453308, \"fp_rate\": 0.121538445353508, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33295971155166626, \"recall\": 0.999541163444519, \"specificity\": 0.8784615397453308, \"npv\": 0.9999682903289795, \"accuracy\": 0.8853899836540222, \"f1\": 0.49952226256449456, \"f2\": 0.7137552152733786, \"f0_5\": 0.3842038426263434, \"p4\": 0.6512312906180558, \"phi\": 0.5406585519415067}, {\"truth_threshold\": -16.643716627549036, \"match_probability\": 9.766474359602076e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94629.0, \"fp\": 13090.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8784801363945007, \"fp_rate\": 0.12151987850666046, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33299362659454346, \"recall\": 0.999541163444519, \"specificity\": 0.8784801363945007, \"npv\": 0.9999682903289795, \"accuracy\": 0.8854074478149414, \"f1\": 0.49956044796086074, \"f2\": 0.713786399283483, \"f0_5\": 0.38423998682941746, \"p4\": 0.651266291993537, \"phi\": 0.5406918032225292}, {\"truth_threshold\": -16.640007359915554, \"match_probability\": 9.791616694839487e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94633.0, \"fp\": 13086.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8785172700881958, \"fp_rate\": 0.1214827448129654, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3330615162849426, \"recall\": 0.999541163444519, \"specificity\": 0.8785172700881958, \"npv\": 0.9999682903289795, \"accuracy\": 0.8854424953460693, \"f1\": 0.49963683627049965, \"f2\": 0.7138487754789942, \"f0_5\": 0.3843122956411282, \"p4\": 0.6513363057093308, \"phi\": 0.5407583759494985}, {\"truth_threshold\": -16.636300786999048, \"match_probability\": 9.8168054186285e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94648.0, \"fp\": 13071.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8786565065383911, \"fp_rate\": 0.12134349346160889, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3333163261413574, \"recall\": 0.999541163444519, \"specificity\": 0.8786565065383911, \"npv\": 0.9999682903289795, \"accuracy\": 0.8855737447738647, \"f1\": 0.4999235006119951, \"f2\": 0.7140827833384327, \"f0_5\": 0.3845836962406723, \"p4\": 0.6515989874231302, \"phi\": 0.5410080945508317}, {\"truth_threshold\": -16.62773585832446, \"match_probability\": 9.875258161323002e-06, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94832.0, \"fp\": 12887.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8803646564483643, \"fp_rate\": 0.11963535100221634, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33647409081459045, \"recall\": 0.999541163444519, \"specificity\": 0.8803646564483643, \"npv\": 0.9999683499336243, \"accuracy\": 0.8871841430664062, \"f1\": 0.5034668721109399, \"f2\": 0.7169658138412253, \"f0_5\": 0.3879443402274832, \"p4\": 0.6548380445554148, \"phi\": 0.5440934358891774}, {\"truth_threshold\": -16.606863853003894, \"match_probability\": 1.0019164220973598e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94836.0, \"fp\": 12883.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8804017901420593, \"fp_rate\": 0.11959821730852127, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33654341101646423, \"recall\": 0.999541163444519, \"specificity\": 0.8804017901420593, \"npv\": 0.9999683499336243, \"accuracy\": 0.8872191905975342, \"f1\": 0.5035444598551395, \"f2\": 0.7170287469826641, \"f0_5\": 0.3880180501128132, \"p4\": 0.6549088063093976, \"phi\": 0.5441609824725289}, {\"truth_threshold\": -16.604455058240315, \"match_probability\": 1.0035906516597024e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94849.0, \"fp\": 12870.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8805224895477295, \"fp_rate\": 0.1194775328040123, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33676886558532715, \"recall\": 0.999541163444519, \"specificity\": 0.8805224895477295, \"npv\": 0.9999683499336243, \"accuracy\": 0.8873329162597656, \"f1\": 0.503796785259993, \"f2\": 0.717233356015541, \"f0_5\": 0.388257800803251, \"p4\": 0.6551388846697443, \"phi\": 0.5443805729500976}, {\"truth_threshold\": -16.59286367801918, \"match_probability\": 1.0116864311609953e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94853.0, \"fp\": 12866.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8805596232414246, \"fp_rate\": 0.11944039911031723, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3368383049964905, \"recall\": 0.999541163444519, \"specificity\": 0.8805596232414246, \"npv\": 0.9999683499336243, \"accuracy\": 0.8873679637908936, \"f1\": 0.5038744747291722, \"f2\": 0.7172963361359296, \"f0_5\": 0.38833162986380165, \"p4\": 0.6552097096166611, \"phi\": 0.5444481460229622}, {\"truth_threshold\": -16.58419672582678, \"match_probability\": 1.0177823408795607e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94860.0, \"fp\": 12859.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8806245923042297, \"fp_rate\": 0.11937541514635086, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3369598984718323, \"recall\": 0.999541163444519, \"specificity\": 0.8806245923042297, \"npv\": 0.9999683499336243, \"accuracy\": 0.8874292373657227, \"f1\": 0.5040104889711553, \"f2\": 0.7174065779651342, \"f0_5\": 0.3884608983046817, \"p4\": 0.6553336890848935, \"phi\": 0.544566558226934}, {\"truth_threshold\": -16.57946314974133, \"match_probability\": 1.0211272010633211e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94876.0, \"fp\": 12843.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.88077312707901, \"fp_rate\": 0.11922688037157059, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3372381031513214, \"recall\": 0.999541163444519, \"specificity\": 0.88077312707901, \"npv\": 0.999968409538269, \"accuracy\": 0.8875692486763, \"f1\": 0.5043216545763235, \"f2\": 0.7176586865802768, \"f0_5\": 0.38875669244497324, \"p4\": 0.6556172419986006, \"phi\": 0.5448372944803607}, {\"truth_threshold\": -16.56841063429464, \"match_probability\": 1.0289800383594514e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94988.0, \"fp\": 12731.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8818128705024719, \"fp_rate\": 0.11818713694810867, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33919858932495117, \"recall\": 0.999541163444519, \"specificity\": 0.8818128705024719, \"npv\": 0.999968409538269, \"accuracy\": 0.8885495066642761, \"f1\": 0.5065106185087583, \"f2\": 0.7194284204500419, \"f0_5\": 0.39083993205904166, \"p4\": 0.6576088085542645, \"phi\": 0.5467414641495677}, {\"truth_threshold\": -16.552544518665215, \"match_probability\": 1.0403586371521324e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 94994.0, \"fp\": 12725.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8818685412406921, \"fp_rate\": 0.11813143640756607, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33930426836013794, \"recall\": 0.999541163444519, \"specificity\": 0.8818685412406921, \"npv\": 0.999968409538269, \"accuracy\": 0.8886020183563232, \"f1\": 0.5066284208078146, \"f2\": 0.7195234739716374, \"f0_5\": 0.39095216444518893, \"p4\": 0.6577158314981109, \"phi\": 0.5468438555271362}, {\"truth_threshold\": -16.551623855666953, \"match_probability\": 1.0410227521483084e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95002.0, \"fp\": 12717.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8819428086280823, \"fp_rate\": 0.11805716902017593, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3394452631473541, \"recall\": 0.999541163444519, \"specificity\": 0.8819428086280823, \"npv\": 0.999968409538269, \"accuracy\": 0.8886720538139343, \"f1\": 0.5067855758045754, \"f2\": 0.7196502510792001, \"f0_5\": 0.39110190793096017, \"p4\": 0.6578585814334001, \"phi\": 0.5469805595722304}, {\"truth_threshold\": -16.550607223157556, \"match_probability\": 1.0417565867382876e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95007.0, \"fp\": 12712.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8819892406463623, \"fp_rate\": 0.1180107519030571, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3395334482192993, \"recall\": 0.999541163444519, \"specificity\": 0.8819892406463623, \"npv\": 0.999968409538269, \"accuracy\": 0.8887158036231995, \"f1\": 0.5068838471979833, \"f2\": 0.7197295094605608, \"f0_5\": 0.3911955558748174, \"p4\": 0.6579478307298109, \"phi\": 0.5470660258469675}, {\"truth_threshold\": -16.53626255885808, \"match_probability\": 1.052166291488365e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95008.0, \"fp\": 12711.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8819985389709473, \"fp_rate\": 0.11800146847963333, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.33955106139183044, \"recall\": 0.999541163444519, \"specificity\": 0.8819985389709473, \"npv\": 0.999968409538269, \"accuracy\": 0.8887245655059814, \"f1\": 0.5069035060502637, \"f2\": 0.7197453632318604, \"f0_5\": 0.3912142908455257, \"p4\": 0.6579656834135487, \"phi\": 0.5470831115486522}, {\"truth_threshold\": -16.51345216937973, \"match_probability\": 1.0689340778848859e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95494.0, \"fp\": 12225.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8865102529525757, \"fp_rate\": 0.11348972469568253, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.348347544670105, \"recall\": 0.999541163444519, \"specificity\": 0.8865102529525757, \"npv\": 0.9999685883522034, \"accuracy\": 0.8929781317710876, \"f1\": 0.5166416317495455, \"f2\": 0.7275338439615248, \"f0_5\": 0.40053690946088405, \"p4\": 0.6667549842140379, \"phi\": 0.5555412027774513}, {\"truth_threshold\": -16.509576376439984, \"match_probability\": 1.071809593906713e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95495.0, \"fp\": 12224.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8865195512771606, \"fp_rate\": 0.11348044127225876, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3483661115169525, \"recall\": 0.999541163444519, \"specificity\": 0.8865195512771606, \"npv\": 0.9999685883522034, \"accuracy\": 0.8929868340492249, \"f1\": 0.5166620547891054, \"f2\": 0.7275500434192069, \"f0_5\": 0.4005565498810896, \"p4\": 0.6667733045534266, \"phi\": 0.5555589129510935}, {\"truth_threshold\": -16.50345926138556, \"match_probability\": 1.076363731193623e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95567.0, \"fp\": 12152.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8871879577636719, \"fp_rate\": 0.11281204223632812, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.34970834851264954, \"recall\": 0.999541163444519, \"specificity\": 0.8871879577636719, \"npv\": 0.9999685883522034, \"accuracy\": 0.8936170339584351, \"f1\": 0.5181367690782953, \"f2\": 0.7287183032627846, \"f0_5\": 0.40197573997982433, \"p4\": 0.668094947533012, \"phi\": 0.5568381626555444}, {\"truth_threshold\": -16.500802601848118, \"match_probability\": 1.0783476123986593e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95569.0, \"fp\": 12150.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8872065544128418, \"fp_rate\": 0.11279347538948059, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3497457802295685, \"recall\": 0.999541163444519, \"specificity\": 0.8872065544128418, \"npv\": 0.9999685883522034, \"accuracy\": 0.8936344981193542, \"f1\": 0.5181778535463664, \"f2\": 0.7287508084840645, \"f0_5\": 0.4020153054947218, \"p4\": 0.6681317325927113, \"phi\": 0.5568737785438383}, {\"truth_threshold\": -16.492461781061344, \"match_probability\": 1.084599977713081e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95794.0, \"fp\": 11925.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8892952799797058, \"fp_rate\": 0.110704705119133, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35400867462158203, \"recall\": 0.999541163444519, \"specificity\": 0.8892952799797058, \"npv\": 0.9999687075614929, \"accuracy\": 0.8956037759780884, \"f1\": 0.5228418273461877, \"f2\": 0.7324262530260917, \"f0_5\": 0.4065167085520914, \"p4\": 0.6722953638884316, \"phi\": 0.5609170505098418}, {\"truth_threshold\": -16.486410397915623, \"match_probability\": 1.0891588362454724e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95803.0, \"fp\": 11916.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8893788456916809, \"fp_rate\": 0.11062115430831909, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35418134927749634, \"recall\": 0.999541163444519, \"specificity\": 0.8893788456916809, \"npv\": 0.9999687075614929, \"accuracy\": 0.8956825137138367, \"f1\": 0.5230301332586338, \"f2\": 0.7325740421047912, \"f0_5\": 0.4066988623633965, \"p4\": 0.6724629595509831, \"phi\": 0.5610802528846969}, {\"truth_threshold\": -16.48013944244483, \"match_probability\": 1.0939033298017807e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95811.0, \"fp\": 11908.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.889453113079071, \"fp_rate\": 0.11054688692092896, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3543349802494049, \"recall\": 0.999541163444519, \"specificity\": 0.889453113079071, \"npv\": 0.9999687075614929, \"accuracy\": 0.8957525491714478, \"f1\": 0.5231976301989512, \"f2\": 0.7327054602533917, \"f0_5\": 0.4068609139584112, \"p4\": 0.6726120017530208, \"phi\": 0.5612253708641957}, {\"truth_threshold\": -16.479405628235895, \"match_probability\": 1.0944598695967336e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95813.0, \"fp\": 11906.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.889471709728241, \"fp_rate\": 0.11052832007408142, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35437339544296265, \"recall\": 0.999541163444519, \"specificity\": 0.889471709728241, \"npv\": 0.9999687075614929, \"accuracy\": 0.8957700729370117, \"f1\": 0.5232395211978061, \"f2\": 0.7327383221581862, \"f0_5\": 0.4069014470374337, \"p4\": 0.6726492723498678, \"phi\": 0.5612616498228385}, {\"truth_threshold\": -16.459435114273735, \"match_probability\": 1.1097151099611409e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95816.0, \"fp\": 11903.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8894995450973511, \"fp_rate\": 0.11050046980381012, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35443106293678284, \"recall\": 0.999541163444519, \"specificity\": 0.8894995450973511, \"npv\": 0.9999687075614929, \"accuracy\": 0.8957962989807129, \"f1\": 0.5233023702754644, \"f2\": 0.7327876205427226, \"f0_5\": 0.4069622618009715, \"p4\": 0.6727051857825588, \"phi\": 0.5613161359953597}, {\"truth_threshold\": -16.45107154960664, \"match_probability\": 1.1161669409522634e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95833.0, \"fp\": 11886.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8896573781967163, \"fp_rate\": 0.11034265160560608, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3547581434249878, \"recall\": 0.999541163444519, \"specificity\": 0.8896573781967163, \"npv\": 0.9999687075614929, \"accuracy\": 0.895945131778717, \"f1\": 0.5236588004327096, \"f2\": 0.7330671034034056, \"f0_5\": 0.4073072224576799, \"p4\": 0.6730221995184102, \"phi\": 0.5616249730875249}, {\"truth_threshold\": -16.447886730552046, \"match_probability\": 1.1186336275393408e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 95834.0, \"fp\": 11885.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8896666169166565, \"fp_rate\": 0.11033336818218231, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35477742552757263, \"recall\": 0.999541163444519, \"specificity\": 0.8896666169166565, \"npv\": 0.9999687075614929, \"accuracy\": 0.8959538340568542, \"f1\": 0.5236797820338168, \"f2\": 0.7330835502108948, \"f0_5\": 0.4073275324740083, \"p4\": 0.6730408564407292, \"phi\": 0.5616431423047413}, {\"truth_threshold\": -16.439512901112384, \"match_probability\": 1.125145315073353e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96027.0, \"fp\": 11692.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8914583325386047, \"fp_rate\": 0.10854166746139526, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.358534038066864, \"recall\": 0.999541163444519, \"specificity\": 0.8914583325386047, \"npv\": 0.9999687671661377, \"accuracy\": 0.8976430296897888, \"f1\": 0.5277609529578033, \"f2\": 0.7362716600193785, \"f0_5\": 0.41128565314805027, \"p4\": 0.6766605877590254, \"phi\": 0.56517768556456}, {\"truth_threshold\": -16.425966369274438, \"match_probability\": 1.1357597729613279e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96028.0, \"fp\": 11691.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8914676308631897, \"fp_rate\": 0.1085323840379715, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3585537075996399, \"recall\": 0.999541163444519, \"specificity\": 0.8914676308631897, \"npv\": 0.9999687671661377, \"accuracy\": 0.8976517915725708, \"f1\": 0.5277822645776127, \"f2\": 0.736288250935148, \"f0_5\": 0.41130636187407166, \"p4\": 0.6766794415300749, \"phi\": 0.5651961270569577}, {\"truth_threshold\": -16.42545674938429, \"match_probability\": 1.1361610368585283e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96031.0, \"fp\": 11688.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8914954662322998, \"fp_rate\": 0.1085045337677002, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3586127460002899, \"recall\": 0.999541163444519, \"specificity\": 0.8914954662322998, \"npv\": 0.9999687671661377, \"accuracy\": 0.897678017616272, \"f1\": 0.5278462097653568, \"f2\": 0.7363380281690141, \"f0_5\": 0.41136850056653657, \"p4\": 0.6767360089804815, \"phi\": 0.5652515177153083}, {\"truth_threshold\": -16.423882812598492, \"match_probability\": 1.1374012165673603e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96047.0, \"fp\": 11672.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8916440010070801, \"fp_rate\": 0.10835599899291992, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3589278757572174, \"recall\": 0.999541163444519, \"specificity\": 0.8916440010070801, \"npv\": 0.9999687671661377, \"accuracy\": 0.8978180885314941, \"f1\": 0.5281875126288139, \"f2\": 0.736603620460335, \"f0_5\": 0.4117002242773984, \"p4\": 0.6770378576117284, \"phi\": 0.565546958813678}, {\"truth_threshold\": -16.422280060495908, \"match_probability\": 1.1386654923531837e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96051.0, \"fp\": 11668.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8916811347007751, \"fp_rate\": 0.10831886529922485, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35900676250457764, \"recall\": 0.999541163444519, \"specificity\": 0.8916811347007751, \"npv\": 0.9999687671661377, \"accuracy\": 0.8978530764579773, \"f1\": 0.5282729073198335, \"f2\": 0.736670048472551, \"f0_5\": 0.41178323881537493, \"p4\": 0.6771133607328202, \"phi\": 0.5656209049331956}, {\"truth_threshold\": -16.414120331917015, \"match_probability\": 1.1451238352631756e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96052.0, \"fp\": 11667.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8916904330253601, \"fp_rate\": 0.10830958187580109, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3590264916419983, \"recall\": 0.999541163444519, \"specificity\": 0.8916904330253601, \"npv\": 0.9999687671661377, \"accuracy\": 0.8978618383407593, \"f1\": 0.5282942603071948, \"f2\": 0.7366866573477026, \"f0_5\": 0.41180399768104253, \"p4\": 0.6771322390747717, \"phi\": 0.5656393806113799}, {\"truth_threshold\": -16.4139083656626, \"match_probability\": 1.1452920916550562e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96055.0, \"fp\": 11664.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8917182683944702, \"fp_rate\": 0.10828173160552979, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.35908564925193787, \"recall\": 0.999541163444519, \"specificity\": 0.8917182683944702, \"npv\": 0.9999687671661377, \"accuracy\": 0.8978881239891052, \"f1\": 0.5283583296276833, \"f2\": 0.7367364884670019, \"f0_5\": 0.41186628683792575, \"p4\": 0.6771888802500023, \"phi\": 0.5656948162064647}, {\"truth_threshold\": -16.409538148299017, \"match_probability\": 1.1487666349001629e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96236.0, \"fp\": 11483.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8933985829353333, \"fp_rate\": 0.10660143196582794, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36269286274909973, \"recall\": 0.999541163444519, \"specificity\": 0.8933985829353333, \"npv\": 0.9999688267707825, \"accuracy\": 0.8994722366333008, \"f1\": 0.5322528099038931, \"f2\": 0.7397554901516866, \"f0_5\": 0.4156595852944918, \"p4\": 0.6806233846896932, \"phi\": 0.5690650701099813}, {\"truth_threshold\": -16.384471431667446, \"match_probability\": 1.1689005405458405e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96349.0, \"fp\": 11370.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8944475650787354, \"fp_rate\": 0.10555241256952286, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36498185992240906, \"recall\": 0.999541163444519, \"specificity\": 0.8944475650787354, \"npv\": 0.9999688863754272, \"accuracy\": 0.9004612565040588, \"f1\": 0.5347134148836068, \"f2\": 0.741652858796559, \"f0_5\": 0.4180634100156094, \"p4\": 0.6827848297814711, \"phi\": 0.5711933231865273}, {\"truth_threshold\": -16.375948645629794, \"match_probability\": 1.1758262287926484e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96355.0, \"fp\": 11364.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8945032954216003, \"fp_rate\": 0.10549671202898026, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36510419845581055, \"recall\": 0.999541163444519, \"specificity\": 0.8945032954216003, \"npv\": 0.9999688863754272, \"accuracy\": 0.900513768196106, \"f1\": 0.5348447027049147, \"f2\": 0.7417538761889628, \"f0_5\": 0.41819182430184043, \"p4\": 0.6828999706211881, \"phi\": 0.571306861520031}, {\"truth_threshold\": -16.370471256682734, \"match_probability\": 1.1802988462006153e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96356.0, \"fp\": 11363.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8945125937461853, \"fp_rate\": 0.10548742860555649, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36512458324432373, \"recall\": 0.999541163444519, \"specificity\": 0.8945125937461853, \"npv\": 0.9999688863754272, \"accuracy\": 0.9005225300788879, \"f1\": 0.5348665902766411, \"f2\": 0.7417707150964813, \"f0_5\": 0.4182132343530014, \"p4\": 0.6829191644384287, \"phi\": 0.5713257801033104}, {\"truth_threshold\": -16.359899440722817, \"match_probability\": 1.1889795325094016e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96363.0, \"fp\": 11356.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8945775628089905, \"fp_rate\": 0.10542244464159012, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36526745557785034, \"recall\": 0.999541163444519, \"specificity\": 0.8945775628089905, \"npv\": 0.9999688863754272, \"accuracy\": 0.9005837440490723, \"f1\": 0.5350198534528634, \"f2\": 0.7418886088595237, \"f0_5\": 0.4183631661161046, \"p4\": 0.6830535505887966, \"phi\": 0.5714583099318883}, {\"truth_threshold\": -16.35516586463737, \"match_probability\": 1.1928870118465367e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96387.0, \"fp\": 11332.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8948003649711609, \"fp_rate\": 0.10519964247941971, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36575809121131897, \"recall\": 0.999541163444519, \"specificity\": 0.8948003649711609, \"npv\": 0.9999688863754272, \"accuracy\": 0.9007938504219055, \"f1\": 0.5355459946732227, \"f2\": 0.7422931007065131, \"f0_5\": 0.41887803502294696, \"p4\": 0.68351469444475, \"phi\": 0.571913285632276}, {\"truth_threshold\": -16.34415634569013, \"match_probability\": 1.2020249043636211e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96397.0, \"fp\": 11322.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8948931694030762, \"fp_rate\": 0.10510680824518204, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3659629225730896, \"recall\": 0.999541163444519, \"specificity\": 0.8948931694030762, \"npv\": 0.9999688863754272, \"accuracy\": 0.9008813500404358, \"f1\": 0.5357655257224841, \"f2\": 0.7424617691835761, \"f0_5\": 0.41909293794731034, \"p4\": 0.6837070167592628, \"phi\": 0.5721031321135729}, {\"truth_threshold\": -16.343617480915682, \"match_probability\": 1.2024739542687601e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96401.0, \"fp\": 11318.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8949303030967712, \"fp_rate\": 0.10506967455148697, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.36604490876197815, \"recall\": 0.999541163444519, \"specificity\": 0.8949303030967712, \"npv\": 0.9999688863754272, \"accuracy\": 0.900916337966919, \"f1\": 0.5358533885449551, \"f2\": 0.7425292580388593, \"f0_5\": 0.41917896087235407, \"p4\": 0.6837839752052096, \"phi\": 0.5721790660958724}, {\"truth_threshold\": -16.33320676844139, \"match_probability\": 1.2111824720320683e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96777.0, \"fp\": 10942.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8984208703041077, \"fp_rate\": 0.10157910734415054, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3739200234413147, \"recall\": 0.999541163444519, \"specificity\": 0.8984208703041077, \"npv\": 0.9999690055847168, \"accuracy\": 0.904207170009613, \"f1\": 0.5442431813449927, \"f2\": 0.7489284650118041, \"f0_5\": 0.42742589540329123, \"p4\": 0.6910942088571481, \"phi\": 0.5794291432637118}, {\"truth_threshold\": -16.321162319992983, \"match_probability\": 1.2213363229463912e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96789.0, \"fp\": 10930.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8985322713851929, \"fp_rate\": 0.10146770626306534, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.37417691946029663, \"recall\": 0.999541163444519, \"specificity\": 0.8985322713851929, \"npv\": 0.9999690055847168, \"accuracy\": 0.9043121933937073, \"f1\": 0.5445152689247178, \"f2\": 0.7491345117729326, \"f0_5\": 0.42769444226288644, \"p4\": 0.6913300225345549, \"phi\": 0.5796641485829659}, {\"truth_threshold\": -16.29020458294235, \"match_probability\": 1.2478269633988317e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 96833.0, \"fp\": 10886.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.8989407420158386, \"fp_rate\": 0.10105923563241959, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.37512198090553284, \"recall\": 0.999541163444519, \"specificity\": 0.8989407420158386, \"npv\": 0.9999690055847168, \"accuracy\": 0.9046972990036011, \"f1\": 0.5455152552276806, \"f2\": 0.7498909875381543, \"f0_5\": 0.4286820078192648, \"p4\": 0.6921960161826924, \"phi\": 0.5805277664855032}, {\"truth_threshold\": -16.287183955103536, \"match_probability\": 1.2504422924977551e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97077.0, \"fp\": 10642.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9012058973312378, \"fp_rate\": 0.09879408776760101, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.38045060634613037, \"recall\": 0.999541163444519, \"specificity\": 0.9012058973312378, \"npv\": 0.9999691247940063, \"accuracy\": 0.9068328142166138, \"f1\": 0.5511279780729497, \"f2\": 0.7541138729257542, \"f0_5\": 0.4342423517529171, \"p4\": 0.6970369844766983, \"phi\": 0.5853733249495244}, {\"truth_threshold\": -16.284776536745973, \"match_probability\": 1.2525306153751122e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97136.0, \"fp\": 10583.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9017536640167236, \"fp_rate\": 0.09824636578559875, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3817618787288666, \"recall\": 0.999541163444519, \"specificity\": 0.9017536640167236, \"npv\": 0.9999691247940063, \"accuracy\": 0.9073492288589478, \"f1\": 0.5525025363544133, \"f2\": 0.7551421308065634, \"f0_5\": 0.43560858552193044, \"p4\": 0.6982174726690844, \"phi\": 0.586559587864329}, {\"truth_threshold\": -16.26947705574166, \"match_probability\": 1.2658839535759256e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97151.0, \"fp\": 10568.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.901892900466919, \"fp_rate\": 0.09810711443424225, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.38209670782089233, \"recall\": 0.999541163444519, \"specificity\": 0.901892900466919, \"npv\": 0.9999691247940063, \"accuracy\": 0.9074804782867432, \"f1\": 0.5528530942007529, \"f2\": 0.7554039995376257, \"f0_5\": 0.4359573048699133, \"p4\": 0.6985182186482437, \"phi\": 0.5868621428535045}, {\"truth_threshold\": -16.262117238471966, \"match_probability\": 1.2723581980616393e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97214.0, \"fp\": 10505.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9024777412414551, \"fp_rate\": 0.09752225875854492, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.38350939750671387, \"recall\": 0.999541163444519, \"specificity\": 0.9024777412414551, \"npv\": 0.9999691247940063, \"accuracy\": 0.9080318808555603, \"f1\": 0.5543303079141573, \"f2\": 0.7565058344137803, \"f0_5\": 0.4374280435888511, \"p4\": 0.6997841154346185, \"phi\": 0.5881367635121785}, {\"truth_threshold\": -16.25894054958359, \"match_probability\": 1.2751628710149441e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97217.0, \"fp\": 10502.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9025055766105652, \"fp_rate\": 0.09749440848827362, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3835769295692444, \"recall\": 0.999541163444519, \"specificity\": 0.9025055766105652, \"npv\": 0.9999691247940063, \"accuracy\": 0.9080581665039062, \"f1\": 0.5544008483563097, \"f2\": 0.7565583829215773, \"f0_5\": 0.4374983263262191, \"p4\": 0.6998445078460365, \"phi\": 0.5881976595524828}, {\"truth_threshold\": -16.255531747941976, \"match_probability\": 1.2781793511938729e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97225.0, \"fp\": 10494.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9025798439979553, \"fp_rate\": 0.09742014110088348, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3837571144104004, \"recall\": 0.999541163444519, \"specificity\": 0.9025798439979553, \"npv\": 0.9999691247940063, \"accuracy\": 0.9081281423568726, \"f1\": 0.5545890440022064, \"f2\": 0.7566985479724879, \"f0_5\": 0.43768585742224125, \"p4\": 0.7000056039857455, \"phi\": 0.5883600242615237}, {\"truth_threshold\": -16.252984236806306, \"match_probability\": 1.2804383254601537e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97243.0, \"fp\": 10476.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9027469754219055, \"fp_rate\": 0.09725303947925568, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3841632008552551, \"recall\": 0.999541163444519, \"specificity\": 0.9027469754219055, \"npv\": 0.9999691247940063, \"accuracy\": 0.9082856774330139, \"f1\": 0.555012951717695, \"f2\": 0.757014109306582, \"f0_5\": 0.4381083907645276, \"p4\": 0.7003683348800802, \"phi\": 0.5887257835462919}, {\"truth_threshold\": -16.223945552184745, \"match_probability\": 1.306471880676382e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97254.0, \"fp\": 10465.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9028490781784058, \"fp_rate\": 0.09715092182159424, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3844117522239685, \"recall\": 0.999541163444519, \"specificity\": 0.9028490781784058, \"npv\": 0.9999691247940063, \"accuracy\": 0.908381998538971, \"f1\": 0.5552723256011556, \"f2\": 0.7572070819428995, \"f0_5\": 0.43836700743245055, \"p4\": 0.7005901842930217, \"phi\": 0.5889495822067655}, {\"truth_threshold\": -16.21689307035662, \"match_probability\": 1.3128739996204072e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97261.0, \"fp\": 10458.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9029140472412109, \"fp_rate\": 0.09708593785762787, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3845701217651367, \"recall\": 0.999541163444519, \"specificity\": 0.9029140472412109, \"npv\": 0.9999691843986511, \"accuracy\": 0.9084432721138, \"f1\": 0.5554375079682121, \"f2\": 0.7573299339436783, \"f0_5\": 0.4385317407059455, \"p4\": 0.7007314325726307, \"phi\": 0.5890920898821055}, {\"truth_threshold\": -16.210775955302196, \"match_probability\": 1.318452410183271e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97354.0, \"fp\": 10365.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9037774205207825, \"fp_rate\": 0.09622257947921753, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.38668638467788696, \"recall\": 0.999541163444519, \"specificity\": 0.9037774205207825, \"npv\": 0.9999691843986511, \"accuracy\": 0.909257173538208, \"f1\": 0.5576414369826777, \"f2\": 0.7589659017002695, \"f0_5\": 0.44073214815614126, \"p4\": 0.702613302029603, \"phi\": 0.5909933533243553}, {\"truth_threshold\": -16.167720576417356, \"match_probability\": 1.3583924075897782e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97359.0, \"fp\": 10360.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9038238525390625, \"fp_rate\": 0.0961761623620987, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3868008255958557, \"recall\": 0.999541163444519, \"specificity\": 0.9038238525390625, \"npv\": 0.9999691843986511, \"accuracy\": 0.9093009829521179, \"f1\": 0.5577604233346136, \"f2\": 0.7590540571933003, \"f0_5\": 0.4408510753123398, \"p4\": 0.7027147571035424, \"phi\": 0.5910960051282963}, {\"truth_threshold\": -16.162422343550492, \"match_probability\": 1.3633901461687115e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97508.0, \"fp\": 10211.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9052070379257202, \"fp_rate\": 0.0947929322719574, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.39024245738983154, \"recall\": 0.999541163444519, \"specificity\": 0.9052070379257202, \"npv\": 0.9999692440032959, \"accuracy\": 0.9106050133705139, \"f1\": 0.5613296684418485, \"f2\": 0.7616905217026435, \"f0_5\": 0.44442479801964035, \"p4\": 0.7057512895413124, \"phi\": 0.5941744679512545}, {\"truth_threshold\": -16.150873959828807, \"match_probability\": 1.3743473619277368e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97525.0, \"fp\": 10194.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9053648710250854, \"fp_rate\": 0.09463511407375336, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3906390070915222, \"recall\": 0.999541163444519, \"specificity\": 0.9053648710250854, \"npv\": 0.9999692440032959, \"accuracy\": 0.9107538461685181, \"f1\": 0.5617398031546826, \"f2\": 0.761992490846762, \"f0_5\": 0.4448362240313666, \"p4\": 0.7060993673138989, \"phi\": 0.5945281854741076}, {\"truth_threshold\": -16.14148339199277, \"match_probability\": 1.3833221046741506e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97715.0, \"fp\": 10004.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9071287512779236, \"fp_rate\": 0.09287126362323761, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.39512667059898376, \"recall\": 0.999541163444519, \"specificity\": 0.9071287512779236, \"npv\": 0.9999693036079407, \"accuracy\": 0.9124167561531067, \"f1\": 0.5663647787840708, \"f2\": 0.7653838045489681, \"f0_5\": 0.44948689025229044, \"p4\": 0.7100125660880847, \"phi\": 0.5985161987215751}, {\"truth_threshold\": -16.13750701938637, \"match_probability\": 1.3871400391257763e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97720.0, \"fp\": 9999.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9071751236915588, \"fp_rate\": 0.09282484650611877, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.39524614810943604, \"recall\": 0.999541163444519, \"specificity\": 0.9071751236915588, \"npv\": 0.9999693036079407, \"accuracy\": 0.9124605059623718, \"f1\": 0.566487517337032, \"f2\": 0.765473457339643, \"f0_5\": 0.449610589756997, \"p4\": 0.7101161165975716, \"phi\": 0.5986219736930652}, {\"truth_threshold\": -16.132773443300923, \"match_probability\": 1.3916987469220266e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97722.0, \"fp\": 9997.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9071937203407288, \"fp_rate\": 0.09280627965927124, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3952939808368683, \"recall\": 0.999541163444519, \"specificity\": 0.9071937203407288, \"npv\": 0.9999693036079407, \"accuracy\": 0.9124780297279358, \"f1\": 0.5665366276549632, \"f2\": 0.7655093243369882, \"f0_5\": 0.4496600886246663, \"p4\": 0.7101575450552849, \"phi\": 0.5986643563601339}, {\"truth_threshold\": -16.125958635664684, \"match_probability\": 1.3982881239938844e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97726.0, \"fp\": 9993.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9072308540344238, \"fp_rate\": 0.09276914596557617, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3953896462917328, \"recall\": 0.999541163444519, \"specificity\": 0.9072308540344238, \"npv\": 0.9999693036079407, \"accuracy\": 0.912513017654419, \"f1\": 0.5666348738402844, \"f2\": 0.76558106841612, \"f0_5\": 0.4497591190640055, \"p4\": 0.7102404161247549, \"phi\": 0.5987490234495968}, {\"truth_threshold\": -16.12143702583365, \"match_probability\": 1.4026773694743402e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97845.0, \"fp\": 9874.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9083355665206909, \"fp_rate\": 0.09166442602872849, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3982570469379425, \"recall\": 0.999541163444519, \"specificity\": 0.9083355665206909, \"npv\": 0.9999693632125854, \"accuracy\": 0.9135545492172241, \"f1\": 0.5695733647099839, \"f2\": 0.7677216230821644, \"f0_5\": 0.4527253581622191, \"p4\": 0.7127144937188781, \"phi\": 0.6012823599513445}, {\"truth_threshold\": -16.121225059579235, \"match_probability\": 1.4028834684288341e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 97866.0, \"fp\": 9853.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9085305333137512, \"fp_rate\": 0.09146947413682938, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.3987673819065094, \"recall\": 0.999541163444519, \"specificity\": 0.9085305333137512, \"npv\": 0.9999693632125854, \"accuracy\": 0.9137383103370667, \"f1\": 0.5700950885457559, \"f2\": 0.7681006111894687, \"f0_5\": 0.4532528783465113, \"p4\": 0.7131528429822956, \"phi\": 0.6017320991989749}, {\"truth_threshold\": -16.103148246186336, \"match_probability\": 1.4205717823158048e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98228.0, \"fp\": 9491.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9118911027908325, \"fp_rate\": 0.08810887485742569, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4077748656272888, \"recall\": 0.999541163444519, \"specificity\": 0.9118911027908325, \"npv\": 0.999969482421875, \"accuracy\": 0.9169065952301025, \"f1\": 0.5792412692784967, \"f2\": 0.7746929678979563, \"f0_5\": 0.46254352934514875, \"p4\": 0.7207927557716238, \"phi\": 0.6096157400947039}, {\"truth_threshold\": -16.092192237029654, \"match_probability\": 1.431400696251331e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98229.0, \"fp\": 9490.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9119004011154175, \"fp_rate\": 0.08809959143400192, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4078003168106079, \"recall\": 0.999541163444519, \"specificity\": 0.9119004011154175, \"npv\": 0.999969482421875, \"accuracy\": 0.9169153571128845, \"f1\": 0.579266941452821, \"f2\": 0.7747113355620362, \"f0_5\": 0.46256972167954924, \"p4\": 0.7208140818477116, \"phi\": 0.6096378574455779}, {\"truth_threshold\": -16.069700705667703, \"match_probability\": 1.4538906782435793e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98238.0, \"fp\": 9481.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9119839668273926, \"fp_rate\": 0.08801604062318802, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4080294668674469, \"recall\": 0.999541163444519, \"specificity\": 0.9119839668273926, \"npv\": 0.999969482421875, \"accuracy\": 0.9169941544532776, \"f1\": 0.5794980934645739, \"f2\": 0.7748766837412255, \"f0_5\": 0.46280558624401574, \"p4\": 0.7210060720060308, \"phi\": 0.6098370625477484}, {\"truth_threshold\": -16.06288666999958, \"match_probability\": 1.4607737340346802e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98239.0, \"fp\": 9480.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9119932651519775, \"fp_rate\": 0.08800675719976425, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4080549478530884, \"recall\": 0.999541163444519, \"specificity\": 0.9119932651519775, \"npv\": 0.999969482421875, \"accuracy\": 0.9170029163360596, \"f1\": 0.5795237884095242, \"f2\": 0.7748950601181018, \"f0_5\": 0.46283180826652315, \"p4\": 0.7210274104115446, \"phi\": 0.609859260293293}, {\"truth_threshold\": -16.054020550742433, \"match_probability\": 1.4697784654806345e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98241.0, \"fp\": 9478.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9120118021965027, \"fp_rate\": 0.08798819035291672, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.40810590982437134, \"recall\": 0.999541163444519, \"specificity\": 0.9120118021965027, \"npv\": 0.999969482421875, \"accuracy\": 0.9170203804969788, \"f1\": 0.5795751851359141, \"f2\": 0.7749318154867781, \"f0_5\": 0.46288426122680265, \"p4\": 0.7210700909232857, \"phi\": 0.609903540072188}, {\"truth_threshold\": -16.05031128310895, \"match_probability\": 1.4735621727676582e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98243.0, \"fp\": 9476.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9120303988456726, \"fp_rate\": 0.08796962350606918, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4081569015979767, \"recall\": 0.999541163444519, \"specificity\": 0.9120303988456726, \"npv\": 0.999969482421875, \"accuracy\": 0.9170379042625427, \"f1\": 0.5796265909796443, \"f2\": 0.7749685743424329, \"f0_5\": 0.46293672607747016, \"p4\": 0.7211127763700302, \"phi\": 0.6099478276976829}, {\"truth_threshold\": -16.024149549269744, \"match_probability\": 1.5005269983524653e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98256.0, \"fp\": 9463.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.912151038646698, \"fp_rate\": 0.08784893900156021, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.40848857164382935, \"recall\": 0.999541163444519, \"specificity\": 0.912151038646698, \"npv\": 0.999969482421875, \"accuracy\": 0.917151689529419, \"f1\": 0.5799609513667021, \"f2\": 0.7752075919335706, \"f0_5\": 0.46327803771444775, \"p4\": 0.7213903521241803, \"phi\": 0.6102360103454806}, {\"truth_threshold\": -16.01197613730251, \"match_probability\": 1.5132417707933465e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98281.0, \"fp\": 9438.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9123831391334534, \"fp_rate\": 0.08761685341596603, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4091278910636902, \"recall\": 0.999541163444519, \"specificity\": 0.9123831391334534, \"npv\": 0.999969482421875, \"accuracy\": 0.9173704981803894, \"f1\": 0.580605037537204, \"f2\": 0.7756676557863501, \"f0_5\": 0.4639358228027829, \"p4\": 0.7219247386574427, \"phi\": 0.6107911518801735}, {\"truth_threshold\": -15.99923422510562, \"match_probability\": 1.5266657422521782e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98282.0, \"fp\": 9437.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9123924374580383, \"fp_rate\": 0.08760756999254227, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4091535210609436, \"recall\": 0.999541163444519, \"specificity\": 0.9123924374580383, \"npv\": 0.999969482421875, \"accuracy\": 0.9173792600631714, \"f1\": 0.5806308307418925, \"f2\": 0.7756860696989839, \"f0_5\": 0.4639621730610854, \"p4\": 0.7219461302024764, \"phi\": 0.6108133734379073}, {\"truth_threshold\": -15.994500649020173, \"match_probability\": 1.5316829813792035e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98306.0, \"fp\": 9413.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9126152396202087, \"fp_rate\": 0.08738476783037186, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4097692370414734, \"recall\": 0.999541163444519, \"specificity\": 0.9126152396202087, \"npv\": 0.999969482421875, \"accuracy\": 0.9175893068313599, \"f1\": 0.5812505559014498, \"f2\": 0.7761282660332541, \"f0_5\": 0.4645954784586947, \"p4\": 0.7224598989873237, \"phi\": 0.6113475274127584}, {\"truth_threshold\": -15.972464285018422, \"match_probability\": 1.5552578106456853e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98410.0, \"fp\": 9309.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9135807156562805, \"fp_rate\": 0.08641929179430008, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.41245898604393005, \"recall\": 0.999541163444519, \"specificity\": 0.9135807156562805, \"npv\": 0.9999695420265198, \"accuracy\": 0.9184995293617249, \"f1\": 0.5839513895094273, \"f2\": 0.7780502905038575, \"f0_5\": 0.46735989930486027, \"p4\": 0.7246945084066102, \"phi\": 0.6136753613286668}, {\"truth_threshold\": -15.969433932388602, \"match_probability\": 1.558527981513787e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98793.0, \"fp\": 8926.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9171362519264221, \"fp_rate\": 0.08286374807357788, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4226764142513275, \"recall\": 0.999541163444519, \"specificity\": 0.9171362519264221, \"npv\": 0.9999696612358093, \"accuracy\": 0.921851634979248, \"f1\": 0.5941179144506569, \"f2\": 0.7852113522216615, \"f0_5\": 0.47783042321078645, \"p4\": 0.7330416294807343, \"phi\": 0.6224388092021562}, {\"truth_threshold\": -15.9656447224364, \"match_probability\": 1.5626267407239326e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98799.0, \"fp\": 8920.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9171919822692871, \"fp_rate\": 0.08280804753303528, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42284050583839417, \"recall\": 0.999541163444519, \"specificity\": 0.9171919822692871, \"npv\": 0.9999696612358093, \"accuracy\": 0.9219041466712952, \"f1\": 0.5942799981812394, \"f2\": 0.7853245848054414, \"f0_5\": 0.47799818602065597, \"p4\": 0.7331738886346115, \"phi\": 0.622578548323195}, {\"truth_threshold\": -15.965467826470592, \"match_probability\": 1.562818350860425e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98800.0, \"fp\": 8919.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9172012209892273, \"fp_rate\": 0.08279876410961151, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42286786437034607, \"recall\": 0.999541163444519, \"specificity\": 0.9172012209892273, \"npv\": 0.9999696612358093, \"accuracy\": 0.9219129085540771, \"f1\": 0.5943070207348127, \"f2\": 0.7853434600778734, \"f0_5\": 0.47802615794247594, \"p4\": 0.7331959363619818, \"phi\": 0.622601835389001}, {\"truth_threshold\": -15.964112809710093, \"match_probability\": 1.5642868571230093e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98803.0, \"fp\": 8916.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9172291159629822, \"fp_rate\": 0.08277091383934021, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42294996976852417, \"recall\": 0.999541163444519, \"specificity\": 0.9172291159629822, \"npv\": 0.9999696612358093, \"accuracy\": 0.9219391345977783, \"f1\": 0.5943881031424804, \"f2\": 0.7854000913395669, \"f0_5\": 0.4781100933540136, \"p4\": 0.7332620873207785, \"phi\": 0.6226717711666983}, {\"truth_threshold\": -15.96284844185861, \"match_probability\": 1.5656583666312978e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98806.0, \"fp\": 8913.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9172569513320923, \"fp_rate\": 0.08274306356906891, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42303210496902466, \"recall\": 0.999541163444519, \"specificity\": 0.9172569513320923, \"npv\": 0.9999696612358093, \"accuracy\": 0.9219654202461243, \"f1\": 0.594469207677613, \"f2\": 0.7854567307692307, \"f0_5\": 0.47819405824674377, \"p4\": 0.7333282499470226, \"phi\": 0.6227416645216077}, {\"truth_threshold\": -15.955971466083067, \"match_probability\": 1.573139176652432e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98823.0, \"fp\": 8896.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9174147844314575, \"fp_rate\": 0.08258524537086487, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42349815368652344, \"recall\": 0.999541163444519, \"specificity\": 0.9174147844314575, \"npv\": 0.9999696612358093, \"accuracy\": 0.9221141934394836, \"f1\": 0.5949292184441713, \"f2\": 0.7857778419065483, \"f0_5\": 0.47867041692303186, \"p4\": 0.7337033920310444, \"phi\": 0.6231382770328694}, {\"truth_threshold\": -15.91584010112696, \"match_probability\": 1.6175126973932145e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98828.0, \"fp\": 8891.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9174611568450928, \"fp_rate\": 0.08253882825374603, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42363542318344116, \"recall\": 0.999541163444519, \"specificity\": 0.9174611568450928, \"npv\": 0.9999696612358093, \"accuracy\": 0.9221579432487488, \"f1\": 0.5950646512474959, \"f2\": 0.7858723363317139, \"f0_5\": 0.47881070308607604, \"p4\": 0.7338137993406265, \"phi\": 0.6232550532846927}, {\"truth_threshold\": -15.899547159087259, \"match_probability\": 1.6358831648525177e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98973.0, \"fp\": 8746.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9188072681427002, \"fp_rate\": 0.0811927318572998, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42765524983406067, \"recall\": 0.999541163444519, \"specificity\": 0.9188072681427002, \"npv\": 0.9999696612358093, \"accuracy\": 0.9234269857406616, \"f1\": 0.5990192034465375, \"f2\": 0.7886225955156517, \"f0_5\": 0.48291507788714494, \"p4\": 0.7370297997132342, \"phi\": 0.6266647234161276}, {\"truth_threshold\": -15.874472613552577, \"match_probability\": 1.6645634289857705e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98977.0, \"fp\": 8742.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9188444018363953, \"fp_rate\": 0.08115559816360474, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.42776721715927124, \"recall\": 0.999541163444519, \"specificity\": 0.9188444018363953, \"npv\": 0.9999696612358093, \"accuracy\": 0.9234620332717896, \"f1\": 0.5991290396516159, \"f2\": 0.7886987375992662, \"f0_5\": 0.48302929958903706, \"p4\": 0.7371189075416622, \"phi\": 0.6267594595064426}, {\"truth_threshold\": -15.861375472800036, \"match_probability\": 1.679743290762845e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98988.0, \"fp\": 8731.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9189465045928955, \"fp_rate\": 0.0810534805059433, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4280754625797272, \"recall\": 0.999541163444519, \"specificity\": 0.9189465045928955, \"npv\": 0.9999697208404541, \"accuracy\": 0.9235582947731018, \"f1\": 0.599431297009723, \"f2\": 0.7889082041624415, \"f0_5\": 0.48334368805656636, \"p4\": 0.7373640627144257, \"phi\": 0.6270201192815087}, {\"truth_threshold\": -15.858190653745442, \"match_probability\": 1.68345543873099e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 98995.0, \"fp\": 8724.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9190114736557007, \"fp_rate\": 0.08098849654197693, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4282718300819397, \"recall\": 0.999541163444519, \"specificity\": 0.9190114736557007, \"npv\": 0.9999697208404541, \"accuracy\": 0.9236195683479309, \"f1\": 0.5996238014405653, \"f2\": 0.7890415590060612, \"f0_5\": 0.4835439666143783, \"p4\": 0.7375201535709509, \"phi\": 0.6271861159360302}, {\"truth_threshold\": -15.84049424866313, \"match_probability\": 1.7042318738785298e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99271.0, \"fp\": 8448.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9215736985206604, \"fp_rate\": 0.07842627912759781, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.43616098165512085, \"recall\": 0.999541163444519, \"specificity\": 0.9215736985206604, \"npv\": 0.9999697804450989, \"accuracy\": 0.9260351657867432, \"f1\": 0.607313786534083, \"f2\": 0.7943357238361493, \"f0_5\": 0.491575146682714, \"p4\": 0.7437265114307018, \"phi\": 0.6338190190846862}, {\"truth_threshold\": -15.833377940934987, \"match_probability\": 1.7126588735648894e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99274.0, \"fp\": 8445.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9216015934944153, \"fp_rate\": 0.07839842885732651, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4362483322620392, \"recall\": 0.999541163444519, \"specificity\": 0.9216015934944153, \"npv\": 0.9999697804450989, \"accuracy\": 0.9260614514350891, \"f1\": 0.607398457105679, \"f2\": 0.7943936594379072, \"f0_5\": 0.4916639080321406, \"p4\": 0.7437945329739637, \"phi\": 0.6338920409380306}, {\"truth_threshold\": -15.828945864941444, \"match_probability\": 1.717928299834105e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99583.0, \"fp\": 8136.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9244701266288757, \"fp_rate\": 0.07552985101938248, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4454365670681, \"recall\": 0.999541163444519, \"specificity\": 0.9244701266288757, \"npv\": 0.9999698996543884, \"accuracy\": 0.9287658333778381, \"f1\": 0.6162478193219859, \"f2\": 0.8004066335154202, \"f0_5\": 0.500981263990678, \"p4\": 0.750866536483257, \"phi\": 0.6415299134735961}, {\"truth_threshold\": -15.785508755961576, \"match_probability\": 1.7704378210723375e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99703.0, \"fp\": 8016.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9255841374397278, \"fp_rate\": 0.07441584020853043, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4491100311279297, \"recall\": 0.999541163444519, \"specificity\": 0.9255841374397278, \"npv\": 0.9999698996543884, \"accuracy\": 0.9298161268234253, \"f1\": 0.619754374318365, \"f2\": 0.8027663808564479, \"f0_5\": 0.5046955608414939, \"p4\": 0.7536485348740805, \"phi\": 0.6445581372450409}, {\"truth_threshold\": -15.7756624430787, \"match_probability\": 1.7825620712937636e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99719.0, \"fp\": 8000.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9257326722145081, \"fp_rate\": 0.07426730543375015, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4496043920516968, \"recall\": 0.999541163444519, \"specificity\": 0.9257326722145081, \"npv\": 0.9999698996543884, \"accuracy\": 0.9299561381340027, \"f1\": 0.6202249323779243, \"f2\": 0.8030820655246147, \"f0_5\": 0.5051949658307306, \"p4\": 0.7540209926809887, \"phi\": 0.6449646308253567}, {\"truth_threshold\": -15.772822748528196, \"match_probability\": 1.7860741276841682e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99767.0, \"fp\": 7952.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9261782765388489, \"fp_rate\": 0.07382170110940933, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4510940909385681, \"recall\": 0.999541163444519, \"specificity\": 0.9261782765388489, \"npv\": 0.9999699592590332, \"accuracy\": 0.9303762316703796, \"f1\": 0.621640903686088, \"f2\": 0.8040306109894436, \"f0_5\": 0.5066991284930062, \"p4\": 0.755140530672426, \"phi\": 0.6461878259191227}, {\"truth_threshold\": -15.770203363916213, \"match_probability\": 1.7893198454877883e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99768.0, \"fp\": 7951.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9261875748634338, \"fp_rate\": 0.07381241768598557, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.45112523436546326, \"recall\": 0.999541163444519, \"specificity\": 0.9261875748634338, \"npv\": 0.9999699592590332, \"accuracy\": 0.9303849935531616, \"f1\": 0.6216704718417048, \"f2\": 0.8040503961809145, \"f0_5\": 0.5067305604664868, \"p4\": 0.7551638889750035, \"phi\": 0.6462133613925363}, {\"truth_threshold\": -15.74244003406969, \"match_probability\": 1.8240864733982633e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99776.0, \"fp\": 7943.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.926261842250824, \"fp_rate\": 0.07373815029859543, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.45137450098991394, \"recall\": 0.999541163444519, \"specificity\": 0.926261842250824, \"npv\": 0.9999699592590332, \"accuracy\": 0.9304550290107727, \"f1\": 0.6219071183859917, \"f2\": 0.8042087127738125, \"f0_5\": 0.5069821567106284, \"p4\": 0.7553508063165671, \"phi\": 0.6464178627141713}, {\"truth_threshold\": -15.731466243186379, \"match_probability\": 1.8380139471456797e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99783.0, \"fp\": 7936.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9263268113136292, \"fp_rate\": 0.07367316633462906, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4515928328037262, \"recall\": 0.999541163444519, \"specificity\": 0.9263268113136292, \"npv\": 0.9999699592590332, \"accuracy\": 0.9305163025856018, \"f1\": 0.6221143319529725, \"f2\": 0.8043472909435542, \"f0_5\": 0.5072025084598429, \"p4\": 0.7555144332863695, \"phi\": 0.6465968861154381}, {\"truth_threshold\": -15.722469520107527, \"match_probability\": 1.8495115003961827e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99854.0, \"fp\": 7865.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9269859790802002, \"fp_rate\": 0.0730140432715416, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4538194537162781, \"recall\": 0.999541163444519, \"specificity\": 0.9269859790802002, \"npv\": 0.9999699592590332, \"accuracy\": 0.9311376810073853, \"f1\": 0.624223899130767, \"f2\": 0.8057555730913395, \"f0_5\": 0.5094483769372291, \"p4\": 0.7571780071425769, \"phi\": 0.648419762948979}, {\"truth_threshold\": -15.720413727739691, \"match_probability\": 1.8521488224536795e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99859.0, \"fp\": 7860.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9270323514938354, \"fp_rate\": 0.07296762615442276, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4539770781993866, \"recall\": 0.999541163444519, \"specificity\": 0.9270323514938354, \"npv\": 0.9999699592590332, \"accuracy\": 0.9311814308166504, \"f1\": 0.6243729995700569, \"f2\": 0.805854933780551, \"f0_5\": 0.509607286565395, \"p4\": 0.7572954305018984, \"phi\": 0.6485486324442686}, {\"truth_threshold\": -15.71554145064113, \"match_probability\": 1.8584143667790443e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 99862.0, \"fp\": 7857.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9270602464675903, \"fp_rate\": 0.07293977588415146, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.45407170057296753, \"recall\": 0.999541163444519, \"specificity\": 0.9270602464675903, \"npv\": 0.9999699592590332, \"accuracy\": 0.9312077164649963, \"f1\": 0.6244624940277114, \"f2\": 0.8059145619573796, \"f0_5\": 0.5097026799363554, \"p4\": 0.7573659016284428, \"phi\": 0.6486259466549125}, {\"truth_threshold\": -15.714963366579273, \"match_probability\": 1.8591591638326626e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100075.0, \"fp\": 7644.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9290375709533691, \"fp_rate\": 0.07096241414546967, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.46089285612106323, \"recall\": 0.999541163444519, \"specificity\": 0.9290375709533691, \"npv\": 0.999970018863678, \"accuracy\": 0.9330719113349915, \"f1\": 0.6308828498334701, \"f2\": 0.8101708363293745, \"f0_5\": 0.5165681221740918, \"p4\": 0.7624023763041974, \"phi\": 0.6541769244516452}, {\"truth_threshold\": -15.71092113638584, \"match_probability\": 1.8643754755448923e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100090.0, \"fp\": 7629.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9291768670082092, \"fp_rate\": 0.07082316279411316, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4613809585571289, \"recall\": 0.999541163444519, \"specificity\": 0.9291768670082092, \"npv\": 0.999970018863678, \"accuracy\": 0.9332032203674316, \"f1\": 0.6313399671529321, \"f2\": 0.8104722690743129, \"f0_5\": 0.5170585815109029, \"p4\": 0.7627595299585618, \"phi\": 0.6545723695500848}, {\"truth_threshold\": -15.702221454382382, \"match_probability\": 1.875651711775498e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100151.0, \"fp\": 7568.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9297431111335754, \"fp_rate\": 0.07025687396526337, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.46337658166885376, \"recall\": 0.999541163444519, \"specificity\": 0.9297431111335754, \"npv\": 0.999970018863678, \"accuracy\": 0.9337370991706848, \"f1\": 0.6332057555351001, \"f2\": 0.8117004098869706, \"f0_5\": 0.5190627482128674, \"p4\": 0.7642153360759122, \"phi\": 0.6561864947344481}, {\"truth_threshold\": -15.696829842404995, \"match_probability\": 1.8826743433206136e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100188.0, \"fp\": 7531.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.930086612701416, \"fp_rate\": 0.06991338729858398, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4645954668521881, \"recall\": 0.999541163444519, \"specificity\": 0.930086612701416, \"npv\": 0.9999700784683228, \"accuracy\": 0.9340609312057495, \"f1\": 0.6343428460493108, \"f2\": 0.8124471629618579, \"f0_5\": 0.520285978153562, \"p4\": 0.7651010198554148, \"phi\": 0.6571704600360274}, {\"truth_threshold\": -15.693306284195142, \"match_probability\": 1.887278015341185e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100434.0, \"fp\": 7285.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9323703050613403, \"fp_rate\": 0.06762966513633728, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.47286540269851685, \"recall\": 0.999541163444519, \"specificity\": 0.9323703050613403, \"npv\": 0.9999701380729675, \"accuracy\": 0.9362139701843262, \"f1\": 0.6420080558011593, \"f2\": 0.8174472130491344, \"f0_5\": 0.528567731081562, \"p4\": 0.771041118122639, \"phi\": 0.6638078246612488}, {\"truth_threshold\": -15.67715473775081, \"match_probability\": 1.9085251554543205e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100484.0, \"fp\": 7235.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9328345060348511, \"fp_rate\": 0.06716549396514893, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4745824337005615, \"recall\": 0.999541163444519, \"specificity\": 0.9328345060348511, \"npv\": 0.9999701380729675, \"accuracy\": 0.9366515874862671, \"f1\": 0.6435887335040378, \"f2\": 0.8184710184860478, \"f0_5\": 0.5302833587588043, \"p4\": 0.7722595166263089, \"phi\": 0.6651775970124659}, {\"truth_threshold\": -15.675325838211153, \"match_probability\": 1.9109460741644252e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100487.0, \"fp\": 7232.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9328623414039612, \"fp_rate\": 0.06713764369487762, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4746858477592468, \"recall\": 0.999541163444519, \"specificity\": 0.9328623414039612, \"npv\": 0.9999701380729675, \"accuracy\": 0.9366778135299683, \"f1\": 0.6436838217187885, \"f2\": 0.8185325283699492, \"f0_5\": 0.5303866506509106, \"p4\": 0.7723327404793779, \"phi\": 0.6652600434166447}, {\"truth_threshold\": -15.66396763189776, \"match_probability\": 1.9260498657061026e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100488.0, \"fp\": 7231.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9328716397285461, \"fp_rate\": 0.06712836027145386, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4747203290462494, \"recall\": 0.999541163444519, \"specificity\": 0.9328716397285461, \"npv\": 0.9999701380729675, \"accuracy\": 0.9366865754127502, \"f1\": 0.643715524034673, \"f2\": 0.8185530337191242, \"f0_5\": 0.5304210902243434, \"p4\": 0.7723571514529073, \"phi\": 0.6652875096521799}, {\"truth_threshold\": -15.643716627549038, \"match_probability\": 1.9532757953024405e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100495.0, \"fp\": 7224.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9329366087913513, \"fp_rate\": 0.06706337630748749, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4749618470668793, \"recall\": 0.999541163444519, \"specificity\": 0.9329366087913513, \"npv\": 0.9999701380729675, \"accuracy\": 0.9367478489875793, \"f1\": 0.6439375277134551, \"f2\": 0.8186965999348551, \"f0_5\": 0.5306622925260662, \"p4\": 0.7725280705972049, \"phi\": 0.6654799181689381}, {\"truth_threshold\": -15.638983051463589, \"match_probability\": 1.9596950195823838e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100497.0, \"fp\": 7222.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9329552054405212, \"fp_rate\": 0.06704480946063995, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.47503089904785156, \"recall\": 0.999541163444519, \"specificity\": 0.9329552054405212, \"npv\": 0.9999701380729675, \"accuracy\": 0.9367653727531433, \"f1\": 0.6440009854644001, \"f2\": 0.8187376281039365, \"f0_5\": 0.5307312477666244, \"p4\": 0.772576918248613, \"phi\": 0.6655348992392817}, {\"truth_threshold\": -15.606863853003894, \"match_probability\": 2.003812767665532e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100500.0, \"fp\": 7219.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9329830408096313, \"fp_rate\": 0.06701695919036865, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4751344919204712, \"recall\": 0.999541163444519, \"specificity\": 0.9329830408096313, \"npv\": 0.9999701380729675, \"accuracy\": 0.9367915987968445, \"f1\": 0.6440961955450424, \"f2\": 0.8187991780684609, \"f0_5\": 0.5308347142346558, \"p4\": 0.7726502010717834, \"phi\": 0.6656174571699763}, {\"truth_threshold\": -15.59386446660658, \"match_probability\": 2.021949320442715e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100519.0, \"fp\": 7200.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9331594109535217, \"fp_rate\": 0.06684057414531708, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4757917821407318, \"recall\": 0.999541163444519, \"specificity\": 0.9331594109535217, \"npv\": 0.9999701380729675, \"accuracy\": 0.9369578957557678, \"f1\": 0.6446998470872589, \"f2\": 0.8191892095168852, \"f0_5\": 0.531490939848401, \"p4\": 0.7731146420319832, \"phi\": 0.6661407069063571}, {\"truth_threshold\": -15.584196725826777, \"match_probability\": 2.0355439643521134e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100521.0, \"fp\": 7198.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9331780076026917, \"fp_rate\": 0.06682200729846954, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4758610725402832, \"recall\": 0.999541163444519, \"specificity\": 0.9331780076026917, \"npv\": 0.9999701380729675, \"accuracy\": 0.9369754195213318, \"f1\": 0.6447634551822801, \"f2\": 0.8192302870753416, \"f0_5\": 0.5315601106230682, \"p4\": 0.7731635623706439, \"phi\": 0.6661958256063711}, {\"truth_threshold\": -15.577459842829336, \"match_probability\": 2.0450712781029233e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100534.0, \"fp\": 7185.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.933298647403717, \"fp_rate\": 0.06670132279396057, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.47631195187568665, \"recall\": 0.999541163444519, \"specificity\": 0.933298647403717, \"npv\": 0.9999701380729675, \"accuracy\": 0.937089204788208, \"f1\": 0.6451772139401718, \"f2\": 0.8194973916532905, \"f0_5\": 0.5320101598879807, \"p4\": 0.7734816924482502, \"phi\": 0.6665545073955033}, {\"truth_threshold\": -15.553270021742252, \"match_probability\": 2.0796495713353106e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100537.0, \"fp\": 7182.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9333265423774719, \"fp_rate\": 0.06667347252368927, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.47641614079475403, \"recall\": 0.999541163444519, \"specificity\": 0.9333265423774719, \"npv\": 0.9999701380729675, \"accuracy\": 0.9371154308319092, \"f1\": 0.6452727721550234, \"f2\": 0.8195590559080991, \"f0_5\": 0.5321141256554734, \"p4\": 0.7735551435023097, \"phi\": 0.6666373841883688}, {\"truth_threshold\": -15.552544518665215, \"match_probability\": 2.0806956276075904e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100575.0, \"fp\": 7144.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9336792826652527, \"fp_rate\": 0.06632070243358612, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4777396023273468, \"recall\": 0.999541163444519, \"specificity\": 0.9336792826652527, \"npv\": 0.9999701976776123, \"accuracy\": 0.9374480247497559, \"f1\": 0.6464856309046841, \"f2\": 0.8203409404735006, \"f0_5\": 0.533434551212982, \"p4\": 0.7744867076718399, \"phi\": 0.6676889743729097}, {\"truth_threshold\": -15.547810942579765, \"match_probability\": 2.0875335942936056e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100589.0, \"fp\": 7130.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9338092803955078, \"fp_rate\": 0.06619073450565338, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4782290458679199, \"recall\": 0.999541163444519, \"specificity\": 0.9338092803955078, \"npv\": 0.9999701976776123, \"accuracy\": 0.9375705718994141, \"f1\": 0.6469336237192496, \"f2\": 0.8206293794108044, \"f0_5\": 0.5339226772116736, \"p4\": 0.7748304697881907, \"phi\": 0.6680774436668706}, {\"truth_threshold\": -15.541483625372765, \"match_probability\": 2.0967089337355402e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100639.0, \"fp\": 7080.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9342734217643738, \"fp_rate\": 0.06572656333446503, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4799852967262268, \"recall\": 0.999541163444519, \"specificity\": 0.9342734217643738, \"npv\": 0.9999701976776123, \"accuracy\": 0.938008189201355, \"f1\": 0.6485386791048479, \"f2\": 0.8216611763522519, \"f0_5\": 0.5356733007639595, \"p4\": 0.7760606357375464, \"phi\": 0.6694695559894828}, {\"truth_threshold\": -15.536262558858079, \"match_probability\": 2.104310442131592e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100641.0, \"fp\": 7078.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9342920184135437, \"fp_rate\": 0.06570799648761749, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4800558388233185, \"recall\": 0.999541163444519, \"specificity\": 0.9342920184135437, \"npv\": 0.9999701976776123, \"accuracy\": 0.9380256533622742, \"f1\": 0.6486030469951863, \"f2\": 0.8217025022004275, \"f0_5\": 0.5357435645187736, \"p4\": 0.7761099219730421, \"phi\": 0.6695253718955486}, {\"truth_threshold\": -15.528686861879946, \"match_probability\": 2.1153891582489497e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100877.0, \"fp\": 6842.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9364829063415527, \"fp_rate\": 0.06351711601018906, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.4885250926017761, \"recall\": 0.999541163444519, \"specificity\": 0.9364829063415527, \"npv\": 0.9999702572822571, \"accuracy\": 0.9400911927223206, \"f1\": 0.6562892292242029, \"f2\": 0.8266083128842115, \"f0_5\": 0.5441661392932086, \"p4\": 0.7819690769588412, \"phi\": 0.6761977559270216}, {\"truth_threshold\": -15.51345216937973, \"match_probability\": 2.137845303612786e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100878.0, \"fp\": 6841.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9364921450614929, \"fp_rate\": 0.06350783258676529, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.48856160044670105, \"recall\": 0.999541163444519, \"specificity\": 0.9364921450614929, \"npv\": 0.9999702572822571, \"accuracy\": 0.9400999546051025, \"f1\": 0.656322185397208, \"f2\": 0.8266292248532686, \"f0_5\": 0.544202391659172, \"p4\": 0.7819940883040933, \"phi\": 0.6762263768254203}, {\"truth_threshold\": -15.507796018014977, \"match_probability\": 2.146243094437969e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6535.0, \"tn\": 100879.0, \"fp\": 6840.0, \"fn\": 3.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.999541163444519, \"tn_rate\": 0.9365014433860779, \"fp_rate\": 0.06349854916334152, \"fn_rate\": 0.00045885590952821076, \"precision\": 0.48859813809394836, \"recall\": 0.999541163444519, \"specificity\": 0.9365014433860779, \"npv\": 0.9999702572822571, \"accuracy\": 0.9401087164878845, \"f1\": 0.656355144880229, \"f2\": 0.8266501378804362, \"f0_5\": 0.5442386488557247, \"p4\": 0.7820191012172901, \"phi\": 0.676255000791996}, {\"truth_threshold\": -15.487191924272954, \"match_probability\": 2.177114282954482e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101010.0, \"fp\": 6709.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9377175569534302, \"fp_rate\": 0.06228242069482803, \"fn_rate\": 0.000611807918176055, \"precision\": 0.4933927357196808, \"recall\": 0.9993882179260254, \"specificity\": 0.9377175569534302, \"npv\": 0.9999604225158691, \"accuracy\": 0.941246509552002, \"f1\": 0.66063394166119, \"f2\": 0.8292930574946059, \"f0_5\": 0.5489833641404805, \"p4\": 0.7852600515832133, \"phi\": 0.6799441440580245}, {\"truth_threshold\": -15.44635481782574, \"match_probability\": 2.239619032497441e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101018.0, \"fp\": 6701.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9377918243408203, \"fp_rate\": 0.0622081533074379, \"fn_rate\": 0.000611807918176055, \"precision\": 0.49369096755981445, \"recall\": 0.9993882179260254, \"specificity\": 0.9377918243408203, \"npv\": 0.9999604225158691, \"accuracy\": 0.9413164854049683, \"f1\": 0.6609012289485662, \"f2\": 0.8294614974483967, \"f0_5\": 0.5492787249066882, \"p4\": 0.7854618692293683, \"phi\": 0.6801766309300153}, {\"truth_threshold\": -15.430966948505565, \"match_probability\": 2.263634244939243e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101125.0, \"fp\": 6594.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.938785195350647, \"fp_rate\": 0.06121482700109482, \"fn_rate\": 0.000611807918176055, \"precision\": 0.4977148175239563, \"recall\": 0.9993882179260254, \"specificity\": 0.938785195350647, \"npv\": 0.9999604225158691, \"accuracy\": 0.9422529935836792, \"f1\": 0.6644971015966643, \"f2\": 0.8317209775967414, \"f0_5\": 0.553259949195597, \"p4\": 0.7881709876967269, \"phi\": 0.6833049370634489}, {\"truth_threshold\": -15.42752743607568, \"match_probability\": 2.2690372645817166e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101128.0, \"fp\": 6591.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9388130307197571, \"fp_rate\": 0.06118697673082352, \"fn_rate\": 0.000611807918176055, \"precision\": 0.49782857298851013, \"recall\": 0.9993882179260254, \"specificity\": 0.9388130307197571, \"npv\": 0.9999604225158691, \"accuracy\": 0.9422792196273804, \"f1\": 0.664598484463205, \"f2\": 0.8317845049265473, \"f0_5\": 0.553372404214235, \"p4\": 0.7882472082955571, \"phi\": 0.6833932100143122}, {\"truth_threshold\": -15.425456749384287, \"match_probability\": 2.2722962567723476e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101135.0, \"fp\": 6584.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9388779997825623, \"fp_rate\": 0.06112199276685715, \"fn_rate\": 0.000611807918176055, \"precision\": 0.49809423089027405, \"recall\": 0.9993882179260254, \"specificity\": 0.9388779997825623, \"npv\": 0.9999604225158691, \"accuracy\": 0.9423404932022095, \"f1\": 0.6648351648351648, \"f2\": 0.8319327731092437, \"f0_5\": 0.5536349771225216, \"p4\": 0.7884251125691347, \"phi\": 0.6835992045819564}, {\"truth_threshold\": -15.422280060495908, \"match_probability\": 2.2773050538195645e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101146.0, \"fp\": 6573.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9389801025390625, \"fp_rate\": 0.06101987510919571, \"fn_rate\": 0.000611807918176055, \"precision\": 0.49851223826408386, \"recall\": 0.9993882179260254, \"specificity\": 0.9389801025390625, \"npv\": 0.9999604821205139, \"accuracy\": 0.9424368143081665, \"f1\": 0.6652074319165182, \"f2\": 0.8321658727934996, \"f0_5\": 0.5540480955126683, \"p4\": 0.7887048355267826, \"phi\": 0.6839232576328577}, {\"truth_threshold\": -15.41852867991789, \"match_probability\": 2.283234206609128e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101196.0, \"fp\": 6523.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9394443035125732, \"fp_rate\": 0.060555703938007355, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5004212260246277, \"recall\": 0.9993882179260254, \"specificity\": 0.9394443035125732, \"npv\": 0.9999604821205139, \"accuracy\": 0.9428743720054626, \"f1\": 0.6669048226588415, \"f2\": 0.8332270652146191, \"f0_5\": 0.5559337031616921, \"p4\": 0.7899787595945815, \"phi\": 0.6854010213751843}, {\"truth_threshold\": -15.4139083656626, \"match_probability\": 2.2905579497310593e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101238.0, \"fp\": 6481.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9398341774940491, \"fp_rate\": 0.06016580015420914, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5020360946655273, \"recall\": 0.9993882179260254, \"specificity\": 0.9398341774940491, \"npv\": 0.9999604821205139, \"accuracy\": 0.9432420134544373, \"f1\": 0.6683373395386897, \"f2\": 0.8341205606760793, \"f0_5\": 0.5575275606675996, \"p4\": 0.7910519776035393, \"phi\": 0.6866487088066485}, {\"truth_threshold\": -15.409538148299017, \"match_probability\": 2.2975068768078908e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101313.0, \"fp\": 6406.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9405304789543152, \"fp_rate\": 0.059469547122716904, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5049459338188171, \"recall\": 0.9993882179260254, \"specificity\": 0.9405304789543152, \"npv\": 0.9999605417251587, \"accuracy\": 0.9438983798027039, \"f1\": 0.670910771126399, \"f2\": 0.8357208636038064, \"f0_5\": 0.5603965830731757, \"p4\": 0.7929755656603351, \"phi\": 0.688891129645406}, {\"truth_threshold\": -15.387654552463767, \"match_probability\": 2.3326215643733095e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101351.0, \"fp\": 6368.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.940883219242096, \"fp_rate\": 0.059116777032613754, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5064331293106079, \"recall\": 0.9993882179260254, \"specificity\": 0.940883219242096, \"npv\": 0.9999605417251587, \"accuracy\": 0.9442309737205505, \"f1\": 0.6722222222222223, \"f2\": 0.8365340298048856, \"f0_5\": 0.5618615209988649, \"p4\": 0.7939536886336555, \"phi\": 0.6900344209871914}, {\"truth_threshold\": -15.387501784297266, \"match_probability\": 2.3328685749081662e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101361.0, \"fp\": 6358.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.940976083278656, \"fp_rate\": 0.05902394279837608, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5068259239196777, \"recall\": 0.9993882179260254, \"specificity\": 0.940976083278656, \"npv\": 0.9999605417251587, \"accuracy\": 0.9443185329437256, \"f1\": 0.6725681935151827, \"f2\": 0.8367482839872964, \"f0_5\": 0.5622483048222214, \"p4\": 0.7942114827645087, \"phi\": 0.690336052586322}, {\"truth_threshold\": -15.384471431667446, \"match_probability\": 2.337773754841624e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101443.0, \"fp\": 6276.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9417372941970825, \"fp_rate\": 0.05826270207762718, \"fn_rate\": 0.000611807918176055, \"precision\": 0.510070264339447, \"recall\": 0.9993882179260254, \"specificity\": 0.9417372941970825, \"npv\": 0.9999605417251587, \"accuracy\": 0.9450361728668213, \"f1\": 0.6754186479222659, \"f2\": 0.8385093167701864, \"f0_5\": 0.5654401329225657, \"p4\": 0.7963316025649192, \"phi\": 0.6928224954529036}, {\"truth_threshold\": -15.375948645629794, \"match_probability\": 2.351624806564019e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101444.0, \"fp\": 6275.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9417465925216675, \"fp_rate\": 0.058253418654203415, \"fn_rate\": 0.000611807918176055, \"precision\": 0.510110080242157, \"recall\": 0.9993882179260254, \"specificity\": 0.9417465925216675, \"npv\": 0.9999605417251587, \"accuracy\": 0.9450449347496033, \"f1\": 0.67545355869127, \"f2\": 0.8385308385308385, \"f0_5\": 0.5654792813376259, \"p4\": 0.7963575261887358, \"phi\": 0.6928529483709102}, {\"truth_threshold\": -15.370405964592441, \"match_probability\": 2.360676662893853e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101445.0, \"fp\": 6274.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9417558908462524, \"fp_rate\": 0.05824413523077965, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5101498961448669, \"recall\": 0.9993882179260254, \"specificity\": 0.9417558908462524, \"npv\": 0.9999605417251587, \"accuracy\": 0.9450536966323853, \"f1\": 0.6754884730693683, \"f2\": 0.8385523613963038, \"f0_5\": 0.5655184351739657, \"p4\": 0.7963834514677103, \"phi\": 0.6928834047054636}, {\"truth_threshold\": -15.359899440722819, \"match_probability\": 2.3779307919083877e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101580.0, \"fp\": 6139.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9430091381072998, \"fp_rate\": 0.05699087306857109, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5155842900276184, \"recall\": 0.9993882179260254, \"specificity\": 0.9430091381072998, \"npv\": 0.9999606013298035, \"accuracy\": 0.9462352395057678, \"f1\": 0.6802352818697621, \"f2\": 0.8414681262073407, \"f0_5\": 0.5708544469683733, \"p4\": 0.7998986256017028, \"phi\": 0.6970280658820559}, {\"truth_threshold\": -15.326301622692144, \"match_probability\": 2.4339570946959736e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101581.0, \"fp\": 6138.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9430184364318848, \"fp_rate\": 0.056981589645147324, \"fn_rate\": 0.000611807918176055, \"precision\": 0.515625, \"recall\": 0.9993882179260254, \"specificity\": 0.9430184364318848, \"npv\": 0.9999606013298035, \"accuracy\": 0.9462440013885498, \"f1\": 0.6802706923477355, \"f2\": 0.8414898001236348, \"f0_5\": 0.5708943487226086, \"p4\": 0.7999247774759848, \"phi\": 0.697059060387673}, {\"truth_threshold\": -15.32337144687755, \"match_probability\": 2.438905469383117e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101593.0, \"fp\": 6126.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.94312983751297, \"fp_rate\": 0.05687018856406212, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5161137580871582, \"recall\": 0.9993882179260254, \"specificity\": 0.94312983751297, \"npv\": 0.9999606013298035, \"accuracy\": 0.946349024772644, \"f1\": 0.6806959058235232, \"f2\": 0.8417499742347727, \"f0_5\": 0.5713736052327818, \"p4\": 0.8002387308347035, \"phi\": 0.6974305290420028}, {\"truth_threshold\": -15.318230023993154, \"match_probability\": 2.4476124427499907e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101755.0, \"fp\": 5964.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9446337223052979, \"fp_rate\": 0.05536627769470215, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5228036642074585, \"recall\": 0.9993882179260254, \"specificity\": 0.9446337223052979, \"npv\": 0.999960720539093, \"accuracy\": 0.947766900062561, \"f1\": 0.6864887581424669, \"f2\": 0.8452781371280724, \"f0_5\": 0.5779232266053423, \"p4\": 0.8045008820894157, \"phi\": 0.7024962734156269}, {\"truth_threshold\": -15.313557655197158, \"match_probability\": 2.4555520316366064e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101756.0, \"fp\": 5963.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9446430206298828, \"fp_rate\": 0.05535699427127838, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5228455066680908, \"recall\": 0.9993882179260254, \"specificity\": 0.9446430206298828, \"npv\": 0.999960720539093, \"accuracy\": 0.9477756023406982, \"f1\": 0.6865248226950355, \"f2\": 0.8453000077621672, \"f0_5\": 0.5779641227045961, \"p4\": 0.8045273299610205, \"phi\": 0.7025278255232927}, {\"truth_threshold\": -15.301866064802512, \"match_probability\": 2.4755321653683146e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101781.0, \"fp\": 5938.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9448751211166382, \"fp_rate\": 0.055124908685684204, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5238935351371765, \"recall\": 0.9993882179260254, \"specificity\": 0.9448751211166382, \"npv\": 0.999960720539093, \"accuracy\": 0.9479944109916687, \"f1\": 0.687427669647554, \"f2\": 0.8458471416735709, \"f0_5\": 0.5789884095984121, \"p4\": 0.8051890816029423, \"phi\": 0.7033180814381953}, {\"truth_threshold\": -15.287183955103538, \"match_probability\": 2.5008533132680054e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101789.0, \"fp\": 5930.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9449493885040283, \"fp_rate\": 0.05505064129829407, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5242297649383545, \"recall\": 0.9993882179260254, \"specificity\": 0.9449493885040283, \"npv\": 0.999960720539093, \"accuracy\": 0.9480644464492798, \"f1\": 0.6877170824123776, \"f2\": 0.8460223741454319, \"f0_5\": 0.5793169486115545, \"p4\": 0.8054010677322816, \"phi\": 0.7035714258275048}, {\"truth_threshold\": -15.284776536745971, \"match_probability\": 2.505029854484376e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101809.0, \"fp\": 5910.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9451350569725037, \"fp_rate\": 0.054864972829818726, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5250723361968994, \"recall\": 0.9993882179260254, \"specificity\": 0.9451350569725037, \"npv\": 0.999960720539093, \"accuracy\": 0.9482395052909851, \"f1\": 0.6884416815930882, \"f2\": 0.8464607731371127, \"f0_5\": 0.5801399296800085, \"p4\": 0.8059315124332977, \"phi\": 0.7042058455007321}, {\"truth_threshold\": -15.248415440213831, \"match_probability\": 2.5689663115325875e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101830.0, \"fp\": 5889.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9453299641609192, \"fp_rate\": 0.05467002093791962, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5259599089622498, \"recall\": 0.9993882179260254, \"specificity\": 0.9453299641609192, \"npv\": 0.999960720539093, \"accuracy\": 0.9484232664108276, \"f1\": 0.6892041558989505, \"f2\": 0.8469215813350616, \"f0_5\": 0.581006580117375, \"p4\": 0.8064892175864697, \"phi\": 0.7048735568537572}, {\"truth_threshold\": -15.235710657106631, \"match_probability\": 2.5916886766184948e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101918.0, \"fp\": 5801.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9461469054222107, \"fp_rate\": 0.05385307967662811, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5297122001647949, \"recall\": 0.9993882179260254, \"specificity\": 0.9461469054222107, \"npv\": 0.9999607801437378, \"accuracy\": 0.9491934776306152, \"f1\": 0.6924177396280401, \"f2\": 0.8488580559669499, \"f0_5\": 0.5846665950821432, \"p4\": 0.8088345264693064, \"phi\": 0.7076894465689594}, {\"truth_threshold\": -15.228679128270194, \"match_probability\": 2.6043507703521806e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101919.0, \"fp\": 5800.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9461562037467957, \"fp_rate\": 0.053843796253204346, \"fn_rate\": 0.000611807918176055, \"precision\": 0.529755175113678, \"recall\": 0.9993882179260254, \"specificity\": 0.9461562037467957, \"npv\": 0.9999607801437378, \"accuracy\": 0.9492022395133972, \"f1\": 0.6924544298431539, \"f2\": 0.8488801122486099, \"f0_5\": 0.5847084511579625, \"p4\": 0.8088612546104459, \"phi\": 0.7077216005404089}, {\"truth_threshold\": -15.223945552184745, \"match_probability\": 2.6129096244232537e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101920.0, \"fp\": 5799.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9461655020713806, \"fp_rate\": 0.05383451282978058, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5297980904579163, \"recall\": 0.9993882179260254, \"specificity\": 0.9461655020713806, \"npv\": 0.9999607801437378, \"accuracy\": 0.9492110013961792, \"f1\": 0.6924911239467967, \"f2\": 0.8489021696764973, \"f0_5\": 0.5847503132271344, \"p4\": 0.8088879844848318, \"phi\": 0.7077538262853486}, {\"truth_threshold\": -15.19957721213308, \"match_probability\": 2.657417536169928e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101928.0, \"fp\": 5791.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9462397694587708, \"fp_rate\": 0.05376024544239044, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5301420092582703, \"recall\": 0.9993882179260254, \"specificity\": 0.9462397694587708, \"npv\": 0.9999607801437378, \"accuracy\": 0.9492809772491455, \"f1\": 0.6927848168371945, \"f2\": 0.8490786703745095, \"f0_5\": 0.5850854256957627, \"p4\": 0.8091018858971425, \"phi\": 0.7080112913457868}, {\"truth_threshold\": -15.185867923127615, \"match_probability\": 2.6827894732515083e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 101931.0, \"fp\": 5788.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9462676048278809, \"fp_rate\": 0.05373239517211914, \"fn_rate\": 0.000611807918176055, \"precision\": 0.530271053314209, \"recall\": 0.9993882179260254, \"specificity\": 0.9462676048278809, \"npv\": 0.9999607801437378, \"accuracy\": 0.9493072628974915, \"f1\": 0.6928950159066808, \"f2\": 0.8491448770598327, \"f0_5\": 0.5852111919177444, \"p4\": 0.8091821275458483, \"phi\": 0.7081078772545638}, {\"truth_threshold\": -15.177056533558, \"match_probability\": 2.699224546950253e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102077.0, \"fp\": 5642.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9476229548454285, \"fp_rate\": 0.052377019077539444, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5366294384002686, \"recall\": 0.9993882179260254, \"specificity\": 0.9476229548454285, \"npv\": 0.9999608397483826, \"accuracy\": 0.9505850672721863, \"f1\": 0.6983007374158384, \"f2\": 0.8523794614902943, \"f0_5\": 0.5913978494623656, \"p4\": 0.8131061842231967, \"phi\": 0.7128512845597202}, {\"truth_threshold\": -15.160952598963492, \"match_probability\": 2.7295223234715634e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102079.0, \"fp\": 5640.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9476415514945984, \"fp_rate\": 0.05235845223069191, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5367175936698914, \"recall\": 0.9993882179260254, \"specificity\": 0.9476415514945984, \"npv\": 0.9999608397483826, \"accuracy\": 0.9506025910377502, \"f1\": 0.6983753740914921, \"f2\": 0.8524239419715076, \"f0_5\": 0.5914835065358294, \"p4\": 0.8131601977261871, \"phi\": 0.7129168093032294}, {\"truth_threshold\": -15.1493420471025, \"match_probability\": 2.7515770541292522e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102160.0, \"fp\": 5559.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9483935236930847, \"fp_rate\": 0.051606494933366776, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5403125882148743, \"recall\": 0.9993882179260254, \"specificity\": 0.9483935236930847, \"npv\": 0.9999608397483826, \"accuracy\": 0.9513115286827087, \"f1\": 0.7014116257849821, \"f2\": 0.8542293110210485, \"f0_5\": 0.5949735931524313, \"p4\": 0.8153536783929264, \"phi\": 0.715584556489986}, {\"truth_threshold\": -15.137507019386371, \"match_probability\": 2.7742415956355944e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102193.0, \"fp\": 5526.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9486998319625854, \"fp_rate\": 0.05130014196038246, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5417910218238831, \"recall\": 0.9993882179260254, \"specificity\": 0.9486998319625854, \"npv\": 0.9999608397483826, \"accuracy\": 0.9516003131866455, \"f1\": 0.702656199591354, \"f2\": 0.8549670260651104, \"f0_5\": 0.596407316806017, \"p4\": 0.8162506517168198, \"phi\": 0.7166787881579237}, {\"truth_threshold\": -15.132773443300922, \"match_probability\": 2.7833587578751008e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102203.0, \"fp\": 5516.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9487926959991455, \"fp_rate\": 0.05120730772614479, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5422406792640686, \"recall\": 0.9993882179260254, \"specificity\": 0.9487926959991455, \"npv\": 0.9999608397483826, \"accuracy\": 0.9516878724098206, \"f1\": 0.7030342156229825, \"f2\": 0.8551908277053557, \"f0_5\": 0.5968431437027294, \"p4\": 0.8165228443401621, \"phi\": 0.717011258941833}, {\"truth_threshold\": -15.125958635664684, \"match_probability\": 2.7965371443409966e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102219.0, \"fp\": 5500.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9489412307739258, \"fp_rate\": 0.05105877295136452, \"fn_rate\": 0.000611807918176055, \"precision\": 0.542961597442627, \"recall\": 0.9993882179260254, \"specificity\": 0.9489412307739258, \"npv\": 0.9999608993530273, \"accuracy\": 0.951827883720398, \"f1\": 0.703639888003446, \"f2\": 0.8555491541402608, \"f0_5\": 0.5975417931740864, \"p4\": 0.8169587233271577, \"phi\": 0.7175439574531121}, {\"truth_threshold\": -15.121437025833652, \"match_probability\": 2.8053153894245672e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102276.0, \"fp\": 5443.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9494704008102417, \"fp_rate\": 0.05052961781620979, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5455456376075745, \"recall\": 0.9993882179260254, \"specificity\": 0.9494704008102417, \"npv\": 0.9999608993530273, \"accuracy\": 0.952326774597168, \"f1\": 0.7058061031596004, \"f2\": 0.8568281360644129, \"f0_5\": 0.6000440803732138, \"p4\": 0.8185152611586144, \"phi\": 0.7194501515028145}, {\"truth_threshold\": -15.121225059579235, \"match_probability\": 2.8057275757693382e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102283.0, \"fp\": 5436.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9495353698730469, \"fp_rate\": 0.05046463385224342, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5458646416664124, \"recall\": 0.9993882179260254, \"specificity\": 0.9495353698730469, \"npv\": 0.9999608993530273, \"accuracy\": 0.9523880481719971, \"f1\": 0.7060730494921115, \"f2\": 0.8569854677089345, \"f0_5\": 0.600352824433092, \"p4\": 0.8187068163890963, \"phi\": 0.719685139730045}, {\"truth_threshold\": -15.115148909350367, \"match_probability\": 2.8175689498360188e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102396.0, \"fp\": 5323.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9505844116210938, \"fp_rate\": 0.04941561073064804, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5510668754577637, \"recall\": 0.9993882179260254, \"specificity\": 0.9505844116210938, \"npv\": 0.9999609589576721, \"accuracy\": 0.9533770084381104, \"f1\": 0.7104104376189182, \"f2\": 0.859533268436423, \"f0_5\": 0.6053811659192825, \"p4\": 0.8218112877113114, \"phi\": 0.7235062720179767}, {\"truth_threshold\": -15.111867341683839, \"match_probability\": 2.8239849317610356e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102426.0, \"fp\": 5293.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9508628845214844, \"fp_rate\": 0.04913710802793503, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5524647235870361, \"recall\": 0.9993882179260254, \"specificity\": 0.9508628845214844, \"npv\": 0.9999609589576721, \"accuracy\": 0.9536396265029907, \"f1\": 0.711570922951266, \"f2\": 0.8602122225440375, \"f0_5\": 0.6067303049437284, \"p4\": 0.8226393697472181, \"phi\": 0.7245295781349166}, {\"truth_threshold\": -15.097221141625681, \"match_probability\": 2.852799143695926e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102529.0, \"fp\": 5190.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9518190622329712, \"fp_rate\": 0.04818091541528702, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5573183298110962, \"recall\": 0.9993882179260254, \"specificity\": 0.9518190622329712, \"npv\": 0.9999609589576721, \"accuracy\": 0.9545410871505737, \"f1\": 0.7155842733545066, \"f2\": 0.8625514837892069, \"f0_5\": 0.6114084665194446, \"p4\": 0.8254949622086564, \"phi\": 0.7280715370308807}, {\"truth_threshold\": -15.092192237029655, \"match_probability\": 2.862760414930147e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102531.0, \"fp\": 5188.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9518376588821411, \"fp_rate\": 0.048162348568439484, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5574133992195129, \"recall\": 0.9993882179260254, \"specificity\": 0.9518376588821411, \"npv\": 0.9999610185623169, \"accuracy\": 0.9545586109161377, \"f1\": 0.7156626506024096, \"f2\": 0.8625970322648783, \"f0_5\": 0.6115000187174784, \"p4\": 0.8255506032525358, \"phi\": 0.7281407353001659}, {\"truth_threshold\": -15.070592891360404, \"match_probability\": 2.905941496914705e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102533.0, \"fp\": 5186.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9518561959266663, \"fp_rate\": 0.04814378172159195, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5575085282325745, \"recall\": 0.9993882179260254, \"specificity\": 0.9518561959266663, \"npv\": 0.9999610185623169, \"accuracy\": 0.9545760750770569, \"f1\": 0.7157410450213605, \"f2\": 0.8626425855513308, \"f0_5\": 0.611591598337639, \"p4\": 0.825606251661451, \"phi\": 0.7282099506076646}, {\"truth_threshold\": -15.06784319457201, \"match_probability\": 2.9114851803938066e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102534.0, \"fp\": 5185.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9518654942512512, \"fp_rate\": 0.04813449829816818, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5575560927391052, \"recall\": 0.9993882179260254, \"specificity\": 0.9518654942512512, \"npv\": 0.9999610185623169, \"accuracy\": 0.9545848369598389, \"f1\": 0.7157802486717424, \"f2\": 0.8626653639988382, \"f0_5\": 0.6116373984348673, \"p4\": 0.8256340786282562, \"phi\": 0.7282445646530038}, {\"truth_threshold\": -15.062886669999578, \"match_probability\": 2.9215047914947276e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102630.0, \"fp\": 5089.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9527567028999329, \"fp_rate\": 0.04724328964948654, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5621612071990967, \"recall\": 0.9993882179260254, \"specificity\": 0.9527567028999329, \"npv\": 0.9999610185623169, \"accuracy\": 0.9554250240325928, \"f1\": 0.7195639006662629, \"f2\": 0.8648577101257445, \"f0_5\": 0.6160663775221573, \"p4\": 0.8283140700937701, \"phi\": 0.7315886096284204}, {\"truth_threshold\": -15.054572527033006, \"match_probability\": 2.938389314451164e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102643.0, \"fp\": 5076.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.952877402305603, \"fp_rate\": 0.04712260514497757, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5627906918525696, \"recall\": 0.9993882179260254, \"specificity\": 0.952877402305603, \"npv\": 0.9999610185623169, \"accuracy\": 0.955538809299469, \"f1\": 0.7200793475865109, \"f2\": 0.8651554472750383, \"f0_5\": 0.6166710710106081, \"p4\": 0.8286782994707911, \"phi\": 0.7320445021534491}, {\"truth_threshold\": -15.054020550742433, \"match_probability\": 2.939513726621525e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102652.0, \"fp\": 5067.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9529609680175781, \"fp_rate\": 0.047039054334163666, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5632272958755493, \"recall\": 0.9993882179260254, \"specificity\": 0.9529609680175781, \"npv\": 0.9999610185623169, \"accuracy\": 0.9556176066398621, \"f1\": 0.7204366282595512, \"f2\": 0.8653616931104813, \"f0_5\": 0.6170904008159873, \"p4\": 0.8289306425825717, \"phi\": 0.732360525021977}, {\"truth_threshold\": -15.018933594091065, \"match_probability\": 3.0118781972905775e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102655.0, \"fp\": 5064.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9529888033866882, \"fp_rate\": 0.047011204063892365, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5633729696273804, \"recall\": 0.9993882179260254, \"specificity\": 0.9529888033866882, \"npv\": 0.9999610185623169, \"accuracy\": 0.9556438326835632, \"f1\": 0.7205558006175562, \"f2\": 0.8654304635761589, \"f0_5\": 0.6172303041753259, \"p4\": 0.8290147904924715, \"phi\": 0.7324659213345387}, {\"truth_threshold\": -14.99923422510562, \"match_probability\": 3.0532848710502164e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102683.0, \"fp\": 5036.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9532487392425537, \"fp_rate\": 0.046751268208026886, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5647363662719727, \"recall\": 0.9993882179260254, \"specificity\": 0.9532487392425537, \"npv\": 0.9999610185623169, \"accuracy\": 0.9558889269828796, \"f1\": 0.7216699801192843, \"f2\": 0.866072848735486, \"f0_5\": 0.6185391343860047, \"p4\": 0.8298009807360648, \"phi\": 0.7334518716773738}, {\"truth_threshold\": -14.994712615274588, \"match_probability\": 3.062869014757934e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102692.0, \"fp\": 5027.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9533323049545288, \"fp_rate\": 0.04666771739721298, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5651760101318359, \"recall\": 0.9993882179260254, \"specificity\": 0.9533323049545288, \"npv\": 0.9999610781669617, \"accuracy\": 0.9559676647186279, \"f1\": 0.7220288413724515, \"f2\": 0.8662795322567814, \"f0_5\": 0.6189610094350346, \"p4\": 0.8300539958118199, \"phi\": 0.7337694735742967}, {\"truth_threshold\": -14.994500649020173, \"match_probability\": 3.063319042421968e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102693.0, \"fp\": 5026.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.953341543674469, \"fp_rate\": 0.046658433973789215, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5652248859405518, \"recall\": 0.9993882179260254, \"specificity\": 0.953341543674469, \"npv\": 0.9999610781669617, \"accuracy\": 0.9559764266014099, \"f1\": 0.722068736877003, \"f2\": 0.8663025031820111, \"f0_5\": 0.6190079199666527, \"p4\": 0.8300821179512924, \"phi\": 0.7338047769304346}, {\"truth_threshold\": -14.978541887142029, \"match_probability\": 3.097391831240036e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102708.0, \"fp\": 5011.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9534808397293091, \"fp_rate\": 0.04651918262243271, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5659592747688293, \"recall\": 0.9993882179260254, \"specificity\": 0.9534808397293091, \"npv\": 0.9999610781669617, \"accuracy\": 0.9561077356338501, \"f1\": 0.7226676989437594, \"f2\": 0.8666472133060986, \"f0_5\": 0.61971243218635, \"p4\": 0.8305041747097873, \"phi\": 0.7343350670524875}, {\"truth_threshold\": -14.96284844185861, \"match_probability\": 3.131267708307739e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102710.0, \"fp\": 5009.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9534993767738342, \"fp_rate\": 0.046500615775585175, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5660573244094849, \"recall\": 0.9993882179260254, \"specificity\": 0.9534993767738342, \"npv\": 0.9999610781669617, \"accuracy\": 0.9561251997947693, \"f1\": 0.7227476356396217, \"f2\": 0.8666931953840031, \"f0_5\": 0.6198064883323847, \"p4\": 0.8305604807911616, \"phi\": 0.7344058195400419}, {\"truth_threshold\": -14.960076214493204, \"match_probability\": 3.1372902277391064e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102737.0, \"fp\": 4982.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9537500143051147, \"fp_rate\": 0.04624996334314346, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5673844814300537, \"recall\": 0.9993882179260254, \"specificity\": 0.9537500143051147, \"npv\": 0.9999610781669617, \"accuracy\": 0.9563615322113037, \"f1\": 0.7238285144566301, \"f2\": 0.8673144313475629, \"f0_5\": 0.6210790464240903, \"p4\": 0.831321347385911, \"phi\": 0.7353629943631806}, {\"truth_threshold\": -14.91584010112696, \"match_probability\": 3.234973068686286e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102751.0, \"fp\": 4968.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9538800120353699, \"fp_rate\": 0.04611999914050102, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5680751204490662, \"recall\": 0.9993882179260254, \"specificity\": 0.9538800120353699, \"npv\": 0.9999610781669617, \"accuracy\": 0.9564840793609619, \"f1\": 0.724390243902439, \"f2\": 0.8676369044457428, \"f0_5\": 0.621740950785978, \"p4\": 0.8317164100240301, \"phi\": 0.7358605786840434}, {\"truth_threshold\": -14.874472613552577, \"match_probability\": 3.3290714434657675e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102955.0, \"fp\": 4764.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9557738304138184, \"fp_rate\": 0.044226180762052536, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5783324241638184, \"recall\": 0.9993882179260254, \"specificity\": 0.9557738304138184, \"npv\": 0.9999611377716064, \"accuracy\": 0.9582695364952087, \"f1\": 0.7326754877775286, \"f2\": 0.8723631508678238, \"f0_5\": 0.6315484245118886, \"p4\": 0.8375151595357588, \"phi\": 0.7432119793717477}, {\"truth_threshold\": -14.861375472800036, \"match_probability\": 3.359430151723108e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102964.0, \"fp\": 4755.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9558573961257935, \"fp_rate\": 0.04414262995123863, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5787935256958008, \"recall\": 0.9993882179260254, \"specificity\": 0.9558573961257935, \"npv\": 0.9999611377716064, \"accuracy\": 0.958348274230957, \"f1\": 0.7330453806024569, \"f2\": 0.8725728479474373, \"f0_5\": 0.6319882384802878, \"p4\": 0.8377728163506821, \"phi\": 0.7435407598603662}, {\"truth_threshold\": -14.859316235634072, \"match_probability\": 3.364228511599e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102966.0, \"fp\": 4753.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9558759331703186, \"fp_rate\": 0.0441240631043911, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5788960456848145, \"recall\": 0.9993882179260254, \"specificity\": 0.9558759331703186, \"npv\": 0.9999611377716064, \"accuracy\": 0.958365797996521, \"f1\": 0.7331276297335203, \"f2\": 0.8726194609898769, \"f0_5\": 0.6320860581201873, \"p4\": 0.8378300945703273, \"phi\": 0.7436138421917078}, {\"truth_threshold\": -14.84049424866313, \"match_probability\": 3.4084056606214e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102970.0, \"fp\": 4749.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9559130668640137, \"fp_rate\": 0.04408692941069603, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5791013240814209, \"recall\": 0.9993882179260254, \"specificity\": 0.9559130668640137, \"npv\": 0.9999611377716064, \"accuracy\": 0.9584007859230042, \"f1\": 0.7332921833791595, \"f2\": 0.8727127020168292, \"f0_5\": 0.6322817882717244, \"p4\": 0.8379446740936567, \"phi\": 0.743760133769874}, {\"truth_threshold\": -14.828945864941444, \"match_probability\": 3.435797575129342e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 102971.0, \"fp\": 4748.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9559223651885986, \"fp_rate\": 0.04407764598727226, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5791526436805725, \"recall\": 0.9993882179260254, \"specificity\": 0.9559223651885986, \"npv\": 0.9999611377716064, \"accuracy\": 0.9584095478057861, \"f1\": 0.7333333333333333, \"f2\": 0.8727360153870812, \"f0_5\": 0.6323307397514807, \"p4\": 0.8379733237847999, \"phi\": 0.7437967006862095}, {\"truth_threshold\": -14.80269205174261, \"match_probability\": 3.498891538610691e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103019.0, \"fp\": 4700.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9563679695129395, \"fp_rate\": 0.04363204166293144, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5816271901130676, \"recall\": 0.9993882179260254, \"specificity\": 0.9563679695129395, \"npv\": 0.9999611973762512, \"accuracy\": 0.9588296413421631, \"f1\": 0.7353139770425389, \"f2\": 0.8738565238324506, \"f0_5\": 0.6346893577340016, \"p4\": 0.8393507757839945, \"phi\": 0.7455579373275864}, {\"truth_threshold\": -14.799508930946288, \"match_probability\": 3.506619643845582e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103020.0, \"fp\": 4699.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9563772678375244, \"fp_rate\": 0.043622758239507675, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5816789865493774, \"recall\": 0.9993882179260254, \"specificity\": 0.9563772678375244, \"npv\": 0.9999611973762512, \"accuracy\": 0.9588384032249451, \"f1\": 0.7353553542287997, \"f2\": 0.8738798983549552, \"f0_5\": 0.6347386827278026, \"p4\": 0.8393795200059753, \"phi\": 0.7455947350400061}, {\"truth_threshold\": -14.771042390103187, \"match_probability\": 3.576495150917982e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103026.0, \"fp\": 4693.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9564329385757446, \"fp_rate\": 0.04356705769896507, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5819898247718811, \"recall\": 0.9993882179260254, \"specificity\": 0.9564329385757446, \"npv\": 0.9999611973762512, \"accuracy\": 0.9588909149169922, \"f1\": 0.7356037151702787, \"f2\": 0.8740201717541936, \"f0_5\": 0.6350347937643355, \"p4\": 0.8395520259606913, \"phi\": 0.7458156917116013}, {\"truth_threshold\": -14.770830423848771, \"match_probability\": 3.5770206430242554e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103029.0, \"fp\": 4690.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9564607739448547, \"fp_rate\": 0.04353920742869377, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5821453928947449, \"recall\": 0.9993882179260254, \"specificity\": 0.9564607739448547, \"npv\": 0.9999611973762512, \"accuracy\": 0.9589172005653381, \"f1\": 0.7357279585632248, \"f2\": 0.8740903253424658, \"f0_5\": 0.6351829529105261, \"p4\": 0.8396383050615577, \"phi\": 0.7459262695227339}, {\"truth_threshold\": -14.770203363916213, \"match_probability\": 3.5785756588111284e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103155.0, \"fp\": 4564.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9576305150985718, \"fp_rate\": 0.042369499802589417, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5887547135353088, \"recall\": 0.9993882179260254, \"specificity\": 0.9576305150985718, \"npv\": 0.9999611973762512, \"accuracy\": 0.9600199460983276, \"f1\": 0.7409843501927875, \"f2\": 0.8770469798657718, \"f0_5\": 0.6414686825053996, \"p4\": 0.843277825749309, \"phi\": 0.7506079035227956}, {\"truth_threshold\": -14.764703115036498, \"match_probability\": 3.592244463488459e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103165.0, \"fp\": 4554.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9577233195304871, \"fp_rate\": 0.042276665568351746, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5892857313156128, \"recall\": 0.9993882179260254, \"specificity\": 0.9577233195304871, \"npv\": 0.999961256980896, \"accuracy\": 0.9601075053215027, \"f1\": 0.7414047429933054, \"f2\": 0.8772824919441461, \"f0_5\": 0.6419728826881509, \"p4\": 0.8435680047229889, \"phi\": 0.7509827107141448}, {\"truth_threshold\": -14.721920823367824, \"match_probability\": 3.700361618207888e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103178.0, \"fp\": 4541.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9578440189361572, \"fp_rate\": 0.04215598106384277, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5899774432182312, \"recall\": 0.9993882179260254, \"specificity\": 0.9578440189361572, \"npv\": 0.999961256980896, \"accuracy\": 0.9602212309837341, \"f1\": 0.741951967296883, \"f2\": 0.8775888468047385, \"f0_5\": 0.6426295290924112, \"p4\": 0.8439455308596931, \"phi\": 0.7514707415108384}, {\"truth_threshold\": -14.702546638973928, \"match_probability\": 3.7503876596064986e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103258.0, \"fp\": 4461.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9585866928100586, \"fp_rate\": 0.041413307189941406, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5942701101303101, \"recall\": 0.9993882179260254, \"specificity\": 0.9585866928100586, \"npv\": 0.999961256980896, \"accuracy\": 0.9609214067459106, \"f1\": 0.7453373638282097, \"f2\": 0.8794788273615635, \"f0_5\": 0.6467001860722911, \"p4\": 0.84627609667642, \"phi\": 0.754492401998297}, {\"truth_threshold\": -14.702221454382382, \"match_probability\": 3.7512330634838284e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103267.0, \"fp\": 4452.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9586702585220337, \"fp_rate\": 0.0413297563791275, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5947569608688354, \"recall\": 0.9993882179260254, \"specificity\": 0.9586702585220337, \"npv\": 0.999961256980896, \"accuracy\": 0.9610002040863037, \"f1\": 0.7457201552157042, \"f2\": 0.8796919597178092, \"f0_5\": 0.6471613644467334, \"p4\": 0.8465390770215984, \"phi\": 0.7548342958934681}, {\"truth_threshold\": -14.697134495832959, \"match_probability\": 3.7644828001467365e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103280.0, \"fp\": 4439.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9587909579277039, \"fp_rate\": 0.04120907187461853, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5954616069793701, \"recall\": 0.9993882179260254, \"specificity\": 0.9587909579277039, \"npv\": 0.999961256980896, \"accuracy\": 0.9611139893531799, \"f1\": 0.7462737707726572, \"f2\": 0.88, \"f0_5\": 0.6478286734086853, \"p4\": 0.8469192211796175, \"phi\": 0.7553288984698693}, {\"truth_threshold\": -14.686401138445897, \"match_probability\": 3.7925931616035835e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103296.0, \"fp\": 4423.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9589394330978394, \"fp_rate\": 0.04106053709983826, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5963311195373535, \"recall\": 0.9993882179260254, \"specificity\": 0.9589394330978394, \"npv\": 0.999961256980896, \"accuracy\": 0.9612540006637573, \"f1\": 0.7469562732209203, \"f2\": 0.8803794227815355, \"f0_5\": 0.6486518683238692, \"p4\": 0.8473875517119922, \"phi\": 0.7559388437872663}, {\"truth_threshold\": -14.684514555020504, \"match_probability\": 3.797555715430917e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103297.0, \"fp\": 4422.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9589487314224243, \"fp_rate\": 0.04105125367641449, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5963855385780334, \"recall\": 0.9993882179260254, \"specificity\": 0.9589487314224243, \"npv\": 0.999961256980896, \"accuracy\": 0.9612627625465393, \"f1\": 0.7469989710757974, \"f2\": 0.8804031475692573, \"f0_5\": 0.6487033874746833, \"p4\": 0.8474168392702862, \"phi\": 0.7559769947134457}, {\"truth_threshold\": -14.678082931809964, \"match_probability\": 3.8145225981544954e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103315.0, \"fp\": 4404.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9591158628463745, \"fp_rate\": 0.04088415205478668, \"fn_rate\": 0.000611807918176055, \"precision\": 0.597366988658905, \"recall\": 0.9993882179260254, \"specificity\": 0.9591158628463745, \"npv\": 0.999961256980896, \"accuracy\": 0.9614202976226807, \"f1\": 0.7477683680476082, \"f2\": 0.8808304125101105, \"f0_5\": 0.6496321336249752, \"p4\": 0.8479443557145286, \"phi\": 0.7566647894275381}, {\"truth_threshold\": -14.67715473775081, \"match_probability\": 3.816977462933583e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103319.0, \"fp\": 4400.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9591529965400696, \"fp_rate\": 0.040847018361091614, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5975854992866516, \"recall\": 0.9993882179260254, \"specificity\": 0.9591529965400696, \"npv\": 0.999961256980896, \"accuracy\": 0.9614553451538086, \"f1\": 0.7479395604395604, \"f2\": 0.8809254165992558, \"f0_5\": 0.6498388829215896, \"p4\": 0.8480616692468249, \"phi\": 0.756817807308083}, {\"truth_threshold\": -14.672784520387227, \"match_probability\": 3.828556952526264e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103321.0, \"fp\": 4398.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9591715335845947, \"fp_rate\": 0.04082845151424408, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5976948142051697, \"recall\": 0.9993882179260254, \"specificity\": 0.9591715335845947, \"npv\": 0.9999613165855408, \"accuracy\": 0.9614728093147278, \"f1\": 0.7480251860331998, \"f2\": 0.8809729263294143, \"f0_5\": 0.6499423069271476, \"p4\": 0.8481203379758335, \"phi\": 0.7568943466310022}, {\"truth_threshold\": -14.671294750297857, \"match_probability\": 3.832512325400486e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103322.0, \"fp\": 4397.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9591808319091797, \"fp_rate\": 0.04081916809082031, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5977495312690735, \"recall\": 0.9993882179260254, \"specificity\": 0.9591808319091797, \"npv\": 0.9999613165855408, \"accuracy\": 0.9614815711975098, \"f1\": 0.7480680061823802, \"f2\": 0.8809966831162527, \"f0_5\": 0.6499940312761132, \"p4\": 0.8481496753317678, \"phi\": 0.7569326956511936}, {\"truth_threshold\": -14.650748156385475, \"match_probability\": 3.8874826392040594e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103349.0, \"fp\": 4370.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9594314694404602, \"fp_rate\": 0.0405685156583786, \"fn_rate\": 0.000611807918176055, \"precision\": 0.599229633808136, \"recall\": 0.9993882179260254, \"specificity\": 0.9594314694404602, \"npv\": 0.9999613165855408, \"accuracy\": 0.9617179036140442, \"f1\": 0.7492260061919505, \"f2\": 0.8816386010362695, \"f0_5\": 0.6513937073812657, \"p4\": 0.8489425385554484, \"phi\": 0.7579683886261235}, {\"truth_threshold\": -14.643716627549038, \"match_probability\": 3.906475286368663e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103351.0, \"fp\": 4368.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9594500660896301, \"fp_rate\": 0.04054994881153107, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5993395447731018, \"recall\": 0.9993882179260254, \"specificity\": 0.9594500660896301, \"npv\": 0.9999613165855408, \"accuracy\": 0.9617353677749634, \"f1\": 0.7493119266055046, \"f2\": 0.8816861877260215, \"f0_5\": 0.6514976269293663, \"p4\": 0.8490013271176092, \"phi\": 0.7580452329608312}, {\"truth_threshold\": -14.638983051463589, \"match_probability\": 3.919313232578546e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103359.0, \"fp\": 4360.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9595243334770203, \"fp_rate\": 0.04047568142414093, \"fn_rate\": 0.000611807918176055, \"precision\": 0.5997796654701233, \"recall\": 0.9993882179260254, \"specificity\": 0.9595243334770203, \"npv\": 0.9999613165855408, \"accuracy\": 0.9618054032325745, \"f1\": 0.7496558054153282, \"f2\": 0.8818765858662204, \"f0_5\": 0.6519136369078501, \"p4\": 0.8492365614025602, \"phi\": 0.7583528863249428}, {\"truth_threshold\": -14.637978704477435, \"match_probability\": 3.922042545680529e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103369.0, \"fp\": 4350.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9596171379089355, \"fp_rate\": 0.04038284718990326, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6003307700157166, \"recall\": 0.9993882179260254, \"specificity\": 0.9596171379089355, \"npv\": 0.9999613165855408, \"accuracy\": 0.9618929028511047, \"f1\": 0.7500860980369648, \"f2\": 0.8821146992115779, \"f0_5\": 0.6524343970923034, \"p4\": 0.8495307844636422, \"phi\": 0.7587379670734399}, {\"truth_threshold\": -14.620384217600789, \"match_probability\": 3.970165031167366e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103371.0, \"fp\": 4348.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9596357345581055, \"fp_rate\": 0.040364280343055725, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6004410982131958, \"recall\": 0.9993882179260254, \"specificity\": 0.9596357345581055, \"npv\": 0.9999613165855408, \"accuracy\": 0.9619104266166687, \"f1\": 0.7501722158438576, \"f2\": 0.8821623373116596, \"f0_5\": 0.652538648983342, \"p4\": 0.8495896531196168, \"phi\": 0.7588150159099615}, {\"truth_threshold\": -14.618827330403722, \"match_probability\": 3.9744515848098785e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103493.0, \"fp\": 4226.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9607682824134827, \"fp_rate\": 0.03923170641064644, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6072490811347961, \"recall\": 0.9993882179260254, \"specificity\": 0.9607682824134827, \"npv\": 0.9999613761901855, \"accuracy\": 0.962978184223175, \"f1\": 0.7554630593132154, \"f2\": 0.8850780234070221, \"f0_5\": 0.6589616362096091, \"p4\": 0.8531958664809012, \"phi\": 0.7635554911874971}, {\"truth_threshold\": -14.618482374185454, \"match_probability\": 3.9754019736037836e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103518.0, \"fp\": 4201.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.961000382900238, \"fp_rate\": 0.03899962082505226, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6086632609367371, \"recall\": 0.9993882179260254, \"specificity\": 0.961000382900238, \"npv\": 0.9999613761901855, \"accuracy\": 0.9631969928741455, \"f1\": 0.7565564754240722, \"f2\": 0.8856778810963212, \"f0_5\": 0.6602934637616719, \"p4\": 0.8539385622246005, \"phi\": 0.764536522811488}, {\"truth_threshold\": -14.583681793020643, \"match_probability\": 4.0724583020823044e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103538.0, \"fp\": 4181.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9611860513687134, \"fp_rate\": 0.03881395235657692, \"fn_rate\": 0.000611807918176055, \"precision\": 0.609799325466156, \"recall\": 0.9993882179260254, \"specificity\": 0.9611860513687134, \"npv\": 0.9999613761901855, \"accuracy\": 0.9633720517158508, \"f1\": 0.7574334898278561, \"f2\": 0.8861583529986167, \"f0_5\": 0.6613628082108587, \"p4\": 0.854533634482236, \"phi\": 0.7653237187507234}, {\"truth_threshold\": -14.577459842829336, \"match_probability\": 4.090058911585789e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103545.0, \"fp\": 4174.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9612510204315186, \"fp_rate\": 0.03874896839261055, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6101979613304138, \"recall\": 0.9993882179260254, \"specificity\": 0.9612510204315186, \"npv\": 0.9999613761901855, \"accuracy\": 0.9634333252906799, \"f1\": 0.7577409254319842, \"f2\": 0.8863266413456321, \"f0_5\": 0.6617378975086085, \"p4\": 0.8547421024056688, \"phi\": 0.7655997365941087}, {\"truth_threshold\": -14.570410085273895, \"match_probability\": 4.1100931520524104e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103549.0, \"fp\": 4170.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9612881541252136, \"fp_rate\": 0.03871183469891548, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6104260087013245, \"recall\": 0.9993882179260254, \"specificity\": 0.9612881541252136, \"npv\": 0.9999613761901855, \"accuracy\": 0.9634683132171631, \"f1\": 0.7579167149982601, \"f2\": 0.8864228348165835, \"f0_5\": 0.6619524253353325, \"p4\": 0.8548612718270316, \"phi\": 0.7657576094743326}, {\"truth_threshold\": -14.553270021742252, \"match_probability\": 4.1592126456226666e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103557.0, \"fp\": 4162.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9613624215126038, \"fp_rate\": 0.038637567311525345, \"fn_rate\": 0.000611807918176055, \"precision\": 0.610882580280304, \"recall\": 0.9993882179260254, \"specificity\": 0.9613624215126038, \"npv\": 0.9999613761901855, \"accuracy\": 0.9635383486747742, \"f1\": 0.7582685389346641, \"f2\": 0.886615284411637, \"f0_5\": 0.6623818985442602, \"p4\": 0.8550997086836899, \"phi\": 0.7660735392277307}, {\"truth_threshold\": -14.552544518665215, \"match_probability\": 4.1613046711308374e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103676.0, \"fp\": 4043.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9624671339988708, \"fp_rate\": 0.03753283992409706, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6177555322647095, \"recall\": 0.9993882179260254, \"specificity\": 0.9624671339988708, \"npv\": 0.9999614357948303, \"accuracy\": 0.9645798802375793, \"f1\": 0.7635407537248028, \"f2\": 0.889487870619946, \"f0_5\": 0.6688367522417393, \"p4\": 0.858661956848955, \"phi\": 0.7708140756884942}, {\"truth_threshold\": -14.547810942579765, \"match_probability\": 4.174980034476436e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103682.0, \"fp\": 4037.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9625228643417358, \"fp_rate\": 0.03747713938355446, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6181061267852783, \"recall\": 0.9993882179260254, \"specificity\": 0.9625228643417358, \"npv\": 0.9999614357948303, \"accuracy\": 0.9646323919296265, \"f1\": 0.7638085218306154, \"f2\": 0.8896331999019688, \"f0_5\": 0.6691655401253533, \"p4\": 0.8588423387388365, \"phi\": 0.7710551423697748}, {\"truth_threshold\": -14.536262558858079, \"match_probability\": 4.208532323678037e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103683.0, \"fp\": 4036.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9625321626663208, \"fp_rate\": 0.03746785596013069, \"fn_rate\": 0.000611807918176055, \"precision\": 0.618164598941803, \"recall\": 0.9993882179260254, \"specificity\": 0.9625321626663208, \"npv\": 0.9999614357948303, \"accuracy\": 0.9646410942077637, \"f1\": 0.7638531681084872, \"f2\": 0.8896574260661184, \"f0_5\": 0.669220369535827, \"p4\": 0.8588724096307991, \"phi\": 0.7710953272839807}, {\"truth_threshold\": -14.507796018014977, \"match_probability\": 4.29239406366476e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103745.0, \"fp\": 3974.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.963107705116272, \"fp_rate\": 0.03689228370785713, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6218119263648987, \"recall\": 0.9993882179260254, \"specificity\": 0.963107705116272, \"npv\": 0.9999614357948303, \"accuracy\": 0.9651837348937988, \"f1\": 0.7666314677930306, \"f2\": 0.8911620294599017, \"f0_5\": 0.6726374305126621, \"p4\": 0.8607408565525101, \"phi\": 0.7735983343988854}, {\"truth_threshold\": -14.49807210255783, \"match_probability\": 4.321421713132584e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103768.0, \"fp\": 3951.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9633212089538574, \"fp_rate\": 0.03667876496911049, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6231759786605835, \"recall\": 0.9993882179260254, \"specificity\": 0.9633212089538574, \"npv\": 0.9999614357948303, \"accuracy\": 0.9653850793838501, \"f1\": 0.767667273688539, \"f2\": 0.8917214837459398, \"f0_5\": 0.6739139403440736, \"p4\": 0.8614360240203649, \"phi\": 0.7745322667313705}, {\"truth_threshold\": -14.491757963626391, \"match_probability\": 4.3403755925395316e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103781.0, \"fp\": 3938.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9634419083595276, \"fp_rate\": 0.03655808046460152, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6239495873451233, \"recall\": 0.9993882179260254, \"specificity\": 0.9634419083595276, \"npv\": 0.9999614357948303, \"accuracy\": 0.9654988050460815, \"f1\": 0.7682539682539683, \"f2\": 0.8920380078636959, \"f0_5\": 0.6746375913765332, \"p4\": 0.8618294333138211, \"phi\": 0.7750614783562255}, {\"truth_threshold\": -14.482880693850854, \"match_probability\": 4.3671641959215254e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103785.0, \"fp\": 3934.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9634790420532227, \"fp_rate\": 0.03652094677090645, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6241880059242249, \"recall\": 0.9993882179260254, \"specificity\": 0.9634790420532227, \"npv\": 0.9999614357948303, \"accuracy\": 0.9655338525772095, \"f1\": 0.7684346701164295, \"f2\": 0.8921354451119606, \"f0_5\": 0.6748605659987605, \"p4\": 0.8619505534117232, \"phi\": 0.7752245324579503}, {\"truth_threshold\": -14.455752874147345, \"match_probability\": 4.450055712827804e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103835.0, \"fp\": 3884.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9639432430267334, \"fp_rate\": 0.036056775599718094, \"fn_rate\": 0.000611807918176055, \"precision\": 0.627183735370636, \"recall\": 0.9993882179260254, \"specificity\": 0.9639432430267334, \"npv\": 0.9999614953994751, \"accuracy\": 0.9659714698791504, \"f1\": 0.7707006369426752, \"f2\": 0.8933552091878589, \"f0_5\": 0.6776602364654636, \"p4\": 0.8634673836825599, \"phi\": 0.7772700283951745}, {\"truth_threshold\": -14.44030290564621, \"match_probability\": 4.497965749136676e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103837.0, \"fp\": 3882.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9639617800712585, \"fp_rate\": 0.03603820875287056, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6273041367530823, \"recall\": 0.9993882179260254, \"specificity\": 0.9639617800712585, \"npv\": 0.9999614953994751, \"accuracy\": 0.9659889340400696, \"f1\": 0.7707915536156659, \"f2\": 0.8934040691314811, \"f0_5\": 0.6777727065267002, \"p4\": 0.863528166076218, \"phi\": 0.7773521207027945}, {\"truth_threshold\": -14.440121972357902, \"match_probability\": 4.498529864304952e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103840.0, \"fp\": 3879.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9639896154403687, \"fp_rate\": 0.03601035848259926, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6274848580360413, \"recall\": 0.9993882179260254, \"specificity\": 0.9639896154403687, \"npv\": 0.9999614953994751, \"accuracy\": 0.9660152196884155, \"f1\": 0.7709279688513953, \"f2\": 0.8934773690687816, \"f0_5\": 0.6779414816351941, \"p4\": 0.8636193554443377, \"phi\": 0.77747537536515}, {\"truth_threshold\": -14.434057803048027, \"match_probability\": 4.517477753472513e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103843.0, \"fp\": 3876.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9640175104141235, \"fp_rate\": 0.03598250821232796, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6276656985282898, \"recall\": 0.9993882179260254, \"specificity\": 0.9640175104141235, \"npv\": 0.9999614953994751, \"accuracy\": 0.9660414457321167, \"f1\": 0.771064432381402, \"f2\": 0.8935506810349543, \"f0_5\": 0.6781103408194612, \"p4\": 0.8637105637508827, \"phi\": 0.7775986081659423}, {\"truth_threshold\": -14.433598093011314, \"match_probability\": 4.518917397230267e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103846.0, \"fp\": 3873.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9640453457832336, \"fp_rate\": 0.035954661667346954, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6278466582298279, \"recall\": 0.9993882179260254, \"specificity\": 0.9640453457832336, \"npv\": 0.9999614953994751, \"accuracy\": 0.9660677313804626, \"f1\": 0.7712009442313367, \"f2\": 0.8936240050329605, \"f0_5\": 0.6782792841423411, \"p4\": 0.8638017910017798, \"phi\": 0.7777219658288322}, {\"truth_threshold\": -14.409538148299017, \"match_probability\": 4.594908185284241e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103851.0, \"fp\": 3868.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9640917778015137, \"fp_rate\": 0.03590824455022812, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6281484365463257, \"recall\": 0.9993882179260254, \"specificity\": 0.9640917778015137, \"npv\": 0.9999614953994751, \"accuracy\": 0.9661114811897278, \"f1\": 0.7714285714285715, \"f2\": 0.8937462384417574, \"f0_5\": 0.6785610434927096, \"p4\": 0.8639538785346064, \"phi\": 0.7779275542415057}, {\"truth_threshold\": -14.408880112407077, \"match_probability\": 4.5970043768263816e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103862.0, \"fp\": 3857.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9641938805580139, \"fp_rate\": 0.03580612689256668, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6288133859634399, \"recall\": 0.9993882179260254, \"specificity\": 0.9641938805580139, \"npv\": 0.9999614953994751, \"accuracy\": 0.96620774269104, \"f1\": 0.7719298245614035, \"f2\": 0.8940152696822921, \"f0_5\": 0.6791817388050393, \"p4\": 0.8642886565338415, \"phi\": 0.7783805003712664}, {\"truth_threshold\": -14.384471431667446, \"match_probability\": 4.6754382085158854e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103876.0, \"fp\": 3843.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9643238186836243, \"fp_rate\": 0.03567615896463394, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6296617388725281, \"recall\": 0.9993882179260254, \"specificity\": 0.9643238186836243, \"npv\": 0.9999614953994751, \"accuracy\": 0.9663302898406982, \"f1\": 0.7725687259828554, \"f2\": 0.8943579074160256, \"f0_5\": 0.6799733588644216, \"p4\": 0.8647151067557424, \"phi\": 0.7789579436806728}, {\"truth_threshold\": -14.375948645629794, \"match_probability\": 4.7031390129443213e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103877.0, \"fp\": 3842.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9643331170082092, \"fp_rate\": 0.035666875541210175, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6297224164009094, \"recall\": 0.9993882179260254, \"specificity\": 0.9643331170082092, \"npv\": 0.9999614953994751, \"accuracy\": 0.9663390517234802, \"f1\": 0.7726144022703086, \"f2\": 0.8943823915900131, \"f0_5\": 0.6800299737729487, \"p4\": 0.8647455833201371, \"phi\": 0.7789992223603186}, {\"truth_threshold\": -14.371347691998766, \"match_probability\": 4.7181612059813626e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103879.0, \"fp\": 3840.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9643517136573792, \"fp_rate\": 0.03564830869436264, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6298438310623169, \"recall\": 0.9993882179260254, \"specificity\": 0.9643517136573792, \"npv\": 0.9999614953994751, \"accuracy\": 0.9663565754890442, \"f1\": 0.7727057710501419, \"f2\": 0.894431363959919, \"f0_5\": 0.6801432318774202, \"p4\": 0.8648065427863783, \"phi\": 0.7790818704920071}, {\"truth_threshold\": -14.333206768441391, \"match_probability\": 4.844553858966704e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103885.0, \"fp\": 3834.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9644073843955994, \"fp_rate\": 0.03559260815382004, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6302083134651184, \"recall\": 0.9993882179260254, \"specificity\": 0.9644073843955994, \"npv\": 0.9999614953994751, \"accuracy\": 0.9664090871810913, \"f1\": 0.7729800070980717, \"f2\": 0.8945783132530121, \"f0_5\": 0.6804832326598625, \"p4\": 0.8649894719006037, \"phi\": 0.7793298065786984}, {\"truth_threshold\": -14.330877600405804, \"match_probability\": 4.852381116418275e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 103893.0, \"fp\": 3826.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9644816517829895, \"fp_rate\": 0.0355183407664299, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6306949853897095, \"recall\": 0.9993882179260254, \"specificity\": 0.9644816517829895, \"npv\": 0.9999614953994751, \"accuracy\": 0.9664790630340576, \"f1\": 0.7733459581015505, \"f2\": 0.8947743207712533, \"f0_5\": 0.6809370961690775, \"p4\": 0.865233495788352, \"phi\": 0.7796606873486512}, {\"truth_threshold\": -14.317818899121216, \"match_probability\": 4.8965001610816816e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104040.0, \"fp\": 3679.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9658463001251221, \"fp_rate\": 0.03415367752313614, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6397728323936462, \"recall\": 0.9993882179260254, \"specificity\": 0.9658463001251221, \"npv\": 0.9999615550041199, \"accuracy\": 0.9677656292915344, \"f1\": 0.7801325294012298, \"f2\": 0.8983913103258628, \"f0_5\": 0.6893859464021945, \"p4\": 0.8697416579163926, \"phi\": 0.7858076980300753}, {\"truth_threshold\": -14.284776536745971, \"match_probability\": 5.009934208621135e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104044.0, \"fp\": 3675.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9658834338188171, \"fp_rate\": 0.03411654382944107, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6400235295295715, \"recall\": 0.9993882179260254, \"specificity\": 0.9658834338188171, \"npv\": 0.9999615550041199, \"accuracy\": 0.9678006768226624, \"f1\": 0.7803188630799546, \"f2\": 0.8984901405351888, \"f0_5\": 0.689618778232786, \"p4\": 0.8698649746938596, \"phi\": 0.7859767092381966}, {\"truth_threshold\": -14.284481446997518, \"match_probability\": 5.0109589971589774e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104049.0, \"fp\": 3670.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9659298658370972, \"fp_rate\": 0.034070126712322235, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6403371095657349, \"recall\": 0.9993882179260254, \"specificity\": 0.9659298658370972, \"npv\": 0.9999615550041199, \"accuracy\": 0.9678444266319275, \"f1\": 0.7805519053876478, \"f2\": 0.8986137088788646, \"f0_5\": 0.6899100392786248, \"p4\": 0.8700191690352143, \"phi\": 0.7861881824323442}, {\"truth_threshold\": -14.27169624029798, \"match_probability\": 5.055561362811962e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104060.0, \"fp\": 3659.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9660319685935974, \"fp_rate\": 0.0339680090546608, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6410281658172607, \"recall\": 0.9993882179260254, \"specificity\": 0.9660319685935974, \"npv\": 0.9999615550041199, \"accuracy\": 0.9679406881332397, \"f1\": 0.7810650887573964, \"f2\": 0.8988856789104416, \"f0_5\": 0.6905516804058338, \"p4\": 0.8703585858973081, \"phi\": 0.7866539383002681}, {\"truth_threshold\": -14.260028403272978, \"match_probability\": 5.0966120502875087e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104080.0, \"fp\": 3639.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9662176370620728, \"fp_rate\": 0.033782340586185455, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6422883868217468, \"recall\": 0.9993882179260254, \"specificity\": 0.9662176370620728, \"npv\": 0.9999615550041199, \"accuracy\": 0.9681157469749451, \"f1\": 0.7819998803183532, \"f2\": 0.8993805918788713, \"f0_5\": 0.6917213635401228, \"p4\": 0.8709763751977897, \"phi\": 0.7875025912386832}, {\"truth_threshold\": -14.257257915208092, \"match_probability\": 5.106408263089309e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104081.0, \"fp\": 3638.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9662269353866577, \"fp_rate\": 0.03377305716276169, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6423515677452087, \"recall\": 0.9993882179260254, \"specificity\": 0.9662269353866577, \"npv\": 0.9999615550041199, \"accuracy\": 0.968124508857727, \"f1\": 0.7820466786355476, \"f2\": 0.8994053518334986, \"f0_5\": 0.6917799517215093, \"p4\": 0.8710072873049498, \"phi\": 0.7875450763123469}, {\"truth_threshold\": -14.256257251019013, \"match_probability\": 5.109951154031381e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104082.0, \"fp\": 3637.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9662362337112427, \"fp_rate\": 0.03376377373933792, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6424146890640259, \"recall\": 0.9993882179260254, \"specificity\": 0.9662362337112427, \"npv\": 0.9999615550041199, \"accuracy\": 0.968133270740509, \"f1\": 0.7820934825543121, \"f2\": 0.8994301131514467, \"f0_5\": 0.6918385498284698, \"p4\": 0.871038201570167, \"phi\": 0.7875875674477083}, {\"truth_threshold\": -14.255531747941975, \"match_probability\": 5.112521363198328e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104102.0, \"fp\": 3617.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.966421902179718, \"fp_rate\": 0.03357810527086258, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6436804533004761, \"recall\": 0.9993882179260254, \"specificity\": 0.966421902179718, \"npv\": 0.9999615550041199, \"accuracy\": 0.9683082699775696, \"f1\": 0.7830307388099946, \"f2\": 0.8999256259813239, \"f0_5\": 0.693012600229095, \"p4\": 0.8716569404162761, \"phi\": 0.7884389621409439}, {\"truth_threshold\": -14.248415440213831, \"match_probability\": 5.137800634697716e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104103.0, \"fp\": 3616.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.966431200504303, \"fp_rate\": 0.03356882184743881, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6437438130378723, \"recall\": 0.9993882179260254, \"specificity\": 0.966431200504303, \"npv\": 0.9999615550041199, \"accuracy\": 0.9683170318603516, \"f1\": 0.7830776605944392, \"f2\": 0.8999504159550438, \"f0_5\": 0.6930714073571217, \"p4\": 0.8716879000531729, \"phi\": 0.7884815809284972}, {\"truth_threshold\": -14.233299442525484, \"match_probability\": 5.191912704738492e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104134.0, \"fp\": 3585.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9667189717292786, \"fp_rate\": 0.03328103572130203, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6457159519195557, \"recall\": 0.9993882179260254, \"specificity\": 0.9667189717292786, \"npv\": 0.9999616146087646, \"accuracy\": 0.9685883522033691, \"f1\": 0.7845350303175842, \"f2\": 0.9007195831380441, \"f0_5\": 0.6948993916705662, \"p4\": 0.872648722804159, \"phi\": 0.7898060907813839}, {\"truth_threshold\": -14.2102233974932, \"match_probability\": 5.275621140944689e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104135.0, \"fp\": 3584.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9667282700538635, \"fp_rate\": 0.033271752297878265, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6457797884941101, \"recall\": 0.9993882179260254, \"specificity\": 0.9667282700538635, \"npv\": 0.9999616146087646, \"accuracy\": 0.9685971140861511, \"f1\": 0.7845821325648416, \"f2\": 0.9007444168734491, \"f0_5\": 0.6949585194639438, \"p4\": 0.8726797517719979, \"phi\": 0.7898489796426721}, {\"truth_threshold\": -14.170151387808755, \"match_probability\": 5.424201712963035e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104156.0, \"fp\": 3563.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.966923177242279, \"fp_rate\": 0.033076800405979156, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6471229195594788, \"recall\": 0.9993882179260254, \"specificity\": 0.966923177242279, \"npv\": 0.9999616146087646, \"accuracy\": 0.9687809348106384, \"f1\": 0.7855725879170424, \"f2\": 0.9012662418273607, \"f0_5\": 0.6962025316455697, \"p4\": 0.8733318618021096, \"phi\": 0.790749729957278}, {\"truth_threshold\": -14.160952598963492, \"match_probability\": 5.4588956451678776e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104158.0, \"fp\": 3561.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.966941773891449, \"fp_rate\": 0.03305823355913162, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6472511291503906, \"recall\": 0.9993882179260254, \"specificity\": 0.966941773891449, \"npv\": 0.9999616146087646, \"accuracy\": 0.9687983989715576, \"f1\": 0.7856670474358204, \"f2\": 0.9013159709769084, \"f0_5\": 0.696321241314634, \"p4\": 0.8733940175147663, \"phi\": 0.7908356362634209}, {\"truth_threshold\": -14.137507019386371, \"match_probability\": 5.5483292672127944e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104171.0, \"fp\": 3548.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9670624732971191, \"fp_rate\": 0.03293754905462265, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6480857133865356, \"recall\": 0.9993882179260254, \"specificity\": 0.9670624732971191, \"npv\": 0.9999616146087646, \"accuracy\": 0.9689121842384338, \"f1\": 0.7862815884476534, \"f2\": 0.9016393442622951, \"f0_5\": 0.6970938420176674, \"p4\": 0.8737982418528092, \"phi\": 0.7913947789232327}, {\"truth_threshold\": -14.13113067009072, \"match_probability\": 5.5729043886960046e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104172.0, \"fp\": 3547.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9670717120170593, \"fp_rate\": 0.03292826563119888, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6481499671936035, \"recall\": 0.9993882179260254, \"specificity\": 0.9670717120170593, \"npv\": 0.9999616146087646, \"accuracy\": 0.9689209461212158, \"f1\": 0.7863289006558758, \"f2\": 0.9016642287417548, \"f0_5\": 0.6971533438606974, \"p4\": 0.8738293512765178, \"phi\": 0.7914378217932636}, {\"truth_threshold\": -14.124802630790251, \"match_probability\": 5.5974009273972205e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104173.0, \"fp\": 3546.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9670810103416443, \"fp_rate\": 0.032918982207775116, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6482142806053162, \"recall\": 0.9993882179260254, \"specificity\": 0.9670810103416443, \"npv\": 0.9999616146087646, \"accuracy\": 0.9689297080039978, \"f1\": 0.78637621855819, \"f2\": 0.9016891145948333, \"f0_5\": 0.6972128558623928, \"p4\": 0.8738604628790696, \"phi\": 0.7914809452830054}, {\"truth_threshold\": -14.117584138252772, \"match_probability\": 5.6254760008308823e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104181.0, \"fp\": 3538.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9671552777290344, \"fp_rate\": 0.03284471482038498, \"fn_rate\": 0.000611807918176055, \"precision\": 0.648729145526886, \"recall\": 0.9993882179260254, \"specificity\": 0.9671552777290344, \"npv\": 0.9999616146087646, \"accuracy\": 0.9689996838569641, \"f1\": 0.7867549668874172, \"f2\": 0.9018882508833922, \"f0_5\": 0.6976893179003117, \"p4\": 0.8741094341654254, \"phi\": 0.7918256356470956}, {\"truth_threshold\": -14.111867341683839, \"match_probability\": 5.647810370208242e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104184.0, \"fp\": 3535.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9671831130981445, \"fp_rate\": 0.03281686455011368, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6489224433898926, \"recall\": 0.9993882179260254, \"specificity\": 0.9671831130981445, \"npv\": 0.9999616146087646, \"accuracy\": 0.9690259695053101, \"f1\": 0.7868970915878847, \"f2\": 0.9019629496700808, \"f0_5\": 0.6978681590977058, \"p4\": 0.8742028343765494, \"phi\": 0.7919549690908448}, {\"truth_threshold\": -14.090363337489997, \"match_probability\": 5.732619127972929e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104199.0, \"fp\": 3520.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9673224091529846, \"fp_rate\": 0.03267761319875717, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6498906016349792, \"recall\": 0.9993882179260254, \"specificity\": 0.9673224091529846, \"npv\": 0.9999616146087646, \"accuracy\": 0.9691572785377502, \"f1\": 0.7876084860173578, \"f2\": 0.9023366292879633, \"f0_5\": 0.6987637421397099, \"p4\": 0.8746701300731058, \"phi\": 0.7926026999812794}, {\"truth_threshold\": -14.06784319457201, \"match_probability\": 5.822800830804339e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104201.0, \"fp\": 3518.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9673409461975098, \"fp_rate\": 0.03265904635190964, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6500198841094971, \"recall\": 0.9993882179260254, \"specificity\": 0.9673409461975098, \"npv\": 0.9999616146087646, \"accuracy\": 0.9691747426986694, \"f1\": 0.7877034358047016, \"f2\": 0.9023864766324163, \"f0_5\": 0.6988833269156719, \"p4\": 0.8747324732950361, \"phi\": 0.792689140287975}, {\"truth_threshold\": -14.062089025661068, \"match_probability\": 5.846070005990323e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104240.0, \"fp\": 3479.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9677029848098755, \"fp_rate\": 0.03229699656367302, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6525517106056213, \"recall\": 0.9993882179260254, \"specificity\": 0.9677029848098755, \"npv\": 0.9999616146087646, \"accuracy\": 0.9695160984992981, \"f1\": 0.7895595432300163, \"f2\": 0.9033596018249689, \"f0_5\": 0.7012234385061172, \"p4\": 0.875949915727503, \"phi\": 0.7943801810013623}, {\"truth_threshold\": -14.054020550742433, \"match_probability\": 5.878854643503836e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104241.0, \"fp\": 3478.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9677122831344604, \"fp_rate\": 0.03228771314024925, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6526168584823608, \"recall\": 0.9993882179260254, \"specificity\": 0.9677122831344604, \"npv\": 0.9999616146087646, \"accuracy\": 0.9695248603820801, \"f1\": 0.789607250755287, \"f2\": 0.9033845813516204, \"f0_5\": 0.7012836474477311, \"p4\": 0.8759811760324101, \"phi\": 0.7944236552413539}, {\"truth_threshold\": -14.047667381283759, \"match_probability\": 5.904798801233382e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104243.0, \"fp\": 3476.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9677308797836304, \"fp_rate\": 0.03226914629340172, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6527472734451294, \"recall\": 0.9993882179260254, \"specificity\": 0.9677308797836304, \"npv\": 0.9999616146087646, \"accuracy\": 0.9695423245429993, \"f1\": 0.7897026831036983, \"f2\": 0.9034345445495271, \"f0_5\": 0.7014040963545021, \"p4\": 0.8760437032268018, \"phi\": 0.7945106972953787}, {\"truth_threshold\": -14.03619399771815, \"match_probability\": 5.951942569022156e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104247.0, \"fp\": 3472.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9677680134773254, \"fp_rate\": 0.03223201259970665, \"fn_rate\": 0.000611807918176055, \"precision\": 0.653008222579956, \"recall\": 0.9993882179260254, \"specificity\": 0.9677680134773254, \"npv\": 0.9999616146087646, \"accuracy\": 0.9695773720741272, \"f1\": 0.7898936170212766, \"f2\": 0.903534487526965, \"f0_5\": 0.7016451183368412, \"p4\": 0.8761687839603969, \"phi\": 0.7946847078232357}, {\"truth_threshold\": -14.033864829682566, \"match_probability\": 5.961558907578577e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104253.0, \"fp\": 3466.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9678236842155457, \"fp_rate\": 0.03217631205916405, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6534000039100647, \"recall\": 0.9993882179260254, \"specificity\": 0.9678236842155457, \"npv\": 0.9999616146087646, \"accuracy\": 0.9696298837661743, \"f1\": 0.7901801910750997, \"f2\": 0.9036844434609427, \"f0_5\": 0.7020069620525162, \"p4\": 0.8763564709506928, \"phi\": 0.7949459877867056}, {\"truth_threshold\": -14.033449736004423, \"match_probability\": 5.963274317826525e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104282.0, \"fp\": 3437.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9680929183959961, \"fp_rate\": 0.0319070927798748, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6553003787994385, \"recall\": 0.9993882179260254, \"specificity\": 0.9680929183959961, \"npv\": 0.9999616146087646, \"accuracy\": 0.9698836803436279, \"f1\": 0.7915682355079048, \"f2\": 0.9044099327298397, \"f0_5\": 0.703761147731679, \"p4\": 0.8772647409093681, \"phi\": 0.7962120697840187}, {\"truth_threshold\": -13.998078220231188, \"match_probability\": 6.111277890600556e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104285.0, \"fp\": 3434.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9681207537651062, \"fp_rate\": 0.0318792425096035, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6554976105690002, \"recall\": 0.9993882179260254, \"specificity\": 0.9681207537651062, \"npv\": 0.9999616742134094, \"accuracy\": 0.9699099659919739, \"f1\": 0.7917121046892039, \"f2\": 0.904485049833887, \"f0_5\": 0.7039431157078216, \"p4\": 0.8773588055812537, \"phi\": 0.7963433102676921}, {\"truth_threshold\": -13.981822351920687, \"match_probability\": 6.180523122278892e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104286.0, \"fp\": 3433.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9681300520896912, \"fp_rate\": 0.03186995908617973, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6555633544921875, \"recall\": 0.9993882179260254, \"specificity\": 0.9681300520896912, \"npv\": 0.9999616742134094, \"accuracy\": 0.9699186682701111, \"f1\": 0.7917600727052408, \"f2\": 0.9045100916415183, \"f0_5\": 0.7040037926130241, \"p4\": 0.8773901648816246, \"phi\": 0.7963870698436724}, {\"truth_threshold\": -13.97462618441073, \"match_probability\": 6.211426686092689e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104291.0, \"fp\": 3428.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9681764841079712, \"fp_rate\": 0.0318235419690609, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6558923721313477, \"recall\": 0.9993882179260254, \"specificity\": 0.9681764841079712, \"npv\": 0.9999616742134094, \"accuracy\": 0.969962477684021, \"f1\": 0.792, \"f2\": 0.9046353214819738, \"f0_5\": 0.7043073341094296, \"p4\": 0.8775469944670594, \"phi\": 0.7966060382239246}, {\"truth_threshold\": -13.971636741392782, \"match_probability\": 6.224310074657202e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104297.0, \"fp\": 3422.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9682321548461914, \"fp_rate\": 0.031767841428518295, \"fn_rate\": 0.000611807918176055, \"precision\": 0.656287670135498, \"recall\": 0.9993882179260254, \"specificity\": 0.9682321548461914, \"npv\": 0.9999616742134094, \"accuracy\": 0.9700149893760681, \"f1\": 0.7922881047653693, \"f2\": 0.9047856430707877, \"f0_5\": 0.7046719295975152, \"p4\": 0.8777352627843087, \"phi\": 0.7968689960688856}, {\"truth_threshold\": -13.968307521021096, \"match_probability\": 6.238689228258347e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104300.0, \"fp\": 3419.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9682599902153015, \"fp_rate\": 0.031739991158246994, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6564854979515076, \"recall\": 0.9993882179260254, \"specificity\": 0.9682599902153015, \"npv\": 0.9999616742134094, \"accuracy\": 0.9700412154197693, \"f1\": 0.7924322357649627, \"f2\": 0.9048608226007478, \"f0_5\": 0.7048543689320388, \"p4\": 0.8778294267455087, \"phi\": 0.7970005238830709}, {\"truth_threshold\": -13.963573944935648, \"match_probability\": 6.259191106994038e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104352.0, \"fp\": 3367.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9687427282333374, \"fp_rate\": 0.031257253140211105, \"fn_rate\": 0.000611807918176055, \"precision\": 0.65993332862854, \"recall\": 0.9993882179260254, \"specificity\": 0.9687427282333374, \"npv\": 0.9999616742134094, \"accuracy\": 0.9704963564872742, \"f1\": 0.7949388648944583, \"f2\": 0.906165922392034, \"f0_5\": 0.7080317281435569, \"p4\": 0.8794647657536794, \"phi\": 0.799290202729765}, {\"truth_threshold\": -13.96284844185861, \"match_probability\": 6.262339326006377e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104397.0, \"fp\": 3322.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9691604971885681, \"fp_rate\": 0.030839499086141586, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6629464030265808, \"recall\": 0.9993882179260254, \"specificity\": 0.9691604971885681, \"npv\": 0.9999616742134094, \"accuracy\": 0.9708901643753052, \"f1\": 0.7971208978894717, \"f2\": 0.9072983781381915, \"f0_5\": 0.7108045776946172, \"p4\": 0.8808848085729689, \"phi\": 0.8012857399861837}, {\"truth_threshold\": -13.951402669490593, \"match_probability\": 6.312216707641e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104404.0, \"fp\": 3315.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9692254662513733, \"fp_rate\": 0.030774515122175217, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6634175777435303, \"recall\": 0.9993882179260254, \"specificity\": 0.9692254662513733, \"npv\": 0.9999616742134094, \"accuracy\": 0.9709514379501343, \"f1\": 0.7974614023311162, \"f2\": 0.9074747923668787, \"f0_5\": 0.711237863020856, \"p4\": 0.8811061096902476, \"phi\": 0.8015973399591727}, {\"truth_threshold\": -13.938142595336753, \"match_probability\": 6.370497173599598e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104417.0, \"fp\": 3302.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9693461656570435, \"fp_rate\": 0.030653830617666245, \"fn_rate\": 0.000611807918176055, \"precision\": 0.664294421672821, \"recall\": 0.9993882179260254, \"specificity\": 0.9693461656570435, \"npv\": 0.9999616742134094, \"accuracy\": 0.9710652232170105, \"f1\": 0.7980945401245878, \"f2\": 0.9078026008669556, \"f0_5\": 0.7120439387995292, \"p4\": 0.8815173878385797, \"phi\": 0.8021768908404592}, {\"truth_threshold\": -13.933711191986673, \"match_probability\": 6.390093717320193e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104426.0, \"fp\": 3293.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9694297313690186, \"fp_rate\": 0.03057027980685234, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6649028062820435, \"recall\": 0.9993882179260254, \"specificity\": 0.9694297313690186, \"npv\": 0.9999616742134094, \"accuracy\": 0.9711440205574036, \"f1\": 0.7985334555453713, \"f2\": 0.908029683982323, \"f0_5\": 0.7126030624263839, \"p4\": 0.8818023402115105, \"phi\": 0.8025787417287249}, {\"truth_threshold\": -13.921150755882305, \"match_probability\": 6.445966630712621e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104434.0, \"fp\": 3285.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9695039987564087, \"fp_rate\": 0.030496012419462204, \"fn_rate\": 0.000611807918176055, \"precision\": 0.665444552898407, \"recall\": 0.9993882179260254, \"specificity\": 0.9695039987564087, \"npv\": 0.9999616742134094, \"accuracy\": 0.9712139964103699, \"f1\": 0.7989240080699395, \"f2\": 0.9082316310361124, \"f0_5\": 0.7131007988824377, \"p4\": 0.8820557834079975, \"phi\": 0.8029364000519691}, {\"truth_threshold\": -13.920942970724695, \"match_probability\": 6.44689502254657e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104438.0, \"fp\": 3281.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9695411324501038, \"fp_rate\": 0.030458878725767136, \"fn_rate\": 0.000611807918176055, \"precision\": 0.665715754032135, \"recall\": 0.9993882179260254, \"specificity\": 0.9695411324501038, \"npv\": 0.9999616742134094, \"accuracy\": 0.9712490439414978, \"f1\": 0.7991194276279582, \"f2\": 0.9083326382517307, \"f0_5\": 0.7133499279444517, \"p4\": 0.8821825587633423, \"phi\": 0.8031154256879603}, {\"truth_threshold\": -13.89318461704425, \"match_probability\": 6.572130094234621e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104440.0, \"fp\": 3279.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9695596694946289, \"fp_rate\": 0.0304403118789196, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6658514142036438, \"recall\": 0.9993882179260254, \"specificity\": 0.9695596694946289, \"npv\": 0.9999616742134094, \"accuracy\": 0.971266508102417, \"f1\": 0.7992171732615743, \"f2\": 0.9083831502849993, \"f0_5\": 0.7134745577637038, \"p4\": 0.8822459598869696, \"phi\": 0.8032049405962818}, {\"truth_threshold\": -13.865397114655972, \"match_probability\": 6.699933131852317e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104456.0, \"fp\": 3263.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9697082042694092, \"fp_rate\": 0.030291777104139328, \"fn_rate\": 0.000611807918176055, \"precision\": 0.666938841342926, \"recall\": 0.9993882179260254, \"specificity\": 0.9697082042694092, \"npv\": 0.9999617338180542, \"accuracy\": 0.9714065790176392, \"f1\": 0.8, \"f2\": 0.9087874488859217, \"f0_5\": 0.7144731662511481, \"p4\": 0.8827534918310906, \"phi\": 0.8039222416757786}, {\"truth_threshold\": -13.863939828240254, \"match_probability\": 6.706703793013726e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104470.0, \"fp\": 3249.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9698382019996643, \"fp_rate\": 0.03016180917620659, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6678932905197144, \"recall\": 0.9993882179260254, \"specificity\": 0.9698382019996643, \"npv\": 0.9999617338180542, \"accuracy\": 0.9715291261672974, \"f1\": 0.8006862324612463, \"f2\": 0.9091415054960345, \"f0_5\": 0.7153492445806875, \"p4\": 0.8831980537940083, \"phi\": 0.8045512306926565}, {\"truth_threshold\": -13.861392317104585, \"match_probability\": 6.718556157367503e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104521.0, \"fp\": 3198.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9703116416931152, \"fp_rate\": 0.029688356444239616, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6713933348655701, \"recall\": 0.9993882179260254, \"specificity\": 0.9703116416931152, \"npv\": 0.9999617338180542, \"accuracy\": 0.9719754457473755, \"f1\": 0.8031960663798402, \"f2\": 0.9104336194404191, \"f0_5\": 0.7185589231513658, \"p4\": 0.8848212618240777, \"phi\": 0.8068537094086374}, {\"truth_threshold\": -13.859338345395692, \"match_probability\": 6.728127565590199e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104541.0, \"fp\": 3178.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9704973101615906, \"fp_rate\": 0.029502687975764275, \"fn_rate\": 0.000611807918176055, \"precision\": 0.67277592420578, \"recall\": 0.9993882179260254, \"specificity\": 0.9704973101615906, \"npv\": 0.9999617338180542, \"accuracy\": 0.9721505045890808, \"f1\": 0.8041846153846154, \"f2\": 0.9109413339281731, \"f0_5\": 0.7198254968492487, \"p4\": 0.8854594175908707, \"phi\": 0.8077614244304645}, {\"truth_threshold\": -13.84049424866313, \"match_probability\": 6.81657898457883e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104553.0, \"fp\": 3166.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9706087112426758, \"fp_rate\": 0.02939128689467907, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6736082434654236, \"recall\": 0.9993882179260254, \"specificity\": 0.9706087112426758, \"npv\": 0.9999617338180542, \"accuracy\": 0.972255527973175, \"f1\": 0.8047789136593176, \"f2\": 0.9112462345196921, \"f0_5\": 0.7205875865719705, \"p4\": 0.8858427459829508, \"phi\": 0.808307373794796}, {\"truth_threshold\": -13.819150899058874, \"match_probability\": 6.918166635738937e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104556.0, \"fp\": 3163.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9706365466117859, \"fp_rate\": 0.029363436624407768, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6738166213035583, \"recall\": 0.9993882179260254, \"specificity\": 0.9706365466117859, \"npv\": 0.9999617338180542, \"accuracy\": 0.972281813621521, \"f1\": 0.8049276255004619, \"f2\": 0.9113224915618288, \"f0_5\": 0.7207783612054891, \"p4\": 0.885938629113157, \"phi\": 0.8084439766815233}, {\"truth_threshold\": -13.815852389901098, \"match_probability\": 6.934000999889391e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104567.0, \"fp\": 3152.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9707387089729309, \"fp_rate\": 0.02926131896674633, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6745818853378296, \"recall\": 0.9993882179260254, \"specificity\": 0.9707387089729309, \"npv\": 0.9999617338180542, \"accuracy\": 0.9723780751228333, \"f1\": 0.8054733727810651, \"f2\": 0.9116022099447514, \"f0_5\": 0.7214787332714986, \"p4\": 0.8862903753959918, \"phi\": 0.8089455315810353}, {\"truth_threshold\": -13.80698678142761, \"match_probability\": 6.976739836748207e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104580.0, \"fp\": 3139.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9708593487739563, \"fp_rate\": 0.029140634462237358, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6754884719848633, \"recall\": 0.9993882179260254, \"specificity\": 0.9708593487739563, \"npv\": 0.9999617338180542, \"accuracy\": 0.9724918603897095, \"f1\": 0.8061193017087163, \"f2\": 0.9119330076762038, \"f0_5\": 0.722308202520451, \"p4\": 0.8867064300408137, \"phi\": 0.8095393192332548}, {\"truth_threshold\": -13.799508930946288, \"match_probability\": 7.012993368688077e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104585.0, \"fp\": 3134.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9709057807922363, \"fp_rate\": 0.029094217345118523, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6758378148078918, \"recall\": 0.9993882179260254, \"specificity\": 0.9709057807922363, \"npv\": 0.9999617338180542, \"accuracy\": 0.9725356101989746, \"f1\": 0.8063680118474639, \"f2\": 0.9120603015075377, \"f0_5\": 0.7226277372262774, \"p4\": 0.8868665534212915, \"phi\": 0.8097680255871382}, {\"truth_threshold\": -13.785508755961576, \"match_probability\": 7.081375170256551e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104586.0, \"fp\": 3133.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9709150791168213, \"fp_rate\": 0.029084933921694756, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6759077310562134, \"recall\": 0.9993882179260254, \"specificity\": 0.9709150791168213, \"npv\": 0.9999617338180542, \"accuracy\": 0.9725443720817566, \"f1\": 0.8064177722925023, \"f2\": 0.9120857645383735, \"f0_5\": 0.722691678095828, \"p4\": 0.88689858492623, \"phi\": 0.8098137723227778}, {\"truth_threshold\": -13.756994422996305, \"match_probability\": 7.222718011163458e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104588.0, \"fp\": 3131.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9709336161613464, \"fp_rate\": 0.02906636707484722, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6760476231575012, \"recall\": 0.9993882179260254, \"specificity\": 0.9709336161613464, \"npv\": 0.9999617338180542, \"accuracy\": 0.9725618362426758, \"f1\": 0.8065173116089613, \"f2\": 0.9121366948655666, \"f0_5\": 0.7228195937873357, \"p4\": 0.8869626547668994, \"phi\": 0.809905286437585}, {\"truth_threshold\": -13.738672704096908, \"match_probability\": 7.315022150734072e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104590.0, \"fp\": 3129.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9709522128105164, \"fp_rate\": 0.029047800227999687, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6761875152587891, \"recall\": 0.9993882179260254, \"specificity\": 0.9709522128105164, \"npv\": 0.9999617338180542, \"accuracy\": 0.9725793600082397, \"f1\": 0.8066168755015123, \"f2\": 0.9121876308809158, \"f0_5\": 0.7229475547687542, \"p4\": 0.8870267337169176, \"phi\": 0.8099969039470135}, {\"truth_threshold\": -13.732613934836628, \"match_probability\": 7.34580479128586e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104591.0, \"fp\": 3128.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9709615111351013, \"fp_rate\": 0.02903851680457592, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6762574911117554, \"recall\": 0.9993882179260254, \"specificity\": 0.9709615111351013, \"npv\": 0.9999617338180542, \"accuracy\": 0.9725881218910217, \"f1\": 0.8066666666666666, \"f2\": 0.9122131010219467, \"f0_5\": 0.7230115522506971, \"p4\": 0.8870587766085422, \"phi\": 0.8100426851068653}, {\"truth_threshold\": -13.71332474580139, \"match_probability\": 7.444672171750775e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104593.0, \"fp\": 3126.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9709800481796265, \"fp_rate\": 0.029019949957728386, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6763975024223328, \"recall\": 0.9993882179260254, \"specificity\": 0.9709800481796265, \"npv\": 0.9999617338180542, \"accuracy\": 0.9726056456565857, \"f1\": 0.8067662674404248, \"f2\": 0.9122640455713169, \"f0_5\": 0.7231395812120944, \"p4\": 0.8871228692262416, \"phi\": 0.810134268096694}, {\"truth_threshold\": -13.682925575485397, \"match_probability\": 7.60319189799886e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104596.0, \"fp\": 3123.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9710078835487366, \"fp_rate\": 0.028992099687457085, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6766076683998108, \"recall\": 0.9993882179260254, \"specificity\": 0.9710078835487366, \"npv\": 0.9999617338180542, \"accuracy\": 0.9726318717002869, \"f1\": 0.8069157147267675, \"f2\": 0.9123404730654304, \"f0_5\": 0.723331709693132, \"p4\": 0.8872190252425762, \"phi\": 0.8102717701628709}, {\"truth_threshold\": -13.678710590847846, \"match_probability\": 7.625436204151346e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104613.0, \"fp\": 3106.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9711657166481018, \"fp_rate\": 0.028834281489253044, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6778008341789246, \"recall\": 0.9993882179260254, \"specificity\": 0.9711657166481018, \"npv\": 0.999961793422699, \"accuracy\": 0.9727806448936462, \"f1\": 0.8077636296204722, \"f2\": 0.9127738042020563, \"f0_5\": 0.7244223690629297, \"p4\": 0.8877642970080213, \"phi\": 0.8110518446238733}, {\"truth_threshold\": -13.658719363407226, \"match_probability\": 7.731828085134784e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104619.0, \"fp\": 3100.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9712214469909668, \"fp_rate\": 0.02877858094871044, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6782229542732239, \"recall\": 0.9993882179260254, \"specificity\": 0.9712214469909668, \"npv\": 0.999961793422699, \"accuracy\": 0.9728331565856934, \"f1\": 0.8080633193173387, \"f2\": 0.9129268428994579, \"f0_5\": 0.7248080933575898, \"p4\": 0.88795690336216, \"phi\": 0.8113276650463707}, {\"truth_threshold\": -13.638983051463589, \"match_probability\": 7.838319256873248e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104694.0, \"fp\": 3025.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9719176888465881, \"fp_rate\": 0.02808232605457306, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6835442781448364, \"recall\": 0.9993882179260254, \"specificity\": 0.9719176888465881, \"npv\": 0.999961793422699, \"accuracy\": 0.9734895825386047, \"f1\": 0.811828290985898, \"f2\": 0.914844165663241, \"f0_5\": 0.7296645374547729, \"p4\": 0.8903714403660707, \"phi\": 0.8147965903430355}, {\"truth_threshold\": -13.630020299974422, \"match_probability\": 7.887162583630576e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104696.0, \"fp\": 3023.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9719362258911133, \"fp_rate\": 0.028063759207725525, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6836873292922974, \"recall\": 0.9993882179260254, \"specificity\": 0.9719362258911133, \"npv\": 0.999961793422699, \"accuracy\": 0.9735071063041687, \"f1\": 0.8119291705498602, \"f2\": 0.914895404519869, \"f0_5\": 0.729794933655006, \"p4\": 0.8904360049171126, \"phi\": 0.8148896121095014}, {\"truth_threshold\": -13.620384217600789, \"match_probability\": 7.940014830642456e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104706.0, \"fp\": 3013.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9720290899276733, \"fp_rate\": 0.027970924973487854, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6844034790992737, \"recall\": 0.9993882179260254, \"specificity\": 0.9720290899276733, \"npv\": 0.999961793422699, \"accuracy\": 0.973594605922699, \"f1\": 0.8124339446689463, \"f2\": 0.9151516849211463, \"f0_5\": 0.7304476143630103, \"p4\": 0.8907589659443974, \"phi\": 0.8153552985497615}, {\"truth_threshold\": -13.62012791902673, \"match_probability\": 7.94142540846483e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104731.0, \"fp\": 2988.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9722611904144287, \"fp_rate\": 0.027738839387893677, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6862003803253174, \"recall\": 0.9993882179260254, \"specificity\": 0.9722611904144287, \"npv\": 0.999961793422699, \"accuracy\": 0.9738134145736694, \"f1\": 0.8136986301369863, \"f2\": 0.915793014520379, \"f0_5\": 0.7320844350826872, \"p4\": 0.8915673780846355, \"phi\": 0.8165225482836159}, {\"truth_threshold\": -13.587825352952418, \"match_probability\": 8.121228339326687e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104744.0, \"fp\": 2975.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9723818302154541, \"fp_rate\": 0.027618154883384705, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6871384978294373, \"recall\": 0.9993882179260254, \"specificity\": 0.9723818302154541, \"npv\": 0.999961793422699, \"accuracy\": 0.9739271998405457, \"f1\": 0.8143578238923164, \"f2\": 0.9161268612770254, \"f0_5\": 0.7329384843182124, \"p4\": 0.8919883233549142, \"phi\": 0.8171312751258466}, {\"truth_threshold\": -13.57948824256959, \"match_probability\": 8.168291676898227e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104747.0, \"fp\": 2972.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.972409725189209, \"fp_rate\": 0.027590304613113403, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6873553395271301, \"recall\": 0.9993882179260254, \"specificity\": 0.972409725189209, \"npv\": 0.999961793422699, \"accuracy\": 0.9739534854888916, \"f1\": 0.8145100972326104, \"f2\": 0.9162039374053509, \"f0_5\": 0.7331358556617746, \"p4\": 0.8920855201304073, \"phi\": 0.8172718872025095}, {\"truth_threshold\": -13.576776647271398, \"match_probability\": 8.183657443338448e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104756.0, \"fp\": 2963.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9724932312965393, \"fp_rate\": 0.0275067538022995, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6880067586898804, \"recall\": 0.9993882179260254, \"specificity\": 0.9724932312965393, \"npv\": 0.999961793422699, \"accuracy\": 0.9740322232246399, \"f1\": 0.8149672591206736, \"f2\": 0.9164352436253471, \"f0_5\": 0.733728608004312, \"p4\": 0.8923772355774584, \"phi\": 0.8176942639613709}, {\"truth_threshold\": -13.571256522156887, \"match_probability\": 8.215027642217302e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104763.0, \"fp\": 2956.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9725582599639893, \"fp_rate\": 0.02744176983833313, \"fn_rate\": 0.000611807918176055, \"precision\": 0.688514232635498, \"recall\": 0.9993882179260254, \"specificity\": 0.9725582599639893, \"npv\": 0.999961793422699, \"accuracy\": 0.974093496799469, \"f1\": 0.8153231844272523, \"f2\": 0.9166152292239492, \"f0_5\": 0.7341903006876713, \"p4\": 0.8926042552128105, \"phi\": 0.8180231394560787}, {\"truth_threshold\": -13.552544518665215, \"match_probability\": 8.322263027541565e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104789.0, \"fp\": 2930.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9727995991706848, \"fp_rate\": 0.027200400829315186, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6904057264328003, \"recall\": 0.9993882179260254, \"specificity\": 0.9727995991706848, \"npv\": 0.9999618530273438, \"accuracy\": 0.9743210673332214, \"f1\": 0.8166479190101237, \"f2\": 0.9172843665768194, \"f0_5\": 0.7359102581429923, \"p4\": 0.8934484671946082, \"phi\": 0.8192477951779241}, {\"truth_threshold\": -13.552519886580205, \"match_probability\": 8.322405108420714e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104791.0, \"fp\": 2928.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.97281813621521, \"fp_rate\": 0.02718183398246765, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6905516982078552, \"recall\": 0.9993882179260254, \"specificity\": 0.97281813621521, \"npv\": 0.9999618530273438, \"accuracy\": 0.9743385314941406, \"f1\": 0.81675, \"f2\": 0.9173358791486494, \"f0_5\": 0.7360428964087775, \"p4\": 0.8935134716792413, \"phi\": 0.819342178610372}, {\"truth_threshold\": -13.547810942579765, \"match_probability\": 8.349611474340862e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104792.0, \"fp\": 2927.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9728274345397949, \"fp_rate\": 0.027172550559043884, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6906246542930603, \"recall\": 0.9993882179260254, \"specificity\": 0.9728274345397949, \"npv\": 0.9999618530273438, \"accuracy\": 0.9743472933769226, \"f1\": 0.8168010500656291, \"f2\": 0.9173616376042456, \"f0_5\": 0.7361092334730296, \"p4\": 0.8935459774127698, \"phi\": 0.8193893812120282}, {\"truth_threshold\": -13.546205747648768, \"match_probability\": 8.358905948674649e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104794.0, \"fp\": 2925.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9728460311889648, \"fp_rate\": 0.02715398371219635, \"fn_rate\": 0.000611807918176055, \"precision\": 0.69077068567276, \"recall\": 0.9993882179260254, \"specificity\": 0.9728460311889648, \"npv\": 0.9999618530273438, \"accuracy\": 0.9743648171424866, \"f1\": 0.816903169344252, \"f2\": 0.9174131588554099, \"f0_5\": 0.7362419434804165, \"p4\": 0.8936109958635052, \"phi\": 0.819483884792838}, {\"truth_threshold\": -13.52566887688985, \"match_probability\": 8.478736379153697e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104796.0, \"fp\": 2923.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.97286456823349, \"fp_rate\": 0.027135416865348816, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6909167766571045, \"recall\": 0.9993882179260254, \"specificity\": 0.97286456823349, \"npv\": 0.9999618530273438, \"accuracy\": 0.9743823409080505, \"f1\": 0.8170053141606752, \"f2\": 0.9174646858940155, \"f0_5\": 0.736374701347879, \"p4\": 0.8936760236274863, \"phi\": 0.8195783408372141}, {\"truth_threshold\": -13.507236168216439, \"match_probability\": 8.587751265895484e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104797.0, \"fp\": 2922.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.972873866558075, \"fp_rate\": 0.02712613344192505, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6909898519515991, \"recall\": 0.9993882179260254, \"specificity\": 0.972873866558075, \"npv\": 0.9999618530273438, \"accuracy\": 0.9743910431861877, \"f1\": 0.8170563961485557, \"f2\": 0.9174904515839137, \"f0_5\": 0.73644109823723, \"p4\": 0.8937085410025719, \"phi\": 0.8196255797591636}, {\"truth_threshold\": -13.493403508467667, \"match_probability\": 8.670480050088097e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104802.0, \"fp\": 2917.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.972920298576355, \"fp_rate\": 0.027079716324806213, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6913554072380066, \"recall\": 0.9993882179260254, \"specificity\": 0.972920298576355, \"npv\": 0.9999618530273438, \"accuracy\": 0.9744348526000977, \"f1\": 0.8173119019325786, \"f2\": 0.917619301744235, \"f0_5\": 0.7367732623697623, \"p4\": 0.8938711628189988, \"phi\": 0.8198619600696307}, {\"truth_threshold\": -13.491230185844472, \"match_probability\": 8.68355025059557e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104810.0, \"fp\": 2909.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9729945659637451, \"fp_rate\": 0.027005448937416077, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6919411420822144, \"recall\": 0.9993882179260254, \"specificity\": 0.9729945659637451, \"npv\": 0.9999618530273438, \"accuracy\": 0.974504828453064, \"f1\": 0.8177210437394405, \"f2\": 0.9178255372945638, \"f0_5\": 0.7373053486797563, \"p4\": 0.8941314789150806, \"phi\": 0.820240501238177}, {\"truth_threshold\": -13.486068873628113, \"match_probability\": 8.714669001157782e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104811.0, \"fp\": 2908.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9730038046836853, \"fp_rate\": 0.02699616551399231, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6920143961906433, \"recall\": 0.9993882179260254, \"specificity\": 0.9730038046836853, \"npv\": 0.9999618530273438, \"accuracy\": 0.974513590335846, \"f1\": 0.8177722152690864, \"f2\": 0.9178513232567287, \"f0_5\": 0.7373719135105855, \"p4\": 0.8941640289199514, \"phi\": 0.8202878421087065}, {\"truth_threshold\": -13.482880693850854, \"match_probability\": 8.733946966038259e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104814.0, \"fp\": 2905.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9730316996574402, \"fp_rate\": 0.02696831524372101, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6922343373298645, \"recall\": 0.9993882179260254, \"specificity\": 0.9730316996574402, \"npv\": 0.9999618530273438, \"accuracy\": 0.9745398759841919, \"f1\": 0.8179257682919197, \"f2\": 0.9179286898373185, \"f0_5\": 0.7375716801372646, \"p4\": 0.8942616929310845, \"phi\": 0.8204299851743396}, {\"truth_threshold\": -13.478147117765406, \"match_probability\": 8.762648161433872e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104887.0, \"fp\": 2832.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9737093448638916, \"fp_rate\": 0.02629062719643116, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6976297497749329, \"recall\": 0.9993882179260254, \"specificity\": 0.9737093448638916, \"npv\": 0.9999618530273438, \"accuracy\": 0.9751787781715393, \"f1\": 0.8216800804828974, \"f2\": 0.9198153049158173, \"f0_5\": 0.7424662515340211, \"p4\": 0.8966446729003258, \"phi\": 0.8239081610825522}, {\"truth_threshold\": -13.477683654006524, \"match_probability\": 8.76546335528595e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104892.0, \"fp\": 2827.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9737557768821716, \"fp_rate\": 0.026244210079312325, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6980023384094238, \"recall\": 0.9993882179260254, \"specificity\": 0.9737557768821716, \"npv\": 0.9999618530273438, \"accuracy\": 0.9752225279808044, \"f1\": 0.8219384866972765, \"f2\": 0.9199448089432039, \"f0_5\": 0.7428038743122186, \"p4\": 0.89680834818985, \"phi\": 0.824147854429975}, {\"truth_threshold\": -13.477126524939912, \"match_probability\": 8.768848692468843e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104895.0, \"fp\": 2824.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9737836122512817, \"fp_rate\": 0.026216359809041023, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6982260942459106, \"recall\": 0.9993882179260254, \"specificity\": 0.9737836122512817, \"npv\": 0.9999618530273438, \"accuracy\": 0.9752487540245056, \"f1\": 0.8220936084549573, \"f2\": 0.9200225288651084, \"f0_5\": 0.7430065954059586, \"p4\": 0.8969065815986705, \"phi\": 0.8242917137058196}, {\"truth_threshold\": -13.452763832010527, \"match_probability\": 8.918171692542147e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104915.0, \"fp\": 2804.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9739692807197571, \"fp_rate\": 0.02603069134056568, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6997215747833252, \"recall\": 0.9993882179260254, \"specificity\": 0.9739692807197571, \"npv\": 0.9999618530273438, \"accuracy\": 0.9754238128662109, \"f1\": 0.8231292517006803, \"f2\": 0.9205409974640744, \"f0_5\": 0.7443609022556391, \"p4\": 0.8975620127108098, \"phi\": 0.8252528021246467}, {\"truth_threshold\": -13.451231496996995, \"match_probability\": 8.927648169287332e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104918.0, \"fp\": 2801.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.973997175693512, \"fp_rate\": 0.02600284107029438, \"fn_rate\": 0.000611807918176055, \"precision\": 0.6999464631080627, \"recall\": 0.9993882179260254, \"specificity\": 0.973997175693512, \"npv\": 0.9999618530273438, \"accuracy\": 0.9754500985145569, \"f1\": 0.8232848232848233, \"f2\": 0.9206188181587623, \"f0_5\": 0.7445644742239846, \"p4\": 0.8976604087119248, \"phi\": 0.825397177558256}, {\"truth_threshold\": -13.450052236712335, \"match_probability\": 8.934947968305799e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104930.0, \"fp\": 2789.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9741085767745972, \"fp_rate\": 0.025891439989209175, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7008473873138428, \"recall\": 0.9993882179260254, \"specificity\": 0.9741085767745972, \"npv\": 0.9999618530273438, \"accuracy\": 0.9755551218986511, \"f1\": 0.8239076981274825, \"f2\": 0.9209302325581395, \"f0_5\": 0.7453798767967146, \"p4\": 0.8980542051610922, \"phi\": 0.8259755095659115}, {\"truth_threshold\": -13.448902328961408, \"match_probability\": 8.942071817928386e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104932.0, \"fp\": 2787.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9741271138191223, \"fp_rate\": 0.02587287314236164, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7009977698326111, \"recall\": 0.9993882179260254, \"specificity\": 0.9741271138191223, \"npv\": 0.9999618530273438, \"accuracy\": 0.9755725860595703, \"f1\": 0.8240116022447821, \"f2\": 0.9209821554421673, \"f0_5\": 0.7455159508922459, \"p4\": 0.8981198709698723, \"phi\": 0.8260719778725658}, {\"truth_threshold\": -13.433216826608655, \"match_probability\": 9.039814854715756e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104939.0, \"fp\": 2780.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9741920828819275, \"fp_rate\": 0.02580788917839527, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7015246152877808, \"recall\": 0.9993882179260254, \"specificity\": 0.9741920828819275, \"npv\": 0.9999619126319885, \"accuracy\": 0.9756338596343994, \"f1\": 0.8243754731264193, \"f2\": 0.9211639316528506, \"f0_5\": 0.7459926017262639, \"p4\": 0.8983497757583854, \"phi\": 0.8264099315077452}, {\"truth_threshold\": -13.412031496718027, \"match_probability\": 9.173527659224626e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104940.0, \"fp\": 2779.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9742013812065125, \"fp_rate\": 0.025798605754971504, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7015998959541321, \"recall\": 0.9993882179260254, \"specificity\": 0.9742013812065125, \"npv\": 0.9999619126319885, \"accuracy\": 0.9756426215171814, \"f1\": 0.8244274809160306, \"f2\": 0.9211899055406739, \"f0_5\": 0.7460607444622059, \"p4\": 0.898382628757975, \"phi\": 0.8264582297585541}, {\"truth_threshold\": -13.40797468219512, \"match_probability\": 9.199357265632287e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104943.0, \"fp\": 2776.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9742292165756226, \"fp_rate\": 0.025770755484700203, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7018259763717651, \"recall\": 0.9993882179260254, \"specificity\": 0.9742292165756226, \"npv\": 0.9999619126319885, \"accuracy\": 0.9756689071655273, \"f1\": 0.8245835436648158, \"f2\": 0.9212678359934577, \"f0_5\": 0.746265247384531, \"p4\": 0.8984812019499452, \"phi\": 0.8266032469720588}, {\"truth_threshold\": -13.37861144421449, \"match_probability\": 9.38849283863665e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 104951.0, \"fp\": 2768.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9743034839630127, \"fp_rate\": 0.025696488097310066, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7024295926094055, \"recall\": 0.9993882179260254, \"specificity\": 0.9743034839630127, \"npv\": 0.9999619126319885, \"accuracy\": 0.9757388830184937, \"f1\": 0.825, \"f2\": 0.9214757150110001, \"f0_5\": 0.7468111370182416, \"p4\": 0.8987441679238308, \"phi\": 0.8269901636304124}, {\"truth_threshold\": -13.372112684331027, \"match_probability\": 9.430875614710997e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105011.0, \"fp\": 2708.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9748604893684387, \"fp_rate\": 0.02513948269188404, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7069898247718811, \"recall\": 0.9993882179260254, \"specificity\": 0.9748604893684387, \"npv\": 0.9999619126319885, \"accuracy\": 0.9762640595436096, \"f1\": 0.8281368821292776, \"f2\": 0.9230378030174606, \"f0_5\": 0.7509309060819197, \"p4\": 0.9007212529297449, \"phi\": 0.8299077535410944}, {\"truth_threshold\": -13.369732644466504, \"match_probability\": 9.446445268762715e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105014.0, \"fp\": 2705.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9748883843421936, \"fp_rate\": 0.02511163242161274, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7072194218635559, \"recall\": 0.9993882179260254, \"specificity\": 0.9748883843421936, \"npv\": 0.9999619126319885, \"accuracy\": 0.9762902855873108, \"f1\": 0.8282943525385055, \"f2\": 0.9231160464524879, \"f0_5\": 0.7511380880121397, \"p4\": 0.9008203319721374, \"phi\": 0.8300543179447247}, {\"truth_threshold\": -13.36694360718949, \"match_probability\": 9.464723196057136e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105018.0, \"fp\": 2701.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9749255180358887, \"fp_rate\": 0.02507449872791767, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7075257301330566, \"recall\": 0.9993882179260254, \"specificity\": 0.9749255180358887, \"npv\": 0.9999619126319885, \"accuracy\": 0.976325273513794, \"f1\": 0.8285044062638687, \"f2\": 0.9232203916692571, \"f0_5\": 0.7514145084870509, \"p4\": 0.9009524707453929, \"phi\": 0.8302499224173581}, {\"truth_threshold\": -13.35095924344746, \"match_probability\": 9.570160738609945e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105019.0, \"fp\": 2700.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9749347567558289, \"fp_rate\": 0.025065215304493904, \"fn_rate\": 0.000611807918176055, \"precision\": 0.707602322101593, \"recall\": 0.9993882179260254, \"specificity\": 0.9749347567558289, \"npv\": 0.9999619126319885, \"accuracy\": 0.9763340353965759, \"f1\": 0.8285569363428861, \"f2\": 0.9232464816594134, \"f0_5\": 0.7514836453972489, \"p4\": 0.9009855114017564, \"phi\": 0.8302988234491039}, {\"truth_threshold\": -13.35040211438085, \"match_probability\": 9.573856830744521e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105021.0, \"fp\": 2698.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9749533534049988, \"fp_rate\": 0.02504664845764637, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7077556252479553, \"recall\": 0.9993882179260254, \"specificity\": 0.9749533534049988, \"npv\": 0.9999619126319885, \"accuracy\": 0.9763515591621399, \"f1\": 0.8286620164870007, \"f2\": 0.9232986660637577, \"f0_5\": 0.7516219573919846, \"p4\": 0.9010515998719588, \"phi\": 0.8303966486501855}, {\"truth_threshold\": -13.33984813277707, \"match_probability\": 9.644144046056575e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105028.0, \"fp\": 2691.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.975018322467804, \"fp_rate\": 0.02498166449368, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7082926630973816, \"recall\": 0.9993882179260254, \"specificity\": 0.975018322467804, \"npv\": 0.9999619126319885, \"accuracy\": 0.976412832736969, \"f1\": 0.829030006978367, \"f2\": 0.9234813579444272, \"f0_5\": 0.7521064505732308, \"p4\": 0.9012829846984037, \"phi\": 0.8307393574931566}, {\"truth_threshold\": -13.330877600405804, \"match_probability\": 9.704291343635909e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105029.0, \"fp\": 2690.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9750276207923889, \"fp_rate\": 0.024972381070256233, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7083694934844971, \"recall\": 0.9993882179260254, \"specificity\": 0.9750276207923889, \"npv\": 0.9999619126319885, \"accuracy\": 0.976421594619751, \"f1\": 0.829082603730491, \"f2\": 0.9235074626865671, \"f0_5\": 0.7521757148777456, \"p4\": 0.9013160492238317, \"phi\": 0.8307883357407531}, {\"truth_threshold\": -13.32337144687755, \"match_probability\": 9.754908138568092e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105049.0, \"fp\": 2670.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9752132892608643, \"fp_rate\": 0.02478671446442604, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7099087238311768, \"recall\": 0.9993882179260254, \"specificity\": 0.9752132892608643, \"npv\": 0.9999619126319885, \"accuracy\": 0.9765965938568115, \"f1\": 0.8301359420658112, \"f2\": 0.9240298676320851, \"f0_5\": 0.7535636850117636, \"p4\": 0.9019778416283893, \"phi\": 0.8317697600020948}, {\"truth_threshold\": -13.298475484784294, \"match_probability\": 9.924688345645235e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105067.0, \"fp\": 2652.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9753803610801697, \"fp_rate\": 0.024619612842798233, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7112997770309448, \"recall\": 0.9993882179260254, \"specificity\": 0.9753803610801697, \"npv\": 0.9999619126319885, \"accuracy\": 0.9767541885375977, \"f1\": 0.8310862375985755, \"f2\": 0.9245005376648368, \"f0_5\": 0.7548172450441292, \"p4\": 0.9025742733233351, \"phi\": 0.8326557239456719}, {\"truth_threshold\": -13.297111201770775, \"match_probability\": 9.934077122707131e-05, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105068.0, \"fp\": 2651.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9753896594047546, \"fp_rate\": 0.024610329419374466, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7113772630691528, \"recall\": 0.9993882179260254, \"specificity\": 0.9753896594047546, \"npv\": 0.9999619126319885, \"accuracy\": 0.9767628908157349, \"f1\": 0.8311390955924441, \"f2\": 0.9245267000594278, \"f0_5\": 0.7548870095660613, \"p4\": 0.9026074311866621, \"phi\": 0.8327050053439141}, {\"truth_threshold\": -13.285307086158964, \"match_probability\": 0.00010015682889680102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105070.0, \"fp\": 2649.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9754082560539246, \"fp_rate\": 0.024591762572526932, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7115321755409241, \"recall\": 0.9993882179260254, \"specificity\": 0.9754082560539246, \"npv\": 0.9999619126319885, \"accuracy\": 0.9767804145812988, \"f1\": 0.8312448317537052, \"f2\": 0.9245790292910712, \"f0_5\": 0.7550265773052923, \"p4\": 0.9026737541090611, \"phi\": 0.832803669223933}, {\"truth_threshold\": -13.281250271636058, \"match_probability\": 0.00010043883487264186, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105072.0, \"fp\": 2647.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9754267930984497, \"fp_rate\": 0.024573195725679398, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7116872072219849, \"recall\": 0.9993882179260254, \"specificity\": 0.9754267930984497, \"npv\": 0.9999619126319885, \"accuracy\": 0.9767979383468628, \"f1\": 0.8313505948215535, \"f2\": 0.9246313644468344, \"f0_5\": 0.7551661966621978, \"p4\": 0.9027400866275286, \"phi\": 0.8329022867497171}, {\"truth_threshold\": -13.27169624029798, \"match_probability\": 0.00010110611577451472, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105073.0, \"fp\": 2646.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9754360914230347, \"fp_rate\": 0.02456391230225563, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7117646932601929, \"recall\": 0.9993882179260254, \"specificity\": 0.9754360914230347, \"npv\": 0.9999619126319885, \"accuracy\": 0.9768067002296448, \"f1\": 0.8314034864486576, \"f2\": 0.9246575342465754, \"f0_5\": 0.7552360257062277, \"p4\": 0.9027732564859414, \"phi\": 0.832951607246233}, {\"truth_threshold\": -13.267448589163669, \"match_probability\": 0.00010140420561743234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105082.0, \"fp\": 2637.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9755196571350098, \"fp_rate\": 0.024480361491441727, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7124632000923157, \"recall\": 0.9993882179260254, \"specificity\": 0.9755196571350098, \"npv\": 0.9999619126319885, \"accuracy\": 0.9768854379653931, \"f1\": 0.8318798141192947, \"f2\": 0.924893129122668, \"f0_5\": 0.7558650687150062, \"p4\": 0.9030718932340956, \"phi\": 0.8333959994733128}, {\"truth_threshold\": -13.255531747941975, \"match_probability\": 0.00010224519995627595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105090.0, \"fp\": 2629.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9755939245223999, \"fp_rate\": 0.02440609410405159, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7130852341651917, \"recall\": 0.9993882179260254, \"specificity\": 0.9755939245223999, \"npv\": 0.9999619126319885, \"accuracy\": 0.9769554734230042, \"f1\": 0.832303674925164, \"f2\": 0.9251026476001699, \"f0_5\": 0.756425098402408, \"p4\": 0.9033375114620167, \"phi\": 0.8337914878276945}, {\"truth_threshold\": -13.250352769458845, \"match_probability\": 0.0001026128610518199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105091.0, \"fp\": 2628.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9756031632423401, \"fp_rate\": 0.024396810680627823, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7131630778312683, \"recall\": 0.9993882179260254, \"specificity\": 0.9756031632423401, \"npv\": 0.9999619126319885, \"accuracy\": 0.9769642353057861, \"f1\": 0.8323566878980891, \"f2\": 0.925128844084499, \"f0_5\": 0.7564951604686704, \"p4\": 0.9033707245568863, \"phi\": 0.833840949515548}, {\"truth_threshold\": -13.245388273771965, \"match_probability\": 0.00010296653666957768, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105094.0, \"fp\": 2625.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.975631058216095, \"fp_rate\": 0.02436896041035652, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7133966684341431, \"recall\": 0.9993882179260254, \"specificity\": 0.975631058216095, \"npv\": 0.9999619126319885, \"accuracy\": 0.9769904613494873, \"f1\": 0.8325157673440785, \"f2\": 0.9252074424400328, \"f0_5\": 0.7567054245610785, \"p4\": 0.9034703782696235, \"phi\": 0.8339893817690548}, {\"truth_threshold\": -13.240219196630427, \"match_probability\": 0.00010333608220100718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105096.0, \"fp\": 2623.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9756495952606201, \"fp_rate\": 0.024350393563508987, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7135524749755859, \"recall\": 0.9993882179260254, \"specificity\": 0.9756495952606201, \"npv\": 0.9999619126319885, \"accuracy\": 0.9770079851150513, \"f1\": 0.8326218540936604, \"f2\": 0.9252598487637713, \"f0_5\": 0.7568456655701247, \"p4\": 0.9035368261041774, \"phi\": 0.8340884536890635}, {\"truth_threshold\": -13.225496630409722, \"match_probability\": 0.00010439590554225565, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105097.0, \"fp\": 2622.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9756588935852051, \"fp_rate\": 0.02434111014008522, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7136303782463074, \"recall\": 0.9993882179260254, \"specificity\": 0.9756588935852051, \"npv\": 0.9999619126319885, \"accuracy\": 0.9770167469978333, \"f1\": 0.8326749076080031, \"f2\": 0.9252860541520336, \"f0_5\": 0.756915805569714, \"p4\": 0.9035700536300598, \"phi\": 0.8341379625942572}, {\"truth_threshold\": -13.217729551021455, \"match_probability\": 0.00010495940132709673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105100.0, \"fp\": 2619.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9756867289543152, \"fp_rate\": 0.02431325986981392, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7138643264770508, \"recall\": 0.9993882179260254, \"specificity\": 0.9756867289543152, \"npv\": 0.9999619722366333, \"accuracy\": 0.9770429730415344, \"f1\": 0.8328341087247467, \"f2\": 0.925364679223906, \"f0_5\": 0.7571263035921205, \"p4\": 0.9036697506452772, \"phi\": 0.8342865365768004}, {\"truth_threshold\": -13.203318251743953, \"match_probability\": 0.00010601299904713591, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105102.0, \"fp\": 2617.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9757053256034851, \"fp_rate\": 0.024294693022966385, \"fn_rate\": 0.000611807918176055, \"precision\": 0.714020311832428, \"recall\": 0.9993882179260254, \"specificity\": 0.9757053256034851, \"npv\": 0.9999619722366333, \"accuracy\": 0.9770604968070984, \"f1\": 0.832940276626936, \"f2\": 0.9254171033623205, \"f0_5\": 0.7572667006629271, \"p4\": 0.9037362273560215, \"phi\": 0.8343857030703234}, {\"truth_threshold\": -13.196957564074884, \"match_probability\": 0.00010648138098205738, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105103.0, \"fp\": 2616.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9757145643234253, \"fp_rate\": 0.024285409599542618, \"fn_rate\": 0.000611807918176055, \"precision\": 0.714098334312439, \"recall\": 0.9993882179260254, \"specificity\": 0.9757145643234253, \"npv\": 0.9999619722366333, \"accuracy\": 0.9770692586898804, \"f1\": 0.8329933707292198, \"f2\": 0.9254433176590562, \"f0_5\": 0.7573369187259493, \"p4\": 0.9037694693223609, \"phi\": 0.8344352592699309}, {\"truth_threshold\": -13.185867923127615, \"match_probability\": 0.00010730294279389903, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105104.0, \"fp\": 2615.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9757238626480103, \"fp_rate\": 0.02427612617611885, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7141764163970947, \"recall\": 0.9993882179260254, \"specificity\": 0.9757238626480103, \"npv\": 0.9999619722366333, \"accuracy\": 0.9770780205726624, \"f1\": 0.8330464716006885, \"f2\": 0.925469533440979, \"f0_5\": 0.7574071498122131, \"p4\": 0.9038027136963619, \"phi\": 0.8344848233587998}, {\"truth_threshold\": -13.17711863273896, \"match_probability\": 0.0001079555931850617, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105159.0, \"fp\": 2560.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9762344360351562, \"fp_rate\": 0.02376553788781166, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7184957265853882, \"recall\": 0.9993882179260254, \"specificity\": 0.9762344360351562, \"npv\": 0.9999619722366333, \"accuracy\": 0.9775593876838684, \"f1\": 0.8359774820880246, \"f2\": 0.9269136923338819, \"f0_5\": 0.7612900219042736, \"p4\": 0.9056348697640325, \"phi\": 0.8372237626901593}, {\"truth_threshold\": -13.160952598963492, \"match_probability\": 0.000109171953320352, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105162.0, \"fp\": 2557.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9762623310089111, \"fp_rate\": 0.02373768761754036, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7187328338623047, \"recall\": 0.9993882179260254, \"specificity\": 0.9762623310089111, \"npv\": 0.9999619722366333, \"accuracy\": 0.9775856137275696, \"f1\": 0.8361379486851366, \"f2\": 0.9269925942740402, \"f0_5\": 0.7615029602349541, \"p4\": 0.9057350159022068, \"phi\": 0.8373738148489847}, {\"truth_threshold\": -13.156219022878043, \"match_probability\": 0.00010953070257039976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105183.0, \"fp\": 2536.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9764572381973267, \"fp_rate\": 0.02354273572564125, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7203969359397888, \"recall\": 0.9993882179260254, \"specificity\": 0.9764572381973267, \"npv\": 0.9999619722366333, \"accuracy\": 0.9777694344520569, \"f1\": 0.8372629420809841, \"f2\": 0.9275452841973766, \"f0_5\": 0.7629968704750338, \"p4\": 0.9064366499217587, \"phi\": 0.8384264378847398}, {\"truth_threshold\": -13.155423561639642, \"match_probability\": 0.00010959110473373347, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105209.0, \"fp\": 2510.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.976698637008667, \"fp_rate\": 0.023301366716623306, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7224679589271545, \"recall\": 0.9993882179260254, \"specificity\": 0.976698637008667, \"npv\": 0.9999619722366333, \"accuracy\": 0.9779969453811646, \"f1\": 0.8386599922988063, \"f2\": 0.9282304807364473, \"f0_5\": 0.7648546144121365, \"p4\": 0.9073068239230662, \"phi\": 0.8397346376192175}, {\"truth_threshold\": -13.144591841378135, \"match_probability\": 0.00011041691751766564, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105210.0, \"fp\": 2509.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.976707935333252, \"fp_rate\": 0.02329208329319954, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7225478291511536, \"recall\": 0.9993882179260254, \"specificity\": 0.976707935333252, \"npv\": 0.9999619722366333, \"accuracy\": 0.9780057072639465, \"f1\": 0.8387138181118028, \"f2\": 0.928256854666856, \"f0_5\": 0.7649262467806135, \"p4\": 0.9073403250060119, \"phi\": 0.8397851285542863}, {\"truth_threshold\": -13.140724178604605, \"match_probability\": 0.00011071329408710606, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105221.0, \"fp\": 2498.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9768100380897522, \"fp_rate\": 0.0231899656355381, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7234278321266174, \"recall\": 0.9993882179260254, \"specificity\": 0.9768100380897522, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781019687652588, \"f1\": 0.8393063583815029, \"f2\": 0.9285470668485676, \"f0_5\": 0.7657150892982703, \"p4\": 0.9077089977516362, \"phi\": 0.8403402837408895}, {\"truth_threshold\": -13.138142209485142, \"match_probability\": 0.0001109115913819088, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105222.0, \"fp\": 2497.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9768193364143372, \"fp_rate\": 0.023180682212114334, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7235079407691956, \"recall\": 0.9993882179260254, \"specificity\": 0.9768193364143372, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781107306480408, \"f1\": 0.8393602671976363, \"f2\": 0.9285734587727027, \"f0_5\": 0.7657868829403216, \"p4\": 0.9077425280839255, \"phi\": 0.8403907941316265}, {\"truth_threshold\": -13.129132521974459, \"match_probability\": 0.00011160632841900145, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105224.0, \"fp\": 2495.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9768378734588623, \"fp_rate\": 0.0231621153652668, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7236681580543518, \"recall\": 0.9993882179260254, \"specificity\": 0.9768378734588623, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781282544136047, \"f1\": 0.839468105608017, \"f2\": 0.9286262471220261, \"f0_5\": 0.7659305106203405, \"p4\": 0.9078095960663142, \"phi\": 0.8404919176065094}, {\"truth_threshold\": -13.128331212114126, \"match_probability\": 0.00011166832773299061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105225.0, \"fp\": 2494.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9768471717834473, \"fp_rate\": 0.023152831941843033, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7237483263015747, \"recall\": 0.9993882179260254, \"specificity\": 0.9768471717834473, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781370162963867, \"f1\": 0.8395220352049338, \"f2\": 0.9286526435474701, \"f0_5\": 0.7660023446658851, \"p4\": 0.9078431337169477, \"phi\": 0.8405424524596454}, {\"truth_threshold\": -13.110978466636599, \"match_probability\": 0.00011301943257451342, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105229.0, \"fp\": 2490.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9768843054771423, \"fp_rate\": 0.023115700110793114, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7240691781044006, \"recall\": 0.9993882179260254, \"specificity\": 0.9768843054771423, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781720042228699, \"f1\": 0.8397378229019407, \"f2\": 0.9287582442574482, \"f0_5\": 0.7662898156400995, \"p4\": 0.9079773087219809, \"phi\": 0.8407447517270594}, {\"truth_threshold\": -13.103878168389588, \"match_probability\": 0.00011357697123354685, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105231.0, \"fp\": 2488.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9769028425216675, \"fp_rate\": 0.02309713326394558, \"fn_rate\": 0.000611807918176055, \"precision\": 0.724229633808136, \"recall\": 0.9993882179260254, \"specificity\": 0.9769028425216675, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781895279884338, \"f1\": 0.8398457583547558, \"f2\": 0.9288110536191505, \"f0_5\": 0.7664336320555529, \"p4\": 0.90804441086974, \"phi\": 0.8408459112279257}, {\"truth_threshold\": -13.102322950463744, \"match_probability\": 0.00011369945871936094, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105232.0, \"fp\": 2487.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9769121408462524, \"fp_rate\": 0.023087849840521812, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7243099212646484, \"recall\": 0.9993882179260254, \"specificity\": 0.9769121408462524, \"npv\": 0.9999619722366333, \"accuracy\": 0.9781982898712158, \"f1\": 0.8398997364869207, \"f2\": 0.928837460552128, \"f0_5\": 0.7665055605086575, \"p4\": 0.9080779656058663, \"phi\": 0.8408965032334617}, {\"truth_threshold\": -13.101087992847983, \"match_probability\": 0.00011379681688434509, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105235.0, \"fp\": 2484.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9769399762153625, \"fp_rate\": 0.02305999957025051, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7245509028434753, \"recall\": 0.9993882179260254, \"specificity\": 0.9769399762153625, \"npv\": 0.9999619722366333, \"accuracy\": 0.978224515914917, \"f1\": 0.8400617125224994, \"f2\": 0.9289166903611032, \"f0_5\": 0.766721426895095, \"p4\": 0.9081786444664425, \"phi\": 0.8410484065806161}, {\"truth_threshold\": -13.098746770677547, \"match_probability\": 0.000113981616530609, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105237.0, \"fp\": 2482.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9769585728645325, \"fp_rate\": 0.023041432723402977, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7247115969657898, \"recall\": 0.9993882179260254, \"specificity\": 0.9769585728645325, \"npv\": 0.9999619722366333, \"accuracy\": 0.978242039680481, \"f1\": 0.8401697312588402, \"f2\": 0.9289695177434031, \"f0_5\": 0.7668654053800291, \"p4\": 0.9082457759196675, \"phi\": 0.8411496641933975}, {\"truth_threshold\": -13.079119553275602, \"match_probability\": 0.00011554270085709015, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105246.0, \"fp\": 2473.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9770421385765076, \"fp_rate\": 0.022957881912589073, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7254357933998108, \"recall\": 0.9993882179260254, \"specificity\": 0.9770421385765076, \"npv\": 0.9999619722366333, \"accuracy\": 0.9783207774162292, \"f1\": 0.8406561595368286, \"f2\": 0.929207315338889, \"f0_5\": 0.767513978292534, \"p4\": 0.9085479884281606, \"phi\": 0.8416058071647998}, {\"truth_threshold\": -13.047804549579142, \"match_probability\": 0.00011807777732138161, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105247.0, \"fp\": 2472.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9770513772964478, \"fp_rate\": 0.022948598489165306, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7255163192749023, \"recall\": 0.9993882179260254, \"specificity\": 0.9770513772964478, \"npv\": 0.9999619722366333, \"accuracy\": 0.9783295392990112, \"f1\": 0.8407102418939784, \"f2\": 0.9292337448091473, \"f0_5\": 0.7675861096752972, \"p4\": 0.9085815798202184, \"phi\": 0.8416565220116373}, {\"truth_threshold\": -13.033889747851887, \"match_probability\": 0.00011922201156842607, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105248.0, \"fp\": 2471.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9770606756210327, \"fp_rate\": 0.02293931506574154, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7255969047546387, \"recall\": 0.9993882179260254, \"specificity\": 0.9770606756210327, \"npv\": 0.9999619722366333, \"accuracy\": 0.9783383011817932, \"f1\": 0.8407643312101911, \"f2\": 0.9292601757829166, \"f0_5\": 0.7676582546172283, \"p4\": 0.9086151736581485, \"phi\": 0.8417073234002009}, {\"truth_threshold\": -13.033864829682566, \"match_probability\": 0.0001192240705383744, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105250.0, \"fp\": 2469.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9770792722702026, \"fp_rate\": 0.022920748218894005, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7257580757141113, \"recall\": 0.9993882179260254, \"specificity\": 0.9770792722702026, \"npv\": 0.9999619722366333, \"accuracy\": 0.9783558249473572, \"f1\": 0.8408725307251785, \"f2\": 0.9293130422415019, \"f0_5\": 0.7678025851938896, \"p4\": 0.9086823686726982, \"phi\": 0.8418087941459139}, {\"truth_threshold\": -13.030688140794185, \"match_probability\": 0.00011948684939693033, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105288.0, \"fp\": 2431.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9774320125579834, \"fp_rate\": 0.022567978128790855, \"fn_rate\": 0.000611807918176055, \"precision\": 0.728834331035614, \"recall\": 0.9993882179260254, \"specificity\": 0.9774320125579834, \"npv\": 0.9999620318412781, \"accuracy\": 0.9786884188652039, \"f1\": 0.8429336257498549, \"f2\": 0.9303186490873366, \"f0_5\": 0.7705552148686259, \"p4\": 0.9099609358736088, \"phi\": 0.8437434725643094}, {\"truth_threshold\": -13.019974009598599, \"match_probability\": 0.00012037741083110459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105305.0, \"fp\": 2414.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9775898456573486, \"fp_rate\": 0.022410159930586815, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7302190661430359, \"recall\": 0.9993882179260254, \"specificity\": 0.9775898456573486, \"npv\": 0.9999620318412781, \"accuracy\": 0.9788371920585632, \"f1\": 0.8438589693917087, \"f2\": 0.9307692307692308, \"f0_5\": 0.771793054571226, \"p4\": 0.9105340741828268, \"phi\": 0.8446128065265979}, {\"truth_threshold\": -13.017867430819072, \"match_probability\": 0.00012055328939691265, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105307.0, \"fp\": 2412.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9776083827018738, \"fp_rate\": 0.02239159308373928, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7303823232650757, \"recall\": 0.9993882179260254, \"specificity\": 0.9776083827018738, \"npv\": 0.9999620318412781, \"accuracy\": 0.9788547158241272, \"f1\": 0.8439679669336089, \"f2\": 0.930822269075161, \"f0_5\": 0.7719389442842965, \"p4\": 0.9106015489618593, \"phi\": 0.8447152994528553}, {\"truth_threshold\": -13.014989215855886, \"match_probability\": 0.00012079400740214596, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105309.0, \"fp\": 2410.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9776269793510437, \"fp_rate\": 0.022373026236891747, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7305456399917603, \"recall\": 0.9993882179260254, \"specificity\": 0.9776269793510437, \"npv\": 0.9999620318412781, \"accuracy\": 0.9788721799850464, \"f1\": 0.8440769926366103, \"f2\": 0.9308753134260315, \"f0_5\": 0.7720848891619795, \"p4\": 0.9106690335890195, \"phi\": 0.8448177471953684}, {\"truth_threshold\": -12.99509571421677, \"match_probability\": 0.0001224709824622548, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105313.0, \"fp\": 2406.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9776641130447388, \"fp_rate\": 0.022335892543196678, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7308725118637085, \"recall\": 0.9993882179260254, \"specificity\": 0.9776641130447388, \"npv\": 0.9999620318412781, \"accuracy\": 0.9789072275161743, \"f1\": 0.8442951285695827, \"f2\": 0.9309814202667275, \"f0_5\": 0.7723769445363847, \"p4\": 0.9108040323963814, \"phi\": 0.8450228214859029}, {\"truth_threshold\": -12.99348383378085, \"match_probability\": 0.0001226078753454287, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105335.0, \"fp\": 2384.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9778683185577393, \"fp_rate\": 0.022131657227873802, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7326754927635193, \"recall\": 0.9993882179260254, \"specificity\": 0.9778683185577393, \"npv\": 0.9999620318412781, \"accuracy\": 0.9790997505187988, \"f1\": 0.8454968944099379, \"f2\": 0.9315654405474765, \"f0_5\": 0.7739872068230277, \"p4\": 0.9115472309073925, \"phi\": 0.8461529285285101}, {\"truth_threshold\": -12.991814146550242, \"match_probability\": 0.0001227498389369113, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105349.0, \"fp\": 2370.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9779983162879944, \"fp_rate\": 0.022001689299941063, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7338274717330933, \"recall\": 0.9993882179260254, \"specificity\": 0.9779983162879944, \"npv\": 0.9999620318412781, \"accuracy\": 0.979222297668457, \"f1\": 0.8462634373785779, \"f2\": 0.9319374714742127, \"f0_5\": 0.7750154196517531, \"p4\": 0.912020797576861, \"phi\": 0.8468742127598095}, {\"truth_threshold\": -12.968307521021096, \"match_probability\": 0.00012476600080211437, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105350.0, \"fp\": 2369.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9780076146125793, \"fp_rate\": 0.021992405876517296, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7339099049568176, \"recall\": 0.9993882179260254, \"specificity\": 0.9780076146125793, \"npv\": 0.9999620318412781, \"accuracy\": 0.979231059551239, \"f1\": 0.8463182436370701, \"f2\": 0.9319640564826701, \"f0_5\": 0.7750889679715303, \"p4\": 0.9120546423094088, \"phi\": 0.8469257850676872}, {\"truth_threshold\": -12.96284844185861, \"match_probability\": 0.000125238943632509, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105380.0, \"fp\": 2339.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.97828608751297, \"fp_rate\": 0.021713903173804283, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7363913059234619, \"recall\": 0.9993882179260254, \"specificity\": 0.97828608751297, \"npv\": 0.9999620318412781, \"accuracy\": 0.9794936180114746, \"f1\": 0.8479657387580299, \"f2\": 0.932762312633833, \"f0_5\": 0.7773019271948608, \"p4\": 0.9130711357815684, \"phi\": 0.8484772863853088}, {\"truth_threshold\": -12.95469514518766, \"match_probability\": 0.00012594863769379406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105383.0, \"fp\": 2336.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9783139228820801, \"fp_rate\": 0.021686052903532982, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7366403341293335, \"recall\": 0.9993882179260254, \"specificity\": 0.9783139228820801, \"npv\": 0.9999620318412781, \"accuracy\": 0.9795198440551758, \"f1\": 0.8481308411214953, \"f2\": 0.9328422134658215, \"f0_5\": 0.7775239183207197, \"p4\": 0.9131729078604245, \"phi\": 0.8486328965360865}, {\"truth_threshold\": -12.945019571112297, \"match_probability\": 0.00012679605580231664, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105386.0, \"fp\": 2333.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.978341817855835, \"fp_rate\": 0.02165820263326168, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7368896007537842, \"recall\": 0.9993882179260254, \"specificity\": 0.978341817855835, \"npv\": 0.9999620318412781, \"accuracy\": 0.9795461297035217, \"f1\": 0.8482960077896787, \"f2\": 0.9329221279876638, \"f0_5\": 0.7777460362805314, \"p4\": 0.913274702283631, \"phi\": 0.8487885045354769}, {\"truth_threshold\": -12.935364615102007, \"match_probability\": 0.0001276473508183884, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105387.0, \"fp\": 2332.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9783510565757751, \"fp_rate\": 0.021648919209837914, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7369726896286011, \"recall\": 0.9993882179260254, \"specificity\": 0.9783510565757751, \"npv\": 0.9999620318412781, \"accuracy\": 0.9795548915863037, \"f1\": 0.8483510776421709, \"f2\": 0.9329487692044092, \"f0_5\": 0.7778201038045808, \"p4\": 0.9133086387247209, \"phi\": 0.8488403909274244}, {\"truth_threshold\": -12.917540091409835, \"match_probability\": 0.00012923401380800394, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105388.0, \"fp\": 2331.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9783603549003601, \"fp_rate\": 0.021639635786414146, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7370558381080627, \"recall\": 0.9993882179260254, \"specificity\": 0.9783603549003601, \"npv\": 0.9999620318412781, \"accuracy\": 0.9795635938644409, \"f1\": 0.848406154645199, \"f2\": 0.9329754119427707, \"f0_5\": 0.7778941854374017, \"p4\": 0.9133425776496109, \"phi\": 0.8488922858527721}, {\"truth_threshold\": -12.91378612941807, \"match_probability\": 0.0001295706811884797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105393.0, \"fp\": 2326.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9784067869186401, \"fp_rate\": 0.02159321866929531, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7374717593193054, \"recall\": 0.9993882179260254, \"specificity\": 0.9784067869186401, \"npv\": 0.9999620318412781, \"accuracy\": 0.9796074032783508, \"f1\": 0.8486816469671385, \"f2\": 0.9331086484633839, \"f0_5\": 0.7782648053742437, \"p4\": 0.9135123095406434, \"phi\": 0.8491519674831991}, {\"truth_threshold\": -12.908997516441355, \"match_probability\": 0.00013000141249259437, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105396.0, \"fp\": 2323.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9784346222877502, \"fp_rate\": 0.02156536839902401, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7377215623855591, \"recall\": 0.9993882179260254, \"specificity\": 0.9784346222877502, \"npv\": 0.9999620318412781, \"accuracy\": 0.979633629322052, \"f1\": 0.8488470282559273, \"f2\": 0.9331886086434916, \"f0_5\": 0.7784873468998713, \"p4\": 0.9136141784983877, \"phi\": 0.8493079106077622}, {\"truth_threshold\": -12.905938790777679, \"match_probability\": 0.0001302772910472835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105400.0, \"fp\": 2319.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9784717559814453, \"fp_rate\": 0.02152823470532894, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7380548715591431, \"recall\": 0.9993882179260254, \"specificity\": 0.9784717559814453, \"npv\": 0.9999620318412781, \"accuracy\": 0.9796686172485352, \"f1\": 0.8490676369306738, \"f2\": 0.9332952435366376, \"f0_5\": 0.7787842669845053, \"p4\": 0.9137500385843691, \"phi\": 0.8495158493300727}, {\"truth_threshold\": -12.899477570206503, \"match_probability\": 0.00013086197986066049, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6534.0, \"tn\": 105405.0, \"fp\": 2314.0, \"fn\": 4.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9993882179260254, \"tn_rate\": 0.9785181879997253, \"fp_rate\": 0.021481817588210106, \"fn_rate\": 0.000611807918176055, \"precision\": 0.7384719848632812, \"recall\": 0.9993882179260254, \"specificity\": 0.9785181879997253, \"npv\": 0.9999620318412781, \"accuracy\": 0.9797124266624451, \"f1\": 0.8493435590796828, \"f2\": 0.9334285714285714, \"f0_5\": 0.7791557357500596, \"p4\": 0.9139199196595389, \"phi\": 0.8497760444229624}, {\"truth_threshold\": -12.89318461704425, \"match_probability\": 0.00013143396387359864, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105686.0, \"fp\": 2033.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9811268448829651, \"fp_rate\": 0.018873179331421852, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7624444961547852, \"recall\": 0.9980116486549377, \"specificity\": 0.9811268448829651, \"npv\": 0.9998770356178284, \"accuracy\": 0.9820929765701294, \"f1\": 0.8644674085850557, \"f2\": 0.9399308556611927, \"f0_5\": 0.8002207505518764, \"p4\": 0.9231644563203321, \"phi\": 0.8639550286236574}, {\"truth_threshold\": -12.89172493155798, \"match_probability\": 0.00013156699551119942, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105738.0, \"fp\": 1981.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.981609582901001, \"fp_rate\": 0.018390441313385963, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7671055793762207, \"recall\": 0.9980116486549377, \"specificity\": 0.981609582901001, \"npv\": 0.9998770952224731, \"accuracy\": 0.9825481176376343, \"f1\": 0.8674554639723477, \"f2\": 0.941341104506896, \"f0_5\": 0.8043242443666486, \"p4\": 0.924972732617575, \"phi\": 0.8668058741162198}, {\"truth_threshold\": -12.888264805296823, \"match_probability\": 0.000131882879773961, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105741.0, \"fp\": 1978.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9816374182701111, \"fp_rate\": 0.018362591043114662, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7673762440681458, \"recall\": 0.9980116486549377, \"specificity\": 0.9816374182701111, \"npv\": 0.9998770952224731, \"accuracy\": 0.9825743436813354, \"f1\": 0.8676284821487933, \"f2\": 0.9414225941422594, \"f0_5\": 0.8045622688039458, \"p4\": 0.9250772691925141, \"phi\": 0.8669711651627858}, {\"truth_threshold\": -12.880477377396538, \"match_probability\": 0.00013259659174915913, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105742.0, \"fp\": 1977.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.981646716594696, \"fp_rate\": 0.018353307619690895, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7674664855003357, \"recall\": 0.9980116486549377, \"specificity\": 0.981646716594696, \"npv\": 0.9998770952224731, \"accuracy\": 0.9825831055641174, \"f1\": 0.867686170212766, \"f2\": 0.9414497604894095, \"f0_5\": 0.8046416415922656, \"p4\": 0.9251121198905018, \"phi\": 0.8670262542846808}, {\"truth_threshold\": -12.879122795030069, \"match_probability\": 0.00013272113193143694, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105743.0, \"fp\": 1976.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9816559553146362, \"fp_rate\": 0.018344024196267128, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7675567865371704, \"recall\": 0.9980116486549377, \"specificity\": 0.9816559553146362, \"npv\": 0.9998770952224731, \"accuracy\": 0.9825918674468994, \"f1\": 0.8677438659485338, \"f2\": 0.9414769284044672, \"f0_5\": 0.8047210300429185, \"p4\": 0.9251469731754752, \"phi\": 0.8670813528659314}, {\"truth_threshold\": -12.868371303657707, \"match_probability\": 0.00013371378031433212, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105744.0, \"fp\": 1975.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9816652536392212, \"fp_rate\": 0.01833474077284336, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7676470875740051, \"recall\": 0.9980116486549377, \"specificity\": 0.9816652536392212, \"npv\": 0.9998770952224731, \"accuracy\": 0.9826006293296814, \"f1\": 0.8678015693576273, \"f2\": 0.9415040978875678, \"f0_5\": 0.8048004341605407, \"p4\": 0.9251818290477235, \"phi\": 0.8671364609093081}, {\"truth_threshold\": -12.855159471636746, \"match_probability\": 0.00013494375495891485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105746.0, \"fp\": 1973.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9816838502883911, \"fp_rate\": 0.018316173925995827, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7678277492523193, \"recall\": 0.9980116486549377, \"specificity\": 0.9816838502883911, \"npv\": 0.9998770952224731, \"accuracy\": 0.9826181530952454, \"f1\": 0.8679169992019155, \"f2\": 0.9415584415584416, \"f0_5\": 0.804959289415248, \"p4\": 0.9252515485552012, \"phi\": 0.8672467053935273}, {\"truth_threshold\": -12.840959816080838, \"match_probability\": 0.00013627830814563085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105747.0, \"fp\": 1972.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9816930890083313, \"fp_rate\": 0.01830689050257206, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7679181098937988, \"recall\": 0.9980116486549377, \"specificity\": 0.9816930890083313, \"npv\": 0.9998770952224731, \"accuracy\": 0.9826268553733826, \"f1\": 0.867974725640173, \"f2\": 0.9415856157464861, \"f0_5\": 0.8050387405616147, \"p4\": 0.925286412191009, \"phi\": 0.8673019222883936}, {\"truth_threshold\": -12.838949896844387, \"match_probability\": 0.00013646827336248136, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105748.0, \"fp\": 1971.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9817023873329163, \"fp_rate\": 0.018297607079148293, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7680084705352783, \"recall\": 0.9980116486549377, \"specificity\": 0.9817023873329163, \"npv\": 0.9998770952224731, \"accuracy\": 0.9826356172561646, \"f1\": 0.8680324597578821, \"f2\": 0.941612791503117, \"f0_5\": 0.8051182073935146, \"p4\": 0.9253212784152486, \"phi\": 0.867357068212356}, {\"truth_threshold\": -12.837226040693665, \"match_probability\": 0.00013663141256323392, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105750.0, \"fp\": 1969.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9817209839820862, \"fp_rate\": 0.01827904023230076, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7681893110275269, \"recall\": 0.9980116486549377, \"specificity\": 0.9817209839820862, \"npv\": 0.9998770952224731, \"accuracy\": 0.9826531410217285, \"f1\": 0.8681479510377861, \"f2\": 0.9416671477226808, \"f0_5\": 0.8052771881324974, \"p4\": 0.9253910186301799, \"phi\": 0.8674673884910463}, {\"truth_threshold\": -12.822665377916818, \"match_probability\": 0.0001380171809839419, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105756.0, \"fp\": 1963.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9817766547203064, \"fp_rate\": 0.018223339691758156, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7687323093414307, \"recall\": 0.9980116486549377, \"specificity\": 0.9817766547203064, \"npv\": 0.9998770952224731, \"accuracy\": 0.9827056527137756, \"f1\": 0.8684946093438041, \"f2\": 0.9418302540415704, \"f0_5\": 0.8057545072857496, \"p4\": 0.925600301427432, \"phi\": 0.8677986574610446}, {\"truth_threshold\": -12.798513746889503, \"match_probability\": 0.00014034679717873997, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105760.0, \"fp\": 1959.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9818137884140015, \"fp_rate\": 0.018186205998063087, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7690947651863098, \"recall\": 0.9980116486549377, \"specificity\": 0.9818137884140015, \"npv\": 0.9998770952224731, \"accuracy\": 0.9827406406402588, \"f1\": 0.8687258687258688, \"f2\": 0.9419390229818686, \"f0_5\": 0.8060730345406928, \"p4\": 0.9257398751091477, \"phi\": 0.8680197202330093}, {\"truth_threshold\": -12.795786905993364, \"match_probability\": 0.00014061228046790213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105762.0, \"fp\": 1957.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9818323850631714, \"fp_rate\": 0.018167639151215553, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7692761421203613, \"recall\": 0.9980116486549377, \"specificity\": 0.9818323850631714, \"npv\": 0.9998770952224731, \"accuracy\": 0.9827581644058228, \"f1\": 0.8688415446071904, \"f2\": 0.9419934168735924, \"f0_5\": 0.8062323926259082, \"p4\": 0.9258096775020234, \"phi\": 0.8681302684203943}, {\"truth_threshold\": -12.791489119334209, \"match_probability\": 0.00014103172965256942, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105763.0, \"fp\": 1956.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9818416237831116, \"fp_rate\": 0.018158355727791786, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7693668007850647, \"recall\": 0.9980116486549377, \"specificity\": 0.9818416237831116, \"npv\": 0.9998770952224731, \"accuracy\": 0.9827669262886047, \"f1\": 0.8688993941008056, \"f2\": 0.9420206161753241, \"f0_5\": 0.8063120952992932, \"p4\": 0.9258445825874801, \"phi\": 0.8681855567851666}, {\"truth_threshold\": -12.783454784252683, \"match_probability\": 0.00014181921138364112, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105766.0, \"fp\": 1953.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9818695187568665, \"fp_rate\": 0.018130505457520485, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7696390748023987, \"recall\": 0.9980116486549377, \"specificity\": 0.9818695187568665, \"npv\": 0.9998770952224731, \"accuracy\": 0.9827931523323059, \"f1\": 0.869072988811934, \"f2\": 0.942102223505631, \"f0_5\": 0.8065512978986403, \"p4\": 0.925949313403406, \"phi\": 0.868351559528666}, {\"truth_threshold\": -12.778432966508761, \"match_probability\": 0.00014231365382449512, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105770.0, \"fp\": 1949.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9819066524505615, \"fp_rate\": 0.018093371763825417, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7700023651123047, \"recall\": 0.9980116486549377, \"specificity\": 0.9819066524505615, \"npv\": 0.9998770952224731, \"accuracy\": 0.9828281998634338, \"f1\": 0.8693045563549161, \"f2\": 0.9422110552763819, \"f0_5\": 0.8068704555572044, \"p4\": 0.9260889908077667, \"phi\": 0.8685729225417287}, {\"truth_threshold\": -12.767258735373218, \"match_probability\": 0.00014342004923203499, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105772.0, \"fp\": 1947.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9819251894950867, \"fp_rate\": 0.018074804916977882, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7701841592788696, \"recall\": 0.9980116486549377, \"specificity\": 0.9819251894950867, \"npv\": 0.9998770952224731, \"accuracy\": 0.982845664024353, \"f1\": 0.8694203864090606, \"f2\": 0.9422654805914972, \"f0_5\": 0.8070301291248206, \"p4\": 0.9261588450793674, \"phi\": 0.8686836612612402}, {\"truth_threshold\": -12.76291925695341, \"match_probability\": 0.0001438520292945022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105774.0, \"fp\": 1945.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9819437861442566, \"fp_rate\": 0.018056238070130348, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7703660130500793, \"recall\": 0.9980116486549377, \"specificity\": 0.9819437861442566, \"npv\": 0.9998770952224731, \"accuracy\": 0.982863187789917, \"f1\": 0.8695362473347548, \"f2\": 0.9423199121945584, \"f0_5\": 0.8071898659013311, \"p4\": 0.9262287097336783, \"phi\": 0.868794518718948}, {\"truth_threshold\": -12.745915099684648, \"match_probability\": 0.00014555730750194265, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105775.0, \"fp\": 1944.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9819530248641968, \"fp_rate\": 0.01804695464670658, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7704569697380066, \"recall\": 0.9980116486549377, \"specificity\": 0.9819530248641968, \"npv\": 0.9998770952224731, \"accuracy\": 0.982871949672699, \"f1\": 0.8695941893782901, \"f2\": 0.9423471303544092, \"f0_5\": 0.8072697580046518, \"p4\": 0.9262636459550762, \"phi\": 0.8688499214904878}, {\"truth_threshold\": -12.741339121970988, \"match_probability\": 0.00014601965540294678, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105777.0, \"fp\": 1942.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9819716215133667, \"fp_rate\": 0.018028387799859047, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7706389427185059, \"recall\": 0.9980116486549377, \"specificity\": 0.9819716215133667, \"npv\": 0.9998770952224731, \"accuracy\": 0.9828894734382629, \"f1\": 0.8697100966344552, \"f2\": 0.9424015713914324, \"f0_5\": 0.8074295896649013, \"p4\": 0.9263335261878087, \"phi\": 0.8689607556905419}, {\"truth_threshold\": -12.741181523599199, \"match_probability\": 0.0001460356049663956, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105780.0, \"fp\": 1939.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9819994568824768, \"fp_rate\": 0.018000537529587746, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7709121108055115, \"recall\": 0.9980116486549377, \"specificity\": 0.9819994568824768, \"npv\": 0.9998770952224731, \"accuracy\": 0.9829156994819641, \"f1\": 0.8698840154646047, \"f2\": 0.9424832447423157, \"f0_5\": 0.8076694558597811, \"p4\": 0.9264383660161091, \"phi\": 0.869127159267783}, {\"truth_threshold\": -12.712225486285325, \"match_probability\": 0.0001489958266623492, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105864.0, \"fp\": 1855.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9827792644500732, \"fp_rate\": 0.01722073182463646, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7786396145820618, \"recall\": 0.9980116486549377, \"specificity\": 0.9827792644500732, \"npv\": 0.9998772144317627, \"accuracy\": 0.9836508631706238, \"f1\": 0.8747821423783348, \"f2\": 0.9447758600718175, \"f0_5\": 0.814444056118628, \"p4\": 0.9293834030796786, \"phi\": 0.8738204878675544}, {\"truth_threshold\": -12.710501630134601, \"match_probability\": 0.00014917393952744725, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105865.0, \"fp\": 1854.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9827885627746582, \"fp_rate\": 0.017211448401212692, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7787325382232666, \"recall\": 0.9980116486549377, \"specificity\": 0.9827885627746582, \"npv\": 0.9998772144317627, \"accuracy\": 0.9836596250534058, \"f1\": 0.874840785680767, \"f2\": 0.9448032202948076, \"f0_5\": 0.8145253907225246, \"p4\": 0.9294185741591392, \"phi\": 0.8738767617114518}, {\"truth_threshold\": -12.704522980025255, \"match_probability\": 0.00014979331882611843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105873.0, \"fp\": 1846.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9828628301620483, \"fp_rate\": 0.017137181013822556, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7794767618179321, \"recall\": 0.9980116486549377, \"specificity\": 0.9828628301620483, \"npv\": 0.9998772144317627, \"accuracy\": 0.9837296605110168, \"f1\": 0.8753102153061909, \"f2\": 0.9450221591402833, \"f0_5\": 0.8151766528409374, \"p4\": 0.9297000372429056, \"phi\": 0.8743273868301908}, {\"truth_threshold\": -12.703244435863416, \"match_probability\": 0.0001499261074820199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105874.0, \"fp\": 1845.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9828721284866333, \"fp_rate\": 0.01712789759039879, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7795698642730713, \"recall\": 0.9980116486549377, \"specificity\": 0.9828721284866333, \"npv\": 0.9998772144317627, \"accuracy\": 0.9837384223937988, \"f1\": 0.875368929433861, \"f2\": 0.9450495336307282, \"f0_5\": 0.8152581338397721, \"p4\": 0.9297352319388058, \"phi\": 0.8743837490633672}, {\"truth_threshold\": -12.688754261803199, \"match_probability\": 0.00015143929715512585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105875.0, \"fp\": 1844.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9828813672065735, \"fp_rate\": 0.01711861416697502, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7796630263328552, \"recall\": 0.9980116486549377, \"specificity\": 0.9828813672065735, \"npv\": 0.9998772144317627, \"accuracy\": 0.9837471842765808, \"f1\": 0.8754276514389213, \"f2\": 0.9450769097071348, \"f0_5\": 0.8153396311291048, \"p4\": 0.9297704292602283, \"phi\": 0.8744402021440334}, {\"truth_threshold\": -12.68475559360462, \"match_probability\": 0.0001518595546398711, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105876.0, \"fp\": 1843.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9828906655311584, \"fp_rate\": 0.017109330743551254, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7797561883926392, \"recall\": 0.9980116486549377, \"specificity\": 0.9828906655311584, \"npv\": 0.9998772144317627, \"accuracy\": 0.9837559461593628, \"f1\": 0.8754863813229572, \"f2\": 0.9451042873696408, \"f0_5\": 0.8154211447138215, \"p4\": 0.9298056292074679, \"phi\": 0.8744965840548834}, {\"truth_threshold\": -12.677506015435792, \"match_probability\": 0.00015262445639614624, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6525.0, \"tn\": 105877.0, \"fp\": 1842.0, \"fn\": 13.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9980116486549377, \"tn_rate\": 0.9828999638557434, \"fp_rate\": 0.017100047320127487, \"fn_rate\": 0.001988375559449196, \"precision\": 0.7798494100570679, \"recall\": 0.9980116486549377, \"specificity\": 0.9828999638557434, \"npv\": 0.9998772144317627, \"accuracy\": 0.9837646484375, \"f1\": 0.8755451190875545, \"f2\": 0.9451316666183841, \"f0_5\": 0.8155026745988102, \"p4\": 0.9298408317808197, \"phi\": 0.8745529758067323}, {\"truth_threshold\": -12.67221754024279, \"match_probability\": 0.0001531848714183357, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105877.0, \"fp\": 1842.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9828999638557434, \"fp_rate\": 0.017100047320127487, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7797967791557312, \"recall\": 0.9977056980133057, \"specificity\": 0.9828999638557434, \"npv\": 0.9998583197593689, \"accuracy\": 0.9837471842765808, \"f1\": 0.8753942159296786, \"f2\": 0.9448967175594635, \"f0_5\": 0.8154157707885394, \"p4\": 0.9297516428166568, \"phi\": 0.8743765110975034}, {\"truth_threshold\": -12.671294750297857, \"match_probability\": 0.0001532828692614479, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105881.0, \"fp\": 1838.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9829370975494385, \"fp_rate\": 0.01706291362643242, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7801698446273804, \"recall\": 0.9977056980133057, \"specificity\": 0.9829370975494385, \"npv\": 0.9998583793640137, \"accuracy\": 0.983782172203064, \"f1\": 0.8756292368615344, \"f2\": 0.9450062295366963, \"f0_5\": 0.815742083937772, \"p4\": 0.9298924931448709, \"phi\": 0.8746021916713874}, {\"truth_threshold\": -12.671024011767587, \"match_probability\": 0.00015331163286621635, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105914.0, \"fp\": 1805.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.983243465423584, \"fp_rate\": 0.016756560653448105, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7832612991333008, \"recall\": 0.9977056980133057, \"specificity\": 0.983243465423584, \"npv\": 0.9998583793640137, \"accuracy\": 0.9840710163116455, \"f1\": 0.8775729853356653, \"f2\": 0.9459106728538283, \"f0_5\": 0.818444165621079, \"p4\": 0.9310561147181867, \"phi\": 0.8764704984237318}, {\"truth_threshold\": -12.65768237446442, \"match_probability\": 0.000154735771139805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105917.0, \"fp\": 1802.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9832713007926941, \"fp_rate\": 0.016728710383176804, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7835435271263123, \"recall\": 0.9977056980133057, \"specificity\": 0.9832713007926941, \"npv\": 0.9998583793640137, \"accuracy\": 0.9840972423553467, \"f1\": 0.877750117742044, \"f2\": 0.9459929808277983, \"f0_5\": 0.8186906973241629, \"p4\": 0.931162040797091, \"phi\": 0.8766409248899177}, {\"truth_threshold\": -12.656730373693621, \"match_probability\": 0.000154837895543216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105919.0, \"fp\": 1800.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9832898378372192, \"fp_rate\": 0.01671014353632927, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7837318181991577, \"recall\": 0.9977056980133057, \"specificity\": 0.9832898378372192, \"npv\": 0.9998583793640137, \"accuracy\": 0.9841147661209106, \"f1\": 0.8778682457438934, \"f2\": 0.946047860768673, \"f0_5\": 0.8188551343208637, \"p4\": 0.9312326713776844, \"phi\": 0.876754538223799}, {\"truth_threshold\": -12.6517085559497, \"match_probability\": 0.00015537771963302355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105920.0, \"fp\": 1799.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9832991361618042, \"fp_rate\": 0.016700860112905502, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7838259935379028, \"recall\": 0.9977056980133057, \"specificity\": 0.9832991361618042, \"npv\": 0.9998583793640137, \"accuracy\": 0.9841235280036926, \"f1\": 0.8779273216689099, \"f2\": 0.9460753031269943, \"f0_5\": 0.8189373775925275, \"p4\": 0.9312679906272691, \"phi\": 0.8768113598457694}, {\"truth_threshold\": -12.643693605445455, \"match_probability\": 0.0001562431938151763, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105926.0, \"fp\": 1793.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9833548665046692, \"fp_rate\": 0.0166451595723629, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7843915224075317, \"recall\": 0.9977056980133057, \"specificity\": 0.9833548665046692, \"npv\": 0.9998584389686584, \"accuracy\": 0.9841760396957397, \"f1\": 0.8782819442574391, \"f2\": 0.9462399907160265, \"f0_5\": 0.8194311843625949, \"p4\": 0.9314799615735209, \"phi\": 0.8771525803857934}, {\"truth_threshold\": -12.641857816302702, \"match_probability\": 0.00015644210433933501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105927.0, \"fp\": 1792.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9833641052246094, \"fp_rate\": 0.016635876148939133, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7844858765602112, \"recall\": 0.9977056980133057, \"specificity\": 0.9833641052246094, \"npv\": 0.9998584389686584, \"accuracy\": 0.9841848015785217, \"f1\": 0.8783410758769272, \"f2\": 0.9462674442220095, \"f0_5\": 0.8195135433941404, \"p4\": 0.9315152993087936, \"phi\": 0.877209471892965}, {\"truth_threshold\": -12.640508680515453, \"match_probability\": 0.0001565884466280529, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105938.0, \"fp\": 1781.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9834662675857544, \"fp_rate\": 0.016533758491277695, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7855250239372253, \"recall\": 0.9977056980133057, \"specificity\": 0.9834662675857544, \"npv\": 0.9998584389686584, \"accuracy\": 0.984281063079834, \"f1\": 0.8789920495890042, \"f2\": 0.946569537961458, \"f0_5\": 0.820420586607637, \"p4\": 0.9319041888343281, \"phi\": 0.8778361014031687}, {\"truth_threshold\": -12.637263428604102, \"match_probability\": 0.0001569410236279384, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105940.0, \"fp\": 1779.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9834848046302795, \"fp_rate\": 0.01651519164443016, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7857142686843872, \"recall\": 0.9977056980133057, \"specificity\": 0.9834848046302795, \"npv\": 0.9998584389686584, \"accuracy\": 0.9842985272407532, \"f1\": 0.8791105121293801, \"f2\": 0.9466244848203401, \"f0_5\": 0.8205857193176672, \"p4\": 0.9319749303977508, \"phi\": 0.877950134740149}, {\"truth_threshold\": -12.62659778574063, \"match_probability\": 0.00015810538191305334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105943.0, \"fp\": 1776.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9835126399993896, \"fp_rate\": 0.01648734137415886, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7859982848167419, \"recall\": 0.9977056980133057, \"specificity\": 0.9835126399993896, \"npv\": 0.9998584389686584, \"accuracy\": 0.9843248128890991, \"f1\": 0.8792882658219316, \"f2\": 0.946706917070622, \"f0_5\": 0.820833543061358, \"p4\": 0.9320810625876584, \"phi\": 0.8781213413340306}, {\"truth_threshold\": -12.618482374185454, \"match_probability\": 0.00015899711662061504, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105944.0, \"fp\": 1775.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9835219383239746, \"fp_rate\": 0.016478057950735092, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7860930562019348, \"recall\": 0.9977056980133057, \"specificity\": 0.9835219383239746, \"npv\": 0.9998584389686584, \"accuracy\": 0.9843335747718811, \"f1\": 0.8793475330277702, \"f2\": 0.9467343976777939, \"f0_5\": 0.8209161842436447, \"p4\": 0.9321164452774258, \"phi\": 0.8781784031762808}, {\"truth_threshold\": -12.607744194570898, \"match_probability\": 0.00016018477916505887, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105947.0, \"fp\": 1772.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9835497736930847, \"fp_rate\": 0.01645020768046379, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7863773107528687, \"recall\": 0.9977056980133057, \"specificity\": 0.9835497736930847, \"npv\": 0.9998584389686584, \"accuracy\": 0.9843598008155823, \"f1\": 0.8795253825928673, \"f2\": 0.9468168490724882, \"f0_5\": 0.8211642076640314, \"p4\": 0.9322226092302952, \"phi\": 0.8783497303354365}, {\"truth_threshold\": -12.587069421553993, \"match_probability\": 0.00016249648442261786, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105948.0, \"fp\": 1771.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9835590720176697, \"fp_rate\": 0.016440924257040024, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7864721417427063, \"recall\": 0.9977056980133057, \"specificity\": 0.9835590720176697, \"npv\": 0.9998584389686584, \"accuracy\": 0.9843685626983643, \"f1\": 0.8795846817691478, \"f2\": 0.9468443360622424, \"f0_5\": 0.8212469154454348, \"p4\": 0.9322580025101013, \"phi\": 0.8784068323842099}, {\"truth_threshold\": -12.58661781896576, \"match_probability\": 0.00016254734991214326, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105951.0, \"fp\": 1768.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9835869073867798, \"fp_rate\": 0.016413073986768723, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7867567539215088, \"recall\": 0.9977056980133057, \"specificity\": 0.9835869073867798, \"npv\": 0.9998584389686584, \"accuracy\": 0.9843948483467102, \"f1\": 0.8797626272843753, \"f2\": 0.9469268066080191, \"f0_5\": 0.8214951387839403, \"p4\": 0.9323641982402439, \"phi\": 0.8785781988908815}, {\"truth_threshold\": -12.579563268025739, \"match_probability\": 0.00016334399710732987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105952.0, \"fp\": 1767.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9835962057113647, \"fp_rate\": 0.016403790563344955, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7868516445159912, \"recall\": 0.9977056980133057, \"specificity\": 0.9835962057113647, \"npv\": 0.9998584389686584, \"accuracy\": 0.9844036102294922, \"f1\": 0.8798219584569733, \"f2\": 0.9469542999825794, \"f0_5\": 0.8215779132449997, \"p4\": 0.9323996021148606, \"phi\": 0.8786353411899598}, {\"truth_threshold\": -12.571256522156887, \"match_probability\": 0.00016428705661723238, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 105953.0, \"fp\": 1766.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9836055040359497, \"fp_rate\": 0.01639450713992119, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7869465351104736, \"recall\": 0.9977056980133057, \"specificity\": 0.9836055040359497, \"npv\": 0.9998584389686584, \"accuracy\": 0.9844123125076294, \"f1\": 0.8798812976326971, \"f2\": 0.946981794953689, \"f0_5\": 0.8216607043885725, \"p4\": 0.9324350086389259, \"phi\": 0.8786925749307827}, {\"truth_threshold\": -12.559630972083024, \"match_probability\": 0.0001656160456087822, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106052.0, \"fp\": 1667.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9845245480537415, \"fp_rate\": 0.015475450083613396, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7964590787887573, \"recall\": 0.9977056980133057, \"specificity\": 0.9845245480537415, \"npv\": 0.999858558177948, \"accuracy\": 0.9852787852287292, \"f1\": 0.885795763172189, \"f2\": 0.9497117232543242, \"f0_5\": 0.8299404549849865, \"p4\": 0.9359534192151849, \"phi\": 0.8844022438242808}, {\"truth_threshold\": -12.540973006964538, \"match_probability\": 0.0001677714591677581, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106058.0, \"fp\": 1661.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9845802783966064, \"fp_rate\": 0.015419749543070793, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7970430254936218, \"recall\": 0.9977056980133057, \"specificity\": 0.9845802783966064, \"npv\": 0.999858558177948, \"accuracy\": 0.9853312969207764, \"f1\": 0.8861567721776933, \"f2\": 0.9498776794035415, \"f0_5\": 0.8304476243825432, \"p4\": 0.9361674973206898, \"phi\": 0.8847515311592313}, {\"truth_threshold\": -12.529982071833453, \"match_probability\": 0.0001690542625985175, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106061.0, \"fp\": 1658.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9846081137657166, \"fp_rate\": 0.015391899272799492, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7973352670669556, \"recall\": 0.9977056980133057, \"specificity\": 0.9846081137657166, \"npv\": 0.9998586177825928, \"accuracy\": 0.9853575825691223, \"f1\": 0.8863373870507507, \"f2\": 0.9499606792298955, \"f0_5\": 0.8307014415974734, \"p4\": 0.9362745725674004, \"phi\": 0.8849262742455661}, {\"truth_threshold\": -12.528560325176834, \"match_probability\": 0.00016922091605140748, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106072.0, \"fp\": 1647.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9847102165222168, \"fp_rate\": 0.015289781615138054, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7984088063240051, \"recall\": 0.9977056980133057, \"specificity\": 0.9847102165222168, \"npv\": 0.9998586177825928, \"accuracy\": 0.9854538440704346, \"f1\": 0.8870002719608376, \"f2\": 0.9502651360643319, \"f0_5\": 0.8316334336274159, \"p4\": 0.9366673884006813, \"phi\": 0.8855679647583219}, {\"truth_threshold\": -12.517194074336583, \"match_probability\": 0.0001705591577996664, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106084.0, \"fp\": 1635.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.984821617603302, \"fp_rate\": 0.015178380534052849, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7995832562446594, \"recall\": 0.9977056980133057, \"specificity\": 0.984821617603302, \"npv\": 0.9998586177825928, \"accuracy\": 0.9855588674545288, \"f1\": 0.8877245508982036, \"f2\": 0.9505974934421452, \"f0_5\": 0.8326525402093439, \"p4\": 0.937096285389305, \"phi\": 0.8862694173072473}, {\"truth_threshold\": -12.510503427852232, \"match_probability\": 0.00017135184454391216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106086.0, \"fp\": 1633.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9848402142524719, \"fp_rate\": 0.015159813687205315, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7997792959213257, \"recall\": 0.9977056980133057, \"specificity\": 0.9848402142524719, \"npv\": 0.9998586177825928, \"accuracy\": 0.9855763912200928, \"f1\": 0.8878453790662856, \"f2\": 0.9506529089425207, \"f0_5\": 0.832822634186201, \"p4\": 0.9371678058558572, \"phi\": 0.886386445341316}, {\"truth_threshold\": -12.507236168216439, \"match_probability\": 0.00017174027669012416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106087.0, \"fp\": 1632.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9848494529724121, \"fp_rate\": 0.015150530263781548, \"fn_rate\": 0.002294279634952545, \"precision\": 0.799877405166626, \"recall\": 0.9977056980133057, \"specificity\": 0.9848494529724121, \"npv\": 0.9998586177825928, \"accuracy\": 0.9855851531028748, \"f1\": 0.8879058054856054, \"f2\": 0.9506806191156324, \"f0_5\": 0.8329077072373461, \"p4\": 0.9372035701237498, \"phi\": 0.8864449750874606}, {\"truth_threshold\": -12.50540083676884, \"match_probability\": 0.00017195885834637628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106088.0, \"fp\": 1631.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9848587512969971, \"fp_rate\": 0.01514124684035778, \"fn_rate\": 0.002294279634952545, \"precision\": 0.7999754548072815, \"recall\": 0.9977056980133057, \"specificity\": 0.9848587512969971, \"npv\": 0.9998586177825928, \"accuracy\": 0.985593855381012, \"f1\": 0.8879662401306834, \"f2\": 0.950708330904215, \"f0_5\": 0.8329927976707361, \"p4\": 0.9372393370817926, \"phi\": 0.8865035973141906}, {\"truth_threshold\": -12.50460726136202, \"match_probability\": 0.00017205345656031164, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106090.0, \"fp\": 1629.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.984877347946167, \"fp_rate\": 0.015122679993510246, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8001717329025269, \"recall\": 0.9977056980133057, \"specificity\": 0.984877347946167, \"npv\": 0.9998586177825928, \"accuracy\": 0.9856113791465759, \"f1\": 0.8880871341048332, \"f2\": 0.9507637593283582, \"f0_5\": 0.8331630307055637, \"p4\": 0.9373108790695476, \"phi\": 0.886620709280292}, {\"truth_threshold\": -12.500331022467194, \"match_probability\": 0.00017256410224880152, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106094.0, \"fp\": 1625.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9849144816398621, \"fp_rate\": 0.015085546299815178, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8005645275115967, \"recall\": 0.9977056980133057, \"specificity\": 0.9849144816398621, \"npv\": 0.9998586177825928, \"accuracy\": 0.9856463670730591, \"f1\": 0.8883290208361705, \"f2\": 0.9508746355685131, \"f0_5\": 0.8335037055967288, \"p4\": 0.9374539953402661, \"phi\": 0.8868551412557715}, {\"truth_threshold\": -12.498774135270125, \"match_probability\": 0.00017275039346999655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106095.0, \"fp\": 1624.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9849237203598022, \"fp_rate\": 0.01507626287639141, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8006628155708313, \"recall\": 0.9977056980133057, \"specificity\": 0.9849237203598022, \"npv\": 0.9998586177825928, \"accuracy\": 0.9856551289558411, \"f1\": 0.8883895131086142, \"f2\": 0.9509023586693489, \"f0_5\": 0.8335889178551347, \"p4\": 0.9374897811378922, \"phi\": 0.8869137550237272}, {\"truth_threshold\": -12.495499003237263, \"match_probability\": 0.00017314294002217614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106096.0, \"fp\": 1623.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9849330186843872, \"fp_rate\": 0.015066979452967644, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8007611036300659, \"recall\": 0.9977056980133057, \"specificity\": 0.9849330186843872, \"npv\": 0.9998586177825928, \"accuracy\": 0.985663890838623, \"f1\": 0.888450013620267, \"f2\": 0.9509300833867864, \"f0_5\": 0.8336741475384694, \"p4\": 0.9375255696281065, \"phi\": 0.8869723793076942}, {\"truth_threshold\": -12.488505587070403, \"match_probability\": 0.00017398413581944032, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106106.0, \"fp\": 1613.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9850258827209473, \"fp_rate\": 0.014974146150052547, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8017453551292419, \"recall\": 0.9977056980133057, \"specificity\": 0.9850258827209473, \"npv\": 0.9998586773872375, \"accuracy\": 0.9857513904571533, \"f1\": 0.889055472263868, \"f2\": 0.9512074195053664, \"f0_5\": 0.8345274039199632, \"p4\": 0.9378836026897217, \"phi\": 0.8875592833098122}, {\"truth_threshold\": -12.487064661691413, \"match_probability\": 0.00017415796306903677, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106108.0, \"fp\": 1611.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9850444197654724, \"fp_rate\": 0.014955579303205013, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8019424676895142, \"recall\": 0.9977056980133057, \"specificity\": 0.9850444197654724, \"npv\": 0.9998586773872375, \"accuracy\": 0.9857689142227173, \"f1\": 0.8891766630316249, \"f2\": 0.9512629061424488, \"f0_5\": 0.8346982648308338, \"p4\": 0.9379552416436192, \"phi\": 0.8876768563021679}, {\"truth_threshold\": -12.482880693850854, \"match_probability\": 0.0001746636842872106, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106111.0, \"fp\": 1608.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9850722551345825, \"fp_rate\": 0.014927729032933712, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8022383451461792, \"recall\": 0.9977056980133057, \"specificity\": 0.9850722551345825, \"npv\": 0.9998586773872375, \"accuracy\": 0.9857951998710632, \"f1\": 0.8893585111459541, \"f2\": 0.9513461482367354, \"f0_5\": 0.834954687419999, \"p4\": 0.9380627202994024, \"phi\": 0.8878531718722222}, {\"truth_threshold\": -12.466479280740405, \"match_probability\": 0.0001766603419690173, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106131.0, \"fp\": 1588.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9852579236030579, \"fp_rate\": 0.01474206056445837, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8042165040969849, \"recall\": 0.9977056980133057, \"specificity\": 0.9852579236030579, \"npv\": 0.9998586773872375, \"accuracy\": 0.9859701991081238, \"f1\": 0.8905727353402962, \"f2\": 0.9519014680559204, \"f0_5\": 0.8366682058385921, \"p4\": 0.9387798654888291, \"phi\": 0.8890312903556044}, {\"truth_threshold\": -12.448902328961408, \"match_probability\": 0.00017882544565878816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106132.0, \"fp\": 1587.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9852672219276428, \"fp_rate\": 0.014732777141034603, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8043156862258911, \"recall\": 0.9977056980133057, \"specificity\": 0.9852672219276428, \"npv\": 0.9998586773872375, \"accuracy\": 0.9859789609909058, \"f1\": 0.8906335335882032, \"f2\": 0.9519292510653202, \"f0_5\": 0.8367540663964288, \"p4\": 0.9388157511156842, \"phi\": 0.8890902953910567}, {\"truth_threshold\": -12.442895395405706, \"match_probability\": 0.00017957143746725378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106136.0, \"fp\": 1583.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9853043556213379, \"fp_rate\": 0.014695643447339535, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8047125339508057, \"recall\": 0.9977056980133057, \"specificity\": 0.9853043556213379, \"npv\": 0.9998586773872375, \"accuracy\": 0.9860140085220337, \"f1\": 0.8908768096148594, \"f2\": 0.952040399322786, \"f0_5\": 0.8370976849237719, \"p4\": 0.9389593206651966, \"phi\": 0.8893265041383748}, {\"truth_threshold\": -12.440210030029622, \"match_probability\": 0.00017990593445913066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106140.0, \"fp\": 1579.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.985341489315033, \"fp_rate\": 0.014658509753644466, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8051098585128784, \"recall\": 0.9977056980133057, \"specificity\": 0.985341489315033, \"npv\": 0.9998586773872375, \"accuracy\": 0.9860489964485168, \"f1\": 0.891120218579235, \"f2\": 0.9521515735388568, \"f0_5\": 0.8374415857854465, \"p4\": 0.9391029334967816, \"phi\": 0.889562883306447}, {\"truth_threshold\": -12.434554574618932, \"match_probability\": 0.00018061243353149488, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106141.0, \"fp\": 1578.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9853507876396179, \"fp_rate\": 0.0146492263302207, \"fn_rate\": 0.002294279634952545, \"precision\": 0.805209219455719, \"recall\": 0.9977056980133057, \"specificity\": 0.9853507876396179, \"npv\": 0.9998586773872375, \"accuracy\": 0.9860577583312988, \"f1\": 0.8911810916046178, \"f2\": 0.9521793711499723, \"f0_5\": 0.8375276051563865, \"p4\": 0.9391388434698035, \"phi\": 0.88962198419189}, {\"truth_threshold\": -12.434057803048027, \"match_probability\": 0.00018067462433101953, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106145.0, \"fp\": 1574.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.985387921333313, \"fp_rate\": 0.014612092636525631, \"fn_rate\": 0.002294279634952545, \"precision\": 0.80560702085495, \"recall\": 0.9977056980133057, \"specificity\": 0.985387921333313, \"npv\": 0.9998586773872375, \"accuracy\": 0.986092746257782, \"f1\": 0.8914246668944311, \"f2\": 0.9522905778270898, \"f0_5\": 0.8378718594255767, \"p4\": 0.9392825104316039, \"phi\": 0.8898585766759645}, {\"truth_threshold\": -12.433497206561125, \"match_probability\": 0.0001807448310812437, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106148.0, \"fp\": 1571.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9854157567024231, \"fp_rate\": 0.01458424236625433, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8059055805206299, \"recall\": 0.9977056980133057, \"specificity\": 0.9854157567024231, \"npv\": 0.9998587369918823, \"accuracy\": 0.9861190319061279, \"f1\": 0.8916074357572444, \"f2\": 0.952373999883198, \"f0_5\": 0.8381302359048157, \"p4\": 0.9393902890847541, \"phi\": 0.8900360714731781}, {\"truth_threshold\": -12.421391391211866, \"match_probability\": 0.00018226758458854728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106150.0, \"fp\": 1569.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.985434353351593, \"fp_rate\": 0.014565675519406796, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8061047792434692, \"recall\": 0.9977056980133057, \"specificity\": 0.985434353351593, \"npv\": 0.9998587369918823, \"accuracy\": 0.9861364960670471, \"f1\": 0.8917293233082707, \"f2\": 0.9524296227076277, \"f0_5\": 0.8383025754382357, \"p4\": 0.9394621550637494, \"phi\": 0.8901544547740577}, {\"truth_threshold\": -12.417144420111681, \"match_probability\": 0.00018280483183263156, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106165.0, \"fp\": 1554.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9855735898017883, \"fp_rate\": 0.01442642416805029, \"fn_rate\": 0.002294279634952545, \"precision\": 0.807601809501648, \"recall\": 0.9977056980133057, \"specificity\": 0.9855735898017883, \"npv\": 0.9998587369918823, \"accuracy\": 0.9862678050994873, \"f1\": 0.8926445432774547, \"f2\": 0.9528470010809548, \"f0_5\": 0.8395973845440972, \"p4\": 0.9400014955284753, \"phi\": 0.8910439420008571}, {\"truth_threshold\": -12.396899840618872, \"match_probability\": 0.00018538763938575557, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106180.0, \"fp\": 1539.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9857128262519836, \"fp_rate\": 0.014287172816693783, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8091044425964355, \"recall\": 0.9977056980133057, \"specificity\": 0.9857128262519836, \"npv\": 0.9998587369918823, \"accuracy\": 0.9863990545272827, \"f1\": 0.8935616438356164, \"f2\": 0.953264745425849, \"f0_5\": 0.840896199659671, \"p4\": 0.9405414466539929, \"phi\": 0.891935764729696}, {\"truth_threshold\": -12.386191491782768, \"match_probability\": 0.00018676853353571704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106190.0, \"fp\": 1529.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9858056902885437, \"fp_rate\": 0.014194338582456112, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8101093173027039, \"recall\": 0.9977056980133057, \"specificity\": 0.9858056902885437, \"npv\": 0.9998587369918823, \"accuracy\": 0.9864866137504578, \"f1\": 0.8941740918437285, \"f2\": 0.9535434452110865, \"f0_5\": 0.8417643111546999, \"p4\": 0.9409017538411169, \"phi\": 0.8925317169425251}, {\"truth_threshold\": -12.381605694669974, \"match_probability\": 0.00018736303515533642, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106191.0, \"fp\": 1528.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9858149290084839, \"fp_rate\": 0.014185055159032345, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8102099299430847, \"recall\": 0.9977056980133057, \"specificity\": 0.9858149290084839, \"npv\": 0.9998587369918823, \"accuracy\": 0.9864953756332397, \"f1\": 0.8942353828226746, \"f2\": 0.9535713241528521, \"f0_5\": 0.8418512208972175, \"p4\": 0.9409377995244407, \"phi\": 0.8925913551766228}, {\"truth_threshold\": -12.37861144421449, \"match_probability\": 0.00018775222966809621, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106192.0, \"fp\": 1527.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9858242273330688, \"fp_rate\": 0.014175771735608578, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8103105425834656, \"recall\": 0.9977056980133057, \"specificity\": 0.9858242273330688, \"npv\": 0.9998587369918823, \"accuracy\": 0.9865041375160217, \"f1\": 0.8942966822045517, \"f2\": 0.9535992047248699, \"f0_5\": 0.8419381485879498, \"p4\": 0.9409738479298402, \"phi\": 0.892651004241743}, {\"truth_threshold\": -12.37146372990868, \"match_probability\": 0.00018868456486486557, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106253.0, \"fp\": 1466.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9863905310630798, \"fp_rate\": 0.01360948383808136, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8164976835250854, \"recall\": 0.9977056980133057, \"specificity\": 0.9863905310630798, \"npv\": 0.9998588562011719, \"accuracy\": 0.9870380163192749, \"f1\": 0.8980519033523783, \"f2\": 0.9553030081134121, \"f0_5\": 0.8472748999844132, \"p4\": 0.9431779604192339, \"phi\": 0.8963109575153411}, {\"truth_threshold\": -12.371340730498556, \"match_probability\": 0.00018870064913721865, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106257.0, \"fp\": 1462.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9864276647567749, \"fp_rate\": 0.013572350144386292, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8169066905975342, \"recall\": 0.9977056980133057, \"specificity\": 0.9864276647567749, \"npv\": 0.9998588562011719, \"accuracy\": 0.9870730042457581, \"f1\": 0.8982992494663637, \"f2\": 0.9554149456601342, \"f0_5\": 0.8476272155517438, \"p4\": 0.9433228479914023, \"phi\": 0.8965524155199782}, {\"truth_threshold\": -12.369732644466504, \"match_probability\": 0.00018891105999536522, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106260.0, \"fp\": 1459.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.986455500125885, \"fp_rate\": 0.01354449987411499, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8172137141227722, \"recall\": 0.9977056980133057, \"specificity\": 0.986455500125885, \"npv\": 0.9998588562011719, \"accuracy\": 0.9870992302894592, \"f1\": 0.8984848484848484, \"f2\": 0.9554989160367962, \"f0_5\": 0.8478916445692299, \"p4\": 0.9434315424667138, \"phi\": 0.896733563016071}, {\"truth_threshold\": -12.3687745926782, \"match_probability\": 0.0001890365282728292, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106264.0, \"fp\": 1455.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9864926338195801, \"fp_rate\": 0.013507366180419922, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8176234364509583, \"recall\": 0.9977056980133057, \"specificity\": 0.9864926338195801, \"npv\": 0.9998588562011719, \"accuracy\": 0.9871342778205872, \"f1\": 0.8987324331771838, \"f2\": 0.9556108995019045, \"f0_5\": 0.8482444733420026, \"p4\": 0.9435765068447551, \"phi\": 0.8969753307674021}, {\"truth_threshold\": -12.35040211438085, \"match_probability\": 0.00019145880662285448, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106270.0, \"fp\": 1449.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9865483045578003, \"fp_rate\": 0.01345166563987732, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8182388544082642, \"recall\": 0.9977056980133057, \"specificity\": 0.9865483045578003, \"npv\": 0.9998588562011719, \"accuracy\": 0.9871867895126343, \"f1\": 0.8991040661612681, \"f2\": 0.9557789239245106, \"f0_5\": 0.8487742674230989, \"p4\": 0.9437940357616765, \"phi\": 0.8973382734955042}, {\"truth_threshold\": -12.346082273391438, \"match_probability\": 0.00019203283785976764, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106271.0, \"fp\": 1448.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9865576028823853, \"fp_rate\": 0.013442382216453552, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8183414936065674, \"recall\": 0.9977056980133057, \"specificity\": 0.9865576028823853, \"npv\": 0.9998588562011719, \"accuracy\": 0.9871955513954163, \"f1\": 0.8991660348749052, \"f2\": 0.9558069337397064, \"f0_5\": 0.8488626307844465, \"p4\": 0.9438303001926632, \"phi\": 0.8973987889774092}, {\"truth_threshold\": -12.321469603462214, \"match_probability\": 0.00019533641680431432, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106279.0, \"fp\": 1440.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9866318702697754, \"fp_rate\": 0.013368114829063416, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8191636204719543, \"recall\": 0.9977056980133057, \"specificity\": 0.9866318702697754, \"npv\": 0.9998588562011719, \"accuracy\": 0.9872655272483826, \"f1\": 0.8996620922694987, \"f2\": 0.9560310713762274, \"f0_5\": 0.8495702005730659, \"p4\": 0.9441205145580669, \"phi\": 0.8978833957519086}, {\"truth_threshold\": -12.320976290056523, \"match_probability\": 0.00019540320827060755, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106281.0, \"fp\": 1438.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9866504669189453, \"fp_rate\": 0.013349547982215881, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8193694353103638, \"recall\": 0.9977056980133057, \"specificity\": 0.9866504669189453, \"npv\": 0.9998588562011719, \"accuracy\": 0.9872830510139465, \"f1\": 0.8997861921511828, \"f2\": 0.9560871222114736, \"f0_5\": 0.8497472773696003, \"p4\": 0.9441930956379944, \"phi\": 0.8980047208804443}, {\"truth_threshold\": -12.317387057152887, \"match_probability\": 0.00019588985527528357, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106283.0, \"fp\": 1436.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9866690039634705, \"fp_rate\": 0.013330981135368347, \"fn_rate\": 0.002294279634952545, \"precision\": 0.819575309753418, \"recall\": 0.9977056980133057, \"specificity\": 0.9866690039634705, \"npv\": 0.9998589158058167, \"accuracy\": 0.9873005747795105, \"f1\": 0.8999103262744016, \"f2\": 0.9561431796194776, \"f0_5\": 0.8499244279981237, \"p4\": 0.9442656877183689, \"phi\": 0.8981260076698374}, {\"truth_threshold\": -12.312564050240322, \"match_probability\": 0.00019654569249640718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106285.0, \"fp\": 1434.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9866876006126404, \"fp_rate\": 0.013312414288520813, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8197813034057617, \"recall\": 0.9977056980133057, \"specificity\": 0.9866876006126404, \"npv\": 0.9998589158058167, \"accuracy\": 0.9873180389404297, \"f1\": 0.9000344946533287, \"f2\": 0.9561992436013955, \"f0_5\": 0.850101652504822, \"p4\": 0.9443382908017002, \"phi\": 0.8982473390411183}, {\"truth_threshold\": -12.311074432099836, \"match_probability\": 0.0001967486956187085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106288.0, \"fp\": 1431.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9867154359817505, \"fp_rate\": 0.013284564018249512, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8200905323028564, \"recall\": 0.9977056980133057, \"specificity\": 0.9867154359817505, \"npv\": 0.9998589158058167, \"accuracy\": 0.9873443245887756, \"f1\": 0.9002208114821971, \"f2\": 0.9562833519028909, \"f0_5\": 0.8503676278875737, \"p4\": 0.9444472160627322, \"phi\": 0.8984295026866544}, {\"truth_threshold\": -12.300854001161206, \"match_probability\": 0.000198147186710636, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106293.0, \"fp\": 1426.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9867618680000305, \"fp_rate\": 0.013238147832453251, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8206063508987427, \"recall\": 0.9977056980133057, \"specificity\": 0.9867618680000305, \"npv\": 0.9998589158058167, \"accuracy\": 0.9873880743980408, \"f1\": 0.9005315110098709, \"f2\": 0.9564235652913404, \"f0_5\": 0.8508112902384306, \"p4\": 0.9446288132148091, \"phi\": 0.8987332768249469}, {\"truth_threshold\": -12.285924228396222, \"match_probability\": 0.00020020795282269243, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106294.0, \"fp\": 1425.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9867711067199707, \"fp_rate\": 0.013228864409029484, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8207095861434937, \"recall\": 0.9977056980133057, \"specificity\": 0.9867711067199707, \"npv\": 0.9998589158058167, \"accuracy\": 0.9873968362808228, \"f1\": 0.9005936766533205, \"f2\": 0.9564516129032258, \"f0_5\": 0.8509000782676754, \"p4\": 0.9446651409056046, \"phi\": 0.8987940485925596}, {\"truth_threshold\": -12.284481446997518, \"match_probability\": 0.00020040823276324703, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106295.0, \"fp\": 1424.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9867804050445557, \"fp_rate\": 0.013219580985605717, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8208128809928894, \"recall\": 0.9977056980133057, \"specificity\": 0.9867804050445557, \"npv\": 0.9998589158058167, \"accuracy\": 0.9874055981636047, \"f1\": 0.9006558508802209, \"f2\": 0.9564796621601807, \"f0_5\": 0.8509888848301415, \"p4\": 0.9447014713505933, \"phi\": 0.8988548315440955}, {\"truth_threshold\": -12.260046360509099, \"match_probability\": 0.0002038307796495224, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106297.0, \"fp\": 1422.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9867990016937256, \"fp_rate\": 0.013201014138758183, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8210195302963257, \"recall\": 0.9977056980133057, \"specificity\": 0.9867990016937256, \"npv\": 0.9998589158058167, \"accuracy\": 0.9874230623245239, \"f1\": 0.9007802250914866, \"f2\": 0.9565357656098777, \"f0_5\": 0.8511665535779529, \"p4\": 0.9447741405044077, \"phi\": 0.8989764310129568}, {\"truth_threshold\": -12.255881261834638, \"match_probability\": 0.00020441997429915197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106298.0, \"fp\": 1421.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868082404136658, \"fp_rate\": 0.013191730715334415, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8211228847503662, \"recall\": 0.9977056980133057, \"specificity\": 0.9868082404136658, \"npv\": 0.9998589158058167, \"accuracy\": 0.9874318242073059, \"f1\": 0.9008424250794089, \"f2\": 0.9565638198029094, \"f0_5\": 0.8512554157749126, \"p4\": 0.9448104792138619, \"phi\": 0.899037247537296}, {\"truth_threshold\": -12.237702877195662, \"match_probability\": 0.00020701148590505488, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106300.0, \"fp\": 1419.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868268370628357, \"fp_rate\": 0.013173163868486881, \"fn_rate\": 0.002294279634952545, \"precision\": 0.821329653263092, \"recall\": 0.9977056980133057, \"specificity\": 0.9868268370628357, \"npv\": 0.9998589158058167, \"accuracy\": 0.9874493479728699, \"f1\": 0.9009668508287293, \"f2\": 0.9566199331260632, \"f0_5\": 0.8514331958439931, \"p4\": 0.9448831648994368, \"phi\": 0.8991589971778059}, {\"truth_threshold\": -12.234188398337718, \"match_probability\": 0.00020751628642718545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106301.0, \"fp\": 1418.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868361353874207, \"fp_rate\": 0.013163880445063114, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8214330673217773, \"recall\": 0.9977056980133057, \"specificity\": 0.9868361353874207, \"npv\": 0.9998589158058167, \"accuracy\": 0.9874581098556519, \"f1\": 0.9010290765936874, \"f2\": 0.9566479922564749, \"f0_5\": 0.8515221137277427, \"p4\": 0.9449195118761864, \"phi\": 0.899219847311367}, {\"truth_threshold\": -12.226094813946819, \"match_probability\": 0.0002086834902014865, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106303.0, \"fp\": 1416.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868546724319458, \"fp_rate\": 0.01314531359821558, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8216400146484375, \"recall\": 0.9977056980133057, \"specificity\": 0.9868546724319458, \"npv\": 0.9998589158058167, \"accuracy\": 0.987475574016571, \"f1\": 0.9011535539131036, \"f2\": 0.9567041154556921, \"f0_5\": 0.8517000052227502, \"p4\": 0.944992214099183, \"phi\": 0.8993415812074712}, {\"truth_threshold\": -12.217729551021455, \"match_probability\": 0.00020989677201466232, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106304.0, \"fp\": 1415.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868639707565308, \"fp_rate\": 0.013136030174791813, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8217434883117676, \"recall\": 0.9977056980133057, \"specificity\": 0.9868639707565308, \"npv\": 0.9998589158058167, \"accuracy\": 0.987484335899353, \"f1\": 0.9012158054711246, \"f2\": 0.9567321795247873, \"f0_5\": 0.8517889788456516, \"p4\": 0.9450285693460593, \"phi\": 0.8994024649770471}, {\"truth_threshold\": -12.197310605161135, \"match_probability\": 0.00021288799682832928, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106306.0, \"fp\": 1413.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868825078010559, \"fp_rate\": 0.013117463327944279, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8219506144523621, \"recall\": 0.9977056980133057, \"specificity\": 0.9868825078010559, \"npv\": 0.9998589158058167, \"accuracy\": 0.987501859664917, \"f1\": 0.9013403343927041, \"f2\": 0.9567883126026754, \"f0_5\": 0.8519669818713755, \"p4\": 0.9451012881121412, \"phi\": 0.8995243492003315}, {\"truth_threshold\": -12.185867923127615, \"match_probability\": 0.00021458286021542382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106307.0, \"fp\": 1412.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9868918061256409, \"fp_rate\": 0.013108179904520512, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8220542073249817, \"recall\": 0.9977056980133057, \"specificity\": 0.9868918061256409, \"npv\": 0.9998589158058167, \"accuracy\": 0.987510621547699, \"f1\": 0.9014026117598286, \"f2\": 0.9568163816117582, \"f0_5\": 0.8520560112858561, \"p4\": 0.9451376516319766, \"phi\": 0.8995852666424297}, {\"truth_threshold\": -12.176027954145423, \"match_probability\": 0.00021605111790847122, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106312.0, \"fp\": 1407.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9869382381439209, \"fp_rate\": 0.013061762787401676, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8225725293159485, \"recall\": 0.9977056980133057, \"specificity\": 0.9869382381439209, \"npv\": 0.9998589158058167, \"accuracy\": 0.9875543713569641, \"f1\": 0.9017141277301631, \"f2\": 0.9569567513643565, \"f0_5\": 0.8525014376078206, \"p4\": 0.9453195106116925, \"phi\": 0.8998901054200774}, {\"truth_threshold\": -12.160952598963492, \"match_probability\": 0.00021832007221197157, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106313.0, \"fp\": 1406.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9869475364685059, \"fp_rate\": 0.013052479363977909, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8226762413978577, \"recall\": 0.9977056980133057, \"specificity\": 0.9869475364685059, \"npv\": 0.9998589158058167, \"accuracy\": 0.9875631332397461, \"f1\": 0.901776456763669, \"f2\": 0.9569848302573282, \"f0_5\": 0.8525905787630051, \"p4\": 0.9453558906859486, \"phi\": 0.899951090297559}, {\"truth_threshold\": -12.160552055151017, \"match_probability\": 0.0002183806808593651, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106314.0, \"fp\": 1405.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.986956775188446, \"fp_rate\": 0.013043195940554142, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8227800130844116, \"recall\": 0.9977056980133057, \"specificity\": 0.986956775188446, \"npv\": 0.9998589158058167, \"accuracy\": 0.9875718951225281, \"f1\": 0.9018387944144891, \"f2\": 0.9570129107981221, \"f0_5\": 0.8526797385620914, \"p4\": 0.9453922735203776, \"phi\": 0.900012086425819}, {\"truth_threshold\": -12.15854819091363, \"match_probability\": 0.00021868415006937397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106319.0, \"fp\": 1400.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9870032072067261, \"fp_rate\": 0.012996778823435307, \"fn_rate\": 0.002294279634952545, \"precision\": 0.82329922914505, \"recall\": 0.9977056980133057, \"specificity\": 0.9870032072067261, \"npv\": 0.9998589158058167, \"accuracy\": 0.9876156449317932, \"f1\": 0.902150611990872, \"f2\": 0.9571533382245048, \"f0_5\": 0.8531258174208737, \"p4\": 0.9455742291061495, \"phi\": 0.9003173190390414}, {\"truth_threshold\": -12.15643098913246, \"match_probability\": 0.0002190052414187375, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106325.0, \"fp\": 1394.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9870589375495911, \"fp_rate\": 0.012941078282892704, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8239232301712036, \"recall\": 0.9977056980133057, \"specificity\": 0.9870589375495911, \"npv\": 0.9998589158058167, \"accuracy\": 0.9876681566238403, \"f1\": 0.9025250778277413, \"f2\": 0.95732190554463, \"f0_5\": 0.8536617285243155, \"p4\": 0.9457926669606884, \"phi\": 0.9006839536311809}, {\"truth_threshold\": -12.156219022878043, \"match_probability\": 0.0002190374138189747, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6523.0, \"tn\": 106327.0, \"fp\": 1392.0, \"fn\": 15.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9977056980133057, \"tn_rate\": 0.9870774745941162, \"fp_rate\": 0.01292251143604517, \"fn_rate\": 0.002294279634952545, \"precision\": 0.8241313695907593, \"recall\": 0.9977056980133057, \"specificity\": 0.9870774745941162, \"npv\": 0.9998589754104614, \"accuracy\": 0.9876856803894043, \"f1\": 0.9026499688645956, \"f2\": 0.9573781078463028, \"f0_5\": 0.8538405152102204, \"p4\": 0.9458655016871684, \"phi\": 0.9008062277748724}, {\"truth_threshold\": -12.13458374747136, \"match_probability\": 0.00022234621079825838, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106353.0, \"fp\": 1366.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9873188734054565, \"fp_rate\": 0.012681142427027225, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8268255591392517, \"recall\": 0.997552752494812, \"specificity\": 0.9873188734054565, \"npv\": 0.9998495578765869, \"accuracy\": 0.9879044890403748, \"f1\": 0.9042007486482739, \"f2\": 0.9579905992949471, \"f0_5\": 0.8561302179049619, \"p4\": 0.9467696173437365, \"phi\": 0.9023130838700236}, {\"truth_threshold\": -12.128362245080234, \"match_probability\": 0.00022330691621682484, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106363.0, \"fp\": 1356.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9874116778373718, \"fp_rate\": 0.012588308192789555, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8278750777244568, \"recall\": 0.997552752494812, \"specificity\": 0.9874116778373718, \"npv\": 0.9998496174812317, \"accuracy\": 0.987991988658905, \"f1\": 0.9048279689234184, \"f2\": 0.9582721128416103, \"f0_5\": 0.8570302233902759, \"p4\": 0.9471346963520573, \"phi\": 0.902928198334533}, {\"truth_threshold\": -12.125226516511205, \"match_probability\": 0.00022379269769813223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106366.0, \"fp\": 1353.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9874395132064819, \"fp_rate\": 0.012560457922518253, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8281905055046082, \"recall\": 0.997552752494812, \"specificity\": 0.9874395132064819, \"npv\": 0.9998496174812317, \"accuracy\": 0.9880182147026062, \"f1\": 0.9050163047249011, \"f2\": 0.9583565991712464, \"f0_5\": 0.8573005941426994, \"p4\": 0.94724427418032, \"phi\": 0.9031130137636599}, {\"truth_threshold\": -12.10731520406141, \"match_probability\": 0.00022658780880403578, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106369.0, \"fp\": 1350.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9874674081802368, \"fp_rate\": 0.012532607652246952, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8285061120986938, \"recall\": 0.997552752494812, \"specificity\": 0.9874674081802368, \"npv\": 0.9998496174812317, \"accuracy\": 0.9880445003509521, \"f1\": 0.905204718945177, \"f2\": 0.9584411003997179, \"f0_5\": 0.8575711355388419, \"p4\": 0.947353877004953, \"phi\": 0.903297848866377}, {\"truth_threshold\": -12.089178721059529, \"match_probability\": 0.00022945362336163595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106374.0, \"fp\": 1345.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9875137805938721, \"fp_rate\": 0.012486190535128117, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8290326595306396, \"recall\": 0.997552752494812, \"specificity\": 0.9875137805938721, \"npv\": 0.9998496174812317, \"accuracy\": 0.9880882501602173, \"f1\": 0.9055189170426935, \"f2\": 0.9585819688997325, \"f0_5\": 0.8580224175130242, \"p4\": 0.9475366039501443, \"phi\": 0.9036062198393799}, {\"truth_threshold\": -12.069436999878263, \"match_probability\": 0.00023261429350349272, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106377.0, \"fp\": 1342.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.987541675567627, \"fp_rate\": 0.012458340264856815, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8293489217758179, \"recall\": 0.997552752494812, \"specificity\": 0.987541675567627, \"npv\": 0.9998496174812317, \"accuracy\": 0.9881145358085632, \"f1\": 0.9057075406193584, \"f2\": 0.9586665098777046, \"f0_5\": 0.8582934147496973, \"p4\": 0.9476462734737362, \"phi\": 0.9037914134213498}, {\"truth_threshold\": -12.06556893446412, \"match_probability\": 0.00023323865583584056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106381.0, \"fp\": 1338.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.987578809261322, \"fp_rate\": 0.012421206571161747, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8297709822654724, \"recall\": 0.997552752494812, \"specificity\": 0.987578809261322, \"npv\": 0.9998496174812317, \"accuracy\": 0.9881495237350464, \"f1\": 0.9059591609945826, \"f2\": 0.9587792543808068, \"f0_5\": 0.8586550107957238, \"p4\": 0.9477925384389048, \"phi\": 0.9040383878167514}, {\"truth_threshold\": -12.062089025661068, \"match_probability\": 0.0002338017955896766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106382.0, \"fp\": 1337.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9875880479812622, \"fp_rate\": 0.012411924079060555, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8298766016960144, \"recall\": 0.997552752494812, \"specificity\": 0.9875880479812622, \"npv\": 0.9998496174812317, \"accuracy\": 0.9881582856178284, \"f1\": 0.9060220879349865, \"f2\": 0.9588074446502602, \"f0_5\": 0.8587454574182335, \"p4\": 0.9478291116347684, \"phi\": 0.9041001601480296}, {\"truth_threshold\": -12.061000609886404, \"match_probability\": 0.00023397820848859312, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106385.0, \"fp\": 1334.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9876159429550171, \"fp_rate\": 0.012384073808789253, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8301934599876404, \"recall\": 0.997552752494812, \"specificity\": 0.9876159429550171, \"npv\": 0.9998496174812317, \"accuracy\": 0.9881845116615295, \"f1\": 0.9062109212171738, \"f2\": 0.9588920254057869, \"f0_5\": 0.8590169116484906, \"p4\": 0.9479388479184274, \"phi\": 0.9042856295717483}, {\"truth_threshold\": -12.055546179794296, \"match_probability\": 0.0002348642814255809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106393.0, \"fp\": 1326.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9876902103424072, \"fp_rate\": 0.012309806421399117, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8310397267341614, \"recall\": 0.997552752494812, \"specificity\": 0.9876902103424072, \"npv\": 0.9998496174812317, \"accuracy\": 0.9882545471191406, \"f1\": 0.9067148616710691, \"f2\": 0.9591176470588235, \"f0_5\": 0.8597416293171632, \"p4\": 0.9482316005021186, \"phi\": 0.9047805825178397}, {\"truth_threshold\": -12.045057799253266, \"match_probability\": 0.00023657755899548856, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106402.0, \"fp\": 1317.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9877737164497375, \"fp_rate\": 0.012226255610585213, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8319938778877258, \"recall\": 0.997552752494812, \"specificity\": 0.9877737164497375, \"npv\": 0.9998496770858765, \"accuracy\": 0.9883333444595337, \"f1\": 0.9072824650483411, \"f2\": 0.9593715983642729, \"f0_5\": 0.8605583997466617, \"p4\": 0.9485611602938688, \"phi\": 0.9053383606743376}, {\"truth_threshold\": -12.01647284874732, \"match_probability\": 0.00024131061024701682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106403.0, \"fp\": 1316.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9877830147743225, \"fp_rate\": 0.012216972187161446, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8321000337600708, \"recall\": 0.997552752494812, \"specificity\": 0.9877830147743225, \"npv\": 0.9998496770858765, \"accuracy\": 0.9883420467376709, \"f1\": 0.9073455759599333, \"f2\": 0.9593998234774934, \"f0_5\": 0.8606492478226445, \"p4\": 0.948597791988484, \"phi\": 0.9054003752982577}, {\"truth_threshold\": -12.009479645326353, \"match_probability\": 0.00024248287505049826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106405.0, \"fp\": 1314.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9878016114234924, \"fp_rate\": 0.012198405340313911, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8323124051094055, \"recall\": 0.997552752494812, \"specificity\": 0.9878016114234924, \"npv\": 0.9998496770858765, \"accuracy\": 0.9883595705032349, \"f1\": 0.9074718241268958, \"f2\": 0.9594562786865952, \"f0_5\": 0.8608310015310702, \"p4\": 0.9486710637455341, \"phi\": 0.9055244392811951}, {\"truth_threshold\": -12.00814729914253, \"match_probability\": 0.00024270685995529594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106406.0, \"fp\": 1313.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9878108501434326, \"fp_rate\": 0.012189121916890144, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8324186205863953, \"recall\": 0.997552752494812, \"specificity\": 0.9878108501434326, \"npv\": 0.9998496770858765, \"accuracy\": 0.9883683323860168, \"f1\": 0.9075349613859319, \"f2\": 0.9594845087827699, \"f0_5\": 0.8609219071756693, \"p4\": 0.9487077038086084, \"phi\": 0.9055864886475721}, {\"truth_threshold\": -12.00442789568741, \"match_probability\": 0.0002433332358814783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106407.0, \"fp\": 1312.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9878201484680176, \"fp_rate\": 0.012179838493466377, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8325248956680298, \"recall\": 0.997552752494812, \"specificity\": 0.9878201484680176, \"npv\": 0.9998496770858765, \"accuracy\": 0.9883770942687988, \"f1\": 0.907598107431116, \"f2\": 0.9595127405402224, \"f0_5\": 0.8610128320219675, \"p4\": 0.9487443466618083, \"phi\": 0.9056485496021304}, {\"truth_threshold\": -12.002862852231262, \"match_probability\": 0.00024359728399647712, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106409.0, \"fp\": 1310.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9878387451171875, \"fp_rate\": 0.012161271646618843, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8327375054359436, \"recall\": 0.997552752494812, \"specificity\": 0.9878387451171875, \"npv\": 0.9998496770858765, \"accuracy\": 0.988394558429718, \"f1\": 0.9077244258872651, \"f2\": 0.959569209039548, \"f0_5\": 0.8611947393440025, \"p4\": 0.9488176407398647, \"phi\": 0.9057727898225875}, {\"truth_threshold\": -11.999079228135269, \"match_probability\": 0.0002442368265084751, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106410.0, \"fp\": 1309.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9878479838371277, \"fp_rate\": 0.012151988223195076, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8328438401222229, \"recall\": 0.997552752494812, \"specificity\": 0.9878479838371277, \"npv\": 0.9998496770858765, \"accuracy\": 0.9884033203125, \"f1\": 0.9077875983018999, \"f2\": 0.9595974457817144, \"f0_5\": 0.8612857218319159, \"p4\": 0.9488542919653609, \"phi\": 0.90583488556874}, {\"truth_threshold\": -11.994884516824266, \"match_probability\": 0.0002449478170347168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106418.0, \"fp\": 1301.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9879222512245178, \"fp_rate\": 0.01207772083580494, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8336955308914185, \"recall\": 0.997552752494812, \"specificity\": 0.9879222512245178, \"npv\": 0.9998496770858765, \"accuracy\": 0.9884733557701111, \"f1\": 0.9082932943388343, \"f2\": 0.9598233995584989, \"f0_5\": 0.8620142743854085, \"p4\": 0.9491476022868004, \"phi\": 0.906332153130121}, {\"truth_threshold\": -11.994600767304583, \"match_probability\": 0.000244995986349152, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106421.0, \"fp\": 1298.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9879501461982727, \"fp_rate\": 0.012049870565533638, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8340153694152832, \"recall\": 0.997552752494812, \"specificity\": 0.9879501461982727, \"npv\": 0.9998496770858765, \"accuracy\": 0.9884995818138123, \"f1\": 0.9084830756372754, \"f2\": 0.9599081596608973, \"f0_5\": 0.8622877994605743, \"p4\": 0.9492576397489789, \"phi\": 0.9065188725651812}, {\"truth_threshold\": -11.993389679249718, \"match_probability\": 0.000245201687133717, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106426.0, \"fp\": 1293.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.987996518611908, \"fp_rate\": 0.012003453448414803, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8345489501953125, \"recall\": 0.997552752494812, \"specificity\": 0.987996518611908, \"npv\": 0.9998496770858765, \"accuracy\": 0.9885433912277222, \"f1\": 0.9087995541001881, \"f2\": 0.9600494597697765, \"f0_5\": 0.8627440605323033, \"p4\": 0.949441091422103, \"phi\": 0.9068301652511358}, {\"truth_threshold\": -11.940706376168693, \"match_probability\": 0.0002543189653053501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106438.0, \"fp\": 1281.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9881079196929932, \"fp_rate\": 0.011892052367329597, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8358323574066162, \"recall\": 0.997552752494812, \"specificity\": 0.9881079196929932, \"npv\": 0.9998496770858765, \"accuracy\": 0.9886484146118164, \"f1\": 0.9095600027892058, \"f2\": 0.9603887498159328, \"f0_5\": 0.863841059602649, \"p4\": 0.9498816607601086, \"phi\": 0.9075786254767005}, {\"truth_threshold\": -11.93717562761448, \"match_probability\": 0.00025494197069527065, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106439.0, \"fp\": 1280.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9881172180175781, \"fp_rate\": 0.01188276894390583, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8359395265579224, \"recall\": 0.997552752494812, \"specificity\": 0.9881172180175781, \"npv\": 0.9998496770858765, \"accuracy\": 0.9886571764945984, \"f1\": 0.9096234309623431, \"f2\": 0.9604170348118042, \"f0_5\": 0.863932602130027, \"p4\": 0.9499183930664439, \"phi\": 0.9076410592319925}, {\"truth_threshold\": -11.935364615102007, \"match_probability\": 0.0002552621181036366, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106443.0, \"fp\": 1276.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9881543517112732, \"fp_rate\": 0.011845635250210762, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8363683223724365, \"recall\": 0.997552752494812, \"specificity\": 0.9881543517112732, \"npv\": 0.9998497366905212, \"accuracy\": 0.9886921644210815, \"f1\": 0.9098772321428571, \"f2\": 0.9605301914580265, \"f0_5\": 0.8642989663397826, \"p4\": 0.9500653503020432, \"phi\": 0.9078909950974178}, {\"truth_threshold\": -11.934541122386067, \"match_probability\": 0.000255407826510313, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106445.0, \"fp\": 1274.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9881729483604431, \"fp_rate\": 0.011827068403363228, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8365828394889832, \"recall\": 0.997552752494812, \"specificity\": 0.9881729483604431, \"npv\": 0.9998497366905212, \"accuracy\": 0.9887096881866455, \"f1\": 0.9100041858518209, \"f2\": 0.9605867797808413, \"f0_5\": 0.8644822649912518, \"p4\": 0.9501388457304982, \"phi\": 0.9080159915283592}, {\"truth_threshold\": -11.921150755882305, \"match_probability\": 0.0002577888142856652, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106446.0, \"fp\": 1273.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9881821870803833, \"fp_rate\": 0.01181778497993946, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8366901874542236, \"recall\": 0.997552752494812, \"specificity\": 0.9881821870803833, \"npv\": 0.9998497366905212, \"accuracy\": 0.9887183904647827, \"f1\": 0.910067675992465, \"f2\": 0.9606150764426901, \"f0_5\": 0.8645739434752638, \"p4\": 0.9501755976485152, \"phi\": 0.908078507341583}, {\"truth_threshold\": -11.918042656044362, \"match_probability\": 0.00025834464197526925, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106447.0, \"fp\": 1272.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9881914854049683, \"fp_rate\": 0.011808501556515694, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8367975354194641, \"recall\": 0.997552752494812, \"specificity\": 0.9881914854049683, \"npv\": 0.9998497366905212, \"accuracy\": 0.9887271523475647, \"f1\": 0.9101311749930227, \"f2\": 0.9606433747716963, \"f0_5\": 0.8646656414063743, \"p4\": 0.9502123523694873, \"phi\": 0.9081411186121389}, {\"truth_threshold\": -11.905969823743787, \"match_probability\": 0.0002605150397846019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106452.0, \"fp\": 1267.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9882379174232483, \"fp_rate\": 0.011762084439396858, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8373346924781799, \"recall\": 0.997552752494812, \"specificity\": 0.9882379174232483, \"npv\": 0.9998497366905212, \"accuracy\": 0.9887709021568298, \"f1\": 0.9104488029594472, \"f2\": 0.9607848914292448, \"f0_5\": 0.8651244229850905, \"p4\": 0.9503961680299383, \"phi\": 0.9084539325711393}, {\"truth_threshold\": -11.905938790777679, \"match_probability\": 0.00026052064217104315, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106455.0, \"fp\": 1264.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9882657527923584, \"fp_rate\": 0.011734234169125557, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8376573324203491, \"recall\": 0.997552752494812, \"specificity\": 0.9882657527923584, \"npv\": 0.9998497366905212, \"accuracy\": 0.9887971878051758, \"f1\": 0.9106394861770455, \"f2\": 0.9608698214390948, \"f0_5\": 0.8653999256939653, \"p4\": 0.95050649108227, \"phi\": 0.9086418457891801}, {\"truth_threshold\": -11.903543086349247, \"match_probability\": 0.0002609535028443197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106456.0, \"fp\": 1263.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9882750511169434, \"fp_rate\": 0.01172495074570179, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8377649188041687, \"recall\": 0.997552752494812, \"specificity\": 0.9882750511169434, \"npv\": 0.9998497366905212, \"accuracy\": 0.9888059496879578, \"f1\": 0.9107030650003491, \"f2\": 0.9608981347791496, \"f0_5\": 0.8654917989277563, \"p4\": 0.950543271044323, \"phi\": 0.9087044791496731}, {\"truth_threshold\": -11.896369436098844, \"match_probability\": 0.00026225395706891137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106459.0, \"fp\": 1260.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9883028864860535, \"fp_rate\": 0.011697100475430489, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8380879163742065, \"recall\": 0.997552752494812, \"specificity\": 0.9883028864860535, \"npv\": 0.9998497366905212, \"accuracy\": 0.9888321757316589, \"f1\": 0.9108938547486034, \"f2\": 0.9609830848116933, \"f0_5\": 0.8657675357085967, \"p4\": 0.9506536277688199, \"phi\": 0.9088924498927079}, {\"truth_threshold\": -11.89318461704425, \"match_probability\": 0.00026283338251389515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106460.0, \"fp\": 1259.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9883121848106384, \"fp_rate\": 0.011687817052006721, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8381956219673157, \"recall\": 0.997552752494812, \"specificity\": 0.9883121848106384, \"npv\": 0.9998497366905212, \"accuracy\": 0.9888409376144409, \"f1\": 0.910957469097004, \"f2\": 0.9610114048271594, \"f0_5\": 0.8658594870160905, \"p4\": 0.9506904189575057, \"phi\": 0.9089552141587597}, {\"truth_threshold\": -11.876511581573531, \"match_probability\": 0.0002658877207516241, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106485.0, \"fp\": 1234.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9885442852973938, \"fp_rate\": 0.011455732397735119, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8408973813056946, \"recall\": 0.997552752494812, \"specificity\": 0.9885442852973938, \"npv\": 0.999849796295166, \"accuracy\": 0.9890597462654114, \"f1\": 0.9125507205820624, \"f2\": 0.9617199480948448, \"f0_5\": 0.8681646344710079, \"p4\": 0.9516111119395232, \"phi\": 0.9105264033672531}, {\"truth_threshold\": -11.866665268690655, \"match_probability\": 0.00026770810871497747, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106486.0, \"fp\": 1233.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.988553524017334, \"fp_rate\": 0.011446448974311352, \"fn_rate\": 0.00244723167270422, \"precision\": 0.841005802154541, \"recall\": 0.997552752494812, \"specificity\": 0.988553524017334, \"npv\": 0.999849796295166, \"accuracy\": 0.9890685081481934, \"f1\": 0.9126145665710488, \"f2\": 0.9617483115580854, \"f0_5\": 0.8682570956919964, \"p4\": 0.9516479762271927, \"phi\": 0.9105893916308729}, {\"truth_threshold\": -11.863939828240254, \"match_probability\": 0.0002682141867274451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106489.0, \"fp\": 1230.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9885814189910889, \"fp_rate\": 0.01141859870404005, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8413312435150146, \"recall\": 0.997552752494812, \"specificity\": 0.9885814189910889, \"npv\": 0.999849796295166, \"accuracy\": 0.9890947341918945, \"f1\": 0.9128061581525543, \"f2\": 0.9618334119867862, \"f0_5\": 0.868534597560326, \"p4\": 0.9517585859866756, \"phi\": 0.9107784277660547}, {\"truth_threshold\": -11.86229772235383, \"match_probability\": 0.00026851956555059816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106498.0, \"fp\": 1221.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9886649250984192, \"fp_rate\": 0.011335047893226147, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8423091769218445, \"recall\": 0.997552752494812, \"specificity\": 0.9886649250984192, \"npv\": 0.999849796295166, \"accuracy\": 0.9891735315322876, \"f1\": 0.9133814158672362, \"f2\": 0.9620888036583567, \"f0_5\": 0.8693681684884031, \"p4\": 0.9520905674091823, \"phi\": 0.9113463471165133}, {\"truth_threshold\": -11.859338345395692, \"match_probability\": 0.00026907079234515585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106501.0, \"fp\": 1218.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9886928200721741, \"fp_rate\": 0.011307197622954845, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8426356315612793, \"recall\": 0.997552752494812, \"specificity\": 0.9886928200721741, \"npv\": 0.999849796295166, \"accuracy\": 0.9891997575759888, \"f1\": 0.9135733295979829, \"f2\": 0.9621739643573705, \"f0_5\": 0.8696463811403274, \"p4\": 0.9522012786272028, \"phi\": 0.9115358122890198}, {\"truth_threshold\": -11.843520749802051, \"match_probability\": 0.0002720362879665608, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106502.0, \"fp\": 1217.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887020587921143, \"fp_rate\": 0.011297914199531078, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8427445292472839, \"recall\": 0.997552752494812, \"specificity\": 0.9887020587921143, \"npv\": 0.999849796295166, \"accuracy\": 0.9892085194587708, \"f1\": 0.9136373187644463, \"f2\": 0.9622023546074179, \"f0_5\": 0.8697391582653224, \"p4\": 0.952238188007559, \"phi\": 0.9115989912326653}, {\"truth_threshold\": -11.838617379718558, \"match_probability\": 0.00027296219344076554, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106503.0, \"fp\": 1216.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887113571166992, \"fp_rate\": 0.011288630776107311, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8428534269332886, \"recall\": 0.997552752494812, \"specificity\": 0.9887113571166992, \"npv\": 0.999849796295166, \"accuracy\": 0.9892172813415527, \"f1\": 0.913701316895489, \"f2\": 0.9622307465329005, \"f0_5\": 0.8698319551880501, \"p4\": 0.952275100208964, \"phi\": 0.9116621821257881}, {\"truth_threshold\": -11.838111453771807, \"match_probability\": 0.00027305790677852266, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106504.0, \"fp\": 1215.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887206554412842, \"fp_rate\": 0.011279347352683544, \"fn_rate\": 0.00244723167270422, \"precision\": 0.842962384223938, \"recall\": 0.997552752494812, \"specificity\": 0.9887206554412842, \"npv\": 0.999849796295166, \"accuracy\": 0.9892260432243347, \"f1\": 0.9137653239929947, \"f2\": 0.9622591401339667, \"f0_5\": 0.8699247719148482, \"p4\": 0.9523120152317421, \"phi\": 0.911725468978075}, {\"truth_threshold\": -11.834502894245098, \"match_probability\": 0.00027374156406409066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106505.0, \"fp\": 1214.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887299537658691, \"fp_rate\": 0.011270063929259777, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8430713415145874, \"recall\": 0.997552752494812, \"specificity\": 0.9887299537658691, \"npv\": 0.999849796295166, \"accuracy\": 0.9892348051071167, \"f1\": 0.9138293400588483, \"f2\": 0.9622875354107648, \"f0_5\": 0.870017608452057, \"p4\": 0.9523489330762182, \"phi\": 0.9117886837867274}, {\"truth_threshold\": -11.834117899367481, \"match_probability\": 0.0002738146039645983, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106508.0, \"fp\": 1211.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887577891349792, \"fp_rate\": 0.011242213658988476, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8433984518051147, \"recall\": 0.997552752494812, \"specificity\": 0.9887577891349792, \"npv\": 0.999849796295166, \"accuracy\": 0.9892610311508179, \"f1\": 0.9140214420853479, \"f2\": 0.962372731297034, \"f0_5\": 0.8702962369895917, \"p4\": 0.9524597035430795, \"phi\": 0.911978399994221}, {\"truth_threshold\": -11.801228991061611, \"match_probability\": 0.00028012664088261456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106509.0, \"fp\": 1210.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887670874595642, \"fp_rate\": 0.011232930235564709, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8435075283050537, \"recall\": 0.997552752494812, \"specificity\": 0.9887670874595642, \"npv\": 0.999849796295166, \"accuracy\": 0.9892697930335999, \"f1\": 0.9140854940434477, \"f2\": 0.9624011332782434, \"f0_5\": 0.8703891528319009, \"p4\": 0.9524966326775933, \"phi\": 0.9120416626700741}, {\"truth_threshold\": -11.799924761615348, \"match_probability\": 0.0002803799252651853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106510.0, \"fp\": 1209.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887763261795044, \"fp_rate\": 0.011223646812140942, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8436166048049927, \"recall\": 0.997552752494812, \"specificity\": 0.9887763261795044, \"npv\": 0.999849796295166, \"accuracy\": 0.9892785549163818, \"f1\": 0.9141495549793258, \"f2\": 0.9624295369359266, \"f0_5\": 0.8704820885163632, \"p4\": 0.9525335646354286, \"phi\": 0.9121049373223642}, {\"truth_threshold\": -11.798167384934114, \"match_probability\": 0.0002807215740194846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106512.0, \"fp\": 1207.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9887949228286743, \"fp_rate\": 0.011205079965293407, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8438349366188049, \"recall\": 0.997552752494812, \"specificity\": 0.9887949228286743, \"npv\": 0.999849796295166, \"accuracy\": 0.9892960786819458, \"f1\": 0.9142777037919675, \"f2\": 0.9624863492813082, \"f0_5\": 0.8706680194371763, \"p4\": 0.9526074370223626, \"phi\": 0.9122316066178386}, {\"truth_threshold\": -11.787388271743243, \"match_probability\": 0.0002828262481593986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106516.0, \"fp\": 1203.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9888320565223694, \"fp_rate\": 0.011167946271598339, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8442718386650085, \"recall\": 0.997552752494812, \"specificity\": 0.9888320565223694, \"npv\": 0.999849796295166, \"accuracy\": 0.989331066608429, \"f1\": 0.9145341092336815, \"f2\": 0.9625999940962895, \"f0_5\": 0.871040119664512, \"p4\": 0.9527552156903843, \"phi\": 0.9124849210237881}, {\"truth_threshold\": -11.781981106468333, \"match_probability\": 0.00028388795746299276, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106518.0, \"fp\": 1201.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9888505935668945, \"fp_rate\": 0.011149379424750805, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8444904685020447, \"recall\": 0.997552752494812, \"specificity\": 0.9888505935668945, \"npv\": 0.999849796295166, \"accuracy\": 0.9893485903739929, \"f1\": 0.9146623658929949, \"f2\": 0.9626568265682657, \"f0_5\": 0.8712262890729362, \"p4\": 0.9528291219766734, \"phi\": 0.9126117343086084}, {\"truth_threshold\": -11.780036567659899, \"match_probability\": 0.0002842707454382796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106519.0, \"fp\": 1200.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9888598918914795, \"fp_rate\": 0.011140096001327038, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8445998430252075, \"recall\": 0.997552752494812, \"specificity\": 0.9888598918914795, \"npv\": 0.999849796295166, \"accuracy\": 0.9893573522567749, \"f1\": 0.914726507713885, \"f2\": 0.9626852453208951, \"f0_5\": 0.8713194036231496, \"p4\": 0.9528660793590256, \"phi\": 0.912675116932757}, {\"truth_threshold\": -11.767250626172165, \"match_probability\": 0.00028680057734413174, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106523.0, \"fp\": 1196.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9888970255851746, \"fp_rate\": 0.01110296230763197, \"fn_rate\": 0.00244723167270422, \"precision\": 0.845037579536438, \"recall\": 0.997552752494812, \"specificity\": 0.9888970255851746, \"npv\": 0.999849796295166, \"accuracy\": 0.9893923401832581, \"f1\": 0.914983164983165, \"f2\": 0.9627989371124889, \"f0_5\": 0.871692060946271, \"p4\": 0.9530139371574102, \"phi\": 0.9129287676191111}, {\"truth_threshold\": -11.749763199443326, \"match_probability\": 0.00029029713002656603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106525.0, \"fp\": 1194.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9889156222343445, \"fp_rate\": 0.011084395460784435, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8452566266059875, \"recall\": 0.997552752494812, \"specificity\": 0.9889156222343445, \"npv\": 0.999849796295166, \"accuracy\": 0.989409863948822, \"f1\": 0.9151115476357514, \"f2\": 0.9628557930790126, \"f0_5\": 0.8718785091706326, \"p4\": 0.9530878830225444, \"phi\": 0.9130557492422343}, {\"truth_threshold\": -11.745915099684648, \"match_probability\": 0.00029107224731127814, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106526.0, \"fp\": 1193.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9889248609542847, \"fp_rate\": 0.011075112037360668, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8453661799430847, \"recall\": 0.997552752494812, \"specificity\": 0.9889248609542847, \"npv\": 0.999849796295166, \"accuracy\": 0.9894185662269592, \"f1\": 0.9151757524731635, \"f2\": 0.9628842235804765, \"f0_5\": 0.8719717631958929, \"p4\": 0.9531248601977363, \"phi\": 0.9131192160585856}, {\"truth_threshold\": -11.741339121970988, \"match_probability\": 0.0002919966735522426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106533.0, \"fp\": 1186.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9889898896217346, \"fp_rate\": 0.011010128073394299, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8461338877677917, \"recall\": 0.997552752494812, \"specificity\": 0.9889898896217346, \"npv\": 0.9998498558998108, \"accuracy\": 0.9894798398017883, \"f1\": 0.9156254387196406, \"f2\": 0.9630832841110455, \"f0_5\": 0.8726251003478727, \"p4\": 0.9533837796501443, \"phi\": 0.913563905326636}, {\"truth_threshold\": -11.729800216542053, \"match_probability\": 0.00029434078397269777, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106534.0, \"fp\": 1185.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9889991283416748, \"fp_rate\": 0.011000844649970531, \"fn_rate\": 0.00244723167270422, \"precision\": 0.846243679523468, \"recall\": 0.997552752494812, \"specificity\": 0.9889991283416748, \"npv\": 0.9998498558998108, \"accuracy\": 0.9894886016845703, \"f1\": 0.9156897156897157, \"f2\": 0.9631117280486724, \"f0_5\": 0.8727185141572552, \"p4\": 0.953420779465265, \"phi\": 0.9136274685951494}, {\"truth_threshold\": -11.707424144361706, \"match_probability\": 0.00029894019474051807, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106548.0, \"fp\": 1171.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9891291260719299, \"fp_rate\": 0.010870876722037792, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8477836847305298, \"recall\": 0.997552752494812, \"specificity\": 0.9891291260719299, \"npv\": 0.9998498558998108, \"accuracy\": 0.9896111488342285, \"f1\": 0.9165905417749982, \"f2\": 0.9635101196631704, \"f0_5\": 0.8740284106137765, \"p4\": 0.9539390743284736, \"phi\": 0.9145187922981026}, {\"truth_threshold\": -11.690162914518096, \"match_probability\": 0.00030253728026586625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106549.0, \"fp\": 1170.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9891384243965149, \"fp_rate\": 0.010861593298614025, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8478938937187195, \"recall\": 0.997552752494812, \"specificity\": 0.9891384243965149, \"npv\": 0.9998498558998108, \"accuracy\": 0.9896199107170105, \"f1\": 0.9166549543218553, \"f2\": 0.9635385888192886, \"f0_5\": 0.8741221251273253, \"p4\": 0.9539761166497257, \"phi\": 0.9145826213220367}, {\"truth_threshold\": -11.678710590847846, \"match_probability\": 0.00030494768739197946, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106551.0, \"fp\": 1168.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.98915696144104, \"fp_rate\": 0.010843026451766491, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8481144309043884, \"recall\": 0.997552752494812, \"specificity\": 0.98915696144104, \"npv\": 0.9998498558998108, \"accuracy\": 0.9896373748779297, \"f1\": 0.9167838065785775, \"f2\": 0.9635955321789492, \"f0_5\": 0.8743096144565392, \"p4\": 0.954050209801621, \"phi\": 0.9147101473135811}, {\"truth_threshold\": -11.662506521297281, \"match_probability\": 0.00030839104547945493, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106552.0, \"fp\": 1167.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.989166259765625, \"fp_rate\": 0.010833743028342724, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8482247591018677, \"recall\": 0.997552752494812, \"specificity\": 0.989166259765625, \"npv\": 0.9998498558998108, \"accuracy\": 0.9896461367607117, \"f1\": 0.9168482462922612, \"f2\": 0.9636240063827901, \"f0_5\": 0.8744033892851397, \"p4\": 0.9540872606329179, \"phi\": 0.9147739285173897}, {\"truth_threshold\": -11.66066386118418, \"match_probability\": 0.0003087850631585367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106556.0, \"fp\": 1163.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9892033934593201, \"fp_rate\": 0.010796609334647655, \"fn_rate\": 0.00244723167270422, \"precision\": 0.848666250705719, \"recall\": 0.997552752494812, \"specificity\": 0.9892033934593201, \"npv\": 0.9998498558998108, \"accuracy\": 0.9896811842918396, \"f1\": 0.9171060957603882, \"f2\": 0.9637379200283713, \"f0_5\": 0.8747786898438757, \"p4\": 0.9542354923347303, \"phi\": 0.9150292590803121}, {\"truth_threshold\": -11.65205706423714, \"match_probability\": 0.0003106321379089575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106557.0, \"fp\": 1162.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.989212691783905, \"fp_rate\": 0.010787325911223888, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8487766981124878, \"recall\": 0.997552752494812, \"specificity\": 0.989212691783905, \"npv\": 0.9998498558998108, \"accuracy\": 0.9896898865699768, \"f1\": 0.9171705807903249, \"f2\": 0.9637664026480671, \"f0_5\": 0.8748725653270376, \"p4\": 0.9542725573559749, \"phi\": 0.9150931010482342}, {\"truth_threshold\": -11.641857816302702, \"match_probability\": 0.0003128352680710214, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106559.0, \"fp\": 1160.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9892312288284302, \"fp_rate\": 0.010768759064376354, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8489976525306702, \"recall\": 0.997552752494812, \"specificity\": 0.9892312288284302, \"npv\": 0.9998498558998108, \"accuracy\": 0.9897074103355408, \"f1\": 0.9172995780590717, \"f2\": 0.9638233729384643, \"f0_5\": 0.8750603767509257, \"p4\": 0.9543466959157045, \"phi\": 0.9152208214788895}, {\"truth_threshold\": -11.63613024000488, \"match_probability\": 0.0003140793185403085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106561.0, \"fp\": 1158.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9892498254776001, \"fp_rate\": 0.01075019221752882, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8492187261581421, \"recall\": 0.997552752494812, \"specificity\": 0.9892498254776001, \"npv\": 0.9998498558998108, \"accuracy\": 0.9897249341011047, \"f1\": 0.9174286116190744, \"f2\": 0.9638803499645306, \"f0_5\": 0.8752482688281711, \"p4\": 0.9544208458339364, \"phi\": 0.9153485905955892}, {\"truth_threshold\": -11.618845984732337, \"match_probability\": 0.000317863583543726, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106565.0, \"fp\": 1154.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9892869591712952, \"fp_rate\": 0.010713058523833752, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8496612906455994, \"recall\": 0.997552752494812, \"specificity\": 0.9892869591712952, \"npv\": 0.9998498558998108, \"accuracy\": 0.9897599220275879, \"f1\": 0.9176867876741241, \"f2\": 0.9639943242284498, \"f0_5\": 0.8756242951506363, \"p4\": 0.9545691797563841, \"phi\": 0.9156043593283039}, {\"truth_threshold\": -11.614614711411924, \"match_probability\": 0.00031879691492404976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106566.0, \"fp\": 1153.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9892961978912354, \"fp_rate\": 0.010703775100409985, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8497719764709473, \"recall\": 0.997552752494812, \"specificity\": 0.9892961978912354, \"npv\": 0.9998498558998108, \"accuracy\": 0.9897686839103699, \"f1\": 0.9177513543938648, \"f2\": 0.9640228220060898, \"f0_5\": 0.8757183522208497, \"p4\": 0.9546062703401533, \"phi\": 0.9156683109160282}, {\"truth_threshold\": -11.609507429193531, \"match_probability\": 0.00031992712561824586, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106570.0, \"fp\": 1149.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9893333315849304, \"fp_rate\": 0.01066664233803749, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8502150774002075, \"recall\": 0.997552752494812, \"specificity\": 0.9893333315849304, \"npv\": 0.9998499155044556, \"accuracy\": 0.989803671836853, \"f1\": 0.9180097121542684, \"f2\": 0.9641368299677734, \"f0_5\": 0.8760947826554188, \"p4\": 0.9547546610976889, \"phi\": 0.9159243236386136}, {\"truth_threshold\": -11.604594469130367, \"match_probability\": 0.00032101811369488343, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106571.0, \"fp\": 1148.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9893426299095154, \"fp_rate\": 0.010657358914613724, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8503259420394897, \"recall\": 0.997552752494812, \"specificity\": 0.9893426299095154, \"npv\": 0.9998499155044556, \"accuracy\": 0.989812433719635, \"f1\": 0.9180743243243243, \"f2\": 0.9641653361717225, \"f0_5\": 0.8761889408350798, \"p4\": 0.9547917658943265, \"phi\": 0.9159883362669299}, {\"truth_threshold\": -11.603310728666958, \"match_probability\": 0.0003213037976853657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106575.0, \"fp\": 1144.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9893797636032104, \"fp_rate\": 0.010620225220918655, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8507696390151978, \"recall\": 0.997552752494812, \"specificity\": 0.9893797636032104, \"npv\": 0.9998499155044556, \"accuracy\": 0.9898474216461182, \"f1\": 0.9183328639819769, \"f2\": 0.9642793778461175, \"f0_5\": 0.8765657760335466, \"p4\": 0.9549402135197288, \"phi\": 0.9162445933756462}, {\"truth_threshold\": -11.60307580598299, \"match_probability\": 0.0003213561049546368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106583.0, \"fp\": 1136.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9894540309906006, \"fp_rate\": 0.010545957833528519, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8516584038734436, \"recall\": 0.997552752494812, \"specificity\": 0.9894540309906006, \"npv\": 0.9998499155044556, \"accuracy\": 0.9899174571037292, \"f1\": 0.9188503803888419, \"f2\": 0.9645075421472937, \"f0_5\": 0.8773204196933011, \"p4\": 0.9552372453452747, \"phi\": 0.9167576108377148}, {\"truth_threshold\": -11.57948824256959, \"match_probability\": 0.00032665162150429374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106585.0, \"fp\": 1134.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9894726276397705, \"fp_rate\": 0.010527390986680984, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8518808484077454, \"recall\": 0.997552752494812, \"specificity\": 0.9894726276397705, \"npv\": 0.9998499155044556, \"accuracy\": 0.9899349808692932, \"f1\": 0.918979850641116, \"f2\": 0.9645646000946522, \"f0_5\": 0.8775092836768742, \"p4\": 0.9553115317700538, \"phi\": 0.9168859666993817}, {\"truth_threshold\": -11.571256522156887, \"match_probability\": 0.0003285201416273573, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106588.0, \"fp\": 1131.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9895004630088806, \"fp_rate\": 0.010499540716409683, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8522148132324219, \"recall\": 0.997552752494812, \"specificity\": 0.9895004630088806, \"npv\": 0.9998499155044556, \"accuracy\": 0.9899612069129944, \"f1\": 0.9191741244450709, \"f2\": 0.9646501996746043, \"f0_5\": 0.877792732166891, \"p4\": 0.9554229827691941, \"phi\": 0.9170786769945481}, {\"truth_threshold\": -11.562668078063858, \"match_probability\": 0.0003304810248761039, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106601.0, \"fp\": 1118.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9896211624145508, \"fp_rate\": 0.010378856211900711, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8536649346351624, \"recall\": 0.997552752494812, \"specificity\": 0.9896211624145508, \"npv\": 0.9998499155044556, \"accuracy\": 0.9900749921798706, \"f1\": 0.920016927634363, \"f2\": 0.9650213068181818, \"f0_5\": 0.8790231279314249, \"p4\": 0.9559062335233547, \"phi\": 0.9179148373364995}, {\"truth_threshold\": -11.559588685131885, \"match_probability\": 0.0003311869470425025, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106604.0, \"fp\": 1115.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9896489977836609, \"fp_rate\": 0.01035100594162941, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8540002703666687, \"recall\": 0.997552752494812, \"specificity\": 0.9896489977836609, \"npv\": 0.9998499155044556, \"accuracy\": 0.9901012778282166, \"f1\": 0.9202116402116403, \"f2\": 0.9651069874811329, \"f0_5\": 0.8793075554117457, \"p4\": 0.9560178213838543, \"phi\": 0.9181080542574198}, {\"truth_threshold\": -11.55555759721859, \"match_probability\": 0.00033211331508398016, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106605.0, \"fp\": 1114.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9896582961082458, \"fp_rate\": 0.010341722518205643, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8541120886802673, \"recall\": 0.997552752494812, \"specificity\": 0.9896582961082458, \"npv\": 0.9998499155044556, \"accuracy\": 0.9901100397109985, \"f1\": 0.9202765627204741, \"f2\": 0.9651355510832248, \"f0_5\": 0.8794024054797476, \"p4\": 0.9560550230457282, \"phi\": 0.9181724845941764}, {\"truth_threshold\": -11.52846730335492, \"match_probability\": 0.0003384063819728147, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106613.0, \"fp\": 1106.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.989732563495636, \"fp_rate\": 0.010267455130815506, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8550078868865967, \"recall\": 0.997552752494812, \"specificity\": 0.989732563495636, \"npv\": 0.9998499751091003, \"accuracy\": 0.9901800155639648, \"f1\": 0.9207962727657772, \"f2\": 0.9653641207815276, \"f0_5\": 0.8801619433198381, \"p4\": 0.9563527391389296, \"phi\": 0.9186885415260724}, {\"truth_threshold\": -11.524052818156111, \"match_probability\": 0.00033944310141503884, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106616.0, \"fp\": 1103.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9897603988647461, \"fp_rate\": 0.010239604860544205, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8553442358970642, \"recall\": 0.997552752494812, \"specificity\": 0.9897603988647461, \"npv\": 0.9998499751091003, \"accuracy\": 0.9902063012123108, \"f1\": 0.9209913153992798, \"f2\": 0.9654498623323563, \"f0_5\": 0.8804471083751823, \"p4\": 0.9564644298114989, \"phi\": 0.9188822037641594}, {\"truth_threshold\": -11.512812430889065, \"match_probability\": 0.00034209720623794835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106618.0, \"fp\": 1101.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9897789359092712, \"fp_rate\": 0.01022103801369667, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8555686473846436, \"recall\": 0.997552752494812, \"specificity\": 0.9897789359092712, \"npv\": 0.9998499751091003, \"accuracy\": 0.99022376537323, \"f1\": 0.9211213897323636, \"f2\": 0.9655070318282754, \"f0_5\": 0.8806373210910073, \"p4\": 0.9565389045511569, \"phi\": 0.919011373913013}, {\"truth_threshold\": -11.503539389336291, \"match_probability\": 0.00034430238661626244, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106619.0, \"fp\": 1100.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9897882342338562, \"fp_rate\": 0.010211754590272903, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8556809425354004, \"recall\": 0.997552752494812, \"specificity\": 0.9897882342338562, \"npv\": 0.9998499751091003, \"accuracy\": 0.990232527256012, \"f1\": 0.9211864406779661, \"f2\": 0.9655356191152958, \"f0_5\": 0.8807324582725652, \"p4\": 0.95657614620936, \"phi\": 0.9190759775966306}, {\"truth_threshold\": -11.498188140467743, \"match_probability\": 0.0003455814033465271, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106621.0, \"fp\": 1098.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9898068308830261, \"fp_rate\": 0.01019318774342537, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8559055328369141, \"recall\": 0.997552752494812, \"specificity\": 0.9898068308830261, \"npv\": 0.9998499751091003, \"accuracy\": 0.9902500510215759, \"f1\": 0.921316570137025, \"f2\": 0.9655927987682104, \"f0_5\": 0.8809227943162785, \"p4\": 0.9566506381041667, \"phi\": 0.9192053068043797}, {\"truth_threshold\": -11.458108472772537, \"match_probability\": 0.0003553131805121773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106626.0, \"fp\": 1093.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9898532032966614, \"fp_rate\": 0.010146770626306534, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8564674854278564, \"recall\": 0.997552752494812, \"specificity\": 0.9898532032966614, \"npv\": 0.9998499751091003, \"accuracy\": 0.9902938008308411, \"f1\": 0.921642054688052, \"f2\": 0.9657357775342791, \"f0_5\": 0.8813989945402454, \"p4\": 0.956836917897273, \"phi\": 0.9195287203874342}, {\"truth_threshold\": -11.45120332702329, \"match_probability\": 0.0003570172774389568, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106636.0, \"fp\": 1083.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9899460673332214, \"fp_rate\": 0.010053936392068863, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8575937151908875, \"recall\": 0.997552752494812, \"specificity\": 0.9899460673332214, \"npv\": 0.9998499751091003, \"accuracy\": 0.9903813600540161, \"f1\": 0.922293714204907, \"f2\": 0.9660218621322985, \"f0_5\": 0.8823529411764706, \"p4\": 0.9572096921501327, \"phi\": 0.9201763965360782}, {\"truth_threshold\": -11.448902328961408, \"match_probability\": 0.0003575869456726546, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106638.0, \"fp\": 1081.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9899646043777466, \"fp_rate\": 0.010035369545221329, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8578192591667175, \"recall\": 0.997552752494812, \"specificity\": 0.9899646043777466, \"npv\": 0.9998499751091003, \"accuracy\": 0.9903988242149353, \"f1\": 0.9224241567074465, \"f2\": 0.9660790993926825, \"f0_5\": 0.8825439783491205, \"p4\": 0.9572842813698724, \"phi\": 0.9203060644785924}, {\"truth_threshold\": -11.443823796657693, \"match_probability\": 0.00035884747827326054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6522.0, \"tn\": 106642.0, \"fp\": 1077.0, \"fn\": 16.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997552752494812, \"tn_rate\": 0.9900017380714417, \"fp_rate\": 0.00999823585152626, \"fn_rate\": 0.00244723167270422, \"precision\": 0.8582708239555359, \"recall\": 0.997552752494812, \"specificity\": 0.9900017380714417, \"npv\": 0.9998499751091003, \"accuracy\": 0.9904338717460632, \"f1\": 0.9226851524368678, \"f2\": 0.9661935942638736, \"f0_5\": 0.8829263009692966, \"p4\": 0.9574334941997169, \"phi\": 0.9205656349737876}, {\"truth_threshold\": -11.437573524188078, \"match_probability\": 0.0003604049452932645, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106661.0, \"fp\": 1058.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9901781678199768, \"fp_rate\": 0.00982185173779726, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8604037761688232, \"recall\": 0.9973998069763184, \"specificity\": 0.9901781678199768, \"npv\": 0.9998406171798706, \"accuracy\": 0.9905914068222046, \"f1\": 0.923850676489339, \"f2\": 0.9666182443449646, \"f0_5\": 0.8847072230965431, \"p4\": 0.9580997409238895, \"phi\": 0.921714931836043}, {\"truth_threshold\": -11.422239287234444, \"match_probability\": 0.00036425467489813824, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106664.0, \"fp\": 1055.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9902060031890869, \"fp_rate\": 0.009794001467525959, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8607444763183594, \"recall\": 0.9973998069763184, \"specificity\": 0.9902060031890869, \"npv\": 0.9998406171798706, \"accuracy\": 0.9906176328659058, \"f1\": 0.9240470454867508, \"f2\": 0.9667042220113852, \"f0_5\": 0.884995385701102, \"p4\": 0.9582118504302867, \"phi\": 0.9219104028410233}, {\"truth_threshold\": -11.421681597217301, \"match_probability\": 0.0003643954575447904, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106669.0, \"fp\": 1050.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9902524352073669, \"fp_rate\": 0.009747584350407124, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8613129258155823, \"recall\": 0.9973998069763184, \"specificity\": 0.9902524352073669, \"npv\": 0.9998406767845154, \"accuracy\": 0.9906613826751709, \"f1\": 0.9243745127223758, \"f2\": 0.9668475521157667, \"f0_5\": 0.8854760740861441, \"p4\": 0.9583987571066477, \"phi\": 0.9222365247237803}, {\"truth_threshold\": -11.417144420111681, \"match_probability\": 0.0003655428406677472, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106671.0, \"fp\": 1048.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9902709722518921, \"fp_rate\": 0.00972901750355959, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8615404963493347, \"recall\": 0.9973998069763184, \"specificity\": 0.9902709722518921, \"npv\": 0.9998406767845154, \"accuracy\": 0.9906789064407349, \"f1\": 0.9245055646133126, \"f2\": 0.9669048960588358, \"f0_5\": 0.8856684956809909, \"p4\": 0.9584735399096205, \"phi\": 0.9223670278483149}, {\"truth_threshold\": -11.41714442011168, \"match_probability\": 0.00036554284066774766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106672.0, \"fp\": 1047.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.990280270576477, \"fp_rate\": 0.009719734080135822, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8616543412208557, \"recall\": 0.9973998069763184, \"specificity\": 0.990280270576477, \"npv\": 0.9998406767845154, \"accuracy\": 0.9906876683235168, \"f1\": 0.9245711044945414, \"f2\": 0.9669335705812574, \"f0_5\": 0.8857647378429775, \"p4\": 0.9585109356265307, \"phi\": 0.9224323832206465}, {\"truth_threshold\": -11.412031496718027, \"match_probability\": 0.00036684014982115803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106676.0, \"fp\": 1043.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9903174042701721, \"fp_rate\": 0.009682600386440754, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8621100187301636, \"recall\": 0.9973998069763184, \"specificity\": 0.9903174042701721, \"npv\": 0.9998406767845154, \"accuracy\": 0.99072265625, \"f1\": 0.9248333569706425, \"f2\": 0.9670482856803891, \"f0_5\": 0.8861499157471326, \"p4\": 0.9586605472714376, \"phi\": 0.9226935916007835}, {\"truth_threshold\": -11.410942608928604, \"match_probability\": 0.0003671170287390778, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106679.0, \"fp\": 1040.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9903452396392822, \"fp_rate\": 0.009654750116169453, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8624520301818848, \"recall\": 0.9973998069763184, \"specificity\": 0.9903452396392822, \"npv\": 0.9998406767845154, \"accuracy\": 0.990748941898346, \"f1\": 0.9250301439818427, \"f2\": 0.9671343398688933, \"f0_5\": 0.8864390190854222, \"p4\": 0.9587727862305795, \"phi\": 0.9228897155832569}, {\"truth_threshold\": -11.40787356802388, \"match_probability\": 0.00036789853935265056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106681.0, \"fp\": 1038.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9903638362884521, \"fp_rate\": 0.009636183269321918, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8626802563667297, \"recall\": 0.9973998069763184, \"specificity\": 0.9903638362884521, \"npv\": 0.9998406767845154, \"accuracy\": 0.9907664060592651, \"f1\": 0.9251613818542952, \"f2\": 0.9671917178369078, \"f0_5\": 0.886631859465927, \"p4\": 0.9588476266014191, \"phi\": 0.9230204716057472}, {\"truth_threshold\": -11.401177671706614, \"match_probability\": 0.00036960938141215383, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106683.0, \"fp\": 1036.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9903823733329773, \"fp_rate\": 0.009617616422474384, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8629085421562195, \"recall\": 0.9973998069763184, \"specificity\": 0.9903823733329773, \"npv\": 0.9998406767845154, \"accuracy\": 0.9907839298248291, \"f1\": 0.925292656970557, \"f2\": 0.9672491026135454, \"f0_5\": 0.8868247837676114, \"p4\": 0.9589224784938346, \"phi\": 0.9231512783036688}, {\"truth_threshold\": -11.382594885137893, \"match_probability\": 0.0003743991733231891, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106688.0, \"fp\": 1031.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9904288053512573, \"fp_rate\": 0.009571199305355549, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8634798526763916, \"recall\": 0.9973998069763184, \"specificity\": 0.9904288053512573, \"npv\": 0.9998406767845154, \"accuracy\": 0.9908276796340942, \"f1\": 0.9256210078069553, \"f2\": 0.9673925943508189, \"f0_5\": 0.8873074620366843, \"p4\": 0.9591096586492884, \"phi\": 0.9234786019276116}, {\"truth_threshold\": -11.37681497877723, \"match_probability\": 0.0003759015821106949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106689.0, \"fp\": 1030.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9904381036758423, \"fp_rate\": 0.009561915881931782, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8635942339897156, \"recall\": 0.9973998069763184, \"specificity\": 0.9904381036758423, \"npv\": 0.9998406767845154, \"accuracy\": 0.9908364415168762, \"f1\": 0.9256867059408049, \"f2\": 0.9674212978073169, \"f0_5\": 0.8874040607479179, \"p4\": 0.9591471033272354, \"phi\": 0.9235440877442926}, {\"truth_threshold\": -11.374543344463733, \"match_probability\": 0.00037649371127873365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106690.0, \"fp\": 1029.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9904473423957825, \"fp_rate\": 0.009552632458508015, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8637086153030396, \"recall\": 0.9973998069763184, \"specificity\": 0.9904473423957825, \"npv\": 0.9998406767845154, \"accuracy\": 0.9908452033996582, \"f1\": 0.9257524134014764, \"f2\": 0.967450002967183, \"f0_5\": 0.8875006804943111, \"p4\": 0.9591845508882471, \"phi\": 0.923609586263286}, {\"truth_threshold\": -11.37146372990868, \"match_probability\": 0.000377297939432205, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106699.0, \"fp\": 1020.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9905309081077576, \"fp_rate\": 0.009469081647694111, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8647394180297852, \"recall\": 0.9973998069763184, \"specificity\": 0.9905309081077576, \"npv\": 0.9998406767845154, \"accuracy\": 0.9909239411354065, \"f1\": 0.9263442005824277, \"f2\": 0.9677084260825691, \"f0_5\": 0.8883712059288322, \"p4\": 0.9595217087303998, \"phi\": 0.9241998152550842}, {\"truth_threshold\": -11.369732644466504, \"match_probability\": 0.0003777507586944914, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106703.0, \"fp\": 1016.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9905680418014526, \"fp_rate\": 0.009431947953999043, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8651983737945557, \"recall\": 0.9973998069763184, \"specificity\": 0.9905680418014526, \"npv\": 0.9998406767845154, \"accuracy\": 0.9909589886665344, \"f1\": 0.926607460035524, \"f2\": 0.9678233251209594, \"f0_5\": 0.8887586545276127, \"p4\": 0.9596716316923536, \"phi\": 0.9244623948965878}, {\"truth_threshold\": -11.369290407285485, \"match_probability\": 0.0003778665266831589, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106704.0, \"fp\": 1015.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9905773401260376, \"fp_rate\": 0.009422664530575275, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8653131723403931, \"recall\": 0.9973998069763184, \"specificity\": 0.9905773401260376, \"npv\": 0.9998406767845154, \"accuracy\": 0.9909677505493164, \"f1\": 0.9266732982805173, \"f2\": 0.9678520541439088, \"f0_5\": 0.8888555694891227, \"p4\": 0.959709119651371, \"phi\": 0.9245281567378952}, {\"truth_threshold\": -11.361649307519977, \"match_probability\": 0.00037987240855121517, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106707.0, \"fp\": 1012.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9906051754951477, \"fp_rate\": 0.009394814260303974, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8656577467918396, \"recall\": 0.9973998069763184, \"specificity\": 0.9906051754951477, \"npv\": 0.9998407363891602, \"accuracy\": 0.9909939765930176, \"f1\": 0.9268708691635278, \"f2\": 0.9679382514472317, \"f0_5\": 0.8891464412326152, \"p4\": 0.9598216008582492, \"phi\": 0.9247252637709623}, {\"truth_threshold\": -11.360161080843179, \"match_probability\": 0.0003802643228764826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106721.0, \"fp\": 998.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9907351732254028, \"fp_rate\": 0.009264846332371235, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8672695755958557, \"recall\": 0.9973998069763184, \"specificity\": 0.9907351732254028, \"npv\": 0.9998407363891602, \"accuracy\": 0.9911165237426758, \"f1\": 0.9277939816461549, \"f2\": 0.9683407086216625, \"f0_5\": 0.8905063636860218, \"p4\": 0.9603468571044633, \"phi\": 0.9256467892810543}, {\"truth_threshold\": -11.358108949814728, \"match_probability\": 0.00038080540056862705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106725.0, \"fp\": 994.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9907723069190979, \"fp_rate\": 0.009227712638676167, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8677312135696411, \"recall\": 0.9973998069763184, \"specificity\": 0.9907723069190979, \"npv\": 0.9998407363891602, \"accuracy\": 0.9911515116691589, \"f1\": 0.9280580658934036, \"f2\": 0.9684557578637836, \"f0_5\": 0.8908956773594185, \"p4\": 0.9604970344535039, \"phi\": 0.9259105804667357}, {\"truth_threshold\": -11.344296841108847, \"match_probability\": 0.0003844672639018764, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106727.0, \"fp\": 992.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.990790843963623, \"fp_rate\": 0.009209145791828632, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8679621815681458, \"recall\": 0.9973998069763184, \"specificity\": 0.990790843963623, \"npv\": 0.9998407363891602, \"accuracy\": 0.9911690354347229, \"f1\": 0.9281901644011102, \"f2\": 0.9685132927372643, \"f0_5\": 0.8910904618748292, \"p4\": 0.9605721404974228, \"phi\": 0.9260425106050395}, {\"truth_threshold\": -11.334725700164482, \"match_probability\": 0.00038702538924883937, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106731.0, \"fp\": 988.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9908279776573181, \"fp_rate\": 0.009172012098133564, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8684245347976685, \"recall\": 0.9973998069763184, \"specificity\": 0.9908279776573181, \"npv\": 0.9998407363891602, \"accuracy\": 0.991204023361206, \"f1\": 0.9284544742649676, \"f2\": 0.9686283829951576, \"f0_5\": 0.8914802865423525, \"p4\": 0.9607223873374958, \"phi\": 0.9263066104514752}, {\"truth_threshold\": -11.328849133827813, \"match_probability\": 0.0003886044708384403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106737.0, \"fp\": 982.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9908837080001831, \"fp_rate\": 0.009116311557590961, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8691190481185913, \"recall\": 0.9973998069763184, \"specificity\": 0.9908837080001831, \"npv\": 0.9998407363891602, \"accuracy\": 0.9912565350532532, \"f1\": 0.9288512214229756, \"f2\": 0.968801069677611, \"f0_5\": 0.8920656634746922, \"p4\": 0.9609478445185337, \"phi\": 0.9267031041797581}, {\"truth_threshold\": -11.317279290470367, \"match_probability\": 0.0003917322290376722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106738.0, \"fp\": 981.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9908929467201233, \"fp_rate\": 0.009107028134167194, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8692348599433899, \"recall\": 0.9973998069763184, \"specificity\": 0.9908929467201233, \"npv\": 0.9998407363891602, \"accuracy\": 0.9912652969360352, \"f1\": 0.9289173789173789, \"f2\": 0.9688298567777975, \"f0_5\": 0.892163301045258, \"p4\": 0.9609854308604645, \"phi\": 0.9267692174159204}, {\"truth_threshold\": -11.31709938609863, \"match_probability\": 0.00039178106203465986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106741.0, \"fp\": 978.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909208416938782, \"fp_rate\": 0.009079177863895893, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8695825934410095, \"recall\": 0.9973998069763184, \"specificity\": 0.9909208416938782, \"npv\": 0.9998407363891602, \"accuracy\": 0.9912915825843811, \"f1\": 0.9291159079575407, \"f2\": 0.9689162283438828, \"f0_5\": 0.8924563420375541, \"p4\": 0.9610982072845724, \"phi\": 0.9269676346012864}, {\"truth_threshold\": -11.306233126609488, \"match_probability\": 0.00039474189607827, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106742.0, \"fp\": 977.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909300804138184, \"fp_rate\": 0.009069894440472126, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8696985840797424, \"recall\": 0.9973998069763184, \"specificity\": 0.9909300804138184, \"npv\": 0.9998407363891602, \"accuracy\": 0.9913002848625183, \"f1\": 0.9291821031632944, \"f2\": 0.9689450222882615, \"f0_5\": 0.8925540651519299, \"p4\": 0.9611358052265023, \"phi\": 0.9270338847416139}, {\"truth_threshold\": -11.305160069865769, \"match_probability\": 0.00039503549286468414, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106743.0, \"fp\": 976.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909393787384033, \"fp_rate\": 0.009060611017048359, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8698145747184753, \"recall\": 0.9973998069763184, \"specificity\": 0.9909393787384033, \"npv\": 0.9998407363891602, \"accuracy\": 0.9913090467453003, \"f1\": 0.9292483078019238, \"f2\": 0.9689738179440697, \"f0_5\": 0.8926518096698243, \"p4\": 0.9611734060692737, \"phi\": 0.9271000625757245}, {\"truth_threshold\": -11.296554279298093, \"match_probability\": 0.00039739801384400947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106744.0, \"fp\": 975.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909486770629883, \"fp_rate\": 0.009051327593624592, \"fn_rate\": 0.002600183477625251, \"precision\": 0.869930624961853, \"recall\": 0.9973998069763184, \"specificity\": 0.9909486770629883, \"npv\": 0.9998407363891602, \"accuracy\": 0.9913178086280823, \"f1\": 0.9293145218754454, \"f2\": 0.9690026153114598, \"f0_5\": 0.8927495755982695, \"p4\": 0.9612110098132235, \"phi\": 0.9271662533412456}, {\"truth_threshold\": -11.291613538027821, \"match_probability\": 0.00039876075671574655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106745.0, \"fp\": 974.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909579753875732, \"fp_rate\": 0.009042044170200825, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8700466752052307, \"recall\": 0.9973998069763184, \"specificity\": 0.9909579753875732, \"npv\": 0.9998407959938049, \"accuracy\": 0.9913265705108643, \"f1\": 0.9293807453858761, \"f2\": 0.9690314143905846, \"f0_5\": 0.8928473629443014, \"p4\": 0.9612486164586885, \"phi\": 0.9272324570424735}, {\"truth_threshold\": -11.289048125769837, \"match_probability\": 0.00039947018370386963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106747.0, \"fp\": 972.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909765124320984, \"fp_rate\": 0.00902347732335329, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8702789545059204, \"recall\": 0.9973998069763184, \"specificity\": 0.9909765124320984, \"npv\": 0.9998407959938049, \"accuracy\": 0.9913440942764282, \"f1\": 0.9295132207255363, \"f2\": 0.9690890176846485, \"f0_5\": 0.8930430019172829, \"p4\": 0.961323838455512, \"phi\": 0.927364903269248}, {\"truth_threshold\": -11.286034903636132, \"match_probability\": 0.00040030505726542975, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106749.0, \"fp\": 970.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9909951090812683, \"fp_rate\": 0.009004910476505756, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8705112934112549, \"recall\": 0.9973998069763184, \"specificity\": 0.9909951090812683, \"npv\": 0.9998407959938049, \"accuracy\": 0.9913615584373474, \"f1\": 0.9296457338370518, \"f2\": 0.9691466278274827, \"f0_5\": 0.8932387266451154, \"p4\": 0.9613990720624399, \"phi\": 0.9274974865661004}, {\"truth_threshold\": -11.283994898043552, \"match_probability\": 0.0004008712715901267, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106758.0, \"fp\": 961.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9910786151885986, \"fp_rate\": 0.008921360597014427, \"fn_rate\": 0.002600183477625251, \"precision\": 0.871558427810669, \"recall\": 0.9973998069763184, \"specificity\": 0.9910786151885986, \"npv\": 0.9998407959938049, \"accuracy\": 0.9914403557777405, \"f1\": 0.9302425106990014, \"f2\": 0.9694059582565261, \"f0_5\": 0.8941205506499205, \"p4\": 0.9617377670409877, \"phi\": 0.9280944549131246}, {\"truth_threshold\": -11.258939515483553, \"match_probability\": 0.0004078911715106498, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106760.0, \"fp\": 959.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9910972118377686, \"fp_rate\": 0.008902793750166893, \"fn_rate\": 0.002600183477625251, \"precision\": 0.871791422367096, \"recall\": 0.9973998069763184, \"specificity\": 0.9910972118377686, \"npv\": 0.9998407959938049, \"accuracy\": 0.9914578795433044, \"f1\": 0.930375231844771, \"f2\": 0.9694636060894386, \"f0_5\": 0.8943167480388392, \"p4\": 0.9618130645517188, \"phi\": 0.9282272384415787}, {\"truth_threshold\": -11.258558249080895, \"match_probability\": 0.0004079989366917252, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106763.0, \"fp\": 956.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9911250472068787, \"fp_rate\": 0.008874943479895592, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8721412420272827, \"recall\": 0.9973998069763184, \"specificity\": 0.9911250472068787, \"npv\": 0.9998407959938049, \"accuracy\": 0.9914841055870056, \"f1\": 0.9305743845879415, \"f2\": 0.9695500906955307, \"f0_5\": 0.8946112056192723, \"p4\": 0.9619260326205011, \"phi\": 0.9284265966304228}, {\"truth_threshold\": -11.224499342169285, \"match_probability\": 0.00041774143185033073, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106765.0, \"fp\": 954.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9911436438560486, \"fp_rate\": 0.008856376633048058, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8723745942115784, \"recall\": 0.9973998069763184, \"specificity\": 0.9911436438560486, \"npv\": 0.9998407959938049, \"accuracy\": 0.9915016293525696, \"f1\": 0.9307072004567187, \"f2\": 0.9696077556725251, \"f0_5\": 0.8948076184203304, \"p4\": 0.9620013592054212, \"phi\": 0.9285595102818117}, {\"truth_threshold\": -11.220605426064793, \"match_probability\": 0.00041886998983006334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106768.0, \"fp\": 951.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9911714792251587, \"fp_rate\": 0.008828526362776756, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8727248311042786, \"recall\": 0.9973998069763184, \"specificity\": 0.9911714792251587, \"npv\": 0.9998407959938049, \"accuracy\": 0.9915278553962708, \"f1\": 0.9309064953604568, \"f2\": 0.9696942660004758, \"f0_5\": 0.8951023993850546, \"p4\": 0.9621143708981573, \"phi\": 0.9287590638442115}, {\"truth_threshold\": -11.219982089115453, \"match_probability\": 0.0004190509318247929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106776.0, \"fp\": 943.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9912457466125488, \"fp_rate\": 0.00875425897538662, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8736602067947388, \"recall\": 0.9973998069763184, \"specificity\": 0.9912457466125488, \"npv\": 0.9998407959938049, \"accuracy\": 0.9915978908538818, \"f1\": 0.9314383659477218, \"f2\": 0.969925035697287, \"f0_5\": 0.8958894323240094, \"p4\": 0.962415863460017, \"phi\": 0.9292916385227475}, {\"truth_threshold\": -11.21355046590491, \"match_probability\": 0.000420922468914077, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106779.0, \"fp\": 940.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9912735819816589, \"fp_rate\": 0.008726408705115318, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8740115165710449, \"recall\": 0.9973998069763184, \"specificity\": 0.9912735819816589, \"npv\": 0.9998407959938049, \"accuracy\": 0.991624116897583, \"f1\": 0.93163797414101, \"f2\": 0.9700116026537352, \"f0_5\": 0.896184926612061, \"p4\": 0.9625289712147289, \"phi\": 0.929491537616768}, {\"truth_threshold\": -11.210824405272207, \"match_probability\": 0.0004217182438757338, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106783.0, \"fp\": 936.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.991310715675354, \"fp_rate\": 0.00868927501142025, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8744803667068481, \"recall\": 0.9973998069763184, \"specificity\": 0.991310715675354, \"npv\": 0.9998407959938049, \"accuracy\": 0.9916591644287109, \"f1\": 0.9319042515183994, \"f2\": 0.9701270493022702, \"f0_5\": 0.8965792223505472, \"p4\": 0.9626798223426648, \"phi\": 0.9297583384419806}, {\"truth_threshold\": -11.205018849509292, \"match_probability\": 0.0004234179813148403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106785.0, \"fp\": 934.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9913293123245239, \"fp_rate\": 0.008670708164572716, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8747149705886841, \"recall\": 0.9973998069763184, \"specificity\": 0.9913293123245239, \"npv\": 0.9998408555984497, \"accuracy\": 0.9916766881942749, \"f1\": 0.9320374472950761, \"f2\": 0.9701847829321273, \"f0_5\": 0.8967765003575554, \"p4\": 0.9627552653934399, \"phi\": 0.9298917747488284}, {\"truth_threshold\": -11.199934711248277, \"match_probability\": 0.00042491212718378385, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106788.0, \"fp\": 931.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.991357147693634, \"fp_rate\": 0.008642857894301414, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8750671148300171, \"recall\": 0.9973998069763184, \"specificity\": 0.991357147693634, \"npv\": 0.9998408555984497, \"accuracy\": 0.9917029142379761, \"f1\": 0.9322373123659757, \"f2\": 0.9702713962623497, \"f0_5\": 0.8970725802013977, \"p4\": 0.9628684518357384, \"phi\": 0.9300921130551124}, {\"truth_threshold\": -11.198492283531527, \"match_probability\": 0.0004253369922373006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106790.0, \"fp\": 929.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9913756847381592, \"fp_rate\": 0.00862429104745388, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8753020167350769, \"recall\": 0.9973998069763184, \"specificity\": 0.9913756847381592, \"npv\": 0.9998408555984497, \"accuracy\": 0.99172043800354, \"f1\": 0.9323706033743209, \"f2\": 0.9703291470745788, \"f0_5\": 0.8972700754031592, \"p4\": 0.9629439240453178, \"phi\": 0.9302256805746244}, {\"truth_threshold\": -11.190508233771421, \"match_probability\": 0.0004276963746578266, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106791.0, \"fp\": 928.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9913849830627441, \"fp_rate\": 0.008615007624030113, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8754194974899292, \"recall\": 0.9973998069763184, \"specificity\": 0.9913849830627441, \"npv\": 0.9998408555984497, \"accuracy\": 0.991729199886322, \"f1\": 0.9324372631729463, \"f2\": 0.970358025058778, \"f0_5\": 0.8973688556173282, \"p4\": 0.9629816645255392, \"phi\": 0.9302924840355175}, {\"truth_threshold\": -11.184350021540773, \"match_probability\": 0.0004295251330601177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106792.0, \"fp\": 927.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9913942813873291, \"fp_rate\": 0.008605724200606346, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8755370378494263, \"recall\": 0.9973998069763184, \"specificity\": 0.9913942813873291, \"npv\": 0.9998408555984497, \"accuracy\": 0.9917379021644592, \"f1\": 0.9325039325039325, \"f2\": 0.9703869047619048, \"f0_5\": 0.8974676575832645, \"p4\": 0.9630194079231676, \"phi\": 0.9303593006363576}, {\"truth_threshold\": -11.180113754216674, \"match_probability\": 0.00043078768149756375, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106794.0, \"fp\": 925.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9914128184318542, \"fp_rate\": 0.008587157353758812, \"fn_rate\": 0.002600183477625251, \"precision\": 0.87577223777771, \"recall\": 0.9973998069763184, \"specificity\": 0.9914128184318542, \"npv\": 0.9998408555984497, \"accuracy\": 0.9917554259300232, \"f1\": 0.932637299771167, \"f2\": 0.9704446693255551, \"f0_5\": 0.8976653267991851, \"p4\": 0.9630949034720027, \"phi\": 0.9304930587903707}, {\"truth_threshold\": -11.169004229577581, \"match_probability\": 0.00043411633708445184, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106806.0, \"fp\": 913.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9915242195129395, \"fp_rate\": 0.008475756272673607, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8771858811378479, \"recall\": 0.9973998069763184, \"specificity\": 0.9915242195129395, \"npv\": 0.9998408555984497, \"accuracy\": 0.9918604493141174, \"f1\": 0.9334383051817922, \"f2\": 0.9707914011790627, \"f0_5\": 0.8988531730716215, \"p4\": 0.9635481220078396, \"phi\": 0.9312963719444582}, {\"truth_threshold\": -11.160952598963492, \"match_probability\": 0.0004365448379234039, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106807.0, \"fp\": 912.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9915335178375244, \"fp_rate\": 0.00846647284924984, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8773038983345032, \"recall\": 0.9973998069763184, \"specificity\": 0.9915335178375244, \"npv\": 0.9998408555984497, \"accuracy\": 0.9918692111968994, \"f1\": 0.9335051177438981, \"f2\": 0.9708203066845318, \"f0_5\": 0.8989523021781086, \"p4\": 0.9635859092073268, \"phi\": 0.9313633861890538}, {\"truth_threshold\": -11.159615808187054, \"match_probability\": 0.0004369493478419691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106809.0, \"fp\": 910.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9915521144866943, \"fp_rate\": 0.008447906002402306, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8775400519371033, \"recall\": 0.9973998069763184, \"specificity\": 0.9915521144866943, \"npv\": 0.9998408555984497, \"accuracy\": 0.9918867349624634, \"f1\": 0.9336387715656096, \"f2\": 0.9708781228597803, \"f0_5\": 0.8991506259996691, \"p4\": 0.9636614923751713, \"phi\": 0.9314974543141977}, {\"truth_threshold\": -11.156219022878043, \"match_probability\": 0.00043797889387372797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106812.0, \"fp\": 907.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9915799498558044, \"fp_rate\": 0.008420055732131004, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8778944611549377, \"recall\": 0.9973998069763184, \"specificity\": 0.9915799498558044, \"npv\": 0.9998408555984497, \"accuracy\": 0.9919129610061646, \"f1\": 0.9338393240727481, \"f2\": 0.9709648600357356, \"f0_5\": 0.899448275862069, \"p4\": 0.9637748890542177, \"phi\": 0.931698741269488}, {\"truth_threshold\": -11.126629277855779, \"match_probability\": 0.0004470505584490092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106820.0, \"fp\": 899.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9916542172431946, \"fp_rate\": 0.008345788344740868, \"fn_rate\": 0.002600183477625251, \"precision\": 0.878840982913971, \"recall\": 0.9973998069763184, \"specificity\": 0.9916542172431946, \"npv\": 0.9998408555984497, \"accuracy\": 0.9919829964637756, \"f1\": 0.9343745522281129, \"f2\": 0.9711962349577028, \"f0_5\": 0.9002429731072947, \"p4\": 0.964077408903296, \"phi\": 0.9322359464471254}, {\"truth_threshold\": -11.111288731721293, \"match_probability\": 0.0004518273653066409, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106829.0, \"fp\": 890.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9917377829551697, \"fp_rate\": 0.008262237533926964, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8799082636833191, \"recall\": 0.9973998069763184, \"specificity\": 0.9917377829551697, \"npv\": 0.9998409152030945, \"accuracy\": 0.9920617341995239, \"f1\": 0.9349774177360384, \"f2\": 0.9714566635878795, \"f0_5\": 0.9011386877452877, \"p4\": 0.9644179676784059, \"phi\": 0.932841306796082}, {\"truth_threshold\": -11.097774931610221, \"match_probability\": 0.0004560776006929229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106831.0, \"fp\": 888.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9917563199996948, \"fp_rate\": 0.00824367068707943, \"fn_rate\": 0.002600183477625251, \"precision\": 0.880145788192749, \"recall\": 0.9973998069763184, \"specificity\": 0.9917563199996948, \"npv\": 0.9998409152030945, \"accuracy\": 0.9920792579650879, \"f1\": 0.9351114935111493, \"f2\": 0.971514555585352, \"f0_5\": 0.9013379775529385, \"p4\": 0.9644936796311945, \"phi\": 0.9329759585615405}, {\"truth_threshold\": -11.09388101550573, \"match_probability\": 0.0004573096791577653, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106840.0, \"fp\": 879.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9918398857116699, \"fp_rate\": 0.008160119876265526, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8812162280082703, \"recall\": 0.9973998069763184, \"specificity\": 0.9918398857116699, \"npv\": 0.9998409152030945, \"accuracy\": 0.992158055305481, \"f1\": 0.9357153106615009, \"f2\": 0.9717751549833095, \"f0_5\": 0.902235873595661, \"p4\": 0.9648345285438468, \"phi\": 0.9335827227561764}, {\"truth_threshold\": -11.091066459379915, \"match_probability\": 0.0004582023070010932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106841.0, \"fp\": 878.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9918491840362549, \"fp_rate\": 0.008150836452841759, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8813353180885315, \"recall\": 0.9973998069763184, \"specificity\": 0.9918491840362549, \"npv\": 0.9998409152030945, \"accuracy\": 0.9921667575836182, \"f1\": 0.9357824495946043, \"f2\": 0.9718041191022623, \"f0_5\": 0.9023357502629102, \"p4\": 0.964872415311188, \"phi\": 0.9336501886813775}, {\"truth_threshold\": -11.086826055345847, \"match_probability\": 0.0004595504276047541, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106845.0, \"fp\": 874.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.99188631772995, \"fp_rate\": 0.008113703690469265, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8818120360374451, \"recall\": 0.9973998069763184, \"specificity\": 0.99188631772995, \"npv\": 0.9998409152030945, \"accuracy\": 0.9922018051147461, \"f1\": 0.9360511017009976, \"f2\": 0.9719199928458581, \"f0_5\": 0.9027354781549366, \"p4\": 0.9650239917283782, \"phi\": 0.9339202718382366}, {\"truth_threshold\": -11.077241250893616, \"match_probability\": 0.0004626122809942483, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106847.0, \"fp\": 872.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9919048547744751, \"fp_rate\": 0.00809513684362173, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8820505738258362, \"recall\": 0.9973998069763184, \"specificity\": 0.9919048547744751, \"npv\": 0.9998409152030945, \"accuracy\": 0.9922192692756653, \"f1\": 0.9361854856076376, \"f2\": 0.9719779400804889, \"f0_5\": 0.9029354749376904, \"p4\": 0.9650997975504585, \"phi\": 0.9340553507964512}, {\"truth_threshold\": -11.049705301205236, \"match_probability\": 0.00047152251307222993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106853.0, \"fp\": 866.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9919605851173401, \"fp_rate\": 0.008039436303079128, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8827670216560364, \"recall\": 0.9973998069763184, \"specificity\": 0.9919605851173401, \"npv\": 0.9998409152030945, \"accuracy\": 0.9922717809677124, \"f1\": 0.936588868940754, \"f2\": 0.9721518232505442, \"f0_5\": 0.9035359973396885, \"p4\": 0.9653272855035001, \"phi\": 0.9344609949896319}, {\"truth_threshold\": -11.03942651443102, \"match_probability\": 0.0004748923702064474, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106861.0, \"fp\": 858.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9920348525047302, \"fp_rate\": 0.007965168915688992, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8837240934371948, \"recall\": 0.9973998069763184, \"specificity\": 0.9920348525047302, \"npv\": 0.9998409152030945, \"accuracy\": 0.9923418164253235, \"f1\": 0.9371272544370195, \"f2\": 0.9723837642778325, \"f0_5\": 0.9043379375381373, \"p4\": 0.9656307673457329, \"phi\": 0.9350025768750391}, {\"truth_threshold\": -10.999904867296717, \"match_probability\": 0.00048807511515568943, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106863.0, \"fp\": 856.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9920533895492554, \"fp_rate\": 0.007946602068841457, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8839636445045471, \"recall\": 0.9973998069763184, \"specificity\": 0.9920533895492554, \"npv\": 0.9998409152030945, \"accuracy\": 0.9923593401908875, \"f1\": 0.9372619475386273, \"f2\": 0.9724417668287154, \"f0_5\": 0.9045386450646397, \"p4\": 0.9657066672123432, \"phi\": 0.9351380853237954}, {\"truth_threshold\": -10.997073252984102, \"match_probability\": 0.0004890335444047438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106864.0, \"fp\": 855.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9920626878738403, \"fp_rate\": 0.00793731864541769, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8840835094451904, \"recall\": 0.9973998069763184, \"specificity\": 0.9920626878738403, \"npv\": 0.9998409152030945, \"accuracy\": 0.9923681020736694, \"f1\": 0.937329308610033, \"f2\": 0.9724707706991171, \"f0_5\": 0.9046390322401643, \"p4\": 0.9657446215584428, \"phi\": 0.9352059456300422}, {\"truth_threshold\": -10.99348383378085, \"match_probability\": 0.0004902511754167046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106865.0, \"fp\": 854.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9920719861984253, \"fp_rate\": 0.007928035221993923, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8842033743858337, \"recall\": 0.9973998069763184, \"specificity\": 0.9920719861984253, \"npv\": 0.9998409748077393, \"accuracy\": 0.9923768639564514, \"f1\": 0.937396679364623, \"f2\": 0.9724997762996987, \"f0_5\": 0.9047394417004273, \"p4\": 0.9657825788468628, \"phi\": 0.9352737335163638}, {\"truth_threshold\": -10.97711027008283, \"match_probability\": 0.0004958440968716676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106869.0, \"fp\": 850.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9921091198921204, \"fp_rate\": 0.007890901528298855, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8846831917762756, \"recall\": 0.9973998069763184, \"specificity\": 0.9921091198921204, \"npv\": 0.9998409748077393, \"accuracy\": 0.9924118518829346, \"f1\": 0.9376662592565964, \"f2\": 0.9726158160069206, \"f0_5\": 0.9051413025373383, \"p4\": 0.9659344374306142, \"phi\": 0.9355450198151102}, {\"truth_threshold\": -10.966253549312205, \"match_probability\": 0.0004995876791101484, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106870.0, \"fp\": 849.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9921183586120605, \"fp_rate\": 0.007881618104875088, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8848032355308533, \"recall\": 0.9973998069763184, \"specificity\": 0.9921183586120605, \"npv\": 0.9998409748077393, \"accuracy\": 0.9924206137657166, \"f1\": 0.9377336784584411, \"f2\": 0.9726448302607243, \"f0_5\": 0.9052418235326781, \"p4\": 0.9659724094357867, \"phi\": 0.9356129610250654}, {\"truth_threshold\": -10.956010506243382, \"match_probability\": 0.0005031455505768861, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106876.0, \"fp\": 843.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9921740889549255, \"fp_rate\": 0.007825917564332485, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8855241537094116, \"recall\": 0.9973998069763184, \"specificity\": 0.9921740889549255, \"npv\": 0.9998409748077393, \"accuracy\": 0.9924731254577637, \"f1\": 0.9381383973528988, \"f2\": 0.9728189521422604, \"f0_5\": 0.9058454186808913, \"p4\": 0.9662003033108452, \"phi\": 0.936020462253934}, {\"truth_threshold\": -10.945019571112297, \"match_probability\": 0.0005069913696912585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106888.0, \"fp\": 831.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9922854900360107, \"fp_rate\": 0.00771451648324728, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8869695067405701, \"recall\": 0.9973998069763184, \"specificity\": 0.9922854900360107, \"npv\": 0.9998409748077393, \"accuracy\": 0.9925781488418579, \"f1\": 0.9389488840892729, \"f2\": 0.9731673829990449, \"f0_5\": 0.9070550269849218, \"p4\": 0.9666564093511325, \"phi\": 0.936836840140022}, {\"truth_threshold\": -10.939679052411861, \"match_probability\": 0.0005088706540014114, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106889.0, \"fp\": 830.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9922947883605957, \"fp_rate\": 0.007705233059823513, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8870902061462402, \"recall\": 0.9973998069763184, \"specificity\": 0.9922947883605957, \"npv\": 0.9998409748077393, \"accuracy\": 0.9925869107246399, \"f1\": 0.9390164878680971, \"f2\": 0.9731964301704324, \"f0_5\": 0.9071559735128819, \"p4\": 0.966694437358342, \"phi\": 0.9369050386295009}, {\"truth_threshold\": -10.939105654712879, \"match_probability\": 0.0005090728413500228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106890.0, \"fp\": 829.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9923040270805359, \"fp_rate\": 0.007695949636399746, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8872109055519104, \"recall\": 0.9973998069763184, \"specificity\": 0.9923040270805359, \"npv\": 0.9998409748077393, \"accuracy\": 0.9925956130027771, \"f1\": 0.9390841013824884, \"f2\": 0.9732254790758761, \"f0_5\": 0.9072569425121042, \"p4\": 0.9667324683164693, \"phi\": 0.9369731646775727}, {\"truth_threshold\": -10.931193144362549, \"match_probability\": 0.0005118711061964795, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106892.0, \"fp\": 827.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9923226237297058, \"fp_rate\": 0.007677382789552212, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8874523639678955, \"recall\": 0.9973998069763184, \"specificity\": 0.9923226237297058, \"npv\": 0.9998409748077393, \"accuracy\": 0.9926131367683411, \"f1\": 0.9392193576263863, \"f2\": 0.9732835820895522, \"f0_5\": 0.9074589479543557, \"p4\": 0.9668085390868554, \"phi\": 0.9371094575339459}, {\"truth_threshold\": -10.919688200885638, \"match_probability\": 0.0005159672881849361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106893.0, \"fp\": 826.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9923319220542908, \"fp_rate\": 0.007668099366128445, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8875731825828552, \"recall\": 0.9973998069763184, \"specificity\": 0.9923319220542908, \"npv\": 0.9998409748077393, \"accuracy\": 0.992621898651123, \"f1\": 0.9392870003601008, \"f2\": 0.9733126361980955, \"f0_5\": 0.9075599844124033, \"p4\": 0.9668465788998035, \"phi\": 0.937177624351459}, {\"truth_threshold\": -10.910634945660588, \"match_probability\": 0.0005192135998085673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106899.0, \"fp\": 820.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.992387592792511, \"fp_rate\": 0.007612398825585842, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8882985711097717, \"recall\": 0.9973998069763184, \"specificity\": 0.992387592792511, \"npv\": 0.9998409748077393, \"accuracy\": 0.9926744103431702, \"f1\": 0.9396930614597594, \"f2\": 0.9734869972830144, \"f0_5\": 0.9081666759512005, \"p4\": 0.9670748797877862, \"phi\": 0.937586997079624}, {\"truth_threshold\": -10.902241791191523, \"match_probability\": 0.0005222414457816789, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106900.0, \"fp\": 819.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.992396891117096, \"fp_rate\": 0.007603115402162075, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8884196281433105, \"recall\": 0.9973998069763184, \"specificity\": 0.992396891117096, \"npv\": 0.9998409748077393, \"accuracy\": 0.9926831722259521, \"f1\": 0.9397607724455973, \"f2\": 0.9735160635375613, \"f0_5\": 0.9082678700763274, \"p4\": 0.9671129402740516, \"phi\": 0.9376552591927134}, {\"truth_threshold\": -10.897189414595637, \"match_probability\": 0.0005240726025631181, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106902.0, \"fp\": 817.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9924154281616211, \"fp_rate\": 0.007584548555314541, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8886617422103882, \"recall\": 0.9973998069763184, \"specificity\": 0.9924154281616211, \"npv\": 0.9998409748077393, \"accuracy\": 0.9927006363868713, \"f1\": 0.9398962236955896, \"f2\": 0.9735742012541057, \"f0_5\": 0.9084703259960992, \"p4\": 0.9671890701110609, \"phi\": 0.9377919104159802}, {\"truth_threshold\": -10.895810167980981, \"match_probability\": 0.000524573603546855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106908.0, \"fp\": 811.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9924711585044861, \"fp_rate\": 0.007528848014771938, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8893889784812927, \"recall\": 0.9973998069763184, \"specificity\": 0.9924711585044861, \"npv\": 0.999841034412384, \"accuracy\": 0.9927532076835632, \"f1\": 0.9403028118240807, \"f2\": 0.9737486560745431, \"f0_5\": 0.9090782356549378, \"p4\": 0.9674175305627758, \"phi\": 0.9382020194775235}, {\"truth_threshold\": -10.888896310384846, \"match_probability\": 0.0005270922337418735, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106914.0, \"fp\": 805.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9925268292427063, \"fp_rate\": 0.007473147939890623, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8901174068450928, \"recall\": 0.9973998069763184, \"specificity\": 0.9925268292427063, \"npv\": 0.999841034412384, \"accuracy\": 0.9928057193756104, \"f1\": 0.9407097518753607, \"f2\": 0.9739231734273254, \"f0_5\": 0.9096869594330673, \"p4\": 0.96764609748356, \"phi\": 0.9386125345044564}, {\"truth_threshold\": -10.877485692105951, \"match_probability\": 0.000531275437946217, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106916.0, \"fp\": 803.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9925454258918762, \"fp_rate\": 0.007454581093043089, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8903604745864868, \"recall\": 0.9973998069763184, \"specificity\": 0.9925454258918762, \"npv\": 0.999841034412384, \"accuracy\": 0.9928231835365295, \"f1\": 0.9408454768431683, \"f2\": 0.973981359780141, \"f0_5\": 0.9098900485572361, \"p4\": 0.9677223101298535, \"phi\": 0.9387495685427912}, {\"truth_threshold\": -10.870912234248278, \"match_probability\": 0.0005337003557197706, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106917.0, \"fp\": 802.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9925547242164612, \"fp_rate\": 0.007445297669619322, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8904820680618286, \"recall\": 0.9973998069763184, \"specificity\": 0.9925547242164612, \"npv\": 0.999841034412384, \"accuracy\": 0.9928319454193115, \"f1\": 0.9409133540148619, \"f2\": 0.9740104555638536, \"f0_5\": 0.9099916271281049, \"p4\": 0.9677604208931878, \"phi\": 0.9388180630360798}, {\"truth_threshold\": -10.863939828240254, \"match_probability\": 0.0005362845343346591, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106920.0, \"fp\": 799.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9925825595855713, \"fp_rate\": 0.0074174473993480206, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8908469676971436, \"recall\": 0.9973998069763184, \"specificity\": 0.9925825595855713, \"npv\": 0.999841034412384, \"accuracy\": 0.9928582310676575, \"f1\": 0.9411170443065378, \"f2\": 0.9740977533460803, \"f0_5\": 0.9102964989669998, \"p4\": 0.9678747709480932, \"phi\": 0.9390236287964747}, {\"truth_threshold\": -10.85505313184511, \"match_probability\": 0.0005395963407088696, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6521.0, \"tn\": 106927.0, \"fp\": 792.0, \"fn\": 17.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9973998069763184, \"tn_rate\": 0.9926475286483765, \"fp_rate\": 0.007352463435381651, \"fn_rate\": 0.002600183477625251, \"precision\": 0.8916997313499451, \"recall\": 0.9973998069763184, \"specificity\": 0.9926475286483765, \"npv\": 0.999841034412384, \"accuracy\": 0.9929194450378418, \"f1\": 0.9415926647895458, \"f2\": 0.9743015090392948, \"f0_5\": 0.9110086616373289, \"p4\": 0.968141691415903, \"phi\": 0.9395038490418026}, {\"truth_threshold\": -10.848254325887499, \"match_probability\": 0.0005421438472827424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106927.0, \"fp\": 792.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9926475286483765, \"fp_rate\": 0.007352463435381651, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.891684889793396, \"recall\": 0.9972468614578247, \"specificity\": 0.9926475286483765, \"npv\": 0.9998316764831543, \"accuracy\": 0.9929107427597046, \"f1\": 0.9415162454873646, \"f2\": 0.9741812096581401, \"f0_5\": 0.9109707706924496, \"p4\": 0.9680991038292734, \"phi\": 0.9394185546946365}, {\"truth_threshold\": -10.84783679185638, \"match_probability\": 0.0005423006881147387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106929.0, \"fp\": 790.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9926661252975464, \"fp_rate\": 0.007333896588534117, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8919288516044617, \"recall\": 0.9972468614578247, \"specificity\": 0.9926661252975464, \"npv\": 0.9998316764831543, \"accuracy\": 0.9929282069206238, \"f1\": 0.9416522241478914, \"f2\": 0.9742394357778973, \"f0_5\": 0.9111744647548773, \"p4\": 0.9681753978438069, \"phi\": 0.939555953756854}, {\"truth_threshold\": -10.81847594952734, \"match_probability\": 0.0005534441580325781, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106935.0, \"fp\": 784.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9927217960357666, \"fp_rate\": 0.007278196047991514, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8926615715026855, \"recall\": 0.9972468614578247, \"specificity\": 0.9927217960357666, \"npv\": 0.9998316764831543, \"accuracy\": 0.9929807186126709, \"f1\": 0.9420603958965468, \"f2\": 0.9744141559062649, \"f0_5\": 0.9117860938636236, \"p4\": 0.9684043510638246, \"phi\": 0.939968309113269}, {\"truth_threshold\": -10.817647979764356, \"match_probability\": 0.0005537616975723664, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106936.0, \"fp\": 783.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9927310943603516, \"fp_rate\": 0.007268912624567747, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8927837610244751, \"recall\": 0.9972468614578247, \"specificity\": 0.9927310943603516, \"npv\": 0.9998316764831543, \"accuracy\": 0.9929894804954529, \"f1\": 0.9421284589263782, \"f2\": 0.9744432820206247, \"f0_5\": 0.9118881118881119, \"p4\": 0.9684425203173648, \"phi\": 0.9400370688936174}, {\"truth_threshold\": -10.817049838243978, \"match_probability\": 0.0005539912076157257, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106937.0, \"fp\": 782.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9927403926849365, \"fp_rate\": 0.00725962920114398, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8929060697555542, \"recall\": 0.9972468614578247, \"specificity\": 0.9927403926849365, \"npv\": 0.9998316764831543, \"accuracy\": 0.9929982423782349, \"f1\": 0.9421965317919075, \"f2\": 0.974472409876248, \"f0_5\": 0.911990152744363, \"p4\": 0.9684806925385554, \"phi\": 0.9401058424759134}, {\"truth_threshold\": -10.804428175041707, \"match_probability\": 0.000558856436527711, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106938.0, \"fp\": 781.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9927496314048767, \"fp_rate\": 0.007250345777720213, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8930283784866333, \"recall\": 0.9972468614578247, \"specificity\": 0.9927496314048767, \"npv\": 0.9998317360877991, \"accuracy\": 0.9930070042610168, \"f1\": 0.942264614495267, \"f2\": 0.9745015394732909, \"f0_5\": 0.9120922164400426, \"p4\": 0.9685188677277436, \"phi\": 0.9401746298648653}, {\"truth_threshold\": -10.79554445616894, \"match_probability\": 0.0005623063965997675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106939.0, \"fp\": 780.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9927589297294617, \"fp_rate\": 0.007241062354296446, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8931506872177124, \"recall\": 0.9972468614578247, \"specificity\": 0.9927589297294617, \"npv\": 0.9998317360877991, \"accuracy\": 0.9930157661437988, \"f1\": 0.9423327070385894, \"f2\": 0.9745306708119096, \"f0_5\": 0.9121943029828194, \"p4\": 0.9685570458852768, \"phi\": 0.9402434310651838}, {\"truth_threshold\": -10.78658466939985, \"match_probability\": 0.0005658074573182705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106943.0, \"fp\": 776.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9927960634231567, \"fp_rate\": 0.0072039286606013775, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8936403393745422, \"recall\": 0.9972468614578247, \"specificity\": 0.9927960634231567, \"npv\": 0.9998317360877991, \"accuracy\": 0.993050754070282, \"f1\": 0.9426051756541853, \"f2\": 0.9746472135852667, \"f0_5\": 0.9126028777783999, \"p4\": 0.968709788205806, \"phi\": 0.9405188604033158}, {\"truth_threshold\": -10.771589561896503, \"match_probability\": 0.0005717156451161701, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106945.0, \"fp\": 774.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9928146600723267, \"fp_rate\": 0.007185361813753843, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8938853740692139, \"recall\": 0.9972468614578247, \"specificity\": 0.9928146600723267, \"npv\": 0.9998317360877991, \"accuracy\": 0.993068277835846, \"f1\": 0.9427414690572585, \"f2\": 0.9747054954254619, \"f0_5\": 0.9128073024584197, \"p4\": 0.968786177185173, \"phi\": 0.9406566149097985}, {\"truth_threshold\": -10.77099725791327, \"match_probability\": 0.0005719502790808233, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106948.0, \"fp\": 771.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9928424954414368, \"fp_rate\": 0.007157511543482542, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8942531943321228, \"recall\": 0.9972468614578247, \"specificity\": 0.9928424954414368, \"npv\": 0.9998317360877991, \"accuracy\": 0.9930945038795471, \"f1\": 0.9429459830790368, \"f2\": 0.9747929312561672, \"f0_5\": 0.9131141112542714, \"p4\": 0.9689007829359224, \"phi\": 0.9408634368708679}, {\"truth_threshold\": -10.769421725213794, \"match_probability\": 0.0005725748756351197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106952.0, \"fp\": 767.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9928796291351318, \"fp_rate\": 0.007120377849787474, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8947440385818481, \"recall\": 0.9972468614578247, \"specificity\": 0.9928796291351318, \"npv\": 0.9998317360877991, \"accuracy\": 0.993129551410675, \"f1\": 0.9432188065099457, \"f2\": 0.974909536768444, \"f0_5\": 0.9135235106204114, \"p4\": 0.9690536322106996, \"phi\": 0.9411392784082321}, {\"truth_threshold\": -10.767250626172165, \"match_probability\": 0.0005734366927137228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106953.0, \"fp\": 766.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9928889274597168, \"fp_rate\": 0.007111094426363707, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8948668837547302, \"recall\": 0.9972468614578247, \"specificity\": 0.9928889274597168, \"npv\": 0.9998317360877991, \"accuracy\": 0.9931382536888123, \"f1\": 0.9432870370370371, \"f2\": 0.9749386925055327, \"f0_5\": 0.913625917829718, \"p4\": 0.9690918519615546, \"phi\": 0.9412082734746066}, {\"truth_threshold\": -10.750791778855902, \"match_probability\": 0.000580012332971333, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106955.0, \"fp\": 764.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9929074645042419, \"fp_rate\": 0.007092527579516172, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8951125741004944, \"recall\": 0.9972468614578247, \"specificity\": 0.9929074645042419, \"npv\": 0.9998317360877991, \"accuracy\": 0.9931557774543762, \"f1\": 0.9434235277094487, \"f2\": 0.9749970092116282, \"f0_5\": 0.9138308011436901, \"p4\": 0.9691683003842938, \"phi\": 0.9413463916541378}, {\"truth_threshold\": -10.739149933240853, \"match_probability\": 0.0005847089372078522, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106956.0, \"fp\": 763.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9929167628288269, \"fp_rate\": 0.007083244156092405, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8952354788780212, \"recall\": 0.9972468614578247, \"specificity\": 0.9929167628288269, \"npv\": 0.9998317360877991, \"accuracy\": 0.9931645393371582, \"f1\": 0.9434917878590551, \"f2\": 0.9750261701809481, \"f0_5\": 0.9139332772638071, \"p4\": 0.9692065290568742, \"phi\": 0.9414154283871797}, {\"truth_threshold\": -10.721112381297317, \"match_probability\": 0.0005920609005619755, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106958.0, \"fp\": 761.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.992935299873352, \"fp_rate\": 0.007064677309244871, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8954814076423645, \"recall\": 0.9972468614578247, \"specificity\": 0.992935299873352, \"npv\": 0.9998317360877991, \"accuracy\": 0.9931820631027222, \"f1\": 0.9436283377957884, \"f2\": 0.9750844973529148, \"f0_5\": 0.9141382984689586, \"p4\": 0.9692829953261982, \"phi\": 0.94155354354766}, {\"truth_threshold\": -10.711591778576935, \"match_probability\": 0.0005959786004099667, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106963.0, \"fp\": 756.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9929817318916321, \"fp_rate\": 0.007018260657787323, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8960967659950256, \"recall\": 0.9972468614578247, \"specificity\": 0.9929817318916321, \"npv\": 0.9998317360877991, \"accuracy\": 0.9932258129119873, \"f1\": 0.9439698856232808, \"f2\": 0.9752303458178773, \"f0_5\": 0.9146512541383761, \"p4\": 0.9694742130733829, \"phi\": 0.9418991613275604}, {\"truth_threshold\": -10.705094150109597, \"match_probability\": 0.0005986672195360069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106975.0, \"fp\": 744.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9930931329727173, \"fp_rate\": 0.006906859576702118, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8975771069526672, \"recall\": 0.9972468614578247, \"specificity\": 0.9930931329727173, \"npv\": 0.9998317360877991, \"accuracy\": 0.9933308362960815, \"f1\": 0.9447906100565135, \"f2\": 0.9755805602106775, \"f0_5\": 0.9158846996684834, \"p4\": 0.9699334394081495, \"phi\": 0.9427300316070034}, {\"truth_threshold\": -10.696959741425248, \"match_probability\": 0.0006020502063722532, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106977.0, \"fp\": 742.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9931117296218872, \"fp_rate\": 0.006888292729854584, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8978242874145508, \"recall\": 0.9972468614578247, \"specificity\": 0.9931117296218872, \"npv\": 0.9998317956924438, \"accuracy\": 0.9933483004570007, \"f1\": 0.9449275362318841, \"f2\": 0.9756389537319686, \"f0_5\": 0.916090597425954, \"p4\": 0.9700100188515621, \"phi\": 0.9428686767719671}, {\"truth_threshold\": -10.678843516226886, \"match_probability\": 0.0006096533054245201, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106987.0, \"fp\": 732.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9932045340538025, \"fp_rate\": 0.006795458495616913, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8990623354911804, \"recall\": 0.9972468614578247, \"specificity\": 0.9932045340538025, \"npv\": 0.9998317956924438, \"accuracy\": 0.9934358596801758, \"f1\": 0.9456127628716461, \"f2\": 0.9759310262244043, \"f0_5\": 0.9171214763967817, \"p4\": 0.9703930950403794, \"phi\": 0.9435629163226023}, {\"truth_threshold\": -10.676071248879085, \"match_probability\": 0.0006108252187140957, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106988.0, \"fp\": 731.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9932138323783875, \"fp_rate\": 0.006786175072193146, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8991863131523132, \"recall\": 0.9972468614578247, \"specificity\": 0.9932138323783875, \"npv\": 0.9998317956924438, \"accuracy\": 0.9934446215629578, \"f1\": 0.9456813401987091, \"f2\": 0.9759602430919379, \"f0_5\": 0.9172246919137921, \"p4\": 0.9704314190733391, \"phi\": 0.9436324001421806}, {\"truth_threshold\": -10.639536841448129, \"match_probability\": 0.0006264812941790671, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106989.0, \"fp\": 730.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9932231307029724, \"fp_rate\": 0.006776891648769379, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.8993103504180908, \"recall\": 0.9972468614578247, \"specificity\": 0.9932231307029724, \"npv\": 0.9998317956924438, \"accuracy\": 0.9934533834457397, \"f1\": 0.9457499274731651, \"f2\": 0.9759894617088797, \"f0_5\": 0.9173279306657662, \"p4\": 0.9704697460920758, \"phi\": 0.9437018980115687}, {\"truth_threshold\": -10.630286012308847, \"match_probability\": 0.0006305087746997045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 106994.0, \"fp\": 725.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9932695031166077, \"fp_rate\": 0.006730474531650543, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.899931013584137, \"recall\": 0.9972468614578247, \"specificity\": 0.9932695031166077, \"npv\": 0.9998317956924438, \"accuracy\": 0.9934971332550049, \"f1\": 0.9460930131321192, \"f2\": 0.9761355810402131, \"f0_5\": 0.9178444732248437, \"p4\": 0.9706614259846714, \"phi\": 0.9440496848862661}, {\"truth_threshold\": -10.621128328465602, \"match_probability\": 0.0006345211882037424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107002.0, \"fp\": 717.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9933437705039978, \"fp_rate\": 0.0066562071442604065, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9009258151054382, \"recall\": 0.9972468614578247, \"specificity\": 0.9933437705039978, \"npv\": 0.9998317956924438, \"accuracy\": 0.9935671091079712, \"f1\": 0.9466424682395644, \"f2\": 0.9763694629967954, \"f0_5\": 0.9186721523981288, \"p4\": 0.9709682692007225, \"phi\": 0.9446068243583133}, {\"truth_threshold\": -10.59558149921346, \"match_probability\": 0.0006458498567541712, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107003.0, \"fp\": 716.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9933530688285828, \"fp_rate\": 0.006646923720836639, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.901050329208374, \"recall\": 0.9972468614578247, \"specificity\": 0.9933530688285828, \"npv\": 0.9998317956924438, \"accuracy\": 0.9935758709907532, \"f1\": 0.946711195005082, \"f2\": 0.97639870612196, \"f0_5\": 0.9187757172650921, \"p4\": 0.9710066380571191, \"phi\": 0.9446765194441374}, {\"truth_threshold\": -10.584041728856425, \"match_probability\": 0.0006510331935540247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107009.0, \"fp\": 710.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9934087991714478, \"fp_rate\": 0.006591223645955324, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9017980694770813, \"recall\": 0.9972468614578247, \"specificity\": 0.9934087991714478, \"npv\": 0.9998317956924438, \"accuracy\": 0.9936283826828003, \"f1\": 0.94712376525276, \"f2\": 0.9765742016655683, \"f0_5\": 0.9193975971572, \"p4\": 0.9712369140194838, \"phi\": 0.9450950733964683}, {\"truth_threshold\": -10.571256522156887, \"match_probability\": 0.0006568245031759069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107010.0, \"fp\": 709.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9934180378913879, \"fp_rate\": 0.006581940222531557, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9019228219985962, \"recall\": 0.9972468614578247, \"specificity\": 0.9934180378913879, \"npv\": 0.9998317956924438, \"accuracy\": 0.9936371445655823, \"f1\": 0.9471925619234401, \"f2\": 0.9766034570564094, \"f0_5\": 0.9195013256614204, \"p4\": 0.9712753038204848, \"phi\": 0.945164867447351}, {\"truth_threshold\": -10.570235330866186, \"match_probability\": 0.0006572892860016295, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107017.0, \"fp\": 702.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9934830665588379, \"fp_rate\": 0.0065169562585651875, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9027969837188721, \"recall\": 0.9972468614578247, \"specificity\": 0.9934830665588379, \"npv\": 0.9998318552970886, \"accuracy\": 0.9936984181404114, \"f1\": 0.9476744186046512, \"f2\": 0.9768082938814646, \"f0_5\": 0.9202280810704002, \"p4\": 0.971544116264903, \"phi\": 0.9456539092005216}, {\"truth_threshold\": -10.569827869636724, \"match_probability\": 0.0006574748287581495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107021.0, \"fp\": 698.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.993520200252533, \"fp_rate\": 0.006479822564870119, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9032973051071167, \"recall\": 0.9972468614578247, \"specificity\": 0.993520200252533, \"npv\": 0.9998318552970886, \"accuracy\": 0.9937334060668945, \"f1\": 0.9479499854608898, \"f2\": 0.9769253820797124, \"f0_5\": 0.9206438859079357, \"p4\": 0.9716977892791783, \"phi\": 0.945933710939178}, {\"truth_threshold\": -10.565740912113482, \"match_probability\": 0.0006593387757939204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107027.0, \"fp\": 692.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9935758709907532, \"fp_rate\": 0.0064241220243275166, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9040488004684448, \"recall\": 0.9972468614578247, \"specificity\": 0.9935758709907532, \"npv\": 0.9998318552970886, \"accuracy\": 0.9937859177589417, \"f1\": 0.9483636363636364, \"f2\": 0.9771010670183431, \"f0_5\": 0.921268298197027, \"p4\": 0.971928388728351, \"phi\": 0.9463537966421005}, {\"truth_threshold\": -10.55555759721859, \"match_probability\": 0.0006640061048992262, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107033.0, \"fp\": 686.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9936316013336182, \"fp_rate\": 0.006368421483784914, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9048015475273132, \"recall\": 0.9972468614578247, \"specificity\": 0.9936316013336182, \"npv\": 0.9998318552970886, \"accuracy\": 0.9938384294509888, \"f1\": 0.9487776484284052, \"f2\": 0.977276815156784, \"f0_5\": 0.921893558056671, \"p4\": 0.9721590961584212, \"phi\": 0.9467743950462169}, {\"truth_threshold\": -10.55124155516426, \"match_probability\": 0.000665994229769297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107035.0, \"fp\": 684.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9936501383781433, \"fp_rate\": 0.00634985463693738, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9050527215003967, \"recall\": 0.9972468614578247, \"specificity\": 0.9936501383781433, \"npv\": 0.9998318552970886, \"accuracy\": 0.9938559532165527, \"f1\": 0.9489157327899869, \"f2\": 0.9773354119198945, \"f0_5\": 0.9221021666572382, \"p4\": 0.9722360226440173, \"phi\": 0.9469146796846429}, {\"truth_threshold\": -10.532621637531616, \"match_probability\": 0.0006746396514911519, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107039.0, \"fp\": 680.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9936872720718384, \"fp_rate\": 0.0063127209432423115, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9055555462837219, \"recall\": 0.9972468614578247, \"specificity\": 0.9936872720718384, \"npv\": 0.9998318552970886, \"accuracy\": 0.9938909411430359, \"f1\": 0.9491920221284029, \"f2\": 0.9774526265291437, \"f0_5\": 0.9225196672137642, \"p4\": 0.9723899116454888, \"phi\": 0.9471955072154962}, {\"truth_threshold\": -10.522501487057498, \"match_probability\": 0.000679385493379, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107045.0, \"fp\": 674.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9937430024147034, \"fp_rate\": 0.006257020402699709, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9063107967376709, \"recall\": 0.9972468614578247, \"specificity\": 0.9937430024147034, \"npv\": 0.9998318552970886, \"accuracy\": 0.993943452835083, \"f1\": 0.9496067579376638, \"f2\": 0.9776285011695556, \"f0_5\": 0.9231466273998981, \"p4\": 0.972620835265725, \"phi\": 0.9476171342170072}, {\"truth_threshold\": -10.511121977234973, \"match_probability\": 0.0006847617712627041, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107048.0, \"fp\": 671.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9937708377838135, \"fp_rate\": 0.006229170132428408, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.906688928604126, \"recall\": 0.9972468614578247, \"specificity\": 0.9937708377838135, \"npv\": 0.9998318552970886, \"accuracy\": 0.993969738483429, \"f1\": 0.9498142617816301, \"f2\": 0.9777164622259544, \"f0_5\": 0.9234604271712651, \"p4\": 0.9727363376496042, \"phi\": 0.9478280976570401}, {\"truth_threshold\": -10.50720660832951, \"match_probability\": 0.000686621410974948, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107049.0, \"fp\": 670.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9937801361083984, \"fp_rate\": 0.006219886709004641, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9068149924278259, \"recall\": 0.9972468614578247, \"specificity\": 0.9937801361083984, \"npv\": 0.9998318552970886, \"accuracy\": 0.9939785003662109, \"f1\": 0.9498834498834499, \"f2\": 0.9777457860956151, \"f0_5\": 0.9235650745084707, \"p4\": 0.9727748444575126, \"phi\": 0.9478984474843595}, {\"truth_threshold\": -10.493265059254524, \"match_probability\": 0.0006932841490856066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107050.0, \"fp\": 669.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9937893748283386, \"fp_rate\": 0.0062106032855808735, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9069411754608154, \"recall\": 0.9972468614578247, \"specificity\": 0.9937893748283386, \"npv\": 0.9998318552970886, \"accuracy\": 0.9939872622489929, \"f1\": 0.9499526480658557, \"f2\": 0.9777751117243034, \"f0_5\": 0.9236697455658186, \"p4\": 0.9728133542726509, \"phi\": 0.9479688985857952}, {\"truth_threshold\": -10.490746837446155, \"match_probability\": 0.0006944944910130277, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107051.0, \"fp\": 668.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9937986731529236, \"fp_rate\": 0.006201320327818394, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9070673584938049, \"recall\": 0.9972468614578247, \"specificity\": 0.9937986731529236, \"npv\": 0.9998318552970886, \"accuracy\": 0.9939959645271301, \"f1\": 0.9500218563310505, \"f2\": 0.9778044391121775, \"f0_5\": 0.9237744403513743, \"p4\": 0.9728518670953723, \"phi\": 0.9480392771209301}, {\"truth_threshold\": -10.472279202186801, \"match_probability\": 0.0007034354184510841, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107054.0, \"fp\": 665.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9938265085220337, \"fp_rate\": 0.0061734700575470924, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9074460864067078, \"recall\": 0.9972468614578247, \"specificity\": 0.9938265085220337, \"npv\": 0.9998319149017334, \"accuracy\": 0.9940222501754761, \"f1\": 0.9502295416454128, \"f2\": 0.9778924318324984, \"f0_5\": 0.9240886671580022, \"p4\": 0.9729674236125707, \"phi\": 0.9482504988975388}, {\"truth_threshold\": -10.469390150597937, \"match_probability\": 0.0007048444920885992, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107066.0, \"fp\": 653.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9939379096031189, \"fp_rate\": 0.006062068976461887, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9089641571044922, \"recall\": 0.9972468614578247, \"specificity\": 0.9939379096031189, \"npv\": 0.9998319149017334, \"accuracy\": 0.9941272735595703, \"f1\": 0.9510611917438553, \"f2\": 0.978244561140285, \"f0_5\": 0.9253477150156117, \"p4\": 0.9734299205866551, \"phi\": 0.9490968549971033}, {\"truth_threshold\": -10.46071343504908, \"match_probability\": 0.0007090933547885017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107068.0, \"fp\": 651.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9939565062522888, \"fp_rate\": 0.006043502129614353, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9092176556587219, \"recall\": 0.9972468614578247, \"specificity\": 0.9939565062522888, \"npv\": 0.9998319149017334, \"accuracy\": 0.9941447973251343, \"f1\": 0.9511999416441753, \"f2\": 0.9783032740149447, \"f0_5\": 0.9255578899551417, \"p4\": 0.9735070455845729, \"phi\": 0.9492380871992148}, {\"truth_threshold\": -10.432799292577537, \"match_probability\": 0.0007229369010933428, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107072.0, \"fp\": 647.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9939936399459839, \"fp_rate\": 0.006006368435919285, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9097251296043396, \"recall\": 0.9972468614578247, \"specificity\": 0.9939936399459839, \"npv\": 0.9998319149017334, \"accuracy\": 0.9941797852516174, \"f1\": 0.951477562933236, \"f2\": 0.9784207209099913, \"f0_5\": 0.9259785263875476, \"p4\": 0.973661331750689, \"phi\": 0.9495208120153409}, {\"truth_threshold\": -10.431141900977538, \"match_probability\": 0.0007237672985910779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107075.0, \"fp\": 644.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.994021475315094, \"fp_rate\": 0.0059785181656479836, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9101060628890991, \"recall\": 0.9972468614578247, \"specificity\": 0.994021475315094, \"npv\": 0.9998319149017334, \"accuracy\": 0.9942060708999634, \"f1\": 0.9516858852722231, \"f2\": 0.9785088245887862, \"f0_5\": 0.9262942547025061, \"p4\": 0.9737770780354396, \"phi\": 0.949732942207002}, {\"truth_threshold\": -10.42899112848611, \"match_probability\": 0.0007248463142414907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107081.0, \"fp\": 638.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.994077205657959, \"fp_rate\": 0.005922817625105381, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9108689427375793, \"recall\": 0.9972468614578247, \"specificity\": 0.994077205657959, \"npv\": 0.9998319149017334, \"accuracy\": 0.9942585825920105, \"f1\": 0.9521028037383178, \"f2\": 0.978685079555689, \"f0_5\": 0.9269263576912141, \"p4\": 0.9740086520582953, \"phi\": 0.9501576807513581}, {\"truth_threshold\": -10.419411027083624, \"match_probability\": 0.0007296720911455097, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107085.0, \"fp\": 634.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.994114339351654, \"fp_rate\": 0.005885683931410313, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9113782644271851, \"recall\": 0.9972468614578247, \"specificity\": 0.994114339351654, \"npv\": 0.9998319149017334, \"accuracy\": 0.9942935705184937, \"f1\": 0.9523809523809523, \"f2\": 0.9788026181468804, \"f0_5\": 0.9273482391761961, \"p4\": 0.9741630951067829, \"phi\": 0.9504411589711446}, {\"truth_threshold\": -10.417144420111681, \"match_probability\": 0.0007308185358518865, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107086.0, \"fp\": 633.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9941235780715942, \"fp_rate\": 0.0058764005079865456, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9115056395530701, \"recall\": 0.9972468614578247, \"specificity\": 0.9941235780715942, \"npv\": 0.9998319149017334, \"accuracy\": 0.9943023324012756, \"f1\": 0.9524505149368198, \"f2\": 0.9788320072061252, \"f0_5\": 0.9274537695590327, \"p4\": 0.9742017134179836, \"phi\": 0.9505120430610537}, {\"truth_threshold\": -10.412410844026232, \"match_probability\": 0.0007332185759438212, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107089.0, \"fp\": 630.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9941514730453491, \"fp_rate\": 0.005848550237715244, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9118881225585938, \"recall\": 0.9972468614578247, \"specificity\": 0.9941514730453491, \"npv\": 0.9998319149017334, \"accuracy\": 0.9943285584449768, \"f1\": 0.9526592635885447, \"f2\": 0.9789201849738755, \"f0_5\": 0.9277705048665262, \"p4\": 0.9743175864750607, \"phi\": 0.950724869702594}, {\"truth_threshold\": -10.389663683689573, \"match_probability\": 0.000744862270019162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107095.0, \"fp\": 624.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942071437835693, \"fp_rate\": 0.005792849697172642, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9126539826393127, \"recall\": 0.9972468614578247, \"specificity\": 0.9942071437835693, \"npv\": 0.9998319745063782, \"accuracy\": 0.9943810701370239, \"f1\": 0.9530770355211227, \"f2\": 0.9790965881787602, \"f0_5\": 0.928404624935923, \"p4\": 0.974549414176854, \"phi\": 0.9511508288780869}, {\"truth_threshold\": -10.378053131828581, \"match_probability\": 0.0007508764553933939, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107096.0, \"fp\": 623.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942164421081543, \"fp_rate\": 0.005783566273748875, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9127817153930664, \"recall\": 0.9972468614578247, \"specificity\": 0.9942164421081543, \"npv\": 0.9998319745063782, \"accuracy\": 0.9943898320198059, \"f1\": 0.953146699802646, \"f2\": 0.9791259948941282, \"f0_5\": 0.9285103958986044, \"p4\": 0.9745880627074786, \"phi\": 0.9512218585494407}, {\"truth_threshold\": -10.362827498717257, \"match_probability\": 0.0007588368267091626, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107099.0, \"fp\": 620.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942442774772644, \"fp_rate\": 0.005755716469138861, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.913165271282196, \"recall\": 0.9972468614578247, \"specificity\": 0.9942442774772644, \"npv\": 0.9998319745063782, \"accuracy\": 0.9944161176681519, \"f1\": 0.9533557537651703, \"f2\": 0.9792142256397933, \"f0_5\": 0.9288278534389424, \"p4\": 0.974704026444171, \"phi\": 0.9514350350934527}, {\"truth_threshold\": -10.34027565672741, \"match_probability\": 0.000770782752612189, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107100.0, \"fp\": 619.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942535758018494, \"fp_rate\": 0.005746433045715094, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.913293182849884, \"recall\": 0.9972468614578247, \"specificity\": 0.9942535758018494, \"npv\": 0.9998319745063782, \"accuracy\": 0.9944248199462891, \"f1\": 0.9534254587994443, \"f2\": 0.979243639422066, \"f0_5\": 0.9289337208639653, \"p4\": 0.9747426870725283, \"phi\": 0.9515061231350727}, {\"truth_threshold\": -10.310847667259825, \"match_probability\": 0.0007866540763384977, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107101.0, \"fp\": 618.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942628741264343, \"fp_rate\": 0.0057371496222913265, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9134211540222168, \"recall\": 0.9972468614578247, \"specificity\": 0.9942628741264343, \"npv\": 0.9998319745063782, \"accuracy\": 0.994433581829071, \"f1\": 0.9534951740274934, \"f2\": 0.9792730549714629, \"f0_5\": 0.9290396124251924, \"p4\": 0.9747813507262092, \"phi\": 0.9515773129967181}, {\"truth_threshold\": -10.308981254370826, \"match_probability\": 0.0007876716262494484, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107102.0, \"fp\": 617.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942721128463745, \"fp_rate\": 0.005727866198867559, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9135491251945496, \"recall\": 0.9972468614578247, \"specificity\": 0.9942721128463745, \"npv\": 0.9998319745063782, \"accuracy\": 0.994442343711853, \"f1\": 0.953564899451554, \"f2\": 0.9793024722881433, \"f0_5\": 0.9291455281308784, \"p4\": 0.9748200174055699, \"phi\": 0.9516484302597322}, {\"truth_threshold\": -10.29910179043376, \"match_probability\": 0.0007930797588576249, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107103.0, \"fp\": 616.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942814111709595, \"fp_rate\": 0.005718582775443792, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9136771559715271, \"recall\": 0.9972468614578247, \"specificity\": 0.9942814111709595, \"npv\": 0.9998319745063782, \"accuracy\": 0.994451105594635, \"f1\": 0.9536346350738628, \"f2\": 0.9793318913722663, \"f0_5\": 0.9292514679892823, \"p4\": 0.9748586871109665, \"phi\": 0.9517195621382416}, {\"truth_threshold\": -10.291613538027821, \"match_probability\": 0.00079720361991276, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107104.0, \"fp\": 615.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9942907094955444, \"fp_rate\": 0.005709299352020025, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9138051867485046, \"recall\": 0.9972468614578247, \"specificity\": 0.9942907094955444, \"npv\": 0.9998319745063782, \"accuracy\": 0.994459867477417, \"f1\": 0.9537043808966577, \"f2\": 0.9793613122239914, \"f0_5\": 0.9293574320086664, \"p4\": 0.9748973598427555, \"phi\": 0.9517907086373485}, {\"truth_threshold\": -10.286963666042896, \"match_probability\": 0.0007997751304378115, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107106.0, \"fp\": 613.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9943092465400696, \"fp_rate\": 0.005690732505172491, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.914061427116394, \"recall\": 0.9972468614578247, \"specificity\": 0.9943092465400696, \"npv\": 0.9998319745063782, \"accuracy\": 0.994477391242981, \"f1\": 0.9538439031526589, \"f2\": 0.9794201592308848, \"f0_5\": 0.9295694325634445, \"p4\": 0.9749747143869363, \"phi\": 0.9519330455177762}, {\"truth_threshold\": -10.279187147328004, \"match_probability\": 0.0008040942997832289, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107107.0, \"fp\": 612.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9943185448646545, \"fp_rate\": 0.005681449081748724, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9141895771026611, \"recall\": 0.9972468614578247, \"specificity\": 0.9943185448646545, \"npv\": 0.9998319745063782, \"accuracy\": 0.9944860935211182, \"f1\": 0.9539136795903438, \"f2\": 0.9794495853863718, \"f0_5\": 0.9296754691153825, \"p4\": 0.9750133962000409, \"phi\": 0.9520043231582772}, {\"truth_threshold\": -10.267334859293962, \"match_probability\": 0.0008107220720143451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107109.0, \"fp\": 610.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9943371415138245, \"fp_rate\": 0.00566288223490119, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9144459962844849, \"recall\": 0.9972468614578247, \"specificity\": 0.9943371415138245, \"npv\": 0.9998319745063782, \"accuracy\": 0.9945036172866821, \"f1\": 0.9540532630962832, \"f2\": 0.9795084430022234, \"f0_5\": 0.9298876148097438, \"p4\": 0.9750907689100616, \"phi\": 0.9521467478809832}, {\"truth_threshold\": -10.264697336772338, \"match_probability\": 0.0008122043777963354, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107114.0, \"fp\": 605.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9943835139274597, \"fp_rate\": 0.005616465117782354, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9150876998901367, \"recall\": 0.9972468614578247, \"specificity\": 0.9943835139274597, \"npv\": 0.9998319745063782, \"accuracy\": 0.9945473670959473, \"f1\": 0.9544024006440752, \"f2\": 0.9796556179944106, \"f0_5\": 0.9304184028768765, \"p4\": 0.9752842536906596, \"phi\": 0.9525031534634785}, {\"truth_threshold\": -10.253148953050651, \"match_probability\": 0.0008187266007918956, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107115.0, \"fp\": 604.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9943928122520447, \"fp_rate\": 0.005607181694358587, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9152161478996277, \"recall\": 0.9972468614578247, \"specificity\": 0.9943928122520447, \"npv\": 0.9998319745063782, \"accuracy\": 0.9945561289787292, \"f1\": 0.9544722588200849, \"f2\": 0.9796850583002765, \"f0_5\": 0.9305246332134498, \"p4\": 0.9753229597362989, \"phi\": 0.9525744611380581}, {\"truth_threshold\": -10.246717329840111, \"match_probability\": 0.0008223816739040612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107116.0, \"fp\": 603.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9944021105766296, \"fp_rate\": 0.00559789827093482, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9153446555137634, \"recall\": 0.9972468614578247, \"specificity\": 0.9944021105766296, \"npv\": 0.9998319745063782, \"accuracy\": 0.9945648908615112, \"f1\": 0.9545421272234829, \"f2\": 0.9797145003756574, \"f0_5\": 0.9306308878104482, \"p4\": 0.975361668812611, \"phi\": 0.9526457834946598}, {\"truth_threshold\": -10.20212472326875, \"match_probability\": 0.0008481758923544273, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107122.0, \"fp\": 597.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9944577813148499, \"fp_rate\": 0.005542197730392218, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9161163568496704, \"recall\": 0.9972468614578247, \"specificity\": 0.9944577813148499, \"npv\": 0.9998319745063782, \"accuracy\": 0.9946174025535583, \"f1\": 0.9549615525448554, \"f2\": 0.9798911899966937, \"f0_5\": 0.9312689253270868, \"p4\": 0.9755939869346112, \"phi\": 0.9530741135792032}, {\"truth_threshold\": -10.18228812545101, \"match_probability\": 0.0008599084875310211, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107123.0, \"fp\": 596.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9944670796394348, \"fp_rate\": 0.0055329143069684505, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9162451028823853, \"recall\": 0.9972468614578247, \"specificity\": 0.9944670796394348, \"npv\": 0.9998319745063782, \"accuracy\": 0.9946261644363403, \"f1\": 0.9550314926029002, \"f2\": 0.9799206444631477, \"f0_5\": 0.9313753499800012, \"p4\": 0.9756327172356337, \"phi\": 0.9531455388596042}, {\"truth_threshold\": -10.173570908349902, \"match_probability\": 0.000865115545514843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107126.0, \"fp\": 593.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9944949150085449, \"fp_rate\": 0.005505064036697149, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9166315197944641, \"recall\": 0.9972468614578247, \"specificity\": 0.9944949150085449, \"npv\": 0.9998319745063782, \"accuracy\": 0.9946523904800415, \"f1\": 0.9552413742582961, \"f2\": 0.9800090184879002, \"f0_5\": 0.9316947699342669, \"p4\": 0.9757489263413166, \"phi\": 0.9533599030604644}, {\"truth_threshold\": -10.159796594089057, \"match_probability\": 0.0008734076539528552, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107129.0, \"fp\": 590.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9945228099822998, \"fp_rate\": 0.005477213766425848, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9170182943344116, \"recall\": 0.9972468614578247, \"specificity\": 0.9945228099822998, \"npv\": 0.999832034111023, \"accuracy\": 0.9946786761283875, \"f1\": 0.9554513481828839, \"f2\": 0.9800974084540918, \"f0_5\": 0.9320144090571216, \"p4\": 0.975865162758432, \"phi\": 0.9535744872840184}, {\"truth_threshold\": -10.148655584185779, \"match_probability\": 0.0008801725723244219, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107131.0, \"fp\": 588.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.994541347026825, \"fp_rate\": 0.005458646919578314, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9172763228416443, \"recall\": 0.9972468614578247, \"specificity\": 0.994541347026825, \"npv\": 0.999832034111023, \"accuracy\": 0.9946961402893066, \"f1\": 0.9555913820899897, \"f2\": 0.9801563439567047, \"f0_5\": 0.9322276236774378, \"p4\": 0.9759426688809635, \"phi\": 0.953717558956711}, {\"truth_threshold\": -10.121904419772399, \"match_probability\": 0.0008966306489279461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107137.0, \"fp\": 582.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9945970773696899, \"fp_rate\": 0.005402946379035711, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9180512428283691, \"recall\": 0.9972468614578247, \"specificity\": 0.9945970773696899, \"npv\": 0.999832034111023, \"accuracy\": 0.9947486519813538, \"f1\": 0.9560117302052786, \"f2\": 0.9803331929993384, \"f0_5\": 0.9328678532593143, \"p4\": 0.9761752601334364, \"phi\": 0.9541472159089411}, {\"truth_threshold\": -10.12013164938844, \"match_probability\": 0.0008977321079115447, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107139.0, \"fp\": 580.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9946156144142151, \"fp_rate\": 0.005384379532188177, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9183098673820496, \"recall\": 0.9972468614578247, \"specificity\": 0.9946156144142151, \"npv\": 0.999832034111023, \"accuracy\": 0.9947661757469177, \"f1\": 0.9561519284352544, \"f2\": 0.9803921568627451, \"f0_5\": 0.933081458583777, \"p4\": 0.9762528148554362, \"phi\": 0.9542905240735395}, {\"truth_threshold\": -10.11633617642843, \"match_probability\": 0.0009000948615446025, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107148.0, \"fp\": 571.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9946991801261902, \"fp_rate\": 0.005300829187035561, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9194753766059875, \"recall\": 0.9972468614578247, \"specificity\": 0.9946991801261902, \"npv\": 0.999832034111023, \"accuracy\": 0.9948449730873108, \"f1\": 0.9567833296646856, \"f2\": 0.9806575820473483, \"f0_5\": 0.934043894332703, \"p4\": 0.9766019615891084, \"phi\": 0.9549363192781115}, {\"truth_threshold\": -10.115488720250578, \"match_probability\": 0.0009006232669390009, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107149.0, \"fp\": 570.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9947084784507751, \"fp_rate\": 0.0052915457636117935, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9196050763130188, \"recall\": 0.9972468614578247, \"specificity\": 0.9947084784507751, \"npv\": 0.999832034111023, \"accuracy\": 0.9948537349700928, \"f1\": 0.956853536835926, \"f2\": 0.9806870826063414, \"f0_5\": 0.9341509542094103, \"p4\": 0.9766407708782721, \"phi\": 0.9550081290660343}, {\"truth_threshold\": -10.078134411278175, \"match_probability\": 0.0009242249119391308, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107159.0, \"fp\": 560.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9948012828826904, \"fp_rate\": 0.005198711529374123, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9209039807319641, \"recall\": 0.9972468614578247, \"specificity\": 0.9948012828826904, \"npv\": 0.999832034111023, \"accuracy\": 0.994941234588623, \"f1\": 0.9575561756498752, \"f2\": 0.9809821858449687, \"f0_5\": 0.9352229043548109, \"p4\": 0.9770290311856072, \"phi\": 0.9557272200946608}, {\"truth_threshold\": -10.072687930065062, \"match_probability\": 0.0009277174093025344, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107160.0, \"fp\": 559.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9948105812072754, \"fp_rate\": 0.0051894281059503555, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.921034038066864, \"recall\": 0.9972468614578247, \"specificity\": 0.9948105812072754, \"npv\": 0.999832034111023, \"accuracy\": 0.994949996471405, \"f1\": 0.9576264962914005, \"f2\": 0.9810117059372273, \"f0_5\": 0.935330234693292, \"p4\": 0.9770678739658137, \"phi\": 0.9557991936201244}, {\"truth_threshold\": -10.070229213192828, \"match_probability\": 0.0009292983516712842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107161.0, \"fp\": 558.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9948198795318604, \"fp_rate\": 0.0051801446825265884, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9211641550064087, \"recall\": 0.9972468614578247, \"specificity\": 0.9948198795318604, \"npv\": 0.999832034111023, \"accuracy\": 0.994958758354187, \"f1\": 0.9576968272620446, \"f2\": 0.9810412278061992, \"f0_5\": 0.9354375896700143, \"p4\": 0.9771067197928166, \"phi\": 0.9558711820612029}, {\"truth_threshold\": -10.068602332619744, \"match_probability\": 0.0009303459069794134, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107163.0, \"fp\": 556.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9948384165763855, \"fp_rate\": 0.005161577835679054, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9214245080947876, \"recall\": 0.9972468614578247, \"specificity\": 0.9948384165763855, \"npv\": 0.999832034111023, \"accuracy\": 0.9949762225151062, \"f1\": 0.9578375201997943, \"f2\": 0.9811002768749247, \"f0_5\": 0.9356523735721256, \"p4\": 0.9771844205886501, \"phi\": 0.9560152037112067}, {\"truth_threshold\": -10.036165827744446, \"match_probability\": 0.0009514799152224341, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107165.0, \"fp\": 554.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9948570132255554, \"fp_rate\": 0.00514301098883152, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9216850399971008, \"recall\": 0.9972468614578247, \"specificity\": 0.9948570132255554, \"npv\": 0.999832034111023, \"accuracy\": 0.9949937462806702, \"f1\": 0.95797825448134, \"f2\": 0.9811593330524289, \"f0_5\": 0.9358672561290693, \"p4\": 0.977262133575985, \"phi\": 0.9561593726689075}, {\"truth_threshold\": -10.036067384599967, \"match_probability\": 0.000951544780448145, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107168.0, \"fp\": 551.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9948848485946655, \"fp_rate\": 0.005115160718560219, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9220761060714722, \"recall\": 0.9972468614578247, \"specificity\": 0.9948848485946655, \"npv\": 0.9998320937156677, \"accuracy\": 0.9950199723243713, \"f1\": 0.9581894334631493, \"f2\": 0.981247930650453, \"f0_5\": 0.9361897650910344, \"p4\": 0.9773787259223493, \"phi\": 0.9563756068268395}, {\"truth_threshold\": -10.035213224646398, \"match_probability\": 0.0009521077809430248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107178.0, \"fp\": 541.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9949776530265808, \"fp_rate\": 0.005022326484322548, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9233819842338562, \"recall\": 0.9972468614578247, \"specificity\": 0.9949776530265808, \"npv\": 0.9998320937156677, \"accuracy\": 0.9951075315475464, \"f1\": 0.9588940363262004, \"f2\": 0.9815433715713726, \"f0_5\": 0.9372664021620378, \"p4\": 0.9777675653603844, \"phi\": 0.9570975357181821}, {\"truth_threshold\": -10.033519873464298, \"match_probability\": 0.0009532248996709967, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107181.0, \"fp\": 538.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9950055480003357, \"fp_rate\": 0.004994476214051247, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9237744212150574, \"recall\": 0.9972468614578247, \"specificity\": 0.9950055480003357, \"npv\": 0.9998320937156677, \"accuracy\": 0.9951337575912476, \"f1\": 0.9591056192997941, \"f2\": 0.9816320385426076, \"f0_5\": 0.9375898763301697, \"p4\": 0.9778842767143131, \"phi\": 0.9573143542902466}, {\"truth_threshold\": -10.02156781490485, \"match_probability\": 0.0009611471057606354, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107183.0, \"fp\": 536.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9950240850448608, \"fp_rate\": 0.0049759093672037125, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9240362644195557, \"recall\": 0.9972468614578247, \"specificity\": 0.9950240850448608, \"npv\": 0.9998320937156677, \"accuracy\": 0.9951512813568115, \"f1\": 0.959246726496984, \"f2\": 0.981691158756926, \"f0_5\": 0.9378056498475347, \"p4\": 0.9779620995547971, \"phi\": 0.9574589751281793}, {\"truth_threshold\": -10.018391126016471, \"match_probability\": 0.0009632637588889966, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107184.0, \"fp\": 535.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9950333833694458, \"fp_rate\": 0.004966625943779945, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.924167275428772, \"recall\": 0.9972468614578247, \"specificity\": 0.9950333833694458, \"npv\": 0.9998320937156677, \"accuracy\": 0.9951600432395935, \"f1\": 0.9593172956668874, \"f2\": 0.9817207215346162, \"f0_5\": 0.9379135738535014, \"p4\": 0.9780010155574809, \"phi\": 0.9575313957923153}, {\"truth_threshold\": -10.016816315219495, \"match_probability\": 0.0009643147937505694, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107185.0, \"fp\": 534.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9950426816940308, \"fp_rate\": 0.004957342520356178, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9242982864379883, \"recall\": 0.9972468614578247, \"specificity\": 0.9950426816940308, \"npv\": 0.9998320937156677, \"accuracy\": 0.9951688051223755, \"f1\": 0.9593878752207181, \"f2\": 0.9817502860928747, \"f0_5\": 0.9380215227024228, \"p4\": 0.9780399346156071, \"phi\": 0.9576037438123014}, {\"truth_threshold\": -10.010320621765723, \"match_probability\": 0.0009686621676080818, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107187.0, \"fp\": 532.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9950612187385559, \"fp_rate\": 0.004938775673508644, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9245604276657104, \"recall\": 0.9972468614578247, \"specificity\": 0.9950612187385559, \"npv\": 0.9998320937156677, \"accuracy\": 0.9951862692832947, \"f1\": 0.9595290654893304, \"f2\": 0.9818094205517408, \"f0_5\": 0.938237494963449, \"p4\": 0.9781177818996306, \"phi\": 0.9577484850005281}, {\"truth_threshold\": -10.009935988129602, \"match_probability\": 0.0009689202045898807, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107191.0, \"fp\": 528.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.995098352432251, \"fp_rate\": 0.004901642445474863, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9250851273536682, \"recall\": 0.9972468614578247, \"specificity\": 0.995098352432251, \"npv\": 0.9998320937156677, \"accuracy\": 0.9952213168144226, \"f1\": 0.9598115707345797, \"f2\": 0.9819277108433735, \"f0_5\": 0.9386697379786928, \"p4\": 0.9782735131488723, \"phi\": 0.9580382358518748}, {\"truth_threshold\": -9.997952586656142, \"match_probability\": 0.0009769939305124663, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107192.0, \"fp\": 527.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9951076507568359, \"fp_rate\": 0.004892359022051096, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9252163767814636, \"recall\": 0.9972468614578247, \"specificity\": 0.9951076507568359, \"npv\": 0.9998320937156677, \"accuracy\": 0.9952300786972046, \"f1\": 0.9598822230401178, \"f2\": 0.9819572878701166, \"f0_5\": 0.9387778609687266, \"p4\": 0.9783124536052054, \"phi\": 0.9581106893229104}, {\"truth_threshold\": -9.983421843211575, \"match_probability\": 0.0009868741202906618, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107196.0, \"fp\": 523.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.995144784450531, \"fp_rate\": 0.004855225328356028, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9257418513298035, \"recall\": 0.9972468614578247, \"specificity\": 0.995144784450531, \"npv\": 0.9998320937156677, \"accuracy\": 0.9952650666236877, \"f1\": 0.9601649363080774, \"f2\": 0.9820756137972586, \"f0_5\": 0.9392106021319504, \"p4\": 0.9784682460174686, \"phi\": 0.9584006541094888}, {\"truth_threshold\": -9.97462618441073, \"match_probability\": 0.0009929031679896765, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107201.0, \"fp\": 518.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.995191216468811, \"fp_rate\": 0.004808808211237192, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9263995289802551, \"recall\": 0.9972468614578247, \"specificity\": 0.995191216468811, \"npv\": 0.9998320937156677, \"accuracy\": 0.9953088164329529, \"f1\": 0.9605185621685327, \"f2\": 0.9822235613136487, \"f0_5\": 0.9397520899394638, \"p4\": 0.9786630553805094, \"phi\": 0.9587635378148798}, {\"truth_threshold\": -9.967120030882475, \"match_probability\": 0.0009980774060125777, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107202.0, \"fp\": 517.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9952004551887512, \"fp_rate\": 0.004799524787813425, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.926531195640564, \"recall\": 0.9972468614578247, \"specificity\": 0.9952004551887512, \"npv\": 0.9998320937156677, \"accuracy\": 0.9953175783157349, \"f1\": 0.9605893186003683, \"f2\": 0.9822531561661997, \"f0_5\": 0.9398604624344116, \"p4\": 0.9787020264364295, \"phi\": 0.958836142381159}, {\"truth_threshold\": -9.963642335855667, \"match_probability\": 0.0010004838181421887, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107203.0, \"fp\": 516.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9952097535133362, \"fp_rate\": 0.004790241364389658, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9266628623008728, \"recall\": 0.9972468614578247, \"specificity\": 0.9952097535133362, \"npv\": 0.9998320937156677, \"accuracy\": 0.9953263401985168, \"f1\": 0.9606600854574923, \"f2\": 0.9822827528022177, \"f0_5\": 0.9399688599273398, \"p4\": 0.978741000554298, \"phi\": 0.958908762085803}, {\"truth_threshold\": -9.961299899493387, \"match_probability\": 0.0010021079471465503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107209.0, \"fp\": 510.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9952654838562012, \"fp_rate\": 0.0047345408238470554, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9274537563323975, \"recall\": 0.9972468614578247, \"specificity\": 0.9952654838562012, \"npv\": 0.9998321533203125, \"accuracy\": 0.995378851890564, \"f1\": 0.9610849056603774, \"f2\": 0.982460370080164, \"f0_5\": 0.9406197703271972, \"p4\": 0.9789749095827002, \"phi\": 0.9593448863575169}, {\"truth_threshold\": -9.961183861583473, \"match_probability\": 0.0010021884705026496, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107212.0, \"fp\": 507.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9952933192253113, \"fp_rate\": 0.004706690553575754, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9278497099876404, \"recall\": 0.9972468614578247, \"specificity\": 0.9952933192253113, \"npv\": 0.9998321533203125, \"accuracy\": 0.9954050779342651, \"f1\": 0.9612974566900111, \"f2\": 0.9825492028090057, \"f0_5\": 0.9409455637014374, \"p4\": 0.9790919054625378, \"phi\": 0.959563197250023}, {\"truth_threshold\": -9.899511998435951, \"match_probability\": 0.001045912790838542, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107213.0, \"fp\": 506.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9953026175498962, \"fp_rate\": 0.004697407130151987, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9279817938804626, \"recall\": 0.9972468614578247, \"specificity\": 0.9953026175498962, \"npv\": 0.9998321533203125, \"accuracy\": 0.9954138398170471, \"f1\": 0.9613683279268652, \"f2\": 0.9825788172885647, \"f0_5\": 0.9410542116505975, \"p4\": 0.9791309102198086, \"phi\": 0.9596359686452461}, {\"truth_threshold\": -9.895864221420807, \"match_probability\": 0.0010485578948656923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107217.0, \"fp\": 502.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9953397512435913, \"fp_rate\": 0.004660273436456919, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9285103678703308, \"recall\": 0.9972468614578247, \"specificity\": 0.9953397512435913, \"npv\": 0.9998321533203125, \"accuracy\": 0.9954488277435303, \"f1\": 0.9616519174041298, \"f2\": 0.9826972930608308, \"f0_5\": 0.941489054467741, \"p4\": 0.9792869599118514, \"phi\": 0.9599272941393764}, {\"truth_threshold\": -9.893154052605308, \"match_probability\": 0.0010505274390411132, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107218.0, \"fp\": 501.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9953489899635315, \"fp_rate\": 0.004650990013033152, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9286426305770874, \"recall\": 0.9972468614578247, \"specificity\": 0.9953489899635315, \"npv\": 0.9998321533203125, \"accuracy\": 0.9954575896263123, \"f1\": 0.9617228409174718, \"f2\": 0.9827269164682121, \"f0_5\": 0.9415978279706545, \"p4\": 0.9793259800024157, \"phi\": 0.9600001415817461}, {\"truth_threshold\": -9.884362667881494, \"match_probability\": 0.001056941820560983, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107219.0, \"fp\": 500.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9953582882881165, \"fp_rate\": 0.0046417065896093845, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9287749528884888, \"recall\": 0.9972468614578247, \"specificity\": 0.9953582882881165, \"npv\": 0.9998321533203125, \"accuracy\": 0.9954663515090942, \"f1\": 0.9617937748930521, \"f2\": 0.9827565416616424, \"f0_5\": 0.9417066266104339, \"p4\": 0.9793650031607267, \"phi\": 0.9600730042485665}, {\"truth_threshold\": -9.868814769965962, \"match_probability\": 0.00106838182720937, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107239.0, \"fp\": 480.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9955439567565918, \"fp_rate\": 0.00445603858679533, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9314285516738892, \"recall\": 0.9972468614578247, \"specificity\": 0.9955439567565918, \"npv\": 0.9998321533203125, \"accuracy\": 0.9956414103507996, \"f1\": 0.9632146550450583, \"f2\": 0.9833494208494209, \"f0_5\": 0.9438878915976605, \"p4\": 0.9801461111130919, \"phi\": 0.9615337271004715}, {\"truth_threshold\": -9.827448343305075, \"match_probability\": 0.0010994248045709492, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107242.0, \"fp\": 477.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9955717921257019, \"fp_rate\": 0.004428188316524029, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9318279027938843, \"recall\": 0.9972468614578247, \"specificity\": 0.9955717921257019, \"npv\": 0.9998322129249573, \"accuracy\": 0.9956676363945007, \"f1\": 0.9634281492427041, \"f2\": 0.9834384144318079, \"f0_5\": 0.9442159531946939, \"p4\": 0.9802633833354325, \"phi\": 0.9617534121193739}, {\"truth_threshold\": -9.792687145314591, \"match_probability\": 0.001126206553447524, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107254.0, \"fp\": 465.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9956831932067871, \"fp_rate\": 0.004316787235438824, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9334287643432617, \"recall\": 0.9972468614578247, \"specificity\": 0.9956831932067871, \"npv\": 0.9998322129249573, \"accuracy\": 0.995772659778595, \"f1\": 0.9642830732825557, \"f2\": 0.9837945498989046, \"f0_5\": 0.9455304832066825, \"p4\": 0.980732749205699, \"phi\": 0.9626332716594328}, {\"truth_threshold\": -9.791594971784443, \"match_probability\": 0.001127058495009008, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107256.0, \"fp\": 463.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.995701789855957, \"fp_rate\": 0.0042982203885912895, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9336960911750793, \"recall\": 0.9972468614578247, \"specificity\": 0.995701789855957, \"npv\": 0.9998322129249573, \"accuracy\": 0.9957901835441589, \"f1\": 0.9644257081576807, \"f2\": 0.9838539308887883, \"f0_5\": 0.9457499274731651, \"p4\": 0.9808110199655848, \"phi\": 0.9627802039909936}, {\"truth_threshold\": -9.786436247192237, \"match_probability\": 0.0011310912278577293, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107257.0, \"fp\": 462.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.995711088180542, \"fp_rate\": 0.004288936965167522, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9338298439979553, \"recall\": 0.9972468614578247, \"specificity\": 0.995711088180542, \"npv\": 0.9998322129249573, \"accuracy\": 0.9957989454269409, \"f1\": 0.9644970414201184, \"f2\": 0.9838836240719503, \"f0_5\": 0.9458596878082748, \"p4\": 0.9808501599677113, \"phi\": 0.9628536492506152}, {\"truth_threshold\": -9.779007988247322, \"match_probability\": 0.001136923457737019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107259.0, \"fp\": 460.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9957296252250671, \"fp_rate\": 0.004270370118319988, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.934097409248352, \"recall\": 0.9972468614578247, \"specificity\": 0.9957296252250671, \"npv\": 0.9998322129249573, \"accuracy\": 0.9958164691925049, \"f1\": 0.9646397396064507, \"f2\": 0.9839430158155258, \"f0_5\": 0.9460792849265773, \"p4\": 0.9809284492181569, \"phi\": 0.9630005860869103}, {\"truth_threshold\": -9.773131421910653, \"match_probability\": 0.0011415586642387057, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107268.0, \"fp\": 451.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9958131909370422, \"fp_rate\": 0.0041868193075060844, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9353033900260925, \"recall\": 0.9972468614578247, \"specificity\": 0.9958131909370422, \"npv\": 0.9998322129249573, \"accuracy\": 0.9958952069282532, \"f1\": 0.9652824043230439, \"f2\": 0.9842103674184102, \"f0_5\": 0.9470687351112661, \"p4\": 0.9812809034796638, \"phi\": 0.9636627435427738}, {\"truth_threshold\": -9.761566467572981, \"match_probability\": 0.0011507358481257916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107270.0, \"fp\": 449.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9958317279815674, \"fp_rate\": 0.00416825246065855, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9355717897415161, \"recall\": 0.9972468614578247, \"specificity\": 0.9958317279815674, \"npv\": 0.9998322129249573, \"accuracy\": 0.9959127306938171, \"f1\": 0.9654253350114755, \"f2\": 0.9842697986171915, \"f0_5\": 0.9472888940547451, \"p4\": 0.9813592605850872, \"phi\": 0.9638100208099086}, {\"truth_threshold\": -9.757638257322432, \"match_probability\": 0.0011538697529890202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107274.0, \"fp\": 445.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9958688616752625, \"fp_rate\": 0.004131118766963482, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9361091256141663, \"recall\": 0.9972468614578247, \"specificity\": 0.9958688616752625, \"npv\": 0.9998322129249573, \"accuracy\": 0.9959477186203003, \"f1\": 0.9657113234096126, \"f2\": 0.9843886825497479, \"f0_5\": 0.9477295191580906, \"p4\": 0.9815160118391861, \"phi\": 0.9641048497167828}, {\"truth_threshold\": -9.755356720182677, \"match_probability\": 0.0011556938630638643, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107278.0, \"fp\": 441.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9959059953689575, \"fp_rate\": 0.0040939850732684135, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9366470575332642, \"recall\": 0.9972468614578247, \"specificity\": 0.9959059953689575, \"npv\": 0.9998322129249573, \"accuracy\": 0.9959827661514282, \"f1\": 0.9659974812949107, \"f2\": 0.9845075952043004, \"f0_5\": 0.9481705543598394, \"p4\": 0.9816728125038084, \"phi\": 0.9643998389268272}, {\"truth_threshold\": -9.755313156006254, \"match_probability\": 0.0011557287210358467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107285.0, \"fp\": 434.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9959710240364075, \"fp_rate\": 0.004029001574963331, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9375898838043213, \"recall\": 0.9972468614578247, \"specificity\": 0.9959710240364075, \"npv\": 0.999832272529602, \"accuracy\": 0.9960439801216125, \"f1\": 0.9664986658760747, \"f2\": 0.9847157614933849, \"f0_5\": 0.9489433544856494, \"p4\": 0.9819473326314719, \"phi\": 0.9649167573523669}, {\"truth_threshold\": -9.7317459528663, \"match_probability\": 0.001174740859796514, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107287.0, \"fp\": 432.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9959895610809326, \"fp_rate\": 0.004010434728115797, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9378595948219299, \"recall\": 0.9972468614578247, \"specificity\": 0.9959895610809326, \"npv\": 0.999832272529602, \"accuracy\": 0.9960615038871765, \"f1\": 0.9666419570051891, \"f2\": 0.9847752537457709, \"f0_5\": 0.9491643859546963, \"p4\": 0.9820257947778553, \"phi\": 0.9650646516644144}, {\"truth_threshold\": -9.731311246216027, \"match_probability\": 0.0011750944649731438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107288.0, \"fp\": 431.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9959988594055176, \"fp_rate\": 0.00400115130469203, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9379945397377014, \"recall\": 0.9972468614578247, \"specificity\": 0.9959988594055176, \"npv\": 0.999832272529602, \"accuracy\": 0.9960702657699585, \"f1\": 0.9667136185039662, \"f2\": 0.9848050025677431, \"f0_5\": 0.9492749403063304, \"p4\": 0.9820650304902462, \"phi\": 0.965138578080526}, {\"truth_threshold\": -9.711591778576935, \"match_probability\": 0.0011912472429553345, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107292.0, \"fp\": 427.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9960359930992126, \"fp_rate\": 0.003964017610996962, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9385346174240112, \"recall\": 0.9972468614578247, \"specificity\": 0.9960359930992126, \"npv\": 0.999832272529602, \"accuracy\": 0.9961052536964417, \"f1\": 0.9670003707823508, \"f2\": 0.984924015831294, \"f0_5\": 0.9497174153702732, \"p4\": 0.9822220042763645, \"phi\": 0.9654344398935417}, {\"truth_threshold\": -9.705094150109597, \"match_probability\": 0.0011966180630633531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107293.0, \"fp\": 426.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9960452914237976, \"fp_rate\": 0.0039547341875731945, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.938669741153717, \"recall\": 0.9972468614578247, \"specificity\": 0.9960452914237976, \"npv\": 0.999832272529602, \"accuracy\": 0.9961140155792236, \"f1\": 0.9670720854345891, \"f2\": 0.984953773641912, \"f0_5\": 0.949828098595653, \"p4\": 0.982261255458868, \"phi\": 0.9655085327447059}, {\"truth_threshold\": -9.700723932746012, \"match_probability\": 0.0012002440015360105, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107294.0, \"fp\": 425.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9960545301437378, \"fp_rate\": 0.003945450764149427, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9388049244880676, \"recall\": 0.9972468614578247, \"specificity\": 0.9960545301437378, \"npv\": 0.999832272529602, \"accuracy\": 0.9961227774620056, \"f1\": 0.9671438107246162, \"f2\": 0.9849835332507478, \"f0_5\": 0.9499388076228218, \"p4\": 0.9823005097364952, \"phi\": 0.9655825529063133}, {\"truth_threshold\": -9.696959741425248, \"match_probability\": 0.0012033759200235127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107298.0, \"fp\": 421.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9960916638374329, \"fp_rate\": 0.003908317070454359, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9393458962440491, \"recall\": 0.9972468614578247, \"specificity\": 0.9960916638374329, \"npv\": 0.999832272529602, \"accuracy\": 0.9961577653884888, \"f1\": 0.9674308183099637, \"f2\": 0.9851025896715317, \"f0_5\": 0.9503819019299167, \"p4\": 0.9824575578055872, \"phi\": 0.9658787900376423}, {\"truth_threshold\": -9.680692806619462, \"match_probability\": 0.0012170046178327319, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107299.0, \"fp\": 420.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961009621620178, \"fp_rate\": 0.003899033647030592, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.939481258392334, \"recall\": 0.9972468614578247, \"specificity\": 0.9961009621620178, \"npv\": 0.999832272529602, \"accuracy\": 0.9961665272712708, \"f1\": 0.9675025968244547, \"f2\": 0.9851323582739031, \"f0_5\": 0.9504927401014637, \"p4\": 0.9824968275643428, \"phi\": 0.9659529768382576}, {\"truth_threshold\": -9.65913080608132, \"match_probability\": 0.001235307495094549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107300.0, \"fp\": 419.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961102604866028, \"fp_rate\": 0.003889750223606825, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9396166801452637, \"recall\": 0.9972468614578247, \"specificity\": 0.9961102604866028, \"npv\": 0.999832272529602, \"accuracy\": 0.9961752891540527, \"f1\": 0.9675743859909476, \"f2\": 0.9851621286754707, \"f0_5\": 0.9506036041290021, \"p4\": 0.9825361004204263, \"phi\": 0.9660270909473194}, {\"truth_threshold\": -9.643729977279122, \"match_probability\": 0.0012485485373654281, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107302.0, \"fp\": 417.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961287975311279, \"fp_rate\": 0.0038711833767592907, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9398875832557678, \"recall\": 0.9972468614578247, \"specificity\": 0.9961287975311279, \"npv\": 0.999832272529602, \"accuracy\": 0.9961928129196167, \"f1\": 0.9677179962894249, \"f2\": 0.9852216748768473, \"f0_5\": 0.9508254097882518, \"p4\": 0.9826146554260476, \"phi\": 0.9661753662008542}, {\"truth_threshold\": -9.643546843451917, \"match_probability\": 0.0012487068386292579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107304.0, \"fp\": 415.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961473941802979, \"fp_rate\": 0.0038526165299117565, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9401586055755615, \"recall\": 0.9972468614578247, \"specificity\": 0.9961473941802979, \"npv\": 0.999832272529602, \"accuracy\": 0.9962102770805359, \"f1\": 0.9678616492243747, \"f2\": 0.9852812282769667, \"f0_5\": 0.9510473189801039, \"p4\": 0.9826932228253924, \"phi\": 0.9663237042058137}, {\"truth_threshold\": -9.64194749416901, \"match_probability\": 0.001250090171741464, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107305.0, \"fp\": 414.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961566925048828, \"fp_rate\": 0.0038433331064879894, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9402942061424255, \"recall\": 0.9972468614578247, \"specificity\": 0.9961566925048828, \"npv\": 0.999832272529602, \"accuracy\": 0.9962190389633179, \"f1\": 0.9679334916864608, \"f2\": 0.9853110076769631, \"f0_5\": 0.9511583124234113, \"p4\": 0.9827325111736305, \"phi\": 0.9663978967541668}, {\"truth_threshold\": -9.640136348905441, \"match_probability\": 0.0012516585426947037, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107307.0, \"fp\": 412.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.996175229549408, \"fp_rate\": 0.0038247662596404552, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9405654668807983, \"recall\": 0.9972468614578247, \"specificity\": 0.996175229549408, \"npv\": 0.999832272529602, \"accuracy\": 0.9962365627288818, \"f1\": 0.9680772086117297, \"f2\": 0.9853705718776448, \"f0_5\": 0.9513803770501371, \"p4\": 0.9828110971690772, \"phi\": 0.9665464173869807}, {\"truth_threshold\": -9.612703081658498, \"match_probability\": 0.0012756562725522134, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107308.0, \"fp\": 411.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961845278739929, \"fp_rate\": 0.003815482836216688, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9407011866569519, \"recall\": 0.9972468614578247, \"specificity\": 0.9961845278739929, \"npv\": 0.999832272529602, \"accuracy\": 0.9962453246116638, \"f1\": 0.9681490830796644, \"f2\": 0.9854003566786567, \"f0_5\": 0.9514914482517074, \"p4\": 0.9828503948170219, \"phi\": 0.9666206570725403}, {\"truth_threshold\": -9.611280542509256, \"match_probability\": 0.0012769131200290231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107309.0, \"fp\": 410.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9961938261985779, \"fp_rate\": 0.003806199412792921, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9408369660377502, \"recall\": 0.9972468614578247, \"specificity\": 0.9961938261985779, \"npv\": 0.999832272529602, \"accuracy\": 0.9962540864944458, \"f1\": 0.9682209682209683, \"f2\": 0.9854301432803337, \"f0_5\": 0.9516025453908576, \"p4\": 0.9828896955656046, \"phi\": 0.9666949124798092}, {\"truth_threshold\": -9.58548451025513, \"match_probability\": 0.0012999202942523041, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107315.0, \"fp\": 404.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9962494969367981, \"fp_rate\": 0.0037504988722503185, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.941652238368988, \"recall\": 0.9972468614578247, \"specificity\": 0.9962494969367981, \"npv\": 0.999832272529602, \"accuracy\": 0.9963065981864929, \"f1\": 0.9686525033427426, \"f2\": 0.9856089007135083, \"f0_5\": 0.9522696734240813, \"p4\": 0.9831255651911199, \"phi\": 0.967140863859958}, {\"truth_threshold\": -9.558959507379173, \"match_probability\": 0.0013240094046189097, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107316.0, \"fp\": 403.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9962587952613831, \"fp_rate\": 0.003741215681657195, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9417882561683655, \"recall\": 0.9972468614578247, \"specificity\": 0.9962587952613831, \"npv\": 0.999832272529602, \"accuracy\": 0.9963153004646301, \"f1\": 0.9687244632642449, \"f2\": 0.9856386999244142, \"f0_5\": 0.9523809523809523, \"p4\": 0.9831648876544797, \"phi\": 0.9672152294835868}, {\"truth_threshold\": -9.555472576659653, \"match_probability\": 0.0013272090953872916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107320.0, \"fp\": 399.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9962959289550781, \"fp_rate\": 0.0037040819879621267, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9423326849937439, \"recall\": 0.9972468614578247, \"specificity\": 0.9962959289550781, \"npv\": 0.9998323321342468, \"accuracy\": 0.9963503479957581, \"f1\": 0.9690124098981943, \"f2\": 0.9857579147893926, \"f0_5\": 0.9528263284035775, \"p4\": 0.98332220854745, \"phi\": 0.9675129381987563}, {\"truth_threshold\": -9.542173213366281, \"match_probability\": 0.0013394839633959618, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107326.0, \"fp\": 393.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9963515996932983, \"fp_rate\": 0.003648381447419524, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9431505799293518, \"recall\": 0.9972468614578247, \"specificity\": 0.9963515996932983, \"npv\": 0.9998323321342468, \"accuracy\": 0.9964028596878052, \"f1\": 0.9694446509553193, \"f2\": 0.9859367911689098, \"f0_5\": 0.9534951740274934, \"p4\": 0.9835582830460577, \"phi\": 0.9679599309020523}, {\"truth_threshold\": -9.535169148667284, \"match_probability\": 0.001345993990855993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107327.0, \"fp\": 392.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9963608980178833, \"fp_rate\": 0.003639098023995757, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9432870149612427, \"recall\": 0.9972468614578247, \"specificity\": 0.9963608980178833, \"npv\": 0.9998323321342468, \"accuracy\": 0.9964116215705872, \"f1\": 0.9695167286245353, \"f2\": 0.9859666102105008, \"f0_5\": 0.9536067396010063, \"p4\": 0.9835976396691276, \"phi\": 0.9680344702873354}, {\"truth_threshold\": -9.534597978582942, \"match_probability\": 0.0013465262643309, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107333.0, \"fp\": 386.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964166283607483, \"fp_rate\": 0.0035833974834531546, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9441065788269043, \"recall\": 0.9972468614578247, \"specificity\": 0.9964166283607483, \"npv\": 0.9998323321342468, \"accuracy\": 0.9964641332626343, \"f1\": 0.9699494198155311, \"f2\": 0.9861455623449694, \"f0_5\": 0.9542766816931093, \"p4\": 0.9838338446809501, \"phi\": 0.968482127791998}, {\"truth_threshold\": -9.524431514155898, \"match_probability\": 0.0013560356403543783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107335.0, \"fp\": 384.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964351654052734, \"fp_rate\": 0.0035648306366056204, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9443800449371338, \"recall\": 0.9972468614578247, \"specificity\": 0.9964351654052734, \"npv\": 0.9998323321342468, \"accuracy\": 0.9964815974235535, \"f1\": 0.9700937360511829, \"f2\": 0.9862052274927396, \"f0_5\": 0.9545002049540318, \"p4\": 0.983912604559814, \"phi\": 0.9686314442983254}, {\"truth_threshold\": -9.51212048823872, \"match_probability\": 0.001367640790325066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107336.0, \"fp\": 383.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964444637298584, \"fp_rate\": 0.0035555472131818533, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9445168972015381, \"recall\": 0.9972468614578247, \"specificity\": 0.9964444637298584, \"npv\": 0.9998323321342468, \"accuracy\": 0.9964903593063354, \"f1\": 0.9701659102745331, \"f2\": 0.9862350627741643, \"f0_5\": 0.9546120058565154, \"p4\": 0.9839519891649567, \"phi\": 0.9687061263616151}, {\"truth_threshold\": -9.508918824879578, \"match_probability\": 0.0013706750970153725, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107337.0, \"fp\": 382.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964537620544434, \"fp_rate\": 0.003546263789758086, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9446537494659424, \"recall\": 0.9972468614578247, \"specificity\": 0.9964537620544434, \"npv\": 0.9998323321342468, \"accuracy\": 0.9964991211891174, \"f1\": 0.9702380952380952, \"f2\": 0.9862648998608338, \"f0_5\": 0.9547238329526152, \"p4\": 0.9839913768810663, \"phi\": 0.9687808243059606}, {\"truth_threshold\": -9.487725429343906, \"match_probability\": 0.0013909309185396684, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107338.0, \"fp\": 381.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964630007743835, \"fp_rate\": 0.003536980366334319, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9447906017303467, \"recall\": 0.9972468614578247, \"specificity\": 0.9964630007743835, \"npv\": 0.9998323321342468, \"accuracy\": 0.9965078830718994, \"f1\": 0.9703102909442667, \"f2\": 0.986294738752912, \"f0_5\": 0.9548356862515377, \"p4\": 0.9840307677085124, \"phi\": 0.9688556267388212}, {\"truth_threshold\": -9.45120332702329, \"match_probability\": 0.0014265412101787899, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107339.0, \"fp\": 380.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964722990989685, \"fp_rate\": 0.0035276971757411957, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9449275135993958, \"recall\": 0.9972468614578247, \"specificity\": 0.9964722990989685, \"npv\": 0.9998323321342468, \"accuracy\": 0.9965166449546814, \"f1\": 0.9703824973954458, \"f2\": 0.9863245794505627, \"f0_5\": 0.9549475657624934, \"p4\": 0.9840701616476647, \"phi\": 0.9689303564684866}, {\"truth_threshold\": -9.449730437624416, \"match_probability\": 0.0014279962705614757, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107341.0, \"fp\": 378.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9964908957481384, \"fp_rate\": 0.0035091303288936615, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9452015161514282, \"recall\": 0.9972468614578247, \"specificity\": 0.9964908957481384, \"npv\": 0.9998323321342468, \"accuracy\": 0.9965341091156006, \"f1\": 0.9705269425424233, \"f2\": 0.9863842662632375, \"f0_5\": 0.9551714034573688, \"p4\": 0.9841489588625676, \"phi\": 0.9690798636283499}, {\"truth_threshold\": -9.412410844026232, \"match_probability\": 0.0014653627207203146, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107356.0, \"fp\": 363.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9966301321983337, \"fp_rate\": 0.003369878977537155, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.947261393070221, \"recall\": 0.9972468614578247, \"specificity\": 0.9966301321983337, \"npv\": 0.9998323321342468, \"accuracy\": 0.9966654181480408, \"f1\": 0.9716116533790329, \"f2\": 0.9868321477221129, \"f0_5\": 0.956853536835926, \"p4\": 0.9847403350629199, \"phi\": 0.9702033764210863}, {\"truth_threshold\": -9.408444738108221, \"match_probability\": 0.001469390757112104, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107357.0, \"fp\": 362.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9966394305229187, \"fp_rate\": 0.003360595554113388, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9473990201950073, \"recall\": 0.9972468614578247, \"specificity\": 0.9966394305229187, \"npv\": 0.9998323917388916, \"accuracy\": 0.9966741800308228, \"f1\": 0.9716840536512668, \"f2\": 0.986862020948114, \"f0_5\": 0.9569658897434392, \"p4\": 0.9847797850760852, \"phi\": 0.9702784819284572}, {\"truth_threshold\": -9.401493000727966, \"match_probability\": 0.0014764777367147451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107359.0, \"fp\": 360.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9966579675674438, \"fp_rate\": 0.003342028707265854, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9476743936538696, \"recall\": 0.9972468614578247, \"specificity\": 0.9966579675674438, \"npv\": 0.9998323917388916, \"accuracy\": 0.9966916441917419, \"f1\": 0.9718288865702788, \"f2\": 0.9869217728263502, \"f0_5\": 0.9571906747313407, \"p4\": 0.9848586944590167, \"phi\": 0.9704285635350307}, {\"truth_threshold\": -9.382194414320514, \"match_probability\": 0.0014963311641203781, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107364.0, \"fp\": 355.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9967043995857239, \"fp_rate\": 0.003295611822977662, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9483636617660522, \"recall\": 0.9972468614578247, \"specificity\": 0.9967043995857239, \"npv\": 0.9998323917388916, \"accuracy\": 0.9967354536056519, \"f1\": 0.9721911578319541, \"f2\": 0.9870711841826384, \"f0_5\": 0.957753099477055, \"p4\": 0.9850560225138332, \"phi\": 0.9708041366502177}, {\"truth_threshold\": -9.356915731434528, \"match_probability\": 0.0015227404208644024, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107366.0, \"fp\": 353.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.996722936630249, \"fp_rate\": 0.003277044976130128, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9486396312713623, \"recall\": 0.9972468614578247, \"specificity\": 0.996722936630249, \"npv\": 0.9998323917388916, \"accuracy\": 0.996752917766571, \"f1\": 0.9723361419730072, \"f2\": 0.9871309613928841, \"f0_5\": 0.95797825448134, \"p4\": 0.9851349755825498, \"phi\": 0.9709544426631134}, {\"truth_threshold\": -9.352583400247019, \"match_probability\": 0.0015273130019930316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107372.0, \"fp\": 347.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.996778666973114, \"fp_rate\": 0.0032213444355875254, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9494684934616089, \"recall\": 0.9972468614578247, \"specificity\": 0.996778666973114, \"npv\": 0.9998323917388916, \"accuracy\": 0.9968054294586182, \"f1\": 0.9727713539723983, \"f2\": 0.9873103364729399, \"f0_5\": 0.9586543551138035, \"p4\": 0.9853719097306071, \"phi\": 0.9714058349983553}, {\"truth_threshold\": -9.352181845254076, \"match_probability\": 0.0015277375188952167, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107374.0, \"fp\": 345.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9967972040176392, \"fp_rate\": 0.003202777588739991, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9497450590133667, \"recall\": 0.9972468614578247, \"specificity\": 0.9967972040176392, \"npv\": 0.9998323917388916, \"accuracy\": 0.9968229532241821, \"f1\": 0.9729165112288294, \"f2\": 0.9873701426537844, \"f0_5\": 0.9588799341137714, \"p4\": 0.9854509127705056, \"phi\": 0.9715563981719817}, {\"truth_threshold\": -9.333255526677295, \"match_probability\": 0.0015478802986392396, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107375.0, \"fp\": 344.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9968065023422241, \"fp_rate\": 0.003193494165316224, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9498834609985352, \"recall\": 0.9972468614578247, \"specificity\": 0.9968065023422241, \"npv\": 0.9998323917388916, \"accuracy\": 0.9968317151069641, \"f1\": 0.9729891061035666, \"f2\": 0.9874000484613521, \"f0_5\": 0.9589927634288404, \"p4\": 0.9854904189778553, \"phi\": 0.9716317039073125}, {\"truth_threshold\": -9.287028958133185, \"match_probability\": 0.0015981997868717561, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107376.0, \"fp\": 343.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9968158006668091, \"fp_rate\": 0.003184210741892457, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9500218629837036, \"recall\": 0.9972468614578247, \"specificity\": 0.9968158006668091, \"npv\": 0.9998323917388916, \"accuracy\": 0.9968404769897461, \"f1\": 0.9730617118125513, \"f2\": 0.9874299560805695, \"f0_5\": 0.9591056192997941, \"p4\": 0.9855299283106346, \"phi\": 0.9717071145804049}, {\"truth_threshold\": -9.274768590168902, \"match_probability\": 0.0016118175614874513, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107377.0, \"fp\": 342.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.996825098991394, \"fp_rate\": 0.00317492731846869, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9501603245735168, \"recall\": 0.9972468614578247, \"specificity\": 0.996825098991394, \"npv\": 0.9998323917388916, \"accuracy\": 0.9968491792678833, \"f1\": 0.9731343283582089, \"f2\": 0.9874598655116011, \"f0_5\": 0.959218501736009, \"p4\": 0.9855694407692154, \"phi\": 0.9717824525412474}, {\"truth_threshold\": -9.272815098913485, \"match_probability\": 0.0016139980076202692, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107379.0, \"fp\": 340.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9968436360359192, \"fp_rate\": 0.0031563604716211557, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9504373073577881, \"recall\": 0.9972468614578247, \"specificity\": 0.9968436360359192, \"npv\": 0.9998323917388916, \"accuracy\": 0.9968667030334473, \"f1\": 0.9732795939692491, \"f2\": 0.9875196898097661, \"f0_5\": 0.9594443463417506, \"p4\": 0.9856484750652702, \"phi\": 0.9719331768242907}, {\"truth_threshold\": -9.255921530493458, \"match_probability\": 0.0016329775306566235, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107384.0, \"fp\": 335.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9968900680541992, \"fp_rate\": 0.0031099433545023203, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9511305689811707, \"recall\": 0.9972468614578247, \"specificity\": 0.9968900680541992, \"npv\": 0.9998323917388916, \"accuracy\": 0.9969104528427124, \"f1\": 0.9736429478085568, \"f2\": 0.9876692822734572, \"f0_5\": 0.9600094234053831, \"p4\": 0.9858461155329877, \"phi\": 0.9723103587926459}, {\"truth_threshold\": -9.253148953050651, \"match_probability\": 0.0016361136717987703, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6520.0, \"tn\": 107385.0, \"fp\": 334.0, \"fn\": 18.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9972468614578247, \"tn_rate\": 0.9968993663787842, \"fp_rate\": 0.003100660163909197, \"fn_rate\": 0.0027531355153769255, \"precision\": 0.9512693285942078, \"recall\": 0.9972468614578247, \"specificity\": 0.9968993663787842, \"npv\": 0.9998323917388916, \"accuracy\": 0.9969192147254944, \"f1\": 0.973715651135006, \"f2\": 0.9876992062049325, \"f0_5\": 0.960122518701773, \"p4\": 0.985885653011381, \"phi\": 0.9723858258716273}, {\"truth_threshold\": -9.250192189952815, \"match_probability\": 0.0016394647763876742, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107385.0, \"fp\": 334.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9968993663787842, \"fp_rate\": 0.003100660163909197, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9512622356414795, \"recall\": 0.997093915939331, \"specificity\": 0.9968993663787842, \"npv\": 0.9998230934143066, \"accuracy\": 0.9969104528427124, \"f1\": 0.9736390112762303, \"f2\": 0.9875776397515528, \"f0_5\": 0.9600883652430044, \"p4\": 0.9858441050528796, \"phi\": 0.9723026375946182}, {\"truth_threshold\": -9.225858989687957, \"match_probability\": 0.0016673048087397385, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107387.0, \"fp\": 332.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9969179034233093, \"fp_rate\": 0.0030820933170616627, \"fn_rate\": 0.0029060875531286, \"precision\": 0.951539933681488, \"recall\": 0.997093915939331, \"specificity\": 0.9969179034233093, \"npv\": 0.9998230934143066, \"accuracy\": 0.9969279766082764, \"f1\": 0.9737844499215774, \"f2\": 0.9876374875011362, \"f0_5\": 0.9603146544104649, \"p4\": 0.985923194208622, \"phi\": 0.9724536309220256}, {\"truth_threshold\": -9.176603966851824, \"match_probability\": 0.0017251111985396078, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107393.0, \"fp\": 326.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9969736337661743, \"fp_rate\": 0.00302639277651906, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9523739814758301, \"recall\": 0.997093915939331, \"specificity\": 0.9969736337661743, \"npv\": 0.9998230934143066, \"accuracy\": 0.9969804883003235, \"f1\": 0.9742210266756333, \"f2\": 0.98781707427948, \"f0_5\": 0.9609941623916505, \"p4\": 0.9861605368178753, \"phi\": 0.9729070883676475}, {\"truth_threshold\": -9.163356208379042, \"match_probability\": 0.00174099753311101, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107394.0, \"fp\": 325.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9969828724861145, \"fp_rate\": 0.003017109353095293, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9525131583213806, \"recall\": 0.997093915939331, \"specificity\": 0.9969828724861145, \"npv\": 0.9998230934143066, \"accuracy\": 0.9969892501831055, \"f1\": 0.9742938275295172, \"f2\": 0.9878470117590011, \"f0_5\": 0.9611075072241552, \"p4\": 0.9862001048815457, \"phi\": 0.9729827065127915}, {\"truth_threshold\": -9.142728479625125, \"match_probability\": 0.001766024940197526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107396.0, \"fp\": 323.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9970014691352844, \"fp_rate\": 0.002998542506247759, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9527915716171265, \"recall\": 0.997093915939331, \"specificity\": 0.9970014691352844, \"npv\": 0.9998230934143066, \"accuracy\": 0.9970067739486694, \"f1\": 0.974439461883408, \"f2\": 0.9879068921622113, \"f0_5\": 0.9613342771190939, \"p4\": 0.9862792504083547, \"phi\": 0.9731340804330905}, {\"truth_threshold\": -9.124563725381984, \"match_probability\": 0.0017883612480117824, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107397.0, \"fp\": 322.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9970107674598694, \"fp_rate\": 0.0029892590828239918, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9529308676719666, \"recall\": 0.997093915939331, \"specificity\": 0.9970107674598694, \"npv\": 0.9998230934143066, \"accuracy\": 0.9970154762268066, \"f1\": 0.9745122953882951, \"f2\": 0.9879368350862304, \"f0_5\": 0.9614477022004602, \"p4\": 0.9863188278722398, \"phi\": 0.9732097472676675}, {\"truth_threshold\": -9.074739212757446, \"match_probability\": 0.0018510861553537098, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107398.0, \"fp\": 321.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9970200061798096, \"fp_rate\": 0.0029799756594002247, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9530701637268066, \"recall\": 0.997093915939331, \"specificity\": 0.9970200061798096, \"npv\": 0.9998230934143066, \"accuracy\": 0.9970242381095886, \"f1\": 0.9745851397817312, \"f2\": 0.9879667798254123, \"f0_5\": 0.9615611540503864, \"p4\": 0.9863584084702764, \"phi\": 0.9732854303418483}, {\"truth_threshold\": -9.064934913523315, \"match_probability\": 0.0018636851252405628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107402.0, \"fp\": 317.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9970571398735046, \"fp_rate\": 0.0029428419657051563, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9536278247833252, \"recall\": 0.997093915939331, \"specificity\": 0.9970571398735046, \"npv\": 0.9998231530189514, \"accuracy\": 0.9970592856407166, \"f1\": 0.9748766262898161, \"f2\": 0.988086576937068, \"f0_5\": 0.9620152293253055, \"p4\": 0.986516762211407, \"phi\": 0.9735883251529606}, {\"truth_threshold\": -9.064263396895406, \"match_probability\": 0.0018645511799509338, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107405.0, \"fp\": 314.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9970850348472595, \"fp_rate\": 0.002914991695433855, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9540465474128723, \"recall\": 0.997093915939331, \"specificity\": 0.9970850348472595, \"npv\": 0.9998231530189514, \"accuracy\": 0.9970855116844177, \"f1\": 0.9750953556203724, \"f2\": 0.9881764438381082, \"f0_5\": 0.962356067316209, \"p4\": 0.9866355604441495, \"phi\": 0.973815756080603}, {\"truth_threshold\": -9.036067384599967, \"match_probability\": 0.0019012804074484142, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107406.0, \"fp\": 313.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9970942735671997, \"fp_rate\": 0.002905708272010088, \"fn_rate\": 0.0029060875531286, \"precision\": 0.954186201095581, \"recall\": 0.997093915939331, \"specificity\": 0.9970942735671997, \"npv\": 0.9998231530189514, \"accuracy\": 0.9970942735671997, \"f1\": 0.975168287210172, \"f2\": 0.9882064031045356, \"f0_5\": 0.9624697336561744, \"p4\": 0.9866751661288462, \"phi\": 0.9738915692909185}, {\"truth_threshold\": -8.996031721210004, \"match_probability\": 0.001954676420453894, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107407.0, \"fp\": 312.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9971035718917847, \"fp_rate\": 0.002896424848586321, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9543258547782898, \"recall\": 0.997093915939331, \"specificity\": 0.9971035718917847, \"npv\": 0.9998231530189514, \"accuracy\": 0.9971030354499817, \"f1\": 0.9752412297105243, \"f2\": 0.9882363641876118, \"f0_5\": 0.9625834268501565, \"p4\": 0.9867147749510574, \"phi\": 0.9739673987941856}, {\"truth_threshold\": -8.971825509131834, \"match_probability\": 0.001987683839136287, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107411.0, \"fp\": 308.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9971407055854797, \"fp_rate\": 0.002859291387721896, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9548850059509277, \"recall\": 0.997093915939331, \"specificity\": 0.9971407055854797, \"npv\": 0.9998231530189514, \"accuracy\": 0.9971380233764648, \"f1\": 0.9755331088664422, \"f2\": 0.9883562266897117, \"f0_5\": 0.9630384683566744, \"p4\": 0.9868732416225263, \"phi\": 0.9742709689056067}, {\"truth_threshold\": -8.948014802198383, \"match_probability\": 0.002020694589068723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107414.0, \"fp\": 305.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9971685409545898, \"fp_rate\": 0.002831441117450595, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9553048014640808, \"recall\": 0.997093915939331, \"specificity\": 0.9971685409545898, \"npv\": 0.9998231530189514, \"accuracy\": 0.9971643090248108, \"f1\": 0.9757521329142343, \"f2\": 0.9884461426491994, \"f0_5\": 0.9633800319205533, \"p4\": 0.9869921245883592, \"phi\": 0.9744987510875304}, {\"truth_threshold\": -8.909342974040904, \"match_probability\": 0.002075478398691182, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107415.0, \"fp\": 304.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9971778392791748, \"fp_rate\": 0.002822157694026828, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9554448127746582, \"recall\": 0.997093915939331, \"specificity\": 0.9971778392791748, \"npv\": 0.9998231530189514, \"accuracy\": 0.997173011302948, \"f1\": 0.9758251627872165, \"f2\": 0.9884761182714178, \"f0_5\": 0.9634939402896837, \"p4\": 0.9870317585241531, \"phi\": 0.9745748002290905}, {\"truth_threshold\": -8.897270141740329, \"match_probability\": 0.002092882891678228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107416.0, \"fp\": 303.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9971871376037598, \"fp_rate\": 0.0028128742706030607, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9555848836898804, \"recall\": 0.997093915939331, \"specificity\": 0.9971871376037598, \"npv\": 0.9998231530189514, \"accuracy\": 0.99718177318573, \"f1\": 0.9758982035928143, \"f2\": 0.988506095711773, \"f0_5\": 0.9636078755986519, \"p4\": 0.9870713956008292, \"phi\": 0.9746507766489316}, {\"truth_threshold\": -8.858861295936537, \"match_probability\": 0.002149228643245257, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107417.0, \"fp\": 302.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9971964359283447, \"fp_rate\": 0.0028035908471792936, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9557249546051025, \"recall\": 0.997093915939331, \"specificity\": 0.9971964359283447, \"npv\": 0.9998231530189514, \"accuracy\": 0.997190535068512, \"f1\": 0.9759712553334831, \"f2\": 0.9885360749704304, \"f0_5\": 0.9637218378570162, \"p4\": 0.9871110358187619, \"phi\": 0.9747267694212901}, {\"truth_threshold\": -8.82772920848725, \"match_probability\": 0.0021960081708756332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107418.0, \"fp\": 301.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9972056746482849, \"fp_rate\": 0.0027943074237555265, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9558650851249695, \"recall\": 0.997093915939331, \"specificity\": 0.9972056746482849, \"npv\": 0.9998231530189514, \"accuracy\": 0.997199296951294, \"f1\": 0.9760443180116783, \"f2\": 0.9885660560475555, \"f0_5\": 0.9638358270743391, \"p4\": 0.9871506791783259, \"phi\": 0.9748027785521389}, {\"truth_threshold\": -8.797632384416737, \"match_probability\": 0.0022421976551964713, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107420.0, \"fp\": 299.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9972242712974548, \"fp_rate\": 0.0027757405769079924, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9561455249786377, \"recall\": 0.997093915939331, \"specificity\": 0.9972242712974548, \"npv\": 0.9998231530189514, \"accuracy\": 0.9972168207168579, \"f1\": 0.9761904761904762, \"f2\": 0.9886260236578708, \"f0_5\": 0.9640638864241349, \"p4\": 0.9872299753238458, \"phi\": 0.974954845913215}, {\"truth_threshold\": -8.791318245485298, \"match_probability\": 0.0022520102771955005, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107421.0, \"fp\": 298.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9972335696220398, \"fp_rate\": 0.0027664571534842253, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9562857747077942, \"recall\": 0.997093915939331, \"specificity\": 0.9972335696220398, \"npv\": 0.9998231530189514, \"accuracy\": 0.9972255825996399, \"f1\": 0.976263571695994, \"f2\": 0.9886560101913919, \"f0_5\": 0.9641779565757558, \"p4\": 0.9872696281105512, \"phi\": 0.9750309041554037}, {\"truth_threshold\": -8.731311246216027, \"match_probability\": 0.002347430477385403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107423.0, \"fp\": 296.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9972521066665649, \"fp_rate\": 0.002747890306636691, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9565663933753967, \"recall\": 0.997093915939331, \"specificity\": 0.9972521066665649, \"npv\": 0.9998231530189514, \"accuracy\": 0.9972430467605591, \"f1\": 0.9764097955515615, \"f2\": 0.9887159887159888, \"f0_5\": 0.964406177880348, \"p4\": 0.9873489431137268, \"phi\": 0.9751831589163358}, {\"truth_threshold\": -8.728884508821485, \"match_probability\": 0.002351373088147248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107424.0, \"fp\": 295.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.9972614049911499, \"fp_rate\": 0.002738606883212924, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9567067623138428, \"recall\": 0.997093915939331, \"specificity\": 0.9972614049911499, \"npv\": 0.9998231530189514, \"accuracy\": 0.9972518086433411, \"f1\": 0.9764829239065309, \"f2\": 0.9887459807073955, \"f0_5\": 0.9645203290524945, \"p4\": 0.9873886053309467, \"phi\": 0.9752592663298572}, {\"truth_threshold\": -8.725482598660902, \"match_probability\": 0.0023569111420969915, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107428.0, \"fp\": 291.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.997298538684845, \"fp_rate\": 0.0027014731895178556, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9572687149047852, \"recall\": 0.997093915939331, \"specificity\": 0.997298538684845, \"npv\": 0.9998231530189514, \"accuracy\": 0.9972867965698242, \"f1\": 0.9767755468984117, \"f2\": 0.9888659668709423, \"f0_5\": 0.9649772040973414, \"p4\": 0.9875472856461242, \"phi\": 0.9755639492017878}, {\"truth_threshold\": -8.7124999787346, \"match_probability\": 0.0023781657209291113, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6519.0, \"tn\": 107432.0, \"fp\": 287.0, \"fn\": 19.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.997093915939331, \"tn_rate\": 0.99733567237854, \"fp_rate\": 0.002664339728653431, \"fn_rate\": 0.0029060875531286, \"precision\": 0.9578313231468201, \"recall\": 0.997093915939331, \"specificity\": 0.99733567237854, \"npv\": 0.9998231530189514, \"accuracy\": 0.9973218441009521, \"f1\": 0.977068345323741, \"f2\": 0.9889859821591116, \"f0_5\": 0.9654345121734494, \"p4\": 0.9877060162933853, \"phi\": 0.9758688057347173}, {\"truth_threshold\": -8.706858202491487, \"match_probability\": 0.0023874616923776283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107432.0, \"fp\": 287.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.99733567237854, \"fp_rate\": 0.002664339728653431, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9578065276145935, \"recall\": 0.9964821338653564, \"specificity\": 0.99733567237854, \"npv\": 0.9997859597206116, \"accuracy\": 0.9972867965698242, \"f1\": 0.9767616191904048, \"f2\": 0.9884991199854343, \"f0_5\": 0.9652995910626445, \"p4\": 0.9875401934973939, \"phi\": 0.9755370156258102}, {\"truth_threshold\": -8.700607930021873, \"match_probability\": 0.0023978026157386503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107435.0, \"fp\": 284.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9973635077476501, \"fp_rate\": 0.0026364894583821297, \"fn_rate\": 0.003517895471304655, \"precision\": 0.958229124546051, \"recall\": 0.9964821338653564, \"specificity\": 0.9973635077476501, \"npv\": 0.9997859597206116, \"accuracy\": 0.9973130822181702, \"f1\": 0.9769813301342131, \"f2\": 0.9885891171739856, \"f0_5\": 0.965642971482777, \"p4\": 0.987659303701267, \"phi\": 0.9757658967405255}, {\"truth_threshold\": -8.685144132081424, \"match_probability\": 0.00242357952511785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107441.0, \"fp\": 278.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9974192380905151, \"fp_rate\": 0.002580788917839527, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9590755105018616, \"recall\": 0.9964821338653564, \"specificity\": 0.9974192380905151, \"npv\": 0.9997859597206116, \"accuracy\": 0.9973655939102173, \"f1\": 0.9774210486835196, \"f2\": 0.9887691607224162, \"f0_5\": 0.96633046573717, \"p4\": 0.9878976091825549, \"phi\": 0.9762241933714847}, {\"truth_threshold\": -8.67330321284064, \"match_probability\": 0.00244350410215533, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107443.0, \"fp\": 276.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9974377751350403, \"fp_rate\": 0.002562222070991993, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9593579769134521, \"recall\": 0.9964821338653564, \"specificity\": 0.9974377751350403, \"npv\": 0.9997859597206116, \"accuracy\": 0.9973831176757812, \"f1\": 0.9775677095055894, \"f2\": 0.9888291898127068, \"f0_5\": 0.9665598480802327, \"p4\": 0.9879770695609955, \"phi\": 0.9763770612463034}, {\"truth_threshold\": -8.60202822927106, \"match_probability\": 0.0025669371746505384, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107445.0, \"fp\": 274.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9974563717842102, \"fp_rate\": 0.0025436552241444588, \"fn_rate\": 0.003517895471304655, \"precision\": 0.959640622138977, \"recall\": 0.9964821338653564, \"specificity\": 0.9974563717842102, \"npv\": 0.9997859597206116, \"accuracy\": 0.9974005818367004, \"f1\": 0.9777144143468147, \"f2\": 0.9888892261922831, \"f0_5\": 0.966789339348252, \"p4\": 0.9880565425534606, \"phi\": 0.9765300845207384}, {\"truth_threshold\": -8.596936538285629, \"match_probability\": 0.002575989270813655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107446.0, \"fp\": 273.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9974656105041504, \"fp_rate\": 0.0025343718007206917, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9597819447517395, \"recall\": 0.9964821338653564, \"specificity\": 0.9974656105041504, \"npv\": 0.9997859597206116, \"accuracy\": 0.9974093437194824, \"f1\": 0.9777877832808044, \"f2\": 0.9889192471159685, \"f0_5\": 0.9669041258533689, \"p4\": 0.988096283780894, \"phi\": 0.9766065763314956}, {\"truth_threshold\": -8.582065246369787, \"match_probability\": 0.00260261041465252, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107449.0, \"fp\": 270.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9974935054779053, \"fp_rate\": 0.0025065215304493904, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9602063298225403, \"recall\": 0.9964821338653564, \"specificity\": 0.9974935054779053, \"npv\": 0.9997860193252563, \"accuracy\": 0.9974356293678284, \"f1\": 0.9780079561660286, \"f2\": 0.9890093208246046, \"f0_5\": 0.9672486489696538, \"p4\": 0.988215526392517, \"phi\": 0.9768361510721967}, {\"truth_threshold\": -8.577960469309229, \"match_probability\": 0.0026100065897260226, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107450.0, \"fp\": 269.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9975027441978455, \"fp_rate\": 0.0024972381070256233, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9603478908538818, \"recall\": 0.9964821338653564, \"specificity\": 0.9975027441978455, \"npv\": 0.9997860193252563, \"accuracy\": 0.9974443316459656, \"f1\": 0.9780813691637892, \"f2\": 0.9890393490405636, \"f0_5\": 0.9673635445744492, \"p4\": 0.9882552802407552, \"phi\": 0.9769127984226711}, {\"truth_threshold\": -8.576623628274088, \"match_probability\": 0.002612419893649565, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107452.0, \"fp\": 267.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9975213408470154, \"fp_rate\": 0.002478671260178089, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9606310725212097, \"recall\": 0.9964821338653564, \"specificity\": 0.9975213408470154, \"npv\": 0.9997860193252563, \"accuracy\": 0.9974618554115295, \"f1\": 0.9782282282282282, \"f2\": 0.9890994109430983, \"f0_5\": 0.9675934176914395, \"p4\": 0.9883347974060386, \"phi\": 0.9770659642293829}, {\"truth_threshold\": -8.575261319708275, \"match_probability\": 0.0026148814618830968, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107455.0, \"fp\": 264.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9975491762161255, \"fp_rate\": 0.0024508212227374315, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9610562324523926, \"recall\": 0.9964821338653564, \"specificity\": 0.9975491762161255, \"npv\": 0.9997860193252563, \"accuracy\": 0.9974881410598755, \"f1\": 0.9784485995344296, \"f2\": 0.9891895174759345, \"f0_5\": 0.9679384322814524, \"p4\": 0.9884540968316374, \"phi\": 0.9772958373335713}, {\"truth_threshold\": -8.57524146718631, \"match_probability\": 0.002614917350689023, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107457.0, \"fp\": 262.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9975677728652954, \"fp_rate\": 0.0024322543758898973, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9613398313522339, \"recall\": 0.9964821338653564, \"specificity\": 0.9975677728652954, \"npv\": 0.9997860193252563, \"accuracy\": 0.9975056052207947, \"f1\": 0.9785955689072474, \"f2\": 0.9892495976191199, \"f0_5\": 0.9681685787314985, \"p4\": 0.9885336455715528, \"phi\": 0.9774492584272796}, {\"truth_threshold\": -8.558959507379173, \"match_probability\": 0.0026445174432722478, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107458.0, \"fp\": 261.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9975770115852356, \"fp_rate\": 0.0024229709524661303, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9614816904067993, \"recall\": 0.9964821338653564, \"specificity\": 0.9975770115852356, \"npv\": 0.9997860193252563, \"accuracy\": 0.9975143671035767, \"f1\": 0.97866907015172, \"f2\": 0.9892796404275996, \"f0_5\": 0.9682836930027942, \"p4\": 0.9885734246794972, \"phi\": 0.9775259492202605}, {\"truth_threshold\": -8.552188037635391, \"match_probability\": 0.002656925935751939, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107461.0, \"fp\": 258.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9976049065589905, \"fp_rate\": 0.002395120682194829, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9619075655937195, \"recall\": 0.9964821338653564, \"specificity\": 0.9976049065589905, \"npv\": 0.9997860193252563, \"accuracy\": 0.9975406527519226, \"f1\": 0.9788896401472467, \"f2\": 0.9893697798025817, \"f0_5\": 0.9686292001189414, \"p4\": 0.9886927809598062, \"phi\": 0.9777561213464122}, {\"truth_threshold\": -8.539601224660828, \"match_probability\": 0.002680145337986926, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107464.0, \"fp\": 255.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9976327419281006, \"fp_rate\": 0.0023672704119235277, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9623337984085083, \"recall\": 0.9964821338653564, \"specificity\": 0.9976327419281006, \"npv\": 0.9997860193252563, \"accuracy\": 0.9975668787956238, \"f1\": 0.9791103095882177, \"f2\": 0.9894599356053703, \"f0_5\": 0.9689749538937474, \"p4\": 0.988812165682758, \"phi\": 0.97798653262215}, {\"truth_threshold\": -8.477889358704516, \"match_probability\": 0.0027969493483470274, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107466.0, \"fp\": 253.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9976512789726257, \"fp_rate\": 0.0023487035650759935, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9626182317733765, \"recall\": 0.9964821338653564, \"specificity\": 0.9976512789726257, \"npv\": 0.9997860193252563, \"accuracy\": 0.9975844025611877, \"f1\": 0.9792574778295505, \"f2\": 0.9895200486026732, \"f0_5\": 0.9692055935733412, \"p4\": 0.9888917713045632, \"phi\": 0.9781401638271681}, {\"truth_threshold\": -8.456385354510674, \"match_probability\": 0.0028388321236341033, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107468.0, \"fp\": 251.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9976698756217957, \"fp_rate\": 0.0023301367182284594, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9629027247428894, \"recall\": 0.9964821338653564, \"specificity\": 0.9976698756217957, \"npv\": 0.9997860193252563, \"accuracy\": 0.9976019263267517, \"f1\": 0.9794046903187011, \"f2\": 0.9895801689045507, \"f0_5\": 0.969436343074817, \"p4\": 0.9889713895750983, \"phi\": 0.9782938617099786}, {\"truth_threshold\": -8.424973487408446, \"match_probability\": 0.0029011386700222384, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107472.0, \"fp\": 247.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9977070093154907, \"fp_rate\": 0.002293003024533391, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9634723663330078, \"recall\": 0.9964821338653564, \"specificity\": 0.9977070093154907, \"npv\": 0.9997860193252563, \"accuracy\": 0.9976369142532349, \"f1\": 0.9796992481203007, \"f2\": 0.9897004314273561, \"f0_5\": 0.9698981718573215, \"p4\": 0.9891306640744547, \"phi\": 0.978601547155336}, {\"truth_threshold\": -8.41714442011168, \"match_probability\": 0.0029168790156531197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107473.0, \"fp\": 246.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9977163076400757, \"fp_rate\": 0.002283719601109624, \"fn_rate\": 0.003517895471304655, \"precision\": 0.963614821434021, \"recall\": 0.9964821338653564, \"specificity\": 0.9977163076400757, \"npv\": 0.9997860193252563, \"accuracy\": 0.9976456761360168, \"f1\": 0.9797729152567862, \"f2\": 0.9897305016254975, \"f0_5\": 0.9700136978143052, \"p4\": 0.9891704906094758, \"phi\": 0.9786784879108311}, {\"truth_threshold\": -8.401861447776593, \"match_probability\": 0.0029478512063911898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107474.0, \"fp\": 245.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9977255463600159, \"fp_rate\": 0.002274436177685857, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9637573957443237, \"recall\": 0.9964821338653564, \"specificity\": 0.9977255463600159, \"npv\": 0.9997860193252563, \"accuracy\": 0.9976544380187988, \"f1\": 0.9798465934727026, \"f2\": 0.9897605736509479, \"f0_5\": 0.9701292512954911, \"p4\": 0.9892103203093264, \"phi\": 0.9787554453788047}, {\"truth_threshold\": -8.366314429436777, \"match_probability\": 0.003021164289216595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107476.0, \"fp\": 243.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9977441430091858, \"fp_rate\": 0.0022558693308383226, \"fn_rate\": 0.003517895471304655, \"precision\": 0.964042603969574, \"recall\": 0.9964821338653564, \"specificity\": 0.9977441430091858, \"npv\": 0.9997860193252563, \"accuracy\": 0.997671902179718, \"f1\": 0.9799939831528279, \"f2\": 0.9898207231844424, \"f0_5\": 0.9703604408698242, \"p4\": 0.9892899892050293, \"phi\": 0.9789094999514877}, {\"truth_threshold\": -8.346068395398644, \"match_probability\": 0.0030637298205002674, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107479.0, \"fp\": 240.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9977719783782959, \"fp_rate\": 0.002228019293397665, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9644707441329956, \"recall\": 0.9964821338653564, \"specificity\": 0.9977719783782959, \"npv\": 0.9997860789299011, \"accuracy\": 0.997698187828064, \"f1\": 0.9802151508312645, \"f2\": 0.989910961193667, \"f0_5\": 0.9707074319089338, \"p4\": 0.9894095162942652, \"phi\": 0.9791405731148257}, {\"truth_threshold\": -8.29592510154538, \"match_probability\": 0.0031717433857848367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107481.0, \"fp\": 238.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9977905750274658, \"fp_rate\": 0.002209452446550131, \"fn_rate\": 0.003517895471304655, \"precision\": 0.964756429195404, \"recall\": 0.9964821338653564, \"specificity\": 0.9977905750274658, \"npv\": 0.9997860789299011, \"accuracy\": 0.9977156519889832, \"f1\": 0.980362651418253, \"f2\": 0.9899711290077495, \"f0_5\": 0.9709388971684053, \"p4\": 0.9894892168552941, \"phi\": 0.9792947056275276}, {\"truth_threshold\": -8.269452890184189, \"match_probability\": 0.0032302896401549216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107482.0, \"fp\": 237.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.997799813747406, \"fp_rate\": 0.0022001690231263638, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9648993015289307, \"recall\": 0.9964821338653564, \"specificity\": 0.997799813747406, \"npv\": 0.9997860789299011, \"accuracy\": 0.9977244138717651, \"f1\": 0.9804364183596689, \"f2\": 0.9900012156576709, \"f0_5\": 0.9710546711977583, \"p4\": 0.9895290718874062, \"phi\": 0.9793718865354654}, {\"truth_threshold\": -8.259066127043797, \"match_probability\": 0.0032535542702133912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107483.0, \"fp\": 236.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.997809112071991, \"fp_rate\": 0.0021908855997025967, \"fn_rate\": 0.003517895471304655, \"precision\": 0.965042233467102, \"recall\": 0.9964821338653564, \"specificity\": 0.997809112071991, \"npv\": 0.9997860789299011, \"accuracy\": 0.9977331757545471, \"f1\": 0.9805101964030402, \"f2\": 0.990031304136401, \"f0_5\": 0.9711704728400214, \"p4\": 0.9895689300877554, \"phi\": 0.9794489947057415}, {\"truth_threshold\": -8.23618810871713, \"match_probability\": 0.0033053879529084543, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107485.0, \"fp\": 234.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9978277087211609, \"fp_rate\": 0.0021723187528550625, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9653282165527344, \"recall\": 0.9964821338653564, \"specificity\": 0.9978277087211609, \"npv\": 0.9997860789299011, \"accuracy\": 0.9977506995201111, \"f1\": 0.9806577858056748, \"f2\": 0.990091486580955, \"f0_5\": 0.9714021590028031, \"p4\": 0.98964865599468, \"phi\": 0.9796032613751525}, {\"truth_threshold\": -8.233513448806184, \"match_probability\": 0.003311501292970908, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107486.0, \"fp\": 233.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9978369474411011, \"fp_rate\": 0.0021630353294312954, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9654712677001953, \"recall\": 0.9964821338653564, \"specificity\": 0.9978369474411011, \"npv\": 0.9997860789299011, \"accuracy\": 0.9977594614028931, \"f1\": 0.9807315971699533, \"f2\": 0.9901215805471124, \"f0_5\": 0.9715180435430958, \"p4\": 0.9896885237020135, \"phi\": 0.9796804198866742}, {\"truth_threshold\": -8.233486246830335, \"match_probability\": 0.0033115635250563326, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107496.0, \"fp\": 223.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9979298114776611, \"fp_rate\": 0.0020702010951936245, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9669041037559509, \"recall\": 0.9964821338653564, \"specificity\": 0.9979298114776611, \"npv\": 0.9997860789299011, \"accuracy\": 0.9978469610214233, \"f1\": 0.981470322386261, \"f2\": 0.9904226208574035, \"f0_5\": 0.9726784114661093, \"p4\": 0.9900873751743424, \"phi\": 0.980453108828607}, {\"truth_threshold\": -8.228188013963473, \"match_probability\": 0.0033237069566224324, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107497.0, \"fp\": 222.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9979391098022461, \"fp_rate\": 0.0020609176717698574, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9670476317405701, \"recall\": 0.9964821338653564, \"specificity\": 0.9979391098022461, \"npv\": 0.9997860789299011, \"accuracy\": 0.9978557229042053, \"f1\": 0.9815442561205273, \"f2\": 0.9904527349569765, \"f0_5\": 0.9727946007286628, \"p4\": 0.9901272777698221, \"phi\": 0.9805304524150786}, {\"truth_threshold\": -8.201622168678695, \"match_probability\": 0.003385267695374315, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107505.0, \"fp\": 214.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9980133771896362, \"fp_rate\": 0.0019866505172103643, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9681973457336426, \"recall\": 0.9964821338653564, \"specificity\": 0.9980133771896362, \"npv\": 0.9997860789299011, \"accuracy\": 0.9979257583618164, \"f1\": 0.982136127232984, \"f2\": 0.9906937136948389, \"f0_5\": 0.9737251150833981, \"p4\": 0.9904466128269451, \"phi\": 0.9811498982895867}, {\"truth_threshold\": -8.173570908349902, \"match_probability\": 0.003451504331900555, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107506.0, \"fp\": 213.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9980226159095764, \"fp_rate\": 0.0019773670937865973, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9683412313461304, \"recall\": 0.9964821338653564, \"specificity\": 0.9980226159095764, \"npv\": 0.9997860789299011, \"accuracy\": 0.9979344606399536, \"f1\": 0.9822101613146389, \"f2\": 0.9907238442822385, \"f0_5\": 0.9738415545590433, \"p4\": 0.9904865440014468, \"phi\": 0.9812273938579186}, {\"truth_threshold\": -8.160220479810013, \"match_probability\": 0.0034834803648079223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107510.0, \"fp\": 209.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9980597496032715, \"fp_rate\": 0.001940233400091529, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9689173102378845, \"recall\": 0.9964821338653564, \"specificity\": 0.9980597496032715, \"npv\": 0.9997861385345459, \"accuracy\": 0.9979695081710815, \"f1\": 0.9825064092896999, \"f2\": 0.9908443849616742, \"f0_5\": 0.9743075910749537, \"p4\": 0.9906463004767333, \"phi\": 0.9815376350548433}, {\"truth_threshold\": -8.093725068023105, \"match_probability\": 0.003647196186907182, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107513.0, \"fp\": 206.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9980876445770264, \"fp_rate\": 0.0019123831298202276, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9693498015403748, \"recall\": 0.9964821338653564, \"specificity\": 0.9980876445770264, \"npv\": 0.9997861385345459, \"accuracy\": 0.9979957342147827, \"f1\": 0.9827287125725922, \"f2\": 0.9909348097222644, \"f0_5\": 0.9746574112859793, \"p4\": 0.990766151209996, \"phi\": 0.9817704265811736}, {\"truth_threshold\": -7.977514510437223, \"match_probability\": 0.003951929061222802, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107514.0, \"fp\": 205.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9980968832969666, \"fp_rate\": 0.0019030997063964605, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9694940447807312, \"recall\": 0.9964821338653564, \"specificity\": 0.9980968832969666, \"npv\": 0.9997861385345459, \"accuracy\": 0.9980044960975647, \"f1\": 0.9828028360235329, \"f2\": 0.99096495497688, \"f0_5\": 0.9747740738524149, \"p4\": 0.9908061078139323, \"phi\": 0.981848147382431}, {\"truth_threshold\": -7.940963787042595, \"match_probability\": 0.0040529194136575885, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107515.0, \"fp\": 204.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9981061816215515, \"fp_rate\": 0.0018938162829726934, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9696383476257324, \"recall\": 0.9964821338653564, \"specificity\": 0.9981061816215515, \"npv\": 0.9997861385345459, \"accuracy\": 0.9980132579803467, \"f1\": 0.9828769706570114, \"f2\": 0.9909951020656506, \"f0_5\": 0.9748907643502723, \"p4\": 0.9908460675982608, \"phi\": 0.9819257954461919}, {\"truth_threshold\": -7.923956324158422, \"match_probability\": 0.004100783607109089, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107521.0, \"fp\": 198.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9981619119644165, \"fp_rate\": 0.0018381158588454127, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9705049991607666, \"recall\": 0.9964821338653564, \"specificity\": 0.9981619119644165, \"npv\": 0.9997861385345459, \"accuracy\": 0.9980657696723938, \"f1\": 0.9833220134329484, \"f2\": 0.9911760231249049, \"f0_5\": 0.975591494459419, \"p4\": 0.9910858931138017, \"phi\": 0.9823921302577563}, {\"truth_threshold\": -7.897861450673367, \"match_probability\": 0.004175319247150784, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107522.0, \"fp\": 197.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9981711506843567, \"fp_rate\": 0.0018288324354216456, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9706496000289917, \"recall\": 0.9964821338653564, \"specificity\": 0.9981711506843567, \"npv\": 0.9997861385345459, \"accuracy\": 0.9980745315551758, \"f1\": 0.9833962264150944, \"f2\": 0.9912061830574489, \"f0_5\": 0.9757083807584017, \"p4\": 0.9911258751715435, \"phi\": 0.9824698972778632}, {\"truth_threshold\": -7.894778422350502, \"match_probability\": 0.0041842140390976525, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107526.0, \"fp\": 193.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982082843780518, \"fp_rate\": 0.0017916987417265773, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9712283611297607, \"recall\": 0.9964821338653564, \"specificity\": 0.9982082843780518, \"npv\": 0.9997861385345459, \"accuracy\": 0.9981095194816589, \"f1\": 0.983693190397101, \"f2\": 0.9913268411442483, \"f0_5\": 0.9761762061732094, \"p4\": 0.9912858352407323, \"phi\": 0.9827811356025277}, {\"truth_threshold\": -7.827448343305075, \"match_probability\": 0.004383242083072091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107528.0, \"fp\": 191.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982268810272217, \"fp_rate\": 0.001773131894879043, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9715180397033691, \"recall\": 0.9964821338653564, \"specificity\": 0.9982268810272217, \"npv\": 0.9997861385345459, \"accuracy\": 0.9981270432472229, \"f1\": 0.9838417396556931, \"f2\": 0.9913871812039686, \"f0_5\": 0.9764102871530483, \"p4\": 0.9913658343836002, \"phi\": 0.982936946799117}, {\"truth_threshold\": -7.801536838872653, \"match_probability\": 0.004462323993981772, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107529.0, \"fp\": 190.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982361793518066, \"fp_rate\": 0.0017638485878705978, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9716629385948181, \"recall\": 0.9964821338653564, \"specificity\": 0.9982361793518066, \"npv\": 0.9997861385345459, \"accuracy\": 0.9981358051300049, \"f1\": 0.9839160311107755, \"f2\": 0.9914173539884956, \"f0_5\": 0.9765273697463877, \"p4\": 0.9914058387334379, \"phi\": 0.983014833085029}, {\"truth_threshold\": -7.796104971349061, \"match_probability\": 0.004479081290500799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107530.0, \"fp\": 189.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982454180717468, \"fp_rate\": 0.0017545651644468307, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9718078970909119, \"recall\": 0.9964821338653564, \"specificity\": 0.9982454180717468, \"npv\": 0.9997861385345459, \"accuracy\": 0.9981445074081421, \"f1\": 0.9839903337864371, \"f2\": 0.9914475286096908, \"f0_5\": 0.9766444804221383, \"p4\": 0.9914458462693871, \"phi\": 0.9830927364333442}, {\"truth_threshold\": -7.789580843742577, \"match_probability\": 0.004499291032775223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107531.0, \"fp\": 188.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982547163963318, \"fp_rate\": 0.0017452817410230637, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9719528555870056, \"recall\": 0.9964821338653564, \"specificity\": 0.9982547163963318, \"npv\": 0.9997861385345459, \"accuracy\": 0.9981532692909241, \"f1\": 0.9840646476852202, \"f2\": 0.9914777050677218, \"f0_5\": 0.9767616191904048, \"p4\": 0.9914858569918297, \"phi\": 0.9831706568504032}, {\"truth_threshold\": -7.78130712105411, \"match_probability\": 0.004525051086092615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107533.0, \"fp\": 186.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982733130455017, \"fp_rate\": 0.0017267148941755295, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9722429513931274, \"recall\": 0.9964821338653564, \"specificity\": 0.9982733130455017, \"npv\": 0.9997861385345459, \"accuracy\": 0.998170793056488, \"f1\": 0.9842133091623234, \"f2\": 0.9915380634949624, \"f0_5\": 0.9769959810449284, \"p4\": 0.9915658879977217, \"phi\": 0.9833266387467219}, {\"truth_threshold\": -7.773216442469588, \"match_probability\": 0.004550383204970898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107535.0, \"fp\": 184.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9982918500900269, \"fp_rate\": 0.0017081480473279953, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9725332260131836, \"recall\": 0.9964821338653564, \"specificity\": 0.9982918500900269, \"npv\": 0.9997861385345459, \"accuracy\": 0.998188316822052, \"f1\": 0.9843620155624386, \"f2\": 0.9915984292715595, \"f0_5\": 0.9772304553908921, \"p4\": 0.9916459317541696, \"phi\": 0.9834825991761857}, {\"truth_threshold\": -7.757274898600567, \"match_probability\": 0.004600710407299813, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107542.0, \"fp\": 177.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.998356819152832, \"fp_rate\": 0.0016431641997769475, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9735504984855652, \"recall\": 0.9964821338653564, \"specificity\": 0.998356819152832, \"npv\": 0.9997861981391907, \"accuracy\": 0.9982495307922363, \"f1\": 0.9848828420256992, \"f2\": 0.991809767385215, \"f0_5\": 0.9780520026421666, \"p4\": 0.9919261853564983, \"phi\": 0.9840290895665635}, {\"truth_threshold\": -7.743384078516601, \"match_probability\": 0.004645014994544381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107543.0, \"fp\": 176.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.998366117477417, \"fp_rate\": 0.0016338807763531804, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9736959934234619, \"recall\": 0.9964821338653564, \"specificity\": 0.998366117477417, \"npv\": 0.9997861981391907, \"accuracy\": 0.9982582926750183, \"f1\": 0.984957290800514, \"f2\": 0.991839965898365, \"f0_5\": 0.9781694793105519, \"p4\": 0.99196623434666, \"phi\": 0.9841072153169901}, {\"truth_threshold\": -7.7200743314580835, \"match_probability\": 0.004720317334407411, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107544.0, \"fp\": 175.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.998375415802002, \"fp_rate\": 0.0016245973529294133, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9738415479660034, \"recall\": 0.9964821338653564, \"specificity\": 0.998375415802002, \"npv\": 0.9997861981391907, \"accuracy\": 0.9982670545578003, \"f1\": 0.9850317508315694, \"f2\": 0.9918701662505328, \"f0_5\": 0.9782869842032554, \"p4\": 0.9920062865282834, \"phi\": 0.9841853582189043}, {\"truth_threshold\": -7.690185677212792, \"match_probability\": 0.004818653145183162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107545.0, \"fp\": 174.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9983847141265869, \"fp_rate\": 0.0016153139295056462, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9739871621131897, \"recall\": 0.9964821338653564, \"specificity\": 0.9983847141265869, \"npv\": 0.9997861981391907, \"accuracy\": 0.9982758164405823, \"f1\": 0.9851062221214183, \"f2\": 0.9919003684418867, \"f0_5\": 0.97840451733045, \"p4\": 0.9920463419017512, \"phi\": 0.984263518278694}, {\"truth_threshold\": -7.632434262362866, \"match_probability\": 0.005014470856644323, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107546.0, \"fp\": 173.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9983939528465271, \"fp_rate\": 0.0016060305060818791, \"fn_rate\": 0.003517895471304655, \"precision\": 0.974132776260376, \"recall\": 0.9964821338653564, \"specificity\": 0.9983939528465271, \"npv\": 0.9997861981391907, \"accuracy\": 0.9982845783233643, \"f1\": 0.9851807046726145, \"f2\": 0.9919305724725944, \"f0_5\": 0.978522078702313, \"p4\": 0.9920864004674461, \"phi\": 0.9843417854151653}, {\"truth_threshold\": -7.597662041362666, \"match_probability\": 0.005136170946208646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107547.0, \"fp\": 172.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9984032511711121, \"fp_rate\": 0.001596747082658112, \"fn_rate\": 0.003517895471304655, \"precision\": 0.974278450012207, \"recall\": 0.9964821338653564, \"specificity\": 0.9984032511711121, \"npv\": 0.9997861981391907, \"accuracy\": 0.9982933402061462, \"f1\": 0.9852551984877127, \"f2\": 0.991960778342824, \"f0_5\": 0.9786396683290273, \"p4\": 0.992126462225751, \"phi\": 0.9844199798161879}, {\"truth_threshold\": -7.5946406332604175, \"match_probability\": 0.005146883379531986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107555.0, \"fp\": 164.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9984775185585022, \"fp_rate\": 0.0015224798116832972, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9754454493522644, \"recall\": 0.9964821338653564, \"specificity\": 0.9984775185585022, \"npv\": 0.9997861981391907, \"accuracy\": 0.9983633160591125, \"f1\": 0.9858515548157676, \"f2\": 0.9922024915476226, \"f0_5\": 0.9795814037409033, \"p4\": 0.9924470712720928, \"phi\": 0.9850462439058996}, {\"truth_threshold\": -7.440313632999358, \"match_probability\": 0.0057246519976944885, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107558.0, \"fp\": 161.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985053539276123, \"fp_rate\": 0.0014946295414119959, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9758837819099426, \"recall\": 0.9964821338653564, \"specificity\": 0.9985053539276123, \"npv\": 0.9997861981391907, \"accuracy\": 0.9983896017074585, \"f1\": 0.9860753746026941, \"f2\": 0.9922931643718776, \"f0_5\": 0.9799350219601709, \"p4\": 0.9925673523888789, \"phi\": 0.9852813433115631}, {\"truth_threshold\": -7.409537307762541, \"match_probability\": 0.005847363399379186, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107560.0, \"fp\": 159.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985239505767822, \"fp_rate\": 0.0014760626945644617, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9761762022972107, \"recall\": 0.9964821338653564, \"specificity\": 0.9985239505767822, \"npv\": 0.9997861981391907, \"accuracy\": 0.9984071254730225, \"f1\": 0.9862246442627914, \"f2\": 0.9923536221288003, \"f0_5\": 0.980170909309743, \"p4\": 0.9926475557854684, \"phi\": 0.9854382524770711}, {\"truth_threshold\": -7.404284370584293, \"match_probability\": 0.005868567626348278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107561.0, \"fp\": 158.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985332489013672, \"fp_rate\": 0.0014667792711406946, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9763224720954895, \"recall\": 0.9964821338653564, \"specificity\": 0.9985332489013672, \"npv\": 0.9997861981391907, \"accuracy\": 0.9984158277511597, \"f1\": 0.9862992960411778, \"f2\": 0.9923838537699924, \"f0_5\": 0.9802888955762865, \"p4\": 0.9926876622805334, \"phi\": 0.985516687953334}, {\"truth_threshold\": -7.385331095684371, \"match_probability\": 0.0059457126318441895, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107562.0, \"fp\": 157.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985424876213074, \"fp_rate\": 0.0014574958477169275, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9764688014984131, \"recall\": 0.9964821338653564, \"specificity\": 0.9985424876213074, \"npv\": 0.9997861981391907, \"accuracy\": 0.9984245896339417, \"f1\": 0.9863739591218774, \"f2\": 0.9924140872532293, \"f0_5\": 0.9804069102510082, \"p4\": 0.9927277719739568, \"phi\": 0.9855951406965842}, {\"truth_threshold\": -7.37867983513451, \"match_probability\": 0.005973023342853582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107563.0, \"fp\": 156.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985517859458923, \"fp_rate\": 0.0014482124242931604, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9766151905059814, \"recall\": 0.9964821338653564, \"specificity\": 0.9985517859458923, \"npv\": 0.9997861981391907, \"accuracy\": 0.9984333515167236, \"f1\": 0.986448633507457, \"f2\": 0.9924443225786795, \"f0_5\": 0.9805249533441696, \"p4\": 0.9927678848661221, \"phi\": 0.9856736107132699}, {\"truth_threshold\": -7.3252142373366995, \"match_probability\": 0.006197136095965551, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107564.0, \"fp\": 155.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985610842704773, \"fp_rate\": 0.0014389291172847152, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9767616391181946, \"recall\": 0.9964821338653564, \"specificity\": 0.9985610842704773, \"npv\": 0.9997861981391907, \"accuracy\": 0.9984421133995056, \"f1\": 0.9865233192004845, \"f2\": 0.9924745597465114, \"f0_5\": 0.9806430248660365, \"p4\": 0.9928080009574134, \"phi\": 0.985752098009843}, {\"truth_threshold\": -7.250192189952814, \"match_probability\": 0.006525762830650964, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107565.0, \"fp\": 154.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9985703825950623, \"fp_rate\": 0.001429645693860948, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9769080877304077, \"recall\": 0.9964821338653564, \"specificity\": 0.9985703825950623, \"npv\": 0.9997861981391907, \"accuracy\": 0.9984508752822876, \"f1\": 0.9865980162035284, \"f2\": 0.9925047987568935, \"f0_5\": 0.9807611248268803, \"p4\": 0.9928481202482144, \"phi\": 0.9858306926252116}, {\"truth_threshold\": -7.2455238013649055, \"match_probability\": 0.006546775151398047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107571.0, \"fp\": 148.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986260533332825, \"fp_rate\": 0.0013739451533183455, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9777877926826477, \"recall\": 0.9964821338653564, \"specificity\": 0.9986260533332825, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985033869743347, \"f1\": 0.98704643587607, \"f2\": 0.9926862715221697, \"f0_5\": 0.981470322386261, \"p4\": 0.9930889032042277, \"phi\": 0.9863020835358257}, {\"truth_threshold\": -7.22550219707023, \"match_probability\": 0.006637656861310822, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107572.0, \"fp\": 147.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986353516578674, \"fp_rate\": 0.0013646617298945785, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9779345393180847, \"recall\": 0.9964821338653564, \"specificity\": 0.9986353516578674, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985121488571167, \"f1\": 0.9871212121212121, \"f2\": 0.9927165234351192, \"f0_5\": 0.9815886217079491, \"p4\": 0.9931290449023495, \"phi\": 0.9863807993873177}, {\"truth_threshold\": -7.099527888741876, \"match_probability\": 0.00723892192223447, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107573.0, \"fp\": 146.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986446499824524, \"fp_rate\": 0.0013553783064708114, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9780813455581665, \"recall\": 0.9964821338653564, \"specificity\": 0.9986446499824524, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985208511352539, \"f1\": 0.9871959996969467, \"f2\": 0.9927467771919666, \"f0_5\": 0.9817069495509614, \"p4\": 0.9931691898030541, \"phi\": 0.9864594425064486}, {\"truth_threshold\": -7.084407549516036, \"match_probability\": 0.0073146314146359985, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107574.0, \"fp\": 145.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986538887023926, \"fp_rate\": 0.0013460948830470443, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9782282114028931, \"recall\": 0.9964821338653564, \"specificity\": 0.9986538887023926, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985296130180359, \"f1\": 0.9872707986058493, \"f2\": 0.9927770327928807, \"f0_5\": 0.9818253059256133, \"p4\": 0.9932093379067258, \"phi\": 0.9865381029701734}, {\"truth_threshold\": -7.068361708469549, \"match_probability\": 0.007395834749462827, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107575.0, \"fp\": 144.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986631870269775, \"fp_rate\": 0.001336811576038599, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9783751368522644, \"recall\": 0.9964821338653564, \"specificity\": 0.9986631870269775, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985383749008179, \"f1\": 0.9873456088504963, \"f2\": 0.9928072902380299, \"f0_5\": 0.9819436908422259, \"p4\": 0.9932494892137491, \"phi\": 0.986616780784981}, {\"truth_threshold\": -6.991661127552933, \"match_probability\": 0.007796524091671886, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107576.0, \"fp\": 143.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986724853515625, \"fp_rate\": 0.001327528152614832, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9785220623016357, \"recall\": 0.9964821338653564, \"specificity\": 0.9986724853515625, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985471367835999, \"f1\": 0.9874204304334647, \"f2\": 0.9928375495275831, \"f0_5\": 0.9820621043111245, \"p4\": 0.9932896437245085, \"phi\": 0.9866954759573641}, {\"truth_threshold\": -6.958876667432177, \"match_probability\": 0.007974295267723374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107577.0, \"fp\": 142.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986817836761475, \"fp_rate\": 0.0013182447291910648, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9786690473556519, \"recall\": 0.9964821338653564, \"specificity\": 0.9986817836761475, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985558986663818, \"f1\": 0.9874952633573323, \"f2\": 0.9928678106617087, \"f0_5\": 0.9821805463426401, \"p4\": 0.9933298014393885, \"phi\": 0.9867741884938183}, {\"truth_threshold\": -6.948805597847777, \"match_probability\": 0.008029707897943912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107578.0, \"fp\": 141.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9986910223960876, \"fp_rate\": 0.0013089613057672977, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9788160920143127, \"recall\": 0.9964821338653564, \"specificity\": 0.9986910223960876, \"npv\": 0.9997862577438354, \"accuracy\": 0.9985646605491638, \"f1\": 0.9875701076246779, \"f2\": 0.9928980736405755, \"f0_5\": 0.9822990169471081, \"p4\": 0.9933699623587738, \"phi\": 0.9868530085157314}, {\"truth_threshold\": -6.916510743318056, \"match_probability\": 0.00820998816733812, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107582.0, \"fp\": 137.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9987281560897827, \"fp_rate\": 0.0012718276120722294, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9794046878814697, \"recall\": 0.9964821338653564, \"specificity\": 0.9987281560897827, \"npv\": 0.9997862577438354, \"accuracy\": 0.998599648475647, \"f1\": 0.9878695981804397, \"f2\": 0.9930191440068284, \"f0_5\": 0.9827731853013938, \"p4\": 0.9935306380890635, \"phi\": 0.9871681020050549}, {\"truth_threshold\": -6.908331847860666, \"match_probability\": 0.008256278866138791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107583.0, \"fp\": 136.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9987374544143677, \"fp_rate\": 0.0012625441886484623, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9795519709587097, \"recall\": 0.9964821338653564, \"specificity\": 0.9987374544143677, \"npv\": 0.9997862577438354, \"accuracy\": 0.998608410358429, \"f1\": 0.987944499203882, \"f2\": 0.9930494162119319, \"f0_5\": 0.9828917989258343, \"p4\": 0.9935708150367474, \"phi\": 0.9872469188688978}, {\"truth_threshold\": -6.892926857983359, \"match_probability\": 0.00834417159443399, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107585.0, \"fp\": 134.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9987560510635376, \"fp_rate\": 0.0012439773418009281, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9798465967178345, \"recall\": 0.9964821338653564, \"specificity\": 0.9987560510635376, \"npv\": 0.9997862577438354, \"accuracy\": 0.9986259341239929, \"f1\": 0.9880943353302495, \"f2\": 0.9931099661595683, \"f0_5\": 0.9831291120903, \"p4\": 0.9936511785529435, \"phi\": 0.9874046949914043}, {\"truth_threshold\": -6.883248289186307, \"match_probability\": 0.008399866309946314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107586.0, \"fp\": 133.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9987652897834778, \"fp_rate\": 0.001234693918377161, \"fn_rate\": 0.003517895471304655, \"precision\": 0.979993999004364, \"recall\": 0.9964821338653564, \"specificity\": 0.9987652897834778, \"npv\": 0.9997862577438354, \"accuracy\": 0.9986346364021301, \"f1\": 0.9881692704383437, \"f2\": 0.993140243902439, \"f0_5\": 0.9832478116510716, \"p4\": 0.993691365122226, \"phi\": 0.9874835641100999}, {\"truth_threshold\": -6.861424611511728, \"match_probability\": 0.008526805488152222, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107587.0, \"fp\": 132.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9987745881080627, \"fp_rate\": 0.0012254106113687158, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9801414012908936, \"recall\": 0.9964821338653564, \"specificity\": 0.9987745881080627, \"npv\": 0.9997862577438354, \"accuracy\": 0.9986433982849121, \"f1\": 0.9882442169131589, \"f2\": 0.9931705234915699, \"f0_5\": 0.9833665398780415, \"p4\": 0.9937315548994785, \"phi\": 0.9875624506580162}, {\"truth_threshold\": -6.850449284987334, \"match_probability\": 0.00859136124307464, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107588.0, \"fp\": 131.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9987838864326477, \"fp_rate\": 0.0012161271879449487, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9802889227867126, \"recall\": 0.9964821338653564, \"specificity\": 0.9987838864326477, \"npv\": 0.9997862577438354, \"accuracy\": 0.9986521601676941, \"f1\": 0.9883191747572816, \"f2\": 0.9932008049271297, \"f0_5\": 0.9834852967815954, \"p4\": 0.9937717478850862, \"phi\": 0.9876413546416866}, {\"truth_threshold\": -6.793527372369865, \"match_probability\": 0.008934022705360539, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107590.0, \"fp\": 129.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9988024234771729, \"fp_rate\": 0.0011975603410974145, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9805839657783508, \"recall\": 0.9964821338653564, \"specificity\": 0.9988024234771729, \"npv\": 0.9997862577438354, \"accuracy\": 0.9986696839332581, \"f1\": 0.9884691245637991, \"f2\": 0.993261373338212, \"f0_5\": 0.983722896660023, \"p4\": 0.9938521434829083, \"phi\": 0.9877992149424412}, {\"truth_threshold\": -6.787285711202813, \"match_probability\": 0.008972410949587907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107594.0, \"fp\": 125.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9988395571708679, \"fp_rate\": 0.0011604266474023461, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9811747074127197, \"recall\": 0.9964821338653564, \"specificity\": 0.9988395571708679, \"npv\": 0.9997862577438354, \"accuracy\": 0.9987046718597412, \"f1\": 0.9887691607224162, \"f2\": 0.9933825323249573, \"f0_5\": 0.9841984409934135, \"p4\": 0.9940129731957729, \"phi\": 0.9881152352775432}, {\"truth_threshold\": -6.721112381297317, \"match_probability\": 0.00938958630513576, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107597.0, \"fp\": 122.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9988674521446228, \"fp_rate\": 0.0011325763771310449, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9816182255744934, \"recall\": 0.9964821338653564, \"specificity\": 0.9988674521446228, \"npv\": 0.9997862577438354, \"accuracy\": 0.9987309575080872, \"f1\": 0.9889943074003795, \"f2\": 0.9934734209643478, \"f0_5\": 0.9845554010759838, \"p4\": 0.9941336291951361, \"phi\": 0.9883524566550212}, {\"truth_threshold\": -6.702892096573477, \"match_probability\": 0.009507787932555635, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107598.0, \"fp\": 121.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.998876690864563, \"fp_rate\": 0.0011232930701225996, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9817661046981812, \"recall\": 0.9964821338653564, \"specificity\": 0.998876690864563, \"npv\": 0.9997862577438354, \"accuracy\": 0.9987396597862244, \"f1\": 0.989069379080006, \"f2\": 0.9935037208734903, \"f0_5\": 0.9846744453176954, \"p4\": 0.9941738542854984, \"phi\": 0.9884315353690911}, {\"truth_threshold\": -6.66056130064375, \"match_probability\": 0.00978812240881463, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107599.0, \"fp\": 120.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.998885989189148, \"fp_rate\": 0.0011140096466988325, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9819141030311584, \"recall\": 0.9964821338653564, \"specificity\": 0.998885989189148, \"npv\": 0.9997863173484802, \"accuracy\": 0.9987484216690063, \"f1\": 0.9891444621574432, \"f2\": 0.9935340226309208, \"f0_5\": 0.9847935183505653, \"p4\": 0.9942140825884579, \"phi\": 0.9885106315910139}, {\"truth_threshold\": -6.655169688666362, \"match_probability\": 0.009824410779488332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107600.0, \"fp\": 119.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9988952875137329, \"fp_rate\": 0.0011047262232750654, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9820621013641357, \"recall\": 0.9964821338653564, \"specificity\": 0.9988952875137329, \"npv\": 0.9997863173484802, \"accuracy\": 0.9987571835517883, \"f1\": 0.9892195566352869, \"f2\": 0.9935643262368083, \"f0_5\": 0.9849126201850396, \"p4\": 0.9942543141044005, \"phi\": 0.9885897453273643}, {\"truth_threshold\": -6.626089302483649, \"match_probability\": 0.010022445745467479, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6515.0, \"tn\": 107601.0, \"fp\": 118.0, \"fn\": 23.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9964821338653564, \"tn_rate\": 0.9989045858383179, \"fp_rate\": 0.0010954427998512983, \"fn_rate\": 0.003517895471304655, \"precision\": 0.9822101593017578, \"recall\": 0.9964821338653564, \"specificity\": 0.9989045858383179, \"npv\": 0.9997863173484802, \"accuracy\": 0.9987659454345703, \"f1\": 0.989294662516134, \"f2\": 0.9935946316913222, \"f0_5\": 0.9850317508315694, \"p4\": 0.9942945488337122, \"phi\": 0.9886688765847209}, {\"truth_threshold\": -6.6213282620477, \"match_probability\": 0.01005524234449737, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6514.0, \"tn\": 107602.0, \"fp\": 117.0, \"fn\": 24.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.996329128742218, \"tn_rate\": 0.9989138245582581, \"fp_rate\": 0.0010861593764275312, \"fn_rate\": 0.003670847276225686, \"precision\": 0.9823555946350098, \"recall\": 0.996329128742218, \"specificity\": 0.9989138245582581, \"npv\": 0.9997770190238953, \"accuracy\": 0.9987659454345703, \"f1\": 0.9892930366770446, \"f2\": 0.9935027300735138, \"f0_5\": 0.9851188675821184, \"p4\": 0.9942937306856544, \"phi\": 0.9886660523912739}, {\"truth_threshold\": -6.5924467836010034, \"match_probability\": 0.010256482404405343, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6514.0, \"tn\": 107605.0, \"fp\": 114.0, \"fn\": 24.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.996329128742218, \"tn_rate\": 0.9989417195320129, \"fp_rate\": 0.00105830910615623, \"fn_rate\": 0.003670847276225686, \"precision\": 0.9828002452850342, \"recall\": 0.996329128742218, \"specificity\": 0.9989417195320129, \"npv\": 0.9997770190238953, \"accuracy\": 0.9987921714782715, \"f1\": 0.9895184566307155, \"f2\": 0.9935936546674802, \"f0_5\": 0.9854765506807867, \"p4\": 0.9944144713704359, \"phi\": 0.9889037126954097}, {\"truth_threshold\": -6.576623628274089, \"match_probability\": 0.010368419577885334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6513.0, \"tn\": 107605.0, \"fp\": 114.0, \"fn\": 25.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9961761832237244, \"tn_rate\": 0.9989417195320129, \"fp_rate\": 0.00105830910615623, \"fn_rate\": 0.0038237993139773607, \"precision\": 0.9827976226806641, \"recall\": 0.9961761832237244, \"specificity\": 0.9989417195320129, \"npv\": 0.9997677206993103, \"accuracy\": 0.9987834692001343, \"f1\": 0.9894417014812001, \"f2\": 0.9934714298788859, \"f0_5\": 0.9854445318646735, \"p4\": 0.9943734143389981, \"phi\": 0.9888217528863561}, {\"truth_threshold\": -6.5638377729708095, \"match_probability\": 0.010459752458826405, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6513.0, \"tn\": 107607.0, \"fp\": 112.0, \"fn\": 25.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9961761832237244, \"tn_rate\": 0.9989602565765381, \"fp_rate\": 0.0010397422593086958, \"fn_rate\": 0.0038237993139773607, \"precision\": 0.983094334602356, \"recall\": 0.9961761832237244, \"specificity\": 0.9989602565765381, \"npv\": 0.9997677206993103, \"accuracy\": 0.9988009333610535, \"f1\": 0.9895920382891438, \"f2\": 0.9935320499130488, \"f0_5\": 0.9856831527332163, \"p4\": 0.9944539292568404, \"phi\": 0.98898023299032}, {\"truth_threshold\": -6.4693251686026505, \"match_probability\": 0.011160022967718123, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6513.0, \"tn\": 107608.0, \"fp\": 111.0, \"fn\": 25.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9961761832237244, \"tn_rate\": 0.998969554901123, \"fp_rate\": 0.0010304588358849287, \"fn_rate\": 0.0038237993139773607, \"precision\": 0.9832427501678467, \"recall\": 0.9961761832237244, \"specificity\": 0.998969554901123, \"npv\": 0.9997677206993103, \"accuracy\": 0.9988096952438354, \"f1\": 0.9896672238261662, \"f2\": 0.9935623627044179, \"f0_5\": 0.9858025065084458, \"p4\": 0.994494191541318, \"phi\": 0.989059499401595}, {\"truth_threshold\": -6.433193183669922, \"match_probability\": 0.011439814934253422, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6513.0, \"tn\": 107611.0, \"fp\": 108.0, \"fn\": 25.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9961761832237244, \"tn_rate\": 0.9989973902702332, \"fp_rate\": 0.0010026086820289493, \"fn_rate\": 0.0038237993139773607, \"precision\": 0.983688235282898, \"recall\": 0.9961761832237244, \"specificity\": 0.9989973902702332, \"npv\": 0.9997677206993103, \"accuracy\": 0.9988359808921814, \"f1\": 0.989892849000684, \"f2\": 0.9936533121777072, \"f0_5\": 0.9861607413239658, \"p4\": 0.9946149977016173, \"phi\": 0.989297404151936}, {\"truth_threshold\": -6.421455983629238, \"match_probability\": 0.011532186716037137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6513.0, \"tn\": 107619.0, \"fp\": 100.0, \"fn\": 25.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9961761832237244, \"tn_rate\": 0.9990716576576233, \"fp_rate\": 0.0009283413528464735, \"fn_rate\": 0.0038237993139773607, \"precision\": 0.9848782420158386, \"recall\": 0.9961761832237244, \"specificity\": 0.9990716576576233, \"npv\": 0.9997677803039551, \"accuracy\": 0.9989059567451477, \"f1\": 0.9904950193901605, \"f2\": 0.9938959255302915, \"f0_5\": 0.9871173082752349, \"p4\": 0.994937289114218, \"phi\": 0.9899327725518217}, {\"truth_threshold\": -6.411069220488847, \"match_probability\": 0.011614545135173267, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107619.0, \"fp\": 100.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9990716576576233, \"fp_rate\": 0.0009283413528464735, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9848759770393372, \"recall\": 0.9960232377052307, \"specificity\": 0.9990716576576233, \"npv\": 0.9997584819793701, \"accuracy\": 0.9988971948623657, \"f1\": 0.9904182509505703, \"f2\": 0.9937736540104993, \"f0_5\": 0.9870854301825017, \"p4\": 0.9948962589658776, \"phi\": 0.9898508939820455}, {\"truth_threshold\": -6.389906472821943, \"match_probability\": 0.011784150951006359, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107621.0, \"fp\": 98.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9990902543067932, \"fp_rate\": 0.0009097745059989393, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9851740002632141, \"recall\": 0.9960232377052307, \"specificity\": 0.9990902543067932, \"npv\": 0.9997584819793701, \"accuracy\": 0.9989147186279297, \"f1\": 0.9905689078186797, \"f2\": 0.993834320249069, \"f0_5\": 0.9873248832555037, \"p4\": 0.9949768690946679, \"phi\": 0.990009879745712}, {\"truth_threshold\": -6.293552212379702, \"match_probability\": 0.012587818877504322, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107623.0, \"fp\": 96.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9991087913513184, \"fp_rate\": 0.0008912076591514051, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9854721426963806, \"recall\": 0.9960232377052307, \"specificity\": 0.9991087913513184, \"npv\": 0.9997584819793701, \"accuracy\": 0.9989322423934937, \"f1\": 0.9907196105279172, \"f2\": 0.9938949938949939, \"f0_5\": 0.9875644525326054, \"p4\": 0.9950574921159988, \"phi\": 0.9901689361971188}, {\"truth_threshold\": -6.252819830716069, \"match_probability\": 0.012943616442264595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107624.0, \"fp\": 95.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9991180896759033, \"fp_rate\": 0.0008819242939352989, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9856213331222534, \"recall\": 0.9960232377052307, \"specificity\": 0.9991180896759033, \"npv\": 0.9997584819793701, \"accuracy\": 0.9989410042762756, \"f1\": 0.9907949790794979, \"f2\": 0.9939253334961384, \"f0_5\": 0.987684280774131, \"p4\": 0.9950978084623364, \"phi\": 0.9902484909473838}, {\"truth_threshold\": -6.248768612532495, \"match_probability\": 0.012979541940143438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107625.0, \"fp\": 94.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9991273880004883, \"fp_rate\": 0.0008726408705115318, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9857705235481262, \"recall\": 0.9960232377052307, \"specificity\": 0.9991273880004883, \"npv\": 0.9997584819793701, \"accuracy\": 0.9989497065544128, \"f1\": 0.9908703590992087, \"f2\": 0.9939556749496307, \"f0_5\": 0.9878041380984164, \"p4\": 0.9951381280329726, \"phi\": 0.9903281538238521}, {\"truth_threshold\": -6.215005106161812, \"match_probability\": 0.013282803169847916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107629.0, \"fp\": 90.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9991645216941833, \"fp_rate\": 0.0008355071768164635, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9863677620887756, \"recall\": 0.9960232377052307, \"specificity\": 0.9991645216941833, \"npv\": 0.9997584819793701, \"accuracy\": 0.9989847540855408, \"f1\": 0.99117199391172, \"f2\": 0.9940770592904683, \"f0_5\": 0.9882838584350149, \"p4\": 0.9952994385662632, \"phi\": 0.9906466206711996}, {\"truth_threshold\": -6.128875288899542, \"match_probability\": 0.014088432018479948, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107631.0, \"fp\": 88.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9991830587387085, \"fp_rate\": 0.0008169403881765902, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9866666793823242, \"recall\": 0.9960232377052307, \"specificity\": 0.9991830587387085, \"npv\": 0.9997584819793701, \"accuracy\": 0.9990022778511047, \"f1\": 0.9913228801948546, \"f2\": 0.9941377625793845, \"f0_5\": 0.9885238933754327, \"p4\": 0.9953801131887894, \"phi\": 0.990805960420151}, {\"truth_threshold\": -6.118385538111997, \"match_probability\": 0.014189782642905872, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107635.0, \"fp\": 84.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9992201924324036, \"fp_rate\": 0.0007798066944815218, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9872649908065796, \"recall\": 0.9960232377052307, \"specificity\": 0.9992201924324036, \"npv\": 0.9997584819793701, \"accuracy\": 0.9990372657775879, \"f1\": 0.9916247906197655, \"f2\": 0.9942591914010016, \"f0_5\": 0.989004313225199, \"p4\": 0.9955415011611345, \"phi\": 0.9911249433349109}, {\"truth_threshold\": -6.0775103004139455, \"match_probability\": 0.014591614728081641, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107636.0, \"fp\": 83.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9992294907569885, \"fp_rate\": 0.0007705233292654157, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9874147176742554, \"recall\": 0.9960232377052307, \"specificity\": 0.9992294907569885, \"npv\": 0.9997584819793701, \"accuracy\": 0.9990460276603699, \"f1\": 0.9917002969618518, \"f2\": 0.9942895532415184, \"f0_5\": 0.9891244911598518, \"p4\": 0.9955818562246728, \"phi\": 0.991204710842462}, {\"truth_threshold\": -6.03453547187366, \"match_probability\": 0.015026177050418687, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107642.0, \"fp\": 77.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9992851614952087, \"fp_rate\": 0.000714822846930474, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9883138537406921, \"recall\": 0.9960232377052307, \"specificity\": 0.9992851614952087, \"npv\": 0.9997585415840149, \"accuracy\": 0.999098539352417, \"f1\": 0.9921535765978517, \"f2\": 0.9944717632326441, \"f0_5\": 0.9898461725542652, \"p4\": 0.9958240544276248, \"phi\": 0.9916837798838681}, {\"truth_threshold\": -5.979087616822415, \"match_probability\": 0.015605739513304387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107643.0, \"fp\": 76.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9992944598197937, \"fp_rate\": 0.000705539423506707, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9884638786315918, \"recall\": 0.9960232377052307, \"specificity\": 0.9992944598197937, \"npv\": 0.9997585415840149, \"accuracy\": 0.999107301235199, \"f1\": 0.9922291634923054, \"f2\": 0.9945021380574222, \"f0_5\": 0.9899665551839465, \"p4\": 0.995864432102033, \"phi\": 0.991763671944764}, {\"truth_threshold\": -5.968691799882789, \"match_probability\": 0.015716824192652773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6512.0, \"tn\": 107644.0, \"fp\": 75.0, \"fn\": 26.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9960232377052307, \"tn_rate\": 0.9993037581443787, \"fp_rate\": 0.0006962560000829399, \"fn_rate\": 0.003976751118898392, \"precision\": 0.9886139631271362, \"recall\": 0.9960232377052307, \"specificity\": 0.9993037581443787, \"npv\": 0.9997585415840149, \"accuracy\": 0.9991160035133362, \"f1\": 0.9923047619047619, \"f2\": 0.9945325147377745, \"f0_5\": 0.9900869670984613, \"p4\": 0.9959048130081213, \"phi\": 0.9918436723816079}, {\"truth_threshold\": -5.922174518727598, \"match_probability\": 0.01622348975785892, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6508.0, \"tn\": 107644.0, \"fp\": 75.0, \"fn\": 30.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9954114556312561, \"tn_rate\": 0.9993037581443787, \"fp_rate\": 0.0006962560000829399, \"fn_rate\": 0.00458855926990509, \"precision\": 0.9886069893836975, \"recall\": 0.9954114556312561, \"specificity\": 0.9993037581443787, \"npv\": 0.9997214078903198, \"accuracy\": 0.999081015586853, \"f1\": 0.9919975611614968, \"f2\": 0.9940430731632809, \"f0_5\": 0.9899604502585945, \"p4\": 0.9957408612328843, \"phi\": 0.9915166410625371}, {\"truth_threshold\": -5.787285711202813, \"match_probability\": 0.017785245368886902, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6508.0, \"tn\": 107664.0, \"fp\": 55.0, \"fn\": 30.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9954114556312561, \"tn_rate\": 0.999489426612854, \"fp_rate\": 0.0005105877062305808, \"fn_rate\": 0.00458855926990509, \"precision\": 0.9916197061538696, \"recall\": 0.9954114556312561, \"specificity\": 0.999489426612854, \"npv\": 0.9997214078903198, \"accuracy\": 0.9992560744285583, \"f1\": 0.9935119456530036, \"f2\": 0.9946507718172092, \"f0_5\": 0.9923757243061909, \"p4\": 0.9965493627696761, \"phi\": 0.9931193712920071}, {\"truth_threshold\": -5.766305209514834, \"match_probability\": 0.018041078165680714, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6508.0, \"tn\": 107665.0, \"fp\": 54.0, \"fn\": 30.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9954114556312561, \"tn_rate\": 0.999498724937439, \"fp_rate\": 0.0005013043410144746, \"fn_rate\": 0.00458855926990509, \"precision\": 0.9917708039283752, \"recall\": 0.9954114556312561, \"specificity\": 0.999498724937439, \"npv\": 0.9997214078903198, \"accuracy\": 0.9992648363113403, \"f1\": 0.993587786259542, \"f2\": 0.9946811762548144, \"f0_5\": 0.9924967974135301, \"p4\": 0.9965898218623611, \"phi\": 0.9931996825332537}, {\"truth_threshold\": -5.7356018933206805, \"match_probability\": 0.01842199271310018, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6508.0, \"tn\": 107677.0, \"fp\": 42.0, \"fn\": 30.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9954114556312561, \"tn_rate\": 0.9996101260185242, \"fp_rate\": 0.0003899033472407609, \"fn_rate\": 0.00458855926990509, \"precision\": 0.9935877919197083, \"recall\": 0.9954114556312561, \"specificity\": 0.9996101260185242, \"npv\": 0.9997214674949646, \"accuracy\": 0.9993698596954346, \"f1\": 0.9944987775061125, \"f2\": 0.9950461745458994, \"f0_5\": 0.993951982405767, \"p4\": 0.9970755839989732, \"phi\": 0.9941650037995303}, {\"truth_threshold\": -5.71568676991827, \"match_probability\": 0.018673273723058405, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6508.0, \"tn\": 107678.0, \"fp\": 41.0, \"fn\": 30.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9954114556312561, \"tn_rate\": 0.9996193647384644, \"fp_rate\": 0.0003806199529208243, \"fn_rate\": 0.00458855926990509, \"precision\": 0.9937394857406616, \"recall\": 0.9954114556312561, \"specificity\": 0.9996193647384644, \"npv\": 0.9997214674949646, \"accuracy\": 0.9993786215782166, \"f1\": 0.9945747688545885, \"f2\": 0.9950766031619828, \"f0_5\": 0.9940734404594611, \"p4\": 0.9971160852742589, \"phi\": 0.9942455493913394}, {\"truth_threshold\": -5.700202963956887, \"match_probability\": 0.018870962676953165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6508.0, \"tn\": 107679.0, \"fp\": 40.0, \"fn\": 30.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9954114556312561, \"tn_rate\": 0.9996286630630493, \"fp_rate\": 0.0003713365294970572, \"fn_rate\": 0.00458855926990509, \"precision\": 0.9938912391662598, \"recall\": 0.9954114556312561, \"specificity\": 0.9996286630630493, \"npv\": 0.9997214674949646, \"accuracy\": 0.9993873238563538, \"f1\": 0.9946507718172092, \"f2\": 0.9951070336391438, \"f0_5\": 0.9941949282004278, \"p4\": 0.9971565897971001, \"phi\": 0.9943262038665792}, {\"truth_threshold\": -5.672196265719251, \"match_probability\": 0.019233764267637427, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6506.0, \"tn\": 107679.0, \"fp\": 40.0, \"fn\": 32.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9951055645942688, \"tn_rate\": 0.9996286630630493, \"fp_rate\": 0.0003713365294970572, \"fn_rate\": 0.00489446334540844, \"precision\": 0.9938893914222717, \"recall\": 0.9951055645942688, \"specificity\": 0.9996286630630493, \"npv\": 0.9997029304504395, \"accuracy\": 0.9993698596954346, \"f1\": 0.9944970956893916, \"f2\": 0.9948620710746835, \"f0_5\": 0.9941323879958438, \"p4\": 0.9970747418133333, \"phi\": 0.994163058404514}, {\"truth_threshold\": -5.535991882120939, \"match_probability\": 0.021097919896331873, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6506.0, \"tn\": 107689.0, \"fp\": 30.0, \"fn\": 32.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9951055645942688, \"tn_rate\": 0.9997215270996094, \"fp_rate\": 0.00027850241167470813, \"fn_rate\": 0.00489446334540844, \"precision\": 0.9954100251197815, \"recall\": 0.9951055645942688, \"specificity\": 0.9997215270996094, \"npv\": 0.9997029304504395, \"accuracy\": 0.9994573593139648, \"f1\": 0.9952577635000764, \"f2\": 0.9951664219285364, \"f0_5\": 0.9953491218407686, \"p4\": 0.9974800171333593, \"phi\": 0.9949700019841923}, {\"truth_threshold\": -5.491673783551182, \"match_probability\": 0.02174177381336935, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6502.0, \"tn\": 107689.0, \"fp\": 30.0, \"fn\": 36.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9944937229156494, \"tn_rate\": 0.9997215270996094, \"fp_rate\": 0.00027850241167470813, \"fn_rate\": 0.005506271030753851, \"precision\": 0.995407223701477, \"recall\": 0.9944937229156494, \"specificity\": 0.9997215270996094, \"npv\": 0.9996657967567444, \"accuracy\": 0.9994223713874817, \"f1\": 0.9949502677888293, \"f2\": 0.9946762942112348, \"f0_5\": 0.9952243923345374, \"p4\": 0.9973163218035155, \"phi\": 0.9946439990421586}, {\"truth_threshold\": -5.437168558123093, \"match_probability\": 0.02256000939329328, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6502.0, \"tn\": 107690.0, \"fp\": 29.0, \"fn\": 36.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9944937229156494, \"tn_rate\": 0.9997307658195496, \"fp_rate\": 0.00026921898825094104, \"fn_rate\": 0.005506271030753851, \"precision\": 0.9955596327781677, \"recall\": 0.9944937229156494, \"specificity\": 0.9997307658195496, \"npv\": 0.9996657967567444, \"accuracy\": 0.9994311332702637, \"f1\": 0.9950263983472339, \"f2\": 0.9947067282685188, \"f0_5\": 0.9953462739575041, \"p4\": 0.9973568775140444, \"phi\": 0.9947248919269176}, {\"truth_threshold\": -5.416285011889856, \"match_probability\": 0.022881422316274953, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6500.0, \"tn\": 107690.0, \"fp\": 29.0, \"fn\": 38.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9941878318786621, \"tn_rate\": 0.9997307658195496, \"fp_rate\": 0.00026921898825094104, \"fn_rate\": 0.0058121751062572, \"precision\": 0.9955582618713379, \"recall\": 0.9941878318786621, \"specificity\": 0.9997307658195496, \"npv\": 0.9996472597122192, \"accuracy\": 0.9994136095046997, \"f1\": 0.9948725797811281, \"f2\": 0.994461613781708, \"f0_5\": 0.9952838855882893, \"p4\": 0.9972749838791497, \"phi\": 0.994561827027933}, {\"truth_threshold\": -5.399214818780476, \"match_probability\": 0.023147462827891024, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6500.0, \"tn\": 107691.0, \"fp\": 28.0, \"fn\": 38.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9941878318786621, \"tn_rate\": 0.9997400641441345, \"fp_rate\": 0.00025993556482717395, \"fn_rate\": 0.0058121751062572, \"precision\": 0.9957107901573181, \"recall\": 0.9941878318786621, \"specificity\": 0.9997400641441345, \"npv\": 0.9996472597122192, \"accuracy\": 0.9994223713874817, \"f1\": 0.994948721873565, \"f2\": 0.9944920440636474, \"f0_5\": 0.9954058192955589, \"p4\": 0.9973155479949001, \"phi\": 0.9946427511418725}, {\"truth_threshold\": -5.39727583099958, \"match_probability\": 0.023177872469162614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6500.0, \"tn\": 107692.0, \"fp\": 27.0, \"fn\": 38.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9941878318786621, \"tn_rate\": 0.9997493624687195, \"fp_rate\": 0.0002506521705072373, \"fn_rate\": 0.0058121751062572, \"precision\": 0.9958633184432983, \"recall\": 0.9941878318786621, \"specificity\": 0.9997493624687195, \"npv\": 0.9996472597122192, \"accuracy\": 0.9994311332702637, \"f1\": 0.9950248756218906, \"f2\": 0.9945224762079623, \"f0_5\": 0.9955277828830484, \"p4\": 0.99735611536776, \"phi\": 0.994723602519532}, {\"truth_threshold\": -5.353574548926899, \"match_probability\": 0.023873687058265314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6499.0, \"tn\": 107692.0, \"fp\": 27.0, \"fn\": 39.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9940348863601685, \"tn_rate\": 0.9997493624687195, \"fp_rate\": 0.0002506521705072373, \"fn_rate\": 0.005965127144008875, \"precision\": 0.9958627223968506, \"recall\": 0.9940348863601685, \"specificity\": 0.9997493624687195, \"npv\": 0.9996379613876343, \"accuracy\": 0.9994223713874817, \"f1\": 0.9949479485609308, \"f2\": 0.9943999020747903, \"f0_5\": 0.9954965994730715, \"p4\": 0.9973151609117515, \"phi\": 0.994642120827869}, {\"truth_threshold\": -5.265421802270892, \"match_probability\": 0.025339808360854407, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6499.0, \"tn\": 107693.0, \"fp\": 26.0, \"fn\": 39.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9940348863601685, \"tn_rate\": 0.9997586607933044, \"fp_rate\": 0.00024136874708347023, \"fn_rate\": 0.005965127144008875, \"precision\": 0.9960153102874756, \"recall\": 0.9940348863601685, \"specificity\": 0.9997586607933044, \"npv\": 0.9996379613876343, \"accuracy\": 0.9994311332702637, \"f1\": 0.9950241139095154, \"f2\": 0.9944303332619273, \"f0_5\": 0.9956186040811325, \"p4\": 0.9973557341184657, \"phi\": 0.9947229969340595}, {\"truth_threshold\": -5.240842342661144, \"match_probability\": 0.02576400782695008, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6499.0, \"tn\": 107695.0, \"fp\": 24.0, \"fn\": 39.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9940348863601685, \"tn_rate\": 0.9997771978378296, \"fp_rate\": 0.00022280191478785127, \"fn_rate\": 0.005965127144008875, \"precision\": 0.9963207244873047, \"recall\": 0.9940348863601685, \"specificity\": 0.9997771978378296, \"npv\": 0.999638020992279, \"accuracy\": 0.9994485974311829, \"f1\": 0.9951764795957431, \"f2\": 0.9944912012241776, \"f0_5\": 0.9958627030340178, \"p4\": 0.9974368903076508, \"phi\": 0.9948848037992365}, {\"truth_threshold\": -5.15219876967633, \"match_probability\": 0.027352014519890337, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6499.0, \"tn\": 107696.0, \"fp\": 23.0, \"fn\": 39.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9940348863601685, \"tn_rate\": 0.9997864961624146, \"fp_rate\": 0.0002135185059159994, \"fn_rate\": 0.005965127144008875, \"precision\": 0.996473491191864, \"recall\": 0.9940348863601685, \"specificity\": 0.9997864961624146, \"npv\": 0.999638020992279, \"accuracy\": 0.9994573593139648, \"f1\": 0.9952526799387442, \"f2\": 0.9945216379996328, \"f0_5\": 0.995984797400846, \"p4\": 0.9974774732909093, \"phi\": 0.9949657345721409}, {\"truth_threshold\": -5.099928876822124, \"match_probability\": 0.02833257681087167, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6498.0, \"tn\": 107696.0, \"fp\": 23.0, \"fn\": 40.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9938819408416748, \"tn_rate\": 0.9997864961624146, \"fp_rate\": 0.0002135185059159994, \"fn_rate\": 0.006118078716099262, \"precision\": 0.996472954750061, \"recall\": 0.9938819408416748, \"specificity\": 0.9997864961624146, \"npv\": 0.9996287226676941, \"accuracy\": 0.9994485974311829, \"f1\": 0.9951757408683667, \"f2\": 0.9943990450830962, \"f0_5\": 0.9959536509104285, \"p4\": 0.9974365206150008, \"phi\": 0.9948842738468014}, {\"truth_threshold\": -5.0286141122715895, \"match_probability\": 0.029725617208373353, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6498.0, \"tn\": 107699.0, \"fp\": 20.0, \"fn\": 40.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9938819408416748, \"tn_rate\": 0.9998143315315247, \"fp_rate\": 0.0001856682647485286, \"fn_rate\": 0.006118078716099262, \"precision\": 0.9969315528869629, \"recall\": 0.9938819408416748, \"specificity\": 0.9998143315315247, \"npv\": 0.9996287226676941, \"accuracy\": 0.9994748830795288, \"f1\": 0.9954044117647058, \"f2\": 0.9944903581267218, \"f0_5\": 0.9963201471941122, \"p4\": 0.9975582968624458, \"phi\": 0.9951272862565154}, {\"truth_threshold\": -5.006819472430641, \"match_probability\": 0.03016443951163511, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6498.0, \"tn\": 107700.0, \"fp\": 19.0, \"fn\": 40.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9938819408416748, \"tn_rate\": 0.9998236298561096, \"fp_rate\": 0.00017638485587667674, \"fn_rate\": 0.006118078716099262, \"precision\": 0.9970845580101013, \"recall\": 0.9938819408416748, \"specificity\": 0.9998236298561096, \"npv\": 0.9996287226676941, \"accuracy\": 0.9994836449623108, \"f1\": 0.9954806587514362, \"f2\": 0.9945207995347272, \"f0_5\": 0.9964423725694658, \"p4\": 0.9975988954671543, \"phi\": 0.9952082965777626}, {\"truth_threshold\": -4.949066586443407, \"match_probability\": 0.03135782145349574, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6498.0, \"tn\": 107701.0, \"fp\": 18.0, \"fn\": 40.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9938819408416748, \"tn_rate\": 0.9998329281806946, \"fp_rate\": 0.00016710144700482488, \"fn_rate\": 0.006118078716099262, \"precision\": 0.9972375631332397, \"recall\": 0.9938819408416748, \"specificity\": 0.9998329281806946, \"npv\": 0.9996287226676941, \"accuracy\": 0.999492347240448, \"f1\": 0.9955569174199479, \"f2\": 0.994551242806416, \"f0_5\": 0.9965646279369363, \"p4\": 0.9976394973336332, \"phi\": 0.9952893251672889}, {\"truth_threshold\": -4.900148212397599, \"match_probability\": 0.032404277642850074, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6498.0, \"tn\": 107702.0, \"fp\": 17.0, \"fn\": 40.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9938819408416748, \"tn_rate\": 0.9998421669006348, \"fp_rate\": 0.0001578180235810578, \"fn_rate\": 0.006118078716099262, \"precision\": 0.997390627861023, \"recall\": 0.9938819408416748, \"specificity\": 0.9998421669006348, \"npv\": 0.9996287226676941, \"accuracy\": 0.99950110912323, \"f1\": 0.9956331877729258, \"f2\": 0.9945816879419598, \"f0_5\": 0.9966869133075649, \"p4\": 0.9976801024622767, \"phi\": 0.9953703720320807}, {\"truth_threshold\": -4.8790225910637615, \"match_probability\": 0.03286655997918108, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6497.0, \"tn\": 107702.0, \"fp\": 17.0, \"fn\": 41.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9937289953231812, \"tn_rate\": 0.9998421669006348, \"fp_rate\": 0.0001578180235810578, \"fn_rate\": 0.006271030753850937, \"precision\": 0.9973902106285095, \"recall\": 0.9937289953231812, \"specificity\": 0.9998421669006348, \"npv\": 0.9996194839477539, \"accuracy\": 0.999492347240448, \"f1\": 0.9955562365920931, \"f2\": 0.9944590705932774, \"f0_5\": 0.9966558262256857, \"p4\": 0.9976391567380396, \"phi\": 0.9952889454834616}, {\"truth_threshold\": -4.785861928280239, \"match_probability\": 0.034982216336848546, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6497.0, \"tn\": 107703.0, \"fp\": 16.0, \"fn\": 41.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9937289953231812, \"tn_rate\": 0.9998514652252197, \"fp_rate\": 0.00014853461470920593, \"fn_rate\": 0.006271030753850937, \"precision\": 0.9975433945655823, \"recall\": 0.9937289953231812, \"specificity\": 0.9998514652252197, \"npv\": 0.9996194839477539, \"accuracy\": 0.99950110912323, \"f1\": 0.9956325185809517, \"f2\": 0.9944895147711618, \"f0_5\": 0.9967781528076097, \"p4\": 0.9976797677117484, \"phi\": 0.995370017199947}, {\"truth_threshold\": -4.763878472120294, \"match_probability\": 0.03550028091712803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6496.0, \"tn\": 107703.0, \"fp\": 16.0, \"fn\": 42.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9935759902000427, \"tn_rate\": 0.9998514652252197, \"fp_rate\": 0.00014853461470920593, \"fn_rate\": 0.0064239827916026115, \"precision\": 0.9975429773330688, \"recall\": 0.9935759902000427, \"specificity\": 0.9998514652252197, \"npv\": 0.999610185623169, \"accuracy\": 0.999492347240448, \"f1\": 0.9955555555555555, \"f2\": 0.994366887092824, \"f0_5\": 0.9967470692935616, \"p4\": 0.9976388160374094, \"phi\": 0.9952885920718562}, {\"truth_threshold\": -4.735761394496716, \"match_probability\": 0.03617366854470815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6496.0, \"tn\": 107704.0, \"fp\": 15.0, \"fn\": 42.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9935759902000427, \"tn_rate\": 0.9998607635498047, \"fp_rate\": 0.00013925120583735406, \"fn_rate\": 0.0064239827916026115, \"precision\": 0.9976962208747864, \"recall\": 0.9935759902000427, \"specificity\": 0.9998607635498047, \"npv\": 0.999610185623169, \"accuracy\": 0.99950110912323, \"f1\": 0.9956318491838455, \"f2\": 0.9943973303125861, \"f0_5\": 0.9968694371125161, \"p4\": 0.9976794328579821, \"phi\": 0.9953696886569507}, {\"truth_threshold\": -4.700202963956887, \"match_probability\": 0.03704289035261565, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6495.0, \"tn\": 107704.0, \"fp\": 15.0, \"fn\": 43.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9934230446815491, \"tn_rate\": 0.9998607635498047, \"fp_rate\": 0.00013925120583735406, \"fn_rate\": 0.006576934829354286, \"precision\": 0.9976958632469177, \"recall\": 0.9934230446815491, \"specificity\": 0.9998607635498047, \"npv\": 0.999600887298584, \"accuracy\": 0.999492347240448, \"f1\": 0.9955548743102391, \"f2\": 0.994274692302982, \"f0_5\": 0.9968383571735527, \"p4\": 0.9976384752316941, \"phi\": 0.9952882649552385}, {\"truth_threshold\": -4.687530502672885, \"match_probability\": 0.037357494994156054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6494.0, \"tn\": 107704.0, \"fp\": 15.0, \"fn\": 44.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9932700991630554, \"tn_rate\": 0.9998607635498047, \"fp_rate\": 0.00013925120583735406, \"fn_rate\": 0.006729886867105961, \"precision\": 0.9976955056190491, \"recall\": 0.9932700991630554, \"specificity\": 0.9998607635498047, \"npv\": 0.9995916485786438, \"accuracy\": 0.9994836449623108, \"f1\": 0.9954778876370046, \"f2\": 0.9941520467836257, \"f0_5\": 0.9968072696015227, \"p4\": 0.9975975090671267, \"phi\": 0.9952068361034684}, {\"truth_threshold\": -4.617059209668595, \"match_probability\": 0.039154375623528935, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6493.0, \"tn\": 107704.0, \"fp\": 15.0, \"fn\": 45.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9931171536445618, \"tn_rate\": 0.9998607635498047, \"fp_rate\": 0.00013925120583735406, \"fn_rate\": 0.0068828389048576355, \"precision\": 0.9976951479911804, \"recall\": 0.9931171536445618, \"specificity\": 0.9998607635498047, \"npv\": 0.9995823502540588, \"accuracy\": 0.9994748830795288, \"f1\": 0.9954008891614288, \"f2\": 0.9940293937538273, \"f0_5\": 0.9967761743936138, \"p4\": 0.9975565343612994, \"phi\": 0.9951254021003336}, {\"truth_threshold\": -4.516452511679053, \"match_probability\": 0.04186388514690645, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6493.0, \"tn\": 107705.0, \"fp\": 14.0, \"fn\": 45.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9931171536445618, \"tn_rate\": 0.9998700618743896, \"fp_rate\": 0.00012996778241358697, \"fn_rate\": 0.0068828389048576355, \"precision\": 0.9978484511375427, \"recall\": 0.9931171536445618, \"specificity\": 0.9998700618743896, \"npv\": 0.9995823502540588, \"accuracy\": 0.9994836449623108, \"f1\": 0.9954771943273285, \"f2\": 0.9940598303683518, \"f0_5\": 0.9968986059080022, \"p4\": 0.9975971621997863, \"phi\": 0.995206536737028}, {\"truth_threshold\": -4.401308392735586, \"match_probability\": 0.04518491060213855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6492.0, \"tn\": 107707.0, \"fp\": 12.0, \"fn\": 46.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9929642081260681, \"tn_rate\": 0.9998885989189148, \"fp_rate\": 0.00011140095739392564, \"fn_rate\": 0.00703579094260931, \"precision\": 0.9981549978256226, \"recall\": 0.9929642081260681, \"specificity\": 0.9998885989189148, \"npv\": 0.9995731115341187, \"accuracy\": 0.999492347240448, \"f1\": 0.9955528293206564, \"f2\": 0.9939980401763842, \"f0_5\": 0.9971124900165879, \"p4\": 0.9976374521835535, \"phi\": 0.9952874416033595}, {\"truth_threshold\": -4.166341135866786, \"match_probability\": 0.05275557994082553, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6492.0, \"tn\": 107708.0, \"fp\": 11.0, \"fn\": 46.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9929642081260681, \"tn_rate\": 0.9998978972434998, \"fp_rate\": 0.00010211754852207378, \"fn_rate\": 0.00703579094260931, \"precision\": 0.9983084797859192, \"recall\": 0.9929642081260681, \"specificity\": 0.9998978972434998, \"npv\": 0.9995731115341187, \"accuracy\": 0.99950110912323, \"f1\": 0.995629169542213, \"f2\": 0.9940284795590262, \"f0_5\": 0.9972350230414746, \"p4\": 0.997678092409585, \"phi\": 0.9953686378323895}, {\"truth_threshold\": -3.8578174164678725, \"match_probability\": 0.0645229725304455, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6491.0, \"tn\": 107708.0, \"fp\": 11.0, \"fn\": 47.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9928112626075745, \"tn_rate\": 0.9998978972434998, \"fp_rate\": 0.00010211754852207378, \"fn_rate\": 0.0071887425146996975, \"precision\": 0.9983082413673401, \"recall\": 0.9928112626075745, \"specificity\": 0.9998978972434998, \"npv\": 0.9995638132095337, \"accuracy\": 0.999492347240448, \"f1\": 0.9955521472392638, \"f2\": 0.993905800208244, \"f0_5\": 0.997203957475573, \"p4\": 0.9976371109570135, \"phi\": 0.9952872198948705}, {\"truth_threshold\": -3.657879007250686, \"match_probability\": 0.07341016964129271, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6490.0, \"tn\": 107708.0, \"fp\": 11.0, \"fn\": 48.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9926583170890808, \"tn_rate\": 0.9998978972434998, \"fp_rate\": 0.00010211754852207378, \"fn_rate\": 0.007341694552451372, \"precision\": 0.9983079433441162, \"recall\": 0.9926583170890808, \"specificity\": 0.9998978972434998, \"npv\": 0.9995545744895935, \"accuracy\": 0.9994836449623108, \"f1\": 0.995475113122172, \"f2\": 0.9937831133433375, \"f0_5\": 0.9971728842726323, \"p4\": 0.9975961209553763, \"phi\": 0.9952057968079473}, {\"truth_threshold\": -3.635845861697161, \"match_probability\": 0.07445579449573433, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6490.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 48.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9926583170890808, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.007341694552451372, \"precision\": 0.99892258644104, \"recall\": 0.9926583170890808, \"specificity\": 0.9999350309371948, \"npv\": 0.9995545744895935, \"accuracy\": 0.999518632888794, \"f1\": 0.9957805907172996, \"f2\": 0.9939048669178229, \"f0_5\": 0.9976634077353502, \"p4\": 0.9977587352548656, \"phi\": 0.9955309093220653}, {\"truth_threshold\": -3.4631637666560375, \"match_probability\": 0.08313593367174198, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6489.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 49.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9925053715705872, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.007494646590203047, \"precision\": 0.9989224076271057, \"recall\": 0.9925053715705872, \"specificity\": 0.9999350309371948, \"npv\": 0.9995452761650085, \"accuracy\": 0.999509871006012, \"f1\": 0.9957035445757251, \"f2\": 0.9937821612349914, \"f0_5\": 0.9976323719328455, \"p4\": 0.9977177470571635, \"phi\": 0.9954495075431513}, {\"truth_threshold\": -3.3593094546232685, \"match_probability\": 0.0887902814304302, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6488.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 50.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9923524260520935, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.0076475986279547215, \"precision\": 0.9989222288131714, \"recall\": 0.9923524260520935, \"specificity\": 0.9999350309371948, \"npv\": 0.9995360374450684, \"accuracy\": 0.99950110912323, \"f1\": 0.9956264866109108, \"f2\": 0.9936594480350415, \"f0_5\": 0.9976013284949874, \"p4\": 0.9976767503055687, \"phi\": 0.9953681006181352}, {\"truth_threshold\": -3.3372120180064417, \"match_probability\": 0.0900373392883097, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6487.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 51.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9921994209289551, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.007800550665706396, \"precision\": 0.9989221096038818, \"recall\": 0.9921994209289551, \"specificity\": 0.9999350309371948, \"npv\": 0.9995267391204834, \"accuracy\": 0.999492347240448, \"f1\": 0.9955494168201351, \"f2\": 0.9935367273172824, \"f0_5\": 0.997570277418958, \"p4\": 0.9976357449970923, \"phi\": 0.9952865973823403}, {\"truth_threshold\": -3.2700978221479047, \"match_probability\": 0.0939221411738694, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6483.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 55.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9915876388549805, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.008412358351051807, \"precision\": 0.9989213943481445, \"recall\": 0.9915876388549805, \"specificity\": 0.9999350309371948, \"npv\": 0.9994896650314331, \"accuracy\": 0.9994573593139648, \"f1\": 0.9952410193429536, \"f2\": 0.9930457692543349, \"f0_5\": 0.9974459966767185, \"p4\": 0.9974716381345479, \"phi\": 0.994960897566069}, {\"truth_threshold\": -2.9429058610119716, \"match_probability\": 0.11508028580925592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6482.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 56.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9914346933364868, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.008565310388803482, \"precision\": 0.998921275138855, \"recall\": 0.9914346933364868, \"specificity\": 0.9999350309371948, \"npv\": 0.9994803667068481, \"accuracy\": 0.9994485974311829, \"f1\": 0.9951638903815153, \"f2\": 0.992923010937165, \"f0_5\": 0.997414907367514, \"p4\": 0.9974305899967838, \"phi\": 0.994879459730419}, {\"truth_threshold\": -2.8626600601433045, \"match_probability\": 0.12086707198413517, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6481.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 57.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9912817478179932, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.008718262426555157, \"precision\": 0.9989210963249207, \"recall\": 0.9912817478179932, \"specificity\": 0.9999350309371948, \"npv\": 0.9994710683822632, \"accuracy\": 0.9994398355484009, \"f1\": 0.9950867495777675, \"f2\": 0.9928002450980392, \"f0_5\": 0.997383810403201, \"p4\": 0.9973895332841765, \"phi\": 0.994798016739521}, {\"truth_threshold\": -2.784670994977663, \"match_probability\": 0.12672990021195413, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6479.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 59.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9909758567810059, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.009024166502058506, \"precision\": 0.998920738697052, \"recall\": 0.9909758567810059, \"specificity\": 0.9999350309371948, \"npv\": 0.999452531337738, \"accuracy\": 0.9994223713874817, \"f1\": 0.9949324324324325, \"f2\": 0.9925546908511551, \"f0_5\": 0.9973215934979374, \"p4\": 0.9973073941224364, \"phi\": 0.9946351152867478}, {\"truth_threshold\": -2.6406885053725935, \"match_probability\": 0.13819232075414367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6478.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 60.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9908229112625122, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.00917711853981018, \"precision\": 0.9989205598831177, \"recall\": 0.9908229112625122, \"specificity\": 0.9999350309371948, \"npv\": 0.9994432926177979, \"accuracy\": 0.9994136095046997, \"f1\": 0.9948552560853874, \"f2\": 0.9924319024420136, \"f0_5\": 0.997290473551327, \"p4\": 0.9972663116673025, \"phi\": 0.9945535655994545}, {\"truth_threshold\": -2.616482293294423, \"match_probability\": 0.14020271284927793, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6477.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 61.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9906699061393738, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.009330070577561855, \"precision\": 0.9989204406738281, \"recall\": 0.9906699061393738, \"specificity\": 0.9999350309371948, \"npv\": 0.9994339942932129, \"accuracy\": 0.9994048476219177, \"f1\": 0.9947780678851175, \"f2\": 0.9923091065081505, \"f0_5\": 0.9972593459382891, \"p4\": 0.997225220625323, \"phi\": 0.9944721019678661}, {\"truth_threshold\": -2.5781471474879862, \"match_probability\": 0.1434365736008512, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6476.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 62.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9905169606208801, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.00948302261531353, \"precision\": 0.9989202618598938, \"recall\": 0.9905169606208801, \"specificity\": 0.9999350309371948, \"npv\": 0.9994246959686279, \"accuracy\": 0.9993960857391357, \"f1\": 0.9947008678288918, \"f2\": 0.9921863030488739, \"f0_5\": 0.9972282106559901, \"p4\": 0.9971841209934936, \"phi\": 0.9943906331744813}, {\"truth_threshold\": -2.5139640948135304, \"match_probability\": 0.14898969131726014, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6475.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 63.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9903640151023865, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.009635974653065205, \"precision\": 0.9989200830459595, \"recall\": 0.9903640151023865, \"specificity\": 0.9999350309371948, \"npv\": 0.9994154572486877, \"accuracy\": 0.9993873238563538, \"f1\": 0.9946236559139785, \"f2\": 0.9920634920634921, \"f0_5\": 0.9971970677015956, \"p4\": 0.9971430127688091, \"phi\": 0.9943091592179898}, {\"truth_threshold\": -2.336374374101688, \"match_probability\": 0.16528055512905288, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6474.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 64.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9902110695838928, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.00978892669081688, \"precision\": 0.9989199042320251, \"recall\": 0.9902110695838928, \"specificity\": 0.9999350309371948, \"npv\": 0.9994061589241028, \"accuracy\": 0.9993786215782166, \"f1\": 0.9945464321376449, \"f2\": 0.9919406735513131, \"f0_5\": 0.9971659170722691, \"p4\": 0.9971018959482625, \"phi\": 0.9942276800970796}, {\"truth_threshold\": -2.3140571087396995, \"match_probability\": 0.1674257886241238, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6472.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 66.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9899051785469055, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.010094829834997654, \"precision\": 0.9989196062088013, \"recall\": 0.9899051785469055, \"specificity\": 0.9999350309371948, \"npv\": 0.9993876218795776, \"accuracy\": 0.9993610978126526, \"f1\": 0.9943919489897826, \"f2\": 0.9916950139437958, \"f0_5\": 0.9971035927774696, \"p4\": 0.9970196365075482, \"phi\": 0.9940647063567564}, {\"truth_threshold\": -2.2104226254520927, \"match_probability\": 0.17767959431775576, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6471.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 67.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9897522330284119, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.010247781872749329, \"precision\": 0.9989194273948669, \"recall\": 0.9897522330284119, \"specificity\": 0.9999350309371948, \"npv\": 0.9993783831596375, \"accuracy\": 0.9993523359298706, \"f1\": 0.9943146896127842, \"f2\": 0.9915721728470732, \"f0_5\": 0.9970724191063174, \"p4\": 0.9969784938813598, \"phi\": 0.9939832117347176}, {\"truth_threshold\": -2.0892163138039535, \"match_probability\": 0.19028885011529362, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6467.0, \"tn\": 107712.0, \"fp\": 7.0, \"fn\": 71.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9891403913497925, \"tn_rate\": 0.9999350309371948, \"fp_rate\": 6.498389120679349e-05, \"fn_rate\": 0.010859590023756027, \"precision\": 0.9989187717437744, \"recall\": 0.9891403913497925, \"specificity\": 0.9999350309371948, \"npv\": 0.9993412494659424, \"accuracy\": 0.9993173480033875, \"f1\": 0.9940055333538272, \"f2\": 0.9910807331576044, \"f0_5\": 0.9969476475303694, \"p4\": 0.9968138372674243, \"phi\": 0.9936570902411247}, {\"truth_threshold\": -2.0729191017021575, \"match_probability\": 0.1920354752164242, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6467.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 71.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9891403913497925, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.010859590023756027, \"precision\": 0.9993818402290344, \"recall\": 0.9891403913497925, \"specificity\": 0.9999628663063049, \"npv\": 0.9993413090705872, \"accuracy\": 0.9993435740470886, \"f1\": 0.9942347605503882, \"f2\": 0.9911718726052172, \"f0_5\": 0.9973166368515206, \"p4\": 0.9969360113302373, \"phi\": 0.9939015990364628}, {\"truth_threshold\": -2.0658422392441658, \"match_probability\": 0.1927977221196495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6466.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 72.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9889874458312988, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.011012542061507702, \"precision\": 0.9993817806243896, \"recall\": 0.9889874458312988, \"specificity\": 0.9999628663063049, \"npv\": 0.9993320107460022, \"accuracy\": 0.9993348121643066, \"f1\": 0.9941574415744158, \"f2\": 0.9910489853473117, \"f0_5\": 0.9972854586957863, \"p4\": 0.9968948334270609, \"phi\": 0.9938200985396485}, {\"truth_threshold\": -1.6885800680387666, \"match_probability\": 0.23677645293021332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6465.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 73.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9888345003128052, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.011165494099259377, \"precision\": 0.9993816614151001, \"recall\": 0.9888345003128052, \"specificity\": 0.9999628663063049, \"npv\": 0.999322772026062, \"accuracy\": 0.9993261098861694, \"f1\": 0.9940801107096179, \"f2\": 0.9909260905551639, \"f0_5\": 0.997254272845067, \"p4\": 0.9968536469017577, \"phi\": 0.9937385015423186}, {\"truth_threshold\": -1.6558088445984334, \"match_probability\": 0.240905921147066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6464.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 74.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9886815547943115, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.011318446137011051, \"precision\": 0.9993815422058105, \"recall\": 0.9886815547943115, \"specificity\": 0.9999628663063049, \"npv\": 0.999313473701477, \"accuracy\": 0.9993173480033875, \"f1\": 0.9940027679532524, \"f2\": 0.9908031882280809, \"f0_5\": 0.9972230792965134, \"p4\": 0.9968124517513068, \"phi\": 0.9936569906940492}, {\"truth_threshold\": -1.6163203919501123, \"match_probability\": 0.2459467531914381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6463.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 75.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9885286092758179, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.011471398174762726, \"precision\": 0.9993814826011658, \"recall\": 0.9885286092758179, \"specificity\": 0.9999628663063049, \"npv\": 0.9993041753768921, \"accuracy\": 0.9993085861206055, \"f1\": 0.9939254133025759, \"f2\": 0.9906802783653699, \"f0_5\": 0.9971918780472752, \"p4\": 0.9967712479726861, \"phi\": 0.9935754746713962}, {\"truth_threshold\": -1.5611675274806458, \"match_probability\": 0.25310524964168507, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6462.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 76.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9883756637573242, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.0116243502125144, \"precision\": 0.9993813633918762, \"recall\": 0.9883756637573242, \"specificity\": 0.9999628663063049, \"npv\": 0.9992949366569519, \"accuracy\": 0.9992998242378235, \"f1\": 0.9938480467548446, \"f2\": 0.9905573609663376, \"f0_5\": 0.9971606690945003, \"p4\": 0.9967300355628715, \"phi\": 0.9934939534730436}, {\"truth_threshold\": -1.4187232624604404, \"match_probability\": 0.2722208345557568, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6461.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 77.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9882227182388306, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.011777302250266075, \"precision\": 0.9993813037872314, \"recall\": 0.9882227182388306, \"specificity\": 0.9999628663063049, \"npv\": 0.9992856383323669, \"accuracy\": 0.9992910623550415, \"f1\": 0.9937706683073136, \"f2\": 0.9904344360302909, \"f0_5\": 0.9971294524353355, \"p4\": 0.9966888145188382, \"phi\": 0.9934124270976754}, {\"truth_threshold\": -1.3359535075359512, \"match_probability\": 0.28373441046184544, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6460.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 78.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9880697727203369, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.01193025428801775, \"precision\": 0.9993811845779419, \"recall\": 0.9880697727203369, \"specificity\": 0.9999628663063049, \"npv\": 0.9992763996124268, \"accuracy\": 0.9992823004722595, \"f1\": 0.9936932779572374, \"f2\": 0.9903115035565366, \"f0_5\": 0.9970982280669259, \"p4\": 0.9966475848375594, \"phi\": 0.9933308955439745}, {\"truth_threshold\": -1.1997084942565066, \"match_probability\": 0.3033122406536579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6459.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 79.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9879167675971985, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.012083206325769424, \"precision\": 0.9993810653686523, \"recall\": 0.9879167675971985, \"specificity\": 0.9999628663063049, \"npv\": 0.9992671012878418, \"accuracy\": 0.9992735385894775, \"f1\": 0.993615875701869, \"f2\": 0.9901885635443815, \"f0_5\": 0.9970669959864156, \"p4\": 0.9966063465160072, \"phi\": 0.9932493588106239}, {\"truth_threshold\": -1.1436308530148114, \"match_probability\": 0.3115882557278395, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6458.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 80.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9877638220787048, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.012236157432198524, \"precision\": 0.9993810057640076, \"recall\": 0.9877638220787048, \"specificity\": 0.9999628663063049, \"npv\": 0.9992578625679016, \"accuracy\": 0.9992648363113403, \"f1\": 0.9935384615384616, \"f2\": 0.9900656159931318, \"f0_5\": 0.9970357561909468, \"p4\": 0.9965650995511521, \"phi\": 0.9931678168963056}, {\"truth_threshold\": -1.11398195276524, \"match_probability\": 0.3160134560436064, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6457.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 81.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9876108765602112, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.012389109469950199, \"precision\": 0.999380886554718, \"recall\": 0.9876108765602112, \"specificity\": 0.9999628663063049, \"npv\": 0.9992485642433167, \"accuracy\": 0.9992560744285583, \"f1\": 0.9934610354642665, \"f2\": 0.9899426609020943, \"f0_5\": 0.9970045086776604, \"p4\": 0.9965238439399634, \"phi\": 0.9930862697997015}, {\"truth_threshold\": -1.0729191017021575, \"match_probability\": 0.3221975842313896, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6454.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 84.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9871520400047302, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.012847965583205223, \"precision\": 0.9993805885314941, \"recall\": 0.9871520400047302, \"specificity\": 0.9999628663063049, \"npv\": 0.9992207884788513, \"accuracy\": 0.9992297887802124, \"f1\": 0.9932286857494613, \"f2\": 0.989573750383318, \"f0_5\": 0.9969107198022861, \"p4\": 0.9964000251980665, \"phi\": 0.9928415060011347}, {\"truth_threshold\": -0.6680827313971577, \"match_probability\": 0.3862554972793825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6453.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 85.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9869990944862366, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.013000917620956898, \"precision\": 0.9993805289268494, \"recall\": 0.9869990944862366, \"specificity\": 0.9999628663063049, \"npv\": 0.9992114901542664, \"accuracy\": 0.9992210268974304, \"f1\": 0.9931512120046172, \"f2\": 0.9894507651261921, \"f0_5\": 0.996879441389112, \"p4\": 0.996358734971207, \"phi\": 0.9927599381555398}, {\"truth_threshold\": -0.562855928437017, \"match_probability\": 0.403683117595775, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6452.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 86.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9868461489677429, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.013153869658708572, \"precision\": 0.9993804097175598, \"recall\": 0.9868461489677429, \"specificity\": 0.9999628663063049, \"npv\": 0.9992022514343262, \"accuracy\": 0.9992123246192932, \"f1\": 0.9930737263352316, \"f2\": 0.9893277723258096, \"f0_5\": 0.9968481552438044, \"p4\": 0.9963174360828386, \"phi\": 0.9926783651210577}, {\"truth_threshold\": -0.37207062486299686, \"match_probability\": 0.4358800772391245, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6450.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 88.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9865401983261108, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.013459773734211922, \"precision\": 0.9993802309036255, \"recall\": 0.9865401983261108, \"specificity\": 0.9999628663063049, \"npv\": 0.999183714389801, \"accuracy\": 0.9991948008537292, \"f1\": 0.9929187192118226, \"f2\": 0.9890817640924983, \"f0_5\": 0.9967855597453175, \"p4\": 0.9962348123094169, \"phi\": 0.9925152034801467}, {\"truth_threshold\": -0.3458389415421262, \"match_probability\": 0.4403560220196268, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6449.0, \"tn\": 107715.0, \"fp\": 4.0, \"fn\": 89.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9863872528076172, \"tn_rate\": 0.9999628663063049, \"fp_rate\": 3.713365367730148e-05, \"fn_rate\": 0.013612725771963596, \"precision\": 0.9993801116943359, \"recall\": 0.9863872528076172, \"specificity\": 0.9999628663063049, \"npv\": 0.9991744160652161, \"accuracy\": 0.9991860389709473, \"f1\": 0.9928411977522901, \"f2\": 0.9889587486581812, \"f0_5\": 0.9967542503863988, \"p4\": 0.9961934874182805, \"phi\": 0.9924336148710736}, {\"truth_threshold\": -0.33595350753595127, \"match_probability\": 0.44204534543834045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6449.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 89.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9863872528076172, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.013612725771963596, \"precision\": 0.9996899962425232, \"recall\": 0.9863872528076172, \"specificity\": 0.9999814629554749, \"npv\": 0.9991744160652161, \"accuracy\": 0.9992035627365112, \"f1\": 0.9929940719069982, \"f2\": 0.9890194153912216, \"f0_5\": 0.9970008039082308, \"p4\": 0.9962750468694465, \"phi\": 0.9925968930531448}, {\"truth_threshold\": -0.31633532574869677, \"match_probability\": 0.4454018376243358, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6447.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 91.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9860813617706299, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.013918629847466946, \"precision\": 0.9996898770332336, \"recall\": 0.9860813617706299, \"specificity\": 0.9999814629554749, \"npv\": 0.9991558790206909, \"accuracy\": 0.9991860389709473, \"f1\": 0.9928389928389928, \"f2\": 0.9887733505107206, \"f0_5\": 0.99693820745964, \"p4\": 0.996192381480245, \"phi\": 0.9924337270546894}, {\"truth_threshold\": -0.17862481631361937, \"match_probability\": 0.4690861596982998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6446.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 92.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9859284162521362, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.01407158188521862, \"precision\": 0.9996898174285889, \"recall\": 0.9859284162521362, \"specificity\": 0.9999814629554749, \"npv\": 0.9991466403007507, \"accuracy\": 0.9991772770881653, \"f1\": 0.9927614353919606, \"f2\": 0.9886503067484662, \"f0_5\": 0.9969068976183112, \"p4\": 0.9961510357683796, \"phi\": 0.9923521362654258}, {\"truth_threshold\": 0.12834571972861064, \"match_probability\": 0.5222259617572003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6444.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 94.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9856225252151489, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.014377485029399395, \"precision\": 0.9996897578239441, \"recall\": 0.9856225252151489, \"specificity\": 0.9999814629554749, \"npv\": 0.9991281032562256, \"accuracy\": 0.9991598129272461, \"f1\": 0.9926062846580407, \"f2\": 0.988404196576477, \"f0_5\": 0.9968442546872099, \"p4\": 0.9960683182948801, \"phi\": 0.992188847618417}, {\"truth_threshold\": 0.18040261889144302, \"match_probability\": 0.53122072063712, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6443.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 95.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9854695796966553, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.01453043706715107, \"precision\": 0.9996896982192993, \"recall\": 0.9854695796966553, \"specificity\": 0.9999814629554749, \"npv\": 0.9991188645362854, \"accuracy\": 0.9991510510444641, \"f1\": 0.9925286913656319, \"f2\": 0.9882811301653527, \"f0_5\": 0.9968129215916827, \"p4\": 0.9960269465271461, \"phi\": 0.9921072412331448}, {\"truth_threshold\": 0.5154851431876041, \"match_probability\": 0.5883883965687954, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6442.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 96.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9853166341781616, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.014683389104902744, \"precision\": 0.9996896386146545, \"recall\": 0.9853166341781616, \"specificity\": 0.9999814629554749, \"npv\": 0.9991095662117004, \"accuracy\": 0.9991422891616821, \"f1\": 0.992451086119242, \"f2\": 0.9881580562032152, \"f0_5\": 0.9967815807389986, \"p4\": 0.9959855660680201, \"phi\": 0.9920256296487763}, {\"truth_threshold\": 0.7018624762804555, \"match_probability\": 0.6192801604409064, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6441.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 97.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9851636290550232, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.014836341142654419, \"precision\": 0.9996895790100098, \"recall\": 0.9851636290550232, \"specificity\": 0.9999814629554749, \"npv\": 0.9991003274917603, \"accuracy\": 0.9991335272789001, \"f1\": 0.9923734689161081, \"f2\": 0.9880349746893695, \"f0_5\": 0.9967502321262767, \"p4\": 0.9959441769144489, \"phi\": 0.9919440128639865}, {\"truth_threshold\": 0.8845486046098866, \"match_probability\": 0.6486527277625264, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6439.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 99.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9848577380180359, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.015142245218157768, \"precision\": 0.9996894598007202, \"recall\": 0.9848577380180359, \"specificity\": 0.9999814629554749, \"npv\": 0.9990817904472351, \"accuracy\": 0.9991160035133362, \"f1\": 0.9922181986285539, \"f2\": 0.9877887890037739, \"f0_5\": 0.9966875116091883, \"p4\": 0.9958613725117489, \"phi\": 0.991780763687838}, {\"truth_threshold\": 0.9794823338141275, \"match_probability\": 0.6634988196725987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6438.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 100.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9847047924995422, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.015295197255909443, \"precision\": 0.9996894598007202, \"recall\": 0.9847047924995422, \"specificity\": 0.9999814629554749, \"npv\": 0.9990724921226501, \"accuracy\": 0.999107301235199, \"f1\": 0.9921405455386038, \"f2\": 0.9876656848306333, \"f0_5\": 0.9966561396990525, \"p4\": 0.995819957256506, \"phi\": 0.9916991312938261}, {\"truth_threshold\": 0.9872690972153965, \"match_probability\": 0.6647028156969707, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6437.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9845518469810486, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.015448149293661118, \"precision\": 0.9996894001960754, \"recall\": 0.9845518469810486, \"specificity\": 0.9999814629554749, \"npv\": 0.99906325340271, \"accuracy\": 0.999098539352417, \"f1\": 0.9920628804808508, \"f2\": 0.9875425731030039, \"f0_5\": 0.9966247600173407, \"p4\": 0.9957785332945892, \"phi\": 0.991617493694086}, {\"truth_threshold\": 1.2971951273384668, \"match_probability\": 0.7107742091650666, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6430.0, \"tn\": 107717.0, \"fp\": 2.0, \"fn\": 108.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9834811687469482, \"tn_rate\": 0.9999814629554749, \"fp_rate\": 1.856682683865074e-05, \"fn_rate\": 0.016518812626600266, \"precision\": 0.9996890425682068, \"recall\": 0.9834811687469482, \"specificity\": 0.9999814629554749, \"npv\": 0.9989984035491943, \"accuracy\": 0.9990372657775879, \"f1\": 0.9915188897455667, \"f2\": 0.9866805794254849, \"f0_5\": 0.996404884398438, \"p4\": 0.9954883215170292, \"phi\": 0.9910457930485463}, {\"truth_threshold\": 1.5290959890485896, \"match_probability\": 0.7426692509998377, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6430.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 108.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9834811687469482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016518812626600266, \"precision\": 1.0, \"recall\": 0.9834811687469482, \"specificity\": 1.0, \"npv\": 0.9989984035491943, \"accuracy\": 0.9990547895431519, \"f1\": 0.9916718075262184, \"f2\": 0.9867411454177153, \"f0_5\": 0.9966519933039866, \"p4\": 0.9955699932515345, \"phi\": 0.991209401053007}, {\"truth_threshold\": 1.992253890958109, \"match_probability\": 0.79913954509959, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6429.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 109.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9833282232284546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016671765595674515, \"precision\": 1.0, \"recall\": 0.9833282232284546, \"specificity\": 1.0, \"npv\": 0.9989891052246094, \"accuracy\": 0.9990460276603699, \"f1\": 0.9915940464255417, \"f2\": 0.9866179675270863, \"f0_5\": 0.9966205741923483, \"p4\": 0.995528504747391, \"phi\": 0.9911277352283259}, {\"truth_threshold\": 2.1077655366074914, \"match_probability\": 0.8116843118153223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6428.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 110.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9831752777099609, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016824716702103615, \"precision\": 1.0, \"recall\": 0.9831752777099609, \"specificity\": 1.0, \"npv\": 0.9989798665046692, \"accuracy\": 0.9990372657775879, \"f1\": 0.9915162733302484, \"f2\": 0.9864947820748926, \"f0_5\": 0.9965891472868217, \"p4\": 0.9954870075095502, \"phi\": 0.9910460641889975}, {\"truth_threshold\": 2.1299868163073863, \"match_probability\": 0.8140273517102465, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6389.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 149.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9772101640701294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.022789843380451202, \"precision\": 1.0, \"recall\": 0.9772101640701294, \"specificity\": 1.0, \"npv\": 0.9986186623573303, \"accuracy\": 0.9986959099769592, \"f1\": 0.9884737371393209, \"f2\": 0.9816846439875849, \"f0_5\": 0.9953573876737085, \"p4\": 0.9938617700389784, \"phi\": 0.9878564445254044}, {\"truth_threshold\": 2.1447628715278304, \"match_probability\": 0.8155728683741708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6388.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 150.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9770572185516357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02294279634952545, \"precision\": 1.0, \"recall\": 0.9770572185516357, \"specificity\": 1.0, \"npv\": 0.9986094236373901, \"accuracy\": 0.9986871480941772, \"f1\": 0.9883954819743154, \"f2\": 0.9815611555009219, \"f0_5\": 0.9953256466188843, \"p4\": 0.9938199209174752, \"phi\": 0.9877745637757643}, {\"truth_threshold\": 2.353116014482114, \"match_probability\": 0.8363142120114133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6387.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 151.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9769042730331421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02309574745595455, \"precision\": 1.0, \"recall\": 0.9769042730331421, \"specificity\": 1.0, \"npv\": 0.99860018491745, \"accuracy\": 0.99867844581604, \"f1\": 0.9883172147001934, \"f2\": 0.9814376594240757, \"f0_5\": 0.9952938976500655, \"p4\": 0.9937780629350687, \"phi\": 0.9876926777564516}, {\"truth_threshold\": 2.4359865846571083, \"match_probability\": 0.8440264291554005, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6386.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 152.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9767513275146484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0232487004250288, \"precision\": 1.0, \"recall\": 0.9767513275146484, \"specificity\": 1.0, \"npv\": 0.998590886592865, \"accuracy\": 0.9986696839332581, \"f1\": 0.9882389353141442, \"f2\": 0.9813141557563464, \"f0_5\": 0.9952621407642915, \"p4\": 0.9937361960886256, \"phi\": 0.9876106945811277}, {\"truth_threshold\": 2.7239185601109885, \"match_probability\": 0.8685360552974424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6385.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 153.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.97659832239151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0234016515314579, \"precision\": 1.0, \"recall\": 0.97659832239151, \"specificity\": 1.0, \"npv\": 0.9985816478729248, \"accuracy\": 0.9986609220504761, \"f1\": 0.988160643813356, \"f2\": 0.9811906444970342, \"f0_5\": 0.9952303759586009, \"p4\": 0.9936943203750114, \"phi\": 0.9875287980116406}, {\"truth_threshold\": 2.851024083935952, \"match_probability\": 0.8782732842352987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6384.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 154.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9764453768730164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02355460450053215, \"precision\": 1.0, \"recall\": 0.9764453768730164, \"specificity\": 1.0, \"npv\": 0.9985724091529846, \"accuracy\": 0.9986521601676941, \"f1\": 0.9880823401950163, \"f2\": 0.9810671256454389, \"f0_5\": 0.9951986032300305, \"p4\": 0.9936524357910896, \"phi\": 0.9874468961684185}, {\"truth_threshold\": 3.1140584897697456, \"match_probability\": 0.8964604826291803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6381.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 157.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9759865403175354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0240134596824646, \"precision\": 1.0, \"recall\": 0.9759865403175354, \"specificity\": 1.0, \"npv\": 0.9985446333885193, \"accuracy\": 0.9986259341239929, \"f1\": 0.9878473566065485, \"f2\": 0.9806965235299542, \"f0_5\": 0.9951032374773876, \"p4\": 0.9935267287860954, \"phi\": 0.9872011589827933}, {\"truth_threshold\": 3.2202870100563894, \"match_probability\": 0.9030981702520939, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6380.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 158.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9758335947990417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02416641265153885, \"precision\": 1.0, \"recall\": 0.9758335947990417, \"specificity\": 1.0, \"npv\": 0.9985353946685791, \"accuracy\": 0.9986171722412109, \"f1\": 0.9877690044898592, \"f2\": 0.9805729743022255, \"f0_5\": 0.9950714330276375, \"p4\": 0.9934848086895521, \"phi\": 0.9871192360310796}, {\"truth_threshold\": 3.3089635022979986, \"match_probability\": 0.9083454985243543, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6379.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 159.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9756806492805481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02431936375796795, \"precision\": 1.0, \"recall\": 0.9756806492805481, \"specificity\": 1.0, \"npv\": 0.9985260963439941, \"accuracy\": 0.998608410358429, \"f1\": 0.9876906402415422, \"f2\": 0.9804494174787126, \"f0_5\": 0.9950396206401697, \"p4\": 0.9934428797069983, \"phi\": 0.9870373077988528}, {\"truth_threshold\": 3.4107282075795506, \"match_probability\": 0.9140513432550242, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6378.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 160.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9755277037620544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02447231486439705, \"precision\": 1.0, \"recall\": 0.9755277037620544, \"specificity\": 1.0, \"npv\": 0.998516857624054, \"accuracy\": 0.998599648475647, \"f1\": 0.9876122638587798, \"f2\": 0.980325853058715, \"f0_5\": 0.9950078003120125, \"p4\": 0.9934009418352887, \"phi\": 0.9869553742847551}, {\"truth_threshold\": 3.4956267666264633, \"match_probability\": 0.9185632289307328, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6377.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 161.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9753747582435608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024625267833471298, \"precision\": 1.0, \"recall\": 0.9753747582435608, \"specificity\": 1.0, \"npv\": 0.9985076189041138, \"accuracy\": 0.998590886592865, \"f1\": 0.9875338753387534, \"f2\": 0.9802022810415322, \"f0_5\": 0.9949759720401922, \"p4\": 0.9933589950712769, \"phi\": 0.9868733435414627}, {\"truth_threshold\": 3.558128811598171, \"match_probability\": 0.9217457982238455, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6376.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 162.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9752217531204224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024778218939900398, \"precision\": 1.0, \"recall\": 0.9752217531204224, \"specificity\": 1.0, \"npv\": 0.9984983205795288, \"accuracy\": 0.998582124710083, \"f1\": 0.9874554746786434, \"f2\": 0.9800787014264634, \"f0_5\": 0.994944135821734, \"p4\": 0.9933170394118147, \"phi\": 0.9867913994527661}, {\"truth_threshold\": 3.563419310156302, \"match_probability\": 0.9220098987429751, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6375.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 163.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9750688076019287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024931171908974648, \"precision\": 1.0, \"recall\": 0.9750688076019287, \"specificity\": 1.0, \"npv\": 0.9984890818595886, \"accuracy\": 0.998573362827301, \"f1\": 0.9873770618756292, \"f2\": 0.9799551142128078, \"f0_5\": 0.9949122916536612, \"p4\": 0.9932750748537528, \"phi\": 0.986709450078122}, {\"truth_threshold\": 3.7109130392036302, \"match_probability\": 0.9290514340146779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6371.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 167.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9744570255279541, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.025542980059981346, \"precision\": 1.0, \"recall\": 0.9744570255279541, \"specificity\": 1.0, \"npv\": 0.9984520673751831, \"accuracy\": 0.9985383749008179, \"f1\": 0.9870632891780928, \"f2\": 0.9794606893583003, \"f0_5\": 0.9947848354256449, \"p4\": 0.9931071275724649, \"phi\": 0.9863815996928771}, {\"truth_threshold\": 3.7242346913816027, \"match_probability\": 0.9296576769177571, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6370.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 168.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9743040800094604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.025695931166410446, \"precision\": 1.0, \"recall\": 0.9743040800094604, \"specificity\": 1.0, \"npv\": 0.9984428286552429, \"accuracy\": 0.9985296130180359, \"f1\": 0.9869848156182213, \"f2\": 0.9793370641411967, \"f0_5\": 0.994752951464801, \"p4\": 0.9930651184741093, \"phi\": 0.9862996238680949}, {\"truth_threshold\": 3.7486848577331005, \"match_probability\": 0.9307579127984925, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6369.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 169.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9741511344909668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.025848884135484695, \"precision\": 1.0, \"recall\": 0.9741511344909668, \"specificity\": 1.0, \"npv\": 0.9984335899353027, \"accuracy\": 0.9985208511352539, \"f1\": 0.9869063298985047, \"f2\": 0.9792134313213001, \"f0_5\": 0.9947210595364528, \"p4\": 0.9930231004582256, \"phi\": 0.9862176427492011}, {\"truth_threshold\": 3.851024083935952, \"match_probability\": 0.9351922232050168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6368.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 170.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9739981889724731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026001835241913795, \"precision\": 1.0, \"recall\": 0.9739981889724731, \"specificity\": 1.0, \"npv\": 0.9984242916107178, \"accuracy\": 0.9985121488571167, \"f1\": 0.9868278320161166, \"f2\": 0.9790897908979089, \"f0_5\": 0.9946891596376133, \"p4\": 0.9929810735216541, \"phi\": 0.9861355643277526}, {\"truth_threshold\": 4.014274294130014, \"match_probability\": 0.9417218605109718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9738451838493347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026154788210988045, \"precision\": 1.0, \"recall\": 0.9738451838493347, \"specificity\": 1.0, \"npv\": 0.9984150528907776, \"accuracy\": 0.9985033869743347, \"f1\": 0.9867493219682294, \"f2\": 0.978966142870322, \"f0_5\": 0.994657251765294, \"p4\": 0.9929390376612331, \"phi\": 0.9860535726097482}, {\"truth_threshold\": 4.040696540224107, \"match_probability\": 0.9427188996617515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6366.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 172.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9736922383308411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026307739317417145, \"precision\": 1.0, \"recall\": 0.9736922383308411, \"specificity\": 1.0, \"npv\": 0.9984058141708374, \"accuracy\": 0.9984946250915527, \"f1\": 0.9866707997520149, \"f2\": 0.9788424872378375, \"f0_5\": 0.9946253359165053, \"p4\": 0.9928969928738001, \"phi\": 0.985971575593541}, {\"truth_threshold\": 4.068125710180411, \"match_probability\": 0.9437369716477808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6365.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 173.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9735392928123474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026460690423846245, \"precision\": 1.0, \"recall\": 0.9735392928123474, \"specificity\": 1.0, \"npv\": 0.9983965158462524, \"accuracy\": 0.9984858632087708, \"f1\": 0.9865922653646438, \"f2\": 0.978718823999754, \"f0_5\": 0.9945934120882555, \"p4\": 0.9928549391561903, \"phi\": 0.9858895732777665}, {\"truth_threshold\": 4.158988780926496, \"match_probability\": 0.9469891661231653, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6364.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 174.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9733863472938538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026613643392920494, \"precision\": 1.0, \"recall\": 0.9733863472938538, \"specificity\": 1.0, \"npv\": 0.9983872771263123, \"accuracy\": 0.9984771013259888, \"f1\": 0.9865137188032863, \"f2\": 0.9785951531553697, \"f0_5\": 0.9945614802775521, \"p4\": 0.9928128765052381, \"phi\": 0.98580756566106}, {\"truth_threshold\": 4.196026750260181, \"match_probability\": 0.9482632656320953, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6362.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 176.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9730804562568665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026919547468423843, \"precision\": 1.0, \"recall\": 0.9730804562568665, \"specificity\": 1.0, \"npv\": 0.9983687996864319, \"accuracy\": 0.9984596371650696, \"f1\": 0.9863565891472869, \"f2\": 0.9783477886448915, \"f0_5\": 0.9944975926968048, \"p4\": 0.9927287243906353, \"phi\": 0.98564353451939}, {\"truth_threshold\": 4.225486212033388, \"match_probability\": 0.9492559382870328, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6361.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 177.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9729275107383728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027072498574852943, \"precision\": 1.0, \"recall\": 0.9729275107383728, \"specificity\": 1.0, \"npv\": 0.9983595609664917, \"accuracy\": 0.9984508752822876, \"f1\": 0.9862780060469803, \"f2\": 0.9782240949773937, \"f0_5\": 0.994465636920768, \"p4\": 0.9926866349206455, \"phi\": 0.9855615109916941}, {\"truth_threshold\": 4.281670157357941, \"match_probability\": 0.9510993388571627, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6360.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 178.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9727745652198792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027225451543927193, \"precision\": 1.0, \"recall\": 0.9727745652198792, \"specificity\": 1.0, \"npv\": 0.9983502626419067, \"accuracy\": 0.9984421133995056, \"f1\": 0.9861994107613583, \"f2\": 0.9781003937007874, \"f0_5\": 0.9944336731502909, \"p4\": 0.9926445365046348, \"phi\": 0.9854794821576016}, {\"truth_threshold\": 4.386114778348392, \"match_probability\": 0.9543585477209197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6358.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 180.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9724686741828918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027531355619430542, \"precision\": 1.0, \"recall\": 0.9724686741828918, \"specificity\": 1.0, \"npv\": 0.9983317852020264, \"accuracy\": 0.9984245896339417, \"f1\": 0.9860421836228288, \"f2\": 0.9778529683174408, \"f0_5\": 0.9943697216140132, \"p4\": 0.9925603128218559, \"phi\": 0.9853153164896173}, {\"truth_threshold\": 4.479355045367828, \"match_probability\": 0.9570924553711381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6357.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 181.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9723156690597534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027684306725859642, \"precision\": 1.0, \"recall\": 0.9723156690597534, \"specificity\": 1.0, \"npv\": 0.9983225464820862, \"accuracy\": 0.9984158277511597, \"f1\": 0.9859635517642497, \"f2\": 0.9777292442092959, \"f0_5\": 0.9943377338422074, \"p4\": 0.9925181875487366, \"phi\": 0.9852332717213139}, {\"truth_threshold\": 4.591635090900572, \"match_probability\": 0.9601772259722035, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6354.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 184.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9718568325042725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02814316377043724, \"precision\": 1.0, \"recall\": 0.9718568325042725, \"specificity\": 1.0, \"npv\": 0.9982947707176208, \"accuracy\": 0.9983896017074585, \"f1\": 0.9857275829972075, \"f2\": 0.9773580262105458, \"f0_5\": 0.9942417224760594, \"p4\": 0.9923917579643203, \"phi\": 0.9849871055396979}, {\"truth_threshold\": 4.713317209673723, \"match_probability\": 0.9632799990498588, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6353.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 185.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9717038869857788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02829611487686634, \"precision\": 1.0, \"recall\": 0.9717038869857788, \"specificity\": 1.0, \"npv\": 0.9982855319976807, \"accuracy\": 0.9983808398246765, \"f1\": 0.9856489023349624, \"f2\": 0.9772342716505154, \"f0_5\": 0.9942097026604069, \"p4\": 0.992349596837226, \"phi\": 0.9849050395156902}, {\"truth_threshold\": 4.790925899993464, \"match_probability\": 0.9651360852653016, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6352.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 186.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9715509414672852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02844906784594059, \"precision\": 1.0, \"recall\": 0.9715509414672852, \"specificity\": 1.0, \"npv\": 0.9982762336730957, \"accuracy\": 0.9983720779418945, \"f1\": 0.9855702094647013, \"f2\": 0.9771105094757568, \"f0_5\": 0.9941776748262693, \"p4\": 0.9923074267386823, \"phi\": 0.9848229681743297}, {\"truth_threshold\": 4.9077858599373325, \"match_probability\": 0.9677613018686356, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6350.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 188.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9712450504302979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02875497005879879, \"precision\": 1.0, \"recall\": 0.9712450504302979, \"specificity\": 1.0, \"npv\": 0.9982577562332153, \"accuracy\": 0.9983546137809753, \"f1\": 0.9854127870887648, \"f2\": 0.9768629622792444, \"f0_5\": 0.9941135950904878, \"p4\": 0.9922230596145032, \"phi\": 0.984658809534062}, {\"truth_threshold\": 4.964172133320302, \"match_probability\": 0.9689586550091802, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6349.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 189.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9710921049118042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02890792302787304, \"precision\": 1.0, \"recall\": 0.9710921049118042, \"specificity\": 1.0, \"npv\": 0.9982485175132751, \"accuracy\": 0.9983458518981934, \"f1\": 0.9853340575774036, \"f2\": 0.9767391772560844, \"f0_5\": 0.9940815431828146, \"p4\": 0.9921808625824927, \"phi\": 0.9845766300958751}, {\"truth_threshold\": 5.041887473526684, \"match_probability\": 0.9705385955341022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6348.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 190.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9709390997886658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02906087413430214, \"precision\": 1.0, \"recall\": 0.9709390997886658, \"specificity\": 1.0, \"npv\": 0.998239278793335, \"accuracy\": 0.9983370900154114, \"f1\": 0.9852553158466553, \"f2\": 0.9766153846153847, \"f0_5\": 0.9940494832445975, \"p4\": 0.9921386565662823, \"phi\": 0.98449453746455}, {\"truth_threshold\": 5.054847964097457, \"match_probability\": 0.9707943824436047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6347.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 191.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9707861542701721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02921382710337639, \"precision\": 1.0, \"recall\": 0.9707861542701721, \"specificity\": 1.0, \"npv\": 0.99822998046875, \"accuracy\": 0.9983283281326294, \"f1\": 0.9851765618936749, \"f2\": 0.9764915843564418, \"f0_5\": 0.9940174152728184, \"p4\": 0.9920964415626806, \"phi\": 0.9844124395090057}, {\"truth_threshold\": 5.06980755898412, \"match_probability\": 0.9710869459187365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6346.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 192.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9706332087516785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02936677820980549, \"precision\": 1.0, \"recall\": 0.9706332087516785, \"specificity\": 1.0, \"npv\": 0.9982207417488098, \"accuracy\": 0.9983195662498474, \"f1\": 0.9850977957156163, \"f2\": 0.9763677764785526, \"f0_5\": 0.9939853392644571, \"p4\": 0.9920542175684949, \"phi\": 0.9843303362278681}, {\"truth_threshold\": 5.252146515085536, \"match_probability\": 0.9744319347560104, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6345.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 193.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9704802632331848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029519731178879738, \"precision\": 1.0, \"recall\": 0.9704802632331848, \"specificity\": 1.0, \"npv\": 0.9982115030288696, \"accuracy\": 0.9983108043670654, \"f1\": 0.9850190173096328, \"f2\": 0.9762439609810136, \"f0_5\": 0.9939532552164922, \"p4\": 0.9920119845805305, \"phi\": 0.9842482276197622}, {\"truth_threshold\": 5.358640852436311, \"match_probability\": 0.9762080118395575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6344.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 194.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9703273177146912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029672682285308838, \"precision\": 1.0, \"recall\": 0.9703273177146912, \"specificity\": 1.0, \"npv\": 0.9982022643089294, \"accuracy\": 0.9983021020889282, \"f1\": 0.9849402266728768, \"f2\": 0.9761201378631216, \"f0_5\": 0.9939211631259008, \"p4\": 0.9919697425955918, \"phi\": 0.984166113683312}, {\"truth_threshold\": 5.4104425616928395, \"match_probability\": 0.9770278603832846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6343.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 195.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9701743721961975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029825635254383087, \"precision\": 1.0, \"recall\": 0.9701743721961975, \"specificity\": 1.0, \"npv\": 0.9981930255889893, \"accuracy\": 0.9982933402061462, \"f1\": 0.9848614238024999, \"f2\": 0.975996307124173, \"f0_5\": 0.9938890629896584, \"p4\": 0.9919274916104812, \"phi\": 0.9840839944171418}, {\"truth_threshold\": 5.476290297672458, \"match_probability\": 0.9780302733545316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6342.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 196.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9700214266777039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029978586360812187, \"precision\": 1.0, \"recall\": 0.9700214266777039, \"specificity\": 1.0, \"npv\": 0.9981837272644043, \"accuracy\": 0.9982845783233643, \"f1\": 0.9847826086956522, \"f2\": 0.975872468763464, \"f0_5\": 0.9938569548047389, \"p4\": 0.991885231622, \"phi\": 0.9840018698198748}, {\"truth_threshold\": 5.525872326523019, \"match_probability\": 0.9787567266564592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6341.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 197.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9698684811592102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030131539329886436, \"precision\": 1.0, \"recall\": 0.9698684811592102, \"specificity\": 1.0, \"npv\": 0.9981744885444641, \"accuracy\": 0.9982758164405823, \"f1\": 0.9847037813494837, \"f2\": 0.9757486227802912, \"f0_5\": 0.9938248385681149, \"p4\": 0.9918429626269477, \"phi\": 0.9839197398901335}, {\"truth_threshold\": 5.532122598992633, \"match_probability\": 0.9788466184556974, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6340.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 198.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9697155356407166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030284490436315536, \"precision\": 1.0, \"recall\": 0.9697155356407166, \"specificity\": 1.0, \"npv\": 0.9981652498245239, \"accuracy\": 0.9982670545578003, \"f1\": 0.984624941761143, \"f2\": 0.9756247691739505, \"f0_5\": 0.9937927142767572, \"p4\": 0.9918006846221223, \"phi\": 0.9838375124284772}, {\"truth_threshold\": 5.5789172536483305, \"match_probability\": 0.9795078981587844, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9695625305175781, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030437443405389786, \"precision\": 1.0, \"recall\": 0.9695625305175781, \"specificity\": 1.0, \"npv\": 0.9981560111045837, \"accuracy\": 0.9982582926750183, \"f1\": 0.9845460899277783, \"f2\": 0.9755009079437382, \"f0_5\": 0.9937605819276353, \"p4\": 0.9917583976043205, \"phi\": 0.9837553718228091}, {\"truth_threshold\": 5.750058327396886, \"match_probability\": 0.9817583313770595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6338.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 200.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9694095849990845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030590394511818886, \"precision\": 1.0, \"recall\": 0.9694095849990845, \"specificity\": 1.0, \"npv\": 0.9981467723846436, \"accuracy\": 0.9982495307922363, \"f1\": 0.9844672258465362, \"f2\": 0.9753770390889505, \"f0_5\": 0.9937284415177171, \"p4\": 0.9917161015703373, \"phi\": 0.9836732258805305}, {\"truth_threshold\": 5.790925899993464, \"match_probability\": 0.9822587784143246, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6337.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 201.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9692566394805908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030743347480893135, \"precision\": 1.0, \"recall\": 0.9692566394805908, \"specificity\": 1.0, \"npv\": 0.9981375336647034, \"accuracy\": 0.9982408285140991, \"f1\": 0.9843883495145631, \"f2\": 0.9752531626088831, \"f0_5\": 0.9936962930439691, \"p4\": 0.9916737965169661, \"phi\": 0.9835910746002617}, {\"truth_threshold\": 5.800888808419042, \"match_probability\": 0.9823787215401107, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6336.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 202.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9691036939620972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030896298587322235, \"precision\": 1.0, \"recall\": 0.9691036939620972, \"specificity\": 1.0, \"npv\": 0.9981282353401184, \"accuracy\": 0.9982320666313171, \"f1\": 0.9843094609290042, \"f2\": 0.9751292785028318, \"f0_5\": 0.9936641365033562, \"p4\": 0.9916314824409991, \"phi\": 0.9835089179806229}, {\"truth_threshold\": 5.827639972832422, \"match_probability\": 0.9826968517417318, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6335.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 203.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9689507484436035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.031049249693751335, \"precision\": 1.0, \"recall\": 0.9689507484436035, \"specificity\": 1.0, \"npv\": 0.9981189966201782, \"accuracy\": 0.9982233047485352, \"f1\": 0.9842305600870038, \"f2\": 0.9750053867700926, \"f0_5\": 0.9936319718928415, \"p4\": 0.9915891593392266, \"phi\": 0.9834267560202334}, {\"truth_threshold\": 5.880613828958216, \"match_probability\": 0.9833102658896872, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6331.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 207.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9683389663696289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03166105970740318, \"precision\": 1.0, \"recall\": 0.9683389663696289, \"specificity\": 1.0, \"npv\": 0.9980820417404175, \"accuracy\": 0.998188316822052, \"f1\": 0.9839148340974435, \"f2\": 0.9745097435581689, \"f0_5\": 0.9935032326909798, \"p4\": 0.9914197766098398, \"phi\": 0.9830979624838149}, {\"truth_threshold\": 5.915560519074382, \"match_probability\": 0.9837031781848956, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6330.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 208.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9681859612464905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.031814008951187134, \"precision\": 1.0, \"recall\": 0.9681859612464905, \"specificity\": 1.0, \"npv\": 0.9980727434158325, \"accuracy\": 0.99817955493927, \"f1\": 0.9838358719303699, \"f2\": 0.9743858136814235, \"f0_5\": 0.9934710276853538, \"p4\": 0.9913774083308446, \"phi\": 0.9830157737920864}, {\"truth_threshold\": 5.941755562055943, \"match_probability\": 0.9839917156117335, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6328.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 210.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9678800702095032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03211991488933563, \"precision\": 1.0, \"recall\": 0.9678800702095032, \"specificity\": 1.0, \"npv\": 0.9980542659759521, \"accuracy\": 0.998162031173706, \"f1\": 0.9836779107725789, \"f2\": 0.9741379310344828, \"f0_5\": 0.9934065934065934, \"p4\": 0.9912926446343514, \"phi\": 0.9828513803601047}, {\"truth_threshold\": 5.943855810334524, \"match_probability\": 0.9840146309548684, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6327.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 211.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9677271246910095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03227286785840988, \"precision\": 1.0, \"recall\": 0.9677271246910095, \"specificity\": 1.0, \"npv\": 0.998045027256012, \"accuracy\": 0.9981532692909241, \"f1\": 0.9835989117761368, \"f2\": 0.9740139782628775, \"f0_5\": 0.9933743641273629, \"p4\": 0.9912502492104114, \"phi\": 0.9827691756170825}, {\"truth_threshold\": 5.953293550257695, \"match_probability\": 0.9841172063530333, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6324.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 214.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9672682881355286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03273172304034233, \"precision\": 1.0, \"recall\": 0.9672682881355286, \"specificity\": 1.0, \"npv\": 0.9980173110961914, \"accuracy\": 0.9981270432472229, \"f1\": 0.9833618410822578, \"f2\": 0.9736420741470625, \"f0_5\": 0.9932776276936609, \"p4\": 0.9911230085971348, \"phi\": 0.9825225292632629}, {\"truth_threshold\": 5.98459107918062, \"match_probability\": 0.9844527546594228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6321.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 217.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9668094515800476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03319057822227478, \"precision\": 1.0, \"recall\": 0.9668094515800476, \"specificity\": 1.0, \"npv\": 0.9979895353317261, \"accuracy\": 0.998100757598877, \"f1\": 0.9831246597713663, \"f2\": 0.9732701013149385, \"f0_5\": 0.9931808183018038, \"p4\": 0.9909956864039062, \"phi\": 0.9822757423647925}, {\"truth_threshold\": 6.005136185981159, \"match_probability\": 0.9846692203153947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6320.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 218.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9666564464569092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03334353119134903, \"precision\": 1.0, \"recall\": 0.9666564464569092, \"specificity\": 1.0, \"npv\": 0.9979802966117859, \"accuracy\": 0.998091995716095, \"f1\": 0.9830455747394619, \"f2\": 0.9731460950973146, \"f0_5\": 0.9931485322773272, \"p4\": 0.9909532275288782, \"phi\": 0.9821935001133593}, {\"truth_threshold\": 6.043069429389784, \"match_probability\": 0.9850611208426632, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6319.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 219.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9665035009384155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03349648043513298, \"precision\": 1.0, \"recall\": 0.9665035009384155, \"specificity\": 1.0, \"npv\": 0.9979710578918457, \"accuracy\": 0.9980832934379578, \"f1\": 0.9829664774053045, \"f2\": 0.9730220812417234, \"f0_5\": 0.9931162381341547, \"p4\": 0.9909107595764856, \"phi\": 0.9821112524990094}, {\"truth_threshold\": 6.126355504547459, \"match_probability\": 0.985887287455927, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6315.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 223.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9658917188644409, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03410828858613968, \"precision\": 1.0, \"recall\": 0.9658917188644409, \"specificity\": 1.0, \"npv\": 0.997934103012085, \"accuracy\": 0.9980482459068298, \"f1\": 0.9826499649887186, \"f2\": 0.9725259494255706, \"f0_5\": 0.9929869803132273, \"p4\": 0.9907407969285383, \"phi\": 0.9817822083846409}, {\"truth_threshold\": 6.156453006935835, \"match_probability\": 0.9861746287144815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6312.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 226.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.96543288230896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03456714749336243, \"precision\": 1.0, \"recall\": 0.96543288230896, \"specificity\": 1.0, \"npv\": 0.9979063272476196, \"accuracy\": 0.9980220198631287, \"f1\": 0.9824124513618677, \"f2\": 0.9721537703302119, \"f0_5\": 0.9928899515509972, \"p4\": 0.9906132294715614, \"phi\": 0.9815352765297368}, {\"truth_threshold\": 6.166248231670972, \"match_probability\": 0.9862668938513268, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6311.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 227.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9652798771858215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03472009673714638, \"precision\": 1.0, \"recall\": 0.9652798771858215, \"specificity\": 1.0, \"npv\": 0.9978970885276794, \"accuracy\": 0.9980132579803467, \"f1\": 0.982333255506265, \"f2\": 0.9720296953454702, \"f0_5\": 0.9928575923478699, \"p4\": 0.9905706887836483, \"phi\": 0.9814529859550831}, {\"truth_threshold\": 6.172568470384786, \"match_probability\": 0.9863261041570697, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6307.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 231.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9646680951118469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.035331904888153076, \"precision\": 1.0, \"recall\": 0.9646680951118469, \"specificity\": 1.0, \"npv\": 0.9978601336479187, \"accuracy\": 0.9979782700538635, \"f1\": 0.9820163487738419, \"f2\": 0.9715333189562217, \"f0_5\": 0.9927280740414279, \"p4\": 0.9904004349341085, \"phi\": 0.9811237698880513}, {\"truth_threshold\": 6.193890566971733, \"match_probability\": 0.986524006050771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6306.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 232.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9645151495933533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.035484857857227325, \"precision\": 1.0, \"recall\": 0.9645151495933533, \"specificity\": 1.0, \"npv\": 0.9978508949279785, \"accuracy\": 0.9979695081710815, \"f1\": 0.9819370912488321, \"f2\": 0.9714092057428061, \"f0_5\": 0.9926956740759398, \"p4\": 0.9903578486809939, \"phi\": 0.9810414524222107}, {\"truth_threshold\": 6.262060126282827, \"match_probability\": 0.9871379581197081, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6305.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 233.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9643622040748596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.035637810826301575, \"precision\": 1.0, \"recall\": 0.9643622040748596, \"specificity\": 1.0, \"npv\": 0.9978416562080383, \"accuracy\": 0.9979607462882996, \"f1\": 0.9818578213812972, \"f2\": 0.9712850848815355, \"f0_5\": 0.9926632659487373, \"p4\": 0.9903152533050789, \"phi\": 0.9809591295739438}, {\"truth_threshold\": 6.27835859799251, \"match_probability\": 0.987280608198311, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6304.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 234.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.964209258556366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.035790760070085526, \"precision\": 1.0, \"recall\": 0.964209258556366, \"specificity\": 1.0, \"npv\": 0.9978324174880981, \"accuracy\": 0.9979519844055176, \"f1\": 0.9817785391683539, \"f2\": 0.9711609563717032, \"f0_5\": 0.9926308496567362, \"p4\": 0.9902726488031064, \"phi\": 0.9808768013418532}, {\"truth_threshold\": 6.289938889608105, \"match_probability\": 0.9873810129421002, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6303.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 235.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9640563130378723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.035943713039159775, \"precision\": 1.0, \"recall\": 0.9640563130378723, \"specificity\": 1.0, \"npv\": 0.9978231191635132, \"accuracy\": 0.9979432225227356, \"f1\": 0.9816992446071178, \"f2\": 0.9710368202126021, \"f0_5\": 0.9925984251968504, \"p4\": 0.990230035171818, \"phi\": 0.9807943752721093}, {\"truth_threshold\": 6.414447123041889, \"match_probability\": 0.9884123024111433, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6302.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 236.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9639033079147339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.036096666008234024, \"precision\": 1.0, \"recall\": 0.9639033079147339, \"specificity\": 1.0, \"npv\": 0.997813880443573, \"accuracy\": 0.9979344606399536, \"f1\": 0.981619937694704, \"f2\": 0.970912676403525, \"f0_5\": 0.9925659925659925, \"p4\": 0.9901874124079535, \"phi\": 0.9807120362612692}, {\"truth_threshold\": 6.448202912998213, \"match_probability\": 0.988677246712517, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6301.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 237.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9637503623962402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03624961897730827, \"precision\": 1.0, \"recall\": 0.9637503623962402, \"specificity\": 1.0, \"npv\": 0.9978046417236328, \"accuracy\": 0.9979257583618164, \"f1\": 0.9815406184282265, \"f2\": 0.9707885249437648, \"f0_5\": 0.9925335517610736, \"p4\": 0.9901447805082515, \"phi\": 0.9806296918624076}, {\"truth_threshold\": 6.547233882415364, \"match_probability\": 0.9894204524162902, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6298.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 240.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9632915258407593, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03670847415924072, \"precision\": 1.0, \"recall\": 0.9632915258407593, \"specificity\": 1.0, \"npv\": 0.9977769255638123, \"accuracy\": 0.9978994727134705, \"f1\": 0.9813025864755376, \"f2\": 0.9704160246533128, \"f0_5\": 0.9924361802710369, \"p4\": 0.99001682996148, \"phi\": 0.9803826263236914}, {\"truth_threshold\": 6.555561306561014, \"match_probability\": 0.9894807025162934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6297.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 241.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9631385803222656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03686142712831497, \"precision\": 1.0, \"recall\": 0.9631385803222656, \"specificity\": 1.0, \"npv\": 0.9977676868438721, \"accuracy\": 0.9978907108306885, \"f1\": 0.9812232177639267, \"f2\": 0.9702918425837468, \"f0_5\": 0.9924037067389523, \"p4\": 0.9899741614857801, \"phi\": 0.9803002603587393}, {\"truth_threshold\": 6.585394773134277, \"match_probability\": 0.9896937783087227, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6296.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 242.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.962985634803772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03701437637209892, \"precision\": 1.0, \"recall\": 0.962985634803772, \"specificity\": 1.0, \"npv\": 0.9977584481239319, \"accuracy\": 0.9978819489479065, \"f1\": 0.9811438366838087, \"f2\": 0.9701676528599605, \"f0_5\": 0.9923712250173381, \"p4\": 0.9899314838579112, \"phi\": 0.9802178889987606}, {\"truth_threshold\": 6.598346114141359, \"match_probability\": 0.9897849442478752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6295.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 243.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9628326892852783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03716732934117317, \"precision\": 1.0, \"recall\": 0.9628326892852783, \"specificity\": 1.0, \"npv\": 0.9977492094039917, \"accuracy\": 0.9978731870651245, \"f1\": 0.9810644432322917, \"f2\": 0.9700434554812464, \"f0_5\": 0.992338735103096, \"p4\": 0.9898887970746024, \"phi\": 0.9801355122423531}, {\"truth_threshold\": 6.599253500880201, \"match_probability\": 0.9897913014452426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6294.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 244.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9626797437667847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03732028231024742, \"precision\": 1.0, \"recall\": 0.9626797437667847, \"specificity\": 1.0, \"npv\": 0.9977399706840515, \"accuracy\": 0.9978644847869873, \"f1\": 0.9809850374064838, \"f2\": 0.9699192504468964, \"f0_5\": 0.992306236993126, \"p4\": 0.9898461011325812, \"phi\": 0.9800530375734617}, {\"truth_threshold\": 6.652508968992813, \"match_probability\": 0.9901576321299064, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6293.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 245.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9625267386436462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03747323155403137, \"precision\": 1.0, \"recall\": 0.9625267386436462, \"specificity\": 1.0, \"npv\": 0.9977307319641113, \"accuracy\": 0.9978557229042053, \"f1\": 0.9809056192034915, \"f2\": 0.9697950377562028, \"f0_5\": 0.9922737306843267, \"p4\": 0.9898033960285735, \"phi\": 0.9799706500130642}, {\"truth_threshold\": 6.750272749653073, \"match_probability\": 0.9907965657081064, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6292.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 246.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9623737931251526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03762618452310562, \"precision\": 1.0, \"recall\": 0.9623737931251526, \"specificity\": 1.0, \"npv\": 0.9977214932441711, \"accuracy\": 0.9978469610214233, \"f1\": 0.9808261886204209, \"f2\": 0.9696708174084576, \"f0_5\": 0.992241216173595, \"p4\": 0.9897606817593038, \"phi\": 0.979888257052025}, {\"truth_threshold\": 6.828060839398159, \"match_probability\": 0.9912754462212838, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6291.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 247.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9622208476066589, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03777913749217987, \"precision\": 1.0, \"recall\": 0.9622208476066589, \"specificity\": 1.0, \"npv\": 0.997712254524231, \"accuracy\": 0.9978381991386414, \"f1\": 0.9807467456543768, \"f2\": 0.9695465894029529, \"f0_5\": 0.992208693457826, \"p4\": 0.9897179583214948, \"phi\": 0.9798058586889389}, {\"truth_threshold\": 6.855698504794094, \"match_probability\": 0.9914395743612049, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6290.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 248.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9620679020881653, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03793209046125412, \"precision\": 1.0, \"recall\": 0.9620679020881653, \"specificity\": 1.0, \"npv\": 0.9977030158042908, \"accuracy\": 0.9978294372558594, \"f1\": 0.9806672903024634, \"f2\": 0.9694223537389803, \"f0_5\": 0.9921761625339138, \"p4\": 0.9896752257118678, \"phi\": 0.9797234549224006}, {\"truth_threshold\": 6.888775504384195, \"match_probability\": 0.9916319846900492, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6289.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 249.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9619149565696716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03808503970503807, \"precision\": 1.0, \"recall\": 0.9619149565696716, \"specificity\": 1.0, \"npv\": 0.9976937770843506, \"accuracy\": 0.9978206753730774, \"f1\": 0.9805878225617838, \"f2\": 0.9692981104158318, \"f0_5\": 0.9921436233987505, \"p4\": 0.9896324839271426, \"phi\": 0.9796410457510044}, {\"truth_threshold\": 6.927613218978106, \"match_probability\": 0.9918524377408953, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6288.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 250.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.961762011051178, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03823799267411232, \"precision\": 1.0, \"recall\": 0.961762011051178, \"specificity\": 1.0, \"npv\": 0.9976845383644104, \"accuracy\": 0.9978119730949402, \"f1\": 0.9805083424294402, \"f2\": 0.969173859432799, \"f0_5\": 0.9921110760492269, \"p4\": 0.9895897329640375, \"phi\": 0.9795586311733433}, {\"truth_threshold\": 7.011211385603992, \"match_probability\": 0.992307608341821, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6287.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 251.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9616090655326843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03839094564318657, \"precision\": 1.0, \"recall\": 0.9616090655326843, \"specificity\": 1.0, \"npv\": 0.9976752996444702, \"accuracy\": 0.9978032112121582, \"f1\": 0.9804288499025341, \"f2\": 0.9690496007891736, \"f0_5\": 0.9920785204822319, \"p4\": 0.989546972819269, \"phi\": 0.9794762111880106}, {\"truth_threshold\": 7.05003239416887, \"match_probability\": 0.9925103106289734, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6286.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 252.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9614561200141907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03854389861226082, \"precision\": 1.0, \"recall\": 0.9614561200141907, \"specificity\": 1.0, \"npv\": 0.99766606092453, \"accuracy\": 0.9977944493293762, \"f1\": 0.980349344978166, \"f2\": 0.9689253344842469, \"f0_5\": 0.9920459566946531, \"p4\": 0.9895042034895519, \"phi\": 0.9793937857935985}, {\"truth_threshold\": 7.101505911374199, \"match_probability\": 0.9927709245797166, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6285.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 253.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.961303174495697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03869684785604477, \"precision\": 1.0, \"recall\": 0.961303174495697, \"specificity\": 1.0, \"npv\": 0.9976568222045898, \"accuracy\": 0.9977856874465942, \"f1\": 0.9802698276534353, \"f2\": 0.9688010605173105, \"f0_5\": 0.9920133846833765, \"p4\": 0.9894614249716002, \"phi\": 0.9793112624116896}, {\"truth_threshold\": 7.187232452865466, \"match_probability\": 0.9931851287709682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6284.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 254.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9611501693725586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03884980082511902, \"precision\": 1.0, \"recall\": 0.9611501693725586, \"specificity\": 1.0, \"npv\": 0.9976475834846497, \"accuracy\": 0.9977769255638123, \"f1\": 0.9801902979254407, \"f2\": 0.9686767788876557, \"f0_5\": 0.9919808044452864, \"p4\": 0.9894186372621253, \"phi\": 0.9792288261879564}, {\"truth_threshold\": 7.24523463212798, \"match_probability\": 0.9934519210955013, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6282.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 256.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9608442783355713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03915570676326752, \"precision\": 1.0, \"recall\": 0.9608442783355713, \"specificity\": 1.0, \"npv\": 0.9976291060447693, \"accuracy\": 0.9977594614028931, \"f1\": 0.9800312012480499, \"f2\": 0.9684281926373559, \"f0_5\": 0.9919156192761953, \"p4\": 0.9893330342554465, \"phi\": 0.9790639374991575}, {\"truth_threshold\": 7.245557055549236, \"match_probability\": 0.9934533747624218, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6281.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 257.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9606913328170776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03930865600705147, \"precision\": 1.0, \"recall\": 0.9606913328170776, \"specificity\": 1.0, \"npv\": 0.9976198673248291, \"accuracy\": 0.9977506995201111, \"f1\": 0.9799516342928466, \"f2\": 0.9683038880152931, \"f0_5\": 0.9918830143389552, \"p4\": 0.9892902189516586, \"phi\": 0.9789814850312716}, {\"truth_threshold\": 7.2690166835203245, \"match_probability\": 0.99355828821313, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6280.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 258.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.960538387298584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03946160897612572, \"precision\": 1.0, \"recall\": 0.960538387298584, \"specificity\": 1.0, \"npv\": 0.9976106286048889, \"accuracy\": 0.9977419376373291, \"f1\": 0.9798720549227649, \"f2\": 0.9681795757276763, \"f0_5\": 0.9918504011624234, \"p4\": 0.9892473944431798, \"phi\": 0.9788990271458469}, {\"truth_threshold\": 7.311578761249677, \"match_probability\": 0.993744382815482, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6279.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 259.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9603854417800903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.039614561945199966, \"precision\": 1.0, \"recall\": 0.9603854417800903, \"specificity\": 1.0, \"npv\": 0.9976013898849487, \"accuracy\": 0.9977331757545471, \"f1\": 0.979792463134899, \"f2\": 0.9680552557737967, \"f0_5\": 0.9918177797434763, \"p4\": 0.989204560726714, \"phi\": 0.9788165638414714}, {\"truth_threshold\": 7.371378401150003, \"match_probability\": 0.9939968526817623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6278.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 260.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9602324962615967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03976751118898392, \"precision\": 1.0, \"recall\": 0.9602324962615967, \"specificity\": 1.0, \"npv\": 0.9975921511650085, \"accuracy\": 0.9977244138717651, \"f1\": 0.9797128589263421, \"f2\": 0.9679309281529448, \"f0_5\": 0.9917851500789889, \"p4\": 0.9891617177989639, \"phi\": 0.9787340951167335}, {\"truth_threshold\": 7.436473429371888, \"match_probability\": 0.9942601772545586, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6277.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 261.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.960079550743103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.039920464158058167, \"precision\": 1.0, \"recall\": 0.960079550743103, \"specificity\": 1.0, \"npv\": 0.9975829124450684, \"accuracy\": 0.9977156519889832, \"f1\": 0.9796332422941865, \"f2\": 0.9678065928644115, \"f0_5\": 0.9917525121658346, \"p4\": 0.9891188656566304, \"phi\": 0.9786516209702203}, {\"truth_threshold\": 7.440140081260287, \"match_probability\": 0.9942746632460366, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6274.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 264.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9596206545829773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.040379319339990616, \"precision\": 1.0, \"recall\": 0.9596206545829773, \"specificity\": 1.0, \"npv\": 0.9975551962852478, \"accuracy\": 0.997689425945282, \"f1\": 0.9793943178270371, \"f2\": 0.9674335409856288, \"f0_5\": 0.9916545489030789, \"p4\": 0.9889902539091154, \"phi\": 0.9784040733324821}, {\"truth_threshold\": 7.460956060718823, \"match_probability\": 0.9943562155041364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6273.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 265.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9594677090644836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.040532272309064865, \"precision\": 1.0, \"recall\": 0.9594677090644836, \"specificity\": 1.0, \"npv\": 0.9975459575653076, \"accuracy\": 0.9976806640625, \"f1\": 0.9793146514713917, \"f2\": 0.9673091750192753, \"f0_5\": 0.9916218779639583, \"p4\": 0.9889473648754264, \"phi\": 0.978321577477773}, {\"truth_threshold\": 7.598280822051069, \"match_probability\": 0.9948660202090299, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6272.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 266.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.95931476354599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.040685225278139114, \"precision\": 1.0, \"recall\": 0.95931476354599, \"specificity\": 1.0, \"npv\": 0.9975367188453674, \"accuracy\": 0.997671902179718, \"f1\": 0.9792349726775956, \"f2\": 0.9671848013816926, \"f0_5\": 0.9915891987605135, \"p4\": 0.9889044666106351, \"phi\": 0.9782390761942147}, {\"truth_threshold\": 7.60084248041531, \"match_probability\": 0.99487508137046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6271.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 267.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9591618180274963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.040838178247213364, \"precision\": 1.0, \"recall\": 0.9591618180274963, \"specificity\": 1.0, \"npv\": 0.9975274801254272, \"accuracy\": 0.997663140296936, \"f1\": 0.9791552814427356, \"f2\": 0.967060420072171, \"f0_5\": 0.9915565112896085, \"p4\": 0.988861559111433, \"phi\": 0.978156569480391}, {\"truth_threshold\": 7.60942164479793, \"match_probability\": 0.9949053120925837, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6270.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 268.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9590088725090027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.040991127490997314, \"precision\": 1.0, \"recall\": 0.9590088725090027, \"specificity\": 1.0, \"npv\": 0.9975182414054871, \"accuracy\": 0.9976544380187988, \"f1\": 0.9790755777638975, \"f2\": 0.9669360310900006, \"f0_5\": 0.9915238155481055, \"p4\": 0.9888186423745101, \"phi\": 0.9780740573348852}, {\"truth_threshold\": 7.6345224685781785, \"match_probability\": 0.9949927456929847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.958855926990509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.041144080460071564, \"precision\": 1.0, \"recall\": 0.958855926990509, \"specificity\": 1.0, \"npv\": 0.9975090026855469, \"accuracy\": 0.9976456761360168, \"f1\": 0.9789958616381667, \"f2\": 0.9668116344344715, \"f0_5\": 0.9914911115328652, \"p4\": 0.9887757163965548, \"phi\": 0.9779915397562802}, {\"truth_threshold\": 7.6446139564980635, \"match_probability\": 0.9950274750987511, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6267.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 271.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9585500359535217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04144998639822006, \"precision\": 1.0, \"recall\": 0.9585500359535217, \"specificity\": 1.0, \"npv\": 0.9974905252456665, \"accuracy\": 0.9976281523704529, \"f1\": 0.9788363920343616, \"f2\": 0.9665628181004966, \"f0_5\": 0.9914256786686072, \"p4\": 0.9886898367042922, \"phi\": 0.9778263955919644}, {\"truth_threshold\": 7.663375850272954, \"match_probability\": 0.995091407525636, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6266.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 272.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9583970904350281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04160293564200401, \"precision\": 1.0, \"recall\": 0.9583970904350281, \"specificity\": 1.0, \"npv\": 0.9974812865257263, \"accuracy\": 0.9976193904876709, \"f1\": 0.978756638550453, \"f2\": 0.9664383984206305, \"f0_5\": 0.991392949813303, \"p4\": 0.9886468829833539, \"phi\": 0.9777438616985847}, {\"truth_threshold\": 7.70570664620268, \"match_probability\": 0.9952326637692601, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6264.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 274.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.958091139793396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04190884158015251, \"precision\": 1.0, \"recall\": 0.958091139793396, \"specificity\": 1.0, \"npv\": 0.997462809085846, \"accuracy\": 0.9976019263267517, \"f1\": 0.9785970942040306, \"f2\": 0.9661895360315893, \"f0_5\": 0.9913274672406153, \"p4\": 0.9885609477752729, \"phi\": 0.9775787775940782}, {\"truth_threshold\": 7.749204167443318, \"match_probability\": 0.9953735995580909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6263.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 275.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9579381942749023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04206179082393646, \"precision\": 1.0, \"recall\": 0.9579381942749023, \"specificity\": 1.0, \"npv\": 0.9974535703659058, \"accuracy\": 0.9975931644439697, \"f1\": 0.9785173033356769, \"f2\": 0.9660650933209933, \"f0_5\": 0.9912947135169358, \"p4\": 0.9885179662814897, \"phi\": 0.9774962273801105}, {\"truth_threshold\": 7.751246270406881, \"match_probability\": 0.9953801132609971, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6262.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 276.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9577852487564087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04221474379301071, \"precision\": 1.0, \"recall\": 0.9577852487564087, \"specificity\": 1.0, \"npv\": 0.9974443316459656, \"accuracy\": 0.9975844025611877, \"f1\": 0.9784375, \"f2\": 0.9659406429320664, \"f0_5\": 0.9912619514974988, \"p4\": 0.9884749755234483, \"phi\": 0.9774136717231052}, {\"truth_threshold\": 7.789403960323453, \"match_probability\": 0.9955001597746845, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6261.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 277.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.957632303237915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04236769676208496, \"precision\": 1.0, \"recall\": 0.957632303237915, \"specificity\": 1.0, \"npv\": 0.9974350929260254, \"accuracy\": 0.9975756406784058, \"f1\": 0.9783576841940776, \"f2\": 0.9658161848640977, \"f0_5\": 0.9912291811791527, \"p4\": 0.9884319754978242, \"phi\": 0.9773311106216404}, {\"truth_threshold\": 7.820252376821779, \"match_probability\": 0.9955949368349759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6260.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 278.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9574793577194214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04252064973115921, \"precision\": 1.0, \"recall\": 0.9574793577194214, \"specificity\": 1.0, \"npv\": 0.9974258542060852, \"accuracy\": 0.9975668787956238, \"f1\": 0.9782778559149867, \"f2\": 0.9656917191163766, \"f0_5\": 0.9911964025587434, \"p4\": 0.9883889662012918, \"phi\": 0.9772485440742936}, {\"truth_threshold\": 7.855421016965859, \"match_probability\": 0.9957005648882882, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9573264122009277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04267359897494316, \"precision\": 1.0, \"recall\": 0.9573264122009277, \"specificity\": 1.0, \"npv\": 0.997416615486145, \"accuracy\": 0.9975581169128418, \"f1\": 0.9781980151598031, \"f2\": 0.9655672456881923, \"f0_5\": 0.9911636156331158, \"p4\": 0.9883459476305234, \"phi\": 0.9771659720796422}, {\"truth_threshold\": 7.873878741679186, \"match_probability\": 0.9957549891207511, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6258.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 280.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9571734666824341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04282655194401741, \"precision\": 1.0, \"recall\": 0.9571734666824341, \"specificity\": 1.0, \"npv\": 0.9974073767662048, \"accuracy\": 0.9975493550300598, \"f1\": 0.9781181619256017, \"f2\": 0.9654427645788337, \"f0_5\": 0.991130820399113, \"p4\": 0.9883029197821901, \"phi\": 0.9770833018713556}, {\"truth_threshold\": 7.895068457546449, \"match_probability\": 0.9958166235398912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6256.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 282.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.956867516040802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04313245788216591, \"precision\": 1.0, \"recall\": 0.956867516040802, \"specificity\": 1.0, \"npv\": 0.9973888993263245, \"accuracy\": 0.9975318908691406, \"f1\": 0.9779584180084414, \"f2\": 0.9651937793137497, \"f0_5\": 0.9910652049933464, \"p4\": 0.9882168362395042, \"phi\": 0.9769181306187461}, {\"truth_threshold\": 7.896852969851113, \"match_probability\": 0.9958217732763675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6255.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 283.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9567145705223083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04328540712594986, \"precision\": 1.0, \"recall\": 0.9567145705223083, \"specificity\": 1.0, \"npv\": 0.9973796606063843, \"accuracy\": 0.9975231289863586, \"f1\": 0.9778785273196279, \"f2\": 0.965069275156602, \"f0_5\": 0.9910323848152608, \"p4\": 0.9881737805384855, \"phi\": 0.976835536813648}, {\"truth_threshold\": 7.900406329571735, \"match_probability\": 0.9958320087512286, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6254.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 284.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9565616250038147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04343836009502411, \"precision\": 1.0, \"recall\": 0.9565616250038147, \"specificity\": 1.0, \"npv\": 0.9973704218864441, \"accuracy\": 0.9975143671035767, \"f1\": 0.9777986241400876, \"f2\": 0.9649447633154354, \"f0_5\": 0.9909995563161564, \"p4\": 0.9881307155465697, \"phi\": 0.9767529375541201}, {\"truth_threshold\": 7.955728014932995, \"match_probability\": 0.9959881802257493, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6253.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 285.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.956408679485321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04359131306409836, \"precision\": 1.0, \"recall\": 0.956408679485321, \"specificity\": 1.0, \"npv\": 0.9973611831665039, \"accuracy\": 0.9975056052207947, \"f1\": 0.9777187084668908, \"f2\": 0.9648202437895387, \"f0_5\": 0.9909667194928684, \"p4\": 0.9880876412604198, \"phi\": 0.9766703328387359}, {\"truth_threshold\": 8.008163878678728, \"match_probability\": 0.9961308208398815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6251.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 287.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9561027884483337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04389721527695656, \"precision\": 1.0, \"recall\": 0.9561027884483337, \"specificity\": 1.0, \"npv\": 0.9973427653312683, \"accuracy\": 0.9974881410598755, \"f1\": 0.9775588396278051, \"f2\": 0.9645711816807085, \"f0_5\": 0.9909010208610741, \"p4\": 0.9880014647920614, \"phi\": 0.9765051070346908}, {\"truth_threshold\": 8.015581979261063, \"match_probability\": 0.9961505880763378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6249.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 289.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9557968974113464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04420312121510506, \"precision\": 1.0, \"recall\": 0.9557968974113464, \"specificity\": 1.0, \"npv\": 0.9973242878913879, \"accuracy\": 0.9974706172943115, \"f1\": 0.9773989207789161, \"f2\": 0.964322088824419, \"f0_5\": 0.9908352888945265, \"p4\": 0.9879152511066821, \"phi\": 0.9763397665622737}, {\"truth_threshold\": 8.04138158640201, \"match_probability\": 0.9962185569585114, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6248.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 290.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9556439518928528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04435607045888901, \"precision\": 1.0, \"recall\": 0.9556439518928528, \"specificity\": 1.0, \"npv\": 0.9973150491714478, \"accuracy\": 0.9974618554115295, \"f1\": 0.9773189425934616, \"f2\": 0.9641975308641976, \"f0_5\": 0.990802410402791, \"p4\": 0.9878721302992503, \"phi\": 0.9762571345391944}, {\"truth_threshold\": 8.049734222944547, \"match_probability\": 0.9962403046981727, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6247.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 291.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9554909467697144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04450902342796326, \"precision\": 1.0, \"recall\": 0.9554909467697144, \"specificity\": 1.0, \"npv\": 0.9973058104515076, \"accuracy\": 0.9974530935287476, \"f1\": 0.977238951896754, \"f2\": 0.9640729652149758, \"f0_5\": 0.9907695235678488, \"p4\": 0.9878290001775285, \"phi\": 0.9761744970516871}, {\"truth_threshold\": 8.091361541248652, \"match_probability\": 0.9963468456627501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6245.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 293.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.955185055732727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.044814929366111755, \"precision\": 1.0, \"recall\": 0.955185055732727, \"specificity\": 1.0, \"npv\": 0.9972873330116272, \"accuracy\": 0.9974356293678284, \"f1\": 0.9770789329578347, \"f2\": 0.9638238108466833, \"f0_5\": 0.9907037248556381, \"p4\": 0.9877427119778214, \"phi\": 0.9760092056776655}, {\"truth_threshold\": 8.161032786961373, \"match_probability\": 0.996518473624577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6242.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 296.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9547262191772461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.045273784548044205, \"precision\": 1.0, \"recall\": 0.9547262191772461, \"specificity\": 1.0, \"npv\": 0.9972596168518066, \"accuracy\": 0.9974093437194824, \"f1\": 0.9768388106416276, \"f2\": 0.9634500216089399, \"f0_5\": 0.9906049641338158, \"p4\": 0.9876132097373302, \"phi\": 0.9757612275976434}, {\"truth_threshold\": 8.19282476844228, \"match_probability\": 0.9965940967591976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6241.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 297.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9545732736587524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.045426737517118454, \"precision\": 1.0, \"recall\": 0.9545732736587524, \"specificity\": 1.0, \"npv\": 0.9972503781318665, \"accuracy\": 0.9974005818367004, \"f1\": 0.9767587448157132, \"f2\": 0.9633254098107615, \"f0_5\": 0.990572027172878, \"p4\": 0.9875700236595016, \"phi\": 0.9756785572935087}, {\"truth_threshold\": 8.20324281360002, \"match_probability\": 0.996618520142615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6229.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 309.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9527378678321838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04726215824484825, \"precision\": 1.0, \"recall\": 0.9527378678321838, \"specificity\": 1.0, \"npv\": 0.9971396327018738, \"accuracy\": 0.9972955584526062, \"f1\": 0.975796976580246, \"f2\": 0.9618294678978413, \"f0_5\": 0.9901761302219113, \"p4\": 0.9870510614182708, \"phi\": 0.9746859002896712}, {\"truth_threshold\": 8.219957395611182, \"match_probability\": 0.9966573405679777, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6228.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 310.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9525848627090454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0474151112139225, \"precision\": 1.0, \"recall\": 0.9525848627090454, \"specificity\": 1.0, \"npv\": 0.9971303939819336, \"accuracy\": 0.9972867965698242, \"f1\": 0.9757167476108413, \"f2\": 0.9617047560222359, \"f0_5\": 0.9901430842607313, \"p4\": 0.9870077536870565, \"phi\": 0.9746031586915316}, {\"truth_threshold\": 8.267188660243358, \"match_probability\": 0.9967646530340906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6227.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 311.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9524319171905518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04756806418299675, \"precision\": 1.0, \"recall\": 0.9524319171905518, \"specificity\": 1.0, \"npv\": 0.9971211552619934, \"accuracy\": 0.997278094291687, \"f1\": 0.9756365060712887, \"f2\": 0.9615800364433738, \"f0_5\": 0.9901100298925142, \"p4\": 0.9869644365742835, \"phi\": 0.9745204116002429}, {\"truth_threshold\": 8.290669146923836, \"match_probability\": 0.996816717253116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6226.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 312.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9522789716720581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.047721017152071, \"precision\": 1.0, \"recall\": 0.9522789716720581, \"specificity\": 1.0, \"npv\": 0.9971119165420532, \"accuracy\": 0.997269332408905, \"f1\": 0.9755562519586336, \"f2\": 0.9614553091605411, \"f0_5\": 0.9900769671140512, \"p4\": 0.986921110076571, \"phi\": 0.9744376590143634}, {\"truth_threshold\": 8.312594373690816, \"match_probability\": 0.9968645786135247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6225.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 313.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9521260261535645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04787396639585495, \"precision\": 1.0, \"recall\": 0.9521260261535645, \"specificity\": 1.0, \"npv\": 0.9971027374267578, \"accuracy\": 0.997260570526123, \"f1\": 0.9754759852699209, \"f2\": 0.961330574173024, \"f0_5\": 0.9900438959221325, \"p4\": 0.9868777741905373, \"phi\": 0.9743549009324503}, {\"truth_threshold\": 8.363394701848309, \"match_probability\": 0.9969727338126234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6224.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 314.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9519730806350708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0480269193649292, \"precision\": 1.0, \"recall\": 0.9519730806350708, \"specificity\": 1.0, \"npv\": 0.9970934987068176, \"accuracy\": 0.9972518086433411, \"f1\": 0.975395706002194, \"f2\": 0.9612058314801087, \"f0_5\": 0.9900108163135458, \"p4\": 0.9868344289127987, \"phi\": 0.9742721373530606}, {\"truth_threshold\": 8.4784715811908, \"match_probability\": 0.9972041760220722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6223.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 315.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9518201351165771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04817987233400345, \"precision\": 1.0, \"recall\": 0.9518201351165771, \"specificity\": 1.0, \"npv\": 0.9970842599868774, \"accuracy\": 0.9972430467605591, \"f1\": 0.9753154141524959, \"f2\": 0.961081081081081, \"f0_5\": 0.9899777282850779, \"p4\": 0.9867910742399699, \"phi\": 0.9741893682747508}, {\"truth_threshold\": 8.478804225301614, \"match_probability\": 0.9972048187829375, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6221.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 317.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9515142440795898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04848577454686165, \"precision\": 1.0, \"recall\": 0.9515142440795898, \"specificity\": 1.0, \"npv\": 0.9970657825469971, \"accuracy\": 0.9972255825996399, \"f1\": 0.9751547926953523, \"f2\": 0.9608315571618324, \"f0_5\": 0.9899115269556362, \"p4\": 0.9867043366954927, \"phi\": 0.974023720591164}, {\"truth_threshold\": 8.485871384882946, \"match_probability\": 0.9972184397313991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6220.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 318.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9513612985610962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0486387275159359, \"precision\": 1.0, \"recall\": 0.9513612985610962, \"specificity\": 1.0, \"npv\": 0.9970565438270569, \"accuracy\": 0.9972168207168579, \"f1\": 0.9750744630819878, \"f2\": 0.9607067836401829, \"f0_5\": 0.9898784136482272, \"p4\": 0.9866609538170656, \"phi\": 0.9739409350003785}, {\"truth_threshold\": 8.651486320342737, \"match_probability\": 0.9975193560034578, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6219.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 319.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9512082934379578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04879168048501015, \"precision\": 1.0, \"recall\": 0.9512082934379578, \"specificity\": 1.0, \"npv\": 0.9970473647117615, \"accuracy\": 0.9972080588340759, \"f1\": 0.9749941208748139, \"f2\": 0.9605820024095642, \"f0_5\": 0.9898452919080665, \"p4\": 0.9866175615299911, \"phi\": 0.9738581439048903}, {\"truth_threshold\": 8.720782753745633, \"match_probability\": 0.9976354164506805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6218.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 320.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9510553479194641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0489446297287941, \"precision\": 1.0, \"recall\": 0.9510553479194641, \"specificity\": 1.0, \"npv\": 0.9970381259918213, \"accuracy\": 0.997199296951294, \"f1\": 0.9749137660708687, \"f2\": 0.9604572134692617, \"f0_5\": 0.9898121617319325, \"p4\": 0.9865741598308759, \"phi\": 0.9737753473032531}, {\"truth_threshold\": 8.754423276097926, \"match_probability\": 0.997689789641404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6217.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 321.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9509024024009705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04909758269786835, \"precision\": 1.0, \"recall\": 0.9509024024009705, \"specificity\": 1.0, \"npv\": 0.9970288872718811, \"accuracy\": 0.997190535068512, \"f1\": 0.9748333986671893, \"f2\": 0.960332416818561, \"f0_5\": 0.9897790231166019, \"p4\": 0.9865307487163248, \"phi\": 0.9736925451940194}, {\"truth_threshold\": 8.77885306769289, \"match_probability\": 0.997728491984906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6212.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 326.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9501376748085022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.049862343817949295, \"precision\": 1.0, \"recall\": 0.9501376748085022, \"specificity\": 1.0, \"npv\": 0.996982753276825, \"accuracy\": 0.9971467852592468, \"f1\": 0.9744313725490196, \"f2\": 0.9597083178840687, \"f0_5\": 0.9896132033390683, \"p4\": 0.9863135517930938, \"phi\": 0.9732783588952982}, {\"truth_threshold\": 8.816579752160495, \"match_probability\": 0.9977869925626162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6209.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 329.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9496787786483765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.050321198999881744, \"precision\": 1.0, \"recall\": 0.9496787786483765, \"specificity\": 1.0, \"npv\": 0.9969550371170044, \"accuracy\": 0.9971204996109009, \"f1\": 0.9741900054914882, \"f2\": 0.9593337659528445, \"f0_5\": 0.9895136099955377, \"p4\": 0.9861831204362903, \"phi\": 0.9730298367637165}, {\"truth_threshold\": 8.863035337425012, \"match_probability\": 0.9978569672657753, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6207.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 331.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9493728876113892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05062710493803024, \"precision\": 1.0, \"recall\": 0.9493728876113892, \"specificity\": 1.0, \"npv\": 0.9969366192817688, \"accuracy\": 0.9971030354499817, \"f1\": 0.9740290309925461, \"f2\": 0.9590840260823882, \"f0_5\": 0.9894471720971753, \"p4\": 0.9860961189737804, \"phi\": 0.9728641277418362}, {\"truth_threshold\": 8.873655165158356, \"match_probability\": 0.9978726509971408, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6206.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 332.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9492199420928955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.050780054181814194, \"precision\": 1.0, \"recall\": 0.9492199420928955, \"specificity\": 1.0, \"npv\": 0.9969273805618286, \"accuracy\": 0.9970942735671997, \"f1\": 0.9739485247959824, \"f2\": 0.9589591445701218, \"f0_5\": 0.9894139404374721, \"p4\": 0.9860526040648991, \"phi\": 0.972781264946289}, {\"truth_threshold\": 8.873878741679185, \"match_probability\": 0.9978729799487466, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6205.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 333.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9490669965744019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05093300715088844, \"precision\": 1.0, \"recall\": 0.9490669965744019, \"specificity\": 1.0, \"npv\": 0.9969181418418884, \"accuracy\": 0.9970855116844177, \"f1\": 0.9738680059640586, \"f2\": 0.9588342553388757, \"f0_5\": 0.989380700299764, \"p4\": 0.9860090796997149, \"phi\": 0.972698396625732}, {\"truth_threshold\": 8.891920947715544, \"match_probability\": 0.9978993590888355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6204.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 334.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9489140510559082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05108596011996269, \"precision\": 1.0, \"recall\": 0.9489140510559082, \"specificity\": 1.0, \"npv\": 0.9969089031219482, \"accuracy\": 0.9970767498016357, \"f1\": 0.9737874744938, \"f2\": 0.9587093583879343, \"f0_5\": 0.9893474516808063, \"p4\": 0.9859655458748112, \"phi\": 0.9726155227787098}, {\"truth_threshold\": 8.90064401694897, \"match_probability\": 0.997911995581564, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6202.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 336.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9486081600189209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05139186233282089, \"precision\": 1.0, \"recall\": 0.9486081600189209, \"specificity\": 1.0, \"npv\": 0.9968904852867126, \"accuracy\": 0.9970592856407166, \"f1\": 0.9736263736263736, \"f2\": 0.9584595413241022, \"f0_5\": 0.9892809289861545, \"p4\": 0.9858784498321728, \"phi\": 0.9724496653408293}, {\"truth_threshold\": 8.91271932270523, \"match_probability\": 0.9979293631318594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6195.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 343.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9475374817848206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05246252566576004, \"precision\": 1.0, \"recall\": 0.9475374817848206, \"specificity\": 1.0, \"npv\": 0.9968258738517761, \"accuracy\": 0.9969980120658875, \"f1\": 0.9730621220450797, \"f2\": 0.9575849383250379, \"f0_5\": 0.989047831917747, \"p4\": 0.985573315198814, \"phi\": 0.971869316016039}, {\"truth_threshold\": 8.922835557297958, \"match_probability\": 0.9979438019825467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6194.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 344.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9473845362663269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05261547863483429, \"precision\": 1.0, \"recall\": 0.9473845362663269, \"specificity\": 1.0, \"npv\": 0.9968166947364807, \"accuracy\": 0.9969892501831055, \"f1\": 0.9729814640276468, \"f2\": 0.9574599641377605, \"f0_5\": 0.9890144983074663, \"p4\": 0.9855296865884616, \"phi\": 0.9717862936018214}, {\"truth_threshold\": 8.95155351851825, \"match_probability\": 0.9979842458216248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6193.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 345.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9472315907478333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05276843160390854, \"precision\": 1.0, \"recall\": 0.9472315907478333, \"specificity\": 1.0, \"npv\": 0.9968074560165405, \"accuracy\": 0.9969804883003235, \"f1\": 0.9729007933390935, \"f2\": 0.9573349822229092, \"f0_5\": 0.9889811561801342, \"p4\": 0.9854860484807028, \"phi\": 0.9717033588533112}, {\"truth_threshold\": 8.963898408361041, \"match_probability\": 0.9980013863666463, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6192.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 346.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9470786452293396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05292138084769249, \"precision\": 1.0, \"recall\": 0.9470786452293396, \"specificity\": 1.0, \"npv\": 0.9967982172966003, \"accuracy\": 0.9969717264175415, \"f1\": 0.9728201099764336, \"f2\": 0.9572099925797675, \"f0_5\": 0.9889478055324857, \"p4\": 0.9854424008721013, \"phi\": 0.9716204185608289}, {\"truth_threshold\": 9.021054288576595, \"match_probability\": 0.9980788692313822, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6191.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 347.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9469256401062012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05307433381676674, \"precision\": 1.0, \"recall\": 0.9469256401062012, \"specificity\": 1.0, \"npv\": 0.9967889785766602, \"accuracy\": 0.9969629645347595, \"f1\": 0.9727394139366801, \"f2\": 0.9570849952076184, \"f0_5\": 0.9889144463612549, \"p4\": 0.9853987437592195, \"phi\": 0.971537472722912}, {\"truth_threshold\": 9.049559967857022, \"match_probability\": 0.9981163847971585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6190.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 348.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9467726945877075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05322728678584099, \"precision\": 1.0, \"recall\": 0.9467726945877075, \"specificity\": 1.0, \"npv\": 0.9967797994613647, \"accuracy\": 0.9969542622566223, \"f1\": 0.9726587052168447, \"f2\": 0.9569599901057448, \"f0_5\": 0.9888810786631733, \"p4\": 0.9853550771386181, \"phi\": 0.9714545213380975}, {\"truth_threshold\": 9.063373516987077, \"match_probability\": 0.998134300523397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6189.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 349.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9466197490692139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05338023975491524, \"precision\": 1.0, \"recall\": 0.9466197490692139, \"specificity\": 1.0, \"npv\": 0.9967705607414246, \"accuracy\": 0.9969455003738403, \"f1\": 0.9725779838139389, \"f2\": 0.95683497727343, \"f0_5\": 0.9888477024349716, \"p4\": 0.9853114010068563, \"phi\": 0.9713715644049216}, {\"truth_threshold\": 9.085068588086397, \"match_probability\": 0.9981620956054766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6188.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 350.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9464668035507202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05353318899869919, \"precision\": 1.0, \"recall\": 0.9464668035507202, \"specificity\": 1.0, \"npv\": 0.9967613220214844, \"accuracy\": 0.9969367384910583, \"f1\": 0.9724972497249725, \"f2\": 0.9567099567099567, \"f0_5\": 0.9888143176733781, \"p4\": 0.9852677153604912, \"phi\": 0.9712886019219201}, {\"truth_threshold\": 9.126199016317393, \"match_probability\": 0.9982136610871719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6186.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 352.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9461609125137329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05383909493684769, \"precision\": 1.0, \"recall\": 0.9461609125137329, \"specificity\": 1.0, \"npv\": 0.9967429041862488, \"accuracy\": 0.9969192147254944, \"f1\": 0.9723357434768941, \"f2\": 0.9564598923866658, \"f0_5\": 0.9887475225369222, \"p4\": 0.9851803155101726, \"phi\": 0.9711226603005801}, {\"truth_threshold\": 9.13171151950192, \"match_probability\": 0.9982204614986355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6185.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 353.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9460079669952393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.053992047905921936, \"precision\": 1.0, \"recall\": 0.9460079669952393, \"specificity\": 1.0, \"npv\": 0.9967336654663086, \"accuracy\": 0.9969104528427124, \"f1\": 0.9722549713117975, \"f2\": 0.9563348486254136, \"f0_5\": 0.9887141121555086, \"p4\": 0.9851366012993257, \"phi\": 0.9710395878800886}, {\"truth_threshold\": 9.142111712127685, \"match_probability\": 0.9982332212381153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6183.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 355.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.945702075958252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.054297950118780136, \"precision\": 1.0, \"recall\": 0.945702075958252, \"specificity\": 1.0, \"npv\": 0.9967151880264282, \"accuracy\": 0.9968929886817932, \"f1\": 0.9720933888845217, \"f2\": 0.9560847379001083, \"f0_5\": 0.98864726574992, \"p4\": 0.9850491442890099, \"phi\": 0.9708736129147936}, {\"truth_threshold\": 9.155273406347998, \"match_probability\": 0.9982492381537863, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6182.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 356.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9455490708351135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.054450903087854385, \"precision\": 1.0, \"recall\": 0.9455490708351135, \"specificity\": 1.0, \"npv\": 0.9967060089111328, \"accuracy\": 0.9968842267990112, \"f1\": 0.9720125786163522, \"f2\": 0.9559596709346199, \"f0_5\": 0.9886138297191838, \"p4\": 0.9850054014826377, \"phi\": 0.9707906170949419}, {\"truth_threshold\": 9.197500788319292, \"match_probability\": 0.9982996540231412, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6181.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 357.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9453961253166199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.054603856056928635, \"precision\": 1.0, \"recall\": 0.9453961253166199, \"specificity\": 1.0, \"npv\": 0.9966967701911926, \"accuracy\": 0.9968754649162292, \"f1\": 0.9719317556411667, \"f2\": 0.9558345962329509, \"f0_5\": 0.9885803851321092, \"p4\": 0.9849616491375175, \"phi\": 0.9707076157149962}, {\"truth_threshold\": 9.234644944136907, \"match_probability\": 0.9983428013788451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6180.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 358.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9452431797981262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.054756805300712585, \"precision\": 1.0, \"recall\": 0.9452431797981262, \"specificity\": 1.0, \"npv\": 0.9966875314712524, \"accuracy\": 0.9968667030334473, \"f1\": 0.971850919955968, \"f2\": 0.9557095137943833, \"f0_5\": 0.9885469319854118, \"p4\": 0.9849178872501932, \"phi\": 0.9706246087734876}, {\"truth_threshold\": 9.259097987861447, \"match_probability\": 0.9983706080745611, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6176.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 362.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9446313977241516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.055368613451719284, \"precision\": 1.0, \"recall\": 0.9446313977241516, \"specificity\": 1.0, \"npv\": 0.9966506361961365, \"accuracy\": 0.9968317151069641, \"f1\": 0.9715274500550574, \"f2\": 0.9552091066567682, \"f0_5\": 0.9884130337366366, \"p4\": 0.9847427442096808, \"phi\": 0.9702925253624219}, {\"truth_threshold\": 9.323452536968889, \"match_probability\": 0.9984415826190443, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6173.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 365.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9441725015640259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05582746863365173, \"precision\": 1.0, \"recall\": 0.9441725015640259, \"specificity\": 1.0, \"npv\": 0.9966229796409607, \"accuracy\": 0.9968054294586182, \"f1\": 0.9712847140272205, \"f2\": 0.9548337200309358, \"f0_5\": 0.9883125200128082, \"p4\": 0.9846112865665675, \"phi\": 0.9700433109709814}, {\"truth_threshold\": 9.329228705046258, \"match_probability\": 0.9984477999691095, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6172.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 366.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9440195560455322, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05598042160272598, \"precision\": 1.0, \"recall\": 0.9440195560455322, \"specificity\": 1.0, \"npv\": 0.9966138005256653, \"accuracy\": 0.9967966675758362, \"f1\": 0.9712037765538946, \"f2\": 0.9547085756713278, \"f0_5\": 0.9882789982706719, \"p4\": 0.984567448216999, \"phi\": 0.9699602594768811}, {\"truth_threshold\": 9.335766158058695, \"match_probability\": 0.9984548068789313, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6169.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 369.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9435607194900513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05643927678465843, \"precision\": 1.0, \"recall\": 0.9435607194900513, \"specificity\": 1.0, \"npv\": 0.9965861439704895, \"accuracy\": 0.996770441532135, \"f1\": 0.9709608876996931, \"f2\": 0.9543330961294514, \"f0_5\": 0.9881783814954828, \"p4\": 0.9844358757141085, \"phi\": 0.9697110715398027}, {\"truth_threshold\": 9.387995721043705, \"match_probability\": 0.998509664791252, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6168.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 370.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9434077739715576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05659222975373268, \"precision\": 1.0, \"recall\": 0.9434077739715576, \"specificity\": 1.0, \"npv\": 0.9965769052505493, \"accuracy\": 0.996761679649353, \"f1\": 0.970879899260192, \"f2\": 0.9542079207920792, \"f0_5\": 0.9881448253764819, \"p4\": 0.984391999050169, \"phi\": 0.9696279977375986}, {\"truth_threshold\": 9.392639490652305, \"match_probability\": 0.9985144470786386, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6162.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 376.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9424900412559509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05750994011759758, \"precision\": 1.0, \"recall\": 0.9424900412559509, \"specificity\": 1.0, \"npv\": 0.9965215921401978, \"accuracy\": 0.9967091679573059, \"f1\": 0.9703937007874016, \"f2\": 0.9534567060716718, \"f0_5\": 0.9879433078945681, \"p4\": 0.9841285376117612, \"phi\": 0.9691293442343948}, {\"truth_threshold\": 9.415159633570292, \"match_probability\": 0.9985374225202012, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9423370957374573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05766289308667183, \"precision\": 1.0, \"recall\": 0.9423370957374573, \"specificity\": 1.0, \"npv\": 0.9965123534202576, \"accuracy\": 0.9967004060745239, \"f1\": 0.9703126230411844, \"f2\": 0.9533314764955281, \"f0_5\": 0.9879096914886794, \"p4\": 0.9840845937637187, \"phi\": 0.9690462313289775}, {\"truth_threshold\": 9.434226824451748, \"match_probability\": 0.9985565975922943, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6160.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 378.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9421841502189636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05781584605574608, \"precision\": 1.0, \"recall\": 0.9421841502189636, \"specificity\": 1.0, \"npv\": 0.9965031147003174, \"accuracy\": 0.9966916441917419, \"f1\": 0.9702315325248071, \"f2\": 0.9532062391681109, \"f0_5\": 0.9878760664571172, \"p4\": 0.9840406403040031, \"phi\": 0.9689631128324873}, {\"truth_threshold\": 9.460956060718823, \"match_probability\": 0.9985830561818699, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6159.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 379.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.94203120470047, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05796879902482033, \"precision\": 1.0, \"recall\": 0.94203120470047, \"specificity\": 1.0, \"npv\": 0.996493935585022, \"accuracy\": 0.9966829419136047, \"f1\": 0.9701504292352524, \"f2\": 0.9530809940887004, \"f0_5\": 0.9878424327965613, \"p4\": 0.9839966772291231, \"phi\": 0.9688799887434427}, {\"truth_threshold\": 9.47030990576482, \"match_probability\": 0.998592200457314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6158.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 380.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9418782591819763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05812174826860428, \"precision\": 1.0, \"recall\": 0.9418782591819763, \"specificity\": 1.0, \"npv\": 0.9964846968650818, \"accuracy\": 0.9966741800308228, \"f1\": 0.9700693131695022, \"f2\": 0.9529557412565769, \"f0_5\": 0.9878087905036894, \"p4\": 0.9839527045355861, \"phi\": 0.9687968590603615}, {\"truth_threshold\": 9.471251224693056, \"match_probability\": 0.9985931174164164, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6157.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 381.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9417253136634827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05827470123767853, \"precision\": 1.0, \"recall\": 0.9417253136634827, \"specificity\": 1.0, \"npv\": 0.9964754581451416, \"accuracy\": 0.9966654181480408, \"f1\": 0.9699881843245373, \"f2\": 0.9528304806710205, \"f0_5\": 0.987775139575178, \"p4\": 0.9839087222198977, \"phi\": 0.9687136303027869}, {\"truth_threshold\": 9.475670255909103, \"match_probability\": 0.9985974141246121, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6154.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 384.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9412664175033569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05873355641961098, \"precision\": 1.0, \"recall\": 0.9412664175033569, \"specificity\": 1.0, \"npv\": 0.9964478611946106, \"accuracy\": 0.9966391324996948, \"f1\": 0.9697447210841474, \"f2\": 0.9524546523865536, \"f0_5\": 0.9876741349425435, \"p4\": 0.9837767175049535, \"phi\": 0.968464190857545}, {\"truth_threshold\": 9.489346450497905, \"match_probability\": 0.9986106288922619, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6153.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 385.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9411134719848633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.058886509388685226, \"precision\": 1.0, \"recall\": 0.9411134719848633, \"specificity\": 1.0, \"npv\": 0.9964386224746704, \"accuracy\": 0.9966304302215576, \"f1\": 0.9696635410921125, \"f2\": 0.952329360780065, \"f0_5\": 0.9876404494382023, \"p4\": 0.9837326966656808, \"phi\": 0.9683810331748604}, {\"truth_threshold\": 9.544500206723695, \"match_probability\": 0.9986626719273081, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6152.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 386.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9409605264663696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.059039462357759476, \"precision\": 1.0, \"recall\": 0.9409605264663696, \"specificity\": 1.0, \"npv\": 0.9964293837547302, \"accuracy\": 0.9966216683387756, \"f1\": 0.9695823483057525, \"f2\": 0.9522040614165428, \"f0_5\": 0.987606755281577, \"p4\": 0.9836886661867588, \"phi\": 0.9682978698892312}, {\"truth_threshold\": 9.562865992186524, \"match_probability\": 0.998679566129962, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6150.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 388.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9406546354293823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.059345364570617676, \"precision\": 1.0, \"recall\": 0.9406546354293823, \"specificity\": 1.0, \"npv\": 0.9964109659194946, \"accuracy\": 0.9966041445732117, \"f1\": 0.9694199243379571, \"f2\": 0.951953439415516, \"f0_5\": 0.9875393409981373, \"p4\": 0.9836005762959473, \"phi\": 0.9681315265031929}, {\"truth_threshold\": 9.58423964297909, \"match_probability\": 0.9986989590113069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6149.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 389.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9405016899108887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.059498317539691925, \"precision\": 1.0, \"recall\": 0.9405016899108887, \"specificity\": 1.0, \"npv\": 0.9964017271995544, \"accuracy\": 0.9965953826904297, \"f1\": 0.9693386931504689, \"f2\": 0.9518281167765704, \"f0_5\": 0.9875056208646495, \"p4\": 0.9835565168770436, \"phi\": 0.9680483463998086}, {\"truth_threshold\": 9.651486320342737, \"match_probability\": 0.9987581376925901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6148.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 390.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.940348744392395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.059651270508766174, \"precision\": 1.0, \"recall\": 0.940348744392395, \"specificity\": 1.0, \"npv\": 0.996392548084259, \"accuracy\": 0.9965866208076477, \"f1\": 0.9692574491565505, \"f2\": 0.951702786377709, \"f0_5\": 0.9874718920655317, \"p4\": 0.983512447804462, \"phi\": 0.9679650671440543}, {\"truth_threshold\": 9.653729276478453, \"match_probability\": 0.9987600645221537, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6147.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 391.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9401957988739014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.059804219752550125, \"precision\": 1.0, \"recall\": 0.9401957988739014, \"specificity\": 1.0, \"npv\": 0.9963833093643188, \"accuracy\": 0.9965779185295105, \"f1\": 0.9691761923531731, \"f2\": 0.9515774482182111, \"f0_5\": 0.9874381545974427, \"p4\": 0.9834683690746914, \"phi\": 0.967881875814217}, {\"truth_threshold\": 9.659788045738733, \"match_probability\": 0.9987652544434249, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6146.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 392.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9400428533554077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.059957172721624374, \"precision\": 1.0, \"recall\": 0.9400428533554077, \"specificity\": 1.0, \"npv\": 0.9963740706443787, \"accuracy\": 0.9965691566467285, \"f1\": 0.9690949227373068, \"f2\": 0.9514521022973559, \"f0_5\": 0.98740440845704, \"p4\": 0.9834242806842184, \"phi\": 0.9677986788725056}, {\"truth_threshold\": 9.676324041969808, \"match_probability\": 0.9987793089724355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6145.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 393.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9398898482322693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.060110125690698624, \"precision\": 1.0, \"recall\": 0.9398898482322693, \"specificity\": 1.0, \"npv\": 0.9963648915290833, \"accuracy\": 0.9965603947639465, \"f1\": 0.9690136403059213, \"f2\": 0.9513267486144223, \"f0_5\": 0.9873706536409795, \"p4\": 0.9833801826295285, \"phi\": 0.9677154763174297}, {\"truth_threshold\": 9.700864002527247, \"match_probability\": 0.9987998723834213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6143.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 395.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.939583957195282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.060416027903556824, \"precision\": 1.0, \"recall\": 0.939583957195282, \"specificity\": 1.0, \"npv\": 0.9963464736938477, \"accuracy\": 0.9965428709983826, \"f1\": 0.968851036984465, \"f2\": 0.9510760179594364, \"f0_5\": 0.9873031179684989, \"p4\": 0.9832919575134299, \"phi\": 0.9675490543612214}, {\"truth_threshold\": 9.70776125162934, \"match_probability\": 0.9988055894340752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6141.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 397.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9392780661582947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06072193384170532, \"precision\": 1.0, \"recall\": 0.9392780661582947, \"specificity\": 1.0, \"npv\": 0.9963279962539673, \"accuracy\": 0.9965253472328186, \"f1\": 0.9686883823645398, \"f2\": 0.9508252562474839, \"f0_5\": 0.987235547553212, \"p4\": 0.9832036936982431, \"phi\": 0.9673826099336588}, {\"truth_threshold\": 9.71251153374382, \"match_probability\": 0.9988095110619152, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6140.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 398.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.939125120639801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06087488681077957, \"precision\": 1.0, \"recall\": 0.939125120639801, \"specificity\": 1.0, \"npv\": 0.9963188171386719, \"accuracy\": 0.9965166449546814, \"f1\": 0.9686070358100647, \"f2\": 0.950699863743342, \"f0_5\": 0.9872017493086372, \"p4\": 0.9831595472696867, \"phi\": 0.9672993792893877}, {\"truth_threshold\": 9.863395812445994, \"match_probability\": 0.9989276019517873, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6139.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 399.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9389721751213074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06102783605456352, \"precision\": 1.0, \"recall\": 0.9389721751213074, \"specificity\": 1.0, \"npv\": 0.9963095784187317, \"accuracy\": 0.9965078830718994, \"f1\": 0.9685256764218664, \"f2\": 0.9505744634727943, \"f0_5\": 0.9871679423683025, \"p4\": 0.9831153911557887, \"phi\": 0.967216049414675}, {\"truth_threshold\": 9.939638148564834, \"match_probability\": 0.9989827475154842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6138.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 400.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9388192296028137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06118078902363777, \"precision\": 1.0, \"recall\": 0.9388192296028137, \"specificity\": 1.0, \"npv\": 0.9963003993034363, \"accuracy\": 0.9964991211891174, \"f1\": 0.9684443041969075, \"f2\": 0.9504490554351193, \"f0_5\": 0.9871341267288517, \"p4\": 0.9830712253530225, \"phi\": 0.9671328075170817}, {\"truth_threshold\": 9.948778069135201, \"match_probability\": 0.9989891652603955, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6131.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 407.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9377485513687134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06225145235657692, \"precision\": 1.0, \"recall\": 0.9377485513687134, \"specificity\": 1.0, \"npv\": 0.9962358474731445, \"accuracy\": 0.9964378476142883, \"f1\": 0.9678743389375641, \"f2\": 0.9495709816311991, \"f0_5\": 0.9868971733951452, \"p4\": 0.9827617931487453, \"phi\": 0.9665499566414784}, {\"truth_threshold\": 9.96104623341726, \"match_probability\": 0.9989977160154173, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6130.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 408.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9375956058502197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06240440532565117, \"precision\": 1.0, \"recall\": 0.9375956058502197, \"specificity\": 1.0, \"npv\": 0.9962266683578491, \"accuracy\": 0.9964290857315063, \"f1\": 0.9677928639090622, \"f2\": 0.9494455114305186, \"f0_5\": 0.9868632880417284, \"p4\": 0.9827175497078663, \"phi\": 0.966466576026584}, {\"truth_threshold\": 9.977312187146218, \"match_probability\": 0.9990089418642638, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6129.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 409.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9374426603317261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06255735456943512, \"precision\": 1.0, \"recall\": 0.9374426603317261, \"specificity\": 1.0, \"npv\": 0.9962174296379089, \"accuracy\": 0.9964203238487244, \"f1\": 0.9677113760164207, \"f2\": 0.9493200334562126, \"f0_5\": 0.9868293939589103, \"p4\": 0.9826732965463016, \"phi\": 0.9663832834401074}, {\"truth_threshold\": 9.9941306812211, \"match_probability\": 0.9990204169803122, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6128.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 410.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9372897148132324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06271030753850937, \"precision\": 1.0, \"recall\": 0.9372897148132324, \"specificity\": 1.0, \"npv\": 0.9962082505226135, \"accuracy\": 0.9964116215705872, \"f1\": 0.9676298752565925, \"f2\": 0.9491945477075588, \"f0_5\": 0.9867954911433172, \"p4\": 0.9826290336605075, \"phi\": 0.9662999852148376}, {\"truth_threshold\": 10.085068588086397, \"match_probability\": 0.9990802025528532, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.937136709690094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06286326050758362, \"precision\": 1.0, \"recall\": 0.937136709690094, \"specificity\": 1.0, \"npv\": 0.9961990118026733, \"accuracy\": 0.9964028596878052, \"f1\": 0.9675483616265298, \"f2\": 0.9490690541838347, \"f0_5\": 0.9867615795915738, \"p4\": 0.9825847610469381, \"phi\": 0.9662166813492732}, {\"truth_threshold\": 10.102448338028015, \"match_probability\": 0.9990912066149924, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6126.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 412.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9369837641716003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06301621347665787, \"precision\": 1.0, \"recall\": 0.9369837641716003, \"specificity\": 1.0, \"npv\": 0.9961898326873779, \"accuracy\": 0.9963940978050232, \"f1\": 0.9674668351231839, \"f2\": 0.9489435528843175, \"f0_5\": 0.9867276593003028, \"p4\": 0.9825404787020465, \"phi\": 0.9661333718419125}, {\"truth_threshold\": 10.107094894416397, \"match_probability\": 0.9990941262532591, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6124.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 414.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.936677873134613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06332211941480637, \"precision\": 1.0, \"recall\": 0.936677873134613, \"specificity\": 1.0, \"npv\": 0.9961713552474976, \"accuracy\": 0.9963765740394592, \"f1\": 0.9673037434844416, \"f2\": 0.948692526955013, \"f0_5\": 0.9866597924856609, \"p4\": 0.9824518848040986, \"phi\": 0.9659667358957924}, {\"truth_threshold\": 10.126199016317393, \"match_probability\": 0.9991060320787437, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6120.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 418.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9360660910606384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06393392384052277, \"precision\": 1.0, \"recall\": 0.9360660910606384, \"specificity\": 1.0, \"npv\": 0.9961345195770264, \"accuracy\": 0.9963415861129761, \"f1\": 0.9669774055933007, \"f2\": 0.9481903817550819, \"f0_5\": 0.9865239538332581, \"p4\": 0.9822745800760633, \"phi\": 0.9656333024907707}, {\"truth_threshold\": 10.16516322979181, \"match_probability\": 0.9991298324503272, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6119.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 419.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9359131455421448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06408687680959702, \"precision\": 1.0, \"recall\": 0.9359131455421448, \"specificity\": 1.0, \"npv\": 0.996125340461731, \"accuracy\": 0.9963328242301941, \"f1\": 0.9668957888915225, \"f2\": 0.948064826004772, \"f0_5\": 0.9864899722705874, \"p4\": 0.9822302295124468, \"phi\": 0.9655499534415095}, {\"truth_threshold\": 10.17470292686292, \"match_probability\": 0.9991355624192901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6118.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 420.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9357602000236511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06423982977867126, \"precision\": 1.0, \"recall\": 0.9357602000236511, \"specificity\": 1.0, \"npv\": 0.9961161017417908, \"accuracy\": 0.9963240623474121, \"f1\": 0.9668141592920354, \"f2\": 0.9479392624728851, \"f0_5\": 0.9864559819413092, \"p4\": 0.9821858691890677, \"phi\": 0.9654665987384139}, {\"truth_threshold\": 10.222572111836332, \"match_probability\": 0.9991637505771317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6116.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 422.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.935454249382019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06454573571681976, \"precision\": 1.0, \"recall\": 0.935454249382019, \"specificity\": 1.0, \"npv\": 0.9960976839065552, \"accuracy\": 0.9963065981864929, \"f1\": 0.9666508613877035, \"f2\": 0.9476881120614851, \"f0_5\": 0.9863879749693568, \"p4\": 0.982097119248769, \"phi\": 0.9652998723646905}, {\"truth_threshold\": 10.271481712317279, \"match_probability\": 0.9991916030238438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6111.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 427.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9346895217895508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06531049311161041, \"precision\": 1.0, \"recall\": 0.9346895217895508, \"specificity\": 1.0, \"npv\": 0.9960516095161438, \"accuracy\": 0.996262788772583, \"f1\": 0.9662423907028224, \"f2\": 0.9470600998047298, \"f0_5\": 0.9862178038861275, \"p4\": 0.9818750733525685, \"phi\": 0.964882863572514}, {\"truth_threshold\": 10.322351729270716, \"match_probability\": 0.9992195888905098, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6110.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 428.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9345365762710571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06546344608068466, \"precision\": 1.0, \"recall\": 0.9345365762710571, \"specificity\": 1.0, \"npv\": 0.9960424304008484, \"accuracy\": 0.9962540864944458, \"f1\": 0.9661606578115117, \"f2\": 0.9469344739941727, \"f0_5\": 0.986183743301698, \"p4\": 0.9818306348226824, \"phi\": 0.9647994635771878}, {\"truth_threshold\": 10.36597768506723, \"match_probability\": 0.999242817065025, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6109.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 429.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9343836307525635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06561639904975891, \"precision\": 1.0, \"recall\": 0.9343836307525635, \"specificity\": 1.0, \"npv\": 0.9960331916809082, \"accuracy\": 0.9962453246116638, \"f1\": 0.9660789119949396, \"f2\": 0.946808840395524, \"f0_5\": 0.986149673920062, \"p4\": 0.9817861865009062, \"phi\": 0.9647160579144377}, {\"truth_threshold\": 10.380868158443636, \"match_probability\": 0.9992505861501999, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6108.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 430.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.934230625629425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06576935201883316, \"precision\": 1.0, \"recall\": 0.934230625629425, \"specificity\": 1.0, \"npv\": 0.9960240125656128, \"accuracy\": 0.9962365627288818, \"f1\": 0.9659971532500395, \"f2\": 0.9466831990080595, \"f0_5\": 0.9861155957378108, \"p4\": 0.9817417283836615, \"phi\": 0.9646326465827509}, {\"truth_threshold\": 10.457102657563645, \"match_probability\": 0.9992891309666327, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6107.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 431.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9340776801109314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06592229753732681, \"precision\": 1.0, \"recall\": 0.9340776801109314, \"specificity\": 1.0, \"npv\": 0.9960147738456726, \"accuracy\": 0.9962278008460999, \"f1\": 0.9659153815737446, \"f2\": 0.9465575498310549, \"f0_5\": 0.9860815087515339, \"p4\": 0.981697260467368, \"phi\": 0.9645492295806137}, {\"truth_threshold\": 10.460504274556847, \"match_probability\": 0.9992908039070229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6106.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 432.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9339247345924377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06607525050640106, \"precision\": 1.0, \"recall\": 0.9339247345924377, \"specificity\": 1.0, \"npv\": 0.9960055947303772, \"accuracy\": 0.9962190389633179, \"f1\": 0.9658335969629864, \"f2\": 0.9464318928637857, \"f0_5\": 0.9860474129578193, \"p4\": 0.981652782748444, \"phi\": 0.9644658069065122}, {\"truth_threshold\": 10.485606517670126, \"match_probability\": 0.999303028340585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6105.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 433.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9337717890739441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06622820347547531, \"precision\": 1.0, \"recall\": 0.9337717890739441, \"specificity\": 1.0, \"npv\": 0.995996356010437, \"accuracy\": 0.9962102770805359, \"f1\": 0.9657517994146959, \"f2\": 0.9463062281055274, \"f0_5\": 0.9860133083532528, \"p4\": 0.9816082952233058, \"phi\": 0.9643823785589315}, {\"truth_threshold\": 10.525642557353574, \"match_probability\": 0.999322091070302, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6104.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 434.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9336188435554504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06638115644454956, \"precision\": 1.0, \"recall\": 0.9336188435554504, \"specificity\": 1.0, \"npv\": 0.9959871768951416, \"accuracy\": 0.9962015748023987, \"f1\": 0.9656699889258029, \"f2\": 0.9461805555555556, \"f0_5\": 0.9859791949344188, \"p4\": 0.981563797888368, \"phi\": 0.9642989445363563}, {\"truth_threshold\": 10.537607615108966, \"match_probability\": 0.9993276863249761, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6102.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 436.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9333129525184631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06668706238269806, \"precision\": 1.0, \"recall\": 0.9333129525184631, \"specificity\": 1.0, \"npv\": 0.995968759059906, \"accuracy\": 0.9961840510368347, \"f1\": 0.9655063291139241, \"f2\": 0.9459291870775718, \"f0_5\": 0.9859109416402766, \"p4\": 0.9814747737747435, \"phi\": 0.9641319655847241}, {\"truth_threshold\": 10.546956004465907, \"match_probability\": 0.999332025804974, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6101.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 437.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9331600069999695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06684001535177231, \"precision\": 1.0, \"recall\": 0.9331600069999695, \"specificity\": 1.0, \"npv\": 0.9959595203399658, \"accuracy\": 0.9961752891540527, \"f1\": 0.9654244797847931, \"f2\": 0.9458034911481102, \"f0_5\": 0.9858768017581281, \"p4\": 0.9814302469888772, \"phi\": 0.964048514520808}, {\"truth_threshold\": 10.574873855767214, \"match_probability\": 0.9993448192416047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6099.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 439.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9328540563583374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06714591383934021, \"precision\": 1.0, \"recall\": 0.9328540563583374, \"specificity\": 1.0, \"npv\": 0.9959411025047302, \"accuracy\": 0.9961577653884888, \"f1\": 0.965260742264778, \"f2\": 0.9455520759046231, \"f0_5\": 0.9858084955065624, \"p4\": 0.9813411639410752, \"phi\": 0.9638815953482651}, {\"truth_threshold\": 10.585630634954692, \"match_probability\": 0.9993496829583843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6098.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 440.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9327011108398438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06729886680841446, \"precision\": 1.0, \"recall\": 0.9327011108398438, \"specificity\": 1.0, \"npv\": 0.9959319233894348, \"accuracy\": 0.9961490035057068, \"f1\": 0.965178854067743, \"f2\": 0.9454263565891473, \"f0_5\": 0.9857743291302942, \"p4\": 0.9812966076719495, \"phi\": 0.963798127236601}, {\"truth_threshold\": 10.587319035911063, \"match_probability\": 0.9993504430919142, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6096.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 442.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9323952198028564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06760477274656296, \"precision\": 1.0, \"recall\": 0.9323952198028564, \"specificity\": 1.0, \"npv\": 0.9959135055541992, \"accuracy\": 0.9961315393447876, \"f1\": 0.965015038784233, \"f2\": 0.9451748945671049, \"f0_5\": 0.9857059698596469, \"p4\": 0.9812074656252605, \"phi\": 0.9636311739548882}, {\"truth_threshold\": 10.666556023192594, \"match_probability\": 0.9993851352835356, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6094.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 444.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9320893287658691, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06791067868471146, \"precision\": 1.0, \"recall\": 0.9320893287658691, \"specificity\": 1.0, \"npv\": 0.9958950877189636, \"accuracy\": 0.9961140155792236, \"f1\": 0.9648511716276124, \"f2\": 0.9449234013521057, \"f0_5\": 0.9856375752086434, \"p4\": 0.9811182842099839, \"phi\": 0.9634641979185242}, {\"truth_threshold\": 10.669094512473167, \"match_probability\": 0.9993862155519976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6093.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 445.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9319363832473755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0680636316537857, \"precision\": 1.0, \"recall\": 0.9319363832473755, \"specificity\": 1.0, \"npv\": 0.9958858489990234, \"accuracy\": 0.9961052536964417, \"f1\": 0.9647692185891853, \"f2\": 0.9447976430454335, \"f0_5\": 0.9856033646069233, \"p4\": 0.9810736787301171, \"phi\": 0.9633806074227119}, {\"truth_threshold\": 10.678166575053586, \"match_probability\": 0.999390060740531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6092.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 446.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9317834377288818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06821657717227936, \"precision\": 1.0, \"recall\": 0.9317834377288818, \"specificity\": 1.0, \"npv\": 0.995876669883728, \"accuracy\": 0.9960964918136597, \"f1\": 0.9646872525732383, \"f2\": 0.9446718769383451, \"f0_5\": 0.9855691451498091, \"p4\": 0.9810290633972899, \"phi\": 0.9632971051672264}, {\"truth_threshold\": 10.703197952742753, \"match_probability\": 0.9994005458805486, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6091.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 447.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9316304922103882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06836953014135361, \"precision\": 1.0, \"recall\": 0.9316304922103882, \"specificity\": 1.0, \"npv\": 0.9958674907684326, \"accuracy\": 0.9960877895355225, \"f1\": 0.9646052735766886, \"f2\": 0.9445461030301151, \"f0_5\": 0.9855349168338619, \"p4\": 0.9809844382078943, \"phi\": 0.9632135972169862}, {\"truth_threshold\": 10.771910702826768, \"match_probability\": 0.9994284115307063, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6089.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 449.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9313245415687561, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0686754360795021, \"precision\": 1.0, \"recall\": 0.9313245415687561, \"specificity\": 1.0, \"npv\": 0.995849072933197, \"accuracy\": 0.9960702657699585, \"f1\": 0.9644412766294448, \"f2\": 0.944294531807326, \"f0_5\": 0.9854664336117045, \"p4\": 0.9808951582449567, \"phi\": 0.9630465642261447}, {\"truth_threshold\": 10.807534612557488, \"match_probability\": 0.9994423449385134, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6086.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 452.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9308657050132751, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06913429498672485, \"precision\": 1.0, \"recall\": 0.9308657050132751, \"specificity\": 1.0, \"npv\": 0.9958214163780212, \"accuracy\": 0.9960439801216125, \"f1\": 0.9641951837769328, \"f2\": 0.9439171164464297, \"f0_5\": 0.9853636422511496, \"p4\": 0.9807611642859831, \"phi\": 0.962795971991099}, {\"truth_threshold\": 10.863035337425012, \"match_probability\": 0.999463379319681, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6085.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9307127594947815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0692872405052185, \"precision\": 1.0, \"recall\": 0.9307127594947815, \"specificity\": 1.0, \"npv\": 0.9958122372627258, \"accuracy\": 0.9960352778434753, \"f1\": 0.9641131268319734, \"f2\": 0.9437912957161027, \"f0_5\": 0.9853293607098905, \"p4\": 0.9807164798813083, \"phi\": 0.9627124298403021}, {\"truth_threshold\": 10.878388741243803, \"match_probability\": 0.9994690568312027, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6084.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 454.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9305598139762878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06944019347429276, \"precision\": 1.0, \"recall\": 0.9305598139762878, \"specificity\": 1.0, \"npv\": 0.9958029985427856, \"accuracy\": 0.9960265159606934, \"f1\": 0.9640310568848043, \"f2\": 0.9436654671795508, \"f0_5\": 0.9852950702856773, \"p4\": 0.9806717855947588, \"phi\": 0.9626287879776909}, {\"truth_threshold\": 10.948778069135201, \"match_probability\": 0.9994943270543075, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6082.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 456.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9302539229393005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06974609941244125, \"precision\": 1.0, \"recall\": 0.9302539229393005, \"specificity\": 1.0, \"npv\": 0.99578458070755, \"accuracy\": 0.9960089921951294, \"f1\": 0.9638668779714739, \"f2\": 0.9434137866848669, \"f0_5\": 0.9852264627745739, \"p4\": 0.9805823673615459, \"phi\": 0.962461675128213}, {\"truth_threshold\": 10.995934558148086, \"match_probability\": 0.9995105805062934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6081.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 457.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9301009774208069, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0698990523815155, \"precision\": 1.0, \"recall\": 0.9301009774208069, \"specificity\": 1.0, \"npv\": 0.9957754015922546, \"accuracy\": 0.9960002303123474, \"f1\": 0.9637847689991283, \"f2\": 0.9432879347252815, \"f0_5\": 0.9851921456807725, \"p4\": 0.9805376434076328, \"phi\": 0.9623781101392}, {\"truth_threshold\": 11.04199986619451, \"match_probability\": 0.9995259535445755, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6080.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 458.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9299479722976685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07005200535058975, \"precision\": 1.0, \"recall\": 0.9299479722976685, \"specificity\": 1.0, \"npv\": 0.9957662224769592, \"accuracy\": 0.9959914684295654, \"f1\": 0.9637026470122048, \"f2\": 0.9431620749565649, \"f0_5\": 0.9851578196901938, \"p4\": 0.9804929095573457, \"phi\": 0.9622945394386306}, {\"truth_threshold\": 11.049360305608586, \"match_probability\": 0.9995283647701676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6078.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 460.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9296420812606812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07035791128873825, \"precision\": 1.0, \"recall\": 0.9296420812606812, \"specificity\": 1.0, \"npv\": 0.9957478046417236, \"accuracy\": 0.9959740042686462, \"f1\": 0.9635383639822448, \"f2\": 0.9429103319888302, \"f0_5\": 0.9850891410048622, \"p4\": 0.9804034121531311, \"phi\": 0.9621273808966977}, {\"truth_threshold\": 11.058237575384123, \"match_probability\": 0.999531256595247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6076.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 462.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9293361902236938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07066380977630615, \"precision\": 1.0, \"recall\": 0.9293361902236938, \"specificity\": 1.0, \"npv\": 0.995729386806488, \"accuracy\": 0.9959564805030823, \"f1\": 0.9633740288568258, \"f2\": 0.9426585577758471, \"f0_5\": 0.9850204266908761, \"p4\": 0.9803138751198466, \"phi\": 0.9619601994901584}, {\"truth_threshold\": 11.080486671941546, \"match_probability\": 0.999538426741068, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6075.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 463.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9291832447052002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0708167627453804, \"precision\": 1.0, \"recall\": 0.9291832447052002, \"specificity\": 1.0, \"npv\": 0.9957201480865479, \"accuracy\": 0.9959477186203003, \"f1\": 0.9632918417505748, \"f2\": 0.9425326589505694, \"f0_5\": 0.9849860561644724, \"p4\": 0.9802690917332154, \"phi\": 0.9618765061367552}, {\"truth_threshold\": 11.104812250493548, \"match_probability\": 0.9995461406748462, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6074.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 464.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9290302991867065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07096971571445465, \"precision\": 1.0, \"recall\": 0.9290302991867065, \"specificity\": 1.0, \"npv\": 0.9957109689712524, \"accuracy\": 0.9959389567375183, \"f1\": 0.963209641611164, \"f2\": 0.9424067523117979, \"f0_5\": 0.9849516767205033, \"p4\": 0.9802242984284083, \"phi\": 0.9617929011273646}, {\"truth_threshold\": 11.129462707444851, \"match_probability\": 0.9995538261885938, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6073.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 465.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9288773536682129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0711226686835289, \"precision\": 1.0, \"recall\": 0.9288773536682129, \"specificity\": 1.0, \"npv\": 0.995701789855957, \"accuracy\": 0.9959302544593811, \"f1\": 0.9631274284354928, \"f2\": 0.9422808378588052, \"f0_5\": 0.9849172883554979, \"p4\": 0.980179495201785, \"phi\": 0.9617092903956849}, {\"truth_threshold\": 11.13691314751298, \"match_probability\": 0.9995561233828708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6071.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 467.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9285714030265808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0714285746216774, \"precision\": 1.0, \"recall\": 0.9285714030265808, \"specificity\": 1.0, \"npv\": 0.9956833720207214, \"accuracy\": 0.9959127306938171, \"f1\": 0.9629629629629629, \"f2\": 0.9420289855072463, \"f0_5\": 0.9848484848484849, \"p4\": 0.9800898589685221, \"phi\": 0.9615420517593162}, {\"truth_threshold\": 11.144800800210112, \"match_probability\": 0.9995585425009904, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6070.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9284184575080872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07158152014017105, \"precision\": 1.0, \"recall\": 0.9284184575080872, \"specificity\": 1.0, \"npv\": 0.9956741333007812, \"accuracy\": 0.9959039688110352, \"f1\": 0.9628807106598984, \"f2\": 0.9419030476072249, \"f0_5\": 0.9848140696995262, \"p4\": 0.9800450259545935, \"phi\": 0.9614584238515544}, {\"truth_threshold\": 11.145733570149988, \"match_probability\": 0.9995588277058177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6068.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 470.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9281125664710999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07188742607831955, \"precision\": 1.0, \"recall\": 0.9281125664710999, \"specificity\": 1.0, \"npv\": 0.9956557750701904, \"accuracy\": 0.9958864450454712, \"f1\": 0.9627161669046486, \"f2\": 0.9416511483550589, \"f0_5\": 0.9847452125933138, \"p4\": 0.9799553301139073, \"phi\": 0.961291150849189}, {\"truth_threshold\": 11.149425690346122, \"match_probability\": 0.9995599548066502, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6067.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 471.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9279596209526062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0720403790473938, \"precision\": 1.0, \"recall\": 0.9279596209526062, \"specificity\": 1.0, \"npv\": 0.9956465363502502, \"accuracy\": 0.995877742767334, \"f1\": 0.9626338754462515, \"f2\": 0.9415251870014588, \"f0_5\": 0.9847107706290982, \"p4\": 0.9799104672798503, \"phi\": 0.9612075057515086}, {\"truth_threshold\": 11.156495445100083, \"match_probability\": 0.9995621049786624, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6061.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 477.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9270418882369995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0729580894112587, \"precision\": 1.0, \"recall\": 0.9270418882369995, \"specificity\": 1.0, \"npv\": 0.9955913424491882, \"accuracy\": 0.9958251714706421, \"f1\": 0.9621398523692356, \"f2\": 0.9407692546487443, \"f0_5\": 0.9845039308686895, \"p4\": 0.9796410812533005, \"phi\": 0.9607054205428806}, {\"truth_threshold\": 11.207124404555298, \"match_probability\": 0.9995771992682895, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6060.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 478.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9268889427185059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07311104238033295, \"precision\": 1.0, \"recall\": 0.9268889427185059, \"specificity\": 1.0, \"npv\": 0.995582103729248, \"accuracy\": 0.9958164691925049, \"f1\": 0.9620574694395936, \"f2\": 0.9406432385446417, \"f0_5\": 0.9844694262135292, \"p4\": 0.9795961487110273, \"phi\": 0.9606217352741503}, {\"truth_threshold\": 11.208681291752367, \"match_probability\": 0.9995776550958329, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6059.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 479.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9267359972000122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0732639953494072, \"precision\": 1.0, \"recall\": 0.9267359972000122, \"specificity\": 1.0, \"npv\": 0.9955729246139526, \"accuracy\": 0.9958077073097229, \"f1\": 0.9619750734301817, \"f2\": 0.9405172146161249, \"f0_5\": 0.9844349125885488, \"p4\": 0.9795512061957922, \"phi\": 0.9605380442615747}, {\"truth_threshold\": 11.26370254006733, \"match_probability\": 0.9995934527047523, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6057.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 481.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9264301061630249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0735699012875557, \"precision\": 1.0, \"recall\": 0.9264301061630249, \"specificity\": 1.0, \"npv\": 0.995554506778717, \"accuracy\": 0.9957901835441589, \"f1\": 0.9618102421595871, \"f2\": 0.9402651432829333, \"f0_5\": 0.9843658584151336, \"p4\": 0.9794612912317678, \"phi\": 0.9603705507947964}, {\"truth_threshold\": 11.283709632377695, \"match_probability\": 0.9995990494876429, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6055.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 483.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9261242151260376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0738757997751236, \"precision\": 1.0, \"recall\": 0.9261242151260376, \"specificity\": 1.0, \"npv\": 0.9955361485481262, \"accuracy\": 0.995772659778595, \"f1\": 0.9616453585325181, \"f2\": 0.9400130406433385, \"f0_5\": 0.984296768320437, \"p4\": 0.9793713363318729, \"phi\": 0.9602031285233223}, {\"truth_threshold\": 11.292947328871326, \"match_probability\": 0.9996016075857661, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6054.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 484.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.925971269607544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07402875274419785, \"precision\": 1.0, \"recall\": 0.925971269607544, \"specificity\": 1.0, \"npv\": 0.995526909828186, \"accuracy\": 0.9957639575004578, \"f1\": 0.9615628970775095, \"f2\": 0.939886977581817, \"f0_5\": 0.9842622097938479, \"p4\": 0.9793263438967926, \"phi\": 0.9601194087609952}, {\"truth_threshold\": 11.293809263996796, \"match_probability\": 0.9996018454386505, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6053.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 485.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9258182644844055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0741817057132721, \"precision\": 1.0, \"recall\": 0.9258182644844055, \"specificity\": 1.0, \"npv\": 0.9955177307128906, \"accuracy\": 0.9957551956176758, \"f1\": 0.9614804225240251, \"f2\": 0.9397609066915076, \"f0_5\": 0.9842276422764228, \"p4\": 0.9792813414667236, \"phi\": 0.960035683245545}, {\"truth_threshold\": 11.315275741249538, \"match_probability\": 0.9996077235866935, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6052.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 486.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9256653189659119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07433465868234634, \"precision\": 1.0, \"recall\": 0.9256653189659119, \"specificity\": 1.0, \"npv\": 0.9955085515975952, \"accuracy\": 0.9957464337348938, \"f1\": 0.9613979348689436, \"f2\": 0.9396348279716805, \"f0_5\": 0.9841930657646523, \"p4\": 0.9792363290379883, \"phi\": 0.9599519519754232}, {\"truth_threshold\": 11.322107785387248, \"match_probability\": 0.9996095761404069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6049.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 489.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9252064824104309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07479351758956909, \"precision\": 1.0, \"recall\": 0.9252064824104309, \"specificity\": 1.0, \"npv\": 0.9954809546470642, \"accuracy\": 0.9957201480865479, \"f1\": 0.9611503932628903, \"f2\": 0.9392565448278004, \"f0_5\": 0.9840892822281513, \"p4\": 0.9791012317229835, \"phi\": 0.9597007236215364}, {\"truth_threshold\": 11.349361504390682, \"match_probability\": 0.9996168795478628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6048.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 490.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9250535368919373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07494646310806274, \"precision\": 1.0, \"recall\": 0.9250535368919373, \"specificity\": 1.0, \"npv\": 0.995471715927124, \"accuracy\": 0.9957114458084106, \"f1\": 0.9610678531701891, \"f2\": 0.9391304347826087, \"f0_5\": 0.9840546697038725, \"p4\": 0.9790561792627727, \"phi\": 0.9596169693172331}, {\"truth_threshold\": 11.398271104871627, \"match_probability\": 0.9996296454999213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6045.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 493.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9245947003364563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07540532201528549, \"precision\": 1.0, \"recall\": 0.9245947003364563, \"specificity\": 1.0, \"npv\": 0.995444118976593, \"accuracy\": 0.9956851601600647, \"f1\": 0.9608201541762695, \"f2\": 0.9387520576451223, \"f0_5\": 0.9839507780454456, \"p4\": 0.9789209617649025, \"phi\": 0.9593655775314394}, {\"truth_threshold\": 11.403289793310007, \"match_probability\": 0.999630931135372, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6044.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 494.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9244417548179626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07555827498435974, \"precision\": 1.0, \"recall\": 0.9244417548179626, \"specificity\": 1.0, \"npv\": 0.9954349398612976, \"accuracy\": 0.9956763982772827, \"f1\": 0.9607375615959307, \"f2\": 0.9386259162628898, \"f0_5\": 0.983916129452367, \"p4\": 0.9788758692142329, \"phi\": 0.9592818001607669}, {\"truth_threshold\": 11.419893209655742, \"match_probability\": 0.9996351527169082, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6043.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9242887496948242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07571122795343399, \"precision\": 1.0, \"recall\": 0.9242887496948242, \"specificity\": 1.0, \"npv\": 0.9954257011413574, \"accuracy\": 0.9956676363945007, \"f1\": 0.9606549558858596, \"f2\": 0.9384997670445722, \"f0_5\": 0.983881471833279, \"p4\": 0.9788307666317189, \"phi\": 0.9591980170214578}, {\"truth_threshold\": 11.446456500071212, \"match_probability\": 0.9996418065334088, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6042.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 496.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9241358041763306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07586418092250824, \"precision\": 1.0, \"recall\": 0.9241358041763306, \"specificity\": 1.0, \"npv\": 0.995416522026062, \"accuracy\": 0.9956589341163635, \"f1\": 0.9605723370429253, \"f2\": 0.938373609989439, \"f0_5\": 0.9838468051846545, \"p4\": 0.978785654013665, \"phi\": 0.9591142281119576}, {\"truth_threshold\": 11.47764673839574, \"match_probability\": 0.9996494646753449, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6041.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 497.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9239828586578369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07601713389158249, \"precision\": 1.0, \"recall\": 0.9239828586578369, \"specificity\": 1.0, \"npv\": 0.9954073429107666, \"accuracy\": 0.9956501722335815, \"f1\": 0.9604897050639956, \"f2\": 0.9382474450967602, \"f0_5\": 0.9838121295029639, \"p4\": 0.9787405313563738, \"phi\": 0.9590304334307108}, {\"truth_threshold\": 11.524241874310158, \"match_probability\": 0.999660601362468, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6039.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 499.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9236769676208496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07632303237915039, \"precision\": 1.0, \"recall\": 0.9236769676208496, \"specificity\": 1.0, \"npv\": 0.995388925075531, \"accuracy\": 0.9956326484680176, \"f1\": 0.9603244016856166, \"f2\": 0.9379950917958435, \"f0_5\": 0.9837427510262592, \"p4\": 0.9786502559092818, \"phi\": 0.9588628267467528}, {\"truth_threshold\": 11.571251371137075, \"match_probability\": 0.9996714786858026, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6038.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 500.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.923524022102356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07647598534822464, \"precision\": 1.0, \"recall\": 0.923524022102356, \"specificity\": 1.0, \"npv\": 0.9953797459602356, \"accuracy\": 0.9956238865852356, \"f1\": 0.9602417302798982, \"f2\": 0.9378689033861448, \"f0_5\": 0.9837080482241772, \"p4\": 0.978605103112077, \"phi\": 0.9587789203971968}, {\"truth_threshold\": 11.600000931591218, \"match_probability\": 0.9996779584661498, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6037.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 501.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9233710765838623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07662893831729889, \"precision\": 1.0, \"recall\": 0.9233710765838623, \"specificity\": 1.0, \"npv\": 0.9953705668449402, \"accuracy\": 0.9956151247024536, \"f1\": 0.9601590457256461, \"f2\": 0.9377427071359782, \"f0_5\": 0.9836733363748941, \"p4\": 0.9785599402608278, \"phi\": 0.95869510260602}, {\"truth_threshold\": 11.605900751387837, \"match_probability\": 0.9996792723260957, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6036.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 502.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9232181310653687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07678189128637314, \"precision\": 1.0, \"recall\": 0.9232181310653687, \"specificity\": 1.0, \"npv\": 0.995361328125, \"accuracy\": 0.9956064224243164, \"f1\": 0.9600763480197232, \"f2\": 0.9376165030446129, \"f0_5\": 0.9836386154748713, \"p4\": 0.9785147673518277, \"phi\": 0.9586112790353081}, {\"truth_threshold\": 11.662220882149592, \"match_probability\": 0.9996915479089773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6034.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 504.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9229121804237366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07708779722452164, \"precision\": 1.0, \"recall\": 0.9229121804237366, \"specificity\": 1.0, \"npv\": 0.9953429698944092, \"accuracy\": 0.9955888986587524, \"f1\": 0.9599109131403119, \"f2\": 0.9373640713353631, \"f0_5\": 0.9835691465084436, \"p4\": 0.97842439134574, \"phi\": 0.9584436145490427}, {\"truth_threshold\": 11.678217167383075, \"match_probability\": 0.9996949480298831, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6033.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 505.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9227592349052429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07724074274301529, \"precision\": 1.0, \"recall\": 0.9227592349052429, \"specificity\": 1.0, \"npv\": 0.995333731174469, \"accuracy\": 0.9955801367759705, \"f1\": 0.9598281759605441, \"f2\": 0.9372378437160168, \"f0_5\": 0.9835343984349527, \"p4\": 0.9783791882412306, \"phi\": 0.9583597736303685}, {\"truth_threshold\": 11.685743663301407, \"match_probability\": 0.9996965348509382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6032.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 506.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9226062893867493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07739369571208954, \"precision\": 1.0, \"recall\": 0.9226062893867493, \"specificity\": 1.0, \"npv\": 0.9953245520591736, \"accuracy\": 0.9955713748931885, \"f1\": 0.9597454256165473, \"f2\": 0.9371116082525478, \"f0_5\": 0.9834996412965499, \"p4\": 0.9783339750641267, \"phi\": 0.9582759269259189}, {\"truth_threshold\": 11.71564128047225, \"match_probability\": 0.999702757129953, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6031.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 507.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9224533438682556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07754664868116379, \"precision\": 1.0, \"recall\": 0.9224533438682556, \"specificity\": 1.0, \"npv\": 0.9953153729438782, \"accuracy\": 0.9955626130104065, \"f1\": 0.9596626621051794, \"f2\": 0.9369853649442252, \"f0_5\": 0.9834648750896876, \"p4\": 0.9782887518107125, \"phi\": 0.9581920744341318}, {\"truth_threshold\": 11.737145284666092, \"match_probability\": 0.9997071535217421, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6030.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 508.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.922300398349762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07769960165023804, \"precision\": 1.0, \"recall\": 0.922300398349762, \"specificity\": 1.0, \"npv\": 0.995306134223938, \"accuracy\": 0.9955539107322693, \"f1\": 0.9595798854232973, \"f2\": 0.9368591137903176, \"f0_5\": 0.9834300998108161, \"p4\": 0.9782435184772711, \"phi\": 0.9581082161534449}, {\"truth_threshold\": 11.741821304543103, \"match_probability\": 0.9997081008738059, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6026.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 512.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9216886162757874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07831141352653503, \"precision\": 1.0, \"recall\": 0.9216886162757874, \"specificity\": 1.0, \"npv\": 0.9952693581581116, \"accuracy\": 0.9955188632011414, \"f1\": 0.95924864692773, \"f2\": 0.9363540307042079, \"f0_5\": 0.9832909079041838, \"p4\": 0.9780624842688215, \"phi\": 0.9577726306780415}, {\"truth_threshold\": 11.807534612557488, \"match_probability\": 0.9997210947027814, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6025.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 513.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9215356111526489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07846435904502869, \"precision\": 1.0, \"recall\": 0.9215356111526489, \"specificity\": 1.0, \"npv\": 0.9952601790428162, \"accuracy\": 0.9955101013183594, \"f1\": 0.9591658043460957, \"f2\": 0.9362277403114025, \"f0_5\": 0.983256087211959, \"p4\": 0.9780172004794198, \"phi\": 0.9576887434219956}, {\"truth_threshold\": 11.85920110113499, \"match_probability\": 0.9997309036164941, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6024.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 514.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9213826656341553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07861731201410294, \"precision\": 1.0, \"recall\": 0.9213826656341553, \"specificity\": 1.0, \"npv\": 0.9952509999275208, \"accuracy\": 0.9955013990402222, \"f1\": 0.9590829485750677, \"f2\": 0.9361014420686226, \"f0_5\": 0.983221257426389, \"p4\": 0.9779719065876485, \"phi\": 0.9576048503676594}, {\"truth_threshold\": 11.8625658947901, \"match_probability\": 0.9997315303296256, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6023.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 515.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9212297201156616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07877026498317719, \"precision\": 1.0, \"recall\": 0.9212297201156616, \"specificity\": 1.0, \"npv\": 0.9952417612075806, \"accuracy\": 0.9954926371574402, \"f1\": 0.9590000796114959, \"f2\": 0.9359751359751359, \"f0_5\": 0.9831864185439112, \"p4\": 0.9779266025897777, \"phi\": 0.9575209515134661}, {\"truth_threshold\": 11.863035337425012, \"match_probability\": 0.9997316176500809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6022.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 516.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.921076774597168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07892321795225143, \"precision\": 1.0, \"recall\": 0.921076774597168, \"specificity\": 1.0, \"npv\": 0.9952325820922852, \"accuracy\": 0.9954838752746582, \"f1\": 0.9589171974522293, \"f2\": 0.9358488220302107, \"f0_5\": 0.9831515705609613, \"p4\": 0.9778812884820753, \"phi\": 0.9574370468578479}, {\"truth_threshold\": 11.881535194001266, \"match_probability\": 0.9997350362726529, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6021.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 517.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9209238290786743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07907617092132568, \"precision\": 1.0, \"recall\": 0.9209238290786743, \"specificity\": 1.0, \"npv\": 0.9952234029769897, \"accuracy\": 0.9954751133918762, \"f1\": 0.9588343020941158, \"f2\": 0.9357225002331148, \"f0_5\": 0.983116713473973, \"p4\": 0.9778359642608078, \"phi\": 0.9573531363992365}, {\"truth_threshold\": 11.920734051634186, \"match_probability\": 0.9997421367351187, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6020.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 518.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9207708835601807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07922912389039993, \"precision\": 1.0, \"recall\": 0.9207708835601807, \"specificity\": 1.0, \"npv\": 0.9952142238616943, \"accuracy\": 0.9954663515090942, \"f1\": 0.9587513935340022, \"f2\": 0.9355961705831157, \"f0_5\": 0.9830818472793782, \"p4\": 0.9777906299222393, \"phi\": 0.9572691256592486}, {\"truth_threshold\": 12.034665267466748, \"match_probability\": 0.9997617124964022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6014.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 524.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.919853150844574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08014683425426483, \"precision\": 1.0, \"recall\": 0.919853150844574, \"specificity\": 1.0, \"npv\": 0.9951590299606323, \"accuracy\": 0.9954138398170471, \"f1\": 0.9582536647546208, \"f2\": 0.9348380277311447, \"f0_5\": 0.9828724586520232, \"p4\": 0.9775184112180864, \"phi\": 0.9567655060519582}, {\"truth_threshold\": 12.04199986619451, \"match_probability\": 0.9997629205789582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6011.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 527.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.919394314289093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08060569316148758, \"precision\": 1.0, \"recall\": 0.919394314289093, \"specificity\": 1.0, \"npv\": 0.9951314330101013, \"accuracy\": 0.995387613773346, \"f1\": 0.9580046218822217, \"f2\": 0.9344588502316327, \"f0_5\": 0.9827676410960696, \"p4\": 0.9773821649793036, \"phi\": 0.9565135232158244}, {\"truth_threshold\": 12.056678198307315, \"match_probability\": 0.9997653198905968, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6006.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 532.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.91862952709198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08137045055627823, \"precision\": 1.0, \"recall\": 0.91862952709198, \"specificity\": 1.0, \"npv\": 0.9950854778289795, \"accuracy\": 0.995343804359436, \"f1\": 0.9575892857142857, \"f2\": 0.9338267305180671, \"f0_5\": 0.9825927622537792, \"p4\": 0.9771548847693878, \"phi\": 0.956093592930918}, {\"truth_threshold\": 12.086327098556888, \"match_probability\": 0.999770092495811, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6005.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 533.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9184765815734863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08152340352535248, \"precision\": 1.0, \"recall\": 0.9184765815734863, \"specificity\": 1.0, \"npv\": 0.9950762987136841, \"accuracy\": 0.9953351020812988, \"f1\": 0.9575061787451168, \"f2\": 0.933700282986597, \"f0_5\": 0.9825577590156424, \"p4\": 0.9771093982217856, \"phi\": 0.9560095893957116}, {\"truth_threshold\": 12.14458304667069, \"match_probability\": 0.9997791892002967, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6004.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 534.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9183236360549927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08167635649442673, \"precision\": 1.0, \"recall\": 0.9183236360549927, \"specificity\": 1.0, \"npv\": 0.9950671195983887, \"accuracy\": 0.9953263401985168, \"f1\": 0.9574230585233615, \"f2\": 0.9335738275904963, \"f0_5\": 0.9825227466125548, \"p4\": 0.9770639014968626, \"phi\": 0.9559255800307462}, {\"truth_threshold\": 12.16878925874886, \"match_probability\": 0.9997828623615118, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5984.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 554.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9152646064758301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08473539352416992, \"precision\": 1.0, \"recall\": 0.9152646064758301, \"specificity\": 1.0, \"npv\": 0.9948832988739014, \"accuracy\": 0.9951512813568115, \"f1\": 0.9557578661555662, \"f2\": 0.9310430669653971, \"f0_5\": 0.9818205683533504, \"p4\": 0.9761518239463967, \"phi\": 0.9542438818092988}, {\"truth_threshold\": 12.191453437807555, \"match_probability\": 0.9997862461319265, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5983.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 555.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9151116609573364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08488834649324417, \"precision\": 1.0, \"recall\": 0.9151116609573364, \"specificity\": 1.0, \"npv\": 0.994874119758606, \"accuracy\": 0.9951425194740295, \"f1\": 0.9556744668956154, \"f2\": 0.9309164462424148, \"f0_5\": 0.9817853626517886, \"p4\": 0.9761061126247138, \"phi\": 0.9541597496309175}, {\"truth_threshold\": 12.206281553839927, \"match_probability\": 0.999788431394281, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5982.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 556.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9149587154388428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08504129946231842, \"precision\": 1.0, \"recall\": 0.9149587154388428, \"specificity\": 1.0, \"npv\": 0.9948649406433105, \"accuracy\": 0.9951337575912476, \"f1\": 0.955591054313099, \"f2\": 0.9307898176386382, \"f0_5\": 0.9817501477056391, \"p4\": 0.9760603910424077, \"phi\": 0.954075611587855}, {\"truth_threshold\": 12.207124404555298, \"match_probability\": 0.9997885549345805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5980.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 558.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9146528244018555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08534719794988632, \"precision\": 1.0, \"recall\": 0.9146528244018555, \"specificity\": 1.0, \"npv\": 0.994846522808075, \"accuracy\": 0.9951162934303284, \"f1\": 0.9554241891675986, \"f2\": 0.9305365367857588, \"f0_5\": 0.9816796900650075, \"p4\": 0.9759689170806911, \"phi\": 0.9539073179013055}, {\"truth_threshold\": 12.213417357717551, \"match_probability\": 0.9997894750434894, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5979.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 559.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.914499819278717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08550015091896057, \"precision\": 1.0, \"recall\": 0.914499819278717, \"specificity\": 1.0, \"npv\": 0.9948373436927795, \"accuracy\": 0.9951075315475464, \"f1\": 0.9553407365982264, \"f2\": 0.9304098845351841, \"f0_5\": 0.9816444473632363, \"p4\": 0.9759231646936591, \"phi\": 0.953823162254627}, {\"truth_threshold\": 12.222572111836332, \"match_probability\": 0.999790806440788, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5978.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 560.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9143468737602234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08565310388803482, \"precision\": 1.0, \"recall\": 0.9143468737602234, \"specificity\": 1.0, \"npv\": 0.9948281645774841, \"accuracy\": 0.9950987696647644, \"f1\": 0.9552572706935123, \"f2\": 0.9302832244008714, \"f0_5\": 0.9816091954022989, \"p4\": 0.9758774020307605, \"phi\": 0.953739000736884}, {\"truth_threshold\": 12.236414392834448, \"match_probability\": 0.9997928035859502, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5976.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 562.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9140409827232361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08595900982618332, \"precision\": 1.0, \"recall\": 0.9140409827232361, \"specificity\": 1.0, \"npv\": 0.9948098063468933, \"accuracy\": 0.9950812458992004, \"f1\": 0.9550902988652709, \"f2\": 0.9300298804780877, \"f0_5\": 0.9815386636883253, \"p4\": 0.9757858458620989, \"phi\": 0.9535706600818133}, {\"truth_threshold\": 12.247395722606997, \"match_probability\": 0.9997943743881903, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5974.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 564.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9137350916862488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08626491576433182, \"precision\": 1.0, \"recall\": 0.9137350916862488, \"specificity\": 1.0, \"npv\": 0.9947914481163025, \"accuracy\": 0.9950637817382812, \"f1\": 0.954923273657289, \"f2\": 0.9297765050115171, \"f0_5\": 0.9814680948938687, \"p4\": 0.9756942485441598, \"phi\": 0.9534022011035984}, {\"truth_threshold\": 12.2562520999992, \"match_probability\": 0.9997956325534308, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5973.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 565.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9135821461677551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08641786128282547, \"precision\": 1.0, \"recall\": 0.9135821461677551, \"specificity\": 1.0, \"npv\": 0.9947822690010071, \"accuracy\": 0.9950550198554993, \"f1\": 0.9548397410278955, \"f2\": 0.9296498054474708, \"f0_5\": 0.9814327965823201, \"p4\": 0.9756484344446568, \"phi\": 0.9533180101990575}, {\"truth_threshold\": 12.26023100009132, \"match_probability\": 0.9997961953001185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5972.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 566.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9134292006492615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08657081425189972, \"precision\": 1.0, \"recall\": 0.9134292006492615, \"specificity\": 1.0, \"npv\": 0.9947730302810669, \"accuracy\": 0.9950462579727173, \"f1\": 0.9547561950439648, \"f2\": 0.9295230979952683, \"f0_5\": 0.9813974889896799, \"p4\": 0.9756026100463657, \"phi\": 0.9532338134138552}, {\"truth_threshold\": 12.264059325430116, \"match_probability\": 0.9997967352881265, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5969.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 569.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9129703044891357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08702967315912247, \"precision\": 1.0, \"recall\": 0.9129703044891357, \"specificity\": 1.0, \"npv\": 0.9947454929351807, \"accuracy\": 0.9950199723243713, \"f1\": 0.9545054769329175, \"f2\": 0.9291429283023567, \"f0_5\": 0.9812915104885908, \"p4\": 0.9754650750204853, \"phi\": 0.9529811877582609}, {\"truth_threshold\": 12.322107785387248, \"match_probability\": 0.9998047499550654, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5968.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 570.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9128173589706421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08718262612819672, \"precision\": 1.0, \"recall\": 0.9128173589706421, \"specificity\": 1.0, \"npv\": 0.9947363138198853, \"accuracy\": 0.9950112700462341, \"f1\": 0.9544218774988006, \"f2\": 0.9290161892901619, \"f0_5\": 0.9812561657349556, \"p4\": 0.975419209388754, \"phi\": 0.9528969674343909}, {\"truth_threshold\": 12.344627928305233, \"match_probability\": 0.999807773518224, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5965.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 573.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9123585224151611, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08764147758483887, \"precision\": 1.0, \"recall\": 0.9123585224151611, \"specificity\": 1.0, \"npv\": 0.994708776473999, \"accuracy\": 0.9949849843978882, \"f1\": 0.9541709989602496, \"f2\": 0.9286359248995859, \"f0_5\": 0.9811500756628726, \"p4\": 0.9752815505705646, \"phi\": 0.9526441762370376}, {\"truth_threshold\": 12.349361504390682, \"match_probability\": 0.9998084030715805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5964.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 574.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9122055768966675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08779443055391312, \"precision\": 1.0, \"recall\": 0.9122055768966675, \"specificity\": 1.0, \"npv\": 0.9946995377540588, \"accuracy\": 0.9949762225151062, \"f1\": 0.9540873460246361, \"f2\": 0.9285091543156059, \"f0_5\": 0.981114693689544, \"p4\": 0.9752356436440424, \"phi\": 0.9525599323413163}, {\"truth_threshold\": 12.37117841997237, \"match_probability\": 0.9998112781238929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5960.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 578.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9115937352180481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08840624243021011, \"precision\": 1.0, \"recall\": 0.9115937352180481, \"specificity\": 1.0, \"npv\": 0.9946628212928772, \"accuracy\": 0.994941234588623, \"f1\": 0.9537526004160666, \"f2\": 0.9280019930244146, \"f0_5\": 0.9809730726183422, \"p4\": 0.9750519125665238, \"phi\": 0.952222897791341}, {\"truth_threshold\": 12.448897177941596, \"match_probability\": 0.9998211739159732, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5959.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 579.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9114407896995544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08855919539928436, \"precision\": 1.0, \"recall\": 0.9114407896995544, \"specificity\": 1.0, \"npv\": 0.9946536421775818, \"accuracy\": 0.9949324727058411, \"f1\": 0.9536688805313275, \"f2\": 0.9278751829591105, \"f0_5\": 0.9809376440376638, \"p4\": 0.975005953935053, \"phi\": 0.9521386244040315}, {\"truth_threshold\": 12.485744359741846, \"match_probability\": 0.99982568260875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5954.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 584.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9106760621070862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08932395279407501, \"precision\": 1.0, \"recall\": 0.9106760621070862, \"specificity\": 1.0, \"npv\": 0.9946077466011047, \"accuracy\": 0.9948887228965759, \"f1\": 0.9532500800512328, \"f2\": 0.9272410141406591, \"f0_5\": 0.9807603610726757, \"p4\": 0.974776005412551, \"phi\": 0.9517170739180102}, {\"truth_threshold\": 12.49109484348441, \"match_probability\": 0.9998263277855127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5953.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 585.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9105231165885925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08947690576314926, \"precision\": 1.0, \"recall\": 0.9105231165885925, \"specificity\": 1.0, \"npv\": 0.9945985078811646, \"accuracy\": 0.994879961013794, \"f1\": 0.9531662797213994, \"f2\": 0.9271141566734153, \"f0_5\": 0.9807248764415156, \"p4\": 0.9747299846080203, \"phi\": 0.95163276508011}, {\"truth_threshold\": 12.555812381858107, \"match_probability\": 0.9998339450866216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5952.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 586.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9103701710700989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08962985873222351, \"precision\": 1.0, \"recall\": 0.9103701710700989, \"specificity\": 1.0, \"npv\": 0.9945893287658691, \"accuracy\": 0.994871199131012, \"f1\": 0.9530824659727782, \"f2\": 0.9269872913032644, \"f0_5\": 0.9806893824556778, \"p4\": 0.9746839534278036, \"phi\": 0.9515484503293861}, {\"truth_threshold\": 12.61834618676678, \"match_probability\": 0.9998409878760598, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5950.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 588.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9100642204284668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08993575721979141, \"precision\": 1.0, \"recall\": 0.9100642204284668, \"specificity\": 1.0, \"npv\": 0.9945709705352783, \"accuracy\": 0.9948537349700928, \"f1\": 0.952914798206278, \"f2\": 0.9267335368512866, \"f0_5\": 0.9806183664051684, \"p4\": 0.9745918599248508, \"phi\": 0.9513798030830064}, {\"truth_threshold\": 12.671289599278044, \"match_probability\": 0.9998467165835381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5949.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 589.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9099112749099731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09008871018886566, \"precision\": 1.0, \"recall\": 0.9099112749099731, \"specificity\": 1.0, \"npv\": 0.9945617914199829, \"accuracy\": 0.9948449730873108, \"f1\": 0.9528309441819492, \"f2\": 0.9266066477679823, \"f0_5\": 0.9805828443330916, \"p4\": 0.974545797594379, \"phi\": 0.9512954705841183}, {\"truth_threshold\": 12.692024150326034, \"match_probability\": 0.9998489035016455, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5944.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 594.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9091465473175049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09085347503423691, \"precision\": 1.0, \"recall\": 0.9091465473175049, \"specificity\": 1.0, \"npv\": 0.9945158958435059, \"accuracy\": 0.9948012232780457, \"f1\": 0.9524114725204295, \"f2\": 0.9259720837487537, \"f0_5\": 0.9804050933562051, \"p4\": 0.9743153299971838, \"phi\": 0.9508736242224697}, {\"truth_threshold\": 12.796820481361902, \"match_probability\": 0.9998594884067351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5942.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 596.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9088405966758728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09115937352180481, \"precision\": 1.0, \"recall\": 0.9088405966758728, \"specificity\": 1.0, \"npv\": 0.994497537612915, \"accuracy\": 0.9947836995124817, \"f1\": 0.9522435897435897, \"f2\": 0.9257182027793357, \"f0_5\": 0.980333927275127, \"p4\": 0.97422307011168, \"phi\": 0.9507048822005563}, {\"truth_threshold\": 12.88133667458248, \"match_probability\": 0.9998674823513779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5928.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 610.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9066992998123169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0933007001876831, \"precision\": 1.0, \"recall\": 0.9066992998123169, \"specificity\": 1.0, \"npv\": 0.9943690299987793, \"accuracy\": 0.9946611523628235, \"f1\": 0.9510669019733675, \"f2\": 0.9239401496259352, \"f0_5\": 0.9798347107438017, \"p4\": 0.9735760823193484, \"phi\": 0.9495228327555523}, {\"truth_threshold\": 12.88138268593779, \"match_probability\": 0.9998674865770883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5927.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 611.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9065463542938232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09345365315675735, \"precision\": 1.0, \"recall\": 0.9065463542938232, \"specificity\": 1.0, \"npv\": 0.9943598508834839, \"accuracy\": 0.9946523904800415, \"f1\": 0.9509827517047733, \"f2\": 0.9238130864428442, \"f0_5\": 0.9797989816835284, \"p4\": 0.9735297904858913, \"phi\": 0.9494383696348037}, {\"truth_threshold\": 12.902002294352584, \"match_probability\": 0.9998693667991569, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5926.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 612.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9063934087753296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0936066061258316, \"precision\": 1.0, \"recall\": 0.9063934087753296, \"specificity\": 1.0, \"npv\": 0.9943506717681885, \"accuracy\": 0.9946436285972595, \"f1\": 0.9508985879332478, \"f2\": 0.9236860153376145, \"f0_5\": 0.9797632431717479, \"p4\": 0.973483488175635, \"phi\": 0.9493539005590117}, {\"truth_threshold\": 12.934324005111838, \"match_probability\": 0.9998722605562252, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5925.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 613.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9062404632568359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09375955909490585, \"precision\": 1.0, \"recall\": 0.9062404632568359, \"specificity\": 1.0, \"npv\": 0.9943414926528931, \"accuracy\": 0.9946349263191223, \"f1\": 0.9508144106555404, \"f2\": 0.9235589363095053, \"f0_5\": 0.9797274952047093, \"p4\": 0.9734371753846648, \"phi\": 0.9492694255265437}, {\"truth_threshold\": 12.95953770600254, \"match_probability\": 0.9998744733607271, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5920.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 618.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9054756760597229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0945243164896965, \"precision\": 1.0, \"recall\": 0.9054756760597229, \"specificity\": 1.0, \"npv\": 0.994295597076416, \"accuracy\": 0.9945911169052124, \"f1\": 0.9503933215604431, \"f2\": 0.9229234222998254, \"f0_5\": 0.9795486134092263, \"p4\": 0.973205454081938, \"phi\": 0.9488469609568634}, {\"truth_threshold\": 12.963568793915835, \"match_probability\": 0.9998748235659893, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5918.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 620.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9051697850227356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.094830222427845, \"precision\": 1.0, \"recall\": 0.9051697850227356, \"specificity\": 1.0, \"npv\": 0.9942772388458252, \"accuracy\": 0.9945736527442932, \"f1\": 0.9502247912652537, \"f2\": 0.9226691612098534, \"f0_5\": 0.9794769943727243, \"p4\": 0.9731126920586027, \"phi\": 0.9486778381323806}, {\"truth_threshold\": 12.971321340032176, \"match_probability\": 0.9998754943334203, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5917.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 621.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9050168395042419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09498317539691925, \"precision\": 1.0, \"recall\": 0.9050168395042419, \"specificity\": 1.0, \"npv\": 0.9942680597305298, \"accuracy\": 0.9945648908615112, \"f1\": 0.9501405058209554, \"f2\": 0.9225420187720228, \"f0_5\": 0.979441170628352, \"p4\": 0.973066295280743, \"phi\": 0.9485933153800288}, {\"truth_threshold\": 12.983060006990788, \"match_probability\": 0.9998765031543303, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5915.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 623.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9047109484672546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09528908133506775, \"precision\": 1.0, \"recall\": 0.9047109484672546, \"specificity\": 1.0, \"npv\": 0.994249701499939, \"accuracy\": 0.9945473670959473, \"f1\": 0.9499718943226532, \"f2\": 0.9222877101069635, \"f0_5\": 0.9793694946685211, \"p4\": 0.9729734701729763, \"phi\": 0.9484242519594694}, {\"truth_threshold\": 13.00467052716891, \"match_probability\": 0.9998783390375817, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5912.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 626.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9042520523071289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0957479327917099, \"precision\": 1.0, \"recall\": 0.9042520523071289, \"specificity\": 1.0, \"npv\": 0.9942221641540527, \"accuracy\": 0.9945211410522461, \"f1\": 0.9497188755020081, \"f2\": 0.9219061876247505, \"f0_5\": 0.9792619094944677, \"p4\": 0.9728341535721599, \"phi\": 0.9481706120143841}, {\"truth_threshold\": 13.075793889494548, \"match_probability\": 0.9998841906767162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5911.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 627.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9040991067886353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09590088576078415, \"precision\": 1.0, \"recall\": 0.9040991067886353, \"specificity\": 1.0, \"npv\": 0.9942129850387573, \"accuracy\": 0.9945123791694641, \"f1\": 0.9496345087958872, \"f2\": 0.921778997598478, \"f0_5\": 0.9792260287588629, \"p4\": 0.9727876936390167, \"phi\": 0.9480860534089894}, {\"truth_threshold\": 13.07699188278957, \"match_probability\": 0.9998842867920795, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5910.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 628.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9039461612701416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0960538387298584, \"precision\": 1.0, \"recall\": 0.9039461612701416, \"specificity\": 1.0, \"npv\": 0.9942038059234619, \"accuracy\": 0.9945036172866821, \"f1\": 0.9495501285347043, \"f2\": 0.921651799638201, \"f0_5\": 0.9791901385114985, \"p4\": 0.9727412231661989, \"phi\": 0.9480013935187693}, {\"truth_threshold\": 13.081593522471438, \"match_probability\": 0.9998846552420076, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5909.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 629.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.903793215751648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09620679169893265, \"precision\": 1.0, \"recall\": 0.903793215751648, \"specificity\": 1.0, \"npv\": 0.9941946268081665, \"accuracy\": 0.9944948554039001, \"f1\": 0.9494657347151925, \"f2\": 0.9215245937431771, \"f0_5\": 0.9791542387485915, \"p4\": 0.9726947421497603, \"phi\": 0.9479168229415975}, {\"truth_threshold\": 13.086327098556888, \"match_probability\": 0.9998850330320211, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5908.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 630.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9036402702331543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0963597446680069, \"precision\": 1.0, \"recall\": 0.9036402702331543, \"specificity\": 1.0, \"npv\": 0.9941854476928711, \"accuracy\": 0.9944860935211182, \"f1\": 0.9493813273340832, \"f2\": 0.9213973799126638, \"f0_5\": 0.9791183294663574, \"p4\": 0.9726482505857524, \"phi\": 0.9478322463798803}, {\"truth_threshold\": 13.096691484004516, \"match_probability\": 0.9998858559062446, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5905.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 633.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9031813740730286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09681859612464905, \"precision\": 1.0, \"recall\": 0.9031813740730286, \"specificity\": 1.0, \"npv\": 0.9941579103469849, \"accuracy\": 0.994459867477417, \"f1\": 0.9491280237884755, \"f2\": 0.9210156908007612, \"f0_5\": 0.9790105444658134, \"p4\": 0.9725087125688004, \"phi\": 0.947578480770999}, {\"truth_threshold\": 13.103354240708502, \"match_probability\": 0.9998863817794645, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5901.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 637.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.902569591999054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09743040800094604, \"precision\": 1.0, \"recall\": 0.902569591999054, \"specificity\": 1.0, \"npv\": 0.994121253490448, \"accuracy\": 0.9944248199462891, \"f1\": 0.9487900956668542, \"f2\": 0.9205066608429788, \"f0_5\": 0.9788666976312123, \"p4\": 0.972322513973685, \"phi\": 0.9472399473700293}, {\"truth_threshold\": 13.129462707444851, \"match_probability\": 0.9998884192088283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5900.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 638.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9024166464805603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0975833609700203, \"precision\": 1.0, \"recall\": 0.9024166464805603, \"specificity\": 1.0, \"npv\": 0.9941120743751526, \"accuracy\": 0.9944161176681519, \"f1\": 0.948705579675189, \"f2\": 0.9203793835018096, \"f0_5\": 0.9788307120578671, \"p4\": 0.9722759378867469, \"phi\": 0.947155322865014}, {\"truth_threshold\": 13.150875999832945, \"match_probability\": 0.9998900629429166, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5895.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 643.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9016518592834473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09834811836481094, \"precision\": 1.0, \"recall\": 0.9016518592834473, \"specificity\": 1.0, \"npv\": 0.9940661787986755, \"accuracy\": 0.9943723082542419, \"f1\": 0.9482827957854097, \"f2\": 0.9197428776484539, \"f0_5\": 0.978650640812803, \"p4\": 0.9720428986247721, \"phi\": 0.9467321103161753}, {\"truth_threshold\": 13.156213871858231, \"match_probability\": 0.9998904689064017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5894.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 644.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9014989137649536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09850107133388519, \"precision\": 1.0, \"recall\": 0.9014989137649536, \"specificity\": 1.0, \"npv\": 0.9940569996833801, \"accuracy\": 0.9943636059761047, \"f1\": 0.9481981981981982, \"f2\": 0.9196155526430756, \"f0_5\": 0.9786145978614598, \"p4\": 0.9719962589791161, \"phi\": 0.9466474497900833}, {\"truth_threshold\": 13.173381529824207, \"match_probability\": 0.999891764430515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5891.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 647.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9010400772094727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09895993024110794, \"precision\": 1.0, \"recall\": 0.9010400772094727, \"specificity\": 1.0, \"npv\": 0.9940295219421387, \"accuracy\": 0.9943373203277588, \"f1\": 0.9479443237589509, \"f2\": 0.9192335299441375, \"f0_5\": 0.9785064115341173, \"p4\": 0.9718562763840409, \"phi\": 0.9463933367006023}, {\"truth_threshold\": 13.177332668264022, \"match_probability\": 0.9998920604199872, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5890.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 648.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.900887131690979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09911287575960159, \"precision\": 1.0, \"recall\": 0.900887131690979, \"specificity\": 1.0, \"npv\": 0.9940203428268433, \"accuracy\": 0.9943285584449768, \"f1\": 0.9478596717090441, \"f2\": 0.9191061731477436, \"f0_5\": 0.9784703302545019, \"p4\": 0.9718095942863736, \"phi\": 0.9463086521197018}, {\"truth_threshold\": 13.187422149184608, \"match_probability\": 0.9998928125808323, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5889.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 649.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.9007341861724854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09926582872867584, \"precision\": 1.0, \"recall\": 0.9007341861724854, \"specificity\": 1.0, \"npv\": 0.9940111637115479, \"accuracy\": 0.9943197965621948, \"f1\": 0.9477750060352458, \"f2\": 0.9189788084017353, \"f0_5\": 0.9784342393832658, \"p4\": 0.9717629015657436, \"phi\": 0.9462239615228694}, {\"truth_threshold\": 13.221299593040523, \"match_probability\": 0.9998952999792348, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5887.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 651.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.900428295135498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09957173466682434, \"precision\": 1.0, \"recall\": 0.900428295135498, \"specificity\": 1.0, \"npv\": 0.993992805480957, \"accuracy\": 0.9943023324012756, \"f1\": 0.9476056338028169, \"f2\": 0.9187240550578982, \"f0_5\": 0.9783620288506282, \"p4\": 0.971669484239642, \"phi\": 0.9460545622747724}, {\"truth_threshold\": 13.224062713640247, \"match_probability\": 0.9998955002930296, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5885.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 653.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.900122344493866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09987764060497284, \"precision\": 1.0, \"recall\": 0.900122344493866, \"specificity\": 1.0, \"npv\": 0.9939744472503662, \"accuracy\": 0.9942848086357117, \"f1\": 0.9474362070353377, \"f2\": 0.9184692699066704, \"f0_5\": 0.9782897799055789, \"p4\": 0.971576024373809, \"phi\": 0.9458851389430329}, {\"truth_threshold\": 13.2562520999992, \"match_probability\": 0.999897805834135, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5884.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 654.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8999693989753723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10003059357404709, \"precision\": 1.0, \"recall\": 0.8999693989753723, \"specificity\": 1.0, \"npv\": 0.9939652681350708, \"accuracy\": 0.9942760467529297, \"f1\": 0.9473514731927226, \"f2\": 0.9183418654014234, \"f0_5\": 0.9782536410188203, \"p4\": 0.9715292784785072, \"phi\": 0.9458004182416446}, {\"truth_threshold\": 13.292566009769898, \"match_probability\": 0.9999003457946758, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5882.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 656.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.899663507938385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10033649206161499, \"precision\": 1.0, \"recall\": 0.899663507938385, \"specificity\": 1.0, \"npv\": 0.9939469695091248, \"accuracy\": 0.9942585825920105, \"f1\": 0.947181964573269, \"f2\": 0.9180870325279391, \"f0_5\": 0.9781813343976585, \"p4\": 0.971435754743144, \"phi\": 0.945630863241723}, {\"truth_threshold\": 13.333064292288887, \"match_probability\": 0.9999031040487852, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5881.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 657.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8995105624198914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10048944503068924, \"precision\": 1.0, \"recall\": 0.8995105624198914, \"specificity\": 1.0, \"npv\": 0.9939377903938293, \"accuracy\": 0.9942498207092285, \"f1\": 0.9470971897898381, \"f2\": 0.9179596041582119, \"f0_5\": 0.9781451666555785, \"p4\": 0.9713889768950807, \"phi\": 0.9455461244499794}, {\"truth_threshold\": 13.343070655428072, \"match_probability\": 0.99990377371798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5880.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 658.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8993576169013977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10064239799976349, \"precision\": 1.0, \"recall\": 0.8993576169013977, \"specificity\": 1.0, \"npv\": 0.9939286112785339, \"accuracy\": 0.9942410588264465, \"f1\": 0.9470124013528749, \"f2\": 0.9178321678321678, \"f0_5\": 0.9781089892873778, \"p4\": 0.9713421883880919, \"phi\": 0.9454613796273473}, {\"truth_threshold\": 13.344627928305233, \"match_probability\": 0.9999038775204689, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5879.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 659.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.899204671382904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10079535096883774, \"precision\": 1.0, \"recall\": 0.899204671382904, \"specificity\": 1.0, \"npv\": 0.9939194321632385, \"accuracy\": 0.9942322969436646, \"f1\": 0.9469275992590803, \"f2\": 0.9177047235490619, \"f0_5\": 0.9780728022892128, \"p4\": 0.9712953892181716, \"phi\": 0.9453766287721618}, {\"truth_threshold\": 13.378274699844944, \"match_probability\": 0.9999060931571128, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5878.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 660.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8990517258644104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10094830393791199, \"precision\": 1.0, \"recall\": 0.8990517258644104, \"specificity\": 1.0, \"npv\": 0.9939102530479431, \"accuracy\": 0.9942235350608826, \"f1\": 0.9468427835051546, \"f2\": 0.9175772713081486, \"f0_5\": 0.9780366056572379, \"p4\": 0.971248579381312, \"phi\": 0.9452918718827567}, {\"truth_threshold\": 13.448897177941596, \"match_probability\": 0.9999105789625796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5877.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 661.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.898898720741272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10110125690698624, \"precision\": 1.0, \"recall\": 0.898898720741272, \"specificity\": 1.0, \"npv\": 0.9939010739326477, \"accuracy\": 0.9942147731781006, \"f1\": 0.9467579540877971, \"f2\": 0.9174498111086827, \"f0_5\": 0.9780003993876056, \"p4\": 0.9712017588735031, \"phi\": 0.9452071089574658}, {\"truth_threshold\": 13.457683755494468, \"match_probability\": 0.9999111218683657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5875.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 663.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8985928297042847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10140715539455414, \"precision\": 1.0, \"recall\": 0.8985928297042847, \"specificity\": 1.0, \"npv\": 0.9938827753067017, \"accuracy\": 0.9941973090171814, \"f1\": 0.946588254249577, \"f2\": 0.9171948668311113, \"f0_5\": 0.977927957919968, \"p4\": 0.9711080858289883, \"phi\": 0.945037564992556}, {\"truth_threshold\": 13.544500206723695, \"match_probability\": 0.9999163120721299, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5874.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 664.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.898439884185791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10156010836362839, \"precision\": 1.0, \"recall\": 0.898439884185791, \"specificity\": 1.0, \"npv\": 0.9938735961914062, \"accuracy\": 0.9941885471343994, \"f1\": 0.9465033838221076, \"f2\": 0.9170673827515144, \"f0_5\": 0.9778917227142572, \"p4\": 0.9710612332842525, \"phi\": 0.9449526883703097}, {\"truth_threshold\": 13.550793159885949, \"match_probability\": 0.9999166762887394, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5872.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 666.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8981339931488037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10186601430177689, \"precision\": 1.0, \"recall\": 0.8981339931488037, \"specificity\": 1.0, \"npv\": 0.9938552379608154, \"accuracy\": 0.9941710233688354, \"f1\": 0.9463336019339242, \"f2\": 0.9168123907069697, \"f0_5\": 0.9778192233397722, \"p4\": 0.9709674961297347, \"phi\": 0.9447831081396565}, {\"truth_threshold\": 13.633873021396028, \"match_probability\": 0.9999213387035406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5871.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 667.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8979810476303101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10201896727085114, \"precision\": 1.0, \"recall\": 0.8979810476303101, \"specificity\": 1.0, \"npv\": 0.99384605884552, \"accuracy\": 0.9941622614860535, \"f1\": 0.9462486904665969, \"f2\": 0.9166848827405303, \"f0_5\": 0.9777829591632803, \"p4\": 0.9709206115119108, \"phi\": 0.9446983089563118}, {\"truth_threshold\": 13.641640699028473, \"match_probability\": 0.9999217610561163, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5870.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 668.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8978281021118164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10217192023992538, \"precision\": 1.0, \"recall\": 0.8978281021118164, \"specificity\": 1.0, \"npv\": 0.9938368797302246, \"accuracy\": 0.9941535592079163, \"f1\": 0.9461637653127015, \"f2\": 0.9165573668103179, \"f0_5\": 0.97774668532214, \"p4\": 0.9708737161950123, \"phi\": 0.9446135037253931}, {\"truth_threshold\": 13.657699645800394, \"match_probability\": 0.9999226270543874, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5869.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 669.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8976751565933228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10232487320899963, \"precision\": 1.0, \"recall\": 0.8976751565933228, \"specificity\": 1.0, \"npv\": 0.9938277006149292, \"accuracy\": 0.9941447973251343, \"f1\": 0.9460788264689288, \"f2\": 0.9164298429155866, \"f0_5\": 0.9777104018124875, \"p4\": 0.9708268101750134, \"phi\": 0.9445286924452282}, {\"truth_threshold\": 13.666556023192594, \"match_probability\": 0.9999231005380218, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5868.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 670.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8975221514701843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10247781872749329, \"precision\": 1.0, \"recall\": 0.8975221514701843, \"specificity\": 1.0, \"npv\": 0.9938185811042786, \"accuracy\": 0.9941360354423523, \"f1\": 0.9459938739319684, \"f2\": 0.9163023110555902, \"f0_5\": 0.9776741086304566, \"p4\": 0.9707798934478858, \"phi\": 0.9444438751141441}, {\"truth_threshold\": 13.671289599278044, \"match_probability\": 0.9999233524173674, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5867.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 671.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8973692059516907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10263077169656754, \"precision\": 1.0, \"recall\": 0.8973692059516907, \"specificity\": 1.0, \"npv\": 0.9938094019889832, \"accuracy\": 0.9941272735595703, \"f1\": 0.9459089076985087, \"f2\": 0.9161747712295825, \"f0_5\": 0.9776378057721788, \"p4\": 0.9707329660095999, \"phi\": 0.9443590517304672}, {\"truth_threshold\": 13.76883584292039, \"match_probability\": 0.9999283631809407, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5857.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 681.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8958396911621094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10416029393672943, \"precision\": 1.0, \"recall\": 0.8958396911621094, \"specificity\": 1.0, \"npv\": 0.9937177300453186, \"accuracy\": 0.99403977394104, \"f1\": 0.945058491327148, \"f2\": 0.9148989346746228, \"f0_5\": 0.9772742441433625, \"p4\": 0.9702631016249826, \"phi\": 0.9435103889219634}, {\"truth_threshold\": 13.769307372144246, \"match_probability\": 0.9999283865891556, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5856.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 682.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8956867456436157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10431324690580368, \"precision\": 1.0, \"recall\": 0.8956867456436157, \"specificity\": 1.0, \"npv\": 0.9937085509300232, \"accuracy\": 0.9940310120582581, \"f1\": 0.944973374213329, \"f2\": 0.9147713071732066, \"f0_5\": 0.9772378345904813, \"p4\": 0.9702160560973964, \"phi\": 0.9434254031232394}, {\"truth_threshold\": 13.770937229363565, \"match_probability\": 0.9999284674415747, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5855.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 683.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8955338001251221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10446619987487793, \"precision\": 1.0, \"recall\": 0.8955338001251221, \"specificity\": 1.0, \"npv\": 0.9936993718147278, \"accuracy\": 0.9940222501754761, \"f1\": 0.9448882433631889, \"f2\": 0.9146436716968164, \"f0_5\": 0.977201415314774, \"p4\": 0.970168999810134, \"phi\": 0.9433405069621728}, {\"truth_threshold\": 13.807534612557488, \"match_probability\": 0.9999302590873629, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5854.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 684.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8953808546066284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10461915284395218, \"precision\": 1.0, \"recall\": 0.8953808546066284, \"specificity\": 1.0, \"npv\": 0.9936901926994324, \"accuracy\": 0.9940134882926941, \"f1\": 0.9448030987734022, \"f2\": 0.9145160282447041, \"f0_5\": 0.9771649863123456, \"p4\": 0.9701219327591393, \"phi\": 0.9432556047266855}, {\"truth_threshold\": 13.850340975607228, \"match_probability\": 0.9999322978419225, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5851.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 687.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8949220180511475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10507800430059433, \"precision\": 1.0, \"recall\": 0.8949220180511475, \"specificity\": 1.0, \"npv\": 0.9936627149581909, \"accuracy\": 0.9939872622489929, \"f1\": 0.9445475825328921, \"f2\": 0.91413305002656, \"f0_5\": 0.9770556409057511, \"p4\": 0.9699806669831671, \"phi\": 0.9430008615568589}, {\"truth_threshold\": 13.934324005111838, \"match_probability\": 0.9999361261985107, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5850.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 688.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.894769012928009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10523095726966858, \"precision\": 1.0, \"recall\": 0.894769012928009, \"specificity\": 1.0, \"npv\": 0.9936535358428955, \"accuracy\": 0.9939785003662109, \"f1\": 0.9444623829512432, \"f2\": 0.9140053746640835, \"f0_5\": 0.9770191729574453, \"p4\": 0.969933556836639, \"phi\": 0.9429159350068447}, {\"truth_threshold\": 13.941169367501907, \"match_probability\": 0.9999364285326136, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5830.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 708.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8917099833488464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10828999429941177, \"precision\": 1.0, \"recall\": 0.8917099833488464, \"specificity\": 1.0, \"npv\": 0.9934702515602112, \"accuracy\": 0.9938034415245056, \"f1\": 0.9427554980595084, \"f2\": 0.911450190732287, \"f0_5\": 0.9762877620738161, \"p4\": 0.9689890838333247, \"phi\": 0.9412159325205515}, {\"truth_threshold\": 13.963568793915835, \"match_probability\": 0.9999374078654646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5829.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 709.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8915570378303528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10844294726848602, \"precision\": 1.0, \"recall\": 0.8915570378303528, \"specificity\": 1.0, \"npv\": 0.9934610724449158, \"accuracy\": 0.9937946796417236, \"f1\": 0.9426700088946389, \"f2\": 0.9113223476439136, \"f0_5\": 0.9762510886313391, \"p4\": 0.9689417463647451, \"phi\": 0.9411308778598698}, {\"truth_threshold\": 13.99300572791099, \"match_probability\": 0.9999386719845718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5823.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 715.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8906393647193909, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10936065763235092, \"precision\": 1.0, \"recall\": 0.8906393647193909, \"specificity\": 1.0, \"npv\": 0.9934061169624329, \"accuracy\": 0.9937421679496765, \"f1\": 0.9421567834317612, \"f2\": 0.9105551211884284, \"f0_5\": 0.9760308414347972, \"p4\": 0.968657493141083, \"phi\": 0.9406203253745891}, {\"truth_threshold\": 14.012709283533846, \"match_probability\": 0.9999395038257154, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5822.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 716.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8904863595962524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10951361060142517, \"precision\": 1.0, \"recall\": 0.8904863595962524, \"specificity\": 1.0, \"npv\": 0.9933969378471375, \"accuracy\": 0.9937334060668945, \"f1\": 0.9420711974110032, \"f2\": 0.9104272221179709, \"f0_5\": 0.9759940991081607, \"p4\": 0.9686100794966845, \"phi\": 0.9405352278412552}, {\"truth_threshold\": 14.081593522471438, \"match_probability\": 0.9999423242947086, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5821.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 717.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8903334140777588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10966656357049942, \"precision\": 1.0, \"recall\": 0.8903334140777588, \"specificity\": 1.0, \"npv\": 0.9933878183364868, \"accuracy\": 0.9937246441841125, \"f1\": 0.941985597540254, \"f2\": 0.910299315047071, \"f0_5\": 0.9759573469250888, \"p4\": 0.9685626549535464, \"phi\": 0.9404501241775467}, {\"truth_threshold\": 14.128813525598385, \"match_probability\": 0.9999441813815416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5820.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 718.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8901804685592651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10981951653957367, \"precision\": 1.0, \"recall\": 0.8901804685592651, \"specificity\": 1.0, \"npv\": 0.9933786392211914, \"accuracy\": 0.9937159419059753, \"f1\": 0.9418999838161515, \"f2\": 0.9101713999749781, \"f0_5\": 0.9759205848816151, \"p4\": 0.9685152195075424, \"phi\": 0.9403650143817551}, {\"truth_threshold\": 14.129462707444851, \"match_probability\": 0.9999442064916723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5819.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 719.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8900275230407715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10997246950864792, \"precision\": 1.0, \"recall\": 0.8900275230407715, \"specificity\": 1.0, \"npv\": 0.993369460105896, \"accuracy\": 0.9937071800231934, \"f1\": 0.9418143562353322, \"f2\": 0.9100434769009415, \"f0_5\": 0.9758838129737707, \"p4\": 0.9684677731545441, \"phi\": 0.940279802446602}, {\"truth_threshold\": 14.162792487289428, \"match_probability\": 0.9999454806134096, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5815.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 723.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8894157409667969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11058427393436432, \"precision\": 1.0, \"recall\": 0.8894157409667969, \"specificity\": 1.0, \"npv\": 0.9933328628540039, \"accuracy\": 0.9936721324920654, \"f1\": 0.9414717072775844, \"f2\": 0.9095317045703382, \"f0_5\": 0.9757366266192362, \"p4\": 0.9682778785899705, \"phi\": 0.9399392773249162}, {\"truth_threshold\": 14.175482630724874, \"match_probability\": 0.999945958044641, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5814.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 724.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8892627954483032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11073722690343857, \"precision\": 1.0, \"recall\": 0.8892627954483032, \"specificity\": 1.0, \"npv\": 0.9933236837387085, \"accuracy\": 0.9936634302139282, \"f1\": 0.9413860103626943, \"f2\": 0.9094037414753176, \"f0_5\": 0.9756998053299322, \"p4\": 0.9682303776400041, \"phi\": 0.9398541306929059}, {\"truth_threshold\": 14.205901820460793, \"match_probability\": 0.9999470855293916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5813.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 725.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8891097903251648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11089017987251282, \"precision\": 1.0, \"recall\": 0.8891097903251648, \"specificity\": 1.0, \"npv\": 0.9933145046234131, \"accuracy\": 0.9936546683311462, \"f1\": 0.9413002995708849, \"f2\": 0.9092757703738464, \"f0_5\": 0.9756629741524001, \"p4\": 0.9681828657582301, \"phi\": 0.9397689779168352}, {\"truth_threshold\": 14.23284426032338, \"match_probability\": 0.9999480644903056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5812.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 726.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8889568448066711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11104313284158707, \"precision\": 1.0, \"recall\": 0.8889568448066711, \"specificity\": 1.0, \"npv\": 0.9933053851127625, \"accuracy\": 0.9936459064483643, \"f1\": 0.9412145748987855, \"f2\": 0.9091477912651733, \"f0_5\": 0.9756261330826563, \"p4\": 0.9681353429405056, \"phi\": 0.9396838189949905}, {\"truth_threshold\": 14.251031033484514, \"match_probability\": 0.9999487150523615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5811.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 727.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8888038992881775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11119608581066132, \"precision\": 1.0, \"recall\": 0.8888038992881775, \"specificity\": 1.0, \"npv\": 0.993296205997467, \"accuracy\": 0.9936371445655823, \"f1\": 0.9411288363430237, \"f2\": 0.9090198041485468, \"f0_5\": 0.9755892821167148, \"p4\": 0.9680878091826858, \"phi\": 0.939598653925657}, {\"truth_threshold\": 14.2562520999992, \"match_probability\": 0.9999489003060222, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5810.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 728.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8886509537696838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11134903877973557, \"precision\": 1.0, \"recall\": 0.8886509537696838, \"specificity\": 1.0, \"npv\": 0.9932870268821716, \"accuracy\": 0.9936283826828003, \"f1\": 0.9410430839002267, \"f2\": 0.9088918090232151, \"f0_5\": 0.9755524212505877, \"p4\": 0.9680402644806234, \"phi\": 0.9395133866312063}, {\"truth_threshold\": 14.36951870064287, \"match_probability\": 0.9999527585378661, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5806.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 732.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8880391716957092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11196084320545197, \"precision\": 1.0, \"recall\": 0.8880391716957092, \"specificity\": 1.0, \"npv\": 0.9932504296302795, \"accuracy\": 0.9935933947563171, \"f1\": 0.940699935191186, \"f2\": 0.908379748419801, \"f0_5\": 0.9754048787043882, \"p4\": 0.9678499761469349, \"phi\": 0.9391726401993703}, {\"truth_threshold\": 14.384899246356934, \"match_probability\": 0.9999532594796879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5805.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 733.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8878862261772156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11211379617452621, \"precision\": 1.0, \"recall\": 0.8878862261772156, \"specificity\": 1.0, \"npv\": 0.9932412505149841, \"accuracy\": 0.9935846328735352, \"f1\": 0.9406141132625779, \"f2\": 0.9082517132396658, \"f0_5\": 0.975367968277438, \"p4\": 0.9678023766613812, \"phi\": 0.9390874382012245}, {\"truth_threshold\": 14.410682115153627, \"match_probability\": 0.999954087336779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5804.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 734.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8877332806587219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11226674914360046, \"precision\": 1.0, \"recall\": 0.8877332806587219, \"specificity\": 1.0, \"npv\": 0.9932320713996887, \"accuracy\": 0.9935758709907532, \"f1\": 0.9405282774266731, \"f2\": 0.9081236700463137, \"f0_5\": 0.9753310479263292, \"p4\": 0.9677547662066589, \"phi\": 0.939002230043566}, {\"truth_threshold\": 14.433427092967799, \"match_probability\": 0.999954805469761, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5802.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 736.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8874273300170898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11257265508174896, \"precision\": 1.0, \"recall\": 0.8874273300170898, \"specificity\": 1.0, \"npv\": 0.9932137727737427, \"accuracy\": 0.993558406829834, \"f1\": 0.9403565640194489, \"f2\": 0.9078675596169493, \"f0_5\": 0.9752571774356216, \"p4\": 0.967659512373059, \"phi\": 0.9388317952428278}, {\"truth_threshold\": 14.499700312386965, \"match_probability\": 0.9999568345243461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5801.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 737.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8872743844985962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11272560060024261, \"precision\": 1.0, \"recall\": 0.8872743844985962, \"specificity\": 1.0, \"npv\": 0.9932045936584473, \"accuracy\": 0.993549644947052, \"f1\": 0.9402706864413648, \"f2\": 0.9077394923794323, \"f0_5\": 0.9752202272880102, \"p4\": 0.9676118689858519, \"phi\": 0.9387464724498812}, {\"truth_threshold\": 14.537158391594286, \"match_probability\": 0.9999579408001789, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5799.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 739.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8869684934616089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11303150653839111, \"precision\": 1.0, \"recall\": 0.8869684934616089, \"specificity\": 1.0, \"npv\": 0.9931862950325012, \"accuracy\": 0.993532121181488, \"f1\": 0.9400988895193321, \"f2\": 0.9074833338549654, \"f0_5\": 0.9751462971682249, \"p4\": 0.9675165492497829, \"phi\": 0.9385760006402232}, {\"truth_threshold\": 14.568241552894774, \"match_probability\": 0.9999588372452628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5798.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 740.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8868155479431152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11318445950746536, \"precision\": 1.0, \"recall\": 0.8868155479431152, \"specificity\": 1.0, \"npv\": 0.9931771159172058, \"accuracy\": 0.993523359298706, \"f1\": 0.9400129701686122, \"f2\": 0.9073552425665101, \"f0_5\": 0.9751093171880255, \"p4\": 0.9674688728925789, \"phi\": 0.9384907554814831}, {\"truth_threshold\": 14.594828884415099, \"match_probability\": 0.9999595888533531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5797.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 741.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8866626024246216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11333741247653961, \"precision\": 1.0, \"recall\": 0.8866626024246216, \"specificity\": 1.0, \"npv\": 0.9931679964065552, \"accuracy\": 0.9935145974159241, \"f1\": 0.9399270368869072, \"f2\": 0.90722714325957, \"f0_5\": 0.9750723272556011, \"p4\": 0.9674211855370298, \"phi\": 0.9384055041511693}, {\"truth_threshold\": 14.599602873520565, \"match_probability\": 0.9999597223505684, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5795.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 743.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8863567113876343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11364331841468811, \"precision\": 1.0, \"recall\": 0.8863567113876343, \"specificity\": 1.0, \"npv\": 0.9931496977806091, \"accuracy\": 0.9934971332550049, \"f1\": 0.939755128516987, \"f2\": 0.9069709205872226, \"f0_5\": 0.9749983175180026, \"p4\": 0.9673257778141895, \"phi\": 0.9382349829689178}, {\"truth_threshold\": 14.662069744806479, \"match_probability\": 0.9999614290392381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5794.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 744.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8862037062644958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11379627138376236, \"precision\": 1.0, \"recall\": 0.8862037062644958, \"specificity\": 1.0, \"npv\": 0.9931405186653137, \"accuracy\": 0.9934883713722229, \"f1\": 0.9396691534219915, \"f2\": 0.9068427972203092, \"f0_5\": 0.9749612977047856, \"p4\": 0.9672780574385389, \"phi\": 0.9381497131135264}, {\"truth_threshold\": 14.671289599278044, \"match_probability\": 0.9999616747399144, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5791.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 747.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8857448697090149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11425512284040451, \"precision\": 1.0, \"recall\": 0.8857448697090149, \"specificity\": 1.0, \"npv\": 0.9931130409240723, \"accuracy\": 0.993462085723877, \"f1\": 0.9394111444561603, \"f2\": 0.9064583789875716, \"f0_5\": 0.9748501784391623, \"p4\": 0.9671348302044658, \"phi\": 0.937893770244587}, {\"truth_threshold\": 14.718566087971828, \"match_probability\": 0.9999629102414457, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5788.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 750.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8852860331535339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11471398174762726, \"precision\": 1.0, \"recall\": 0.8852860331535339, \"specificity\": 1.0, \"npv\": 0.9930855631828308, \"accuracy\": 0.9934358596801758, \"f1\": 0.9391530098977771, \"f2\": 0.9060738885410144, \"f0_5\": 0.9747389693499495, \"p4\": 0.9669915037217612, \"phi\": 0.9376378679239856}, {\"truth_threshold\": 14.743811854021361, \"match_probability\": 0.999963553607091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5787.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 751.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8851330876350403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11486693471670151, \"precision\": 1.0, \"recall\": 0.8851330876350403, \"specificity\": 1.0, \"npv\": 0.9930764436721802, \"accuracy\": 0.9934270977973938, \"f1\": 0.9390669371196755, \"f2\": 0.9059457090077961, \"f0_5\": 0.9747018796739204, \"p4\": 0.9669437061527109, \"phi\": 0.9375525547750297}, {\"truth_threshold\": 14.743867526334688, \"match_probability\": 0.9999635550134464, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5786.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 752.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8849801421165466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11501988023519516, \"precision\": 1.0, \"recall\": 0.8849801421165466, \"specificity\": 1.0, \"npv\": 0.9930672645568848, \"accuracy\": 0.9934183359146118, \"f1\": 0.9389808503732554, \"f2\": 0.9058175214478051, \"f0_5\": 0.9746647800013476, \"p4\": 0.9668958975392585, \"phi\": 0.9374672354354747}, {\"truth_threshold\": 14.7594595861879, \"match_probability\": 0.9999639467610651, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5785.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 753.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8848271369934082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11517283320426941, \"precision\": 1.0, \"recall\": 0.8848271369934082, \"specificity\": 1.0, \"npv\": 0.9930581450462341, \"accuracy\": 0.9934095740318298, \"f1\": 0.9388947496551164, \"f2\": 0.9056893258602874, \"f0_5\": 0.9746276703281892, \"p4\": 0.9668480778772045, \"phi\": 0.9373819099035867}, {\"truth_threshold\": 14.769538178422936, \"match_probability\": 0.9999641977404077, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5782.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 756.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8843683004379272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11563169211149216, \"precision\": 1.0, \"recall\": 0.8843683004379272, \"specificity\": 1.0, \"npv\": 0.9930306673049927, \"accuracy\": 0.9933833479881287, \"f1\": 0.9386363636363636, \"f2\": 0.9053046909250329, \"f0_5\": 0.9745162812647475, \"p4\": 0.9667045525574031, \"phi\": 0.9371257998407442}, {\"truth_threshold\": 14.779895722933441, \"match_probability\": 0.9999644538461026, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5781.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 757.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8842153549194336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1157846450805664, \"precision\": 1.0, \"recall\": 0.8842153549194336, \"specificity\": 1.0, \"npv\": 0.9930214881896973, \"accuracy\": 0.9933745861053467, \"f1\": 0.9385502069973212, \"f2\": 0.9051764632198666, \"f0_5\": 0.974479131548783, \"p4\": 0.9666566886589024, \"phi\": 0.9370404495142861}, {\"truth_threshold\": 14.780785371562063, \"match_probability\": 0.9999644757583672, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5780.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 758.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8840624094009399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11593759804964066, \"precision\": 1.0, \"recall\": 0.8840624094009399, \"specificity\": 1.0, \"npv\": 0.9930123686790466, \"accuracy\": 0.9933658242225647, \"f1\": 0.9384640363695405, \"f2\": 0.9050482274834022, \"f0_5\": 0.97444197181199, \"p4\": 0.9666088136907696, \"phi\": 0.9369550929868125}, {\"truth_threshold\": 14.78589773698972, \"match_probability\": 0.9999646014156116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5779.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 759.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8839094638824463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1160905510187149, \"precision\": 1.0, \"recall\": 0.8839094638824463, \"specificity\": 1.0, \"npv\": 0.9930031895637512, \"accuracy\": 0.9933570623397827, \"f1\": 0.9383778517496143, \"f2\": 0.9049199837148852, \"f0_5\": 0.9744048020503137, \"p4\": 0.966560927648792, \"phi\": 0.9368697302565844}, {\"truth_threshold\": 14.826958648579426, \"match_probability\": 0.9999655946674451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5778.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 760.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8837565183639526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11624349653720856, \"precision\": 1.0, \"recall\": 0.8837565183639526, \"specificity\": 1.0, \"npv\": 0.9929940104484558, \"accuracy\": 0.9933483004570007, \"f1\": 0.9382916531341344, \"f2\": 0.9047917319135609, \"f0_5\": 0.9743676222596964, \"p4\": 0.966513030528755, \"phi\": 0.9367843613218629}, {\"truth_threshold\": 14.827743410056662, \"match_probability\": 0.9999656133766723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5777.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 761.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.883603572845459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1163964495062828, \"precision\": 1.0, \"recall\": 0.883603572845459, \"specificity\": 1.0, \"npv\": 0.9929848909378052, \"accuracy\": 0.9933395981788635, \"f1\": 0.9382054405196915, \"f2\": 0.9046634720786746, \"f0_5\": 0.9743304324360791, \"p4\": 0.966465122326442, \"phi\": 0.9366989861809083}, {\"truth_threshold\": 14.86180377306543, \"match_probability\": 0.9999664156699799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5776.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 762.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8834505677223206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11654940247535706, \"precision\": 1.0, \"recall\": 0.8834505677223206, \"specificity\": 1.0, \"npv\": 0.9929757118225098, \"accuracy\": 0.9933308362960815, \"f1\": 0.9381192139028748, \"f2\": 0.9045352042094713, \"f0_5\": 0.9742932325753998, \"p4\": 0.966417203037634, \"phi\": 0.9366136048319795}, {\"truth_threshold\": 14.901191245612315, \"match_probability\": 0.9999673201337037, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5774.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 764.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8831446766853333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11685530841350555, \"precision\": 1.0, \"recall\": 0.8831446766853333, \"specificity\": 1.0, \"npv\": 0.9929574131965637, \"accuracy\": 0.9933133125305176, \"f1\": 0.937946718648473, \"f2\": 0.9042786443650943, \"f0_5\": 0.9742188027265978, \"p4\": 0.9663213311836467, \"phi\": 0.9364428235032335}, {\"truth_threshold\": 14.913875949495303, \"match_probability\": 0.9999676061983297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5772.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 766.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.882838785648346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11716121435165405, \"precision\": 1.0, \"recall\": 0.882838785648346, \"specificity\": 1.0, \"npv\": 0.9929391145706177, \"accuracy\": 0.9932957887649536, \"f1\": 0.9377741673436231, \"f2\": 0.9040220523743892, \"f0_5\": 0.9741443326807534, \"p4\": 0.9662254149329992, \"phi\": 0.9362719209469151}, {\"truth_threshold\": 14.931230328036419, \"match_probability\": 0.9999679935211361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5769.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 769.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.882379949092865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1176200658082962, \"precision\": 1.0, \"recall\": 0.882379949092865, \"specificity\": 1.0, \"npv\": 0.9929116368293762, \"accuracy\": 0.9932695627212524, \"f1\": 0.9375152352319818, \"f2\": 0.9036371041007487, \"f0_5\": 0.9740325521712704, \"p4\": 0.9660814572392815, \"phi\": 0.936015665021338}, {\"truth_threshold\": 14.95925211318125, \"match_probability\": 0.9999686091722269, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5768.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 770.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8822270035743713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11777301877737045, \"precision\": 1.0, \"recall\": 0.8822270035743713, \"specificity\": 1.0, \"npv\": 0.9929025173187256, \"accuracy\": 0.9932608008384705, \"f1\": 0.9374288964732651, \"f2\": 0.9035087719298246, \"f0_5\": 0.9739952718676123, \"p4\": 0.9660334491063766, \"phi\": 0.93593023393795}, {\"truth_threshold\": 15.053584521231897, \"match_probability\": 0.9999705959774828, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5767.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 771.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8820740580558777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1179259717464447, \"precision\": 1.0, \"recall\": 0.8820740580558777, \"specificity\": 1.0, \"npv\": 0.9928933382034302, \"accuracy\": 0.9932520389556885, \"f1\": 0.9373425436814303, \"f2\": 0.9033804317177856, \"f0_5\": 0.9739579814902385, \"p4\": 0.9659854298489102, \"phi\": 0.9358447966308858}, {\"truth_threshold\": 15.111413977521503, \"match_probability\": 0.9999717512752199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5766.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 772.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8819210529327393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11807892471551895, \"precision\": 1.0, \"recall\": 0.8819210529327393, \"specificity\": 1.0, \"npv\": 0.9928842186927795, \"accuracy\": 0.9932432770729065, \"f1\": 0.937256176853056, \"f2\": 0.9032520834638762, \"f0_5\": 0.9739206810350652, \"p4\": 0.9659373994626422, \"phi\": 0.9357593530983968}, {\"truth_threshold\": 15.12186484052314, \"match_probability\": 0.9999719551634807, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5765.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 773.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8817681074142456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1182318776845932, \"precision\": 1.0, \"recall\": 0.8817681074142456, \"specificity\": 1.0, \"npv\": 0.9928750395774841, \"accuracy\": 0.9932345747947693, \"f1\": 0.9371697959847192, \"f2\": 0.9031237271673402, \"f0_5\": 0.9738833704980067, \"p4\": 0.9658893579433301, \"phi\": 0.9356739033387339}, {\"truth_threshold\": 15.125461964792049, \"match_probability\": 0.9999720249996416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5764.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 774.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.881615161895752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11838483065366745, \"precision\": 1.0, \"recall\": 0.881615161895752, \"specificity\": 1.0, \"npv\": 0.9928659200668335, \"accuracy\": 0.9932258129119873, \"f1\": 0.9370834010729963, \"f2\": 0.902995362827422, \"f0_5\": 0.9738460498749747, \"p4\": 0.9658413052867291, \"phi\": 0.9355883509120768}, {\"truth_threshold\": 15.132451933917245, \"match_probability\": 0.9999721602090953, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5763.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 775.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8814622163772583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1185377761721611, \"precision\": 1.0, \"recall\": 0.8814622163772583, \"specificity\": 1.0, \"npv\": 0.9928567409515381, \"accuracy\": 0.9932170510292053, \"f1\": 0.9369969921144622, \"f2\": 0.9028669904433652, \"f0_5\": 0.973808719161879, \"p4\": 0.9657932414885926, \"phi\": 0.9355028886848946}, {\"truth_threshold\": 15.132457227746261, \"match_probability\": 0.9999721603112476, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5762.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 776.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8813092708587646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11869072914123535, \"precision\": 1.0, \"recall\": 0.8813092708587646, \"specificity\": 1.0, \"npv\": 0.9928476214408875, \"accuracy\": 0.9932082891464233, \"f1\": 0.936910569105691, \"f2\": 0.9027386100144137, \"f0_5\": 0.9737713783546272, \"p4\": 0.9657451665446715, \"phi\": 0.9354174202252846}, {\"truth_threshold\": 15.140517530527948, \"match_probability\": 0.9999723154129404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5761.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 777.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.881156325340271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1188436821103096, \"precision\": 1.0, \"recall\": 0.881156325340271, \"specificity\": 1.0, \"npv\": 0.992838442325592, \"accuracy\": 0.9931995272636414, \"f1\": 0.9368241320432555, \"f2\": 0.9026102215398114, \"f0_5\": 0.9737340274491245, \"p4\": 0.9656970804507149, \"phi\": 0.9353319455314952}, {\"truth_threshold\": 15.151633118812299, \"match_probability\": 0.9999725278899981, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5759.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 779.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8808504343032837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1191495880484581, \"precision\": 1.0, \"recall\": 0.8808504343032837, \"specificity\": 1.0, \"npv\": 0.992820143699646, \"accuracy\": 0.9931820631027222, \"f1\": 0.9366512157436773, \"f2\": 0.9023534204506283, \"f0_5\": 0.9736592953269764, \"p4\": 0.9656008747956797, \"phi\": 0.9351609774343653}, {\"truth_threshold\": 15.187285796743804, \"match_probability\": 0.9999731984579325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5758.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 780.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.88069748878479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11930254101753235, \"precision\": 1.0, \"recall\": 0.88069748878479, \"specificity\": 1.0, \"npv\": 0.9928109645843506, \"accuracy\": 0.9931733012199402, \"f1\": 0.9365647364996746, \"f2\": 0.9022250078345346, \"f0_5\": 0.9736219141021305, \"p4\": 0.9655527552260882, \"phi\": 0.9350754840275172}, {\"truth_threshold\": 15.2562520999992, \"match_probability\": 0.9999744495001998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5756.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 782.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.880391538143158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11960843950510025, \"precision\": 1.0, \"recall\": 0.880391538143158, \"specificity\": 1.0, \"npv\": 0.9927926659584045, \"accuracy\": 0.9931557774543762, \"f1\": 0.9363917358060843, \"f2\": 0.9019681584555598, \"f0_5\": 0.9735471213043773, \"p4\": 0.9654564825814587, \"phi\": 0.934904478488478}, {\"truth_threshold\": 15.279153631456726, \"match_probability\": 0.999974851879842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5755.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 783.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8802385926246643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1197613924741745, \"precision\": 1.0, \"recall\": 0.8802385926246643, \"specificity\": 1.0, \"npv\": 0.9927835464477539, \"accuracy\": 0.9931470155715942, \"f1\": 0.9363052143496299, \"f2\": 0.901839721691165, \"f0_5\": 0.973509709723256, \"p4\": 0.9654083294978947, \"phi\": 0.9348188698433284}, {\"truth_threshold\": 15.293874245992082, \"match_probability\": 0.999975107168975, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5754.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 784.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8800856471061707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11991434544324875, \"precision\": 1.0, \"recall\": 0.8800856471061707, \"specificity\": 1.0, \"npv\": 0.9927743673324585, \"accuracy\": 0.9931382536888123, \"f1\": 0.9362186788154897, \"f2\": 0.9017112768758228, \"f0_5\": 0.9734722880151587, \"p4\": 0.9653601652344771, \"phi\": 0.9347333514532182}, {\"truth_threshold\": 15.393342342375082, \"match_probability\": 0.9999767655642153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5753.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 785.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.879932701587677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.120067298412323, \"precision\": 1.0, \"recall\": 0.879932701587677, \"specificity\": 1.0, \"npv\": 0.9927652478218079, \"accuracy\": 0.993129551410675, \"f1\": 0.9361321292002278, \"f2\": 0.9015828240087761, \"f0_5\": 0.9734348561759729, \"p4\": 0.9653119897869374, \"phi\": 0.9346478268148821}, {\"truth_threshold\": 15.41549997985054, \"match_probability\": 0.9999771196759503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5752.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 786.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8797797560691833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12022025138139725, \"precision\": 1.0, \"recall\": 0.8797797560691833, \"specificity\": 1.0, \"npv\": 0.9927560687065125, \"accuracy\": 0.9931207895278931, \"f1\": 0.9360455655004069, \"f2\": 0.9014543630892679, \"f0_5\": 0.973397414201584, \"p4\": 0.9652638031510051, \"phi\": 0.9345622959265614}, {\"truth_threshold\": 15.452580278045703, \"match_probability\": 0.9999777002424579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5751.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 787.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8796268105506897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1203732043504715, \"precision\": 1.0, \"recall\": 0.8796268105506897, \"specificity\": 1.0, \"npv\": 0.9927469491958618, \"accuracy\": 0.9931120276451111, \"f1\": 0.9359589877125885, \"f2\": 0.9013258941165407, \"f0_5\": 0.9733599620878749, \"p4\": 0.9652156053224075, \"phi\": 0.9344767587864958}, {\"truth_threshold\": 15.455162008897506, \"match_probability\": 0.9999777401117357, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5750.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 788.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.879473865032196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12052615731954575, \"precision\": 1.0, \"recall\": 0.879473865032196, \"specificity\": 1.0, \"npv\": 0.9927377700805664, \"accuracy\": 0.9931032657623291, \"f1\": 0.9358723958333334, \"f2\": 0.9011974170898376, \"f0_5\": 0.9733224998307265, \"p4\": 0.9651673962968695, \"phi\": 0.9343912153929251}, {\"truth_threshold\": 15.551781866704735, \"match_probability\": 0.9999791820418628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5749.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 789.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8793209195137024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12067911028862, \"precision\": 1.0, \"recall\": 0.8793209195137024, \"specificity\": 1.0, \"npv\": 0.9927286505699158, \"accuracy\": 0.9930945038795471, \"f1\": 0.9357857898592008, \"f2\": 0.901068932008401, \"f0_5\": 0.9732850274260175, \"p4\": 0.9651191760701143, \"phi\": 0.9343056657440881}, {\"truth_threshold\": 15.565154361064057, \"match_probability\": 0.999979374110233, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5748.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 790.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.879167914390564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12083205580711365, \"precision\": 1.0, \"recall\": 0.879167914390564, \"specificity\": 1.0, \"npv\": 0.9927194714546204, \"accuracy\": 0.9930857419967651, \"f1\": 0.9356991697867492, \"f2\": 0.9009404388714733, \"f0_5\": 0.9732475448696241, \"p4\": 0.9650709446378627, \"phi\": 0.9342201098382227}, {\"truth_threshold\": 15.573476937804054, \"match_probability\": 0.999979492751284, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5747.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 791.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8790149688720703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1209850087761879, \"precision\": 1.0, \"recall\": 0.8790149688720703, \"specificity\": 1.0, \"npv\": 0.9927103519439697, \"accuracy\": 0.9930770397186279, \"f1\": 0.9356125356125357, \"f2\": 0.9008119376782971, \"f0_5\": 0.9732100521574206, \"p4\": 0.965022701995833, \"phi\": 0.9341345476735661}, {\"truth_threshold\": 15.631649772850963, \"match_probability\": 0.9999803031860665, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5745.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 793.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.878709077835083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1212909147143364, \"precision\": 1.0, \"recall\": 0.878709077835083, \"specificity\": 1.0, \"npv\": 0.9926920533180237, \"accuracy\": 0.993059515953064, \"f1\": 0.9354392249450459, \"f2\": 0.9005549111201681, \"f0_5\": 0.9731350362490684, \"p4\": 0.9649261830653032, \"phi\": 0.9339633079718705}, {\"truth_threshold\": 15.642763361478801, \"match_probability\": 0.9999804543316926, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5741.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 797.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8780972957611084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1219027191400528, \"precision\": 1.0, \"recall\": 0.8780972957611084, \"specificity\": 1.0, \"npv\": 0.9926554560661316, \"accuracy\": 0.993024468421936, \"f1\": 0.9350924342373157, \"f2\": 0.9000407612955821, \"f0_5\": 0.9729848823808556, \"p4\": 0.9647330104982845, \"phi\": 0.933620946531379}, {\"truth_threshold\": 15.706827341244296, \"match_probability\": 0.9999813032675382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5740.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 798.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8779443502426147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12205567210912704, \"precision\": 1.0, \"recall\": 0.8779443502426147, \"specificity\": 1.0, \"npv\": 0.992646336555481, \"accuracy\": 0.9930157661437988, \"f1\": 0.935005701254276, \"f2\": 0.8999122036874452, \"f0_5\": 0.9729473184622687, \"p4\": 0.9646846892677466, \"phi\": 0.9335353404977887}, {\"truth_threshold\": 15.722561173364607, \"match_probability\": 0.9999815060599168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5738.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 800.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8776383996009827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12236157804727554, \"precision\": 1.0, \"recall\": 0.8776383996009827, \"specificity\": 1.0, \"npv\": 0.9926280379295349, \"accuracy\": 0.9929982423782349, \"f1\": 0.934832192896709, \"f2\": 0.8996550642834744, \"f0_5\": 0.9728721600542557, \"p4\": 0.9645880130700467, \"phi\": 0.9333641096100677}, {\"truth_threshold\": 15.793323038054183, \"match_probability\": 0.9999823912557058, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5737.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 801.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.877485454082489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12251453101634979, \"precision\": 1.0, \"recall\": 0.877485454082489, \"specificity\": 1.0, \"npv\": 0.9926188588142395, \"accuracy\": 0.9929894804954529, \"f1\": 0.934745417515275, \"f2\": 0.8995264824861238, \"f0_5\": 0.9728345655565354, \"p4\": 0.9645396580942803, \"phi\": 0.9332783880996849}, {\"truth_threshold\": 15.826008074674334, \"match_probability\": 0.999982785699427, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5735.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 803.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8771795630455017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12282043695449829, \"precision\": 1.0, \"recall\": 0.8771795630455017, \"specificity\": 1.0, \"npv\": 0.9926005601882935, \"accuracy\": 0.9929719567298889, \"f1\": 0.9345718243298297, \"f2\": 0.8992692946968984, \"f0_5\": 0.972759345952914, \"p4\": 0.9644429143673876, \"phi\": 0.9331071195319033}, {\"truth_threshold\": 15.842586870406114, \"match_probability\": 0.9999829823827173, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5734.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 804.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8770266175270081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12297338992357254, \"precision\": 1.0, \"recall\": 0.8770266175270081, \"specificity\": 1.0, \"npv\": 0.9925914406776428, \"accuracy\": 0.9929632544517517, \"f1\": 0.9344850065189049, \"f2\": 0.8991406887035063, \"f0_5\": 0.9727217208387053, \"p4\": 0.9643945256076439, \"phi\": 0.9330214758262253}, {\"truth_threshold\": 15.894684178684757, \"match_probability\": 0.9999835859345045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5733.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 805.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8768736720085144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12312633544206619, \"precision\": 1.0, \"recall\": 0.8768736720085144, \"specificity\": 1.0, \"npv\": 0.9925822615623474, \"accuracy\": 0.9929544925689697, \"f1\": 0.9343981745579008, \"f2\": 0.8990120746432492, \"f0_5\": 0.9726840855106889, \"p4\": 0.9643461255779533, \"phi\": 0.9329358258369912}, {\"truth_threshold\": 15.911636363403227, \"match_probability\": 0.9999837776738295, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5730.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 808.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8764148354530334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12358519434928894, \"precision\": 1.0, \"recall\": 0.8764148354530334, \"specificity\": 1.0, \"npv\": 0.9925548434257507, \"accuracy\": 0.9929282069206238, \"f1\": 0.9341375937398109, \"f2\": 0.898626184053698, \"f0_5\": 0.9725711182021861, \"p4\": 0.9642008578260471, \"phi\": 0.9326788381502045}, {\"truth_threshold\": 15.91522507932624, \"match_probability\": 0.999983817976201, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5729.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 809.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.876261830329895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12373814731836319, \"precision\": 1.0, \"recall\": 0.876261830329895, \"specificity\": 1.0, \"npv\": 0.9925457239151001, \"accuracy\": 0.9929194450378418, \"f1\": 0.934050705143882, \"f2\": 0.8984975377183902, \"f0_5\": 0.9725334419773206, \"p4\": 0.9641524126734049, \"phi\": 0.9325931630089941}, {\"truth_threshold\": 15.92408609923009, \"match_probability\": 0.9999839170598495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5727.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 811.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8759559392929077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12404405325651169, \"precision\": 1.0, \"recall\": 0.8759559392929077, \"specificity\": 1.0, \"npv\": 0.992527425289154, \"accuracy\": 0.9929019808769226, \"f1\": 0.9338768854463921, \"f2\": 0.8982402208350325, \"f0_5\": 0.9724580588195341, \"p4\": 0.9640554884891758, \"phi\": 0.9324216971148861}, {\"truth_threshold\": 15.949142548622625, \"match_probability\": 0.9999841939692241, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5726.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 812.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8758029937744141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12419699877500534, \"precision\": 1.0, \"recall\": 0.8758029937744141, \"specificity\": 1.0, \"npv\": 0.9925182461738586, \"accuracy\": 0.9928932189941406, \"f1\": 0.9337899543378996, \"f2\": 0.8981115502854633, \"f0_5\": 0.9724203518782691, \"p4\": 0.9640070094489361, \"phi\": 0.9323360030830314}, {\"truth_threshold\": 15.973363759798405, \"match_probability\": 0.9999844571152618, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5725.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 813.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8756500482559204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12434995174407959, \"precision\": 1.0, \"recall\": 0.8756500482559204, \"specificity\": 1.0, \"npv\": 0.992509126663208, \"accuracy\": 0.9928844571113586, \"f1\": 0.9337030090516187, \"f2\": 0.8979828716629544, \"f0_5\": 0.9723826346898566, \"p4\": 0.9639585191041743, \"phi\": 0.9322503027534013}, {\"truth_threshold\": 15.986725440628122, \"match_probability\": 0.9999846004006524, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5723.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 815.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8753441572189331, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12465585768222809, \"precision\": 1.0, \"recall\": 0.8753441572189331, \"specificity\": 1.0, \"npv\": 0.992490828037262, \"accuracy\": 0.9928669333457947, \"f1\": 0.9335290759318163, \"f2\": 0.8977254901960784, \"f0_5\": 0.972307169554876, \"p4\": 0.963861504483755, \"phi\": 0.9320788831936918}, {\"truth_threshold\": 15.9983573400555, \"match_probability\": 0.9999847240606655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5720.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 818.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8748852610588074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12511470913887024, \"precision\": 1.0, \"recall\": 0.8748852610588074, \"specificity\": 1.0, \"npv\": 0.9924634099006653, \"accuracy\": 0.9928407073020935, \"f1\": 0.9332680698319464, \"f2\": 0.8973393574297188, \"f0_5\": 0.9721938948942824, \"p4\": 0.9637158976608428, \"phi\": 0.9318217065762703}, {\"truth_threshold\": 16.028233648532392, \"match_probability\": 0.9999850371474602, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5719.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 819.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8747323155403137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12526766955852509, \"precision\": 1.0, \"recall\": 0.8747323155403137, \"specificity\": 1.0, \"npv\": 0.9924542307853699, \"accuracy\": 0.9928319454193115, \"f1\": 0.9331810394060537, \"f2\": 0.897210630353613, \"f0_5\": 0.9721561161351737, \"p4\": 0.9636673393979026, \"phi\": 0.9317359684225669}, {\"truth_threshold\": 16.03035139642464, \"match_probability\": 0.999985059095155, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5718.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 820.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8745793700218201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12542061507701874, \"precision\": 1.0, \"recall\": 0.8745793700218201, \"specificity\": 1.0, \"npv\": 0.9924451112747192, \"accuracy\": 0.9928231835365295, \"f1\": 0.9330939947780679, \"f2\": 0.897081895199247, \"f0_5\": 0.972118327099626, \"p4\": 0.9636187698000713, \"phi\": 0.9316501271539223}, {\"truth_threshold\": 16.117131264437692, \"match_probability\": 0.9999859313010859, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5717.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 821.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8744264245033264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12557357549667358, \"precision\": 1.0, \"recall\": 0.8744264245033264, \"specificity\": 1.0, \"npv\": 0.9924359917640686, \"accuracy\": 0.9928144216537476, \"f1\": 0.9330069359445124, \"f2\": 0.8969531519658602, \"f0_5\": 0.9720805277834456, \"p4\": 0.9635701888630014, \"phi\": 0.9315643763699}, {\"truth_threshold\": 16.14316606511283, \"match_probability\": 0.9999861829035659, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5716.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 822.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8742734789848328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12572652101516724, \"precision\": 1.0, \"recall\": 0.8742734789848328, \"specificity\": 1.0, \"npv\": 0.9924268126487732, \"accuracy\": 0.9928057193756104, \"f1\": 0.9329198629019095, \"f2\": 0.8968244006526923, \"f0_5\": 0.9720427181824366, \"p4\": 0.9635215965823433, \"phi\": 0.9314786192720461}, {\"truth_threshold\": 16.15715648685757, \"match_probability\": 0.999986316244363, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5713.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 825.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8738146424293518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1261853724718094, \"precision\": 1.0, \"recall\": 0.8738146424293518, \"specificity\": 1.0, \"npv\": 0.9923993945121765, \"accuracy\": 0.9927794337272644, \"f1\": 0.9326585584850217, \"f2\": 0.8964380982268947, \"f0_5\": 0.971929227628445, \"p4\": 0.9633757516353116, \"phi\": 0.9312213100776142}, {\"truth_threshold\": 16.208360537333025, \"match_probability\": 0.9999867933836413, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5712.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 826.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8736616969108582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12633833289146423, \"precision\": 1.0, \"recall\": 0.8736616969108582, \"specificity\": 1.0, \"npv\": 0.9923902750015259, \"accuracy\": 0.9927706718444824, \"f1\": 0.9325714285714286, \"f2\": 0.8963093145869947, \"f0_5\": 0.9718913768461171, \"p4\": 0.9633271139367613, \"phi\": 0.9311355277065492}, {\"truth_threshold\": 16.222537683606888, \"match_probability\": 0.999986922525799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5710.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 828.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8733557462692261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12664423882961273, \"precision\": 1.0, \"recall\": 0.8733557462692261, \"specificity\": 1.0, \"npv\": 0.9923719763755798, \"accuracy\": 0.9927532076835632, \"f1\": 0.9323971260613978, \"f2\": 0.8960517230556776, \"f0_5\": 0.971815644359725, \"p4\": 0.9632298044391905, \"phi\": 0.9309639439942938}, {\"truth_threshold\": 16.246730816379472, \"match_probability\": 0.99998713999588, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5708.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 830.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8730498552322388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12695014476776123, \"precision\": 1.0, \"recall\": 0.8730498552322388, \"specificity\": 1.0, \"npv\": 0.9923536777496338, \"accuracy\": 0.9927356839179993, \"f1\": 0.9322227666176711, \"f2\": 0.8957940991839297, \"f0_5\": 0.9717398706162751, \"p4\": 0.9631324494452292, \"phi\": 0.9307922380916076}, {\"truth_threshold\": 16.28298088671982, \"match_probability\": 0.9999874590947169, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5707.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 831.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8728969097137451, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12710309028625488, \"precision\": 1.0, \"recall\": 0.8728969097137451, \"specificity\": 1.0, \"npv\": 0.9923445582389832, \"accuracy\": 0.9927269220352173, \"f1\": 0.9321355655369539, \"f2\": 0.8956652751184908, \"f0_5\": 0.9717019682626167, \"p4\": 0.9630837548761825, \"phi\": 0.9307064240806872}, {\"truth_threshold\": 16.30937828430943, \"match_probability\": 0.9999876864698513, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5706.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 832.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8727439641952515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12725603580474854, \"precision\": 1.0, \"recall\": 0.8727439641952515, \"specificity\": 1.0, \"npv\": 0.9923353791236877, \"accuracy\": 0.9927181601524353, \"f1\": 0.9320483502123489, \"f2\": 0.8955364429656602, \"f0_5\": 0.9716640555820448, \"p4\": 0.96303504891993, \"phi\": 0.9306206037380206}, {\"truth_threshold\": 16.320067486328995, \"match_probability\": 0.9999877773648784, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5704.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 834.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8724380731582642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12756194174289703, \"precision\": 1.0, \"recall\": 0.8724380731582642, \"specificity\": 1.0, \"npv\": 0.9923171401023865, \"accuracy\": 0.9927006363868713, \"f1\": 0.9318738768175134, \"f2\": 0.8952787543947764, \"f0_5\": 0.9715881992232746, \"p4\": 0.9629376028283093, \"phi\": 0.930448944050266}, {\"truth_threshold\": 16.323083848424197, \"match_probability\": 0.9999878028927471, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5703.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 835.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8722851276397705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12771490216255188, \"precision\": 1.0, \"recall\": 0.8722851276397705, \"specificity\": 1.0, \"npv\": 0.9923079609870911, \"accuracy\": 0.9926919341087341, \"f1\": 0.931786618740299, \"f2\": 0.8951498979752002, \"f0_5\": 0.9715502555366269, \"p4\": 0.9628888626841865, \"phi\": 0.9303631047015843}, {\"truth_threshold\": 16.3632178962452, \"match_probability\": 0.9999881375215682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5701.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 837.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8719791769981384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12802080810070038, \"precision\": 1.0, \"recall\": 0.8719791769981384, \"specificity\": 1.0, \"npv\": 0.9922897219657898, \"accuracy\": 0.9926744103431702, \"f1\": 0.9316120598088079, \"f2\": 0.8948921608639688, \"f0_5\": 0.9714743371276668, \"p4\": 0.9627913481774122, \"phi\": 0.9301914069856229}, {\"truth_threshold\": 16.498922517980567, \"match_probability\": 0.9999892024621125, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5700.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 838.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8718262314796448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12817375361919403, \"precision\": 1.0, \"recall\": 0.8718262314796448, \"specificity\": 1.0, \"npv\": 0.9922805428504944, \"accuracy\": 0.9926656484603882, \"f1\": 0.9315247589475405, \"f2\": 0.8947632801707899, \"f0_5\": 0.9714363623968914, \"p4\": 0.9627425738059924, \"phi\": 0.9301054516653695}, {\"truth_threshold\": 16.520131734929432, \"match_probability\": 0.9999893600351174, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5698.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 840.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8715203404426575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12847965955734253, \"precision\": 1.0, \"recall\": 0.8715203404426575, \"specificity\": 1.0, \"npv\": 0.9922622442245483, \"accuracy\": 0.9926481246948242, \"f1\": 0.931350114416476, \"f2\": 0.8945054945054945, \"f0_5\": 0.9713603818615751, \"p4\": 0.9626449908051505, \"phi\": 0.9299337158726967}, {\"truth_threshold\": 16.60713394231785, \"match_probability\": 0.9999899827112889, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5696.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 842.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8712144494056702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12878556549549103, \"precision\": 1.0, \"recall\": 0.8712144494056702, \"specificity\": 1.0, \"npv\": 0.9922440052032471, \"accuracy\": 0.992630660533905, \"f1\": 0.9311754127840445, \"f2\": 0.8942476764632002, \"f0_5\": 0.971284359866312, \"p4\": 0.9625473620976962, \"phi\": 0.929761954688275}, {\"truth_threshold\": 16.61070178918836, \"match_probability\": 0.99999000745362, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5695.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 843.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8710615038871765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12893851101398468, \"precision\": 1.0, \"recall\": 0.8710615038871765, \"specificity\": 1.0, \"npv\": 0.9922348260879517, \"accuracy\": 0.992621898651123, \"f1\": 0.931088040546064, \"f2\": 0.8941187552987723, \"f0_5\": 0.9712463333105942, \"p4\": 0.9624985305930025, \"phi\": 0.9296760645696514}, {\"truth_threshold\": 16.625294032880138, \"match_probability\": 0.9999901080135382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5694.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 844.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8709085583686829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12909147143363953, \"precision\": 1.0, \"recall\": 0.8709085583686829, \"specificity\": 1.0, \"npv\": 0.992225706577301, \"accuracy\": 0.9926131367683411, \"f1\": 0.9310006540222368, \"f2\": 0.893989826037807, \"f0_5\": 0.9712082963771577, \"p4\": 0.962449687648467, \"phi\": 0.92959016809768}, {\"truth_threshold\": 16.638530931584782, \"match_probability\": 0.9999901983577086, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5693.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 845.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8707555532455444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12924441695213318, \"precision\": 1.0, \"recall\": 0.8707555532455444, \"specificity\": 1.0, \"npv\": 0.9922165870666504, \"accuracy\": 0.9926043748855591, \"f1\": 0.9309132532090589, \"f2\": 0.8938608886795415, \"f0_5\": 0.9711702490617536, \"p4\": 0.9624008332596885, \"phi\": 0.9295042652705561}, {\"truth_threshold\": 16.65695553493558, \"match_probability\": 0.9999903227369852, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5692.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 846.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8706026077270508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12939736247062683, \"precision\": 1.0, \"recall\": 0.8706026077270508, \"specificity\": 1.0, \"npv\": 0.992207407951355, \"accuracy\": 0.9925956130027771, \"f1\": 0.9308258381030253, \"f2\": 0.8937319432232131, \"f0_5\": 0.9711321913601311, \"p4\": 0.9623519674222641, \"phi\": 0.9294183560864737}, {\"truth_threshold\": 16.685031637858188, \"match_probability\": 0.9999905092425045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5691.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 847.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8704496622085571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12955032289028168, \"precision\": 1.0, \"recall\": 0.8704496622085571, \"specificity\": 1.0, \"npv\": 0.9921982884407043, \"accuracy\": 0.9925869107246399, \"f1\": 0.9307384087006296, \"f2\": 0.893602989668059, \"f0_5\": 0.9710941232680363, \"p4\": 0.9623030901317883, \"phi\": 0.9293323435216427}, {\"truth_threshold\": 16.735826034416473, \"match_probability\": 0.999990837576065, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5689.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 849.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8701437711715698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12985622882843018, \"precision\": 1.0, \"recall\": 0.8701437711715698, \"specificity\": 1.0, \"npv\": 0.9921799898147583, \"accuracy\": 0.9925693869590759, \"f1\": 0.9305635069927211, \"f2\": 0.8933450582582205, \"f0_5\": 0.9710179558954052, \"p4\": 0.962205301174049, \"phi\": 0.9291604933362625}, {\"truth_threshold\": 16.754617040047453, \"match_probability\": 0.9999909561411127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5686.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 852.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8696849346160889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13031508028507233, \"precision\": 1.0, \"recall\": 0.8696849346160889, \"specificity\": 1.0, \"npv\": 0.9921525716781616, \"accuracy\": 0.99254310131073, \"f1\": 0.9303010471204188, \"f2\": 0.8929581003831899, \"f0_5\": 0.970903626801448, \"p4\": 0.9620585317292881, \"phi\": 0.9289026703222237}, {\"truth_threshold\": 16.777525443001394, \"match_probability\": 0.9999910986121842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5683.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 855.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8692260384559631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13077393174171448, \"precision\": 1.0, \"recall\": 0.8692260384559631, \"specificity\": 1.0, \"npv\": 0.9921252131462097, \"accuracy\": 0.9925168752670288, \"f1\": 0.9300384583912936, \"f2\": 0.892571069577509, \"f0_5\": 0.9707892039631022, \"p4\": 0.9619116589687295, \"phi\": 0.9286447899815622}, {\"truth_threshold\": 16.79903082507643, \"match_probability\": 0.9999912303145803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5682.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 856.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8690730929374695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13092689216136932, \"precision\": 1.0, \"recall\": 0.8690730929374695, \"specificity\": 1.0, \"npv\": 0.9921160340309143, \"accuracy\": 0.9925081133842468, \"f1\": 0.9299509001636661, \"f2\": 0.8924420430985739, \"f0_5\": 0.9707510421649695, \"p4\": 0.9618626784021727, \"phi\": 0.9285587200255323}, {\"truth_threshold\": 16.83232414378797, \"match_probability\": 0.9999914303750737, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5681.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 857.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8689201474189758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13107983767986298, \"precision\": 1.0, \"recall\": 0.8689201474189758, \"specificity\": 1.0, \"npv\": 0.9921069145202637, \"accuracy\": 0.9924993515014648, \"f1\": 0.9298633276045503, \"f2\": 0.8923130085131782, \"f0_5\": 0.9707128699337024, \"p4\": 0.9618136863383855, \"phi\": 0.9284727407792936}, {\"truth_threshold\": 16.851894303686496, \"match_probability\": 0.9999915458361774, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5680.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 858.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8687672019004822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13123279809951782, \"precision\": 1.0, \"recall\": 0.8687672019004822, \"specificity\": 1.0, \"npv\": 0.992097795009613, \"accuracy\": 0.9924905896186829, \"f1\": 0.9297757407104272, \"f2\": 0.8921839658205579, \"f0_5\": 0.9706746872650215, \"p4\": 0.9617646827729377, \"phi\": 0.9283867551543593}, {\"truth_threshold\": 16.864734916249514, \"match_probability\": 0.9999916207474117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5679.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 859.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8686142563819885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13138574361801147, \"precision\": 1.0, \"recall\": 0.8686142563819885, \"specificity\": 1.0, \"npv\": 0.9920886158943176, \"accuracy\": 0.9924818873405457, \"f1\": 0.9296881394777768, \"f2\": 0.8920549150199492, \"f0_5\": 0.9706364941546455, \"p4\": 0.9617156677013967, \"phi\": 0.9283007631489126}, {\"truth_threshold\": 16.87272125477331, \"match_probability\": 0.9999916670039714, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5678.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 860.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8684613108634949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13153870403766632, \"precision\": 1.0, \"recall\": 0.8684613108634949, \"specificity\": 1.0, \"npv\": 0.992079496383667, \"accuracy\": 0.9924731254577637, \"f1\": 0.9296005239030779, \"f2\": 0.8919258561105875, \"f0_5\": 0.9705982905982906, \"p4\": 0.9616666411193278, \"phi\": 0.9282147647611371}, {\"truth_threshold\": 16.884191948043153, \"match_probability\": 0.9999917329953718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5677.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 861.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8683083653450012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13169164955615997, \"precision\": 1.0, \"recall\": 0.8683083653450012, \"specificity\": 1.0, \"npv\": 0.9920703768730164, \"accuracy\": 0.9924643635749817, \"f1\": 0.929512893982808, \"f2\": 0.8917967890917088, \"f0_5\": 0.9705600765916707, \"p4\": 0.9616176030222934, \"phi\": 0.9281287599892142}, {\"truth_threshold\": 16.8966812460477, \"match_probability\": 0.9999918042527174, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5676.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 862.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8681554198265076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13184459507465363, \"precision\": 1.0, \"recall\": 0.8681554198265076, \"specificity\": 1.0, \"npv\": 0.992061197757721, \"accuracy\": 0.9924556016921997, \"f1\": 0.9294252497134435, \"f2\": 0.8916677139625487, \"f0_5\": 0.9705218521304972, \"p4\": 0.9615685534058545, \"phi\": 0.9280427488313256}, {\"truth_threshold\": 16.897690730835027, \"match_probability\": 0.9999918099854054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5675.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 863.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8680024743080139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13199755549430847, \"precision\": 1.0, \"recall\": 0.8680024743080139, \"specificity\": 1.0, \"npv\": 0.9920520782470703, \"accuracy\": 0.9924468398094177, \"f1\": 0.92933759109146, \"f2\": 0.8915386307223426, \"f0_5\": 0.9704836172104795, \"p4\": 0.9615194922655691, \"phi\": 0.9279567312856519}, {\"truth_threshold\": 16.910696251742383, \"match_probability\": 0.999991883483877, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5673.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 865.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8676965236663818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13230346143245697, \"precision\": 1.0, \"recall\": 0.8676965236663818, \"specificity\": 1.0, \"npv\": 0.992033839225769, \"accuracy\": 0.9924293756484985, \"f1\": 0.9291622307755303, \"f2\": 0.8912804399057345, \"f0_5\": 0.9704071159767362, \"p4\": 0.961421335395681, \"phi\": 0.9277845798559381}, {\"truth_threshold\": 16.93977613220204, \"match_probability\": 0.999992045446452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5672.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 866.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8675435781478882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13245640695095062, \"precision\": 1.0, \"recall\": 0.8675435781478882, \"specificity\": 1.0, \"npv\": 0.9920246601104736, \"accuracy\": 0.9924206137657166, \"f1\": 0.929074529074529, \"f2\": 0.891151332327803, \"f0_5\": 0.9703688496544173, \"p4\": 0.9613722396571834, \"phi\": 0.9276985431278657}, {\"truth_threshold\": 16.94411506792638, \"match_probability\": 0.9999920693338108, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5671.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 867.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8673906326293945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13260936737060547, \"precision\": 1.0, \"recall\": 0.8673906326293945, \"specificity\": 1.0, \"npv\": 0.992015540599823, \"accuracy\": 0.9924118518829346, \"f1\": 0.9289868130067983, \"f2\": 0.8910222166357665, \"f0_5\": 0.9703305728560674, \"p4\": 0.9613231323770498, \"phi\": 0.92761250000472}, {\"truth_threshold\": 17.002064961322322, \"match_probability\": 0.9999923815758194, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5668.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 870.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8669317960739136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13306821882724762, \"precision\": 1.0, \"recall\": 0.8669317960739136, \"specificity\": 1.0, \"npv\": 0.9919881224632263, \"accuracy\": 0.9923855662345886, \"f1\": 0.9287235785679174, \"f2\": 0.890634820867379, \"f0_5\": 0.9702156795617939, \"p4\": 0.9611757412422901, \"phi\": 0.9273543322466018}, {\"truth_threshold\": 17.029884475498275, \"match_probability\": 0.9999925270736041, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5667.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 871.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8667788505554199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13322116434574127, \"precision\": 1.0, \"recall\": 0.8667788505554199, \"specificity\": 1.0, \"npv\": 0.9919790029525757, \"accuracy\": 0.9923768639564514, \"f1\": 0.9286358049979516, \"f2\": 0.8905056727112731, \"f0_5\": 0.9701773608162706, \"p4\": 0.9611265877510583, \"phi\": 0.9272682635249186}, {\"truth_threshold\": 17.051830007568523, \"match_probability\": 0.9999926398868616, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5666.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 872.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8666259050369263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13337412476539612, \"precision\": 1.0, \"recall\": 0.8666259050369263, \"specificity\": 1.0, \"npv\": 0.991969883441925, \"accuracy\": 0.9923681020736694, \"f1\": 0.9285480170435922, \"f2\": 0.8903765164372368, \"f0_5\": 0.9701390315731799, \"p4\": 0.9610774226959019, \"phi\": 0.9271821883990359}, {\"truth_threshold\": 17.059747488943998, \"match_probability\": 0.9999926801680864, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5665.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 873.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8664728999137878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13352707028388977, \"precision\": 1.0, \"recall\": 0.8664728999137878, \"specificity\": 1.0, \"npv\": 0.9919607043266296, \"accuracy\": 0.9923593401908875, \"f1\": 0.9284602147013029, \"f2\": 0.8902473520445046, \"f0_5\": 0.9701006918282075, \"p4\": 0.9610282460723565, \"phi\": 0.9270961068671267}, {\"truth_threshold\": 17.07390399732606, \"match_probability\": 0.9999927516424912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5664.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 874.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8663199543952942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13368003070354462, \"precision\": 1.0, \"recall\": 0.8663199543952942, \"specificity\": 1.0, \"npv\": 0.991951584815979, \"accuracy\": 0.9923505783081055, \"f1\": 0.9283723979675463, \"f2\": 0.8901181795323108, \"f0_5\": 0.9700623415770364, \"p4\": 0.9609790578759552, \"phi\": 0.927010018927362}, {\"truth_threshold\": 17.086978798764324, \"match_probability\": 0.9999928170353889, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5662.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 876.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8660140633583069, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13398592174053192, \"precision\": 1.0, \"recall\": 0.8660140633583069, \"specificity\": 1.0, \"npv\": 0.9919333457946777, \"accuracy\": 0.9923330545425415, \"f1\": 0.9281967213114755, \"f2\": 0.8898598101464764, \"f0_5\": 0.96998560953882, \"p4\": 0.9608806467467058, \"phi\": 0.9268377265598058}, {\"truth_threshold\": 17.0893086211043, \"match_probability\": 0.9999928286257843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5661.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 877.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8658611178398132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13413888216018677, \"precision\": 1.0, \"recall\": 0.8658611178398132, \"specificity\": 1.0, \"npv\": 0.9919241666793823, \"accuracy\": 0.9923242926597595, \"f1\": 0.9281088613820805, \"f2\": 0.8897306132713042, \"f0_5\": 0.9699472277431294, \"p4\": 0.9608314238049126, \"phi\": 0.9267516193773553}, {\"truth_threshold\": 17.104191594675633, \"match_probability\": 0.999992902225526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5660.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 878.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8657081723213196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13429182767868042, \"precision\": 1.0, \"recall\": 0.8657081723213196, \"specificity\": 1.0, \"npv\": 0.9919150471687317, \"accuracy\": 0.9923155903816223, \"f1\": 0.9280209870470569, \"f2\": 0.8896014082736075, \"f0_5\": 0.9699088354239496, \"p4\": 0.960782189272373, \"phi\": 0.9266655057797256}, {\"truth_threshold\": 17.104214578324704, \"match_probability\": 0.9999929023385992, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5658.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 880.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8654022812843323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13459773361682892, \"precision\": 1.0, \"recall\": 0.8654022812843323, \"specificity\": 1.0, \"npv\": 0.9918968081474304, \"accuracy\": 0.9922980666160583, \"f1\": 0.9278451951459495, \"f2\": 0.8893429739075762, \"f0_5\": 0.9698320191978059, \"p4\": 0.9606836854171392, \"phi\": 0.9264932593315989}, {\"truth_threshold\": 17.120297118614488, \"match_probability\": 0.9999929810203333, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5656.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 882.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8650963306427002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13490363955497742, \"precision\": 1.0, \"recall\": 0.8650963306427002, \"specificity\": 1.0, \"npv\": 0.9918785095214844, \"accuracy\": 0.9922805428504944, \"f1\": 0.9276693455797933, \"f2\": 0.8890845070422535, \"f0_5\": 0.9697551608257321, \"p4\": 0.96058513514515, \"phi\": 0.926320987200756}, {\"truth_threshold\": 17.12444392597062, \"match_probability\": 0.9999930011662141, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5655.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 883.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8649433851242065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13505658507347107, \"precision\": 1.0, \"recall\": 0.8649433851242065, \"specificity\": 1.0, \"npv\": 0.9918693900108337, \"accuracy\": 0.9922717809677124, \"f1\": 0.9275813991634544, \"f2\": 0.888955261420442, \"f0_5\": 0.9697167158241305, \"p4\": 0.9605358425916576, \"phi\": 0.9262348414997282}, {\"truth_threshold\": 17.133532677548143, \"match_probability\": 0.9999930451188654, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5654.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 884.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8647904396057129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13520954549312592, \"precision\": 1.0, \"recall\": 0.8647904396057129, \"specificity\": 1.0, \"npv\": 0.9918602705001831, \"accuracy\": 0.9922630786895752, \"f1\": 0.92749343832021, \"f2\": 0.8888260076715085, \"f0_5\": 0.9696782602730328, \"p4\": 0.9604865384205141, \"phi\": 0.9261485920501737}, {\"truth_threshold\": 17.13722992312138, \"match_probability\": 0.9999930629194427, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5653.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 885.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8646374940872192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13536249101161957, \"precision\": 1.0, \"recall\": 0.8646374940872192, \"specificity\": 1.0, \"npv\": 0.9918511509895325, \"accuracy\": 0.9922543168067932, \"f1\": 0.9274054630465097, \"f2\": 0.8886967457946864, \"f0_5\": 0.9696397941680961, \"p4\": 0.9604372226272275, \"phi\": 0.9260624334867774}, {\"truth_threshold\": 17.142441316318884, \"match_probability\": 0.9999930879326211, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5652.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 886.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8644845485687256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13551545143127441, \"precision\": 1.0, \"recall\": 0.8644845485687256, \"specificity\": 1.0, \"npv\": 0.9918419718742371, \"accuracy\": 0.9922455549240112, \"f1\": 0.9273174733388023, \"f2\": 0.8885674757892089, \"f0_5\": 0.9696013175049749, \"p4\": 0.9603878952073034, \"phi\": 0.9259762684935174}, {\"truth_threshold\": 17.15057420411789, \"match_probability\": 0.999993126788047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5651.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 887.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8643316030502319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13566839694976807, \"precision\": 1.0, \"recall\": 0.8643316030502319, \"specificity\": 1.0, \"npv\": 0.9918328523635864, \"accuracy\": 0.9922367930412292, \"f1\": 0.9272294691935351, \"f2\": 0.8884381976543093, \"f0_5\": 0.9695628302793219, \"p4\": 0.9603385561562446, \"phi\": 0.925890097068555}, {\"truth_threshold\": 17.1968301461282, \"match_probability\": 0.9999933436614158, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5650.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 888.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8641786575317383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1358213573694229, \"precision\": 1.0, \"recall\": 0.8641786575317383, \"specificity\": 1.0, \"npv\": 0.9918237328529358, \"accuracy\": 0.9922280311584473, \"f1\": 0.9271414506071546, \"f2\": 0.8883089113892209, \"f0_5\": 0.969524332486787, \"p4\": 0.9602892054695524, \"phi\": 0.9258039192100499}, {\"truth_threshold\": 17.277959709650304, \"match_probability\": 0.9999937076462424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5647.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 891.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8637198209762573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13628020882606506, \"precision\": 1.0, \"recall\": 0.8637198209762573, \"specificity\": 1.0, \"npv\": 0.9917963147163391, \"accuracy\": 0.9922018051147461, \"f1\": 0.9268773081657776, \"f2\": 0.8879210038051512, \"f0_5\": 0.9694087756643549, \"p4\": 0.9601410835506483, \"phi\": 0.9255453470148712}, {\"truth_threshold\": 17.286307747734654, \"match_probability\": 0.9999937439510715, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5643.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 895.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8631079792976379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13689202070236206, \"precision\": 1.0, \"recall\": 0.8631079792976379, \"specificity\": 1.0, \"npv\": 0.9917598366737366, \"accuracy\": 0.9921667575836182, \"f1\": 0.9265249158525573, \"f2\": 0.8874036798238717, \"f0_5\": 0.9692545517004466, \"p4\": 0.9599434244865539, \"phi\": 0.9252003964943996}, {\"truth_threshold\": 17.286321245383522, \"match_probability\": 0.9999937440096016, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5642.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 896.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8629550337791443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1370449662208557, \"precision\": 1.0, \"recall\": 0.8629550337791443, \"specificity\": 1.0, \"npv\": 0.9917506575584412, \"accuracy\": 0.992158055305481, \"f1\": 0.9264367816091954, \"f2\": 0.8872743284896522, \"f0_5\": 0.9692159692159692, \"p4\": 0.9598939805525466, \"phi\": 0.925114167093042}, {\"truth_threshold\": 17.28784119476095, \"match_probability\": 0.9999937505970797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5641.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 897.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8628020882606506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13719792664051056, \"precision\": 1.0, \"recall\": 0.8628020882606506, \"specificity\": 1.0, \"npv\": 0.9917415380477905, \"accuracy\": 0.992149293422699, \"f1\": 0.9263486328926841, \"f2\": 0.8871449690183374, \"f0_5\": 0.9691773761253523, \"p4\": 0.9598445249423092, \"phi\": 0.9250279312415448}, {\"truth_threshold\": 17.291532185904437, \"match_probability\": 0.9999937665650183, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5640.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 898.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.862649142742157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1373508721590042, \"precision\": 1.0, \"recall\": 0.862649142742157, \"specificity\": 1.0, \"npv\": 0.9917324185371399, \"accuracy\": 0.992140531539917, \"f1\": 0.9262604696994581, \"f2\": 0.8870156014091596, \"f0_5\": 0.9691387724242216, \"p4\": 0.9597950576513194, \"phi\": 0.9249416889380603}, {\"truth_threshold\": 17.294326518389536, \"match_probability\": 0.9999937786266969, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5639.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 899.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8624961972236633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13750381767749786, \"precision\": 1.0, \"recall\": 0.8624961972236633, \"specificity\": 1.0, \"npv\": 0.9917232990264893, \"accuracy\": 0.992131769657135, \"f1\": 0.9261722920259505, \"f2\": 0.8868862256613507, \"f0_5\": 0.969100158108201, \"p4\": 0.9597455786750526, \"phi\": 0.9248554401807395}, {\"truth_threshold\": 17.340564682766036, \"match_probability\": 0.9999939748582045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5638.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 900.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8623432517051697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1376567780971527, \"precision\": 1.0, \"recall\": 0.8623432517051697, \"specificity\": 1.0, \"npv\": 0.9917141795158386, \"accuracy\": 0.992123007774353, \"f1\": 0.926084099868594, \"f2\": 0.8867568417741428, \"f0_5\": 0.9690615331729117, \"p4\": 0.9596960880089818, \"phi\": 0.924769184967733}, {\"truth_threshold\": 17.34876177190212, \"match_probability\": 0.9999940089945156, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5637.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 901.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8621902465820312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13780972361564636, \"precision\": 1.0, \"recall\": 0.8621902465820312, \"specificity\": 1.0, \"npv\": 0.9917050004005432, \"accuracy\": 0.992114245891571, \"f1\": 0.9259958932238193, \"f2\": 0.8866274497467678, \"f0_5\": 0.9690228976139723, \"p4\": 0.9596465856485774, \"phi\": 0.9246829232971902}, {\"truth_threshold\": 17.352343026938097, \"match_probability\": 0.9999940238476774, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5635.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 903.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.861884355545044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13811562955379486, \"precision\": 1.0, \"recall\": 0.861884355545044, \"specificity\": 1.0, \"npv\": 0.9916867613792419, \"accuracy\": 0.9920967817306519, \"f1\": 0.9258194364577343, \"f2\": 0.8863686412684431, \"f0_5\": 0.9689455946076071, \"p4\": 0.9595475458266397, \"phi\": 0.9245102830983386}, {\"truth_threshold\": 17.353874939664404, \"match_probability\": 0.9999940301899951, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5634.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 904.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8617314100265503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1382685899734497, \"precision\": 1.0, \"recall\": 0.8617314100265503, \"specificity\": 1.0, \"npv\": 0.9916776418685913, \"accuracy\": 0.9920880198478699, \"f1\": 0.9257311863292803, \"f2\": 0.8862392248159567, \"f0_5\": 0.9689069271514068, \"p4\": 0.9594980083560358, \"phi\": 0.9244240020358744}, {\"truth_threshold\": 17.35942024623365, \"match_probability\": 0.999994053092056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5633.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 905.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8615784645080566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13842153549194336, \"precision\": 1.0, \"recall\": 0.8615784645080566, \"specificity\": 1.0, \"npv\": 0.9916685223579407, \"accuracy\": 0.9920792579650879, \"f1\": 0.9256429216991209, \"f2\": 0.8861098002202297, \"f0_5\": 0.9688682490540076, \"p4\": 0.9594484591729578, \"phi\": 0.9243377145084616}, {\"truth_threshold\": 17.38918755301634, \"match_probability\": 0.9999941745374276, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5632.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 906.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.861425518989563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.138574481010437, \"precision\": 1.0, \"recall\": 0.861425518989563, \"specificity\": 1.0, \"npv\": 0.99165940284729, \"accuracy\": 0.9920704960823059, \"f1\": 0.9255546425636811, \"f2\": 0.8859803674804934, \"f0_5\": 0.9688295603110163, \"p4\": 0.9593988982728646, \"phi\": 0.9242514205142457}, {\"truth_threshold\": 17.413038554888633, \"match_probability\": 0.9999942700531858, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5631.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 907.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8612725734710693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13872744143009186, \"precision\": 1.0, \"recall\": 0.8612725734710693, \"specificity\": 1.0, \"npv\": 0.9916502237319946, \"accuracy\": 0.9920617341995239, \"f1\": 0.9254663489193853, \"f2\": 0.885850926595979, \"f0_5\": 0.9687908609180373, \"p4\": 0.959349325651213, \"phi\": 0.9241651200513712}, {\"truth_threshold\": 17.414488991379198, \"match_probability\": 0.9999942758109515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5630.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 908.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8611196279525757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1388803869485855, \"precision\": 1.0, \"recall\": 0.8611196279525757, \"specificity\": 1.0, \"npv\": 0.991641104221344, \"accuracy\": 0.9920530319213867, \"f1\": 0.9253780407626562, \"f2\": 0.8857214775659178, \"f0_5\": 0.9687521508706725, \"p4\": 0.9592997413034571, \"phi\": 0.924078813117982}, {\"truth_threshold\": 17.431154656684562, \"match_probability\": 0.9999943415545709, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5628.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 910.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8608136773109436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.139186292886734, \"precision\": 1.0, \"recall\": 0.8608136773109436, \"specificity\": 1.0, \"npv\": 0.9916228652000427, \"accuracy\": 0.9920355081558228, \"f1\": 0.9252013808975834, \"f2\": 0.8854625550660793, \"f0_5\": 0.9686746987951808, \"p4\": 0.959200537411438, \"phi\": 0.9239061798322304}, {\"truth_threshold\": 17.459314801276395, \"match_probability\": 0.9999944509309228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5627.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 911.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.86066073179245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13933925330638885, \"precision\": 1.0, \"recall\": 0.86066073179245, \"specificity\": 1.0, \"npv\": 0.9916137456893921, \"accuracy\": 0.9920267462730408, \"f1\": 0.9251130291820797, \"f2\": 0.8853330815947639, \"f0_5\": 0.9686359567582455, \"p4\": 0.9591509178580715, \"phi\": 0.9238197559327238}, {\"truth_threshold\": 17.52740904878242, \"match_probability\": 0.9999947067570079, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5626.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 912.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8605077862739563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1394921988248825, \"precision\": 1.0, \"recall\": 0.8605077862739563, \"specificity\": 1.0, \"npv\": 0.9916046261787415, \"accuracy\": 0.9920179843902588, \"f1\": 0.9250246629398224, \"f2\": 0.8852035999748253, \"f0_5\": 0.9685972040493079, \"p4\": 0.9591012865603945, \"phi\": 0.9237334230904773}, {\"truth_threshold\": 17.543381565765724, \"match_probability\": 0.9999947650365985, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5624.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 914.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.860201895236969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.139798104763031, \"precision\": 1.0, \"recall\": 0.860201895236969, \"specificity\": 1.0, \"npv\": 0.9915863275527954, \"accuracy\": 0.9920004606246948, \"f1\": 0.9248478868607137, \"f2\": 0.884944612286002, \"f0_5\": 0.9685196665977819, \"p4\": 0.9590019887138767, \"phi\": 0.9235607379646912}, {\"truth_threshold\": 17.54748172927111, \"match_probability\": 0.9999947798932531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5621.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 917.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.859743058681488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14025695621967316, \"precision\": 1.0, \"recall\": 0.859743058681488, \"specificity\": 1.0, \"npv\": 0.9915589690208435, \"accuracy\": 0.9919742345809937, \"f1\": 0.9245826137017847, \"f2\": 0.8845560696188588, \"f0_5\": 0.9684032802701399, \"p4\": 0.9588529537477574, \"phi\": 0.9233016616448494}, {\"truth_threshold\": 17.606382831885682, \"match_probability\": 0.999994988722228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5620.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 918.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8595901131629944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.140409916639328, \"precision\": 1.0, \"recall\": 0.8595901131629944, \"specificity\": 1.0, \"npv\": 0.9915498495101929, \"accuracy\": 0.9919654726982117, \"f1\": 0.924494160223721, \"f2\": 0.8844265390910235, \"f0_5\": 0.9683644634364877, \"p4\": 0.9588032518884279, \"phi\": 0.9232152898958049}, {\"truth_threshold\": 17.606456656836563, \"match_probability\": 0.999994988978655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5619.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 919.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.859437108039856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14056286215782166, \"precision\": 1.0, \"recall\": 0.859437108039856, \"specificity\": 1.0, \"npv\": 0.9915407299995422, \"accuracy\": 0.9919567108154297, \"f1\": 0.9244056921937978, \"f2\": 0.8842970004091781, \"f0_5\": 0.9683256358999104, \"p4\": 0.958753538252836, \"phi\": 0.9231289116557699}, {\"truth_threshold\": 17.62287516179562, \"match_probability\": 0.9999950456827317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5618.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 920.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8592841625213623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1407158225774765, \"precision\": 1.0, \"recall\": 0.8592841625213623, \"specificity\": 1.0, \"npv\": 0.9915316104888916, \"accuracy\": 0.9919479489326477, \"f1\": 0.9243172096084238, \"f2\": 0.8841674535725528, \"f0_5\": 0.9682867976559807, \"p4\": 0.9587038128364079, \"phi\": 0.9230424293053943}, {\"truth_threshold\": 17.6397762462929, \"match_probability\": 0.999995103383333, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5617.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 921.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8591312170028687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14086876809597015, \"precision\": 1.0, \"recall\": 0.8591312170028687, \"specificity\": 1.0, \"npv\": 0.9915224313735962, \"accuracy\": 0.9919392466545105, \"f1\": 0.9242287124640066, \"f2\": 0.8840378985803771, \"f0_5\": 0.9682479487002689, \"p4\": 0.9586540756345673, \"phi\": 0.9229560380695396}, {\"truth_threshold\": 17.64828853437861, \"match_probability\": 0.9999951321894798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5616.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 922.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.858978271484375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1410217136144638, \"precision\": 1.0, \"recall\": 0.858978271484375, \"specificity\": 1.0, \"npv\": 0.9915133118629456, \"accuracy\": 0.9919304847717285, \"f1\": 0.9241402007569525, \"f2\": 0.8839083354318812, \"f0_5\": 0.9682090890283429, \"p4\": 0.9586043266427354, \"phi\": 0.9228696403370915}, {\"truth_threshold\": 17.64873602971832, \"match_probability\": 0.9999951336991364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5614.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 924.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8586723804473877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1413276195526123, \"precision\": 1.0, \"recall\": 0.8586723804473877, \"specificity\": 1.0, \"npv\": 0.9914950728416443, \"accuracy\": 0.9919129610061646, \"f1\": 0.923963133640553, \"f2\": 0.883649184662847, \"f0_5\": 0.9681313375181072, \"p4\": 0.9585047932707713, \"phi\": 0.9226968253749386}, {\"truth_threshold\": 17.669357572908304, \"match_probability\": 0.9999952027618028, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5613.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 925.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.858519434928894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14148057997226715, \"precision\": 1.0, \"recall\": 0.858519434928894, \"specificity\": 1.0, \"npv\": 0.9914859533309937, \"accuracy\": 0.9919041991233826, \"f1\": 0.9238745782240145, \"f2\": 0.8835195970407681, \"f0_5\": 0.968092445670921, \"p4\": 0.9584550088814698, \"phi\": 0.9226104081414941}, {\"truth_threshold\": 17.757777466083557, \"match_probability\": 0.9999954879451876, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5612.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 926.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8583664894104004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1416335254907608, \"precision\": 1.0, \"recall\": 0.8583664894104004, \"specificity\": 1.0, \"npv\": 0.991476833820343, \"accuracy\": 0.9918954372406006, \"f1\": 0.9237860082304526, \"f2\": 0.8833900012592872, \"f0_5\": 0.9680535430897674, \"p4\": 0.9584052126838386, \"phi\": 0.9225239844039761}, {\"truth_threshold\": 17.78793987735653, \"match_probability\": 0.9999955812989832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5611.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 927.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8582135438919067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14178648591041565, \"precision\": 1.0, \"recall\": 0.8582135438919067, \"specificity\": 1.0, \"npv\": 0.9914677143096924, \"accuracy\": 0.9918867349624634, \"f1\": 0.9236974236562681, \"f2\": 0.8832603973176337, \"f0_5\": 0.9680146297702021, \"p4\": 0.9583554046732872, \"phi\": 0.9224375541605128}, {\"truth_threshold\": 17.79873069203983, \"match_probability\": 0.9999956142257616, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5610.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 928.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8580605983734131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1419394314289093, \"precision\": 1.0, \"recall\": 0.8580605983734131, \"specificity\": 1.0, \"npv\": 0.9914585947990417, \"accuracy\": 0.9918779730796814, \"f1\": 0.9236088244978597, \"f2\": 0.8831307852150369, \"f0_5\": 0.9679757057077784, \"p4\": 0.9583055848452225, \"phi\": 0.9223511174092309}, {\"truth_threshold\": 17.807500184328042, \"match_probability\": 0.9999956408039281, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5609.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 929.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8579075932502747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14209237694740295, \"precision\": 1.0, \"recall\": 0.8579075932502747, \"specificity\": 1.0, \"npv\": 0.9914494752883911, \"accuracy\": 0.9918692111968994, \"f1\": 0.9235202107516259, \"f2\": 0.8830011649507258, \"f0_5\": 0.9679367708980465, \"p4\": 0.9582557531950494, \"phi\": 0.9222645764565336}, {\"truth_threshold\": 17.826221470386653, \"match_probability\": 0.9999956970058139, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5607.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 931.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8576017022132874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14239828288555145, \"precision\": 1.0, \"recall\": 0.8576017022132874, \"specificity\": 1.0, \"npv\": 0.9914311766624451, \"accuracy\": 0.9918516874313354, \"f1\": 0.923342939481268, \"f2\": 0.882741899933877, \"f0_5\": 0.9678588690188497, \"p4\": 0.9581560544099847, \"phi\": 0.9220916703814881}, {\"truth_threshold\": 17.870426804043216, \"match_probability\": 0.9999958268529886, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5606.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 932.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8574487566947937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1425512433052063, \"precision\": 1.0, \"recall\": 0.8574487566947937, \"specificity\": 1.0, \"npv\": 0.9914220571517944, \"accuracy\": 0.9918429255485535, \"f1\": 0.9232542819499341, \"f2\": 0.8826122551797972, \"f0_5\": 0.9678199019404737, \"p4\": 0.9581061872658907, \"phi\": 0.9220052075719227}, {\"truth_threshold\": 17.87968586353728, \"match_probability\": 0.9999958535499195, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5605.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 933.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8572958111763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14270418882369995, \"precision\": 1.0, \"recall\": 0.8572958111763, \"specificity\": 1.0, \"npv\": 0.9914129376411438, \"accuracy\": 0.9918342232704163, \"f1\": 0.9231656098163551, \"f2\": 0.8824826022609189, \"f0_5\": 0.967780924096968, \"p4\": 0.9580563082812832, \"phi\": 0.9219187382451596}, {\"truth_threshold\": 17.90553748025289, \"match_probability\": 0.9999959271880231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5604.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 934.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8571428656578064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1428571492433548, \"precision\": 1.0, \"recall\": 0.8571428656578064, \"specificity\": 1.0, \"npv\": 0.9914038181304932, \"accuracy\": 0.9918254613876343, \"f1\": 0.9230769230769231, \"f2\": 0.8823529411764706, \"f0_5\": 0.967741935483871, \"p4\": 0.958006417451555, \"phi\": 0.9218322623993209}, {\"truth_threshold\": 17.909942334600796, \"match_probability\": 0.9999959396041683, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5603.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 935.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8569899201393127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14301009476184845, \"precision\": 1.0, \"recall\": 0.8569899201393127, \"specificity\": 1.0, \"npv\": 0.9913946986198425, \"accuracy\": 0.9918166995048523, \"f1\": 0.922988221728029, \"f2\": 0.882223271925681, \"f0_5\": 0.9677029360967185, \"p4\": 0.9579565147720968, \"phi\": 0.921745780032528}, {\"truth_threshold\": 17.934902463820556, \"match_probability\": 0.9999960092487723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5600.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 938.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.856531023979187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1434689462184906, \"precision\": 1.0, \"recall\": 0.856531023979187, \"specificity\": 1.0, \"npv\": 0.9913673400878906, \"accuracy\": 0.9917904138565063, \"f1\": 0.922722029988466, \"f2\": 0.8818342151675485, \"f0_5\": 0.9675858732462506, \"p4\": 0.9578067355892087, \"phi\": 0.9214861960214777}, {\"truth_threshold\": 17.9364678837545, \"match_probability\": 0.9999960135766368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5595.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 943.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8557662963867188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14423370361328125, \"precision\": 1.0, \"recall\": 0.8557662963867188, \"specificity\": 1.0, \"npv\": 0.9913217425346375, \"accuracy\": 0.9917466640472412, \"f1\": 0.9222780845627627, \"f2\": 0.8811856238384729, \"f0_5\": 0.9673905525969984, \"p4\": 0.9575568661922037, \"phi\": 0.9210535883105287}, {\"truth_threshold\": 17.958071628274737, \"match_probability\": 0.9999960728266672, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5594.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 944.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8556133508682251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1443866640329361, \"precision\": 1.0, \"recall\": 0.8556133508682251, \"specificity\": 1.0, \"npv\": 0.991312563419342, \"accuracy\": 0.9917379021644592, \"f1\": 0.9221892515661062, \"f2\": 0.8810558810558811, \"f0_5\": 0.9673514560420557, \"p4\": 0.9575068566573478, \"phi\": 0.9209670471621715}, {\"truth_threshold\": 17.969849280940462, \"match_probability\": 0.9999961047560905, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5593.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 945.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8554604053497314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14453960955142975, \"precision\": 1.0, \"recall\": 0.8554604053497314, \"specificity\": 1.0, \"npv\": 0.9913034439086914, \"accuracy\": 0.991729199886322, \"f1\": 0.9221004039238315, \"f2\": 0.8809261300992283, \"f0_5\": 0.9673123486682809, \"p4\": 0.9574568352265342, \"phi\": 0.9208804994740237}, {\"truth_threshold\": 18.003507655700773, \"match_probability\": 0.9999961945807059, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5592.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 946.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8553074598312378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1446925699710846, \"precision\": 1.0, \"recall\": 0.8553074598312378, \"specificity\": 1.0, \"npv\": 0.9912943243980408, \"accuracy\": 0.99172043800354, \"f1\": 0.9220115416323166, \"f2\": 0.8807963709677419, \"f0_5\": 0.9672732304711824, \"p4\": 0.9574068018951273, \"phi\": 0.920793945244197}, {\"truth_threshold\": 18.033981249786223, \"match_probability\": 0.9999962741181037, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5590.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 948.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8550015091896057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1449984759092331, \"precision\": 1.0, \"recall\": 0.8550015091896057, \"specificity\": 1.0, \"npv\": 0.9912760853767395, \"accuracy\": 0.9917029142379761, \"f1\": 0.9218337730870713, \"f2\": 0.8805368281771785, \"f0_5\": 0.9671949615890373, \"p4\": 0.9573066995119771, \"phi\": 0.9206207193029006}, {\"truth_threshold\": 18.046515864115527, \"match_probability\": 0.999996306349464, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5587.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 951.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8545426726341248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14545732736587524, \"precision\": 1.0, \"recall\": 0.8545426726341248, \"specificity\": 1.0, \"npv\": 0.9912487268447876, \"accuracy\": 0.9916766881942749, \"f1\": 0.9215670103092783, \"f2\": 0.8801474526607643, \"f0_5\": 0.9670774769784671, \"p4\": 0.9571564565667641, \"phi\": 0.9203609780297752}, {\"truth_threshold\": 18.062714442315226, \"match_probability\": 0.9999963475896606, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5586.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 952.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8543897271156311, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1456102728843689, \"precision\": 1.0, \"recall\": 0.8543897271156311, \"specificity\": 1.0, \"npv\": 0.991239607334137, \"accuracy\": 0.9916679263114929, \"f1\": 0.9214780600461894, \"f2\": 0.8800176444640494, \"f0_5\": 0.9670382937469705, \"p4\": 0.9571063517343069, \"phi\": 0.9202743845018699}, {\"truth_threshold\": 18.063114340042397, \"match_probability\": 0.9999963486019209, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5583.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 955.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8539308905601501, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14606913924217224, \"precision\": 1.0, \"recall\": 0.8539308905601501, \"specificity\": 1.0, \"npv\": 0.9912122488021851, \"accuracy\": 0.991641640663147, \"f1\": 0.9212111211946209, \"f2\": 0.8796281707893493, \"f0_5\": 0.9669206789054382, \"p4\": 0.956955965619638, \"phi\": 0.9200145645810461}, {\"truth_threshold\": 18.06658854460422, \"match_probability\": 0.9999963573843699, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5582.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 956.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8537778854370117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1462220847606659, \"precision\": 1.0, \"recall\": 0.8537778854370117, \"specificity\": 1.0, \"npv\": 0.9912031292915344, \"accuracy\": 0.991632878780365, \"f1\": 0.9211221122112211, \"f2\": 0.8794983298670196, \"f0_5\": 0.9668814522275341, \"p4\": 0.9569058130267905, \"phi\": 0.9199279448220835}, {\"truth_threshold\": 18.142002297354924, \"match_probability\": 0.9999965429025188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5581.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 957.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8536249399185181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14637504518032074, \"precision\": 1.0, \"recall\": 0.8536249399185181, \"specificity\": 1.0, \"npv\": 0.9911940097808838, \"accuracy\": 0.991624116897583, \"f1\": 0.9210330885386583, \"f2\": 0.8793684807613525, \"f0_5\": 0.9668422146767376, \"p4\": 0.9568556484821953, \"phi\": 0.9198412205767548}, {\"truth_threshold\": 18.147896187154753, \"match_probability\": 0.9999965569970549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5579.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 959.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8533190488815308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14668093621730804, \"precision\": 1.0, \"recall\": 0.8533190488815308, \"specificity\": 1.0, \"npv\": 0.9911757707595825, \"accuracy\": 0.9916066527366638, \"f1\": 0.9208549971114962, \"f2\": 0.8791087579969116, \"f0_5\": 0.9667637069383794, \"p4\": 0.9567552835191, \"phi\": 0.9196679482220577}, {\"truth_threshold\": 18.152005978341826, \"match_probability\": 0.9999965667911132, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5578.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 960.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8531661033630371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1468338966369629, \"precision\": 1.0, \"recall\": 0.8531661033630371, \"specificity\": 1.0, \"npv\": 0.9911666512489319, \"accuracy\": 0.9915978908538818, \"f1\": 0.9207659293496203, \"f2\": 0.87897888433659, \"f0_5\": 0.9667244367417678, \"p4\": 0.9567050830912629, \"phi\": 0.9195813021933509}, {\"truth_threshold\": 18.187543720308078, \"match_probability\": 0.9999966503275758, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5576.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 962.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8528602123260498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1471398025751114, \"precision\": 1.0, \"recall\": 0.8528602123260498, \"specificity\": 1.0, \"npv\": 0.9911484122276306, \"accuracy\": 0.9915803670883179, \"f1\": 0.920587749711078, \"f2\": 0.878719112455875, \"f0_5\": 0.9666458636710353, \"p4\": 0.9566046463196489, \"phi\": 0.9194079904237175}, {\"truth_threshold\": 18.22321586263534, \"match_probability\": 0.9999967321358898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5574.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 964.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8525543212890625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1474457085132599, \"precision\": 1.0, \"recall\": 0.8525543212890625, \"specificity\": 1.0, \"npv\": 0.9911301732063293, \"accuracy\": 0.9915629029273987, \"f1\": 0.9204095112285336, \"f2\": 0.8784593078232364, \"f0_5\": 0.9665672470000694, \"p4\": 0.9565041616289393, \"phi\": 0.9192346523584414}, {\"truth_threshold\": 18.227530116870383, \"match_probability\": 0.9999967418935249, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5573.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 965.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8524013757705688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14759865403175354, \"precision\": 1.0, \"recall\": 0.8524013757705688, \"specificity\": 1.0, \"npv\": 0.9911210536956787, \"accuracy\": 0.9915541410446167, \"f1\": 0.9203203699116506, \"f2\": 0.8783293932230103, \"f0_5\": 0.9665279223031564, \"p4\": 0.9564539013022235, \"phi\": 0.9191479734601784}, {\"truth_threshold\": 18.22964227850548, \"match_probability\": 0.9999967466600139, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5572.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 966.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8522483706474304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1477515995502472, \"precision\": 1.0, \"recall\": 0.8522483706474304, \"specificity\": 1.0, \"npv\": 0.9911119341850281, \"accuracy\": 0.9915453791618347, \"f1\": 0.9202312138728324, \"f2\": 0.8781994704324801, \"f0_5\": 0.9664885866925692, \"p4\": 0.956403628981689, \"phi\": 0.9190611899834376}, {\"truth_threshold\": 18.23695706163869, \"match_probability\": 0.9999967631133679, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5569.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 969.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8517895340919495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14821046590805054, \"precision\": 1.0, \"recall\": 0.8517895340919495, \"specificity\": 1.0, \"npv\": 0.9910845756530762, \"accuracy\": 0.9915190935134888, \"f1\": 0.9199636573882878, \"f2\": 0.8778096529113206, \"f0_5\": 0.9663705143333102, \"p4\": 0.956252740010292, \"phi\": 0.9188010940279364}, {\"truth_threshold\": 18.297796775521153, \"match_probability\": 0.9999968967771226, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5566.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 972.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8513306975364685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1486693173646927, \"precision\": 1.0, \"recall\": 0.8513306975364685, \"specificity\": 1.0, \"npv\": 0.9910572171211243, \"accuracy\": 0.9914928674697876, \"f1\": 0.9196959682749505, \"f2\": 0.8774197616495365, \"f0_5\": 0.9662523435872509, \"p4\": 0.9561017429256564, \"phi\": 0.9185409387871394}, {\"truth_threshold\": 18.300758141600078, \"match_probability\": 0.9999969031404391, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5565.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 973.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8511777520179749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14882226288318634, \"precision\": 1.0, \"recall\": 0.8511777520179749, \"specificity\": 1.0, \"npv\": 0.9910480976104736, \"accuracy\": 0.9914841055870056, \"f1\": 0.9196067090803933, \"f2\": 0.8772897815051864, \"f0_5\": 0.9662129314535731, \"p4\": 0.9560513865170244, \"phi\": 0.9184542071901173}, {\"truth_threshold\": 18.327486656987034, \"match_probability\": 0.9999969599869295, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5564.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 974.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8510248064994812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1489752233028412, \"precision\": 1.0, \"recall\": 0.8510248064994812, \"specificity\": 1.0, \"npv\": 0.991038978099823, \"accuracy\": 0.9914753437042236, \"f1\": 0.9195174351346885, \"f2\": 0.8771597931643335, \"f0_5\": 0.9661735083697993, \"p4\": 0.9560010180770111, \"phi\": 0.9183674689981981}, {\"truth_threshold\": 18.33482750646612, \"match_probability\": 0.9999969754160609, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5561.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 977.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8505659103393555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14943407475948334, \"precision\": 1.0, \"recall\": 0.8505659103393555, \"specificity\": 1.0, \"npv\": 0.9910116195678711, \"accuracy\": 0.9914491176605225, \"f1\": 0.9192495247541119, \"f2\": 0.8767697789550026, \"f0_5\": 0.9660551733722466, \"p4\": 0.9558498405216099, \"phi\": 0.9181071167431559}, {\"truth_threshold\": 18.343280736546138, \"match_probability\": 0.9999969930862327, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5560.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 978.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8504129648208618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14958703517913818, \"precision\": 1.0, \"recall\": 0.8504129648208618, \"specificity\": 1.0, \"npv\": 0.9910025000572205, \"accuracy\": 0.9914403557777405, \"f1\": 0.9191601917672343, \"f2\": 0.8766397578203835, \"f0_5\": 0.9660157064424213, \"p4\": 0.9557994239089851, \"phi\": 0.9180203521441406}, {\"truth_threshold\": 18.348690862199586, \"match_probability\": 0.9999970043410495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5559.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 979.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8502600193023682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14973998069763184, \"precision\": 1.0, \"recall\": 0.8502600193023682, \"specificity\": 1.0, \"npv\": 0.9909933805465698, \"accuracy\": 0.9914315938949585, \"f1\": 0.9190708440109118, \"f2\": 0.8765097284853837, \"f0_5\": 0.9659762285396538, \"p4\": 0.9557489952414233, \"phi\": 0.9179335809406524}, {\"truth_threshold\": 18.3488602150466, \"match_probability\": 0.9999970046926776, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5557.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 981.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8499541282653809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15004588663578033, \"precision\": 1.0, \"recall\": 0.8499541282653809, \"specificity\": 1.0, \"npv\": 0.9909751415252686, \"accuracy\": 0.9914140701293945, \"f1\": 0.918892104175279, \"f2\": 0.8762496452111388, \"f0_5\": 0.9658972397969825, \"p4\": 0.9556481017226119, \"phi\": 0.9177600187125886}, {\"truth_threshold\": 18.352763893503834, \"match_probability\": 0.9999970127864719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5556.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 982.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8498011827468872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.150198832154274, \"precision\": 1.0, \"recall\": 0.8498011827468872, \"specificity\": 1.0, \"npv\": 0.9909660220146179, \"accuracy\": 0.9914053678512573, \"f1\": 0.918802712088639, \"f2\": 0.8761195912703419, \"f0_5\": 0.9658577289479174, \"p4\": 0.9555976368619181, \"phi\": 0.9176732276841758}, {\"truth_threshold\": 18.3549411346692, \"match_probability\": 0.9999970172912075, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5554.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 984.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8494952321052551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15050473809242249, \"precision\": 1.0, \"recall\": 0.8494952321052551, \"specificity\": 1.0, \"npv\": 0.9909477829933167, \"accuracy\": 0.9913878440856934, \"f1\": 0.9186238835593781, \"f2\": 0.8758594587775185, \"f0_5\": 0.9657786742714057, \"p4\": 0.9554966709143242, \"phi\": 0.9174995276395884}, {\"truth_threshold\": 18.35845685580925, \"match_probability\": 0.9999970245509361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5552.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 986.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8491893410682678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15081064403057098, \"precision\": 1.0, \"recall\": 0.8491893410682678, \"specificity\": 1.0, \"npv\": 0.9909296035766602, \"accuracy\": 0.9913703203201294, \"f1\": 0.9184449958643507, \"f2\": 0.875599293464547, \"f0_5\": 0.965699575593126, \"p4\": 0.9553956566335873, \"phi\": 0.9173258992636734}, {\"truth_threshold\": 18.358681067496978, \"match_probability\": 0.9999970250133183, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5551.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 987.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8490363955497742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15096360445022583, \"precision\": 1.0, \"recall\": 0.8490363955497742, \"specificity\": 1.0, \"npv\": 0.9909204840660095, \"accuracy\": 0.9913615584373474, \"f1\": 0.918355529820498, \"f2\": 0.8754691984985649, \"f0_5\": 0.9656600097418412, \"p4\": 0.9553451313564554, \"phi\": 0.9172390751469223}, {\"truth_threshold\": 18.364129851478552, \"match_probability\": 0.999997036228051, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5549.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 989.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8487305045127869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15126949548721313, \"precision\": 1.0, \"recall\": 0.8487305045127869, \"specificity\": 1.0, \"npv\": 0.9909022450447083, \"accuracy\": 0.9913440942764282, \"f1\": 0.9181765533217506, \"f2\": 0.8752089839437242, \"f0_5\": 0.9655808449919956, \"p4\": 0.9552440445049736, \"phi\": 0.9170654070462125}, {\"truth_threshold\": 18.37162191916744, \"match_probability\": 0.9999970515792915, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5548.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 990.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8485775589942932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15142245590686798, \"precision\": 1.0, \"recall\": 0.8485775589942932, \"specificity\": 1.0, \"npv\": 0.9908931255340576, \"accuracy\": 0.9913353323936462, \"f1\": 0.9180870428595068, \"f2\": 0.8750788643533123, \"f0_5\": 0.9655412460842325, \"p4\": 0.9551934829211397, \"phi\": 0.9169785630584031}, {\"truth_threshold\": 18.375574156350535, \"match_probability\": 0.9999970596453599, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5547.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 991.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8484246134757996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15157540142536163, \"precision\": 1.0, \"recall\": 0.8484246134757996, \"specificity\": 1.0, \"npv\": 0.990884006023407, \"accuracy\": 0.9913265705108643, \"f1\": 0.9179975175837816, \"f2\": 0.8749487365532036, \"f0_5\": 0.965501636148437, \"p4\": 0.9551429092255838, \"phi\": 0.9168917124430551}, {\"truth_threshold\": 18.391336987150666, \"match_probability\": 0.9999970915966019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5546.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 992.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8482716679573059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15172836184501648, \"precision\": 1.0, \"recall\": 0.8482716679573059, \"specificity\": 1.0, \"npv\": 0.9908748865127563, \"accuracy\": 0.9913178086280823, \"f1\": 0.917907977490897, \"f2\": 0.874818600542621, \"f0_5\": 0.9654620151800014, \"p4\": 0.9550923234135577, \"phi\": 0.9168048551982408}, {\"truth_threshold\": 18.393008684991283, \"match_probability\": 0.9999970949647022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5544.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 994.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8479657173156738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15203426778316498, \"precision\": 1.0, \"recall\": 0.8479657173156738, \"specificity\": 1.0, \"npv\": 0.9908566474914551, \"accuracy\": 0.9913002848625183, \"f1\": 0.9177288528389339, \"f2\": 0.8745583038869258, \"f0_5\": 0.9653827401267674, \"p4\": 0.95499111542109, \"phi\": 0.9166310225791374}, {\"truth_threshold\": 18.425300889625074, \"match_probability\": 0.9999971592663263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5543.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 995.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8478127717971802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15218721330165863, \"precision\": 1.0, \"recall\": 0.8478127717971802, \"specificity\": 1.0, \"npv\": 0.9908475279808044, \"accuracy\": 0.9912915825843811, \"f1\": 0.917639268272494, \"f2\": 0.8744281432402587, \"f0_5\": 0.9653430860327412, \"p4\": 0.9549404932311399, \"phi\": 0.9165441454259419}, {\"truth_threshold\": 18.427418715777115, \"match_probability\": 0.9999971634333534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5542.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 996.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8476598262786865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15234015882015228, \"precision\": 1.0, \"recall\": 0.8476598262786865, \"specificity\": 1.0, \"npv\": 0.9908384084701538, \"accuracy\": 0.9912828207015991, \"f1\": 0.9175496688741722, \"f2\": 0.8742979743800088, \"f0_5\": 0.9653034208876193, \"p4\": 0.9548898589057022, \"phi\": 0.9164572616355585}, {\"truth_threshold\": 18.448217817748432, \"match_probability\": 0.9999972040341923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5541.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 997.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8475068807601929, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15249311923980713, \"precision\": 1.0, \"recall\": 0.8475068807601929, \"specificity\": 1.0, \"npv\": 0.9908292889595032, \"accuracy\": 0.9912740588188171, \"f1\": 0.9174600546402848, \"f2\": 0.8741677973053986, \"f0_5\": 0.9652637446867814, \"p4\": 0.9548392124400166, \"phi\": 0.9163703712060557}, {\"truth_threshold\": 18.466884943602203, \"match_probability\": 0.9999972399782351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5538.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1000.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8470480442047119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15295197069644928, \"precision\": 1.0, \"recall\": 0.8470480442047119, \"specificity\": 1.0, \"npv\": 0.990801990032196, \"accuracy\": 0.9912477731704712, \"f1\": 0.9171911228883737, \"f2\": 0.8737772167876302, \"f0_5\": 0.9651446497037295, \"p4\": 0.9546872001538285, \"phi\": 0.9161096600634963}, {\"truth_threshold\": 18.471963746241226, \"match_probability\": 0.99999724967739, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5537.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1001.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8468950986862183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15310493111610413, \"precision\": 1.0, \"recall\": 0.8468950986862183, \"specificity\": 1.0, \"npv\": 0.9907928705215454, \"accuracy\": 0.991239070892334, \"f1\": 0.9171014492753623, \"f2\": 0.873647006847802, \"f0_5\": 0.9651049292337726, \"p4\": 0.9546365050794955, \"phi\": 0.9160227430581774}, {\"truth_threshold\": 18.500639731970818, \"match_probability\": 0.9999973038048027, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5536.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1002.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8467420935630798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15325787663459778, \"precision\": 1.0, \"recall\": 0.8467420935630798, \"specificity\": 1.0, \"npv\": 0.9907837510108948, \"accuracy\": 0.991230309009552, \"f1\": 0.9170117608083486, \"f2\": 0.8735167886897248, \"f0_5\": 0.9650651976849592, \"p4\": 0.9545857978410746, \"phi\": 0.9159358194040659}, {\"truth_threshold\": 18.502616214457454, \"match_probability\": 0.9999973074960329, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5533.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1005.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8462832570075989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15371672809123993, \"precision\": 1.0, \"recall\": 0.8462832570075989, \"specificity\": 1.0, \"npv\": 0.9907563924789429, \"accuracy\": 0.991204023361206, \"f1\": 0.9167426062463756, \"f2\": 0.8731260848982169, \"f0_5\": 0.9649459365190094, \"p4\": 0.9544336030935161, \"phi\": 0.9156749102036116}, {\"truth_threshold\": 18.51291137843169, \"match_probability\": 0.9999973266414691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5531.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1007.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8459773659706116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15402263402938843, \"precision\": 1.0, \"recall\": 0.8459773659706116, \"specificity\": 1.0, \"npv\": 0.9907382130622864, \"accuracy\": 0.9911865592002869, \"f1\": 0.9165630955340127, \"f2\": 0.872865574598365, \"f0_5\": 0.9648663735957016, \"p4\": 0.95433207902042, \"phi\": 0.9155010029909255}, {\"truth_threshold\": 18.515621735364814, \"match_probability\": 0.9999973316591162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5530.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1008.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8458244204521179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15417559444904327, \"precision\": 1.0, \"recall\": 0.8458244204521179, \"specificity\": 1.0, \"npv\": 0.9907290935516357, \"accuracy\": 0.9911777973175049, \"f1\": 0.9164733178654292, \"f2\": 0.8727353071144498, \"f0_5\": 0.9648265754763068, \"p4\": 0.9542812986970985, \"phi\": 0.9154140393949057}, {\"truth_threshold\": 18.549458211757745, \"match_probability\": 0.9999973935131214, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5528.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1010.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8455185294151306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15448148548603058, \"precision\": 1.0, \"recall\": 0.8455185294151306, \"specificity\": 1.0, \"npv\": 0.9907108545303345, \"accuracy\": 0.9911602735519409, \"f1\": 0.916293717884966, \"f2\": 0.8724747474747475, \"f0_5\": 0.9647469458987784, \"p4\": 0.9541797014529563, \"phi\": 0.9152400922137999}, {\"truth_threshold\": 18.549772908972596, \"match_probability\": 0.9999973940816148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5527.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1011.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.845365583896637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15463444590568542, \"precision\": 1.0, \"recall\": 0.845365583896637, \"specificity\": 1.0, \"npv\": 0.9907017350196838, \"accuracy\": 0.9911515116691589, \"f1\": 0.9162038955656858, \"f2\": 0.8723444553174027, \"f0_5\": 0.9647071144313342, \"p4\": 0.954128884522547, \"phi\": 0.9151531086248262}, {\"truth_threshold\": 18.554811781661616, \"match_probability\": 0.9999974031673552, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5523.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1015.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8447537422180176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15524625778198242, \"precision\": 1.0, \"recall\": 0.8447537422180176, \"specificity\": 1.0, \"npv\": 0.9906653165817261, \"accuracy\": 0.9911165237426758, \"f1\": 0.9158444573418456, \"f2\": 0.8718232044198895, \"f0_5\": 0.9645476772616137, \"p4\": 0.9539254946333401, \"phi\": 0.9148050091569588}, {\"truth_threshold\": 18.55911255445865, \"match_probability\": 0.999997410897144, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5522.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1016.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8446007966995239, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15539920330047607, \"precision\": 1.0, \"recall\": 0.8446007966995239, \"specificity\": 1.0, \"npv\": 0.9906561970710754, \"accuracy\": 0.9911077618598938, \"f1\": 0.9157545605306799, \"f2\": 0.8716928711245817, \"f0_5\": 0.9645077901208692, \"p4\": 0.9538746165951246, \"phi\": 0.914717992199022}, {\"truth_threshold\": 18.568015316687994, \"match_probability\": 0.9999974268250658, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5519.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1019.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.844141960144043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15585805475711823, \"precision\": 1.0, \"recall\": 0.844141960144043, \"specificity\": 1.0, \"npv\": 0.9906288385391235, \"accuracy\": 0.9910815358161926, \"f1\": 0.9154847806253629, \"f2\": 0.8713018218559565, \"f0_5\": 0.964388061787936, \"p4\": 0.9537219090453266, \"phi\": 0.9144569012497168}, {\"truth_threshold\": 18.570059804691017, \"match_probability\": 0.999997430469, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5518.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1020.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8439890146255493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15601101517677307, \"precision\": 1.0, \"recall\": 0.8439890146255493, \"specificity\": 1.0, \"npv\": 0.9906197190284729, \"accuracy\": 0.9910727739334106, \"f1\": 0.9153948241539482, \"f2\": 0.8711714556362489, \"f0_5\": 0.964348130024467, \"p4\": 0.9536709820342915, \"phi\": 0.9143698575682788}, {\"truth_threshold\": 18.573320449573988, \"match_probability\": 0.9999974362698419, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5517.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1021.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8438360095024109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15616396069526672, \"precision\": 1.0, \"recall\": 0.8438360095024109, \"specificity\": 1.0, \"npv\": 0.990610659122467, \"accuracy\": 0.9910640120506287, \"f1\": 0.9153048527581916, \"f2\": 0.8710410811834918, \"f0_5\": 0.9643081870936168, \"p4\": 0.953620042768006, \"phi\": 0.914282708739867}, {\"truth_threshold\": 18.57896419295237, \"match_probability\": 0.999997446279396, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5515.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1023.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8435301184654236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15646986663341522, \"precision\": 1.0, \"recall\": 0.8435301184654236, \"specificity\": 1.0, \"npv\": 0.9905924201011658, \"accuracy\": 0.9910464882850647, \"f1\": 0.9151248651787937, \"f2\": 0.8707803075757097, \"f0_5\": 0.9642282677110288, \"p4\": 0.9535181274503896, \"phi\": 0.914108587923448}, {\"truth_threshold\": 18.593610800530456, \"match_probability\": 0.9999974720741933, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5514.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1024.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8433771729469299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15662282705307007, \"precision\": 1.0, \"recall\": 0.8433771729469299, \"specificity\": 1.0, \"npv\": 0.9905833005905151, \"accuracy\": 0.9910377264022827, \"f1\": 0.9150348489877199, \"f2\": 0.8706499084191246, \"f0_5\": 0.9641882912499126, \"p4\": 0.9534671513894046, \"phi\": 0.9140215174787817}, {\"truth_threshold\": 18.595943841318658, \"match_probability\": 0.9999974761588909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5513.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1025.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8432242274284363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15677577257156372, \"precision\": 1.0, \"recall\": 0.8432242274284363, \"specificity\": 1.0, \"npv\": 0.9905741810798645, \"accuracy\": 0.9910290241241455, \"f1\": 0.9149448178574392, \"f2\": 0.8705195010263698, \"f0_5\": 0.9641483036026582, \"p4\": 0.9534161630538617, \"phi\": 0.9139344403405356}, {\"truth_threshold\": 18.612400904640605, \"match_probability\": 0.9999975047851137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5512.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1026.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8430712819099426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15692871809005737, \"precision\": 1.0, \"recall\": 0.8430712819099426, \"specificity\": 1.0, \"npv\": 0.9905650615692139, \"accuracy\": 0.9910202622413635, \"f1\": 0.9148547717842324, \"f2\": 0.8703890853966649, \"f0_5\": 0.9641083047645701, \"p4\": 0.9533651624389274, \"phi\": 0.913847356506752}, {\"truth_threshold\": 18.62589979671772, \"match_probability\": 0.9999975280231949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5511.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1027.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.842918336391449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15708167850971222, \"precision\": 1.0, \"recall\": 0.842918336391449, \"specificity\": 1.0, \"npv\": 0.990556001663208, \"accuracy\": 0.9910115003585815, \"f1\": 0.9147647107643788, \"f2\": 0.8702586615292297, \"f0_5\": 0.9640682947309496, \"p4\": 0.9533141495397662, \"phi\": 0.9137602659754724}, {\"truth_threshold\": 18.676869229556562, \"match_probability\": 0.9999976138315425, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5510.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1028.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8427653908729553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15723462402820587, \"precision\": 1.0, \"recall\": 0.8427653908729553, \"specificity\": 1.0, \"npv\": 0.9905468821525574, \"accuracy\": 0.9910027384757996, \"f1\": 0.9146746347941567, \"f2\": 0.8701282294232834, \"f0_5\": 0.9640282734970956, \"p4\": 0.9532631243515396, \"phi\": 0.9136731687447376}, {\"truth_threshold\": 18.688298124321776, \"match_probability\": 0.999997632659824, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5509.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1029.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8426124453544617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15738758444786072, \"precision\": 1.0, \"recall\": 0.8426124453544617, \"specificity\": 1.0, \"npv\": 0.9905377626419067, \"accuracy\": 0.9909939765930176, \"f1\": 0.9145845438698431, \"f2\": 0.8699977890780456, \"f0_5\": 0.9639882410583047, \"p4\": 0.9532120868694068, \"phi\": 0.9135860648125872}, {\"truth_threshold\": 18.701448199477362, \"match_probability\": 0.9999976541398877, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5504.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1034.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8418476581573486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15815234184265137, \"precision\": 1.0, \"recall\": 0.8418476581573486, \"specificity\": 1.0, \"npv\": 0.9904922246932983, \"accuracy\": 0.9909502267837524, \"f1\": 0.9141338648065106, \"f2\": 0.8693454637351529, \"f0_5\": 0.9637879106254815, \"p4\": 0.9529567148805409, \"phi\": 0.9131503459903917}, {\"truth_threshold\": 18.72228544566445, \"match_probability\": 0.9999976877782116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5500.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1038.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.841235876083374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15876415371894836, \"precision\": 1.0, \"recall\": 0.841235876083374, \"specificity\": 1.0, \"npv\": 0.9904558062553406, \"accuracy\": 0.9909152388572693, \"f1\": 0.9137730520019937, \"f2\": 0.868823455073929, \"f0_5\": 0.9636274441096082, \"p4\": 0.9527521955044298, \"phi\": 0.9128017289300793}, {\"truth_threshold\": 18.736718586358464, \"match_probability\": 0.9999977107949726, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5499.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1039.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8410828709602356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15891709923744202, \"precision\": 1.0, \"recall\": 0.8410828709602356, \"specificity\": 1.0, \"npv\": 0.9904466867446899, \"accuracy\": 0.9909064769744873, \"f1\": 0.9136828113317271, \"f2\": 0.8686929322928185, \"f0_5\": 0.9635872993621645, \"p4\": 0.9527010348164278, \"phi\": 0.9127144592531756}, {\"truth_threshold\": 18.736963086208647, \"match_probability\": 0.9999977111829005, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5498.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1040.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8409299254417419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15907004475593567, \"precision\": 1.0, \"recall\": 0.8409299254417419, \"specificity\": 1.0, \"npv\": 0.9904375672340393, \"accuracy\": 0.9908977150917053, \"f1\": 0.9135925556663343, \"f2\": 0.8685624012638231, \"f0_5\": 0.963547143357869, \"p4\": 0.952649861781102, \"phi\": 0.9126272814587897}, {\"truth_threshold\": 18.74077125030007, \"match_probability\": 0.9999977172165232, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5497.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1041.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8407769799232483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15922300517559052, \"precision\": 1.0, \"recall\": 0.8407769799232483, \"specificity\": 1.0, \"npv\": 0.9904284477233887, \"accuracy\": 0.9908889532089233, \"f1\": 0.9135022850020773, \"f2\": 0.8684318619861607, \"f0_5\": 0.9635069760919862, \"p4\": 0.9525986763935813, \"phi\": 0.9125400969393901}, {\"truth_threshold\": 18.757600263808833, \"match_probability\": 0.9999977436903854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5496.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1042.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8406240344047546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15937595069408417, \"precision\": 1.0, \"recall\": 0.8406240344047546, \"specificity\": 1.0, \"npv\": 0.9904193878173828, \"accuracy\": 0.9908801913261414, \"f1\": 0.9134119993352169, \"f2\": 0.8683013144590496, \"f0_5\": 0.9634667975597784, \"p4\": 0.9525474786489915, \"phi\": 0.9124529056930049}, {\"truth_threshold\": 18.761756792957193, \"match_probability\": 0.9999977501816385, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5494.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1044.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8403181433677673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15968185663223267, \"precision\": 1.0, \"recall\": 0.8403181433677673, \"specificity\": 1.0, \"npv\": 0.9904011487960815, \"accuracy\": 0.9908627271652222, \"f1\": 0.9132313829787234, \"f2\": 0.8680401946533527, \"f0_5\": 0.9633864066774216, \"p4\": 0.9524450460690959, \"phi\": 0.9122785030113855}, {\"truth_threshold\": 18.777049835071193, \"match_probability\": 0.9999977739044433, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5492.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1046.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.84001225233078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15998776257038116, \"precision\": 1.0, \"recall\": 0.84001225233078, \"specificity\": 1.0, \"npv\": 0.9903829097747803, \"accuracy\": 0.9908452033996582, \"f1\": 0.913050706566916, \"f2\": 0.8677790418404753, \"f0_5\": 0.9633059706728408, \"p4\": 0.9523425640023722, \"phi\": 0.9121040733981377}, {\"truth_threshold\": 18.791240786161126, \"match_probability\": 0.9999977956938603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5490.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1048.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8397063612937927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16029366850852966, \"precision\": 1.0, \"recall\": 0.8397063612937927, \"specificity\": 1.0, \"npv\": 0.9903647303581238, \"accuracy\": 0.9908276796340942, \"f1\": 0.9128699700698371, \"f2\": 0.8675178560141584, \"f0_5\": 0.9632254895080357, \"p4\": 0.9522400324097363, \"phi\": 0.9119295181466666}, {\"truth_threshold\": 18.793546614575014, \"match_probability\": 0.9999977992141337, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5487.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1051.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.839247465133667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16075251996517181, \"precision\": 1.0, \"recall\": 0.839247465133667, \"specificity\": 1.0, \"npv\": 0.9903374314308167, \"accuracy\": 0.9908014535903931, \"f1\": 0.9125987525987526, \"f2\": 0.8671260153607889, \"f0_5\": 0.9631046830021766, \"p4\": 0.9520861420740994, \"phi\": 0.9116677827189672}, {\"truth_threshold\": 18.799972883734448, \"match_probability\": 0.9999978089953827, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5486.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1052.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8390945196151733, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16090548038482666, \"precision\": 1.0, \"recall\": 0.8390945196151733, \"specificity\": 1.0, \"npv\": 0.990328311920166, \"accuracy\": 0.9907926917076111, \"f1\": 0.9125083166999335, \"f2\": 0.8669953852961628, \"f0_5\": 0.9630643915455376, \"p4\": 0.9520348204901858, \"phi\": 0.9115805240855277}, {\"truth_threshold\": 18.811853695662595, \"match_probability\": 0.9999978269645072, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5485.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1053.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8389415740966797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1610584259033203, \"precision\": 1.0, \"recall\": 0.8389415740966797, \"specificity\": 1.0, \"npv\": 0.9903191924095154, \"accuracy\": 0.9907839298248291, \"f1\": 0.9124178657572986, \"f2\": 0.8668647469734804, \"f0_5\": 0.9630240887702788, \"p4\": 0.9519834864954201, \"phi\": 0.9114932587033491}, {\"truth_threshold\": 18.81350424342518, \"match_probability\": 0.9999978294491905, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5484.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1054.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.838788628578186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16121138632297516, \"precision\": 1.0, \"recall\": 0.838788628578186, \"specificity\": 1.0, \"npv\": 0.9903100728988647, \"accuracy\": 0.9907751679420471, \"f1\": 0.9123273997670936, \"f2\": 0.8667341003919585, \"f0_5\": 0.9629837746716302, \"p4\": 0.9519321400848973, \"phi\": 0.9114059865704486}, {\"truth_threshold\": 18.826261109545076, \"match_probability\": 0.9999978485573913, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5483.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1055.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8386356830596924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1613643318414688, \"precision\": 1.0, \"recall\": 0.8386356830596924, \"specificity\": 1.0, \"npv\": 0.9903010129928589, \"accuracy\": 0.9907664060592651, \"f1\": 0.9122369187255636, \"f2\": 0.8666034455508139, \"f0_5\": 0.9629434492448191, \"p4\": 0.9518807812537102, \"phi\": 0.9113187076848427}, {\"truth_threshold\": 18.826880536377892, \"match_probability\": 0.9999978494809214, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5481.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1057.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8383297920227051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1616702377796173, \"precision\": 1.0, \"recall\": 0.8383297920227051, \"specificity\": 1.0, \"npv\": 0.9902827739715576, \"accuracy\": 0.990748941898346, \"f1\": 0.9120559114735003, \"f2\": 0.8663421110865236, \"f0_5\": 0.9628627643876045, \"p4\": 0.9517780263097003, \"phi\": 0.9111440308798805}, {\"truth_threshold\": 18.849091315449108, \"match_probability\": 0.9999978823352704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5480.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1058.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8381767868995667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16182318329811096, \"precision\": 1.0, \"recall\": 0.8381767868995667, \"specificity\": 1.0, \"npv\": 0.990273654460907, \"accuracy\": 0.990740180015564, \"f1\": 0.9119653852554501, \"f2\": 0.8662114314618108, \"f0_5\": 0.9628224049476422, \"p4\": 0.9517266301870498, \"phi\": 0.9110567317156896}, {\"truth_threshold\": 18.853397262223694, \"match_probability\": 0.9999978886463325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5479.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1059.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.838023841381073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1619761437177658, \"precision\": 1.0, \"recall\": 0.838023841381073, \"specificity\": 1.0, \"npv\": 0.9902645945549011, \"accuracy\": 0.990731418132782, \"f1\": 0.911874843971041, \"f2\": 0.8660807435743416, \"f0_5\": 0.9627820341603992, \"p4\": 0.9516752216240796, \"phi\": 0.9109694257908468}, {\"truth_threshold\": 18.860939443289503, \"match_probability\": 0.9999978996553301, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5478.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1060.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8378708958625793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16212908923625946, \"precision\": 1.0, \"recall\": 0.8378708958625793, \"specificity\": 1.0, \"npv\": 0.9902554750442505, \"accuracy\": 0.99072265625, \"f1\": 0.9117842876165113, \"f2\": 0.8659500474233323, \"f0_5\": 0.9627416520210896, \"p4\": 0.9516238006158693, \"phi\": 0.910882113103364}, {\"truth_threshold\": 18.89532524426164, \"match_probability\": 0.9999979491238579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5477.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1061.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8377179503440857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1622820496559143, \"precision\": 1.0, \"recall\": 0.8377179503440857, \"specificity\": 1.0, \"npv\": 0.9902463555335999, \"accuracy\": 0.990713894367218, \"f1\": 0.9116937161880982, \"f2\": 0.865819343007999, \"f0_5\": 0.9627012585249244, \"p4\": 0.951572367157496, \"phi\": 0.9107947936512519}, {\"truth_threshold\": 18.903483538416207, \"match_probability\": 0.9999979606886013, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5476.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1062.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.837565004825592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16243499517440796, \"precision\": 1.0, \"recall\": 0.837565004825592, \"specificity\": 1.0, \"npv\": 0.9902372360229492, \"accuracy\": 0.9907051920890808, \"f1\": 0.9116031296820376, \"f2\": 0.8656886303275578, \"f0_5\": 0.9626608536671121, \"p4\": 0.9515209212440342, \"phi\": 0.9107074674325206}, {\"truth_threshold\": 18.910472675221556, \"match_probability\": 0.9999979705441344, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5475.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1063.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8374120593070984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1625879406929016, \"precision\": 1.0, \"recall\": 0.8374120593070984, \"specificity\": 1.0, \"npv\": 0.9902281761169434, \"accuracy\": 0.9906964302062988, \"f1\": 0.9115125280945642, \"f2\": 0.8655579093812249, \"f0_5\": 0.9626204374428582, \"p4\": 0.9514694628705559, \"phi\": 0.9106201344451792}, {\"truth_threshold\": 18.91187874142418, \"match_probability\": 0.9999979725210965, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5473.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1065.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8371061682701111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1628938466310501, \"precision\": 1.0, \"recall\": 0.8371061682701111, \"specificity\": 1.0, \"npv\": 0.9902099370956421, \"accuracy\": 0.9906789064407349, \"f1\": 0.9113312796603114, \"f2\": 0.8652964426877471, \"f0_5\": 0.9625395708758354, \"p4\": 0.9513665087238241, \"phi\": 0.9104454481566965}, {\"truth_threshold\": 18.937461527012168, \"match_probability\": 0.9999980081566795, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5471.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1067.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.836800217628479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1631997525691986, \"precision\": 1.0, \"recall\": 0.836800217628479, \"specificity\": 1.0, \"npv\": 0.9901917576789856, \"accuracy\": 0.9906613826751709, \"f1\": 0.9111499708551919, \"f2\": 0.8650349429212915, \"f0_5\": 0.9624586587854479, \"p4\": 0.9512635046778242, \"phi\": 0.9102706359164837}, {\"truth_threshold\": 18.94426033296978, \"match_probability\": 0.9999980175212853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5469.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1069.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8364943265914917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1635056585073471, \"precision\": 1.0, \"recall\": 0.8364943265914917, \"specificity\": 1.0, \"npv\": 0.9901735782623291, \"accuracy\": 0.9906439185142517, \"f1\": 0.910968601649038, \"f2\": 0.8647734100755827, \"f0_5\": 0.9623777011332442, \"p4\": 0.9511604506930379, \"phi\": 0.9100958953981638}, {\"truth_threshold\": 18.94935721941253, \"match_probability\": 0.9999980245127982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5466.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1072.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8360354900360107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16396450996398926, \"precision\": 1.0, \"recall\": 0.8360354900360107, \"specificity\": 1.0, \"npv\": 0.9901462197303772, \"accuracy\": 0.9906176328659058, \"f1\": 0.910696434521826, \"f2\": 0.8643810487696881, \"f0_5\": 0.9622561791423139, \"p4\": 0.9510057759940852, \"phi\": 0.9098337337463716}, {\"truth_threshold\": 18.95608576836657, \"match_probability\": 0.9999980337047532, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5464.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1074.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8357295989990234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16427041590213776, \"precision\": 1.0, \"recall\": 0.8357295989990234, \"specificity\": 1.0, \"npv\": 0.9901280403137207, \"accuracy\": 0.9906001091003418, \"f1\": 0.9105149141809699, \"f2\": 0.8641194331983806, \"f0_5\": 0.9621751074170599, \"p4\": 0.9509025969891672, \"phi\": 0.9096589253723107}, {\"truth_threshold\": 18.961667739090338, \"match_probability\": 0.9999980412978859, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5463.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1075.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8355766534805298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1644233763217926, \"precision\": 1.0, \"recall\": 0.8355766534805298, \"specificity\": 1.0, \"npv\": 0.9901189208030701, \"accuracy\": 0.9905914068222046, \"f1\": 0.9104241313223898, \"f2\": 0.8639886130001582, \"f0_5\": 0.9621345544205706, \"p4\": 0.9508509887101531, \"phi\": 0.9095715109974175}, {\"truth_threshold\": 18.981298302303465, \"match_probability\": 0.9999980677691348, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5462.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1076.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8354236483573914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16457632184028625, \"precision\": 1.0, \"recall\": 0.8354236483573914, \"specificity\": 1.0, \"npv\": 0.9901098608970642, \"accuracy\": 0.9905826449394226, \"f1\": 0.9103333333333333, \"f2\": 0.8638577845258429, \"f0_5\": 0.962093989995068, \"p4\": 0.9507993679068206, \"phi\": 0.909483990897254}, {\"truth_threshold\": 19.02151740094401, \"match_probability\": 0.999998120891387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5460.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1078.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.835117757320404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16488222777843475, \"precision\": 1.0, \"recall\": 0.835117757320404, \"specificity\": 1.0, \"npv\": 0.9900916218757629, \"accuracy\": 0.9905651211738586, \"f1\": 0.9101516919486581, \"f2\": 0.8635961027457927, \"f0_5\": 0.9620128268376912, \"p4\": 0.9506960887073393, \"phi\": 0.9093091281493486}, {\"truth_threshold\": 19.044726994993923, \"match_probability\": 0.9999981508799307, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5459.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1079.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8349648118019104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1650351732969284, \"precision\": 1.0, \"recall\": 0.8349648118019104, \"specificity\": 1.0, \"npv\": 0.9900825619697571, \"accuracy\": 0.9905563592910767, \"f1\": 0.9100608485454696, \"f2\": 0.8634652494384866, \"f0_5\": 0.9619722280961444, \"p4\": 0.9506444303012537, \"phi\": 0.9092216865755053}, {\"truth_threshold\": 19.048628025750624, \"match_probability\": 0.999998155873167, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5458.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1080.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8348118662834167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16518813371658325, \"precision\": 1.0, \"recall\": 0.8348118662834167, \"specificity\": 1.0, \"npv\": 0.9900734424591064, \"accuracy\": 0.9905475974082947, \"f1\": 0.9099699899966656, \"f2\": 0.8633343878519456, \"f0_5\": 0.9619316179062389, \"p4\": 0.9505927593509755, \"phi\": 0.9091342381990598}, {\"truth_threshold\": 19.065189527112597, \"match_probability\": 0.9999981769218433, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5457.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1081.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8346589207649231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1653410792350769, \"precision\": 1.0, \"recall\": 0.8346589207649231, \"specificity\": 1.0, \"npv\": 0.9900643229484558, \"accuracy\": 0.9905388951301575, \"f1\": 0.9098791162984576, \"f2\": 0.8632035179853839, \"f0_5\": 0.9618909962631319, \"p4\": 0.9505410758515299, \"phi\": 0.9090467830180048}, {\"truth_threshold\": 19.07020874908476, \"match_probability\": 0.999998183253409, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5456.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1082.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8345059752464294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16549403965473175, \"precision\": 1.0, \"recall\": 0.8345059752464294, \"specificity\": 1.0, \"npv\": 0.99005526304245, \"accuracy\": 0.9905301332473755, \"f1\": 0.9097882274470569, \"f2\": 0.8630726398380157, \"f0_5\": 0.9618503631619773, \"p4\": 0.9504893797979391, \"phi\": 0.9089593210303316}, {\"truth_threshold\": 19.07154557863318, \"match_probability\": 0.9999981849360593, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5454.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1084.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8342000842094421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16579994559288025, \"precision\": 1.0, \"recall\": 0.8342000842094421, \"specificity\": 1.0, \"npv\": 0.9900370240211487, \"accuracy\": 0.9905126094818115, \"f1\": 0.909606404269513, \"f2\": 0.8628108586977157, \"f0_5\": 0.9617690625661283, \"p4\": 0.9503859500083981, \"phi\": 0.9087843766270925}, {\"truth_threshold\": 19.07646169472249, \"match_probability\": 0.9999981911105195, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5453.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1085.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8340471386909485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1659528911113739, \"precision\": 1.0, \"recall\": 0.8340471386909485, \"specificity\": 1.0, \"npv\": 0.9900279641151428, \"accuracy\": 0.9905038475990295, \"f1\": 0.9095154699357851, \"f2\": 0.8626799557032115, \"f0_5\": 0.9617283950617284, \"p4\": 0.9503342162624794, \"phi\": 0.9086967951993017}, {\"truth_threshold\": 19.08366001993314, \"match_probability\": 0.9999982001134764, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5452.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1086.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8338941335678101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16610583662986755, \"precision\": 1.0, \"recall\": 0.8338941335678101, \"specificity\": 1.0, \"npv\": 0.9900188446044922, \"accuracy\": 0.9904950857162476, \"f1\": 0.9094245204336947, \"f2\": 0.8625490444247563, \"f0_5\": 0.9616877160798701, \"p4\": 0.9502824699424786, \"phi\": 0.9086093059564284}, {\"truth_threshold\": 19.085656456365793, \"match_probability\": 0.999998202602476, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5451.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1087.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8337411880493164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1662587970495224, \"precision\": 1.0, \"recall\": 0.8337411880493164, \"specificity\": 1.0, \"npv\": 0.9900097250938416, \"accuracy\": 0.9904863834381104, \"f1\": 0.9093335557594462, \"f2\": 0.8624181248615638, \"f0_5\": 0.961647025615694, \"p4\": 0.9502307110434047, \"phi\": 0.9085218098968787}, {\"truth_threshold\": 19.091093133408968, \"match_probability\": 0.9999982093630615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5450.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1088.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8335882425308228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16641174256801605, \"precision\": 1.0, \"recall\": 0.8335882425308228, \"specificity\": 1.0, \"npv\": 0.9900006651878357, \"accuracy\": 0.9904776215553284, \"f1\": 0.9092425759092426, \"f2\": 0.8622871970128473, \"f0_5\": 0.9616063236643376, \"p4\": 0.9501789395602643, \"phi\": 0.9084343070186383}, {\"truth_threshold\": 19.100191027050275, \"match_probability\": 0.999998220619589, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5449.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1089.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8334352970123291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1665647029876709, \"precision\": 1.0, \"recall\": 0.8334352970123291, \"specificity\": 1.0, \"npv\": 0.9899915456771851, \"accuracy\": 0.9904688596725464, \"f1\": 0.9091515808792859, \"f2\": 0.8621562608778203, \"f0_5\": 0.961565610220936, \"p4\": 0.9501271554880614, \"phi\": 0.9083467973196924}, {\"truth_threshold\": 19.121886098149595, \"match_probability\": 0.999998247177459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5448.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1090.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8332823514938354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16671764850616455, \"precision\": 1.0, \"recall\": 0.8332823514938354, \"specificity\": 1.0, \"npv\": 0.9899824261665344, \"accuracy\": 0.9904600977897644, \"f1\": 0.9090605706657767, \"f2\": 0.8620253164556962, \"f0_5\": 0.9615248852806213, \"p4\": 0.9500753588217971, \"phi\": 0.9082592807980249}, {\"truth_threshold\": 19.15156442320251, \"match_probability\": 0.9999982828671409, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5447.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1091.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8331294059753418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1668706089258194, \"precision\": 1.0, \"recall\": 0.8331294059753418, \"specificity\": 1.0, \"npv\": 0.9899733662605286, \"accuracy\": 0.9904513359069824, \"f1\": 0.9089695452649145, \"f2\": 0.8618943637456882, \"f0_5\": 0.961484148838523, \"p4\": 0.95002354955647, \"phi\": 0.9081717574516192}, {\"truth_threshold\": 19.171386330391677, \"match_probability\": 0.9999983062983113, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5446.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1092.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8329764604568481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16702355444431305, \"precision\": 1.0, \"recall\": 0.8329764604568481, \"specificity\": 1.0, \"npv\": 0.9899642467498779, \"accuracy\": 0.9904425740242004, \"f1\": 0.9088785046728972, \"f2\": 0.8617634027470094, \"f0_5\": 0.9614434008897677, \"p4\": 0.949971727687076, \"phi\": 0.9080842272784577}, {\"truth_threshold\": 19.178826503206967, \"match_probability\": 0.9999983150104604, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5444.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1094.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8326705694198608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16732946038246155, \"precision\": 1.0, \"recall\": 0.8326705694198608, \"specificity\": 1.0, \"npv\": 0.9899460673332214, \"accuracy\": 0.9904251098632812, \"f1\": 0.9086963779001836, \"f2\": 0.8615014558804912, \"f0_5\": 0.9613618704527795, \"p4\": 0.9498680461160587, \"phi\": 0.9079090473578798}, {\"truth_threshold\": 19.1926401328348, \"match_probability\": 0.9999983310670111, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5441.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1097.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8322116732597351, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1677883118391037, \"precision\": 1.0, \"recall\": 0.8322116732597351, \"specificity\": 1.0, \"npv\": 0.9899187684059143, \"accuracy\": 0.9903988242149353, \"f1\": 0.9084230737123299, \"f2\": 0.8611084733960055, \"f0_5\": 0.9612394883753799, \"p4\": 0.9497124291037788, \"phi\": 0.9076463748287679}, {\"truth_threshold\": 19.193842937683566, \"match_probability\": 0.999998332457853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5440.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1098.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8320587277412415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16794127225875854, \"precision\": 1.0, \"recall\": 0.8320587277412415, \"specificity\": 1.0, \"npv\": 0.9899096488952637, \"accuracy\": 0.9903900623321533, \"f1\": 0.9083319418934713, \"f2\": 0.8609774626487718, \"f0_5\": 0.9611986712841897, \"p4\": 0.9496605315047514, \"phi\": 0.907558803643993}, {\"truth_threshold\": 19.21027680692784, \"match_probability\": 0.9999983513451668, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5438.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1100.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8317528367042542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16824716329574585, \"precision\": 1.0, \"recall\": 0.8317528367042542, \"specificity\": 1.0, \"npv\": 0.9898914694786072, \"accuracy\": 0.9903725981712341, \"f1\": 0.9081496325985304, \"f2\": 0.8607154162709718, \"f0_5\": 0.9611170024743726, \"p4\": 0.9495566983841637, \"phi\": 0.9073836407496926}, {\"truth_threshold\": 19.213206506086305, \"match_probability\": 0.9999983546897085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5437.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8315998911857605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1684001237154007, \"precision\": 1.0, \"recall\": 0.8315998911857605, \"specificity\": 1.0, \"npv\": 0.9898823499679565, \"accuracy\": 0.9903638362884521, \"f1\": 0.9080584551148225, \"f2\": 0.86058438063883, \"f0_5\": 0.9610761507459521, \"p4\": 0.9495047628525503, \"phi\": 0.9072960490361157}, {\"truth_threshold\": 19.224698774085905, \"match_probability\": 0.9999983677438917, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5436.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1102.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8314469456672668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16855306923389435, \"precision\": 1.0, \"recall\": 0.8314469456672668, \"specificity\": 1.0, \"npv\": 0.9898732900619507, \"accuracy\": 0.9903550744056702, \"f1\": 0.9079672624018708, \"f2\": 0.8604533367101431, \"f0_5\": 0.96103528746199, \"p4\": 0.9494528146666841, \"phi\": 0.9072084504755523}, {\"truth_threshold\": 19.225397146153682, \"match_probability\": 0.999998368533833, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5435.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1103.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8312940001487732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1687060296535492, \"precision\": 1.0, \"recall\": 0.8312940001487732, \"specificity\": 1.0, \"npv\": 0.9898641705513, \"accuracy\": 0.9903463125228882, \"f1\": 0.9078760544558591, \"f2\": 0.8603222844841232, \"f0_5\": 0.9609944126175826, \"p4\": 0.9494008538215317, \"phi\": 0.9071207459021574}, {\"truth_threshold\": 19.22993355253459, \"match_probability\": 0.9999983736557455, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5434.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1104.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8311409950256348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16885897517204285, \"precision\": 1.0, \"recall\": 0.8311409950256348, \"specificity\": 1.0, \"npv\": 0.9898551106452942, \"accuracy\": 0.9903375506401062, \"f1\": 0.9077848312729703, \"f2\": 0.8601912239599823, \"f0_5\": 0.9609535262078235, \"p4\": 0.9493488803120574, \"phi\": 0.9070331336328671}, {\"truth_threshold\": 19.241775658283075, \"match_probability\": 0.9999983869506426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5433.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1105.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8309880495071411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1690119355916977, \"precision\": 1.0, \"recall\": 0.8309880495071411, \"specificity\": 1.0, \"npv\": 0.9898459911346436, \"accuracy\": 0.990328848361969, \"f1\": 0.907693592849386, \"f2\": 0.8600601551369321, \"f0_5\": 0.9609126282278033, \"p4\": 0.9492968941332225, \"phi\": 0.9069455145105008}, {\"truth_threshold\": 19.254657916166614, \"match_probability\": 0.9999984012899074, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5432.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1106.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8308351039886475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16916488111019135, \"precision\": 1.0, \"recall\": 0.8308351039886475, \"specificity\": 1.0, \"npv\": 0.9898368716239929, \"accuracy\": 0.990320086479187, \"f1\": 0.9076023391812865, \"f2\": 0.8599290780141844, \"f0_5\": 0.9608717186726102, \"p4\": 0.9492448952799859, \"phi\": 0.9068578885330276}, {\"truth_threshold\": 19.266833359820858, \"match_probability\": 0.9999984147252264, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5431.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1107.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8306821584701538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1693178415298462, \"precision\": 1.0, \"recall\": 0.8306821584701538, \"specificity\": 1.0, \"npv\": 0.9898278117179871, \"accuracy\": 0.990311324596405, \"f1\": 0.9075110702648509, \"f2\": 0.8597979925909508, \"f0_5\": 0.9608307975373293, \"p4\": 0.9491928837473036, \"phi\": 0.9067702556984162}, {\"truth_threshold\": 19.28916779379733, \"match_probability\": 0.9999984390779171, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5430.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1108.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8305292129516602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16947078704833984, \"precision\": 1.0, \"recall\": 0.8305292129516602, \"specificity\": 1.0, \"npv\": 0.9898186922073364, \"accuracy\": 0.990302562713623, \"f1\": 0.9074197860962567, \"f2\": 0.8596668988664429, \"f0_5\": 0.960789864817043, \"p4\": 0.949140859530129, \"phi\": 0.9066826160046334}, {\"truth_threshold\": 19.31314186605591, \"match_probability\": 0.9999984648022646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5429.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1109.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8303762674331665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1696237325668335, \"precision\": 1.0, \"recall\": 0.8303762674331665, \"specificity\": 1.0, \"npv\": 0.9898096323013306, \"accuracy\": 0.9902938008308411, \"f1\": 0.9073284866716804, \"f2\": 0.859535796839872, \"f0_5\": 0.9607489205068309, \"p4\": 0.9490888226234131, \"phi\": 0.9065949694496457}, {\"truth_threshold\": 19.319429525389147, \"match_probability\": 0.9999984714785067, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5428.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1110.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8302233219146729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16977669298648834, \"precision\": 1.0, \"recall\": 0.8302233219146729, \"specificity\": 1.0, \"npv\": 0.9898005127906799, \"accuracy\": 0.9902850389480591, \"f1\": 0.9072371719872974, \"f2\": 0.8594046865104497, \"f0_5\": 0.9607079646017699, \"p4\": 0.9490367730221038, \"phi\": 0.9065073160314188}, {\"truth_threshold\": 19.320235456670478, \"match_probability\": 0.9999984723321435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5427.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1111.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8300703763961792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.169929638504982, \"precision\": 1.0, \"recall\": 0.8300703763961792, \"specificity\": 1.0, \"npv\": 0.9897913932800293, \"accuracy\": 0.9902763366699219, \"f1\": 0.9071458420392813, \"f2\": 0.8592735678773868, \"f0_5\": 0.960666997096934, \"p4\": 0.9489847107211464, \"phi\": 0.9064196557479169}, {\"truth_threshold\": 19.32524336811964, \"match_probability\": 0.9999984776258131, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5426.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1112.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8299174308776855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17008259892463684, \"precision\": 1.0, \"recall\": 0.8299174308776855, \"specificity\": 1.0, \"npv\": 0.9897823333740234, \"accuracy\": 0.9902675747871399, \"f1\": 0.9070544968238048, \"f2\": 0.8591424409398949, \"f0_5\": 0.9606260179873947, \"p4\": 0.9489326357154839, \"phi\": 0.9063318893551846}, {\"truth_threshold\": 19.334607482609957, \"match_probability\": 0.9999984874750878, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5425.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1113.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8297644257545471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1702355444431305, \"precision\": 1.0, \"recall\": 0.8297644257545471, \"specificity\": 1.0, \"npv\": 0.9897732138633728, \"accuracy\": 0.9902588129043579, \"f1\": 0.9069631363370392, \"f2\": 0.8590113056971846, \"f0_5\": 0.9605850272682201, \"p4\": 0.9488805480000563, \"phi\": 0.9062442153263324}, {\"truth_threshold\": 19.359884719126754, \"match_probability\": 0.9999985137449562, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5424.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1114.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8296114802360535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17038850486278534, \"precision\": 1.0, \"recall\": 0.8296114802360535, \"specificity\": 1.0, \"npv\": 0.9897641539573669, \"accuracy\": 0.9902500510215759, \"f1\": 0.9068717605751546, \"f2\": 0.8588801621484672, \"f0_5\": 0.9605440249344762, \"p4\": 0.9488284475698008, \"phi\": 0.9061565344260909}, {\"truth_threshold\": 19.374263388215706, \"match_probability\": 0.9999985284841743, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5423.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1115.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8294585347175598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.170541450381279, \"precision\": 1.0, \"recall\": 0.8294585347175598, \"specificity\": 1.0, \"npv\": 0.9897550344467163, \"accuracy\": 0.990241289138794, \"f1\": 0.9067803695343198, \"f2\": 0.8587490102929533, \"f0_5\": 0.9605030109812256, \"p4\": 0.9487763344196521, \"phi\": 0.9060688466524205}, {\"truth_threshold\": 19.407753904100165, \"match_probability\": 0.9999985622502459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5422.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1116.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8293055891990662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17069439589977264, \"precision\": 1.0, \"recall\": 0.8293055891990662, \"specificity\": 1.0, \"npv\": 0.9897459745407104, \"accuracy\": 0.990232527256012, \"f1\": 0.9066889632107024, \"f2\": 0.8586178501298537, \"f0_5\": 0.9604619854035287, \"p4\": 0.9487242085445424, \"phi\": 0.9059811520032813}, {\"truth_threshold\": 19.41188106798276, \"match_probability\": 0.9999985663573793, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5421.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1117.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8291526436805725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1708473563194275, \"precision\": 1.0, \"recall\": 0.8291526436805725, \"specificity\": 1.0, \"npv\": 0.9897368550300598, \"accuracy\": 0.99022376537323, \"f1\": 0.9065975416004682, \"f2\": 0.858486681658379, \"f0_5\": 0.9604209481964425, \"p4\": 0.9486720699394009, \"phi\": 0.905893450476632}, {\"truth_threshold\": 19.424813231106903, \"match_probability\": 0.9999985791509534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5420.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1118.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8289996981620789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17100030183792114, \"precision\": 1.0, \"recall\": 0.8289996981620789, \"specificity\": 1.0, \"npv\": 0.9897277355194092, \"accuracy\": 0.9902150630950928, \"f1\": 0.9065061046997825, \"f2\": 0.8583555048777398, \"f0_5\": 0.9603798993550217, \"p4\": 0.9486199185991543, \"phi\": 0.9058057420704303}, {\"truth_threshold\": 19.481440226757442, \"match_probability\": 0.9999986338400809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5419.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1119.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8288467526435852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.171153262257576, \"precision\": 1.0, \"recall\": 0.8288467526435852, \"specificity\": 1.0, \"npv\": 0.9897186756134033, \"accuracy\": 0.9902063012123108, \"f1\": 0.9064146525048089, \"f2\": 0.8582243197871464, \"f0_5\": 0.9603388388743177, \"p4\": 0.9485677545187264, \"phi\": 0.9057180267826335}, {\"truth_threshold\": 19.50401738510333, \"match_probability\": 0.9999986550530728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5418.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1120.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8286938071250916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17130620777606964, \"precision\": 1.0, \"recall\": 0.8286938071250916, \"specificity\": 1.0, \"npv\": 0.9897095561027527, \"accuracy\": 0.9901975393295288, \"f1\": 0.9063231850117096, \"f2\": 0.8580931263858093, \"f0_5\": 0.9602977667493796, \"p4\": 0.9485155776930385, \"phi\": 0.9056303046111973}, {\"truth_threshold\": 19.505634696914907, \"match_probability\": 0.9999986565599587, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5417.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1121.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8285408616065979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1714591681957245, \"precision\": 1.0, \"recall\": 0.8285408616065979, \"specificity\": 1.0, \"npv\": 0.9897004961967468, \"accuracy\": 0.9901887774467468, \"f1\": 0.9062317022166457, \"f2\": 0.8579619246729386, \"f0_5\": 0.9602566829752535, \"p4\": 0.9484633881170093, \"phi\": 0.9055424762338565}, {\"truth_threshold\": 19.508068734756254, \"match_probability\": 0.9999986588246249, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5413.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1125.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8279290199279785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1720709651708603, \"precision\": 1.0, \"recall\": 0.8279290199279785, \"specificity\": 1.0, \"npv\": 0.9896640777587891, \"accuracy\": 0.9901537895202637, \"f1\": 0.9058656179399214, \"f2\": 0.8574370346903215, \"f0_5\": 0.9600922312876907, \"p4\": 0.9482545022077542, \"phi\": 0.905191491072737}, {\"truth_threshold\": 19.53341754500194, \"match_probability\": 0.9999986821838402, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5411.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1127.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8276231288909912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1723768711090088, \"precision\": 1.0, \"recall\": 0.8276231288909912, \"specificity\": 1.0, \"npv\": 0.9896458983421326, \"accuracy\": 0.9901362657546997, \"f1\": 0.9056824838898653, \"f2\": 0.8571745398092704, \"f0_5\": 0.9600099354197715, \"p4\": 0.948149982618762, \"phi\": 0.905015957124819}, {\"truth_threshold\": 19.541048269087725, \"match_probability\": 0.9999986891356429, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5410.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1128.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8274701833724976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17252983152866364, \"precision\": 1.0, \"recall\": 0.8274701833724976, \"specificity\": 1.0, \"npv\": 0.9896368384361267, \"accuracy\": 0.9901275038719177, \"f1\": 0.9055908938734516, \"f2\": 0.8570432798935429, \"f0_5\": 0.959968769962382, \"p4\": 0.9480977036478354, \"phi\": 0.9049281798018438}, {\"truth_threshold\": 19.567302711092207, \"match_probability\": 0.9999987127752229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5409.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1129.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8273172378540039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1726827770471573, \"precision\": 1.0, \"recall\": 0.8273172378540039, \"specificity\": 1.0, \"npv\": 0.9896277189254761, \"accuracy\": 0.9901187419891357, \"f1\": 0.9054992885243157, \"f2\": 0.8569120116599601, \"f0_5\": 0.9599275928160715, \"p4\": 0.9480454118858185, \"phi\": 0.9048403955767884}, {\"truth_threshold\": 19.580981744602273, \"match_probability\": 0.999998724922458, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5408.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1130.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8271642923355103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17283572256565094, \"precision\": 1.0, \"recall\": 0.8271642923355103, \"specificity\": 1.0, \"npv\": 0.9896186590194702, \"accuracy\": 0.9901100397109985, \"f1\": 0.905407667838607, \"f2\": 0.8567807351077313, \"f0_5\": 0.9598864039758609, \"p4\": 0.9479931073276054, \"phi\": 0.904752604447599}, {\"truth_threshold\": 19.581317716786895, \"match_probability\": 0.9999987252193607, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5407.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1131.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8270113468170166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1729886829853058, \"precision\": 1.0, \"recall\": 0.8270113468170166, \"specificity\": 1.0, \"npv\": 0.9896095395088196, \"accuracy\": 0.9901012778282166, \"f1\": 0.9053160318124739, \"f2\": 0.8566494502360658, \"f0_5\": 0.9598452034367677, \"p4\": 0.947940789968088, \"phi\": 0.9046647070047658}, {\"truth_threshold\": 19.588616158204537, \"match_probability\": 0.999998731652048, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5404.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1134.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8265524506568909, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17344753444194794, \"precision\": 1.0, \"recall\": 0.8265524506568909, \"specificity\": 1.0, \"npv\": 0.9895823001861572, \"accuracy\": 0.9900749921798706, \"f1\": 0.9050410316529894, \"f2\": 0.8562555456965395, \"f0_5\": 0.9597215315763302, \"p4\": 0.9477837610305826, \"phi\": 0.9044012714147251}, {\"truth_threshold\": 19.604526145925156, \"match_probability\": 0.999998745562482, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5402.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1136.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8262465596199036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17375344038009644, \"precision\": 1.0, \"recall\": 0.8262465596199036, \"specificity\": 1.0, \"npv\": 0.9895641207695007, \"accuracy\": 0.9900575280189514, \"f1\": 0.904857621440536, \"f2\": 0.8559929010585029, \"f0_5\": 0.9596390250834932, \"p4\": 0.9476790109719451, \"phi\": 0.9042256131193692}, {\"truth_threshold\": 19.619737788084766, \"match_probability\": 0.999998758719652, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5401.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1137.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8260936141014099, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17390640079975128, \"precision\": 1.0, \"recall\": 0.8260936141014099, \"specificity\": 1.0, \"npv\": 0.9895550012588501, \"accuracy\": 0.9900487661361694, \"f1\": 0.9047658932908954, \"f2\": 0.8558615662536051, \"f0_5\": 0.9595977542463222, \"p4\": 0.9476266166971699, \"phi\": 0.904137773594915}, {\"truth_threshold\": 19.623603764259805, \"match_probability\": 0.9999987620414424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5399.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1139.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8257877230644226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1742122918367386, \"precision\": 1.0, \"recall\": 0.8257877230644226, \"specificity\": 1.0, \"npv\": 0.9895368218421936, \"accuracy\": 0.9900312423706055, \"f1\": 0.9045823908854821, \"f2\": 0.8555988716680929, \"f0_5\": 0.9595151773654653, \"p4\": 0.947521789631069, \"phi\": 0.9039620737821481}, {\"truth_threshold\": 19.64859265075695, \"match_probability\": 0.999998783299431, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5397.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1141.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8254817724227905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17451819777488708, \"precision\": 1.0, \"recall\": 0.8254817724227905, \"specificity\": 1.0, \"npv\": 0.9895186424255371, \"accuracy\": 0.9900137186050415, \"f1\": 0.9043988269794722, \"f2\": 0.8553361437763479, \"f0_5\": 0.9594325535092085, \"p4\": 0.9474169111753521, \"phi\": 0.9037862467755466}, {\"truth_threshold\": 19.657359509810828, \"match_probability\": 0.9999987906705564, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5395.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1143.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8251758813858032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17482410371303558, \"precision\": 1.0, \"recall\": 0.8251758813858032, \"specificity\": 1.0, \"npv\": 0.9895004630088806, \"accuracy\": 0.9899962544441223, \"f1\": 0.9042152015419425, \"f2\": 0.8550733825720354, \"f0_5\": 0.9593498826374565, \"p4\": 0.9473119812889226, \"phi\": 0.9036104915309443}, {\"truth_threshold\": 19.66851012798647, \"match_probability\": 0.9999987999814477, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5394.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1144.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8250229358673096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17497706413269043, \"precision\": 1.0, \"recall\": 0.8250229358673096, \"specificity\": 1.0, \"npv\": 0.9894914031028748, \"accuracy\": 0.9899874925613403, \"f1\": 0.9041233657391887, \"f2\": 0.8549419894756863, \"f0_5\": 0.9593085295582272, \"p4\": 0.9472594970463359, \"phi\": 0.9035226035101941}, {\"truth_threshold\": 19.66962531382928, \"match_probability\": 0.999998800908688, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5393.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1145.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8248699903488159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17513000965118408, \"precision\": 1.0, \"recall\": 0.8248699903488159, \"specificity\": 1.0, \"npv\": 0.9894822835922241, \"accuracy\": 0.9899787306785583, \"f1\": 0.9040315145419495, \"f2\": 0.8548105880488192, \"f0_5\": 0.9592671647100676, \"p4\": 0.94720699993064, \"phi\": 0.9034347085543879}, {\"truth_threshold\": 19.71339510558168, \"match_probability\": 0.9999988367414544, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5392.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1146.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8247170448303223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17528295516967773, \"precision\": 1.0, \"recall\": 0.8247170448303223, \"specificity\": 1.0, \"npv\": 0.9894732236862183, \"accuracy\": 0.9899699687957764, \"f1\": 0.9039396479463537, \"f2\": 0.8546791782906417, \"f0_5\": 0.9592257880879528, \"p4\": 0.9471544899366854, \"phi\": 0.9033468066614566}, {\"truth_threshold\": 19.723912326237535, \"match_probability\": 0.9999988451907433, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5391.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1147.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8245640993118286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17543591558933258, \"precision\": 1.0, \"recall\": 0.8245640993118286, \"specificity\": 1.0, \"npv\": 0.9894641041755676, \"accuracy\": 0.9899612069129944, \"f1\": 0.9038477659485288, \"f2\": 0.8545477602003614, \"f0_5\": 0.959184399686855, \"p4\": 0.94710196705932, \"phi\": 0.9032588978293306}, {\"truth_threshold\": 19.736963086208647, \"match_probability\": 0.9999988555901406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5390.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1148.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.824411153793335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17558886110782623, \"precision\": 1.0, \"recall\": 0.824411153793335, \"specificity\": 1.0, \"npv\": 0.9894550442695618, \"accuracy\": 0.9899525046348572, \"f1\": 0.903755868544601, \"f2\": 0.854416333777186, \"f0_5\": 0.9591429995017439, \"p4\": 0.947049431293389, \"phi\": 0.9031709820559392}, {\"truth_threshold\": 19.75634883111283, \"match_probability\": 0.9999988708649035, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5389.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1149.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8242582082748413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17574182152748108, \"precision\": 1.0, \"recall\": 0.8242582082748413, \"specificity\": 1.0, \"npv\": 0.9894459247589111, \"accuracy\": 0.9899437427520752, \"f1\": 0.903663955730695, \"f2\": 0.8542848990203228, \"f0_5\": 0.959101587527586, \"p4\": 0.9469968826337347, \"phi\": 0.9030829597741079}, {\"truth_threshold\": 19.75730143421088, \"match_probability\": 0.9999988716102178, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5384.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1154.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8234934210777283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17650657892227173, \"precision\": 1.0, \"recall\": 0.8234934210777283, \"specificity\": 1.0, \"npv\": 0.9894005060195923, \"accuracy\": 0.9898999333381653, \"f1\": 0.9032041603757759, \"f2\": 0.8536276002029427, \"f0_5\": 0.9588943506447246, \"p4\": 0.9467339457489049, \"phi\": 0.9026432419238934}, {\"truth_threshold\": 19.771819033860343, \"match_probability\": 0.9999988829080638, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5383.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1155.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8233404755592346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17665952444076538, \"precision\": 1.0, \"recall\": 0.8233404755592346, \"specificity\": 1.0, \"npv\": 0.9893913865089417, \"accuracy\": 0.9898912310600281, \"f1\": 0.903112155020552, \"f2\": 0.853496115427303, \"f0_5\": 0.9588528678304239, \"p4\": 0.9466813196184469, \"phi\": 0.9025552774947866}, {\"truth_threshold\": 19.783481458281734, \"match_probability\": 0.9999988919019741, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5382.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1156.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.823187530040741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17681248486042023, \"precision\": 1.0, \"recall\": 0.823187530040741, \"specificity\": 1.0, \"npv\": 0.9893823266029358, \"accuracy\": 0.9898824691772461, \"f1\": 0.9030201342281879, \"f2\": 0.8533646223124247, \"f0_5\": 0.9588113731917622, \"p4\": 0.9466286805580852, \"phi\": 0.9024673061078109}, {\"truth_threshold\": 19.79514131410989, \"match_probability\": 0.9999989008215159, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5380.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1158.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8228816390037537, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17711839079856873, \"precision\": 1.0, \"recall\": 0.8228816390037537, \"specificity\": 1.0, \"npv\": 0.9893641471862793, \"accuracy\": 0.9898649454116821, \"f1\": 0.902836046316496, \"f2\": 0.8531016110617785, \"f0_5\": 0.9587283484211276, \"p4\": 0.9465233636269296, \"phi\": 0.9022912428077055}, {\"truth_threshold\": 19.79726966701203, \"match_probability\": 0.9999989024418947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5378.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1160.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8225756883621216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17742428183555603, \"precision\": 1.0, \"recall\": 0.8225756883621216, \"specificity\": 1.0, \"npv\": 0.9893459677696228, \"accuracy\": 0.9898474216461182, \"f1\": 0.9026518966096005, \"f2\": 0.8528385664446558, \"f0_5\": 0.9586452762923351, \"p4\": 0.9464179949139675, \"phi\": 0.9021152512777757}, {\"truth_threshold\": 19.79816900680746, \"match_probability\": 0.9999989031258708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5377.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1161.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8224227428436279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17757724225521088, \"precision\": 1.0, \"recall\": 0.8224227428436279, \"specificity\": 1.0, \"npv\": 0.9893369078636169, \"accuracy\": 0.989838719367981, \"f1\": 0.902559798573227, \"f2\": 0.8527070316216816, \"f0_5\": 0.9586037224559651, \"p4\": 0.9463652911263375, \"phi\": 0.9020272450614348}, {\"truth_threshold\": 19.80597298964369, \"match_probability\": 0.9999989090431765, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5375.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1163.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8221168518066406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17788314819335938, \"precision\": 1.0, \"recall\": 0.8221168518066406, \"specificity\": 1.0, \"npv\": 0.9893187284469604, \"accuracy\": 0.989821195602417, \"f1\": 0.9023755561151683, \"f2\": 0.8524439369429379, \"f0_5\": 0.958520579213924, \"p4\": 0.9462598446628122, \"phi\": 0.9018512117155796}, {\"truth_threshold\": 19.836504152613898, \"match_probability\": 0.9999989318880423, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5374.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1164.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.821963906288147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17803609371185303, \"precision\": 1.0, \"recall\": 0.821963906288147, \"specificity\": 1.0, \"npv\": 0.9893096089363098, \"accuracy\": 0.989812433719635, \"f1\": 0.9022834116856951, \"f2\": 0.8523123770855802, \"f0_5\": 0.9584789897981023, \"p4\": 0.9462071019765217, \"phi\": 0.9017631845818936}, {\"truth_threshold\": 19.840197198512957, \"match_probability\": 0.9999989346187219, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5371.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1167.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.821505069732666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17849494516849518, \"precision\": 1.0, \"recall\": 0.821505069732666, \"specificity\": 1.0, \"npv\": 0.9892823696136475, \"accuracy\": 0.9897862076759338, \"f1\": 0.9020068855487446, \"f2\": 0.8519176474320338, \"f0_5\": 0.9583541503104703, \"p4\": 0.9460487960371086, \"phi\": 0.9014989615891952}, {\"truth_threshold\": 19.841237728699344, \"match_probability\": 0.9999989353868403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5368.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1170.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8210461735725403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17895381152629852, \"precision\": 1.0, \"recall\": 0.8210461735725403, \"specificity\": 1.0, \"npv\": 0.9892551302909851, \"accuracy\": 0.9897599220275879, \"f1\": 0.901730220057114, \"f2\": 0.8515228426395939, \"f0_5\": 0.9582292038557658, \"p4\": 0.9458903731674996, \"phi\": 0.9012347754475571}, {\"truth_threshold\": 19.849821545861616, \"match_probability\": 0.9999989417023141, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8208932280540466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17910675704479218, \"precision\": 1.0, \"recall\": 0.8208932280540466, \"specificity\": 1.0, \"npv\": 0.9892460107803345, \"accuracy\": 0.9897511601448059, \"f1\": 0.9016379672406551, \"f2\": 0.8513912243408738, \"f0_5\": 0.958187531243305, \"p4\": 0.9458375395354752, \"phi\": 0.9011466994247986}, {\"truth_threshold\": 19.862827066768972, \"match_probability\": 0.99999895119971, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5366.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1172.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.820740282535553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17925971746444702, \"precision\": 1.0, \"recall\": 0.820740282535553, \"specificity\": 1.0, \"npv\": 0.9892369508743286, \"accuracy\": 0.9897423982620239, \"f1\": 0.9015456989247311, \"f2\": 0.8512595976902088, \"f0_5\": 0.958145846725234, \"p4\": 0.9457846928903404, \"phi\": 0.9010586164107781}, {\"truth_threshold\": 19.873103102983624, \"match_probability\": 0.9999989586435608, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5365.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1173.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8205873370170593, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17941266298294067, \"precision\": 1.0, \"recall\": 0.8205873370170593, \"specificity\": 1.0, \"npv\": 0.989227831363678, \"accuracy\": 0.9897336959838867, \"f1\": 0.9014534151054356, \"f2\": 0.8511279626868039, \"f0_5\": 0.9581041502964498, \"p4\": 0.9457318332268712, \"phi\": 0.9009705264034001}, {\"truth_threshold\": 19.881543203936065, \"match_probability\": 0.9999989647179458, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5364.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1174.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8204343914985657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17956562340259552, \"precision\": 1.0, \"recall\": 0.8204343914985657, \"specificity\": 1.0, \"npv\": 0.9892187714576721, \"accuracy\": 0.9897249341011047, \"f1\": 0.9013611157788607, \"f2\": 0.8509963193298642, \"f0_5\": 0.9580624419518469, \"p4\": 0.9456789605398404, \"phi\": 0.9008824294005691}, {\"truth_threshold\": 19.885574291849363, \"match_probability\": 0.9999989676066254, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5363.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1175.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.820281445980072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17971856892108917, \"precision\": 1.0, \"recall\": 0.820281445980072, \"specificity\": 1.0, \"npv\": 0.9892097115516663, \"accuracy\": 0.9897161722183228, \"f1\": 0.9012688009410974, \"f2\": 0.8508646676185944, \"f0_5\": 0.9580207216863166, \"p4\": 0.9456260748240187, \"phi\": 0.9007943254001873}, {\"truth_threshold\": 19.89726986426929, \"match_probability\": 0.9999989759421424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5361.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1177.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8199755549430847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18002447485923767, \"precision\": 1.0, \"recall\": 0.8199755549430847, \"specificity\": 1.0, \"npv\": 0.9891915321350098, \"accuracy\": 0.9896986484527588, \"f1\": 0.9010841247163627, \"f2\": 0.8506013391298829, \"f0_5\": 0.9579372453720248, \"p4\": 0.9455202642850697, \"phi\": 0.9006179965864414}, {\"truth_threshold\": 19.902909839489634, \"match_probability\": 0.9999989799377063, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5358.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1180.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.819516658782959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18048332631587982, \"precision\": 1.0, \"recall\": 0.819516658782959, \"specificity\": 1.0, \"npv\": 0.9891642928123474, \"accuracy\": 0.9896724224090576, \"f1\": 0.9008069939475454, \"f2\": 0.8502062837194542, \"f0_5\": 0.957811941365749, \"p4\": 0.9453614506298119, \"phi\": 0.9003536005230567}, {\"truth_threshold\": 19.919176774295423, \"match_probability\": 0.9999989913746853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5355.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1183.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.819057822227478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18094217777252197, \"precision\": 1.0, \"recall\": 0.819057822227478, \"specificity\": 1.0, \"npv\": 0.9891369938850403, \"accuracy\": 0.9896461367607117, \"f1\": 0.9005297233666862, \"f2\": 0.849811153077094, \"f0_5\": 0.957686529794692, \"p4\": 0.945202519432489, \"phi\": 0.9000891413682646}, {\"truth_threshold\": 19.922103500409094, \"match_probability\": 0.999998993418759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5354.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1184.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8189048767089844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18109513819217682, \"precision\": 1.0, \"recall\": 0.8189048767089844, \"specificity\": 1.0, \"npv\": 0.9891279339790344, \"accuracy\": 0.9896373748779297, \"f1\": 0.9004372687521023, \"f2\": 0.8496794261410525, \"f0_5\": 0.9576447020104457, \"p4\": 0.9451495162217527, \"phi\": 0.9000009742865338}, {\"truth_threshold\": 19.923699888891317, \"match_probability\": 0.9999989945319563, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5353.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1185.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8187519311904907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18124808371067047, \"precision\": 1.0, \"recall\": 0.8187519311904907, \"specificity\": 1.0, \"npv\": 0.9891188740730286, \"accuracy\": 0.9896286725997925, \"f1\": 0.9003447985871668, \"f2\": 0.8495476908427234, \"f0_5\": 0.957602862254025, \"p4\": 0.945096499929775, \"phi\": 0.8999127003033996}, {\"truth_threshold\": 19.954403205085473, \"match_probability\": 0.9999990157041314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5350.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1188.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.818293035030365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18170695006847382, \"precision\": 1.0, \"recall\": 0.818293035030365, \"specificity\": 1.0, \"npv\": 0.9890916347503662, \"accuracy\": 0.9896023869514465, \"f1\": 0.9000672947510094, \"f2\": 0.8491524347660466, \"f0_5\": 0.9574772711002935, \"p4\": 0.9449373725137744, \"phi\": 0.8996481358433032}, {\"truth_threshold\": 19.976455658628034, \"match_probability\": 0.9999990306352595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5348.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1190.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8179871439933777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18201284110546112, \"precision\": 1.0, \"recall\": 0.8179871439933777, \"specificity\": 1.0, \"npv\": 0.9890734553337097, \"accuracy\": 0.9895848631858826, \"f1\": 0.8998822143698468, \"f2\": 0.8488888888888889, \"f0_5\": 0.9573934837092731, \"p4\": 0.9448312220670496, \"phi\": 0.899471724405002}, {\"truth_threshold\": 19.97654740278987, \"match_probability\": 0.9999990306969015, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5347.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1191.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.817834198474884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18216580152511597, \"precision\": 1.0, \"recall\": 0.817834198474884, \"specificity\": 1.0, \"npv\": 0.9890643358230591, \"accuracy\": 0.9895761013031006, \"f1\": 0.8997896508203618, \"f2\": 0.8487571034001079, \"f0_5\": 0.9573515720117454, \"p4\": 0.9447781271770547, \"phi\": 0.8993835081400449}, {\"truth_threshold\": 19.994801577102397, \"match_probability\": 0.9999990428840531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5346.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1192.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8176812529563904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18231874704360962, \"precision\": 1.0, \"recall\": 0.8176812529563904, \"specificity\": 1.0, \"npv\": 0.9890552759170532, \"accuracy\": 0.9895673990249634, \"f1\": 0.8996970716930327, \"f2\": 0.848625309543463, \"f0_5\": 0.9573096483059953, \"p4\": 0.9447250191689356, \"phi\": 0.899295284841732}, {\"truth_threshold\": 19.994882274440542, \"match_probability\": 0.9999990429375879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5345.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1193.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8175283074378967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18247170746326447, \"precision\": 1.0, \"recall\": 0.8175283074378967, \"specificity\": 1.0, \"npv\": 0.9890462160110474, \"accuracy\": 0.9895586371421814, \"f1\": 0.8996044769839266, \"f2\": 0.8484935073181573, \"f0_5\": 0.9572677125868615, \"p4\": 0.9446718980374124, \"phi\": 0.8992070545079485}, {\"truth_threshold\": 20.002272390058884, \"match_probability\": 0.999999047827541, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5344.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1194.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8173753619194031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18262465298175812, \"precision\": 1.0, \"recall\": 0.8173753619194031, \"specificity\": 1.0, \"npv\": 0.9890370965003967, \"accuracy\": 0.9895498752593994, \"f1\": 0.8995118666891095, \"f2\": 0.8483616967233935, \"f0_5\": 0.9572257648491797, \"p4\": 0.9446187637772019, \"phi\": 0.8991187171738104}, {\"truth_threshold\": 20.013506670609956, \"match_probability\": 0.9999990552133164, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5343.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1195.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8172224164009094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18277761340141296, \"precision\": 1.0, \"recall\": 0.8172224164009094, \"specificity\": 1.0, \"npv\": 0.9890280365943909, \"accuracy\": 0.9895411133766174, \"f1\": 0.8994192408046461, \"f2\": 0.8482298777583743, \"f0_5\": 0.9571838050877821, \"p4\": 0.9445656163830182, \"phi\": 0.8990304727538423}, {\"truth_threshold\": 20.01576096506238, \"match_probability\": 0.9999990566884461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5342.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1196.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.817069411277771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18293055891990662, \"precision\": 1.0, \"recall\": 0.817069411277771, \"specificity\": 1.0, \"npv\": 0.989018976688385, \"accuracy\": 0.9895323514938354, \"f1\": 0.8993265993265993, \"f2\": 0.8480980504223027, \"f0_5\": 0.9571418332974988, \"p4\": 0.9445124558495726, \"phi\": 0.8989422212920504}, {\"truth_threshold\": 20.019383236946627, \"match_probability\": 0.9999990590539091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5341.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1197.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8169164657592773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18308350443840027, \"precision\": 1.0, \"recall\": 0.8169164657592773, \"specificity\": 1.0, \"npv\": 0.9890098571777344, \"accuracy\": 0.9895235896110535, \"f1\": 0.8992339422510313, \"f2\": 0.8479662147143809, \"f0_5\": 0.9570998494731561, \"p4\": 0.9444592821715734, \"phi\": 0.8988539627863162}, {\"truth_threshold\": 20.03004171127816, \"match_probability\": 0.9999990659798945, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.81661057472229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18338941037654877, \"precision\": 1.0, \"recall\": 0.81661057472229, \"specificity\": 1.0, \"npv\": 0.9889917373657227, \"accuracy\": 0.9895061254501343, \"f1\": 0.899048581291572, \"f2\": 0.8477025181797974, \"f0_5\": 0.9570158457015846, \"p4\": 0.9443528953607343, \"phi\": 0.898677424634541}, {\"truth_threshold\": 20.06120341264125, \"match_probability\": 0.9999990859380585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5338.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1200.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8164576292037964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1835423707962036, \"precision\": 1.0, \"recall\": 0.8164576292037964, \"specificity\": 1.0, \"npv\": 0.988982617855072, \"accuracy\": 0.9894973635673523, \"f1\": 0.8989558773997979, \"f2\": 0.8475706573515401, \"f0_5\": 0.9569738257439943, \"p4\": 0.9442996822172971, \"phi\": 0.8985891449842572}, {\"truth_threshold\": 20.065746761017227, \"match_probability\": 0.9999990888121003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5335.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1203.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8159987926483154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18400122225284576, \"precision\": 1.0, \"recall\": 0.8159987926483154, \"specificity\": 1.0, \"npv\": 0.9889553785324097, \"accuracy\": 0.9894710779190063, \"f1\": 0.8986776720289733, \"f2\": 0.8471750246133325, \"f0_5\": 0.9568476935217735, \"p4\": 0.944139963771271, \"phi\": 0.8983242637103452}, {\"truth_threshold\": 20.07114816866861, \"match_probability\": 0.9999990922171795, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5334.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1204.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8158458471298218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1841541826725006, \"precision\": 1.0, \"recall\": 0.8158458471298218, \"specificity\": 1.0, \"npv\": 0.9889463186264038, \"accuracy\": 0.9894623756408691, \"f1\": 0.8985849056603774, \"f2\": 0.8470431302801245, \"f0_5\": 0.9568056253139126, \"p4\": 0.9440866979329955, \"phi\": 0.8982358557857705}, {\"truth_threshold\": 20.077050665798115, \"match_probability\": 0.9999990959236001, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5333.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1205.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8156929016113281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18430712819099426, \"precision\": 1.0, \"recall\": 0.8156929016113281, \"specificity\": 1.0, \"npv\": 0.988937258720398, \"accuracy\": 0.9894536137580872, \"f1\": 0.8984921236627075, \"f2\": 0.8469112275686835, \"f0_5\": 0.9567635450304988, \"p4\": 0.9440334189077317, \"phi\": 0.8981475408431809}, {\"truth_threshold\": 20.07881737625771, \"match_probability\": 0.9999990970300449, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5331.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1207.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.815386950969696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18461303412914276, \"precision\": 1.0, \"recall\": 0.815386950969696, \"specificity\": 1.0, \"npv\": 0.9889190793037415, \"accuracy\": 0.9894360899925232, \"f1\": 0.8983065127643441, \"f2\": 0.846647397007909, \"f0_5\": 0.9566793482162085, \"p4\": 0.9439268212749682, \"phi\": 0.8979708897666967}, {\"truth_threshold\": 20.08498547061451, \"match_probability\": 0.9999991008823557, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5325.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1213.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8144692778587341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18553073704242706, \"precision\": 1.0, \"recall\": 0.8144692778587341, \"specificity\": 1.0, \"npv\": 0.9888646006584167, \"accuracy\": 0.9893835783004761, \"f1\": 0.8977493045603979, \"f2\": 0.8458557041649458, \"f0_5\": 0.9564264674186364, \"p4\": 0.9436067113353886, \"phi\": 0.897440666721188}, {\"truth_threshold\": 20.100027002181342, \"match_probability\": 0.9999991102078453, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5324.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1214.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8143163323402405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1856836974620819, \"precision\": 1.0, \"recall\": 0.8143163323402405, \"specificity\": 1.0, \"npv\": 0.9888555407524109, \"accuracy\": 0.9893748164176941, \"f1\": 0.8976563817231495, \"f2\": 0.8457237260134706, \"f0_5\": 0.9563842782208809, \"p4\": 0.9435533133876164, \"phi\": 0.8973522881254042}, {\"truth_threshold\": 20.10177612172907, \"match_probability\": 0.9999991112859722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5323.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1215.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.814163327217102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18583664298057556, \"precision\": 1.0, \"recall\": 0.814163327217102, \"specificity\": 1.0, \"npv\": 0.988846480846405, \"accuracy\": 0.9893660545349121, \"f1\": 0.8975634432172667, \"f2\": 0.8455917394757744, \"f0_5\": 0.9563420768954366, \"p4\": 0.9434999021995557, \"phi\": 0.8972639024473639}, {\"truth_threshold\": 20.121886098149595, \"match_probability\": 0.9999991235879614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5320.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1218.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8137044906616211, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1862955093383789, \"precision\": 1.0, \"recall\": 0.8137044906616211, \"specificity\": 1.0, \"npv\": 0.9888192415237427, \"accuracy\": 0.9893398284912109, \"f1\": 0.89728453364817, \"f2\": 0.8451957295373665, \"f0_5\": 0.9562154001006542, \"p4\": 0.9433395891401716, \"phi\": 0.8969987028983194}, {\"truth_threshold\": 20.136120140094526, \"match_probability\": 0.9999991321923691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5319.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1219.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8135515451431274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18644845485687256, \"precision\": 1.0, \"recall\": 0.8135515451431274, \"specificity\": 1.0, \"npv\": 0.988810122013092, \"accuracy\": 0.989331066608429, \"f1\": 0.8971915324281016, \"f2\": 0.8450637094467923, \"f0_5\": 0.9561731502121233, \"p4\": 0.9432861249374711, \"phi\": 0.8969102888698639}, {\"truth_threshold\": 20.143912404479597, \"match_probability\": 0.9999991368669202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5318.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1220.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8133985996246338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1866014003753662, \"precision\": 1.0, \"recall\": 0.8133985996246338, \"specificity\": 1.0, \"npv\": 0.9888010621070862, \"accuracy\": 0.989322304725647, \"f1\": 0.8970985155195681, \"f2\": 0.8449316809659994, \"f0_5\": 0.9561308881697231, \"p4\": 0.9432326474677245, \"phi\": 0.8968218677484526}, {\"truth_threshold\": 20.147247952526893, \"match_probability\": 0.9999991388601992, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5317.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1221.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8132456541061401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18675436079502106, \"precision\": 1.0, \"recall\": 0.8132456541061401, \"specificity\": 1.0, \"npv\": 0.9887920022010803, \"accuracy\": 0.989313542842865, \"f1\": 0.8970054829185997, \"f2\": 0.844799644094188, \"f0_5\": 0.9560886139682083, \"p4\": 0.9431791567255718, \"phi\": 0.8967334395319425}, {\"truth_threshold\": 20.149494220388352, \"match_probability\": 0.9999991401999445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5316.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1222.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8130927085876465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1869073063135147, \"precision\": 1.0, \"recall\": 0.8130927085876465, \"specificity\": 1.0, \"npv\": 0.9887829422950745, \"accuracy\": 0.9893048405647278, \"f1\": 0.8969124346212249, \"f2\": 0.844667598830558, \"f0_5\": 0.9560463276023308, \"p4\": 0.9431256527056501, \"phi\": 0.8966449040053901}, {\"truth_threshold\": 20.149635910741175, \"match_probability\": 0.9999991402843832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5314.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1224.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8127867579460144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1872132122516632, \"precision\": 1.0, \"recall\": 0.8127867579460144, \"specificity\": 1.0, \"npv\": 0.988764762878418, \"accuracy\": 0.9892873167991638, \"f1\": 0.8967262909213635, \"f2\": 0.8444034831246424, \"f0_5\": 0.9559617183564798, \"p4\": 0.9430186048110323, \"phi\": 0.8964680120596392}, {\"truth_threshold\": 20.1577113934946, \"match_probability\": 0.9999991450831924, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5313.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1225.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8126338124275208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18736617267131805, \"precision\": 1.0, \"recall\": 0.8126338124275208, \"specificity\": 1.0, \"npv\": 0.9887557029724121, \"accuracy\": 0.9892785549163818, \"f1\": 0.8966331955109273, \"f2\": 0.8442714126807565, \"f0_5\": 0.9559193954659949, \"p4\": 0.9429650609255958, \"phi\": 0.8963795554323127}, {\"truth_threshold\": 20.169540851968303, \"match_probability\": 0.9999991520644638, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5309.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1229.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8120220303535461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18797796964645386, \"precision\": 1.0, \"recall\": 0.8120220303535461, \"specificity\": 1.0, \"npv\": 0.9887194037437439, \"accuracy\": 0.9892435669898987, \"f1\": 0.8962606567063391, \"f2\": 0.8437430469470137, \"f0_5\": 0.9557499819975517, \"p4\": 0.9427507523375589, \"phi\": 0.8960256578432021}, {\"truth_threshold\": 20.171122861183484, \"match_probability\": 0.99999915299377, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5308.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1230.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8118690848350525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1881309300661087, \"precision\": 1.0, \"recall\": 0.8118690848350525, \"specificity\": 1.0, \"npv\": 0.9887102842330933, \"accuracy\": 0.9892348051071167, \"f1\": 0.8961674826945805, \"f2\": 0.8436109345200254, \"f0_5\": 0.9557075981274757, \"p4\": 0.9426971419020678, \"phi\": 0.8959371656652207}, {\"truth_threshold\": 20.177542448330158, \"match_probability\": 0.9999991567543334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5306.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1232.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8115631937980652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1884368360042572, \"precision\": 1.0, \"recall\": 0.8115631937980652, \"specificity\": 1.0, \"npv\": 0.9886921644210815, \"accuracy\": 0.9892172813415527, \"f1\": 0.8959810874704491, \"f2\": 0.8433466844681798, \"f0_5\": 0.9556227937468482, \"p4\": 0.942589881047194, \"phi\": 0.895760059654761}, {\"truth_threshold\": 20.17815498657906, \"match_probability\": 0.9999991571122816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5305.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1233.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8114101886749268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18858978152275085, \"precision\": 1.0, \"recall\": 0.8114101886749268, \"specificity\": 1.0, \"npv\": 0.9886831045150757, \"accuracy\": 0.9892085194587708, \"f1\": 0.8958878662501055, \"f2\": 0.8432145468417205, \"f0_5\": 0.9555803732257367, \"p4\": 0.9425362306170245, \"phi\": 0.895671546111566}, {\"truth_threshold\": 20.17981157719878, \"match_probability\": 0.9999991580795805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5303.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1235.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8111042976379395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18889568746089935, \"precision\": 1.0, \"recall\": 0.8111042976379395, \"specificity\": 1.0, \"npv\": 0.9886649250984192, \"accuracy\": 0.9891910552978516, \"f1\": 0.8957013765729246, \"f2\": 0.8429502463837227, \"f0_5\": 0.9554954954954955, \"p4\": 0.9424288897242312, \"phi\": 0.8954944976538569}, {\"truth_threshold\": 20.2267737467438, \"match_probability\": 0.9999991850442416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5302.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1236.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8109513521194458, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.189048632979393, \"precision\": 1.0, \"recall\": 0.8109513521194458, \"specificity\": 1.0, \"npv\": 0.9886558651924133, \"accuracy\": 0.9891822934150696, \"f1\": 0.8956081081081081, \"f2\": 0.8428180835505819, \"f0_5\": 0.9554530382757875, \"p4\": 0.9423751992508033, \"phi\": 0.8954059627350278}, {\"truth_threshold\": 20.233555151478107, \"match_probability\": 0.9999991888659584, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5299.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1239.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8104925155639648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18950749933719635, \"precision\": 1.0, \"recall\": 0.8104925155639648, \"specificity\": 1.0, \"npv\": 0.988628625869751, \"accuracy\": 0.9891560077667236, \"f1\": 0.8953282081608516, \"f2\": 0.8424215446249722, \"f0_5\": 0.9553255931347804, \"p4\": 0.9422140476575072, \"phi\": 0.8951403151927299}, {\"truth_threshold\": 20.240782015025403, \"match_probability\": 0.9999991929189929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5292.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1246.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8094218373298645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1905781626701355, \"precision\": 1.0, \"recall\": 0.8094218373298645, \"specificity\": 1.0, \"npv\": 0.9885651469230652, \"accuracy\": 0.9890947341918945, \"f1\": 0.8946745562130177, \"f2\": 0.8414959928762245, \"f0_5\": 0.9550277918140475, \"p4\": 0.9418375589020996, \"phi\": 0.8945201206371972}, {\"truth_threshold\": 20.241775658283075, \"match_probability\": 0.9999991934746708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5291.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1247.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8092688918113708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19073110818862915, \"precision\": 1.0, \"recall\": 0.8092688918113708, \"specificity\": 1.0, \"npv\": 0.9885560870170593, \"accuracy\": 0.9890860319137573, \"f1\": 0.8945811142108377, \"f2\": 0.8413637375568489, \"f0_5\": 0.9549851996245758, \"p4\": 0.9417837211864907, \"phi\": 0.8944315071655495}, {\"truth_threshold\": 20.250202775442713, \"match_probability\": 0.9999991981720364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5286.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1252.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8085041046142578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1914958655834198, \"precision\": 1.0, \"recall\": 0.8085041046142578, \"specificity\": 1.0, \"npv\": 0.9885107278823853, \"accuracy\": 0.9890422224998474, \"f1\": 0.8941136671177267, \"f2\": 0.8407023347541193, \"f0_5\": 0.954772054042338, \"p4\": 0.9415143312261759, \"phi\": 0.8939882319806925}, {\"truth_threshold\": 20.257345510189996, \"match_probability\": 0.9999992021320456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5285.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1253.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8083511590957642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19164882600307465, \"precision\": 1.0, \"recall\": 0.8083511590957642, \"specificity\": 1.0, \"npv\": 0.9885016083717346, \"accuracy\": 0.9890335202217102, \"f1\": 0.8940201302545885, \"f2\": 0.8405700289467825, \"f0_5\": 0.9547293879615579, \"p4\": 0.9414604129195268, \"phi\": 0.8938995755473117}, {\"truth_threshold\": 20.25938962189953, \"match_probability\": 0.9999992032617196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5284.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1254.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8081982135772705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1918017715215683, \"precision\": 1.0, \"recall\": 0.8081982135772705, \"specificity\": 1.0, \"npv\": 0.9884925484657288, \"accuracy\": 0.9890247583389282, \"f1\": 0.8939265775672475, \"f2\": 0.8404377147219748, \"f0_5\": 0.9546867095468671, \"p4\": 0.9414064811619577, \"phi\": 0.8938109119475347}, {\"truth_threshold\": 20.277078121881075, \"match_probability\": 0.999999212970667, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5283.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1255.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8080452680587769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19195473194122314, \"precision\": 1.0, \"recall\": 0.8080452680587769, \"specificity\": 1.0, \"npv\": 0.9884834885597229, \"accuracy\": 0.9890159964561462, \"f1\": 0.8938330090516877, \"f2\": 0.840305392078893, \"f0_5\": 0.9546440187929165, \"p4\": 0.9413525359480095, \"phi\": 0.8937222411791836}, {\"truth_threshold\": 20.295935771251195, \"match_probability\": 0.9999992231910773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5279.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1259.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8074334859848022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19256652891635895, \"precision\": 1.0, \"recall\": 0.8074334859848022, \"specificity\": 1.0, \"npv\": 0.9884471893310547, \"accuracy\": 0.9889810085296631, \"f1\": 0.8934585766268934, \"f2\": 0.8397760173077535, \"f0_5\": 0.9544731322774282, \"p4\": 0.9411366204191369, \"phi\": 0.8933673858301473}, {\"truth_threshold\": 20.298274166090508, \"match_probability\": 0.9999992244491486, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5278.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1260.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8072805404663086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1927194893360138, \"precision\": 1.0, \"recall\": 0.8072805404663086, \"specificity\": 1.0, \"npv\": 0.9884381294250488, \"accuracy\": 0.9889722466468811, \"f1\": 0.8933649289099526, \"f2\": 0.8396436525612472, \"f0_5\": 0.9544303797468354, \"p4\": 0.9410826078413008, \"phi\": 0.8932786791771624}, {\"truth_threshold\": 20.29893107059542, \"match_probability\": 0.9999992248022006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5277.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1261.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8071275353431702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19287243485450745, \"precision\": 1.0, \"recall\": 0.8071275353431702, \"specificity\": 1.0, \"npv\": 0.988429069519043, \"accuracy\": 0.9889634847640991, \"f1\": 0.8932712653406687, \"f2\": 0.8395112793916446, \"f0_5\": 0.9543876148448238, \"p4\": 0.9410285817742682, \"phi\": 0.893189965342513}, {\"truth_threshold\": 20.308299222380477, \"match_probability\": 0.9999992298196418, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5276.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1262.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8069745898246765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1930253952741623, \"precision\": 1.0, \"recall\": 0.8069745898246765, \"specificity\": 1.0, \"npv\": 0.9884200096130371, \"accuracy\": 0.9889547228813171, \"f1\": 0.8931775859150161, \"f2\": 0.8393788977981418, \"f0_5\": 0.9543448375660227, \"p4\": 0.9409745422125589, \"phi\": 0.8931012443240145}, {\"truth_threshold\": 20.31184283984179, \"match_probability\": 0.9999992317090732, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5275.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1263.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8068216443061829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19317834079265594, \"precision\": 1.0, \"recall\": 0.8068216443061829, \"specificity\": 1.0, \"npv\": 0.9884109497070312, \"accuracy\": 0.9889459609985352, \"f1\": 0.8930838906289681, \"f2\": 0.8392465077799345, \"f0_5\": 0.9543020479050582, \"p4\": 0.9409204891506902, \"phi\": 0.8930125161194806}, {\"truth_threshold\": 20.31794733876848, \"match_probability\": 0.9999992349530846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5274.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1264.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8066686987876892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1933313012123108, \"precision\": 1.0, \"recall\": 0.8066686987876892, \"specificity\": 1.0, \"npv\": 0.9884018898010254, \"accuracy\": 0.9889371991157532, \"f1\": 0.8929901794784965, \"f2\": 0.8391141093362184, \"f0_5\": 0.9542592458565535, \"p4\": 0.9408664225831761, \"phi\": 0.8929237807267245}, {\"truth_threshold\": 20.333652932057607, \"match_probability\": 0.9999992432364299, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5271.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1267.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8062098622322083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19379015266895294, \"precision\": 1.0, \"recall\": 0.8062098622322083, \"specificity\": 1.0, \"npv\": 0.988374650478363, \"accuracy\": 0.988910973072052, \"f1\": 0.8927089508002372, \"f2\": 0.8387168634439741, \"f0_5\": 0.9541307653319817, \"p4\": 0.9407041417918586, \"phi\": 0.8926575313972366}, {\"truth_threshold\": 20.334214273574265, \"match_probability\": 0.9999992435308233, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5270.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1268.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8060569167137146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1939430981874466, \"precision\": 1.0, \"recall\": 0.8060569167137146, \"specificity\": 1.0, \"npv\": 0.9883655905723572, \"accuracy\": 0.98890221118927, \"f1\": 0.8926151761517616, \"f2\": 0.8385844312901789, \"f0_5\": 0.9540879136794844, \"p4\": 0.940650021146845, \"phi\": 0.8925686666017324}, {\"truth_threshold\": 20.342784221232865, \"match_probability\": 0.9999992480111045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.805903971195221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19409605860710144, \"precision\": 1.0, \"recall\": 0.805903971195221, \"specificity\": 1.0, \"npv\": 0.9883565306663513, \"accuracy\": 0.988893449306488, \"f1\": 0.8925213856187008, \"f2\": 0.8384519907068521, \"f0_5\": 0.9540450496125154, \"p4\": 0.9405958869687123, \"phi\": 0.8924798952259363}, {\"truth_threshold\": 20.352434279058627, \"match_probability\": 0.9999992530243019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5268.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1270.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8057509660720825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1942490041255951, \"precision\": 1.0, \"recall\": 0.8057509660720825, \"specificity\": 1.0, \"npv\": 0.9883474707603455, \"accuracy\": 0.988884687423706, \"f1\": 0.8924275791970184, \"f2\": 0.838319541693189, \"f0_5\": 0.9540021731256791, \"p4\": 0.9405417392519567, \"phi\": 0.892391116648771}, {\"truth_threshold\": 20.359169239333916, \"match_probability\": 0.9999992565032931, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5266.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1272.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8054450750350952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1945549100637436, \"precision\": 1.0, \"recall\": 0.8054450750350952, \"specificity\": 1.0, \"npv\": 0.988329291343689, \"accuracy\": 0.9888672232627869, \"f1\": 0.8922399186716368, \"f2\": 0.8380546183716341, \"f0_5\": 0.9539163828708065, \"p4\": 0.9404334031805471, \"phi\": 0.8922135378815557}, {\"truth_threshold\": 20.38518537119621, \"match_probability\": 0.9999992697906006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5264.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1274.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8051391839981079, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1948608160018921, \"precision\": 1.0, \"recall\": 0.8051391839981079, \"specificity\": 1.0, \"npv\": 0.9883111715316772, \"accuracy\": 0.9888496994972229, \"f1\": 0.8920521945432978, \"f2\": 0.8377896613190731, \"f0_5\": 0.9538305428716387, \"p4\": 0.940325012888527, \"phi\": 0.8920359302825192}, {\"truth_threshold\": 20.389045175642675, \"match_probability\": 0.9999992717415995, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5263.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1275.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8049862384796143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19501376152038574, \"precision\": 1.0, \"recall\": 0.8049862384796143, \"specificity\": 1.0, \"npv\": 0.9883021116256714, \"accuracy\": 0.9888409376144409, \"f1\": 0.8919583086179137, \"f2\": 0.8376571701416521, \"f0_5\": 0.9537876042044219, \"p4\": 0.9402707973959971, \"phi\": 0.8919471156655735}, {\"truth_threshold\": 20.39230619681913, \"match_probability\": 0.999999273385871, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5262.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1276.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8048332929611206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1951667219400406, \"precision\": 1.0, \"recall\": 0.8048332929611206, \"specificity\": 1.0, \"npv\": 0.9882930517196655, \"accuracy\": 0.9888321757316589, \"f1\": 0.8918644067796611, \"f2\": 0.8375246705290634, \"f0_5\": 0.9537446530848981, \"p4\": 0.9402165683317595, \"phi\": 0.8918582938340773}, {\"truth_threshold\": 20.404505158321182, \"match_probability\": 0.9999992795039773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5261.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1277.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.804680347442627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19531966745853424, \"precision\": 1.0, \"recall\": 0.804680347442627, \"specificity\": 1.0, \"npv\": 0.9882839918136597, \"accuracy\": 0.988823413848877, \"f1\": 0.8917704890244936, \"f2\": 0.8373921624805017, \"f0_5\": 0.9537016895076499, \"p4\": 0.9401623256902896, \"phi\": 0.891769364075985}, {\"truth_threshold\": 20.40913663738063, \"match_probability\": 0.9999992818132729, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8043743968009949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19562557339668274, \"precision\": 1.0, \"recall\": 0.8043743968009949, \"specificity\": 1.0, \"npv\": 0.9882658123970032, \"accuracy\": 0.9888059496879578, \"f1\": 0.8915826057472239, \"f2\": 0.8371271210722359, \"f0_5\": 0.953615724958294, \"p4\": 0.9400537996535394, \"phi\": 0.8915916843022048}, {\"truth_threshold\": 20.41906607923458, \"match_probability\": 0.9999992867392647, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5257.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1281.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8040685057640076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19593147933483124, \"precision\": 1.0, \"recall\": 0.8040685057640076, \"specificity\": 1.0, \"npv\": 0.9882476925849915, \"accuracy\": 0.9887884259223938, \"f1\": 0.8913946587537092, \"f2\": 0.8368620459104078, \"f0_5\": 0.9535297105129508, \"p4\": 0.9399452192414902, \"phi\": 0.8914139756349757}, {\"truth_threshold\": 20.426200229420502, \"match_probability\": 0.9999992902576417, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5256.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1282.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8039155602455139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1960844248533249, \"precision\": 1.0, \"recall\": 0.8039155602455139, \"specificity\": 1.0, \"npv\": 0.9882386326789856, \"accuracy\": 0.9887796640396118, \"f1\": 0.8913006613532305, \"f2\": 0.8367294956698931, \"f0_5\": 0.9534866845657064, \"p4\": 0.939890908630885, \"phi\": 0.891325110460805}, {\"truth_threshold\": 20.449812786642454, \"match_probability\": 0.9999993017794251, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5254.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1284.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8036096692085266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1963903307914734, \"precision\": 1.0, \"recall\": 0.8036096692085266, \"specificity\": 1.0, \"npv\": 0.9882205128669739, \"accuracy\": 0.9887621998786926, \"f1\": 0.891112618724559, \"f2\": 0.8364643698656308, \"f0_5\": 0.9534005951948901, \"p4\": 0.9397822465728009, \"phi\": 0.891147358420317}, {\"truth_threshold\": 20.459434503534073, \"match_probability\": 0.9999993064205469, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5250.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1288.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.802997887134552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19700214266777039, \"precision\": 1.0, \"recall\": 0.802997887134552, \"specificity\": 1.0, \"npv\": 0.9881842732429504, \"accuracy\": 0.9887271523475647, \"f1\": 0.8907363420427553, \"f2\": 0.8359340169415961, \"f0_5\": 0.9532282663955262, \"p4\": 0.939564758953755, \"phi\": 0.8907916666986843}, {\"truth_threshold\": 20.474083570187208, \"match_probability\": 0.9999993134274854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5248.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1290.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8026919364929199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19730804860591888, \"precision\": 1.0, \"recall\": 0.8026919364929199, \"specificity\": 1.0, \"npv\": 0.988166093826294, \"accuracy\": 0.9887096881866455, \"f1\": 0.8905481079246563, \"f2\": 0.8356687898089172, \"f0_5\": 0.9531420268797676, \"p4\": 0.9394559333038953, \"phi\": 0.8906138277740789}, {\"truth_threshold\": 20.483533404486455, \"match_probability\": 0.9999993179099225, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5247.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1291.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8025389909744263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19746099412441254, \"precision\": 1.0, \"recall\": 0.8025389909744263, \"specificity\": 1.0, \"npv\": 0.9881570339202881, \"accuracy\": 0.9887009263038635, \"f1\": 0.8904539669070852, \"f2\": 0.8355361635720883, \"f0_5\": 0.9530988883237667, \"p4\": 0.9394014999994112, \"phi\": 0.8905248974413704}, {\"truth_threshold\": 20.498466458989768, \"match_probability\": 0.9999993249336853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5243.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1295.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8019272089004517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19807280600070953, \"precision\": 1.0, \"recall\": 0.8019272089004517, \"specificity\": 1.0, \"npv\": 0.9881207942962646, \"accuracy\": 0.9886658787727356, \"f1\": 0.8900772430184195, \"f2\": 0.835005574136009, \"f0_5\": 0.9529262086513995, \"p4\": 0.9391836301211172, \"phi\": 0.8901690027151903}, {\"truth_threshold\": 20.505485700724094, \"match_probability\": 0.9999993282101518, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5242.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1296.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.801774263381958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19822575151920319, \"precision\": 1.0, \"recall\": 0.801774263381958, \"specificity\": 1.0, \"npv\": 0.9881117343902588, \"accuracy\": 0.9886571764945984, \"f1\": 0.8899830220713073, \"f2\": 0.8348729056507613, \"f0_5\": 0.9528830073438522, \"p4\": 0.939129128458568, \"phi\": 0.8900800361016766}, {\"truth_threshold\": 20.519699559943795, \"match_probability\": 0.9999993347963224, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5240.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1298.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8014683127403259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19853165745735168, \"precision\": 1.0, \"recall\": 0.8014683127403259, \"specificity\": 1.0, \"npv\": 0.9880936145782471, \"accuracy\": 0.9886396527290344, \"f1\": 0.8897945321786381, \"f2\": 0.8346075433231397, \"f0_5\": 0.9527965670230563, \"p4\": 0.9390200840628155, \"phi\": 0.8899020810894475}, {\"truth_threshold\": 20.522424027733326, \"match_probability\": 0.9999993360513448, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5239.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1299.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8013153672218323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19868461787700653, \"precision\": 1.0, \"recall\": 0.8013153672218323, \"specificity\": 1.0, \"npv\": 0.9880845546722412, \"accuracy\": 0.9886308908462524, \"f1\": 0.8897002632249299, \"f2\": 0.8344748494791501, \"f0_5\": 0.9527533279988362, \"p4\": 0.9389655413184333, \"phi\": 0.8898130926862853}, {\"truth_threshold\": 20.531894942021683, \"match_probability\": 0.9999993403957153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5238.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1300.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.8011624217033386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19883756339550018, \"precision\": 1.0, \"recall\": 0.8011624217033386, \"specificity\": 1.0, \"npv\": 0.9880754947662354, \"accuracy\": 0.9886221289634705, \"f1\": 0.8896059782608695, \"f2\": 0.8343421471806308, \"f0_5\": 0.952710076391415, \"p4\": 0.9389109848689231, \"phi\": 0.8897240970154583}, {\"truth_threshold\": 20.533115433337013, \"match_probability\": 0.999999340953491, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5237.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1301.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.801009476184845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19899052381515503, \"precision\": 1.0, \"recall\": 0.801009476184845, \"specificity\": 1.0, \"npv\": 0.9880664348602295, \"accuracy\": 0.9886133670806885, \"f1\": 0.8895116772823779, \"f2\": 0.8342094364267737, \"f0_5\": 0.9526668121952995, \"p4\": 0.9388564147086876, \"phi\": 0.8896350940747406}, {\"truth_threshold\": 20.580981744602273, \"match_probability\": 0.9999993624608225, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5234.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1304.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.800550639629364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19944937527179718, \"precision\": 1.0, \"recall\": 0.800550639629364, \"specificity\": 1.0, \"npv\": 0.9880391955375671, \"accuracy\": 0.9885871410369873, \"f1\": 0.8892286782195039, \"f2\": 0.833811253425094, \"f0_5\": 0.9525369440198005, \"p4\": 0.9386926219076148, \"phi\": 0.8893679406542}, {\"truth_threshold\": 20.586160360462326, \"match_probability\": 0.999999364745193, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5230.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1308.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7999387979507446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20006118714809418, \"precision\": 1.0, \"recall\": 0.7999387979507446, \"specificity\": 1.0, \"npv\": 0.9880029559135437, \"accuracy\": 0.9885521531105042, \"f1\": 0.888851121685928, \"f2\": 0.8332802243324199, \"f0_5\": 0.9523636098769029, \"p4\": 0.9384740392159486, \"phi\": 0.8890117687520535}, {\"truth_threshold\": 20.592736575720018, \"match_probability\": 0.999999367634274, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5229.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1309.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.799785852432251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20021413266658783, \"precision\": 1.0, \"recall\": 0.799785852432251, \"specificity\": 1.0, \"npv\": 0.9879938960075378, \"accuracy\": 0.9885433912277222, \"f1\": 0.8887566924449732, \"f2\": 0.8331474459067588, \"f0_5\": 0.952320244773075, \"p4\": 0.9384193591680547, \"phi\": 0.8889227075627518}, {\"truth_threshold\": 20.597248679408057, \"match_probability\": 0.9999993696089399, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5228.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1310.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7996329069137573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20036707818508148, \"precision\": 1.0, \"recall\": 0.7996329069137573, \"specificity\": 1.0, \"npv\": 0.987984836101532, \"accuracy\": 0.9885346293449402, \"f1\": 0.8886622471528132, \"f2\": 0.8330146590184832, \"f0_5\": 0.9522768670309654, \"p4\": 0.9383646653589256, \"phi\": 0.8888336390834743}, {\"truth_threshold\": 20.605523928865065, \"match_probability\": 0.9999993732144887, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5227.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1311.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7994799613952637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20052003860473633, \"precision\": 1.0, \"recall\": 0.7994799613952637, \"specificity\": 1.0, \"npv\": 0.9879757761955261, \"accuracy\": 0.9885258674621582, \"f1\": 0.8885677858053549, \"f2\": 0.8328818636667835, \"f0_5\": 0.9522334766450484, \"p4\": 0.9383099577829338, \"phi\": 0.8887445633119846}, {\"truth_threshold\": 20.60757365285042, \"match_probability\": 0.9999993741043679, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5223.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1315.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7988681793212891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20113185048103333, \"precision\": 1.0, \"recall\": 0.7988681793212891, \"specificity\": 1.0, \"npv\": 0.9879395365715027, \"accuracy\": 0.988490879535675, \"f1\": 0.8881897797806309, \"f2\": 0.8323505976095618, \"f0_5\": 0.9520597885526796, \"p4\": 0.9380909896976816, \"phi\": 0.8883880862012042}, {\"truth_threshold\": 20.622749772113536, \"match_probability\": 0.9999993806538297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5222.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1316.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7987151741981506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20128479599952698, \"precision\": 1.0, \"recall\": 0.7987151741981506, \"specificity\": 1.0, \"npv\": 0.9879304766654968, \"accuracy\": 0.9884821176528931, \"f1\": 0.888095238095238, \"f2\": 0.8322177599286033, \"f0_5\": 0.9520163348647269, \"p4\": 0.938036213202856, \"phi\": 0.8882989739258514}, {\"truth_threshold\": 20.62689757965763, \"match_probability\": 0.999999382431917, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5221.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1317.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.798562228679657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20143774151802063, \"precision\": 1.0, \"recall\": 0.798562228679657, \"specificity\": 1.0, \"npv\": 0.987921416759491, \"accuracy\": 0.9884733557701111, \"f1\": 0.88800068032996, \"f2\": 0.8320849137793644, \"f0_5\": 0.9519728684997447, \"p4\": 0.9379814229073383, \"phi\": 0.8882098543448403}, {\"truth_threshold\": 20.6275572623424, \"match_probability\": 0.9999993827142397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5218.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1320.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.798103392124176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20189660787582397, \"precision\": 1.0, \"recall\": 0.798103392124176, \"specificity\": 1.0, \"npv\": 0.9878942370414734, \"accuracy\": 0.9884470701217651, \"f1\": 0.8877169105137802, \"f2\": 0.8316863245138667, \"f0_5\": 0.9518423932871215, \"p4\": 0.9378169691601268, \"phi\": 0.8879424517454104}, {\"truth_threshold\": 20.63407897020543, \"match_probability\": 0.9999993854983827, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5215.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1323.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7976445555686951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20235545933246613, \"precision\": 1.0, \"recall\": 0.7976445555686951, \"specificity\": 1.0, \"npv\": 0.9878670573234558, \"accuracy\": 0.988420844078064, \"f1\": 0.8874329958308517, \"f2\": 0.8312876590046865, \"f0_5\": 0.9517118037812979, \"p4\": 0.9376523910031369, \"phi\": 0.8876748821825012}, {\"truth_threshold\": 20.635212035117533, \"match_probability\": 0.9999993859808107, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5213.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1325.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7973386645317078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20266136527061462, \"precision\": 1.0, \"recall\": 0.7973386645317078, \"specificity\": 1.0, \"npv\": 0.9878489375114441, \"accuracy\": 0.9884033203125, \"f1\": 0.8872436388392477, \"f2\": 0.831021839630161, \"f0_5\": 0.9516246805403432, \"p4\": 0.9375426030397517, \"phi\": 0.8874965332733525}, {\"truth_threshold\": 20.640449132582415, \"match_probability\": 0.999999388205707, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5212.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1326.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7971856594085693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20281431078910828, \"precision\": 1.0, \"recall\": 0.7971856594085693, \"specificity\": 1.0, \"npv\": 0.9878398776054382, \"accuracy\": 0.988394558429718, \"f1\": 0.8871489361702127, \"f2\": 0.8308889172299452, \"f0_5\": 0.951581099832031, \"p4\": 0.9374876882834298, \"phi\": 0.8874073478310572}, {\"truth_threshold\": 20.64313822066484, \"match_probability\": 0.9999993893449883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5211.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1327.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7970327138900757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20296727120876312, \"precision\": 1.0, \"recall\": 0.7970327138900757, \"specificity\": 1.0, \"npv\": 0.9878308176994324, \"accuracy\": 0.9883858561515808, \"f1\": 0.8870542173802026, \"f2\": 0.8307559863533464, \"f0_5\": 0.9515375063910598, \"p4\": 0.9374327596697869, \"phi\": 0.8873181550606098}, {\"truth_threshold\": 20.643308447149597, \"match_probability\": 0.9999993894170365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5208.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1330.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7965738773345947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20342612266540527, \"precision\": 1.0, \"recall\": 0.7965738773345947, \"specificity\": 1.0, \"npv\": 0.9878036379814148, \"accuracy\": 0.9883595705032349, \"f1\": 0.8867699642431466, \"f2\": 0.8303571428571429, \"f0_5\": 0.9514066496163683, \"p4\": 0.9372678906281188, \"phi\": 0.8870505327577981}, {\"truth_threshold\": 20.67617848242885, \"match_probability\": 0.9999994031711312, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5207.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1331.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7964209318161011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20357908308506012, \"precision\": 1.0, \"recall\": 0.7964209318161011, \"specificity\": 1.0, \"npv\": 0.9877945780754089, \"accuracy\": 0.9883508086204529, \"f1\": 0.8866751809280545, \"f2\": 0.8302241780669026, \"f0_5\": 0.9513630051889206, \"p4\": 0.9372129065283628, \"phi\": 0.88696131065218}, {\"truth_threshold\": 20.690486067950296, \"match_probability\": 0.9999994090607834, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5206.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1332.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7962679862976074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20373202860355377, \"precision\": 1.0, \"recall\": 0.7962679862976074, \"specificity\": 1.0, \"npv\": 0.9877855181694031, \"accuracy\": 0.9883420467376709, \"f1\": 0.8865803814713896, \"f2\": 0.8300912047962242, \"f0_5\": 0.9513193480008771, \"p4\": 0.9371579085428554, \"phi\": 0.886871979992223}, {\"truth_threshold\": 20.692986770115404, \"match_probability\": 0.9999994100842029, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5202.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1336.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.795656144618988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20434384047985077, \"precision\": 1.0, \"recall\": 0.795656144618988, \"specificity\": 1.0, \"npv\": 0.9877492785453796, \"accuracy\": 0.9883070588111877, \"f1\": 0.8862010221465076, \"f2\": 0.8295592268929004, \"f0_5\": 0.951144591530754, \"p4\": 0.9369377776293596, \"phi\": 0.886514988735334}, {\"truth_threshold\": 20.703373533255792, \"match_probability\": 0.9999994143160799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5201.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1337.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7955031991004944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20449678599834442, \"precision\": 1.0, \"recall\": 0.7955031991004944, \"specificity\": 1.0, \"npv\": 0.9877402186393738, \"accuracy\": 0.9882982969284058, \"f1\": 0.8861061419200954, \"f2\": 0.8294262112078589, \"f0_5\": 0.9511008704557091, \"p4\": 0.9368827101296032, \"phi\": 0.8864257225498853}, {\"truth_threshold\": 20.715706846615486, \"match_probability\": 0.9999994193016318, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5200.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1338.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7953502535820007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20464974641799927, \"precision\": 1.0, \"recall\": 0.7953502535820007, \"specificity\": 1.0, \"npv\": 0.9877311587333679, \"accuracy\": 0.9882895350456238, \"f1\": 0.8860112455273471, \"f2\": 0.8292931870375095, \"f0_5\": 0.9510571365864364, \"p4\": 0.9368276287098766, \"phi\": 0.8863364490114157}, {\"truth_threshold\": 20.719124356022007, \"match_probability\": 0.9999994206755829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5198.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1340.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7950443625450134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20495563745498657, \"precision\": 1.0, \"recall\": 0.7950443625450134, \"specificity\": 1.0, \"npv\": 0.987713098526001, \"accuracy\": 0.9882720708847046, \"f1\": 0.8858214042263122, \"f2\": 0.8290271132376396, \"f0_5\": 0.950969630442737, \"p4\": 0.9367174240876533, \"phi\": 0.8861578798663442}, {\"truth_threshold\": 20.72912736237781, \"match_probability\": 0.9999994246784655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5197.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1341.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7948914170265198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20510859787464142, \"precision\": 1.0, \"recall\": 0.7948914170265198, \"specificity\": 1.0, \"npv\": 0.9877040386199951, \"accuracy\": 0.9882633090019226, \"f1\": 0.8857264593097571, \"f2\": 0.8288940636064946, \"f0_5\": 0.9509258581570665, \"p4\": 0.9366623008737192, \"phi\": 0.8860684829568819}, {\"truth_threshold\": 20.731054810948923, \"match_probability\": 0.9999994254465846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5195.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1343.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7945855259895325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20541450381278992, \"precision\": 1.0, \"recall\": 0.7945855259895325, \"specificity\": 1.0, \"npv\": 0.9876859188079834, \"accuracy\": 0.9882457852363586, \"f1\": 0.8855365209238899, \"f2\": 0.8286279388777236, \"f0_5\": 0.9508382751299509, \"p4\": 0.9365520126115887, \"phi\": 0.8858898696274756}, {\"truth_threshold\": 20.740015462805953, \"match_probability\": 0.9999994290041034, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5191.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1347.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7939736843109131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20602630078792572, \"precision\": 1.0, \"recall\": 0.7939736843109131, \"specificity\": 1.0, \"npv\": 0.98764967918396, \"accuracy\": 0.9882107973098755, \"f1\": 0.8851564498252196, \"f2\": 0.8280955875315062, \"f0_5\": 0.9506629550948649, \"p4\": 0.9363312685898252, \"phi\": 0.8855325545507531}, {\"truth_threshold\": 20.767759449391725, \"match_probability\": 0.99999943987982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5190.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1348.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7938207387924194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20617926120758057, \"precision\": 1.0, \"recall\": 0.7938207387924194, \"specificity\": 1.0, \"npv\": 0.9876406192779541, \"accuracy\": 0.9882020354270935, \"f1\": 0.8850613915416098, \"f2\": 0.8279624784634038, \"f0_5\": 0.9506190929738443, \"p4\": 0.9362760476556069, \"phi\": 0.8854432073479036}, {\"truth_threshold\": 20.78426702088045, \"match_probability\": 0.9999994462522835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5189.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1349.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7936677932739258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20633220672607422, \"precision\": 1.0, \"recall\": 0.7936677932739258, \"specificity\": 1.0, \"npv\": 0.9876315593719482, \"accuracy\": 0.9881932735443115, \"f1\": 0.8849663170461328, \"f2\": 0.8278293609010561, \"f0_5\": 0.9505752179966293, \"p4\": 0.9362208127383915, \"phi\": 0.8853538527670318}, {\"truth_threshold\": 20.796482937647276, \"match_probability\": 0.9999994509213048, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5187.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1351.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7933619022369385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20663811266422272, \"precision\": 1.0, \"recall\": 0.7933619022369385, \"specificity\": 1.0, \"npv\": 0.9876134395599365, \"accuracy\": 0.9881757497787476, \"f1\": 0.8847761194029851, \"f2\": 0.827563100290373, \"f0_5\": 0.9504874294510005, \"p4\": 0.9361103009319723, \"phi\": 0.8851750200708304}, {\"truth_threshold\": 20.79816900680746, \"match_probability\": 0.9999994515626346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5185.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1353.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7930559515953064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20694401860237122, \"precision\": 1.0, \"recall\": 0.7930559515953064, \"specificity\": 1.0, \"npv\": 0.9875953793525696, \"accuracy\": 0.9881582856178284, \"f1\": 0.8845858568625778, \"f2\": 0.8272968056929508, \"f0_5\": 0.9503995894127135, \"p4\": 0.9359997331245419, \"phi\": 0.8849962592078263}, {\"truth_threshold\": 20.799972883734448, \"match_probability\": 0.9999994522479456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5183.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1355.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7927500605583191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20724992454051971, \"precision\": 1.0, \"recall\": 0.7927500605583191, \"specificity\": 1.0, \"npv\": 0.9875772595405579, \"accuracy\": 0.9881407618522644, \"f1\": 0.8843955293916901, \"f2\": 0.8270304771022818, \"f0_5\": 0.9503116978364503, \"p4\": 0.9358891092700236, \"phi\": 0.8848174687870939}, {\"truth_threshold\": 20.81534096331088, \"match_probability\": 0.9999994580518168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5180.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1358.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7922912240028381, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20770877599716187, \"precision\": 1.0, \"recall\": 0.7922912240028381, \"specificity\": 1.0, \"npv\": 0.9875500798225403, \"accuracy\": 0.9881145358085632, \"f1\": 0.8841099163679809, \"f2\": 0.8266309204647007, \"f0_5\": 0.9501797637390857, \"p4\": 0.93572306829904, \"phi\": 0.8845492276952573}, {\"truth_threshold\": 20.835303946212154, \"match_probability\": 0.9999994654992594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5178.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1360.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7919853329658508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20801468193531036, \"precision\": 1.0, \"recall\": 0.7919853329658508, \"specificity\": 1.0, \"npv\": 0.9875319600105286, \"accuracy\": 0.9880970120429993, \"f1\": 0.8839194264254011, \"f2\": 0.8263645068624321, \"f0_5\": 0.950091743119266, \"p4\": 0.9356123041248865, \"phi\": 0.8843702618250163}, {\"truth_threshold\": 20.84526881661264, \"match_probability\": 0.9999994691783984, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5177.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1361.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7918323874473572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2081676423549652, \"precision\": 1.0, \"recall\": 0.7918323874473572, \"specificity\": 1.0, \"npv\": 0.9875229001045227, \"accuracy\": 0.9880882501602173, \"f1\": 0.8838241570635936, \"f2\": 0.8262312873056912, \"f0_5\": 0.950047713425824, \"p4\": 0.9355569009624201, \"phi\": 0.8842808185111165}, {\"truth_threshold\": 20.84761275708094, \"match_probability\": 0.9999994700401214, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5175.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1363.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7915264368057251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20847353339195251, \"precision\": 1.0, \"recall\": 0.7915264368057251, \"specificity\": 1.0, \"npv\": 0.9875048398971558, \"accuracy\": 0.9880707263946533, \"f1\": 0.88363356953812, \"f2\": 0.8259648226769241, \"f0_5\": 0.94995961524341, \"p4\": 0.935446052457776, \"phi\": 0.8841019096577931}, {\"truth_threshold\": 20.868558334698857, \"match_probability\": 0.999999477678686, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5171.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1367.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7909146547317505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2090853452682495, \"precision\": 1.0, \"recall\": 0.7909146547317505, \"specificity\": 1.0, \"npv\": 0.9874686002731323, \"accuracy\": 0.9880357384681702, \"f1\": 0.883252199163037, \"f2\": 0.8254317913354404, \"f0_5\": 0.9497832635368452, \"p4\": 0.9352241865674227, \"phi\": 0.8837440029847923}, {\"truth_threshold\": 20.885574291849363, \"match_probability\": 0.9999994838030463, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5170.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1368.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7907617092132568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20923830568790436, \"precision\": 1.0, \"recall\": 0.7907617092132568, \"specificity\": 1.0, \"npv\": 0.9874595403671265, \"accuracy\": 0.9880269765853882, \"f1\": 0.8831568158524086, \"f2\": 0.8252985122278271, \"f0_5\": 0.9497391432140495, \"p4\": 0.9351686848774463, \"phi\": 0.8836544062185638}, {\"truth_threshold\": 20.88904935746432, \"match_probability\": 0.9999994850449294, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5169.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1369.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7906087636947632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.209391251206398, \"precision\": 1.0, \"recall\": 0.7906087636947632, \"specificity\": 1.0, \"npv\": 0.9874504804611206, \"accuracy\": 0.9880182147026062, \"f1\": 0.88306141624669, \"f2\": 0.8251652246096868, \"f0_5\": 0.949695009921364, \"p4\": 0.9351131690889022, \"phi\": 0.8835649035690771}, {\"truth_threshold\": 20.889255520445754, \"match_probability\": 0.9999994851185119, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5168.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1370.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7904558181762695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20954419672489166, \"precision\": 1.0, \"recall\": 0.7904558181762695, \"specificity\": 1.0, \"npv\": 0.9874414205551147, \"accuracy\": 0.988009512424469, \"f1\": 0.8829660003417051, \"f2\": 0.8250319284802043, \"f0_5\": 0.9496508636530687, \"p4\": 0.9350576391959784, \"phi\": 0.8834753934934645}, {\"truth_threshold\": 20.891382756334817, \"match_probability\": 0.9999994858771384, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5167.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1371.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7903028726577759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2096971571445465, \"precision\": 1.0, \"recall\": 0.7903028726577759, \"specificity\": 1.0, \"npv\": 0.9874324202537537, \"accuracy\": 0.988000750541687, \"f1\": 0.8828705681332764, \"f2\": 0.8248986238385645, \"f0_5\": 0.9496067044034404, \"p4\": 0.9350020951928598, \"phi\": 0.8833858759894232}, {\"truth_threshold\": 20.903971217859652, \"match_probability\": 0.9999994903436805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5165.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1373.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7899969220161438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.210003063082695, \"precision\": 1.0, \"recall\": 0.7899969220161438, \"specificity\": 1.0, \"npv\": 0.9874143004417419, \"accuracy\": 0.987983226776123, \"f1\": 0.8826796547893703, \"f2\": 0.8246319890155507, \"f0_5\": 0.9495183469372748, \"p4\": 0.9348909648327627, \"phi\": 0.8832068186868393}, {\"truth_threshold\": 20.912017880414215, \"match_probability\": 0.9999994931783855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7893851399421692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2106148600578308, \"precision\": 1.0, \"recall\": 0.7893851399421692, \"specificity\": 1.0, \"npv\": 0.9873780608177185, \"accuracy\": 0.9879482388496399, \"f1\": 0.8822976322762629, \"f2\": 0.8240986171877495, \"f0_5\": 0.9493414759767493, \"p4\": 0.9346685345340157, \"phi\": 0.8828485132048597}, {\"truth_threshold\": 20.93356719515627, \"match_probability\": 0.9999995006924407, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5160.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1378.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7892321944236755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21076782047748566, \"precision\": 1.0, \"recall\": 0.7892321944236755, \"specificity\": 1.0, \"npv\": 0.9873690605163574, \"accuracy\": 0.9879394769668579, \"f1\": 0.8822020858266371, \"f2\": 0.8239652529381707, \"f0_5\": 0.9492972256972552, \"p4\": 0.9346128915964448, \"phi\": 0.8827589436278718}, {\"truth_threshold\": 20.933653362920744, \"match_probability\": 0.9999995007222618, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5157.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1381.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7887732982635498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2112266719341278, \"precision\": 1.0, \"recall\": 0.7887732982635498, \"specificity\": 1.0, \"npv\": 0.9873418807983398, \"accuracy\": 0.987913191318512, \"f1\": 0.881915348439504, \"f2\": 0.8235651090740682, \"f0_5\": 0.949164396672311, \"p4\": 0.9344458778193729, \"phi\": 0.8824901902063053}, {\"truth_threshold\": 20.948486031092326, \"match_probability\": 0.9999995058291472, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5155.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1383.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7884674072265625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2115325778722763, \"precision\": 1.0, \"recall\": 0.7884674072265625, \"specificity\": 1.0, \"npv\": 0.9873237609863281, \"accuracy\": 0.9878957271575928, \"f1\": 0.8817241084409476, \"f2\": 0.8232983038936978, \"f0_5\": 0.9490757787760512, \"p4\": 0.9343344644392138, \"phi\": 0.8823109839932851}, {\"truth_threshold\": 20.978683696240847, \"match_probability\": 0.9999995160653402, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5154.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1384.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7883144617080688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21168552339076996, \"precision\": 1.0, \"recall\": 0.7883144617080688, \"specificity\": 1.0, \"npv\": 0.987314760684967, \"accuracy\": 0.9878869652748108, \"f1\": 0.8816284639069449, \"f2\": 0.8231648885197725, \"f0_5\": 0.9490314502467408, \"p4\": 0.9342787364729402, \"phi\": 0.882221369700234}, {\"truth_threshold\": 20.97874125244928, \"match_probability\": 0.9999995160846464, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5152.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1386.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7880085706710815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21199142932891846, \"precision\": 1.0, \"recall\": 0.7880085706710815, \"specificity\": 1.0, \"npv\": 0.9872966408729553, \"accuracy\": 0.9878694415092468, \"f1\": 0.881437125748503, \"f2\": 0.8228980322003577, \"f0_5\": 0.9489427539969056, \"p4\": 0.9341672379587062, \"phi\": 0.8820421187294595}, {\"truth_threshold\": 20.998218533850817, \"match_probability\": 0.9999995225738988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5151.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1387.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7878556251525879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2121443897485733, \"precision\": 1.0, \"recall\": 0.7878556251525879, \"specificity\": 1.0, \"npv\": 0.9872875809669495, \"accuracy\": 0.9878606796264648, \"f1\": 0.8813414321156643, \"f2\": 0.8227645912532345, \"f0_5\": 0.9488983862648294, \"p4\": 0.9341114673990158, \"phi\": 0.8819523803189175}, {\"truth_threshold\": 21.001261395367266, \"match_probability\": 0.9999995235798008, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5149.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1389.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7875497341156006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2124502956867218, \"precision\": 1.0, \"recall\": 0.7875497341156006, \"specificity\": 1.0, \"npv\": 0.9872695207595825, \"accuracy\": 0.9878432154655457, \"f1\": 0.8811499957217421, \"f2\": 0.8224976837800709, \"f0_5\": 0.9488096115574556, \"p4\": 0.9339998836451411, \"phi\": 0.881773084529807}, {\"truth_threshold\": 21.0029338151147, \"match_probability\": 0.9999995241317626, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5146.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1392.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7870908379554749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21290914714336395, \"precision\": 1.0, \"recall\": 0.7870908379554749, \"specificity\": 1.0, \"npv\": 0.9872423410415649, \"accuracy\": 0.9878169298171997, \"f1\": 0.8808627182471757, \"f2\": 0.8220972586107739, \"f0_5\": 0.9486763513015264, \"p4\": 0.9338324013399524, \"phi\": 0.881504084797359}, {\"truth_threshold\": 21.019481680091108, \"match_probability\": 0.9999995295588351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5145.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1393.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7869378924369812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2130620926618576, \"precision\": 1.0, \"recall\": 0.7869378924369812, \"specificity\": 1.0, \"npv\": 0.9872332811355591, \"accuracy\": 0.9878081679344177, \"f1\": 0.8807669263031755, \"f2\": 0.8219637664951912, \"f0_5\": 0.948631905007744, \"p4\": 0.9337765454348622, \"phi\": 0.8814144032642309}, {\"truth_threshold\": 21.019746547303928, \"match_probability\": 0.9999995296451963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5144.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1394.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7867849469184875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21321505308151245, \"precision\": 1.0, \"recall\": 0.7867849469184875, \"specificity\": 1.0, \"npv\": 0.987224280834198, \"accuracy\": 0.9877994060516357, \"f1\": 0.8806711179592536, \"f2\": 0.8218302658486708, \"f0_5\": 0.948587445600059, \"p4\": 0.9337206752849462, \"phi\": 0.8813247142494004}, {\"truth_threshold\": 21.020561428143907, \"match_probability\": 0.9999995299107929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5143.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1395.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7866320013999939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2133679986000061, \"precision\": 1.0, \"recall\": 0.7866320013999939, \"specificity\": 1.0, \"npv\": 0.9872152209281921, \"accuracy\": 0.9877907037734985, \"f1\": 0.8805752932111977, \"f2\": 0.8216967566703947, \"f0_5\": 0.9485429730726669, \"p4\": 0.9336647908843119, \"phi\": 0.8812350177505376}, {\"truth_threshold\": 21.022141728550064, \"match_probability\": 0.9999995304254373, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5141.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1397.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7863261103630066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2136739045381546, \"precision\": 1.0, \"recall\": 0.7863261103630066, \"specificity\": 1.0, \"npv\": 0.9871971011161804, \"accuracy\": 0.9877731800079346, \"f1\": 0.8803835944858293, \"f2\": 0.8214297127153037, \"f0_5\": 0.9484539886355251, \"p4\": 0.9335529793073036, \"phi\": 0.8810555004689894}, {\"truth_threshold\": 21.022365305070895, \"match_probability\": 0.9999995304982023, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5140.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1398.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7861731648445129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21382686495780945, \"precision\": 1.0, \"recall\": 0.7861731648445129, \"specificity\": 1.0, \"npv\": 0.9871880412101746, \"accuracy\": 0.9877644181251526, \"f1\": 0.8802877205000856, \"f2\": 0.8212961779368528, \"f0_5\": 0.9484094767141487, \"p4\": 0.9334970521191289, \"phi\": 0.8809657814946036}, {\"truth_threshold\": 21.037485644296734, \"match_probability\": 0.9999995353931742, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5139.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1399.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7860202193260193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2139798104763031, \"precision\": 1.0, \"recall\": 0.7860202193260193, \"specificity\": 1.0, \"npv\": 0.9871790409088135, \"accuracy\": 0.9877556562423706, \"f1\": 0.8801918300933459, \"f2\": 0.8211626346233741, \"f0_5\": 0.9483649516498117, \"p4\": 0.9334411106566346, \"phi\": 0.8808760550268532}, {\"truth_threshold\": 21.042751459413953, \"match_probability\": 0.9999995370858903, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5138.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1400.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7858672142028809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21413275599479675, \"precision\": 1.0, \"recall\": 0.7858672142028809, \"specificity\": 1.0, \"npv\": 0.9871699810028076, \"accuracy\": 0.9877468943595886, \"f1\": 0.8800959232613909, \"f2\": 0.8210290827740492, \"f0_5\": 0.9483204134366925, \"p4\": 0.9333851549139122, \"phi\": 0.8807863210634027}, {\"truth_threshold\": 21.045027825362542, \"match_probability\": 0.9999995378157261, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5137.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1401.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7857142686843872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2142857164144516, \"precision\": 1.0, \"recall\": 0.7857142686843872, \"specificity\": 1.0, \"npv\": 0.9871609210968018, \"accuracy\": 0.9877381920814514, \"f1\": 0.88, \"f2\": 0.8208955223880597, \"f0_5\": 0.9482758620689655, \"p4\": 0.9333291848850499, \"phi\": 0.8806965796019157}, {\"truth_threshold\": 21.06191439507974, \"match_probability\": 0.9999995431939969, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5136.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1402.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7855613231658936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21443866193294525, \"precision\": 1.0, \"recall\": 0.7855613231658936, \"specificity\": 1.0, \"npv\": 0.9871518611907959, \"accuracy\": 0.9877294301986694, \"f1\": 0.8799040603049512, \"f2\": 0.820761953464587, \"f0_5\": 0.948231297540802, \"p4\": 0.9332732005641329, \"phi\": 0.880606830640055}, {\"truth_threshold\": 21.063630150035795, \"match_probability\": 0.9999995437369397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5135.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1403.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7854083776473999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2145916223526001, \"precision\": 1.0, \"recall\": 0.7854083776473999, \"specificity\": 1.0, \"npv\": 0.98714280128479, \"accuracy\": 0.9877206683158875, \"f1\": 0.8798081041720209, \"f2\": 0.8206283760028127, \"f0_5\": 0.9481867198463697, \"p4\": 0.9332172019452426, \"phi\": 0.8805170741754813}, {\"truth_threshold\": 21.07020874908476, \"match_probability\": 0.9999995458127334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5133.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1405.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7851024866104126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2148975282907486, \"precision\": 1.0, \"recall\": 0.7851024866104126, \"specificity\": 1.0, \"npv\": 0.9871247410774231, \"accuracy\": 0.9877031445503235, \"f1\": 0.8796161425756148, \"f2\": 0.8203611954610835, \"f0_5\": 0.9480975249353528, \"p4\": 0.9331051617898537, \"phi\": 0.8803374368308523}, {\"truth_threshold\": 21.085656456365793, \"match_probability\": 0.9999995506500132, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5132.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1406.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.784949541091919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21505047380924225, \"precision\": 1.0, \"recall\": 0.784949541091919, \"specificity\": 1.0, \"npv\": 0.9871156811714172, \"accuracy\": 0.9876943826675415, \"f1\": 0.8795201371036847, \"f2\": 0.8202275923794912, \"f0_5\": 0.9480529077070864, \"p4\": 0.933049120241502, \"phi\": 0.8802476578346368}, {\"truth_threshold\": 21.098040180821624, \"match_probability\": 0.9999995544906097, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5131.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1407.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7847965955734253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2152034193277359, \"precision\": 1.0, \"recall\": 0.7847965955734253, \"specificity\": 1.0, \"npv\": 0.9871066212654114, \"accuracy\": 0.9876856803894043, \"f1\": 0.8794241151769646, \"f2\": 0.8200939807563213, \"f0_5\": 0.9480082772891878, \"p4\": 0.9329930643714716, \"phi\": 0.8801578713263394}, {\"truth_threshold\": 21.098338352045946, \"match_probability\": 0.9999995545826765, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5128.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1410.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7843376994132996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21566228568553925, \"precision\": 1.0, \"recall\": 0.7843376994132996, \"specificity\": 1.0, \"npv\": 0.9870795011520386, \"accuracy\": 0.9876593947410583, \"f1\": 0.87913595062575, \"f2\": 0.819693094629156, \"f0_5\": 0.9478743068391867, \"p4\": 0.9328248107719453, \"phi\": 0.8798884667055059}, {\"truth_threshold\": 21.10082810188429, \"match_probability\": 0.9999995553506981, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7841847538948059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2158152312040329, \"precision\": 1.0, \"recall\": 0.7841847538948059, \"specificity\": 1.0, \"npv\": 0.9870704412460327, \"accuracy\": 0.9876506328582764, \"f1\": 0.8790398628375482, \"f2\": 0.8195594488314843, \"f0_5\": 0.9478296236042298, \"p4\": 0.9327686975558211, \"phi\": 0.8797986501254254}, {\"truth_threshold\": 21.11490124516979, \"match_probability\": 0.9999995596670564, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5126.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1412.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7840318083763123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21596819162368774, \"precision\": 1.0, \"recall\": 0.7840318083763123, \"specificity\": 1.0, \"npv\": 0.9870614409446716, \"accuracy\": 0.9876418709754944, \"f1\": 0.8789437585733882, \"f2\": 0.8194257944881387, \"f0_5\": 0.9477849271503587, \"p4\": 0.9327125699883125, \"phi\": 0.8797088260215292}, {\"truth_threshold\": 21.118043505828723, \"match_probability\": 0.9999995606250791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5125.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1413.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7838788628578186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2161211371421814, \"precision\": 1.0, \"recall\": 0.7838788628578186, \"specificity\": 1.0, \"npv\": 0.9870523810386658, \"accuracy\": 0.9876331686973572, \"f1\": 0.878847637829032, \"f2\": 0.8192921315982991, \"f0_5\": 0.9477402174717064, \"p4\": 0.9326564280634683, \"phi\": 0.8796189943914674}, {\"truth_threshold\": 21.12155562908498, \"match_probability\": 0.9999995616934001, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5124.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1414.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.783725917339325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21627408266067505, \"precision\": 1.0, \"recall\": 0.783725917339325, \"specificity\": 1.0, \"npv\": 0.9870433211326599, \"accuracy\": 0.9876244068145752, \"f1\": 0.8787515006002401, \"f2\": 0.8191584601611459, \"f0_5\": 0.9476954945624029, \"p4\": 0.9326002717753344, \"phi\": 0.879529053249661}, {\"truth_threshold\": 21.121656478771627, \"match_probability\": 0.9999995617240383, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5123.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1415.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7835729718208313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2164270430803299, \"precision\": 1.0, \"recall\": 0.7835729718208313, \"specificity\": 1.0, \"npv\": 0.987034261226654, \"accuracy\": 0.9876156449317932, \"f1\": 0.8786553468827716, \"f2\": 0.8190247801758593, \"f0_5\": 0.9476507584165742, \"p4\": 0.9325441011179532, \"phi\": 0.8794392065507268}, {\"truth_threshold\": 21.156037066255124, \"match_probability\": 0.9999995720450364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5122.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1416.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7834200263023376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21657998859882355, \"precision\": 1.0, \"recall\": 0.7834200263023376, \"specificity\": 1.0, \"npv\": 0.987025260925293, \"accuracy\": 0.9876068830490112, \"f1\": 0.8785591766723843, \"f2\": 0.8188910916416192, \"f0_5\": 0.9476060090283431, \"p4\": 0.9324879160853639, \"phi\": 0.8793493523185668}, {\"truth_threshold\": 21.16628021750805, \"match_probability\": 0.9999995750727592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5120.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1418.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7831140756607056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21688589453697205, \"precision\": 1.0, \"recall\": 0.7831140756607056, \"specificity\": 1.0, \"npv\": 0.9870071411132812, \"accuracy\": 0.9875893592834473, \"f1\": 0.8783667867558758, \"f2\": 0.8186236889229982, \"f0_5\": 0.9475164705011474, \"p4\": 0.9323755028707009, \"phi\": 0.8791696212451482}, {\"truth_threshold\": 21.17806337258512, \"match_probability\": 0.9999995785291999, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5119.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1419.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7829611301422119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2170388549566269, \"precision\": 1.0, \"recall\": 0.7829611301422119, \"specificity\": 1.0, \"npv\": 0.9869981408119202, \"accuracy\": 0.9875806570053101, \"f1\": 0.8782705670412627, \"f2\": 0.8184899747369767, \"f0_5\": 0.9474716813504109, \"p4\": 0.9323192746766891, \"phi\": 0.8790797443991766}, {\"truth_threshold\": 21.186243200409322, \"match_probability\": 0.9999995809121026, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5118.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1420.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7828081846237183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21719180047512054, \"precision\": 1.0, \"recall\": 0.7828081846237183, \"specificity\": 1.0, \"npv\": 0.9869890809059143, \"accuracy\": 0.9875718951225281, \"f1\": 0.8781743308167468, \"f2\": 0.8183562519987209, \"f0_5\": 0.9474268789337282, \"p4\": 0.9322630320835928, \"phi\": 0.8789898600105528}, {\"truth_threshold\": 21.19048642958622, \"match_probability\": 0.9999995821429052, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5105.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1433.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.780819833278656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2191801816225052, \"precision\": 1.0, \"recall\": 0.780819833278656, \"specificity\": 1.0, \"npv\": 0.9868715405464172, \"accuracy\": 0.9874581098556519, \"f1\": 0.8769217555612815, \"f2\": 0.8166170777745785, \"f0_5\": 0.9468432376289042, \"p4\": 0.9315305653324585, \"phi\": 0.8778204711740926}, {\"truth_threshold\": 21.192536153571577, \"match_probability\": 0.9999995827361582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5102.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1436.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7803609371185303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21963903307914734, \"precision\": 1.0, \"recall\": 0.7803609371185303, \"specificity\": 1.0, \"npv\": 0.9868444204330444, \"accuracy\": 0.9874318242073059, \"f1\": 0.8766323024054983, \"f2\": 0.8162155244128751, \"f0_5\": 0.9467082312773696, \"p4\": 0.931361187430944, \"phi\": 0.8775504776778984}, {\"truth_threshold\": 21.20113367378573, \"match_probability\": 0.9999995852153825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5101.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1437.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7802079916000366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.219791978597641, \"precision\": 1.0, \"recall\": 0.7802079916000366, \"specificity\": 1.0, \"npv\": 0.9868353605270386, \"accuracy\": 0.9874230623245239, \"f1\": 0.8765357848612424, \"f2\": 0.8160816561610086, \"f0_5\": 0.94666320243486, \"p4\": 0.9313046991361792, \"phi\": 0.8774604646831515}, {\"truth_threshold\": 21.203906251228535, \"match_probability\": 0.9999995860117515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5100.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1438.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.780055046081543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21994493901729584, \"precision\": 1.0, \"recall\": 0.780055046081543, \"specificity\": 1.0, \"npv\": 0.9868263006210327, \"accuracy\": 0.9874143600463867, \"f1\": 0.876439250730366, \"f2\": 0.8159477793421221, \"f0_5\": 0.9466181602197639, \"p4\": 0.9312481963342308, \"phi\": 0.8773704441030994}, {\"truth_threshold\": 21.217253339149007, \"match_probability\": 0.9999995898240986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5099.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1439.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7799021005630493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2200978845357895, \"precision\": 1.0, \"recall\": 0.7799021005630493, \"specificity\": 1.0, \"npv\": 0.9868173003196716, \"accuracy\": 0.9874055981636047, \"f1\": 0.8763427000085933, \"f2\": 0.8158138939553934, \"f0_5\": 0.9465731046261231, \"p4\": 0.9311916790190619, \"phi\": 0.8772804159353614}, {\"truth_threshold\": 21.228100721386, \"match_probability\": 0.999999592896576, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5092.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1446.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.778831422328949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22116854786872864, \"precision\": 1.0, \"recall\": 0.778831422328949, \"specificity\": 1.0, \"npv\": 0.9867540001869202, \"accuracy\": 0.9873443245887756, \"f1\": 0.8756663800515907, \"f2\": 0.8148764562796057, \"f0_5\": 0.9462573403701776, \"p4\": 0.9307956509348793, \"phi\": 0.876649903817614}, {\"truth_threshold\": 21.230378462589726, \"match_probability\": 0.9999995935388075, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5088.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1450.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7782196402549744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22178035974502563, \"precision\": 1.0, \"recall\": 0.7782196402549744, \"specificity\": 1.0, \"npv\": 0.9867178201675415, \"accuracy\": 0.9873093366622925, \"f1\": 0.8752795458455187, \"f2\": 0.8143405889884763, \"f0_5\": 0.9460766084046114, \"p4\": 0.9305690289496695, \"phi\": 0.8762893999680031}, {\"truth_threshold\": 21.243941914618496, \"match_probability\": 0.9999995973422312, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5087.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1451.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7780666947364807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22193332016468048, \"precision\": 1.0, \"recall\": 0.7780666947364807, \"specificity\": 1.0, \"npv\": 0.9867088198661804, \"accuracy\": 0.9873005747795105, \"f1\": 0.8751827956989248, \"f2\": 0.8142066007234546, \"f0_5\": 0.946031391802425, \"p4\": 0.9305123370037371, \"phi\": 0.8761992805427606}, {\"truth_threshold\": 21.257800642364423, \"match_probability\": 0.999999601191697, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5085.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7777608036994934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22223921120166779, \"precision\": 1.0, \"recall\": 0.7777608036994934, \"specificity\": 1.0, \"npv\": 0.9866907000541687, \"accuracy\": 0.9872830510139465, \"f1\": 0.8749892454615847, \"f2\": 0.813938598456958, \"f0_5\": 0.9459409182230821, \"p4\": 0.9303989093297628, \"phi\": 0.8760190188336472}, {\"truth_threshold\": 21.264971437808285, \"match_probability\": 0.9999996031690215, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5084.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1454.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7776078581809998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22239217162132263, \"precision\": 1.0, \"recall\": 0.7776078581809998, \"specificity\": 1.0, \"npv\": 0.9866816997528076, \"accuracy\": 0.9872742891311646, \"f1\": 0.874892445362244, \"f2\": 0.8138045844538353, \"f0_5\": 0.9458956612339063, \"p4\": 0.9303421735895491, \"phi\": 0.8759288765449815}, {\"truth_threshold\": 21.266722015413304, \"match_probability\": 0.9999996036502471, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5083.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1455.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7774548530578613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22254511713981628, \"precision\": 1.0, \"recall\": 0.7774548530578613, \"specificity\": 1.0, \"npv\": 0.9866726398468018, \"accuracy\": 0.9872655272483826, \"f1\": 0.8747956286033904, \"f2\": 0.8136705618696974, \"f0_5\": 0.9458503907703759, \"p4\": 0.9302854232390642, \"phi\": 0.8758387266303781}, {\"truth_threshold\": 21.272579824163877, \"match_probability\": 0.999999605256292, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5080.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1458.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7769960165023804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22300398349761963, \"precision\": 1.0, \"recall\": 0.7769960165023804, \"specificity\": 1.0, \"npv\": 0.986645519733429, \"accuracy\": 0.9872393012046814, \"f1\": 0.8745050783267344, \"f2\": 0.8132684426229508, \"f0_5\": 0.945714498473453, \"p4\": 0.9301150844650232, \"phi\": 0.8755682311069299}, {\"truth_threshold\": 21.280769789898937, \"match_probability\": 0.9999996074908439, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5078.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1460.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7766901254653931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22330987453460693, \"precision\": 1.0, \"recall\": 0.7766901254653931, \"specificity\": 1.0, \"npv\": 0.986627459526062, \"accuracy\": 0.9872217774391174, \"f1\": 0.8743112947658402, \"f2\": 0.8130003202049312, \"f0_5\": 0.9456238361266294, \"p4\": 0.9300014521191545, \"phi\": 0.8753877601617156}, {\"truth_threshold\": 21.2835958339777, \"match_probability\": 0.9999996082589634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5077.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1461.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7765371799468994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22346283495426178, \"precision\": 1.0, \"recall\": 0.7765371799468994, \"specificity\": 1.0, \"npv\": 0.9866183996200562, \"accuracy\": 0.9872130155563354, \"f1\": 0.874214377959535, \"f2\": 0.8128662461173909, \"f0_5\": 0.9455784846904567, \"p4\": 0.9299446139789442, \"phi\": 0.8752975644314168}, {\"truth_threshold\": 21.2978096931974, \"match_probability\": 0.9999996120995602, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5076.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1462.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7763842344284058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22361578047275543, \"precision\": 1.0, \"recall\": 0.7763842344284058, \"specificity\": 1.0, \"npv\": 0.9866093993186951, \"accuracy\": 0.9872043132781982, \"f1\": 0.8741174444635784, \"f2\": 0.8127321634430639, \"f0_5\": 0.9455331197377245, \"p4\": 0.9298877611857317, \"phi\": 0.875207361058349}, {\"truth_threshold\": 21.299342748300262, \"match_probability\": 0.9999996125115369, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5071.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1467.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7756194472312927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22438053786754608, \"precision\": 1.0, \"recall\": 0.7756194472312927, \"specificity\": 1.0, \"npv\": 0.9865642189979553, \"accuracy\": 0.9871605038642883, \"f1\": 0.8736325264880695, \"f2\": 0.812061621240752, \"f0_5\": 0.9453060920140184, \"p4\": 0.9296032772103832, \"phi\": 0.8747562294671296}, {\"truth_threshold\": 21.300669347336644, \"match_probability\": 0.9999996128676797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5070.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7754665017127991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22453349828720093, \"precision\": 1.0, \"recall\": 0.7754665017127991, \"specificity\": 1.0, \"npv\": 0.9865551590919495, \"accuracy\": 0.9871518015861511, \"f1\": 0.8735354927636113, \"f2\": 0.8119274870283775, \"f0_5\": 0.945260645834887, \"p4\": 0.9295463363705587, \"phi\": 0.8746659801868233}, {\"truth_threshold\": 21.304789229513375, \"match_probability\": 0.9999996139716301, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5069.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1469.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7753135561943054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22468644380569458, \"precision\": 1.0, \"recall\": 0.7753135561943054, \"specificity\": 1.0, \"npv\": 0.9865461587905884, \"accuracy\": 0.9871430397033691, \"f1\": 0.8734384423192901, \"f2\": 0.8117933442234394, \"f0_5\": 0.9452151860968151, \"p4\": 0.9294893808348341, \"phi\": 0.874575620737682}, {\"truth_threshold\": 21.311056110477033, \"match_probability\": 0.9999996156448501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5067.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1471.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7750076651573181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22499234974384308, \"precision\": 1.0, \"recall\": 0.7750076651573181, \"specificity\": 1.0, \"npv\": 0.9865280985832214, \"accuracy\": 0.9871255159378052, \"f1\": 0.8732442912537699, \"f2\": 0.8115250328325699, \"f0_5\": 0.9451242259195702, \"p4\": 0.9293754256511138, \"phi\": 0.8743950838498338}, {\"truth_threshold\": 21.3128406227817, \"match_probability\": 0.9999996161199762, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5066.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1472.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7748547196388245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22514531016349792, \"precision\": 1.0, \"recall\": 0.7748547196388245, \"specificity\": 1.0, \"npv\": 0.9865190386772156, \"accuracy\": 0.9871167540550232, \"f1\": 0.8731471906239228, \"f2\": 0.8113908642449869, \"f0_5\": 0.9450787254682487, \"p4\": 0.9293184259908239, \"phi\": 0.8743048039067499}, {\"truth_threshold\": 21.317349063639288, \"match_probability\": 0.9999996173177333, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5065.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1473.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.774701714515686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22529825568199158, \"precision\": 1.0, \"recall\": 0.774701714515686, \"specificity\": 1.0, \"npv\": 0.9865099787712097, \"accuracy\": 0.9871079921722412, \"f1\": 0.8730500732569163, \"f2\": 0.811256687061537, \"f0_5\": 0.9450332114336891, \"p4\": 0.9292614116100459, \"phi\": 0.8742145162943321}, {\"truth_threshold\": 21.31773537251406, \"match_probability\": 0.9999996174201901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5064.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1474.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7745487689971924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22545120120048523, \"precision\": 1.0, \"recall\": 0.7745487689971924, \"specificity\": 1.0, \"npv\": 0.9865009784698486, \"accuracy\": 0.9870992302894592, \"f1\": 0.8729529391484226, \"f2\": 0.8111225012813942, \"f0_5\": 0.9449876838098081, \"p4\": 0.9292043825026243, \"phi\": 0.8741242210101586}, {\"truth_threshold\": 21.33250543445865, \"match_probability\": 0.9999996213169929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5063.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1475.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7743958234786987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22560416162014008, \"precision\": 1.0, \"recall\": 0.7743958234786987, \"specificity\": 1.0, \"npv\": 0.9864919185638428, \"accuracy\": 0.987090528011322, \"f1\": 0.8728557882941126, \"f2\": 0.8109883069037321, \"f0_5\": 0.9449421425905189, \"p4\": 0.9291473386623998, \"phi\": 0.8740339180518062}, {\"truth_threshold\": 21.34167464219129, \"match_probability\": 0.9999996237161217, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5062.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1476.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7742428779602051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22575710713863373, \"precision\": 1.0, \"recall\": 0.7742428779602051, \"specificity\": 1.0, \"npv\": 0.9864829182624817, \"accuracy\": 0.98708176612854, \"f1\": 0.8727586206896552, \"f2\": 0.8108541039277247, \"f0_5\": 0.9448965877697305, \"p4\": 0.9290902800832103, \"phi\": 0.8739436074168507}, {\"truth_threshold\": 21.349738448993627, \"match_probability\": 0.999999625813457, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5061.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1477.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7740899324417114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22591006755828857, \"precision\": 1.0, \"recall\": 0.7740899324417114, \"specificity\": 1.0, \"npv\": 0.9864738583564758, \"accuracy\": 0.9870730042457581, \"f1\": 0.8726614363307181, \"f2\": 0.8107198923525454, \"f0_5\": 0.9448510193413486, \"p4\": 0.9290332067588897, \"phi\": 0.8738532891028665}, {\"truth_threshold\": 21.355909344673584, \"match_probability\": 0.9999996274105609, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5060.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1478.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7739369869232178, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22606301307678223, \"precision\": 1.0, \"recall\": 0.7739369869232178, \"specificity\": 1.0, \"npv\": 0.9864648580551147, \"accuracy\": 0.9870642423629761, \"f1\": 0.8725642352129678, \"f2\": 0.8105856721773677, \"f0_5\": 0.9448054372992756, \"p4\": 0.9289761186832688, \"phi\": 0.8737628605113518}, {\"truth_threshold\": 21.358925295450444, \"match_probability\": 0.9999996281886445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5056.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1482.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7733252048492432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22667482495307922, \"precision\": 1.0, \"recall\": 0.7733252048492432, \"specificity\": 1.0, \"npv\": 0.9864286780357361, \"accuracy\": 0.9870292544364929, \"f1\": 0.8721752630671037, \"f2\": 0.8100487054601384, \"f0_5\": 0.9446229728719827, \"p4\": 0.9287476187442764, \"phi\": 0.8734014796277659}, {\"truth_threshold\": 21.366325099142593, \"match_probability\": 0.9999996300908387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5055.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1483.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7731721997261047, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22682777047157288, \"precision\": 1.0, \"recall\": 0.7731721997261047, \"specificity\": 1.0, \"npv\": 0.986419677734375, \"accuracy\": 0.9870204925537109, \"f1\": 0.8720779780902269, \"f2\": 0.809914442272567, \"f0_5\": 0.9445773226698557, \"p4\": 0.9286904568194942, \"phi\": 0.8733111151789247}, {\"truth_threshold\": 21.367221519807998, \"match_probability\": 0.9999996303206108, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5053.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1485.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7728663086891174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22713367640972137, \"precision\": 1.0, \"recall\": 0.7728663086891174, \"specificity\": 1.0, \"npv\": 0.9864016175270081, \"accuracy\": 0.987002968788147, \"f1\": 0.8718833577775861, \"f2\": 0.8096458900817177, \"f0_5\": 0.9444859813084112, \"p4\": 0.928576088598572, \"phi\": 0.8731303631906747}, {\"truth_threshold\": 21.367541171448835, \"match_probability\": 0.9999996304025099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5051.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1487.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7725604176521301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22743958234786987, \"precision\": 1.0, \"recall\": 0.7725604176521301, \"specificity\": 1.0, \"npv\": 0.9863835573196411, \"accuracy\": 0.9869855046272278, \"f1\": 0.871688670290793, \"f2\": 0.8093773034644105, \"f0_5\": 0.9443945852965373, \"p4\": 0.9284616611745321, \"phi\": 0.8729494777155536}, {\"truth_threshold\": 21.39102165812931, \"match_probability\": 0.9999996363691802, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5050.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1488.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7724074721336365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22759254276752472, \"precision\": 1.0, \"recall\": 0.7724074721336365, \"specificity\": 1.0, \"npv\": 0.9863744974136353, \"accuracy\": 0.9869767427444458, \"f1\": 0.8715913013462202, \"f2\": 0.8092429972437665, \"f0_5\": 0.9443488667813599, \"p4\": 0.9284044252458401, \"phi\": 0.8728590747524322}, {\"truth_threshold\": 21.395179082877938, \"match_probability\": 0.999999637415549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5049.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1489.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7722545266151428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22774548828601837, \"precision\": 1.0, \"recall\": 0.7722545266151428, \"specificity\": 1.0, \"npv\": 0.9863654971122742, \"accuracy\": 0.9869679808616638, \"f1\": 0.8714939155950634, \"f2\": 0.8091086824140252, \"f0_5\": 0.9443031345851725, \"p4\": 0.9283471744977584, \"phi\": 0.8727686640810757}, {\"truth_threshold\": 21.407584551253155, \"match_probability\": 0.9999996405199783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5048.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1490.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7721015810966492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22789843380451202, \"precision\": 1.0, \"recall\": 0.7721015810966492, \"specificity\": 1.0, \"npv\": 0.9863564372062683, \"accuracy\": 0.9869592189788818, \"f1\": 0.8713965130329708, \"f2\": 0.808974358974359, \"f0_5\": 0.9442573887018332, \"p4\": 0.9282899089240761, \"phi\": 0.8726782456990428}, {\"truth_threshold\": 21.41139271534458, \"match_probability\": 0.9999996414676167, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5047.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1491.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7719486355781555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22805139422416687, \"precision\": 1.0, \"recall\": 0.7719486355781555, \"specificity\": 1.0, \"npv\": 0.9863473773002625, \"accuracy\": 0.9869504570960999, \"f1\": 0.8712990936555891, \"f2\": 0.8088400269239399, \"f0_5\": 0.9442116291251964, \"p4\": 0.9282326285185792, \"phi\": 0.8725878196038913}, {\"truth_threshold\": 21.435088614934827, \"match_probability\": 0.9999996473083206, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5043.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7713367938995361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22866320610046387, \"precision\": 1.0, \"recall\": 0.7713367938995361, \"specificity\": 1.0, \"npv\": 0.9863112568855286, \"accuracy\": 0.9869154691696167, \"f1\": 0.8709092479060531, \"f2\": 0.8083026125981728, \"f0_5\": 0.9440284537626357, \"p4\": 0.9280033584540409, \"phi\": 0.8722260380432063}, {\"truth_threshold\": 21.46096564758118, \"match_probability\": 0.9999996535780088, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5042.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1496.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7711838483810425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22881615161895752, \"precision\": 1.0, \"recall\": 0.7711838483810425, \"specificity\": 1.0, \"npv\": 0.9863022565841675, \"accuracy\": 0.9869067072868347, \"f1\": 0.8708117443868739, \"f2\": 0.808168237481567, \"f0_5\": 0.9439826256271999, \"p4\": 0.9279460037961371, \"phi\": 0.872135470575205}, {\"truth_threshold\": 21.464168079619522, \"match_probability\": 0.9999996543461283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5040.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1498.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7708779573440552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22912205755710602, \"precision\": 1.0, \"recall\": 0.7708779573440552, \"specificity\": 1.0, \"npv\": 0.9862841963768005, \"accuracy\": 0.9868891835212708, \"f1\": 0.8706166868198307, \"f2\": 0.8078994614003591, \"f0_5\": 0.9438909281594127, \"p4\": 0.927831249866574, \"phi\": 0.87195451797506}, {\"truth_threshold\": 21.470594348778956, \"match_probability\": 0.9999996558823671, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5038.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1500.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7705720663070679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22942796349525452, \"precision\": 1.0, \"recall\": 0.7705720663070679, \"specificity\": 1.0, \"npv\": 0.9862661361694336, \"accuracy\": 0.9868717193603516, \"f1\": 0.8704215618521078, \"f2\": 0.8076306508496313, \"f0_5\": 0.9437991757212439, \"p4\": 0.9277164364103958, \"phi\": 0.8717735344440931}, {\"truth_threshold\": 21.49055733168023, \"match_probability\": 0.9999996606112266, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5035.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1503.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7701131701469421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22988681495189667, \"precision\": 1.0, \"recall\": 0.7701131701469421, \"specificity\": 1.0, \"npv\": 0.9862390160560608, \"accuracy\": 0.9868454337120056, \"f1\": 0.8701287479478096, \"f2\": 0.8072273703786834, \"f0_5\": 0.9436614438863483, \"p4\": 0.9275441045043845, \"phi\": 0.8715020011094009}, {\"truth_threshold\": 21.49251032018157, \"match_probability\": 0.9999996610703491, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5032.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1506.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7696543335914612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23034566640853882, \"precision\": 1.0, \"recall\": 0.7696543335914612, \"specificity\": 1.0, \"npv\": 0.9862119555473328, \"accuracy\": 0.9868192076683044, \"f1\": 0.8698357821953328, \"f2\": 0.8068240123140071, \"f0_5\": 0.9435235880897023, \"p4\": 0.9273716383821176, \"phi\": 0.8712302952019066}, {\"truth_threshold\": 21.497629972819436, \"match_probability\": 0.9999996622709676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5030.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1508.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7693484425544739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23065157234668732, \"precision\": 1.0, \"recall\": 0.7693484425544739, \"specificity\": 1.0, \"npv\": 0.9861938953399658, \"accuracy\": 0.9868016839027405, \"f1\": 0.8696403872752421, \"f2\": 0.8065550638188699, \"f0_5\": 0.9434316152749643, \"p4\": 0.9272565863191458, \"phi\": 0.8710491877316262}, {\"truth_threshold\": 21.511132025077686, \"match_probability\": 0.9999996654169973, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5028.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1510.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7690424919128418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23095747828483582, \"precision\": 1.0, \"recall\": 0.7690424919128418, \"specificity\": 1.0, \"npv\": 0.9861758351325989, \"accuracy\": 0.9867841601371765, \"f1\": 0.8694449247795262, \"f2\": 0.8062860808210391, \"f0_5\": 0.9433395872420263, \"p4\": 0.9271414744791122, \"phi\": 0.8708680492321547}, {\"truth_threshold\": 21.52235928050094, \"match_probability\": 0.9999996680106631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5027.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1511.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7688895463943481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23111043870449066, \"precision\": 1.0, \"recall\": 0.7688895463943481, \"specificity\": 1.0, \"npv\": 0.986166775226593, \"accuracy\": 0.9867753982543945, \"f1\": 0.869347168179853, \"f2\": 0.8061515763815389, \"f0_5\": 0.94329355250319, \"p4\": 0.9270838961269939, \"phi\": 0.8707774683403069}, {\"truth_threshold\": 21.52306176867309, \"match_probability\": 0.9999996681722785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5025.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1513.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7685836553573608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23141632974147797, \"precision\": 1.0, \"recall\": 0.7685836553573608, \"specificity\": 1.0, \"npv\": 0.9861487746238708, \"accuracy\": 0.9867579340934753, \"f1\": 0.8691516042549511, \"f2\": 0.8058825416172178, \"f0_5\": 0.9432014415496659, \"p4\": 0.926968694527117, \"phi\": 0.8705962832600473}, {\"truth_threshold\": 21.53344853181348, \"match_probability\": 0.9999996705527106, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5023.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1515.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7682777643203735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23172223567962646, \"precision\": 1.0, \"recall\": 0.7682777643203735, \"specificity\": 1.0, \"npv\": 0.9861307144165039, \"accuracy\": 0.9867404103279114, \"f1\": 0.8689559726667243, \"f2\": 0.8056134723336006, \"f0_5\": 0.9431092752534735, \"p4\": 0.9268534330244288, \"phi\": 0.8704149641454249}, {\"truth_threshold\": 21.562400711004486, \"match_probability\": 0.999999677098199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5022.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1516.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7681248188018799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2318751960992813, \"precision\": 1.0, \"recall\": 0.7681248188018799, \"specificity\": 1.0, \"npv\": 0.986121654510498, \"accuracy\": 0.9867316484451294, \"f1\": 0.8688581314878893, \"f2\": 0.8054789247449798, \"f0_5\": 0.9430631713362878, \"p4\": 0.9267957797937831, \"phi\": 0.8703243443956007}, {\"truth_threshold\": 21.56280441337501, \"match_probability\": 0.9999996771885424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5021.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1517.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7679718732833862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23202814161777496, \"precision\": 1.0, \"recall\": 0.7679718732833862, \"specificity\": 1.0, \"npv\": 0.986112654209137, \"accuracy\": 0.9867228865623474, \"f1\": 0.8687602733800501, \"f2\": 0.8053443685240432, \"f0_5\": 0.9430170535647209, \"p4\": 0.9267381115685308, \"phi\": 0.8702337168687156}, {\"truth_threshold\": 21.563703753170437, \"match_probability\": 0.9999996773897122, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5019.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1519.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7676659822463989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23233404755592346, \"precision\": 1.0, \"recall\": 0.7676659822463989, \"specificity\": 1.0, \"npv\": 0.98609459400177, \"accuracy\": 0.9867054224014282, \"f1\": 0.868564506359782, \"f2\": 0.8050752301818999, \"f0_5\": 0.9429247764334561, \"p4\": 0.9266227301089682, \"phi\": 0.8700524384738604}, {\"truth_threshold\": 21.5798447751617, \"match_probability\": 0.9999996809789924, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5016.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1522.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7672070860862732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2327928990125656, \"precision\": 1.0, \"recall\": 0.7672070860862732, \"specificity\": 1.0, \"npv\": 0.9860674738883972, \"accuracy\": 0.9866791367530823, \"f1\": 0.8682707287519473, \"f2\": 0.8046714579055442, \"f0_5\": 0.9427862566724307, \"p4\": 0.9264495453022441, \"phi\": 0.8697804624916928}, {\"truth_threshold\": 21.5910479362335, \"match_probability\": 0.9999996834467361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5015.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1523.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7670541405677795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23294585943222046, \"precision\": 1.0, \"recall\": 0.7670541405677795, \"specificity\": 1.0, \"npv\": 0.9860584735870361, \"accuracy\": 0.9866703748703003, \"f1\": 0.8681727689777547, \"f2\": 0.8045368498732633, \"f0_5\": 0.9427400556432814, \"p4\": 0.9263917869767471, \"phi\": 0.8696897882504137}, {\"truth_threshold\": 21.59747253559674, \"match_probability\": 0.9999996848532742, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5013.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1525.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7667482495307922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23325176537036896, \"precision\": 1.0, \"recall\": 0.7667482495307922, \"specificity\": 1.0, \"npv\": 0.9860404133796692, \"accuracy\": 0.9866529107093811, \"f1\": 0.8679767985455805, \"f2\": 0.8042676078934703, \"f0_5\": 0.942647611884167, \"p4\": 0.9262762252028958, \"phi\": 0.8695083133283951}, {\"truth_threshold\": 21.600772364169462, \"match_probability\": 0.9999996855732749, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5012.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1526.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7665953040122986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2334047108888626, \"precision\": 1.0, \"recall\": 0.7665953040122986, \"specificity\": 1.0, \"npv\": 0.9860314130783081, \"accuracy\": 0.9866441488265991, \"f1\": 0.8678787878787879, \"f2\": 0.8041329739442947, \"f0_5\": 0.9426013691416535, \"p4\": 0.9262184217418711, \"phi\": 0.869417615686606}, {\"truth_threshold\": 21.605589220955352, \"match_probability\": 0.999999686621329, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5011.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1527.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7664423584938049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23355765640735626, \"precision\": 1.0, \"recall\": 0.7664423584938049, \"specificity\": 1.0, \"npv\": 0.9860223531723022, \"accuracy\": 0.9866353869438171, \"f1\": 0.8677807602389818, \"f2\": 0.803998331354491, \"f0_5\": 0.9425551124821308, \"p4\": 0.9261606032229943, \"phi\": 0.8693269102429421}, {\"truth_threshold\": 21.61022653340627, \"match_probability\": 0.9999996876270172, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5009.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1529.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7661364078521729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23386356234550476, \"precision\": 1.0, \"recall\": 0.7661364078521729, \"specificity\": 1.0, \"npv\": 0.9860042929649353, \"accuracy\": 0.9866178631782532, \"f1\": 0.8675846540226899, \"f2\": 0.8037290202496711, \"f0_5\": 0.9424625573869195, \"p4\": 0.9260449209863043, \"phi\": 0.8691454759400346}, {\"truth_threshold\": 21.613742066419512, \"match_probability\": 0.999999688387275, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5008.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1530.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7659834623336792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2340165227651596, \"precision\": 1.0, \"recall\": 0.7659834623336792, \"specificity\": 1.0, \"npv\": 0.9859952926635742, \"accuracy\": 0.986609160900116, \"f1\": 0.867486575437381, \"f2\": 0.803594351732991, \"f0_5\": 0.9424162589386527, \"p4\": 0.9259870572557924, \"phi\": 0.8690547470758117}, {\"truth_threshold\": 21.615910692005453, \"match_probability\": 0.999999688855332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5007.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1531.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7658305168151855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23416946828365326, \"precision\": 1.0, \"recall\": 0.7658305168151855, \"specificity\": 1.0, \"npv\": 0.9859862923622131, \"accuracy\": 0.986600399017334, \"f1\": 0.8673884798614119, \"f2\": 0.8034596745723547, \"f0_5\": 0.9423699465482195, \"p4\": 0.9259291784420307, \"phi\": 0.8689640103997542}, {\"truth_threshold\": 21.620503127584183, \"match_probability\": 0.9999996898442032, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5006.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1532.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7656775712966919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2343224287033081, \"precision\": 1.0, \"recall\": 0.7656775712966919, \"specificity\": 1.0, \"npv\": 0.9859772324562073, \"accuracy\": 0.986591637134552, \"f1\": 0.8672903672903672, \"f2\": 0.8033249887669298, \"f0_5\": 0.9423236202093216, \"p4\": 0.9258712845386609, \"phi\": 0.8688732659093689}, {\"truth_threshold\": 21.639953401610246, \"match_probability\": 0.9999996939976312, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5003.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1535.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7652187347412109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23478128015995026, \"precision\": 1.0, \"recall\": 0.7652187347412109, \"specificity\": 1.0, \"npv\": 0.9859501719474792, \"accuracy\": 0.986565351486206, \"f1\": 0.8669959275626029, \"f2\": 0.8029208794735997, \"f0_5\": 0.9421845574387947, \"p4\": 0.9256975122272658, \"phi\": 0.8686008823753495}, {\"truth_threshold\": 21.642718261451037, \"match_probability\": 0.9999996945835091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5002.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1536.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7650657892227173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2349342256784439, \"precision\": 1.0, \"recall\": 0.7650657892227173, \"specificity\": 1.0, \"npv\": 0.9859411716461182, \"accuracy\": 0.9865566492080688, \"f1\": 0.866897746967071, \"f2\": 0.802786159080696, \"f0_5\": 0.9421381752429745, \"p4\": 0.925639557901809, \"phi\": 0.8685101065928597}, {\"truth_threshold\": 21.651994560917533, \"match_probability\": 0.9999996965409881, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5001.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1537.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7649128437042236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23508718609809875, \"precision\": 1.0, \"recall\": 0.7649128437042236, \"specificity\": 1.0, \"npv\": 0.9859321117401123, \"accuracy\": 0.9865478873252869, \"f1\": 0.8667995493543634, \"f2\": 0.8026514300388405, \"f0_5\": 0.9420917790671389, \"p4\": 0.9255815884548989, \"phi\": 0.8684193229835555}, {\"truth_threshold\": 21.658836477630892, \"match_probability\": 0.9999996979767213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5000.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1538.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7647598385810852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2352401316165924, \"precision\": 1.0, \"recall\": 0.7647598385810852, \"specificity\": 1.0, \"npv\": 0.9859231114387512, \"accuracy\": 0.9865391254425049, \"f1\": 0.8667013347200555, \"f2\": 0.8025166923472008, \"f0_5\": 0.9420453689049665, \"p4\": 0.9255236038801558, \"phi\": 0.8683285315449364}, {\"truth_threshold\": 21.672383009468838, \"match_probability\": 0.999999700799368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4998.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1540.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7644539475440979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2355460375547409, \"precision\": 1.0, \"recall\": 0.7644539475440979, \"specificity\": 1.0, \"npv\": 0.9859050512313843, \"accuracy\": 0.9865216016769409, \"f1\": 0.866504854368932, \"f2\": 0.802247191011236, \"f0_5\": 0.941952506596306, \"p4\": 0.9254075893216335, \"phi\": 0.8681469251697446}, {\"truth_threshold\": 21.67412912074528, \"match_probability\": 0.9999997011612749, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4997.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1541.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7643010020256042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23569898307323456, \"precision\": 1.0, \"recall\": 0.7643010020256042, \"specificity\": 1.0, \"npv\": 0.9858960509300232, \"accuracy\": 0.9865128397941589, \"f1\": 0.8664065886432596, \"f2\": 0.8021124273652445, \"f0_5\": 0.941906054437156, \"p4\": 0.9253495593250768, \"phi\": 0.8680561102281645}, {\"truth_threshold\": 21.686057946365914, \"match_probability\": 0.9999997036220145, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4996.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1542.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7641480565071106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2358519434928894, \"precision\": 1.0, \"recall\": 0.7641480565071106, \"specificity\": 1.0, \"npv\": 0.9858869910240173, \"accuracy\": 0.9865041375160217, \"f1\": 0.8663083058782729, \"f2\": 0.8019776550661358, \"f0_5\": 0.941859588266345, \"p4\": 0.9252915141751322, \"phi\": 0.8679651842263746}, {\"truth_threshold\": 21.68959380592936, \"match_probability\": 0.9999997043475092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4993.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1545.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7636892199516296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23631079494953156, \"precision\": 1.0, \"recall\": 0.7636892199516296, \"specificity\": 1.0, \"npv\": 0.9858599305152893, \"accuracy\": 0.9864778518676758, \"f1\": 0.866013355303096, \"f2\": 0.8015732862417724, \"f0_5\": 0.9417201056205206, \"p4\": 0.9251172877409759, \"phi\": 0.8676926687930061}, {\"truth_threshold\": 21.692986770115404, \"match_probability\": 0.9999997050420144, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4991.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1547.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7633832693099976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23661670088768005, \"precision\": 1.0, \"recall\": 0.7633832693099976, \"specificity\": 1.0, \"npv\": 0.9858418703079224, \"accuracy\": 0.9864603281021118, \"f1\": 0.8658166363084396, \"f2\": 0.8013036637446618, \"f0_5\": 0.9416270470153196, \"p4\": 0.9250010609005449, \"phi\": 0.867510952594772}, {\"truth_threshold\": 21.700437210183534, \"match_probability\": 0.9999997065613248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4989.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1549.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7630773782730103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23692260682582855, \"precision\": 1.0, \"recall\": 0.7630773782730103, \"specificity\": 1.0, \"npv\": 0.9858238697052002, \"accuracy\": 0.9864428639411926, \"f1\": 0.8656198490500564, \"f2\": 0.8010340066150734, \"f0_5\": 0.9415339322110666, \"p4\": 0.9248847732927977, \"phi\": 0.867329204978967}, {\"truth_threshold\": 21.703373533255792, \"match_probability\": 0.9999997071579542, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4988.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1550.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7629244327545166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2370755523443222, \"precision\": 1.0, \"recall\": 0.7629244327545166, \"specificity\": 1.0, \"npv\": 0.9858148097991943, \"accuracy\": 0.9864341020584106, \"f1\": 0.8655214298108624, \"f2\": 0.8008991650610148, \"f0_5\": 0.9414873537183843, \"p4\": 0.92482660668513, \"phi\": 0.8672383193831887}, {\"truth_threshold\": 21.705132843914697, \"match_probability\": 0.9999997075148459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4986.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1552.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7626185417175293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2373814582824707, \"precision\": 1.0, \"recall\": 0.7626185417175293, \"specificity\": 1.0, \"npv\": 0.9857968091964722, \"accuracy\": 0.9864165782928467, \"f1\": 0.8653245400902464, \"f2\": 0.8006294559701972, \"f0_5\": 0.9413941545200514, \"p4\": 0.9247102278300736, \"phi\": 0.8670564212836843}, {\"truth_threshold\": 21.706518129806135, \"match_probability\": 0.9999997077955574, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4985.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1553.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7624655961990356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23753441870212555, \"precision\": 1.0, \"recall\": 0.7624655961990356, \"specificity\": 1.0, \"npv\": 0.9857877492904663, \"accuracy\": 0.9864078164100647, \"f1\": 0.8652260695999305, \"f2\": 0.8004945884317692, \"f0_5\": 0.9413475338016466, \"p4\": 0.9246520155698209, \"phi\": 0.8669655120846425}, {\"truth_threshold\": 21.715706846615486, \"match_probability\": 0.9999997096507316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4984.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1554.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.762312650680542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2376873642206192, \"precision\": 1.0, \"recall\": 0.762312650680542, \"specificity\": 1.0, \"npv\": 0.9857787489891052, \"accuracy\": 0.9863990545272827, \"f1\": 0.8651275820170109, \"f2\": 0.8003597122302158, \"f0_5\": 0.9413008989952406, \"p4\": 0.9245937880791701, \"phi\": 0.8668745950160998}, {\"truth_threshold\": 21.72968199898753, \"match_probability\": 0.9999997124497184, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4980.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1558.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7617008090019226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2382991760969162, \"precision\": 1.0, \"recall\": 0.7617008090019226, \"specificity\": 1.0, \"npv\": 0.9857426285743713, \"accuracy\": 0.9863640666007996, \"f1\": 0.8647334606702552, \"f2\": 0.7998201207760504, \"f0_5\": 0.9411142187618112, \"p4\": 0.9243607256837092, \"phi\": 0.8665107963069648}, {\"truth_threshold\": 21.75751585646707, \"match_probability\": 0.9999997179442397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4979.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1559.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.761547863483429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23845212161540985, \"precision\": 1.0, \"recall\": 0.761547863483429, \"specificity\": 1.0, \"npv\": 0.9857336282730103, \"accuracy\": 0.9863553047180176, \"f1\": 0.8646348875575237, \"f2\": 0.7996852012463461, \"f0_5\": 0.9410675134195207, \"p4\": 0.9243024219443791, \"phi\": 0.8664198398481091}, {\"truth_threshold\": 21.76619661706918, \"match_probability\": 0.9999997196362856, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4978.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1560.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7613949179649353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2386050820350647, \"precision\": 1.0, \"recall\": 0.7613949179649353, \"specificity\": 1.0, \"npv\": 0.9857246279716492, \"accuracy\": 0.9863465428352356, \"f1\": 0.8645362973254602, \"f2\": 0.7995502730485062, \"f0_5\": 0.9410207939508507, \"p4\": 0.9242441029359502, \"phi\": 0.8663288755045999}, {\"truth_threshold\": 21.77396279472929, \"match_probability\": 0.9999997211414574, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4976.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1562.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.761089026927948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2389109879732132, \"precision\": 1.0, \"recall\": 0.761089026927948, \"specificity\": 1.0, \"npv\": 0.9857065677642822, \"accuracy\": 0.9863290786743164, \"f1\": 0.8643390654854959, \"f2\": 0.7992803906450784, \"f0_5\": 0.9409273126087285, \"p4\": 0.924127419085941, \"phi\": 0.8661468714441797}, {\"truth_threshold\": 21.786096174506884, \"match_probability\": 0.9999997234768835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4975.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1563.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7609360814094543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23906393349170685, \"precision\": 1.0, \"recall\": 0.7609360814094543, \"specificity\": 1.0, \"npv\": 0.9856975674629211, \"accuracy\": 0.9863203167915344, \"f1\": 0.8642404238686702, \"f2\": 0.7991454364378192, \"f0_5\": 0.9408805507224449, \"p4\": 0.924069054231424, \"phi\": 0.8660558834265677}, {\"truth_threshold\": 21.796482937647276, \"match_probability\": 0.999999725460577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4973.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1565.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.760630190372467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23936983942985535, \"precision\": 1.0, \"recall\": 0.760630190372467, \"specificity\": 1.0, \"npv\": 0.9856795072555542, \"accuracy\": 0.9863027930259705, \"f1\": 0.8640430892190079, \"f2\": 0.7988755020080321, \"f0_5\": 0.940786984487325, \"p4\": 0.9239522786309969, \"phi\": 0.8658738837044659}, {\"truth_threshold\": 21.79816900680746, \"match_probability\": 0.9999997257812421, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4972.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1566.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7604771852493286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.239522784948349, \"precision\": 1.0, \"recall\": 0.7604771852493286, \"specificity\": 1.0, \"npv\": 0.9856705069541931, \"accuracy\": 0.9862940311431885, \"f1\": 0.8639443961772372, \"f2\": 0.7987405217838324, \"f0_5\": 0.9407401801256339, \"p4\": 0.9238938678721282, \"phi\": 0.8657828719949056}, {\"truth_threshold\": 21.80221583987016, \"match_probability\": 0.9999997265493616, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4971.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1567.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.760324239730835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23967574536800385, \"precision\": 1.0, \"recall\": 0.760324239730835, \"specificity\": 1.0, \"npv\": 0.9856614470481873, \"accuracy\": 0.9862853288650513, \"f1\": 0.8638456859848814, \"f2\": 0.7986055328856473, \"f0_5\": 0.9406933615926122, \"p4\": 0.9238354417988445, \"phi\": 0.8656918006488179}, {\"truth_threshold\": 21.808849773852813, \"match_probability\": 0.9999997278038808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4969.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1569.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7600183486938477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23998165130615234, \"precision\": 1.0, \"recall\": 0.7600183486938477, \"specificity\": 1.0, \"npv\": 0.9856434464454651, \"accuracy\": 0.9862678050994873, \"f1\": 0.8636482141305293, \"f2\": 0.7983355290639761, \"f0_5\": 0.9405996819868252, \"p4\": 0.9237185436830744, \"phi\": 0.865509737697659}, {\"truth_threshold\": 21.821919562359845, \"match_probability\": 0.999999730258647, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4968.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1570.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.759865403175354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.240134596824646, \"precision\": 1.0, \"recall\": 0.759865403175354, \"specificity\": 1.0, \"npv\": 0.985634446144104, \"accuracy\": 0.9862590432167053, \"f1\": 0.8635494524595863, \"f2\": 0.7982005141388174, \"f0_5\": 0.9405528209011738, \"p4\": 0.9236600716276003, \"phi\": 0.8654186943583347}, {\"truth_threshold\": 21.825945479990693, \"match_probability\": 0.9999997310103251, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4967.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1571.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7597124576568604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24028754234313965, \"precision\": 1.0, \"recall\": 0.7597124576568604, \"specificity\": 1.0, \"npv\": 0.9856253862380981, \"accuracy\": 0.9862502813339233, \"f1\": 0.8634506736201651, \"f2\": 0.7980654905363282, \"f0_5\": 0.94050594561842, \"p4\": 0.9236015842317358, \"phi\": 0.8653276431064578}, {\"truth_threshold\": 21.826653138445295, \"match_probability\": 0.9999997311422353, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4965.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1573.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.759406566619873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24059344828128815, \"precision\": 1.0, \"recall\": 0.759406566619873, \"specificity\": 1.0, \"npv\": 0.985607385635376, \"accuracy\": 0.9862328171730042, \"f1\": 0.8632530644179779, \"f2\": 0.7977954172960118, \"f0_5\": 0.9404121524357906, \"p4\": 0.9234845633928193, \"phi\": 0.8651454650909028}, {\"truth_threshold\": 21.82769159126714, \"match_probability\": 0.9999997313356895, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4960.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1578.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.75864177942276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24135822057724, \"precision\": 1.0, \"recall\": 0.75864177942276, \"specificity\": 1.0, \"npv\": 0.985562264919281, \"accuracy\": 0.9861890077590942, \"f1\": 0.8627587406505479, \"f2\": 0.7971200822833633, \"f0_5\": 0.9401774205777542, \"p4\": 0.923191742383032, \"phi\": 0.8646899590002768}, {\"truth_threshold\": 21.835303946212154, \"match_probability\": 0.9999997327495583, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4959.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1579.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7584888339042664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24151116609573364, \"precision\": 1.0, \"recall\": 0.7584888339042664, \"specificity\": 1.0, \"npv\": 0.9855532646179199, \"accuracy\": 0.986180305480957, \"f1\": 0.8626598243019918, \"f2\": 0.7969849892321044, \"f0_5\": 0.940130431485554, \"p4\": 0.9231331320296258, \"phi\": 0.8645988443463271}, {\"truth_threshold\": 21.837637784385162, \"match_probability\": 0.9999997331815379, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4957.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1581.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.758182942867279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24181707203388214, \"precision\": 1.0, \"recall\": 0.758182942867279, \"specificity\": 1.0, \"npv\": 0.985535204410553, \"accuracy\": 0.9861627817153931, \"f1\": 0.8624619399739017, \"f2\": 0.7967147770741586, \"f0_5\": 0.9400364105287112, \"p4\": 0.9230158651191269, \"phi\": 0.8644165394255613}, {\"truth_threshold\": 21.838480635100534, \"match_probability\": 0.9999997333373729, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4956.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1582.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7580299973487854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2419700175523758, \"precision\": 1.0, \"recall\": 0.7580299973487854, \"specificity\": 1.0, \"npv\": 0.9855262041091919, \"accuracy\": 0.9861540198326111, \"f1\": 0.8623629719853837, \"f2\": 0.7965796579657966, \"f0_5\": 0.9399893786510887, \"p4\": 0.9229572085489584, \"phi\": 0.8643254009524682}, {\"truth_threshold\": 21.844075221567685, \"match_probability\": 0.9999997343694538, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4953.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1585.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7575711011886597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24242888391017914, \"precision\": 1.0, \"recall\": 0.7575711011886597, \"specificity\": 1.0, \"npv\": 0.9854991436004639, \"accuracy\": 0.9861277937889099, \"f1\": 0.862065964668001, \"f2\": 0.7961742485131008, \"f0_5\": 0.9398481973434535, \"p4\": 0.9227811463002428, \"phi\": 0.8640518860401584}, {\"truth_threshold\": 21.844352122620688, \"match_probability\": 0.9999997344204321, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4952.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1586.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.757418155670166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2425818294286728, \"precision\": 1.0, \"recall\": 0.757418155670166, \"specificity\": 1.0, \"npv\": 0.9854901432991028, \"accuracy\": 0.9861190319061279, \"f1\": 0.8619669277632724, \"f2\": 0.7960390946502057, \"f0_5\": 0.9398011083276399, \"p4\": 0.9227224280160977, \"phi\": 0.8639607157740412}, {\"truth_threshold\": 21.85624781502105, \"match_probability\": 0.9999997366012554, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4951.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1587.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7572652101516724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24273477494716644, \"precision\": 1.0, \"recall\": 0.7572652101516724, \"specificity\": 1.0, \"npv\": 0.9854811429977417, \"accuracy\": 0.986110270023346, \"f1\": 0.8618678736182436, \"f2\": 0.7959039320965823, \"f0_5\": 0.939754005011009, \"p4\": 0.9226636942870721, \"phi\": 0.8638695375545107}, {\"truth_threshold\": 21.864127843863958, \"match_probability\": 0.9999997380360223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4950.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1588.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7571122646331787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2428877353668213, \"precision\": 1.0, \"recall\": 0.7571122646331787, \"specificity\": 1.0, \"npv\": 0.9854720830917358, \"accuracy\": 0.986101508140564, \"f1\": 0.8617688022284122, \"f2\": 0.7957687608513921, \"f0_5\": 0.9397068873870453, \"p4\": 0.9226049451066036, \"phi\": 0.8637783513790024}, {\"truth_threshold\": 21.866675354999625, \"match_probability\": 0.99999973849819, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4947.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1591.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7566534280776978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24334658682346344, \"precision\": 1.0, \"recall\": 0.7566534280776978, \"specificity\": 1.0, \"npv\": 0.9854450821876526, \"accuracy\": 0.986075222492218, \"f1\": 0.8614714845450587, \"f2\": 0.7953631949580372, \"f0_5\": 0.9395654486059409, \"p4\": 0.9224286047908656, \"phi\": 0.8635046932371627}, {\"truth_threshold\": 21.870543516954083, \"match_probability\": 0.9999997391983909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4946.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1592.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7565004825592041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2434995472431183, \"precision\": 1.0, \"recall\": 0.7565004825592041, \"specificity\": 1.0, \"npv\": 0.9854360222816467, \"accuracy\": 0.9860665202140808, \"f1\": 0.8613723441309649, \"f2\": 0.7952279889381954, \"f0_5\": 0.9395182736874098, \"p4\": 0.9223697937389315, \"phi\": 0.8634134752070686}, {\"truth_threshold\": 21.878503090726213, \"match_probability\": 0.9999997406333117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4945.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1593.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7563474774360657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24365249276161194, \"precision\": 1.0, \"recall\": 0.7563474774360657, \"specificity\": 1.0, \"npv\": 0.9854270219802856, \"accuracy\": 0.9860577583312988, \"f1\": 0.8612731864495341, \"f2\": 0.7950927742225938, \"f0_5\": 0.9394710844289079, \"p4\": 0.9223109672026885, \"phi\": 0.8633222492081537}, {\"truth_threshold\": 21.8856318480578, \"match_probability\": 0.9999997419117531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4944.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1594.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.756194531917572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2438054382801056, \"precision\": 1.0, \"recall\": 0.756194531917572, \"specificity\": 1.0, \"npv\": 0.9854180216789246, \"accuracy\": 0.9860489964485168, \"f1\": 0.861174011496255, \"f2\": 0.7949575508103937, \"f0_5\": 0.939423880823896, \"p4\": 0.9222521251755524, \"phi\": 0.8632310152378455}, {\"truth_threshold\": 21.888525142004664, \"match_probability\": 0.9999997424288247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4942.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1596.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7558886408805847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2441113442182541, \"precision\": 1.0, \"recall\": 0.7558886408805847, \"specificity\": 1.0, \"npv\": 0.9853999614715576, \"accuracy\": 0.9860314726829529, \"f1\": 0.8609756097560975, \"f2\": 0.7946870778928411, \"f0_5\": 0.9393294305481639, \"p4\": 0.922134394622245, \"phi\": 0.8630484714939315}, {\"truth_threshold\": 21.89601861119819, \"match_probability\": 0.9999997437632006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4941.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1597.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7557356953620911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24426430463790894, \"precision\": 1.0, \"recall\": 0.7557356953620911, \"specificity\": 1.0, \"npv\": 0.9853909611701965, \"accuracy\": 0.9860227108001709, \"f1\": 0.8608763829601882, \"f2\": 0.7945518283858103, \"f0_5\": 0.9392821838643449, \"p4\": 0.9220755060828862, \"phi\": 0.8629572135889849}, {\"truth_threshold\": 21.90075218728364, \"match_probability\": 0.9999997446025521, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4939.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1599.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7554298043251038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24457021057605743, \"precision\": 1.0, \"recall\": 0.7554298043251038, \"specificity\": 1.0, \"npv\": 0.9853729605674744, \"accuracy\": 0.9860052466392517, \"f1\": 0.8606778774941187, \"f2\": 0.7942813032710431, \"f0_5\": 0.939187647372024, \"p4\": 0.9219576824457622, \"phi\": 0.8627746219375587}, {\"truth_threshold\": 21.902909839489634, \"match_probability\": 0.9999997449842315, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4938.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1600.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7552768588066101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2447231560945511, \"precision\": 1.0, \"recall\": 0.7552768588066101, \"specificity\": 1.0, \"npv\": 0.9853639602661133, \"accuracy\": 0.9859964847564697, \"f1\": 0.860578598814918, \"f2\": 0.7941460276616276, \"f0_5\": 0.9391403575503994, \"p4\": 0.921898747334787, \"phi\": 0.8626833400747673}, {\"truth_threshold\": 21.908151990975785, \"match_probability\": 0.9999997459091706, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4937.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1601.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7551239132881165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24487610161304474, \"precision\": 1.0, \"recall\": 0.7551239132881165, \"specificity\": 1.0, \"npv\": 0.9853549003601074, \"accuracy\": 0.9859877228736877, \"f1\": 0.860479302832244, \"f2\": 0.7940107433497379, \"f0_5\": 0.9390930533363768, \"p4\": 0.9218397966867238, \"phi\": 0.8625920502225375}, {\"truth_threshold\": 21.92950174773778, \"match_probability\": 0.9999997496416532, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4936.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1602.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7549709677696228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24502906203269958, \"precision\": 1.0, \"recall\": 0.7549709677696228, \"specificity\": 1.0, \"npv\": 0.9853459000587463, \"accuracy\": 0.9859789609909058, \"f1\": 0.8603799895415722, \"f2\": 0.7938754503345342, \"f0_5\": 0.9390457347233848, \"p4\": 0.9217808304949582, \"phi\": 0.8625007523782863}, {\"truth_threshold\": 21.933653362920744, \"match_probability\": 0.9999997503610686, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4934.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1604.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7546650171279907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24533496797084808, \"precision\": 1.0, \"recall\": 0.7546650171279907, \"specificity\": 1.0, \"npv\": 0.9853278994560242, \"accuracy\": 0.9859614968299866, \"f1\": 0.8601813110181311, \"f2\": 0.7936048381908255, \"f0_5\": 0.9389510542741875, \"p4\": 0.9216628514538441, \"phi\": 0.8623180807844179}, {\"truth_threshold\": 21.938099267951934, \"match_probability\": 0.9999997511291883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4933.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1605.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7545120716094971, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24548791348934174, \"precision\": 1.0, \"recall\": 0.7545120716094971, \"specificity\": 1.0, \"npv\": 0.9853188395500183, \"accuracy\": 0.9859527349472046, \"f1\": 0.8600819457763055, \"f2\": 0.7934695190606402, \"f0_5\": 0.9389036924248192, \"p4\": 0.9216038385912483, \"phi\": 0.8622267589435684}, {\"truth_threshold\": 21.93979915204987, \"match_probability\": 0.9999997514222524, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4930.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1608.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7540532350540161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24594677984714508, \"precision\": 1.0, \"recall\": 0.7540532350540161, \"specificity\": 1.0, \"npv\": 0.9852918386459351, \"accuracy\": 0.9859264492988586, \"f1\": 0.8597837460760377, \"f2\": 0.7930635094266778, \"f0_5\": 0.9387615202985756, \"p4\": 0.9214267065557435, \"phi\": 0.8619526934573875}, {\"truth_threshold\": 21.96289815172474, \"match_probability\": 0.999999755370539, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4929.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1609.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7539002895355225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24609972536563873, \"precision\": 1.0, \"recall\": 0.7539002895355225, \"specificity\": 1.0, \"npv\": 0.985282838344574, \"accuracy\": 0.9859176874160767, \"f1\": 0.8596843115025726, \"f2\": 0.7929281554647534, \"f0_5\": 0.9387141007084635, \"p4\": 0.9213676313725468, \"phi\": 0.8618613395864982}, {\"truth_threshold\": 21.965066315552203, \"match_probability\": 0.9999997557379058, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4927.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1611.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7535943984985352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24640563130378723, \"precision\": 1.0, \"recall\": 0.7535943984985352, \"specificity\": 1.0, \"npv\": 0.985264778137207, \"accuracy\": 0.9859002232551575, \"f1\": 0.8594853903183602, \"f2\": 0.7926574214099553, \"f0_5\": 0.9386192181665778, \"p4\": 0.9212494342092507, \"phi\": 0.8616786078039244}, {\"truth_threshold\": 21.9677704288233, \"match_probability\": 0.9999997561953092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4924.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1614.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7531355023384094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24686448276042938, \"precision\": 1.0, \"recall\": 0.7531355023384094, \"specificity\": 1.0, \"npv\": 0.9852377772331238, \"accuracy\": 0.9858739376068115, \"f1\": 0.8591868783807364, \"f2\": 0.7922512549877719, \"f0_5\": 0.9384767858504232, \"p4\": 0.9210720213722713, \"phi\": 0.861404398019855}, {\"truth_threshold\": 21.97403870932994, \"match_probability\": 0.9999997572523036, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4923.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1615.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7529825568199158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24701744318008423, \"precision\": 1.0, \"recall\": 0.7529825568199158, \"specificity\": 1.0, \"npv\": 0.9852287769317627, \"accuracy\": 0.9858651757240295, \"f1\": 0.8590873396736759, \"f2\": 0.7921158487530169, \"f0_5\": 0.9384292794510103, \"p4\": 0.9210128525087682, \"phi\": 0.8613129960285782}, {\"truth_threshold\": 22.0029338151147, \"match_probability\": 0.9999997620658247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4920.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1618.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7525237202644348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24747629463672638, \"precision\": 1.0, \"recall\": 0.7525237202644348, \"specificity\": 1.0, \"npv\": 0.9852017164230347, \"accuracy\": 0.9858389496803284, \"f1\": 0.8587886193052889, \"f2\": 0.7917095777548918, \"f0_5\": 0.9382866732779007, \"p4\": 0.9208352520713916, \"phi\": 0.8610386898849502}, {\"truth_threshold\": 22.005228947654466, \"match_probability\": 0.9999997624440448, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4915.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1623.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7517589330673218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24824105203151703, \"precision\": 1.0, \"recall\": 0.7517589330673218, \"specificity\": 1.0, \"npv\": 0.9851566553115845, \"accuracy\": 0.9857951998710632, \"f1\": 0.8582904042608923, \"f2\": 0.7910322850613191, \"f0_5\": 0.9380487060080922, \"p4\": 0.9205389381188381, \"phi\": 0.8605813868305731}, {\"truth_threshold\": 22.006659442216897, \"match_probability\": 0.999999762679475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4914.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1624.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7516059875488281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24839399755001068, \"precision\": 1.0, \"recall\": 0.7516059875488281, \"specificity\": 1.0, \"npv\": 0.9851476550102234, \"accuracy\": 0.9857864379882812, \"f1\": 0.8581907090464548, \"f2\": 0.7908968003605228, \"f0_5\": 0.9380010689470871, \"p4\": 0.9204796282845981, \"phi\": 0.8604899124804816}, {\"truth_threshold\": 22.020561428143907, \"match_probability\": 0.9999997649553412, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4912.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1626.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7513000965118408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24869990348815918, \"precision\": 1.0, \"recall\": 0.7513000965118408, \"specificity\": 1.0, \"npv\": 0.9851296544075012, \"accuracy\": 0.9857689142227173, \"f1\": 0.8579912663755459, \"f2\": 0.7906258047901107, \"f0_5\": 0.9379057511647445, \"p4\": 0.9203609615188021, \"phi\": 0.8603068875924273}, {\"truth_threshold\": 22.020626720234198, \"match_probability\": 0.9999997649659783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4908.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1630.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7506882548332214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24931171536445618, \"precision\": 1.0, \"recall\": 0.7506882548332214, \"specificity\": 1.0, \"npv\": 0.9850935935974121, \"accuracy\": 0.9857339262962341, \"f1\": 0.8575921719377949, \"f2\": 0.7900837089504186, \"f0_5\": 0.9377149407718762, \"p4\": 0.9201234394100747, \"phi\": 0.8599408451505388}, {\"truth_threshold\": 22.030506184171262, \"match_probability\": 0.9999997665699745, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4907.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1631.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7505353093147278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24946466088294983, \"precision\": 1.0, \"recall\": 0.7505353093147278, \"specificity\": 1.0, \"npv\": 0.985084593296051, \"accuracy\": 0.9857251644134521, \"f1\": 0.8574923547400611, \"f2\": 0.7899481631733153, \"f0_5\": 0.9376672017121456, \"p4\": 0.9200640195568051, \"phi\": 0.8598492623226764}, {\"truth_threshold\": 22.03523976025671, \"match_probability\": 0.9999997673346183, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4906.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1632.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7503823637962341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24961762130260468, \"precision\": 1.0, \"recall\": 0.7503823637962341, \"specificity\": 1.0, \"npv\": 0.9850755929946899, \"accuracy\": 0.9857164025306702, \"f1\": 0.8573925200978679, \"f2\": 0.789812608667654, \"f0_5\": 0.9376194480544301, \"p4\": 0.9200045839596501, \"phi\": 0.8597577234747978}, {\"truth_threshold\": 22.037422975248433, \"match_probability\": 0.9999997676864419, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4905.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1633.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7502294182777405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24977056682109833, \"precision\": 1.0, \"recall\": 0.7502294182777405, \"specificity\": 1.0, \"npv\": 0.9850665926933289, \"accuracy\": 0.9857076406478882, \"f1\": 0.8572926680066416, \"f2\": 0.7896770454325917, \"f0_5\": 0.937571679792033, \"p4\": 0.9199451326118784, \"phi\": 0.8596661765541659}, {\"truth_threshold\": 22.08414936073766, \"match_probability\": 0.9999997750901293, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4904.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1634.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7500764727592468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24992352724075317, \"precision\": 1.0, \"recall\": 0.7500764727592468, \"specificity\": 1.0, \"npv\": 0.9850575923919678, \"accuracy\": 0.9856988787651062, \"f1\": 0.8571927984618074, \"f2\": 0.7895414734672849, \"f0_5\": 0.9375238969182534, \"p4\": 0.9198856655067543, \"phi\": 0.8595746215581554}, {\"truth_threshold\": 22.088124711956542, \"match_probability\": 0.999999775709016, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4900.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1638.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7494646906852722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25053533911705017, \"precision\": 1.0, \"recall\": 0.7494646906852722, \"specificity\": 1.0, \"npv\": 0.9850215315818787, \"accuracy\": 0.985663890838623, \"f1\": 0.8567931456548348, \"f2\": 0.7889990982867449, \"f0_5\": 0.9373326191751473, \"p4\": 0.9196476393778885, \"phi\": 0.8592082686770958}, {\"truth_threshold\": 22.108024269394246, \"match_probability\": 0.9999997787814945, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4897.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1641.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7490057945251465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25099417567253113, \"precision\": 1.0, \"recall\": 0.7490057945251465, \"specificity\": 1.0, \"npv\": 0.9849945306777954, \"accuracy\": 0.9856376647949219, \"f1\": 0.8564932225623088, \"f2\": 0.7885922251924378, \"f0_5\": 0.9371890071193447, \"p4\": 0.9194689539984264, \"phi\": 0.8589334060428413}, {\"truth_threshold\": 22.123144608620088, \"match_probability\": 0.9999997810878939, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4889.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1649.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7477821707725525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2522177994251251, \"precision\": 1.0, \"recall\": 0.7477821707725525, \"specificity\": 1.0, \"npv\": 0.984922468662262, \"accuracy\": 0.9855676293373108, \"f1\": 0.8556926577404393, \"f2\": 0.7875068457846075, \"f0_5\": 0.9368053958764467, \"p4\": 0.9189917634556773, \"phi\": 0.858200117196779}, {\"truth_threshold\": 22.12650942133091, \"match_probability\": 0.9999997815978698, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4888.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1650.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7476292252540588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2523707449436188, \"precision\": 1.0, \"recall\": 0.7476292252540588, \"specificity\": 1.0, \"npv\": 0.9849134683609009, \"accuracy\": 0.9855588674545288, \"f1\": 0.8555925083143707, \"f2\": 0.7873711340206185, \"f0_5\": 0.9367573783058644, \"p4\": 0.9189320433137436, \"phi\": 0.8581084326161958}, {\"truth_threshold\": 22.12728496962562, \"match_probability\": 0.9999997817152445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4886.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1652.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7473233342170715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25267666578292847, \"precision\": 1.0, \"recall\": 0.7473233342170715, \"specificity\": 1.0, \"npv\": 0.9848954677581787, \"accuracy\": 0.9855413436889648, \"f1\": 0.8553921568627451, \"f2\": 0.7870996842580064, \"f0_5\": 0.9366612989801396, \"p4\": 0.9188125554057343, \"phi\": 0.8579250390917182}, {\"truth_threshold\": 22.134775433807626, \"match_probability\": 0.9999997828456403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4884.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1654.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7470174431800842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25298255681991577, \"precision\": 1.0, \"recall\": 0.7470174431800842, \"specificity\": 1.0, \"npv\": 0.9848774671554565, \"accuracy\": 0.9855238795280457, \"f1\": 0.8551917352477675, \"f2\": 0.7868281995102462, \"f0_5\": 0.9365651606964792, \"p4\": 0.9186930039534834, \"phi\": 0.8577415608930357}, {\"truth_threshold\": 22.19640009770028, \"match_probability\": 0.999999791926063, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4883.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1655.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7468644976615906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2531355023384094, \"precision\": 1.0, \"recall\": 0.7468644976615906, \"specificity\": 1.0, \"npv\": 0.9848684072494507, \"accuracy\": 0.9855151176452637, \"f1\": 0.8550914981175028, \"f2\": 0.786692444014822, \"f0_5\": 0.9365170694284618, \"p4\": 0.9186332043812331, \"phi\": 0.8576498356797363}, {\"truth_threshold\": 22.217253339149007, \"match_probability\": 0.9999997949120072, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4882.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1656.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7467115521430969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25328847765922546, \"precision\": 1.0, \"recall\": 0.7467115521430969, \"specificity\": 1.0, \"npv\": 0.9848594069480896, \"accuracy\": 0.9855063557624817, \"f1\": 0.8549912434325744, \"f2\": 0.7865566797705742, \"f0_5\": 0.9364689634005985, \"p4\": 0.9185733889024733, \"phi\": 0.857558102332953}, {\"truth_threshold\": 22.225411633303573, \"match_probability\": 0.9999997960684859, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4881.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1657.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7465586066246033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2534414231777191, \"precision\": 1.0, \"recall\": 0.7465586066246033, \"specificity\": 1.0, \"npv\": 0.9848504066467285, \"accuracy\": 0.9854975938796997, \"f1\": 0.8548909711883702, \"f2\": 0.7864209067766571, \"f0_5\": 0.9364208426060932, \"p4\": 0.9185135575103798, \"phi\": 0.8574663608500294}, {\"truth_threshold\": 22.23695706163869, \"match_probability\": 0.9999997976939716, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4878.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1660.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7460997104644775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25390028953552246, \"precision\": 1.0, \"recall\": 0.7460997104644775, \"specificity\": 1.0, \"npv\": 0.9848234057426453, \"accuracy\": 0.9854713678359985, \"f1\": 0.8545900490539594, \"f2\": 0.7860135352884305, \"f0_5\": 0.9362763915547025, \"p4\": 0.9183339677857937, \"phi\": 0.857191035355069}, {\"truth_threshold\": 22.237073115163735, \"match_probability\": 0.9999997977102448, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4876.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1662.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7457938194274902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25420618057250977, \"precision\": 1.0, \"recall\": 0.7457938194274902, \"specificity\": 1.0, \"npv\": 0.9848054051399231, \"accuracy\": 0.9854538440704346, \"f1\": 0.8543893464166813, \"f2\": 0.7857419105324224, \"f0_5\": 0.9361800168957838, \"p4\": 0.918214161610777, \"phi\": 0.8570074790872456}, {\"truth_threshold\": 22.237530525931277, \"match_probability\": 0.9999997977743712, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4874.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1664.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7454879283905029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25451207160949707, \"precision\": 1.0, \"recall\": 0.7454879283905029, \"specificity\": 1.0, \"npv\": 0.9847874045372009, \"accuracy\": 0.9854363203048706, \"f1\": 0.8541885734314757, \"f2\": 0.7854702507574293, \"f0_5\": 0.9360835830068372, \"p4\": 0.9180942916183069, \"phi\": 0.8568238379877594}, {\"truth_threshold\": 22.243941914618496, \"match_probability\": 0.999999798671075, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4873.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1665.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7453349828720093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2546650469303131, \"precision\": 1.0, \"recall\": 0.7453349828720093, \"specificity\": 1.0, \"npv\": 0.9847784042358398, \"accuracy\": 0.9854276180267334, \"f1\": 0.8540881605468408, \"f2\": 0.7853344077356971, \"f0_5\": 0.9360353438340376, \"p4\": 0.9180343326733948, \"phi\": 0.8567320313096791}, {\"truth_threshold\": 22.251411125662056, \"match_probability\": 0.9999997997107141, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4871.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1667.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7450290322303772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2549709379673004, \"precision\": 1.0, \"recall\": 0.7450290322303772, \"specificity\": 1.0, \"npv\": 0.9847604036331177, \"accuracy\": 0.9854100942611694, \"f1\": 0.8538872819703742, \"f2\": 0.7850626954195274, \"f0_5\": 0.9359388209976174, \"p4\": 0.917914366851919, \"phi\": 0.8565483934705094}, {\"truth_threshold\": 22.255581457808105, \"match_probability\": 0.9999998002888449, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4870.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1668.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7448760867118835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25512388348579407, \"precision\": 1.0, \"recall\": 0.7448760867118835, \"specificity\": 1.0, \"npv\": 0.9847514033317566, \"accuracy\": 0.9854013323783875, \"f1\": 0.8537868162692848, \"f2\": 0.7849268261233963, \"f0_5\": 0.9358905373203167, \"p4\": 0.917854359961624, \"phi\": 0.8564565100603664}, {\"truth_threshold\": 22.25938962189953, \"match_probability\": 0.9999998008153109, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4869.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1669.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7447231411933899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2552768290042877, \"precision\": 1.0, \"recall\": 0.7447231411933899, \"specificity\": 1.0, \"npv\": 0.9847424030303955, \"accuracy\": 0.9853925704956055, \"f1\": 0.8536863329534496, \"f2\": 0.7847909480674382, \"f0_5\": 0.9358422387944952, \"p4\": 0.9177943370757972, \"phi\": 0.856364670720682}, {\"truth_threshold\": 22.266722015413304, \"match_probability\": 0.9999998018250843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4862.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1676.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7436525225639343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25634750723838806, \"precision\": 1.0, \"recall\": 0.7436525225639343, \"specificity\": 1.0, \"npv\": 0.9846794009208679, \"accuracy\": 0.9853312969207764, \"f1\": 0.8529824561403508, \"f2\": 0.7838395563293996, \"f0_5\": 0.9355037327791887, \"p4\": 0.9173737284220923, \"phi\": 0.855721514125701}, {\"truth_threshold\": 22.275883775476274, \"match_probability\": 0.999999803079596, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4861.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1677.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7434995174407959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2565004527568817, \"precision\": 1.0, \"recall\": 0.7434995174407959, \"specificity\": 1.0, \"npv\": 0.9846704006195068, \"accuracy\": 0.9853225350379944, \"f1\": 0.8528818317396263, \"f2\": 0.7837036081643182, \"f0_5\": 0.935455315218228, \"p4\": 0.9173135773241676, \"phi\": 0.8556295570495529}, {\"truth_threshold\": 22.2791653431428, \"match_probability\": 0.9999998035270039, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4857.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1681.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7428877353668213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2571122646331787, \"precision\": 1.0, \"recall\": 0.7428877353668213, \"specificity\": 1.0, \"npv\": 0.9846343398094177, \"accuracy\": 0.9852875471115112, \"f1\": 0.8524791575252304, \"f2\": 0.7831597278209552, \"f0_5\": 0.9352614958022029, \"p4\": 0.9170728122878231, \"phi\": 0.8552618036241628}, {\"truth_threshold\": 22.28905587634563, \"match_probability\": 0.9999998048693364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4853.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1685.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7422759532928467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2577240765094757, \"precision\": 1.0, \"recall\": 0.7422759532928467, \"specificity\": 1.0, \"npv\": 0.9845983982086182, \"accuracy\": 0.9852525591850281, \"f1\": 0.8520762005091739, \"f2\": 0.7826157071440091, \"f0_5\": 0.9350674373795761, \"p4\": 0.916831789887897, \"phi\": 0.8548939712405295}, {\"truth_threshold\": 22.29148063052729, \"match_probability\": 0.9999998051970193, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4851.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1687.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7419700026512146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.258029967546463, \"precision\": 1.0, \"recall\": 0.7419700026512146, \"specificity\": 1.0, \"npv\": 0.984580397605896, \"accuracy\": 0.9852350354194641, \"f1\": 0.8518746158574063, \"f2\": 0.782343644163468, \"f0_5\": 0.9349703184025904, \"p4\": 0.9167111820379775, \"phi\": 0.8547099534354059}, {\"truth_threshold\": 22.2930696100624, \"match_probability\": 0.9999998054114565, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4850.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1688.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.741817057132721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25818294286727905, \"precision\": 1.0, \"recall\": 0.741817057132721, \"specificity\": 1.0, \"npv\": 0.9845713973045349, \"accuracy\": 0.9852262735366821, \"f1\": 0.8517737969792765, \"f2\": 0.7822075995097091, \"f0_5\": 0.934921736448454, \"p4\": 0.916650853926233, \"phi\": 0.8546179583709534}, {\"truth_threshold\": 22.29791225373783, \"match_probability\": 0.9999998060635299, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4846.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1692.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7412052750587463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25879472494125366, \"precision\": 1.0, \"recall\": 0.7412052750587463, \"specificity\": 1.0, \"npv\": 0.9845353960990906, \"accuracy\": 0.985191285610199, \"f1\": 0.8513703443429375, \"f2\": 0.7816633331182657, \"f0_5\": 0.9347272586991745, \"p4\": 0.9164093800717964, \"phi\": 0.8542498435000957}, {\"truth_threshold\": 22.30724794638561, \"match_probability\": 0.9999998073144426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4843.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1695.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7407463788986206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.259253591299057, \"precision\": 1.0, \"recall\": 0.7407463788986206, \"specificity\": 1.0, \"npv\": 0.9845083951950073, \"accuracy\": 0.985164999961853, \"f1\": 0.8510675687549425, \"f2\": 0.781255041135667, \"f0_5\": 0.9345812427634118, \"p4\": 0.9162281050081865, \"phi\": 0.8539736577902604}, {\"truth_threshold\": 22.312905914871987, \"match_probability\": 0.9999998080686378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4840.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1698.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7402875423431396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25971245765686035, \"precision\": 1.0, \"recall\": 0.7402875423431396, \"specificity\": 1.0, \"npv\": 0.9844813942909241, \"accuracy\": 0.9851387739181519, \"f1\": 0.8507646335032519, \"f2\": 0.780846670108415, \"f0_5\": 0.9344350915128581, \"p4\": 0.9160466843015564, \"phi\": 0.853697450280111}, {\"truth_threshold\": 22.31913357594395, \"match_probability\": 0.9999998088953593, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4839.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1699.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.740134596824646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.259865403175354, \"precision\": 1.0, \"recall\": 0.740134596824646, \"specificity\": 1.0, \"npv\": 0.984472393989563, \"accuracy\": 0.9851300120353699, \"f1\": 0.85066361958337, \"f2\": 0.7807105288632183, \"f0_5\": 0.9343863443268711, \"p4\": 0.9159861783349696, \"phi\": 0.853605364615738}, {\"truth_threshold\": 22.319842688029905, \"match_probability\": 0.9999998089892678, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4838.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1700.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7399816513061523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26001834869384766, \"precision\": 1.0, \"recall\": 0.7399816513061523, \"specificity\": 1.0, \"npv\": 0.9844633936882019, \"accuracy\": 0.9851212501525879, \"f1\": 0.85056258790436, \"f2\": 0.7805743788318813, \"f0_5\": 0.9343375820780224, \"p4\": 0.9159256561578734, \"phi\": 0.8535132182911375}, {\"truth_threshold\": 22.327054482001397, \"match_probability\": 0.9999998099417161, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4837.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1701.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7398287057876587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2601712942123413, \"precision\": 1.0, \"recall\": 0.7398287057876587, \"specificity\": 1.0, \"npv\": 0.9844543933868408, \"accuracy\": 0.9851124882698059, \"f1\": 0.8504615384615385, \"f2\": 0.7804382200135532, \"f0_5\": 0.9342888047593294, \"p4\": 0.915865117763269, \"phi\": 0.8534211161154944}, {\"truth_threshold\": 22.330695643782885, \"match_probability\": 0.9999998104207919, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4836.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1702.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.739675760269165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26032426953315735, \"precision\": 1.0, \"recall\": 0.739675760269165, \"specificity\": 1.0, \"npv\": 0.9844453930854797, \"accuracy\": 0.9851037859916687, \"f1\": 0.8503604712502199, \"f2\": 0.7803020524073835, \"f0_5\": 0.9342400123638049, \"p4\": 0.915804563144154, \"phi\": 0.8533290056827257}, {\"truth_threshold\": 22.35313676723078, \"match_probability\": 0.9999998133468796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4835.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1703.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7395228147506714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.260477215051651, \"precision\": 1.0, \"recall\": 0.7395228147506714, \"specificity\": 1.0, \"npv\": 0.9844363927841187, \"accuracy\": 0.9850950241088867, \"f1\": 0.8502593862657171, \"f2\": 0.7801658760125214, \"f0_5\": 0.9341912048844578, \"p4\": 0.9157439922935217, \"phi\": 0.8532368869901116}, {\"truth_threshold\": 22.358925295450444, \"match_probability\": 0.9999998140942877, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4834.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1704.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.739369809627533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26063016057014465, \"precision\": 1.0, \"recall\": 0.739369809627533, \"specificity\": 1.0, \"npv\": 0.9844273924827576, \"accuracy\": 0.9850862622261047, \"f1\": 0.8501582835033415, \"f2\": 0.7800296908281159, \"f0_5\": 0.9341423823142924, \"p4\": 0.9156834052043612, \"phi\": 0.8531447076056691}, {\"truth_threshold\": 22.371058675228042, \"match_probability\": 0.9999998156512386, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4833.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1705.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7392168641090393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2607831060886383, \"precision\": 1.0, \"recall\": 0.7392168641090393, \"specificity\": 1.0, \"npv\": 0.9844183921813965, \"accuracy\": 0.9850775003433228, \"f1\": 0.850057162958403, \"f2\": 0.7798934968533161, \"f0_5\": 0.9340935446463084, \"p4\": 0.9156228018696579, \"phi\": 0.8530525723800123}, {\"truth_threshold\": 22.38144543836843, \"match_probability\": 0.9999998169737012, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4830.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1708.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7387580275535583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26124197244644165, \"precision\": 1.0, \"recall\": 0.7387580275535583, \"specificity\": 1.0, \"npv\": 0.9843913912773132, \"accuracy\": 0.9850512146949768, \"f1\": 0.8497536945812808, \"f2\": 0.7794848621780388, \"f0_5\": 0.9339469409853817, \"p4\": 0.9154408943220838, \"phi\": 0.8527761170840348}, {\"truth_threshold\": 22.383131507528617, \"match_probability\": 0.999999817187478, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4826.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1712.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7381462454795837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26185378432273865, \"precision\": 1.0, \"recall\": 0.7381462454795837, \"specificity\": 1.0, \"npv\": 0.9843554496765137, \"accuracy\": 0.9850162267684937, \"f1\": 0.8493488208377332, \"f2\": 0.7789398928271677, \"f0_5\": 0.9337512576425974, \"p4\": 0.915198123061452, \"phi\": 0.8524073416724053}, {\"truth_threshold\": 22.397809839641422, \"match_probability\": 0.999999819038027, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4825.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1713.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7379932403564453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2620067298412323, \"precision\": 1.0, \"recall\": 0.7379932403564453, \"specificity\": 1.0, \"npv\": 0.9843464493751526, \"accuracy\": 0.9850074648857117, \"f1\": 0.8492475578632404, \"f2\": 0.7788036284985634, \"f0_5\": 0.9337022989395464, \"p4\": 0.9151373895093915, \"phi\": 0.8523150877450307}, {\"truth_threshold\": 22.399369216718227, \"match_probability\": 0.9999998192335191, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4821.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1717.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7373814582824707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2626185417175293, \"precision\": 1.0, \"recall\": 0.7373814582824707, \"specificity\": 1.0, \"npv\": 0.9843104481697083, \"accuracy\": 0.9849724769592285, \"f1\": 0.8488423276696893, \"f2\": 0.7782584831950409, \"f0_5\": 0.9335063124467509, \"p4\": 0.9148942921420041, \"phi\": 0.8519461989925933}, {\"truth_threshold\": 22.402850975167706, \"match_probability\": 0.9999998196692497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4820.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1718.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.737228512763977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26277148723602295, \"precision\": 1.0, \"recall\": 0.737228512763977, \"specificity\": 1.0, \"npv\": 0.9843014478683472, \"accuracy\": 0.9849637150764465, \"f1\": 0.8487409755238599, \"f2\": 0.7781221748676224, \"f0_5\": 0.933457277868154, \"p4\": 0.9148334769750646, \"phi\": 0.8518539035572825}, {\"truth_threshold\": 22.407584551253155, \"match_probability\": 0.9999998202599568, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4818.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1720.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7369226217269897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26307740807533264, \"precision\": 1.0, \"recall\": 0.7369226217269897, \"specificity\": 1.0, \"npv\": 0.9842835068702698, \"accuracy\": 0.9849461913108826, \"f1\": 0.8485382176822825, \"f2\": 0.7778495318049725, \"f0_5\": 0.9333591631150717, \"p4\": 0.9147117976015878, \"phi\": 0.8516693927667709}, {\"truth_threshold\": 22.42026644693331, \"match_probability\": 0.9999998218330229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4814.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1724.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7363107800483704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26368919014930725, \"precision\": 1.0, \"recall\": 0.7363107800483704, \"specificity\": 1.0, \"npv\": 0.9842475056648254, \"accuracy\": 0.9849112033843994, \"f1\": 0.8481324876673714, \"f2\": 0.7773041400245431, \"f0_5\": 0.9331627510273707, \"p4\": 0.9144682424979864, \"phi\": 0.851300218921768}, {\"truth_threshold\": 22.430677113075557, \"match_probability\": 0.9999998231140701, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4810.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1728.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7356989979743958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26430100202560425, \"precision\": 1.0, \"recall\": 0.7356989979743958, \"specificity\": 1.0, \"npv\": 0.9842115640640259, \"accuracy\": 0.9848762154579163, \"f1\": 0.847726471624956, \"f2\": 0.7767586073251082, \"f0_5\": 0.9329660951198696, \"p4\": 0.9142244252072866, \"phi\": 0.8509309119140325}, {\"truth_threshold\": 22.445543683450108, \"match_probability\": 0.9999998249274706, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4809.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1729.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7355460524559021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2644539475440979, \"precision\": 1.0, \"recall\": 0.7355460524559021, \"specificity\": 1.0, \"npv\": 0.9842025637626648, \"accuracy\": 0.9848674535751343, \"f1\": 0.8476249228871067, \"f2\": 0.7766222021252543, \"f0_5\": 0.9329168929929387, \"p4\": 0.9141634298646041, \"phi\": 0.8508385774745958}, {\"truth_threshold\": 22.44872037233849, \"match_probability\": 0.999999825312541, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4808.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1730.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7353931069374084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26460692286491394, \"precision\": 1.0, \"recall\": 0.7353931069374084, \"specificity\": 1.0, \"npv\": 0.9841935634613037, \"accuracy\": 0.9848586916923523, \"f1\": 0.8475233562488983, \"f2\": 0.7764857881136951, \"f0_5\": 0.9328676755917734, \"p4\": 0.9141024180996916, \"phi\": 0.8507462347013164}, {\"truth_threshold\": 22.449350503273962, \"match_probability\": 0.9999998253888231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4804.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1734.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7347812652587891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26521873474121094, \"precision\": 1.0, \"recall\": 0.7347812652587891, \"specificity\": 1.0, \"npv\": 0.9841575622558594, \"accuracy\": 0.9848237037658691, \"f1\": 0.8471169105977782, \"f2\": 0.7759400439333247, \"f0_5\": 0.9326706531024307, \"p4\": 0.91385820667527, \"phi\": 0.8503767276290449}, {\"truth_threshold\": 22.46707684499975, \"match_probability\": 0.9999998275211373, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4803.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1735.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7346283197402954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2653716802597046, \"precision\": 1.0, \"recall\": 0.7346283197402954, \"specificity\": 1.0, \"npv\": 0.9841486215591431, \"accuracy\": 0.9848149418830872, \"f1\": 0.8470152543867384, \"f2\": 0.7758035858504281, \"f0_5\": 0.9326213592233009, \"p4\": 0.9137971126923173, \"phi\": 0.8502843431398863}, {\"truth_threshold\": 22.484125708469687, \"match_probability\": 0.9999998295473878, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4802.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1736.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7344753742218018, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26552462577819824, \"precision\": 1.0, \"recall\": 0.7344753742218018, \"specificity\": 1.0, \"npv\": 0.984139621257782, \"accuracy\": 0.9848061800003052, \"f1\": 0.8469135802469135, \"f2\": 0.7756671189507011, \"f0_5\": 0.9325720500271887, \"p4\": 0.9137360022443496, \"phi\": 0.8501918977043286}, {\"truth_threshold\": 22.49311449169694, \"match_probability\": 0.9999998306060994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4801.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1737.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7343224287033081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2656775712966919, \"precision\": 1.0, \"recall\": 0.7343224287033081, \"specificity\": 1.0, \"npv\": 0.9841306209564209, \"accuracy\": 0.9847974181175232, \"f1\": 0.8468118881735602, \"f2\": 0.7755306432332891, \"f0_5\": 0.9325227255069536, \"p4\": 0.9136748753242215, \"phi\": 0.8500994965063091}, {\"truth_threshold\": 22.496780467998672, \"match_probability\": 0.9999998310359932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4800.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1738.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7341694831848145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26583051681518555, \"precision\": 1.0, \"recall\": 0.7341694831848145, \"specificity\": 1.0, \"npv\": 0.9841216206550598, \"accuracy\": 0.9847886562347412, \"f1\": 0.8467101781619333, \"f2\": 0.7753941586973379, \"f0_5\": 0.9324733856554511, \"p4\": 0.9136137319247838, \"phi\": 0.8500070869523209}, {\"truth_threshold\": 22.49842863514994, \"match_probability\": 0.9999998312289112, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4799.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1739.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7340165376663208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2659834921360016, \"precision\": 1.0, \"recall\": 0.7340165376663208, \"specificity\": 1.0, \"npv\": 0.9841126203536987, \"accuracy\": 0.984779953956604, \"f1\": 0.8466084502072859, \"f2\": 0.7752576653419921, \"f0_5\": 0.932424030465532, \"p4\": 0.9135525720388827, \"phi\": 0.8499146690395923}, {\"truth_threshold\": 22.499991467472483, \"match_probability\": 0.9999998314116373, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4798.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1740.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7338635921478271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26613643765449524, \"precision\": 1.0, \"recall\": 0.7338635921478271, \"specificity\": 1.0, \"npv\": 0.9841036200523376, \"accuracy\": 0.984771192073822, \"f1\": 0.8465067043048694, \"f2\": 0.7751211631663975, \"f0_5\": 0.9323746599300428, \"p4\": 0.9134913956593607, \"phi\": 0.8498222427653498}, {\"truth_threshold\": 22.52306176867309, \"match_probability\": 0.9999998340861117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4794.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1744.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7332517504692078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26674824953079224, \"precision\": 1.0, \"recall\": 0.7332517504692078, \"specificity\": 1.0, \"npv\": 0.9840676784515381, \"accuracy\": 0.9847361445426941, \"f1\": 0.846099541122485, \"f2\": 0.7745750662444257, \"f0_5\": 0.9321770241891577, \"p4\": 0.9132465250617641, \"phi\": 0.8494524013598099}, {\"truth_threshold\": 22.53344853181348, \"match_probability\": 0.9999998352763281, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4792.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1746.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7329458594322205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26705414056777954, \"precision\": 1.0, \"recall\": 0.7329458594322205, \"specificity\": 1.0, \"npv\": 0.9840496778488159, \"accuracy\": 0.9847186803817749, \"f1\": 0.8458958517210945, \"f2\": 0.7743019648397105, \"f0_5\": 0.9320781140589746, \"p4\": 0.9131239906148358, \"phi\": 0.8492674040757819}, {\"truth_threshold\": 22.534543296654515, \"match_probability\": 0.9999998354012785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4789.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1749.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7324870228767395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2675130069255829, \"precision\": 1.0, \"recall\": 0.7324870228767395, \"specificity\": 1.0, \"npv\": 0.9840227365493774, \"accuracy\": 0.984692394733429, \"f1\": 0.8455901827491834, \"f2\": 0.7738922465337255, \"f0_5\": 0.9319296333774422, \"p4\": 0.9129400648476501, \"phi\": 0.8489899242423625}, {\"truth_threshold\": 22.536517822450165, \"match_probability\": 0.9999998356264003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4788.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1750.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7323340177536011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26766595244407654, \"precision\": 1.0, \"recall\": 0.7323340177536011, \"specificity\": 1.0, \"npv\": 0.9840137362480164, \"accuracy\": 0.984683632850647, \"f1\": 0.8454882571075402, \"f2\": 0.7737556561085973, \"f0_5\": 0.9318801089918256, \"p4\": 0.912878723137334, \"phi\": 0.84889736152017}, {\"truth_threshold\": 22.548256045889403, \"match_probability\": 0.9999998369583697, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4787.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1751.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7321810722351074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2678188979625702, \"precision\": 1.0, \"recall\": 0.7321810722351074, \"specificity\": 1.0, \"npv\": 0.9840047359466553, \"accuracy\": 0.984674870967865, \"f1\": 0.8453863134657836, \"f2\": 0.7736190568538092, \"f0_5\": 0.9318305691816554, \"p4\": 0.9128173648543887, \"phi\": 0.8488048430700391}, {\"truth_threshold\": 22.551372310163277, \"match_probability\": 0.9999998373101643, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4786.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1752.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7320281267166138, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26797184348106384, \"precision\": 1.0, \"recall\": 0.7320281267166138, \"specificity\": 1.0, \"npv\": 0.9839957356452942, \"accuracy\": 0.9846661686897278, \"f1\": 0.8452843518191452, \"f2\": 0.7734824487685048, \"f0_5\": 0.9317810139397243, \"p4\": 0.9127559899916066, \"phi\": 0.8487123162249963}, {\"truth_threshold\": 22.551620839544512, \"match_probability\": 0.999999837338188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4785.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1753.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7318751811981201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2681248188018799, \"precision\": 1.0, \"recall\": 0.7318751811981201, \"specificity\": 1.0, \"npv\": 0.9839867949485779, \"accuracy\": 0.9846574068069458, \"f1\": 0.8451823721628544, \"f2\": 0.7733458318518279, \"f0_5\": 0.9317314432588207, \"p4\": 0.912694598541776, \"phi\": 0.8486197809822488}, {\"truth_threshold\": 22.551776356701716, \"match_probability\": 0.9999998373557214, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4784.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1754.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7317222356796265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26827776432037354, \"precision\": 1.0, \"recall\": 0.7317222356796265, \"specificity\": 1.0, \"npv\": 0.9839777946472168, \"accuracy\": 0.9846486449241638, \"f1\": 0.8450803744921392, \"f2\": 0.7732092061029222, \"f0_5\": 0.9316818571317286, \"p4\": 0.9126331904976812, \"phi\": 0.8485271846485093}, {\"truth_threshold\": 22.55657499583885, \"match_probability\": 0.999999837895804, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4782.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1756.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7314163446426392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26858365535736084, \"precision\": 1.0, \"recall\": 0.7314163446426392, \"specificity\": 1.0, \"npv\": 0.9839597940444946, \"accuracy\": 0.9846311211585999, \"f1\": 0.8448763250883392, \"f2\": 0.7729359281049978, \"f0_5\": 0.9315826385100912, \"p4\": 0.9125103245978141, \"phi\": 0.8483420721388049}, {\"truth_threshold\": 22.59162194293805, \"match_probability\": 0.9999998417863041, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4781.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1757.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7312633991241455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2687366306781769, \"precision\": 1.0, \"recall\": 0.7312633991241455, \"specificity\": 1.0, \"npv\": 0.9839507937431335, \"accuracy\": 0.9846223592758179, \"f1\": 0.8447742733457019, \"f2\": 0.7727992758542657, \"f0_5\": 0.9315330060010911, \"p4\": 0.9124488667275892, \"phi\": 0.8482495032720166}, {\"truth_threshold\": 22.605523928865065, \"match_probability\": 0.9999998433035485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4780.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1758.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7311104536056519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26888957619667053, \"precision\": 1.0, \"recall\": 0.7311104536056519, \"specificity\": 1.0, \"npv\": 0.9839418530464172, \"accuracy\": 0.9846136569976807, \"f1\": 0.8446722035695352, \"f2\": 0.7726626147678779, \"f0_5\": 0.9314833580169928, \"p4\": 0.9123873922341945, \"phi\": 0.848156925993539}, {\"truth_threshold\": 22.640692569009143, \"match_probability\": 0.9999998470771625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4777.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1761.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7306515574455261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2693484127521515, \"precision\": 1.0, \"recall\": 0.7306515574455261, \"specificity\": 1.0, \"npv\": 0.983914852142334, \"accuracy\": 0.9845873713493347, \"f1\": 0.844365885992046, \"f2\": 0.7722525784862103, \"f0_5\": 0.9313343211416986, \"p4\": 0.9122028689426034, \"phi\": 0.8478790909325511}, {\"truth_threshold\": 22.652623738670247, \"match_probability\": 0.9999998483366278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4776.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1762.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7304986119270325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26950138807296753, \"precision\": 1.0, \"recall\": 0.7304986119270325, \"specificity\": 1.0, \"npv\": 0.9839059114456177, \"accuracy\": 0.9845786094665527, \"f1\": 0.8442637440339402, \"f2\": 0.772115882048629, \"f0_5\": 0.931284611184775, \"p4\": 0.9121413278841198, \"phi\": 0.8477864799740105}, {\"truth_threshold\": 22.655171249805914, \"match_probability\": 0.9999998486041987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4773.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1765.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7300397753715515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2699602246284485, \"precision\": 1.0, \"recall\": 0.7300397753715515, \"specificity\": 1.0, \"npv\": 0.9838789105415344, \"accuracy\": 0.9845523834228516, \"f1\": 0.843957209795774, \"f2\": 0.7717057396928052, \"f0_5\": 0.9311353882169333, \"p4\": 0.9119566047232597, \"phi\": 0.8475085437843597}, {\"truth_threshold\": 22.66323942672135, \"match_probability\": 0.9999998494485065, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4772.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1766.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7298868298530579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27011317014694214, \"precision\": 1.0, \"recall\": 0.7298868298530579, \"specificity\": 1.0, \"npv\": 0.9838699102401733, \"accuracy\": 0.9845436215400696, \"f1\": 0.8438549955791335, \"f2\": 0.7715690078903117, \"f0_5\": 0.9310856161710762, \"p4\": 0.9118949969836296, \"phi\": 0.8474158991008309}, {\"truth_threshold\": 22.676869229556562, \"match_probability\": 0.9999998508641378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4771.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1767.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7297338843345642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2702661454677582, \"precision\": 1.0, \"recall\": 0.7297338843345642, \"specificity\": 1.0, \"npv\": 0.983860969543457, \"accuracy\": 0.9845348596572876, \"f1\": 0.8437527632858784, \"f2\": 0.7714322672444459, \"f0_5\": 0.9310358285848099, \"p4\": 0.9118333725555473, \"phi\": 0.8473232459803463}, {\"truth_threshold\": 22.683300852767104, \"match_probability\": 0.9999998515275147, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4770.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1768.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7295809388160706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27041909098625183, \"precision\": 1.0, \"recall\": 0.7295809388160706, \"specificity\": 1.0, \"npv\": 0.983851969242096, \"accuracy\": 0.9845260977745056, \"f1\": 0.8436505129112133, \"f2\": 0.7712955177543497, \"f0_5\": 0.9309860254508548, \"p4\": 0.9117717314317381, \"phi\": 0.8472305316557043}, {\"truth_threshold\": 22.686259797392598, \"match_probability\": 0.9999998518317174, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4765.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1773.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7288161516189575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2711838483810425, \"precision\": 1.0, \"recall\": 0.7288161516189575, \"specificity\": 1.0, \"npv\": 0.9838070273399353, \"accuracy\": 0.9844823479652405, \"f1\": 0.8431389896487658, \"f2\": 0.7706116376103762, \"f0_5\": 0.9307367763106492, \"p4\": 0.9114632751218789, \"phi\": 0.8467670443419403}, {\"truth_threshold\": 22.712949753016677, \"match_probability\": 0.9999998545476403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4764.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1774.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7286632061004639, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27133679389953613, \"precision\": 1.0, \"recall\": 0.7286632061004639, \"specificity\": 1.0, \"npv\": 0.9837980270385742, \"accuracy\": 0.9844735860824585, \"f1\": 0.8430366306848346, \"f2\": 0.7704748350368741, \"f0_5\": 0.9306868797374385, \"p4\": 0.9114015336707033, \"phi\": 0.8466743320732804}, {\"truth_threshold\": 22.71726622369229, \"match_probability\": 0.999999854982176, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4760.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1778.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7280513644218445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27194860577583313, \"precision\": 1.0, \"recall\": 0.7280513644218445, \"specificity\": 1.0, \"npv\": 0.9837620854377747, \"accuracy\": 0.9844385981559753, \"f1\": 0.8426270136307311, \"f2\": 0.769927536231884, \"f0_5\": 0.9304871373836892, \"p4\": 0.9111544003252141, \"phi\": 0.8463033455578411}, {\"truth_threshold\": 22.75644727425731, \"match_probability\": 0.999999858867604, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4759.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1779.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7278984189033508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2721015512943268, \"precision\": 1.0, \"recall\": 0.7278984189033508, \"specificity\": 1.0, \"npv\": 0.9837531447410583, \"accuracy\": 0.9844298362731934, \"f1\": 0.8425245640435514, \"f2\": 0.769790689398596, \"f0_5\": 0.9304371627434113, \"p4\": 0.9110925750670705, \"phi\": 0.8462105909580165}, {\"truth_threshold\": 22.759470847504318, \"match_probability\": 0.9999998591630769, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4758.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1780.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7277454733848572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2722545266151428, \"precision\": 1.0, \"recall\": 0.7277454733848572, \"specificity\": 1.0, \"npv\": 0.9837441444396973, \"accuracy\": 0.9844210743904114, \"f1\": 0.8424220963172805, \"f2\": 0.7696538337107732, \"f0_5\": 0.9303871724677356, \"p4\": 0.9110307330255738, \"phi\": 0.846117827884528}, {\"truth_threshold\": 22.76083966778186, \"match_probability\": 0.9999998592966387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4757.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1781.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7275925278663635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2724074721336365, \"precision\": 1.0, \"recall\": 0.7275925278663635, \"specificity\": 1.0, \"npv\": 0.9837351441383362, \"accuracy\": 0.9844123125076294, \"f1\": 0.8423196104471005, \"f2\": 0.7695169691675564, \"f0_5\": 0.9303371665493233, \"p4\": 0.910968874193394, \"phi\": 0.8460250563345422}, {\"truth_threshold\": 22.791886573079083, \"match_probability\": 0.9999998622922368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4756.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1782.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7274395823478699, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2725604176521301, \"precision\": 1.0, \"recall\": 0.7274395823478699, \"specificity\": 1.0, \"npv\": 0.9837262034416199, \"accuracy\": 0.9844036102294922, \"f1\": 0.8422171064281919, \"f2\": 0.769380095768086, \"f0_5\": 0.9302871449808309, \"p4\": 0.9109069985631971, \"phi\": 0.8459322234666119}, {\"truth_threshold\": 22.796919884152967, \"match_probability\": 0.999999862771838, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4755.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1783.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7272866368293762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2727133631706238, \"precision\": 1.0, \"recall\": 0.7272866368293762, \"specificity\": 1.0, \"npv\": 0.9837172031402588, \"accuracy\": 0.9843948483467102, \"f1\": 0.8421145842557336, \"f2\": 0.7692432135115023, \"f0_5\": 0.9302371077549104, \"p4\": 0.9108451061276448, \"phi\": 0.845839434949809}, {\"truth_threshold\": 22.80221583987016, \"match_probability\": 0.9999998632746622, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4754.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1784.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7271336913108826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27286630868911743, \"precision\": 1.0, \"recall\": 0.7271336913108826, \"specificity\": 1.0, \"npv\": 0.9837082028388977, \"accuracy\": 0.9843860864639282, \"f1\": 0.8420120439249026, \"f2\": 0.7691063223969455, \"f0_5\": 0.9301870548642092, \"p4\": 0.9107831968793945, \"phi\": 0.8457466379479969}, {\"truth_threshold\": 22.808113762834815, \"match_probability\": 0.9999998638324719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4753.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1785.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7269807457923889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27301928400993347, \"precision\": 1.0, \"recall\": 0.7269807457923889, \"specificity\": 1.0, \"npv\": 0.9836992025375366, \"accuracy\": 0.9843773245811462, \"f1\": 0.8419094854308742, \"f2\": 0.768969422423556, \"f0_5\": 0.9301369863013699, \"p4\": 0.9107212708110993, \"phi\": 0.8456538324583354}, {\"truth_threshold\": 22.826653138445295, \"match_probability\": 0.9999998655710995, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4752.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1786.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7268278002738953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2731722295284271, \"precision\": 1.0, \"recall\": 0.7268278002738953, \"specificity\": 1.0, \"npv\": 0.9836902618408203, \"accuracy\": 0.9843685626983643, \"f1\": 0.8418069087688219, \"f2\": 0.7688325135904738, \"f0_5\": 0.9300869020590308, \"p4\": 0.910659327915408, \"phi\": 0.8455610184779837}, {\"truth_threshold\": 22.830314984327163, \"match_probability\": 0.9999998659118741, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4748.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1790.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7262159585952759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2737840414047241, \"precision\": 1.0, \"recall\": 0.7262159585952759, \"specificity\": 1.0, \"npv\": 0.9836543202400208, \"accuracy\": 0.9843335747718811, \"f1\": 0.8413964203437888, \"f2\": 0.7682847896440129, \"f0_5\": 0.9298864081472777, \"p4\": 0.9104113879115101, \"phi\": 0.8451896247116201}, {\"truth_threshold\": 22.837762663084387, \"match_probability\": 0.9999998666022984, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4746.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1792.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7259100675582886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2740899324417114, \"precision\": 1.0, \"recall\": 0.7259100675582886, \"specificity\": 1.0, \"npv\": 0.9836363196372986, \"accuracy\": 0.9843160510063171, \"f1\": 0.8411910669975186, \"f2\": 0.7680108744902583, \"f0_5\": 0.929786066922655, \"p4\": 0.9102873167537404, \"phi\": 0.8450038503484096}, {\"truth_threshold\": 22.853300683343686, \"match_probability\": 0.9999998680313005, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4745.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1793.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7257571220397949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2742428779602051, \"precision\": 1.0, \"recall\": 0.7257571220397949, \"specificity\": 1.0, \"npv\": 0.9836273789405823, \"accuracy\": 0.9843072891235352, \"f1\": 0.8410883630240185, \"f2\": 0.7678739036152378, \"f0_5\": 0.9297358727172976, \"p4\": 0.9102252558600852, \"phi\": 0.8449109768428813}, {\"truth_threshold\": 22.868558334698857, \"match_probability\": 0.9999998694196204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4744.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1794.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7256041765213013, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2743958532810211, \"precision\": 1.0, \"recall\": 0.7256041765213013, \"specificity\": 1.0, \"npv\": 0.9836183786392212, \"accuracy\": 0.9842985272407532, \"f1\": 0.840985640843822, \"f2\": 0.7677369238736406, \"f0_5\": 0.9296856627733793, \"p4\": 0.9101631780800704, \"phi\": 0.8448180948238754}, {\"truth_threshold\": 22.901389150708997, \"match_probability\": 0.9999998723576276, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4743.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1795.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7254512310028076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27454879879951477, \"precision\": 1.0, \"recall\": 0.7254512310028076, \"specificity\": 1.0, \"npv\": 0.9836093783378601, \"accuracy\": 0.984289824962616, \"f1\": 0.8408829004520876, \"f2\": 0.7675999352646059, \"f0_5\": 0.9296354370834967, \"p4\": 0.9101010834063065, \"phi\": 0.8447252042885367}, {\"truth_threshold\": 22.902311564360446, \"match_probability\": 0.999999872439212, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4742.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1796.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.725298285484314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2747017443180084, \"precision\": 1.0, \"recall\": 0.725298285484314, \"specificity\": 1.0, \"npv\": 0.9836004376411438, \"accuracy\": 0.984281063079834, \"f1\": 0.8407801418439717, \"f2\": 0.7674629377872726, \"f0_5\": 0.9295851956402416, \"p4\": 0.9100389718313993, \"phi\": 0.8446322523208387}, {\"truth_threshold\": 22.90409607666511, \"match_probability\": 0.999999872596898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4740.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1798.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7249923348426819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2750076353549957, \"precision\": 1.0, \"recall\": 0.7249923348426819, \"specificity\": 1.0, \"npv\": 0.9835824370384216, \"accuracy\": 0.98426353931427, \"f1\": 0.8405745699592126, \"f2\": 0.7671889162242652, \"f0_5\": 0.9294846654639579, \"p4\": 0.9099146979485571, \"phi\": 0.844446428632106}, {\"truth_threshold\": 22.90845036770236, \"match_probability\": 0.9999998729808418, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4738.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1800.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7246864438056946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2753135561943054, \"precision\": 1.0, \"recall\": 0.7246864438056946, \"specificity\": 1.0, \"npv\": 0.9835644960403442, \"accuracy\": 0.984246015548706, \"f1\": 0.8403689251507627, \"f2\": 0.7669148591777274, \"f0_5\": 0.9293840721851706, \"p4\": 0.9097903563723053, \"phi\": 0.8442605178977628}, {\"truth_threshold\": 22.912383012471178, \"match_probability\": 0.9999998733266121, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4737.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1801.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7245334982872009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2754665017127991, \"precision\": 1.0, \"recall\": 0.7245334982872009, \"specificity\": 1.0, \"npv\": 0.9835554957389832, \"accuracy\": 0.9842373132705688, \"f1\": 0.8402660753880266, \"f2\": 0.7667778173459807, \"f0_5\": 0.9293337518637683, \"p4\": 0.9097281601806197, \"phi\": 0.844167576193703}, {\"truth_threshold\": 22.93739677977978, \"match_probability\": 0.9999998755039728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4736.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1802.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7243805527687073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2756194472312927, \"precision\": 1.0, \"recall\": 0.7243805527687073, \"specificity\": 1.0, \"npv\": 0.9835465550422668, \"accuracy\": 0.9842285513877869, \"f1\": 0.840163207379812, \"f2\": 0.7666407666407666, \"f0_5\": 0.9292834157444471, \"p4\": 0.9096659470433359, \"phi\": 0.8440746259532814}, {\"truth_threshold\": 22.956021175949196, \"match_probability\": 0.9999998771008182, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4735.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1803.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7242276072502136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2757723927497864, \"precision\": 1.0, \"recall\": 0.7242276072502136, \"specificity\": 1.0, \"npv\": 0.9835375547409058, \"accuracy\": 0.9842197895050049, \"f1\": 0.8400603211212632, \"f2\": 0.7665037070612232, \"f0_5\": 0.9292330638197661, \"p4\": 0.9096037169530296, \"phi\": 0.8439816671736311}, {\"truth_threshold\": 22.9677704288233, \"match_probability\": 0.9999998780976398, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4732.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1806.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7237687110900879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2762312591075897, \"precision\": 1.0, \"recall\": 0.7237687110900879, \"specificity\": 1.0, \"npv\": 0.9835106134414673, \"accuracy\": 0.9841935038566589, \"f1\": 0.8397515527950311, \"f2\": 0.7660924750679964, \"f0_5\": 0.9290819131390874, \"p4\": 0.909416924889667, \"phi\": 0.8437026866039826}, {\"truth_threshold\": 22.971141515175038, \"match_probability\": 0.9999998783821514, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4731.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1807.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7236157655715942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2763842046260834, \"precision\": 1.0, \"recall\": 0.7236157655715942, \"specificity\": 1.0, \"npv\": 0.9835016131401062, \"accuracy\": 0.9841848015785217, \"f1\": 0.8396485934865561, \"f2\": 0.7659553799825146, \"f0_5\": 0.9290314979184667, \"p4\": 0.9093546269129408, \"phi\": 0.843609693633362}, {\"truth_threshold\": 22.97598415885047, \"match_probability\": 0.9999998787896973, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4730.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1808.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7234628200531006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2765371799468994, \"precision\": 1.0, \"recall\": 0.7234628200531006, \"specificity\": 1.0, \"npv\": 0.9834926724433899, \"accuracy\": 0.9841760396957397, \"f1\": 0.8395456159034433, \"f2\": 0.7658182760183926, \"f0_5\": 0.9289810668552125, \"p4\": 0.9092923119460053, \"phi\": 0.8435166921091535}, {\"truth_threshold\": 22.997914593142543, \"match_probability\": 0.9999998806182838, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4725.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1813.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7226980924606323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27730193734169006, \"precision\": 1.0, \"recall\": 0.7226980924606323, \"specificity\": 1.0, \"npv\": 0.9834477305412292, \"accuracy\": 0.9841322898864746, \"f1\": 0.839030453697949, \"f2\": 0.7651326229879846, \"f0_5\": 0.9287286736378646, \"p4\": 0.9089804819972789, \"phi\": 0.8430515030794186}, {\"truth_threshold\": 23.005228947654466, \"match_probability\": 0.9999998812220082, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4724.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1814.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7225451469421387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2774548828601837, \"precision\": 1.0, \"recall\": 0.7225451469421387, \"specificity\": 1.0, \"npv\": 0.9834387898445129, \"accuracy\": 0.9841235280036926, \"f1\": 0.8389273663647665, \"f2\": 0.7649954657339033, \"f0_5\": 0.9286781473617992, \"p4\": 0.9089180649324798, \"phi\": 0.8429583971583375}, {\"truth_threshold\": 23.005716154242652, \"match_probability\": 0.9999998812621135, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4720.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1818.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7219333052635193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2780666947364807, \"precision\": 1.0, \"recall\": 0.7219333052635193, \"specificity\": 1.0, \"npv\": 0.9834028482437134, \"accuracy\": 0.9840884804725647, \"f1\": 0.8385148338958962, \"f2\": 0.7644467478621404, \"f0_5\": 0.928475883232355, \"p4\": 0.9086682261739251, \"phi\": 0.8425860466932009}, {\"truth_threshold\": 23.030506184171262, \"match_probability\": 0.9999998832849736, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4719.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1819.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7217803597450256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27821964025497437, \"precision\": 1.0, \"recall\": 0.7217803597450256, \"specificity\": 1.0, \"npv\": 0.9833939075469971, \"accuracy\": 0.9840797781944275, \"f1\": 0.8384116549702407, \"f2\": 0.7643095461760228, \"f0_5\": 0.9284252774061541, \"p4\": 0.9086057238220097, \"phi\": 0.8424929508732404}, {\"truth_threshold\": 23.049031946438582, \"match_probability\": 0.9999998847741387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4716.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1822.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7213215231895447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2786785066127777, \"precision\": 1.0, \"recall\": 0.7213215231895447, \"specificity\": 1.0, \"npv\": 0.9833669662475586, \"accuracy\": 0.9840534925460815, \"f1\": 0.8381020081748711, \"f2\": 0.7638978877802255, \"f0_5\": 0.9282733643020235, \"p4\": 0.9084181142568433, \"phi\": 0.8422136118725388}, {\"truth_threshold\": 23.056772921806353, \"match_probability\": 0.9999998853907429, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4715.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1823.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.721168577671051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27883145213127136, \"precision\": 1.0, \"recall\": 0.721168577671051, \"specificity\": 1.0, \"npv\": 0.9833579659461975, \"accuracy\": 0.9840447306632996, \"f1\": 0.837998755887319, \"f2\": 0.7637606505329316, \"f0_5\": 0.9282226947003701, \"p4\": 0.9083555435402906, \"phi\": 0.8421204286244632}, {\"truth_threshold\": 23.089687544279087, \"match_probability\": 0.9999998879759138, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4714.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1824.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7210155725479126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.278984397649765, \"precision\": 1.0, \"recall\": 0.7210155725479126, \"specificity\": 1.0, \"npv\": 0.9833490252494812, \"accuracy\": 0.9840359687805176, \"f1\": 0.8378954852470671, \"f2\": 0.7636234043931834, \"f0_5\": 0.9281720091360164, \"p4\": 0.9082929557137998, \"phi\": 0.8420272898291237}, {\"truth_threshold\": 23.098040180821624, \"match_probability\": 0.9999998886226152, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4713.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1825.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.720862627029419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27913734316825867, \"precision\": 1.0, \"recall\": 0.720862627029419, \"specificity\": 1.0, \"npv\": 0.9833400249481201, \"accuracy\": 0.9840272665023804, \"f1\": 0.8377921962492223, \"f2\": 0.7634861493601166, \"f0_5\": 0.9281213076014179, \"p4\": 0.9082303507698506, \"phi\": 0.841934142431088}, {\"truth_threshold\": 23.118411032534638, \"match_probability\": 0.9999998901842128, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4710.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1828.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.720403790473938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.279596209526062, \"precision\": 1.0, \"recall\": 0.720403790473938, \"specificity\": 1.0, \"npv\": 0.9833130836486816, \"accuracy\": 0.9840009808540344, \"f1\": 0.8374822190611664, \"f2\": 0.7630743308923595, \"f0_5\": 0.9279691071006384, \"p4\": 0.908042433157983, \"phi\": 0.8416545955069153}, {\"truth_threshold\": 23.122817054842326, \"match_probability\": 0.9999998905190809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4709.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1829.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7202508449554443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27974915504455566, \"precision\": 1.0, \"recall\": 0.7202508449554443, \"specificity\": 1.0, \"npv\": 0.9833041429519653, \"accuracy\": 0.9839922189712524, \"f1\": 0.8373788565839779, \"f2\": 0.7629370402773727, \"f0_5\": 0.9279183416095216, \"p4\": 0.9079797596689088, \"phi\": 0.8415614136636637}, {\"truth_threshold\": 23.123144608620088, \"match_probability\": 0.9999998905439349, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4708.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1830.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7200978994369507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2799021005630493, \"precision\": 1.0, \"recall\": 0.7200978994369507, \"specificity\": 1.0, \"npv\": 0.9832951426506042, \"accuracy\": 0.9839834570884705, \"f1\": 0.8372754757247021, \"f2\": 0.762799740764744, \"f0_5\": 0.9278675601103665, \"p4\": 0.9079170690247085, \"phi\": 0.8414682232031877}, {\"truth_threshold\": 23.124703985696893, \"match_probability\": 0.9999998906621796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4705.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1833.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7196390628814697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28036096692085266, \"precision\": 1.0, \"recall\": 0.7196390628814697, \"specificity\": 1.0, \"npv\": 0.9832682013511658, \"accuracy\": 0.9839572310447693, \"f1\": 0.8369652228053011, \"f2\": 0.7623877888323557, \"f0_5\": 0.9277151194889187, \"p4\": 0.9077288940858613, \"phi\": 0.8411885469774609}, {\"truth_threshold\": 23.14528083778612, \"match_probability\": 0.9999998922105731, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4703.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1835.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7193331122398376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28066685795783997, \"precision\": 1.0, \"recall\": 0.7193331122398376, \"specificity\": 1.0, \"npv\": 0.9832502603530884, \"accuracy\": 0.9839397072792053, \"f1\": 0.8367582955253091, \"f2\": 0.7621131097066925, \"f0_5\": 0.9276134122287969, \"p4\": 0.9076033582125239, \"phi\": 0.8410020884178881}, {\"truth_threshold\": 23.148666253891594, \"match_probability\": 0.9999998924632143, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4702.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1836.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.719180166721344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.280819833278656, \"precision\": 1.0, \"recall\": 0.719180166721344, \"specificity\": 1.0, \"npv\": 0.9832413196563721, \"accuracy\": 0.9839309453964233, \"f1\": 0.8366548042704627, \"f2\": 0.7619757567900435, \"f0_5\": 0.9275625345222126, \"p4\": 0.9075405644789302, \"phi\": 0.8409088461874973}, {\"truth_threshold\": 23.153277291773318, \"match_probability\": 0.9999998928063669, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4693.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1845.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7178035974502563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28219640254974365, \"precision\": 1.0, \"recall\": 0.7178035974502563, \"specificity\": 1.0, \"npv\": 0.9831605553627014, \"accuracy\": 0.983852207660675, \"f1\": 0.835722553646158, \"f2\": 0.7607391797698169, \"f0_5\": 0.9271039114974319, \"p4\": 0.9069746456042288, \"phi\": 0.840069170716297}, {\"truth_threshold\": 23.171122861183484, \"match_probability\": 0.9999998941241428, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4692.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1846.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7176506519317627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2823493480682373, \"precision\": 1.0, \"recall\": 0.7176506519317627, \"specificity\": 1.0, \"npv\": 0.9831515550613403, \"accuracy\": 0.9838434457778931, \"f1\": 0.8356188780053428, \"f2\": 0.7606017377772014, \"f0_5\": 0.9270528728364814, \"p4\": 0.9069116794486366, \"phi\": 0.8399757887849352}, {\"truth_threshold\": 23.172573170670304, \"match_probability\": 0.9999998942305239, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4691.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1847.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.717497706413269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28250229358673096, \"precision\": 1.0, \"recall\": 0.717497706413269, \"specificity\": 1.0, \"npv\": 0.9831425547599792, \"accuracy\": 0.9838346838951111, \"f1\": 0.8355151838988334, \"f2\": 0.7604642868722239, \"f0_5\": 0.9270018180380998, \"p4\": 0.90684869600902, \"phi\": 0.8398824513634547}, {\"truth_threshold\": 23.17791104269559, \"match_probability\": 0.9999998946211406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4690.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1848.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7173447608947754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2826552391052246, \"precision\": 1.0, \"recall\": 0.7173447608947754, \"specificity\": 1.0, \"npv\": 0.9831336140632629, \"accuracy\": 0.9838259220123291, \"f1\": 0.8354114713216958, \"f2\": 0.7603268270540172, \"f0_5\": 0.926950747094632, \"p4\": 0.9067856952777562, \"phi\": 0.8397891052721258}, {\"truth_threshold\": 23.185685966504693, \"match_probability\": 0.9999998951875172, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4689.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1849.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7171918153762817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28280818462371826, \"precision\": 1.0, \"recall\": 0.7171918153762817, \"specificity\": 1.0, \"npv\": 0.9831246137619019, \"accuracy\": 0.9838171601295471, \"f1\": 0.8353077402689943, \"f2\": 0.7601893583217146, \"f0_5\": 0.9268996599984186, \"p4\": 0.9067226772472188, \"phi\": 0.8396957505080103}, {\"truth_threshold\": 23.205164761699024, \"match_probability\": 0.9999998965931503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4687.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1851.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7168859243392944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28311410546302795, \"precision\": 1.0, \"recall\": 0.7168859243392944, \"specificity\": 1.0, \"npv\": 0.9831066727638245, \"accuracy\": 0.9837996959686279, \"f1\": 0.8351002227171492, \"f2\": 0.7599143941113525, \"f0_5\": 0.9267974373170924, \"p4\": 0.9065965892577927, \"phi\": 0.839508961740297}, {\"truth_threshold\": 23.230080085863147, \"match_probability\": 0.9999998983636528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4685.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1853.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7165799736976624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28341999650001526, \"precision\": 1.0, \"recall\": 0.7165799736976624, \"specificity\": 1.0, \"npv\": 0.9830887317657471, \"accuracy\": 0.983782172203064, \"f1\": 0.834892631203778, \"f2\": 0.7596393942341991, \"f0_5\": 0.9266951499327478, \"p4\": 0.9064704319796374, \"phi\": 0.8393221914446334}, {\"truth_threshold\": 23.25023486778075, \"match_probability\": 0.9999998997736638, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4684.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1854.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7164270281791687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2835729718208313, \"precision\": 1.0, \"recall\": 0.7164270281791687, \"specificity\": 1.0, \"npv\": 0.9830797910690308, \"accuracy\": 0.983773410320282, \"f1\": 0.8347888076991623, \"f2\": 0.7595018809184071, \"f0_5\": 0.9266439819577431, \"p4\": 0.9064073273381715, \"phi\": 0.8392287932670212}, {\"truth_threshold\": 23.2656178278294, \"match_probability\": 0.9999999008366652, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4683.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1855.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.716274082660675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28372591733932495, \"precision\": 1.0, \"recall\": 0.716274082660675, \"specificity\": 1.0, \"npv\": 0.9830707907676697, \"accuracy\": 0.9837646484375, \"f1\": 0.8346849656893325, \"f2\": 0.7593643586833144, \"f0_5\": 0.9265927977839336, \"p4\": 0.9063442053515766, \"phi\": 0.8391353331678488}, {\"truth_threshold\": 23.276707079141943, \"match_probability\": 0.9999999015959606, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4682.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1856.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7161211371421814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2838788628578186, \"precision\": 1.0, \"recall\": 0.7161211371421814, \"specificity\": 1.0, \"npv\": 0.9830618500709534, \"accuracy\": 0.9837559461593628, \"f1\": 0.8345811051693405, \"f2\": 0.7592268275280535, \"f0_5\": 0.9265415974036254, \"p4\": 0.9062810660121945, \"phi\": 0.8390419176009466}, {\"truth_threshold\": 23.277949270836558, \"match_probability\": 0.9999999016806521, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4681.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1857.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7159681916236877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28403180837631226, \"precision\": 1.0, \"recall\": 0.7159681916236877, \"specificity\": 1.0, \"npv\": 0.9830528497695923, \"accuracy\": 0.9837471842765808, \"f1\": 0.8344772261342366, \"f2\": 0.7590892874517562, \"f0_5\": 0.9264903808091204, \"p4\": 0.9062179093123622, \"phi\": 0.8389484933376932}, {\"truth_threshold\": 23.285399710904688, \"match_probability\": 0.9999999021870891, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4678.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1860.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7155093550682068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2844906747341156, \"precision\": 1.0, \"recall\": 0.7155093550682068, \"specificity\": 1.0, \"npv\": 0.9830259680747986, \"accuracy\": 0.9837208986282349, \"f1\": 0.8341654778887304, \"f2\": 0.7586766136879662, \"f0_5\": 0.9263366336633664, \"p4\": 0.9060283349734702, \"phi\": 0.8386681150819589}, {\"truth_threshold\": 23.2930696100624, \"match_probability\": 0.9999999027057188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4677.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1861.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7153563499450684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28464362025260925, \"precision\": 1.0, \"recall\": 0.7153563499450684, \"specificity\": 1.0, \"npv\": 0.9830169677734375, \"accuracy\": 0.9837121367454529, \"f1\": 0.8340615247436469, \"f2\": 0.7585390379188427, \"f0_5\": 0.9262853521349916, \"p4\": 0.9059651087551202, \"phi\": 0.8385746559983116}, {\"truth_threshold\": 23.29354059000506, \"match_probability\": 0.9999999027374761, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4676.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1862.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7152034044265747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2847965657711029, \"precision\": 1.0, \"recall\": 0.7152034044265747, \"specificity\": 1.0, \"npv\": 0.9830080270767212, \"accuracy\": 0.9837034344673157, \"f1\": 0.8339575530586767, \"f2\": 0.7584014532243415, \"f0_5\": 0.9262340543538546, \"p4\": 0.9059018651379385, \"phi\": 0.8384811882035339}, {\"truth_threshold\": 23.295935771251195, \"match_probability\": 0.9999999028988187, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4675.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1863.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.715050458908081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28494951128959656, \"precision\": 1.0, \"recall\": 0.715050458908081, \"specificity\": 1.0, \"npv\": 0.9829990267753601, \"accuracy\": 0.9836946725845337, \"f1\": 0.8338535628288594, \"f2\": 0.7582638596035942, \"f0_5\": 0.9261827403122276, \"p4\": 0.9058386041142354, \"phi\": 0.8383877116946659}, {\"truth_threshold\": 23.354736894337123, \"match_probability\": 0.9999999067768843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4673.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1865.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7147445678710938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28525543212890625, \"precision\": 1.0, \"recall\": 0.7147445678710938, \"specificity\": 1.0, \"npv\": 0.9829810857772827, \"accuracy\": 0.9836771488189697, \"f1\": 0.8336455267148336, \"f2\": 0.7579886455798864, \"f0_5\": 0.9260800634165676, \"p4\": 0.9057120298164834, \"phi\": 0.8382006792372048}, {\"truth_threshold\": 23.357167855144073, \"match_probability\": 0.9999999069338343, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4671.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1867.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7144386768341064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28556132316589355, \"precision\": 1.0, \"recall\": 0.7144386768341064, \"specificity\": 1.0, \"npv\": 0.9829631447792053, \"accuracy\": 0.9836596250534058, \"f1\": 0.8334374163618521, \"f2\": 0.7577133958407682, \"f0_5\": 0.9259773213860915, \"p4\": 0.9055853858002544, \"phi\": 0.8380136651625046}, {\"truth_threshold\": 23.371058675228042, \"match_probability\": 0.9999999078256108, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4668.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1870.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7139797806739807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2860201895236969, \"precision\": 1.0, \"recall\": 0.7139797806739807, \"specificity\": 1.0, \"npv\": 0.9829362630844116, \"accuracy\": 0.9836333990097046, \"f1\": 0.8331251115473853, \"f2\": 0.7573004542504866, \"f0_5\": 0.9258230860769536, \"p4\": 0.9053952889188177, \"phi\": 0.8377330252632292}, {\"truth_threshold\": 23.38144543836843, \"match_probability\": 0.9999999084868423, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4662.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1876.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7130621075630188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2869378924369812, \"precision\": 1.0, \"recall\": 0.7130621075630188, \"specificity\": 1.0, \"npv\": 0.9828824400901794, \"accuracy\": 0.9835808873176575, \"f1\": 0.8325, \"f2\": 0.7564743298500681, \"f0_5\": 0.9255141745414119, \"p4\": 0.9050146233055194, \"phi\": 0.8371715627100998}, {\"truth_threshold\": 23.38512038104264, \"match_probability\": 0.9999999087196548, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4660.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1878.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7127562165260315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2872438132762909, \"precision\": 1.0, \"recall\": 0.7127562165260315, \"specificity\": 1.0, \"npv\": 0.982864499092102, \"accuracy\": 0.9835633635520935, \"f1\": 0.8322914806215396, \"f2\": 0.7561988835518629, \"f0_5\": 0.9254110731591072, \"p4\": 0.9048875947331517, \"phi\": 0.8369843029261277}, {\"truth_threshold\": 23.393076263555972, \"match_probability\": 0.9999999092216438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4659.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1879.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7126032710075378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28739675879478455, \"precision\": 1.0, \"recall\": 0.7126032710075378, \"specificity\": 1.0, \"npv\": 0.982855498790741, \"accuracy\": 0.9835546016693115, \"f1\": 0.8321871929981245, \"f2\": 0.756061146992957, \"f0_5\": 0.9253594978946532, \"p4\": 0.9048240541555842, \"phi\": 0.8368906865659949}, {\"truth_threshold\": 23.399993054633143, \"match_probability\": 0.9999999096558257, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4653.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1885.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7116855382919312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28831446170806885, \"precision\": 1.0, \"recall\": 0.7116855382919312, \"specificity\": 1.0, \"npv\": 0.9828017354011536, \"accuracy\": 0.9835020899772644, \"f1\": 0.831561075864534, \"f2\": 0.7552345398474274, \"f0_5\": 0.9250497017892644, \"p4\": 0.904442442121181, \"phi\": 0.8363287508474269}, {\"truth_threshold\": 23.42026644693331, \"match_probability\": 0.9999999109165035, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4652.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1886.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7115325927734375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2884674072265625, \"precision\": 1.0, \"recall\": 0.7115325927734375, \"specificity\": 1.0, \"npv\": 0.9827927350997925, \"accuracy\": 0.9834933280944824, \"f1\": 0.8314566577301161, \"f2\": 0.7550967406830282, \"f0_5\": 0.9249980116121849, \"p4\": 0.9043787786146368, \"phi\": 0.8362350730663165}, {\"truth_threshold\": 23.424582917608927, \"match_probability\": 0.9999999111826385, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4651.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1887.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7113796472549438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28862038254737854, \"precision\": 1.0, \"recall\": 0.7113796472549438, \"specificity\": 1.0, \"npv\": 0.9827837944030762, \"accuracy\": 0.9834846258163452, \"f1\": 0.8313522209312718, \"f2\": 0.7549589325715028, \"f0_5\": 0.92494630498767, \"p4\": 0.9043150975156493, \"phi\": 0.836141333093462}, {\"truth_threshold\": 23.426559400095563, \"match_probability\": 0.9999999113042344, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4650.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1888.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7112267017364502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2887733280658722, \"precision\": 1.0, \"recall\": 0.7112267017364502, \"specificity\": 1.0, \"npv\": 0.9827747941017151, \"accuracy\": 0.9834758639335632, \"f1\": 0.8312477654629961, \"f2\": 0.7548211155119797, \"f0_5\": 0.9248945819078686, \"p4\": 0.9042513988164147, \"phi\": 0.8360476377326046}, {\"truth_threshold\": 23.47068398126876, \"match_probability\": 0.9999999139759143, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4647.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1891.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7107678055763245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28923219442367554, \"precision\": 1.0, \"recall\": 0.7107678055763245, \"specificity\": 1.0, \"npv\": 0.9827479124069214, \"accuracy\": 0.9834495782852173, \"f1\": 0.8309342869915065, \"f2\": 0.754407610636709, \"f0_5\": 0.9247393138581549, \"p4\": 0.9040601970391189, \"phi\": 0.8357664988882482}, {\"truth_threshold\": 23.477965161142485, \"match_probability\": 0.999999914408978, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4646.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1892.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7106148600578308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2893851399421692, \"precision\": 1.0, \"recall\": 0.7106148600578308, \"specificity\": 1.0, \"npv\": 0.9827389717102051, \"accuracy\": 0.9834408164024353, \"f1\": 0.830829756795422, \"f2\": 0.754269757776479, \"f0_5\": 0.9246875248785925, \"p4\": 0.9039964278607634, \"phi\": 0.8356727149092191}, {\"truth_threshold\": 23.47991926593636, \"match_probability\": 0.9999999145248311, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4644.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1894.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7103089690208435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2896910309791565, \"precision\": 1.0, \"recall\": 0.7103089690208435, \"specificity\": 1.0, \"npv\": 0.9827210307121277, \"accuracy\": 0.9834233522415161, \"f1\": 0.8306206403147917, \"f2\": 0.7539940251980777, \"f0_5\": 0.9245838974277295, \"p4\": 0.9038688365782117, \"phi\": 0.8354852273934407}, {\"truth_threshold\": 23.485714688004794, \"match_probability\": 0.9999999148675028, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4643.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1895.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7101560235023499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28984397649765015, \"precision\": 1.0, \"recall\": 0.7101560235023499, \"specificity\": 1.0, \"npv\": 0.9827120900154114, \"accuracy\": 0.9834145903587341, \"f1\": 0.8305160540202129, \"f2\": 0.753856145478162, \"f0_5\": 0.924532058940661, \"p4\": 0.9038050144583475, \"phi\": 0.8353914704225438}, {\"truth_threshold\": 23.49311449169694, \"match_probability\": 0.9999999153030426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4642.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1896.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7100030779838562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2899969518184662, \"precision\": 1.0, \"recall\": 0.7100030779838562, \"specificity\": 1.0, \"npv\": 0.9827030897140503, \"accuracy\": 0.9834058284759521, \"f1\": 0.8304114490161002, \"f2\": 0.7537182568032733, \"f0_5\": 0.9244802039353143, \"p4\": 0.9037411746756377, \"phi\": 0.835297651183285}, {\"truth_threshold\": 23.49607865337895, \"match_probability\": 0.9999999154768823, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4641.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1897.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7098501324653625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29014989733695984, \"precision\": 1.0, \"recall\": 0.7098501324653625, \"specificity\": 1.0, \"npv\": 0.982694149017334, \"accuracy\": 0.9833970665931702, \"f1\": 0.8303068252974327, \"f2\": 0.7535803591725392, \"f0_5\": 0.9244283324037925, \"p4\": 0.9036773172222371, \"phi\": 0.8352038765784804}, {\"truth_threshold\": 23.4965895573119, \"match_probability\": 0.9999999155068092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4640.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1898.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7096971273422241, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2903028428554535, \"precision\": 1.0, \"recall\": 0.7096971273422241, \"specificity\": 1.0, \"npv\": 0.9826851487159729, \"accuracy\": 0.9833883047103882, \"f1\": 0.8302021828591877, \"f2\": 0.753442452585087, \"f0_5\": 0.9243764443381943, \"p4\": 0.9036134420902953, \"phi\": 0.8351100931549534}, {\"truth_threshold\": 23.51966498336408, \"match_probability\": 0.999999916847499, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4638.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1900.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7093912363052368, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2906087636947632, \"precision\": 1.0, \"recall\": 0.7093912363052368, \"specificity\": 1.0, \"npv\": 0.9826672673225403, \"accuracy\": 0.983370840549469, \"f1\": 0.8299928418038655, \"f2\": 0.7531666125365378, \"f0_5\": 0.9242726185731367, \"p4\": 0.9034856387593636, \"phi\": 0.8349224998396582}, {\"truth_threshold\": 23.52235928050094, \"match_probability\": 0.9999999170026451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4634.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1904.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7087794542312622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2912205457687378, \"precision\": 1.0, \"recall\": 0.7087794542312622, \"specificity\": 1.0, \"npv\": 0.9826313853263855, \"accuracy\": 0.9833357930183411, \"f1\": 0.8295739348370927, \"f2\": 0.7526148249204184, \"f0_5\": 0.9240647682858738, \"p4\": 0.9032298196090786, \"phi\": 0.8345471537516457}, {\"truth_threshold\": 23.52306176867309, \"match_probability\": 0.999999917043049, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4629.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1909.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7080146670341492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29198530316352844, \"precision\": 1.0, \"recall\": 0.7080146670341492, \"specificity\": 1.0, \"npv\": 0.9825865626335144, \"accuracy\": 0.9832920432090759, \"f1\": 0.8290498791080864, \"f2\": 0.7519248887300608, \"f0_5\": 0.9238045821026583, \"p4\": 0.9029096466053864, \"phi\": 0.8340777855410879}, {\"truth_threshold\": 23.527092856586385, \"match_probability\": 0.9999999172745185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4627.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1911.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7077087759971619, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29229122400283813, \"precision\": 1.0, \"recall\": 0.7077087759971619, \"specificity\": 1.0, \"npv\": 0.982568621635437, \"accuracy\": 0.983274519443512, \"f1\": 0.8288401253918495, \"f2\": 0.751648851489652, \"f0_5\": 0.9237003912800447, \"p4\": 0.9027814530474682, \"phi\": 0.8338899441540883}, {\"truth_threshold\": 23.545079357001022, \"match_probability\": 0.9999999182994787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4622.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1916.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7069440484046936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2930559813976288, \"precision\": 1.0, \"recall\": 0.7069440484046936, \"specificity\": 1.0, \"npv\": 0.9825238585472107, \"accuracy\": 0.9832307696342468, \"f1\": 0.8283154121863799, \"f2\": 0.7509586014167804, \"f0_5\": 0.923439622792296, \"p4\": 0.902460657707642, \"phi\": 0.8334202658159839}, {\"truth_threshold\": 23.558970177084987, \"match_probability\": 0.9999999190823475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4621.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1917.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7067910432815552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29320892691612244, \"precision\": 1.0, \"recall\": 0.7067910432815552, \"specificity\": 1.0, \"npv\": 0.9825148582458496, \"accuracy\": 0.9832220077514648, \"f1\": 0.8282104131194552, \"f2\": 0.7508205244857505, \"f0_5\": 0.9233874190712174, \"p4\": 0.9023964451856723, \"phi\": 0.8333263142391976}, {\"truth_threshold\": 23.586223896088423, \"match_probability\": 0.9999999205966019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4620.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1918.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7066380977630615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2933618724346161, \"precision\": 1.0, \"recall\": 0.7066380977630615, \"specificity\": 1.0, \"npv\": 0.9825059175491333, \"accuracy\": 0.9832133054733276, \"f1\": 0.8281053952321205, \"f2\": 0.7506824385805277, \"f0_5\": 0.923335198656967, \"p4\": 0.9023322148271765, \"phi\": 0.8332323537830054}, {\"truth_threshold\": 23.615054722570274, \"match_probability\": 0.9999999221676497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4619.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1919.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7064851522445679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29351484775543213, \"precision\": 1.0, \"recall\": 0.7064851522445679, \"specificity\": 1.0, \"npv\": 0.9824969172477722, \"accuracy\": 0.9832045435905457, \"f1\": 0.8280003585193152, \"f2\": 0.7505443437002373, \"f0_5\": 0.9232829615415368, \"p4\": 0.9022679666242062, \"phi\": 0.8331383308613804}, {\"truth_threshold\": 23.61546868489242, \"match_probability\": 0.9999999221899794, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4618.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1920.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7063322067260742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2936677932739258, \"precision\": 1.0, \"recall\": 0.7063322067260742, \"specificity\": 1.0, \"npv\": 0.9824879765510559, \"accuracy\": 0.9831957817077637, \"f1\": 0.827895302975977, \"f2\": 0.7504062398440039, \"f0_5\": 0.9232307077169132, \"p4\": 0.902203700568808, \"phi\": 0.8330443526316645}, {\"truth_threshold\": 23.64271605623705, \"match_probability\": 0.9999999236457431, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4615.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1923.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7058733701705933, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29412662982940674, \"precision\": 1.0, \"recall\": 0.7058733701705933, \"specificity\": 1.0, \"npv\": 0.9824610948562622, \"accuracy\": 0.9831694960594177, \"f1\": 0.8275800233121133, \"f2\": 0.7499918744108948, \"f0_5\": 0.9230738459076726, \"p4\": 0.9020107952084442, \"phi\": 0.8327623645988945}, {\"truth_threshold\": 23.64859265075695, \"match_probability\": 0.9999999239561277, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4613.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1925.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.705567479133606, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29443255066871643, \"precision\": 1.0, \"recall\": 0.705567479133606, \"specificity\": 1.0, \"npv\": 0.9824431538581848, \"accuracy\": 0.9831520318984985, \"f1\": 0.8273697426239799, \"f2\": 0.7497155858930603, \"f0_5\": 0.9229691876750701, \"p4\": 0.9018821022267081, \"phi\": 0.8325742744771024}, {\"truth_threshold\": 23.65336486929913, \"match_probability\": 0.9999999242072538, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4612.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1926.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7054144740104675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2945854961872101, \"precision\": 1.0, \"recall\": 0.7054144740104675, \"specificity\": 1.0, \"npv\": 0.9824342131614685, \"accuracy\": 0.9831432700157166, \"f1\": 0.8272645739910314, \"f2\": 0.7495774281627877, \"f0_5\": 0.9229168334267189, \"p4\": 0.9018177288894613, \"phi\": 0.832480242864547}, {\"truth_threshold\": 23.667013983938244, \"match_probability\": 0.9999999249209359, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4611.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1927.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7052615284919739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29473844170570374, \"precision\": 1.0, \"recall\": 0.7052615284919739, \"specificity\": 1.0, \"npv\": 0.9824252724647522, \"accuracy\": 0.9831345081329346, \"f1\": 0.8271593864920621, \"f2\": 0.7494392614504437, \"f0_5\": 0.9228644624129373, \"p4\": 0.9017533376439819, \"phi\": 0.8323862023450622}, {\"truth_threshold\": 23.685759569639337, \"match_probability\": 0.9999999258901614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4610.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1928.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7051085829734802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2948914170265198, \"precision\": 1.0, \"recall\": 0.7051085829734802, \"specificity\": 1.0, \"npv\": 0.9824162721633911, \"accuracy\": 0.9831257462501526, \"f1\": 0.8270541801219949, \"f2\": 0.7493010857551524, \"f0_5\": 0.9228120746256706, \"p4\": 0.9016889284822789, \"phi\": 0.8322920992825279}, {\"truth_threshold\": 23.702664421169843, \"match_probability\": 0.9999999267534793, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4606.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1932.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7044968008995056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2955031991004944, \"precision\": 1.0, \"recall\": 0.7044968008995056, \"specificity\": 1.0, \"npv\": 0.9823804497718811, \"accuracy\": 0.9830907583236694, \"f1\": 0.8266331658291457, \"f2\": 0.7487482931269913, \"f0_5\": 0.9226023555804823, \"p4\": 0.901431112513242, \"phi\": 0.8319158123809622}, {\"truth_threshold\": 23.703373533255792, \"match_probability\": 0.9999999267894725, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4604.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1934.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7041909098625183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2958091199398041, \"precision\": 1.0, \"recall\": 0.7041909098625183, \"specificity\": 1.0, \"npv\": 0.9823625683784485, \"accuracy\": 0.9830732345581055, \"f1\": 0.8264225453239993, \"f2\": 0.7484718428924437, \"f0_5\": 0.9224973952071812, \"p4\": 0.9013020968232641, \"phi\": 0.8317275617238302}, {\"truth_threshold\": 23.70550207425945, \"match_probability\": 0.999999926897407, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4601.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1937.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7037320137023926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2962679862976074, \"precision\": 1.0, \"recall\": 0.7037320137023926, \"specificity\": 1.0, \"npv\": 0.9823356866836548, \"accuracy\": 0.9830470085144043, \"f1\": 0.826106472753389, \"f2\": 0.7480571001203135, \"f0_5\": 0.9223398284018924, \"p4\": 0.9011084384760045, \"phi\": 0.8314451455438675}, {\"truth_threshold\": 23.708107109341242, \"match_probability\": 0.9999999270292873, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4600.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1938.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7035790681838989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2964209318161011, \"precision\": 1.0, \"recall\": 0.7035790681838989, \"specificity\": 1.0, \"npv\": 0.9823266863822937, \"accuracy\": 0.9830382466316223, \"f1\": 0.8260010773927097, \"f2\": 0.7479188345473465, \"f0_5\": 0.9222872724356403, \"p4\": 0.901043849711509, \"phi\": 0.8313510068286546}, {\"truth_threshold\": 23.712949753016677, \"match_probability\": 0.9999999272738149, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4591.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1947.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7022024989128113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2977975010871887, \"precision\": 1.0, \"recall\": 0.7022024989128113, \"specificity\": 1.0, \"npv\": 0.9822461009025574, \"accuracy\": 0.9829594492912292, \"f1\": 0.8250516668164255, \"f2\": 0.746674039618775, \"f0_5\": 0.921813508955104, \"p4\": 0.9004617396644614, \"phi\": 0.8305032480697445}, {\"truth_threshold\": 23.754387314779546, \"match_probability\": 0.9999999293329668, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4590.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1948.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7020495533943176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2979504466056824, \"precision\": 1.0, \"recall\": 0.7020495533943176, \"specificity\": 1.0, \"npv\": 0.9822371602058411, \"accuracy\": 0.9829506874084473, \"f1\": 0.8249460819554277, \"f2\": 0.7465356840804112, \"f0_5\": 0.9217607839987147, \"p4\": 0.9003969704928203, \"phi\": 0.8304090197658394}, {\"truth_threshold\": 23.781362598421435, \"match_probability\": 0.9999999306420114, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4587.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1951.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7015907168388367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2984093129634857, \"precision\": 1.0, \"recall\": 0.7015907168388367, \"specificity\": 1.0, \"npv\": 0.9822102785110474, \"accuracy\": 0.9829244613647461, \"f1\": 0.8246292134831461, \"f2\": 0.7461205634535931, \"f0_5\": 0.9216025074338986, \"p4\": 0.900202554434675, \"phi\": 0.8301262272313108}, {\"truth_threshold\": 23.786096174506884, \"match_probability\": 0.9999999308692066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4586.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1952.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.701437771320343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29856225848197937, \"precision\": 1.0, \"recall\": 0.701437771320343, \"specificity\": 1.0, \"npv\": 0.982201337814331, \"accuracy\": 0.9829156994819641, \"f1\": 0.8245235526788924, \"f2\": 0.745982171904483, \"f0_5\": 0.9215497146531629, \"p4\": 0.900137712873882, \"phi\": 0.830031963004038}, {\"truth_threshold\": 23.81534096331088, \"match_probability\": 0.999999932256445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4585.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1953.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7012848258018494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.298715204000473, \"precision\": 1.0, \"recall\": 0.7012848258018494, \"specificity\": 1.0, \"npv\": 0.98219233751297, \"accuracy\": 0.9829069375991821, \"f1\": 0.8244178728760226, \"f2\": 0.7458437713504896, \"f0_5\": 0.921496904895892, \"p4\": 0.900072853195536, \"phi\": 0.8299376897895593}, {\"truth_threshold\": 23.821633916473136, \"match_probability\": 0.9999999325512949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4584.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1954.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7011318206787109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2988681495189667, \"precision\": 1.0, \"recall\": 0.7011318206787109, \"specificity\": 1.0, \"npv\": 0.9821833968162537, \"accuracy\": 0.9828981757164001, \"f1\": 0.8243121740694119, \"f2\": 0.745705361790734, \"f0_5\": 0.9214440781538956, \"p4\": 0.9000079753915213, \"phi\": 0.8298434075847642}, {\"truth_threshold\": 23.824181427608806, \"match_probability\": 0.9999999326702907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4582.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1956.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7008259296417236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29917407035827637, \"precision\": 1.0, \"recall\": 0.7008259296417236, \"specificity\": 1.0, \"npv\": 0.982165515422821, \"accuracy\": 0.982880711555481, \"f1\": 0.8241007194244604, \"f2\": 0.7454285156504197, \"f0_5\": 0.9213383736829406, \"p4\": 0.8998781653739988, \"phi\": 0.829654762401969}, {\"truth_threshold\": 23.826703730774785, \"match_probability\": 0.9999999327879023, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4581.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1957.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.70067298412323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29932701587677, \"precision\": 1.0, \"recall\": 0.70067298412323, \"specificity\": 1.0, \"npv\": 0.98215651512146, \"accuracy\": 0.982871949672699, \"f1\": 0.8239949635758611, \"f2\": 0.7452900790681027, \"f0_5\": 0.9212854959375755, \"p4\": 0.8998132331442354, \"phi\": 0.8295604532019234}, {\"truth_threshold\": 23.827583388100667, \"match_probability\": 0.9999999328288711, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4578.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1960.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.700214147567749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.299785852432251, \"precision\": 1.0, \"recall\": 0.700214147567749, \"specificity\": 1.0, \"npv\": 0.982129693031311, \"accuracy\": 0.982845664024353, \"f1\": 0.8236775818639799, \"f2\": 0.744874715261959, \"f0_5\": 0.9211267605633803, \"p4\": 0.8996183274733014, \"phi\": 0.8292774177603399}, {\"truth_threshold\": 23.837762663084387, \"match_probability\": 0.9999999333011448, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4577.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1961.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.7000612020492554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.299938827753067, \"precision\": 1.0, \"recall\": 0.7000612020492554, \"specificity\": 1.0, \"npv\": 0.98212069272995, \"accuracy\": 0.9828369617462158, \"f1\": 0.8235717498875393, \"f2\": 0.7447362426372482, \"f0_5\": 0.921073814698543, \"p4\": 0.8995533225619594, \"phi\": 0.8291830725248438}, {\"truth_threshold\": 23.85660290530118, \"match_probability\": 0.9999999341665065, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4576.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1962.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6999082565307617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30009177327156067, \"precision\": 1.0, \"recall\": 0.6999082565307617, \"specificity\": 1.0, \"npv\": 0.9821117520332336, \"accuracy\": 0.9828281998634338, \"f1\": 0.8234658988662947, \"f2\": 0.7445977609997396, \"f0_5\": 0.9210208517832703, \"p4\": 0.8994882994598487, \"phi\": 0.8290887182740867}, {\"truth_threshold\": 23.881417034708942, \"match_probability\": 0.9999999352891499, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4575.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1963.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6997552514076233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3002447187900543, \"precision\": 1.0, \"recall\": 0.6997552514076233, \"specificity\": 1.0, \"npv\": 0.9821028113365173, \"accuracy\": 0.9828194379806519, \"f1\": 0.8233600287951048, \"f2\": 0.7444592703485534, \"f0_5\": 0.9209678718093244, \"p4\": 0.8994232581588097, \"phi\": 0.8289943550049431}, {\"truth_threshold\": 23.8856318480578, \"match_probability\": 0.9999999354779258, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4574.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1964.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6996023058891296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.300397664308548, \"precision\": 1.0, \"recall\": 0.6996023058891296, \"specificity\": 1.0, \"npv\": 0.982093870639801, \"accuracy\": 0.9828106760978699, \"f1\": 0.8232541396688265, \"f2\": 0.7443207706828093, \"f0_5\": 0.9209148747684626, \"p4\": 0.8993581986506785, \"phi\": 0.8288999827142862}, {\"truth_threshold\": 23.893124289408508, \"match_probability\": 0.9999999358121439, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4573.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1965.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.699449360370636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.300550639629364, \"precision\": 1.0, \"recall\": 0.699449360370636, \"specificity\": 1.0, \"npv\": 0.9820848703384399, \"accuracy\": 0.9828019142150879, \"f1\": 0.8231482314823149, \"f2\": 0.7441822620016273, \"f0_5\": 0.9208618606524366, \"p4\": 0.8992931209272855, \"phi\": 0.8288055475584819}, {\"truth_threshold\": 23.93739677977978, \"match_probability\": 0.9999999377519826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4572.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1966.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6992964148521423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30070358514785767, \"precision\": 1.0, \"recall\": 0.6992964148521423, \"specificity\": 1.0, \"npv\": 0.9820759296417236, \"accuracy\": 0.9827931523323059, \"f1\": 0.823042304230423, \"f2\": 0.7440437443041271, \"f0_5\": 0.9208088294529928, \"p4\": 0.899228024980457, \"phi\": 0.8287111572097675}, {\"truth_threshold\": 23.946706213093194, \"match_probability\": 0.9999999381523638, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4570.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1968.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.698990523815155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30100947618484497, \"precision\": 1.0, \"recall\": 0.698990523815155, \"specificity\": 1.0, \"npv\": 0.982058048248291, \"accuracy\": 0.9827756881713867, \"f1\": 0.8228303925099028, \"f2\": 0.74376668185665, \"f0_5\": 0.9207027157708115, \"p4\": 0.8990977783837727, \"phi\": 0.8285223494164837}, {\"truth_threshold\": 23.9556393378632, \"match_probability\": 0.9999999385341393, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4569.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1969.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6988375782966614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3011624217033386, \"precision\": 1.0, \"recall\": 0.6988375782966614, \"specificity\": 1.0, \"npv\": 0.9820491075515747, \"accuracy\": 0.9827669262886047, \"f1\": 0.8227244080309715, \"f2\": 0.7436281371049119, \"f0_5\": 0.9206496332715403, \"p4\": 0.8990326277175444, \"phi\": 0.8284278781025595}, {\"truth_threshold\": 23.956021175949196, \"match_probability\": 0.9999999385504054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4562.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1976.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.697766900062561, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30223309993743896, \"precision\": 1.0, \"recall\": 0.697766900062561, \"specificity\": 1.0, \"npv\": 0.981986403465271, \"accuracy\": 0.9827056527137756, \"f1\": 0.821981981981982, \"f2\": 0.742658071237872, \"f0_5\": 0.9202775760509966, \"p4\": 0.8985760614214329, \"phi\": 0.8277666486997229}, {\"truth_threshold\": 23.971141515175038, \"match_probability\": 0.999999939191072, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4560.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1978.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6974610090255737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30253899097442627, \"precision\": 1.0, \"recall\": 0.6974610090255737, \"specificity\": 1.0, \"npv\": 0.9819685220718384, \"accuracy\": 0.9826881289482117, \"f1\": 0.8217696882321139, \"f2\": 0.7423808283407137, \"f0_5\": 0.9201711195415287, \"p4\": 0.8984454492085172, \"phi\": 0.8275776598889063}, {\"truth_threshold\": 23.975356499812587, \"match_probability\": 0.9999999393684724, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4558.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1980.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6971551179885864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30284491181373596, \"precision\": 1.0, \"recall\": 0.6971551179885864, \"specificity\": 1.0, \"npv\": 0.981950581073761, \"accuracy\": 0.9826706647872925, \"f1\": 0.8215573179524153, \"f2\": 0.742103549332465, \"f0_5\": 0.9200645942672587, \"p4\": 0.8983147636750218, \"phi\": 0.8273885808782224}, {\"truth_threshold\": 23.982772340362576, \"match_probability\": 0.9999999396793351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4557.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1981.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.697002112865448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3029978573322296, \"precision\": 1.0, \"recall\": 0.697002112865448, \"specificity\": 1.0, \"npv\": 0.9819416403770447, \"accuracy\": 0.9826619029045105, \"f1\": 0.8214511041009463, \"f2\": 0.7419648962844768, \"f0_5\": 0.9200113058224986, \"p4\": 0.8982493933924468, \"phi\": 0.8272940547190417}, {\"truth_threshold\": 23.987294140197392, \"match_probability\": 0.9999999398681005, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4555.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1983.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6966962218284607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3033037483692169, \"precision\": 1.0, \"recall\": 0.6966962218284607, \"specificity\": 1.0, \"npv\": 0.9819237589836121, \"accuracy\": 0.9826443791389465, \"f1\": 0.8212386189488867, \"f2\": 0.7416875630963624, \"f0_5\": 0.919904677276032, \"p4\": 0.8981185977543792, \"phi\": 0.8271049212208558}, {\"truth_threshold\": 24.02982323797419, \"match_probability\": 0.9999999416148515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4554.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1984.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.696543276309967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30345672369003296, \"precision\": 1.0, \"recall\": 0.696543276309967, \"specificity\": 1.0, \"npv\": 0.9819148182868958, \"accuracy\": 0.9826356172561646, \"f1\": 0.8211323476379373, \"f2\": 0.7415488829544714, \"f0_5\": 0.9198513371576311, \"p4\": 0.8980531723823665, \"phi\": 0.8270103678122073}, {\"truth_threshold\": 24.032840022344274, \"match_probability\": 0.9999999417368116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4553.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1985.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6963903307914734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3036096692085266, \"precision\": 1.0, \"recall\": 0.6963903307914734, \"specificity\": 1.0, \"npv\": 0.9819058775901794, \"accuracy\": 0.9826268553733826, \"f1\": 0.8210260571634659, \"f2\": 0.7414101937795148, \"f0_5\": 0.9197979797979798, \"p4\": 0.8979877286306795, \"phi\": 0.8269158053159685}, {\"truth_threshold\": 24.033682873059643, \"match_probability\": 0.9999999417708402, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4551.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1987.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6960844397544861, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3039155602455139, \"precision\": 1.0, \"recall\": 0.6960844397544861, \"specificity\": 1.0, \"npv\": 0.981887936592102, \"accuracy\": 0.9826093912124634, \"f1\": 0.8208134187032194, \"f2\": 0.7411327883268736, \"f0_5\": 0.9196912133214776, \"p4\": 0.8978567859551884, \"phi\": 0.8267266530480579}, {\"truth_threshold\": 24.051636093794123, \"match_probability\": 0.9999999424909669, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4550.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1988.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6959314942359924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30406853556632996, \"precision\": 1.0, \"recall\": 0.6959314942359924, \"specificity\": 1.0, \"npv\": 0.9818789958953857, \"accuracy\": 0.9826006293296814, \"f1\": 0.8207070707070707, \"f2\": 0.7409940720474236, \"f0_5\": 0.9196378041878891, \"p4\": 0.8977912870148245, \"phi\": 0.8266320092992951}, {\"truth_threshold\": 24.060155084420835, \"match_probability\": 0.9999999428295522, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4548.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1990.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6956256031990051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30437442660331726, \"precision\": 1.0, \"recall\": 0.6956256031990051, \"specificity\": 1.0, \"npv\": 0.9818611145019531, \"accuracy\": 0.9825831055641174, \"f1\": 0.8204943171567743, \"f2\": 0.7407166123778501, \"f0_5\": 0.919530934088152, \"p4\": 0.8976602338874236, \"phi\": 0.8264428024279504}, {\"truth_threshold\": 24.064921119272913, \"match_probability\": 0.9999999430181067, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4547.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1991.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6954725980758667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3045273721218109, \"precision\": 1.0, \"recall\": 0.6954725980758667, \"specificity\": 1.0, \"npv\": 0.9818521738052368, \"accuracy\": 0.9825743436813354, \"f1\": 0.8203879115922418, \"f2\": 0.7405778689859605, \"f0_5\": 0.9194774731052333, \"p4\": 0.8975946796837969, \"phi\": 0.8263481853339509}, {\"truth_threshold\": 24.06766123794909, \"match_probability\": 0.99999994312623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4544.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1994.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6950137615203857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30498623847961426, \"precision\": 1.0, \"recall\": 0.6950137615203857, \"specificity\": 1.0, \"npv\": 0.9818252921104431, \"accuracy\": 0.9825481176376343, \"f1\": 0.8200685796787583, \"f2\": 0.7401615845712797, \"f0_5\": 0.9193169863235413, \"p4\": 0.8973979064135715, \"phi\": 0.8260642253756324}, {\"truth_threshold\": 24.103290693308796, \"match_probability\": 0.9999999445136083, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4543.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1995.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6948608160018921, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3051391839981079, \"precision\": 1.0, \"recall\": 0.6948608160018921, \"specificity\": 1.0, \"npv\": 0.9818163514137268, \"accuracy\": 0.9825393557548523, \"f1\": 0.8199620972836387, \"f2\": 0.7400228050171037, \"f0_5\": 0.9192634560906515, \"p4\": 0.8973322784093405, \"phi\": 0.8259695718177241}, {\"truth_threshold\": 24.112055357307543, \"match_probability\": 0.9999999448496775, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4540.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 1998.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6944019794464111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30559805035591125, \"precision\": 1.0, \"recall\": 0.6944019794464111, \"specificity\": 1.0, \"npv\": 0.9817895293235779, \"accuracy\": 0.9825131297111511, \"f1\": 0.8196425347535656, \"f2\": 0.7396064120943568, \"f0_5\": 0.9191027613571949, \"p4\": 0.8971352835376694, \"phi\": 0.8256855023685177}, {\"truth_threshold\": 24.144421121539796, \"match_probability\": 0.9999999460731577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4538.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2000.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.694096028804779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30590394139289856, \"precision\": 1.0, \"recall\": 0.694096028804779, \"specificity\": 1.0, \"npv\": 0.9817715883255005, \"accuracy\": 0.9824956059455872, \"f1\": 0.8194293968941856, \"f2\": 0.7393287715868361, \"f0_5\": 0.9189955447549615, \"p4\": 0.8970038611574064, \"phi\": 0.8254961130877495}, {\"truth_threshold\": 24.162516513161993, \"match_probability\": 0.9999999467453253, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4537.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2001.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6939430832862854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3060568869113922, \"precision\": 1.0, \"recall\": 0.6939430832862854, \"specificity\": 1.0, \"npv\": 0.9817626476287842, \"accuracy\": 0.9824868440628052, \"f1\": 0.8193227990970655, \"f2\": 0.7391899377627162, \"f0_5\": 0.9189419103945556, \"p4\": 0.8969381222025037, \"phi\": 0.8254013506964679}, {\"truth_threshold\": 24.16628021750805, \"match_probability\": 0.9999999468840751, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4535.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2003.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6936371922492981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3063628077507019, \"precision\": 1.0, \"recall\": 0.6936371922492981, \"specificity\": 1.0, \"npv\": 0.9817447662353516, \"accuracy\": 0.9824693202972412, \"f1\": 0.8191095457418947, \"f2\": 0.7389122429693356, \"f0_5\": 0.9188345895129265, \"p4\": 0.896806588721395, \"phi\": 0.8252119065639997}, {\"truth_threshold\": 24.17791104269559, \"match_probability\": 0.9999999473105675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4534.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2004.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6934842467308044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30651575326919556, \"precision\": 1.0, \"recall\": 0.6934842467308044, \"specificity\": 1.0, \"npv\": 0.9817358255386353, \"accuracy\": 0.982460618019104, \"f1\": 0.8190028901734104, \"f2\": 0.7387733819983054, \"f0_5\": 0.9187809029747913, \"p4\": 0.8967407941784694, \"phi\": 0.82511717077731}, {\"truth_threshold\": 24.17806385153769, \"match_probability\": 0.999999947316148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4533.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2005.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6933313012123108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3066686987876892, \"precision\": 1.0, \"recall\": 0.6933313012123108, \"specificity\": 1.0, \"npv\": 0.981726884841919, \"accuracy\": 0.982451856136322, \"f1\": 0.8188962153373679, \"f2\": 0.7386345119765357, \"f0_5\": 0.9187271990271585, \"p4\": 0.8966749810894752, \"phi\": 0.8250224258393861}, {\"truth_threshold\": 24.18333060232365, \"match_probability\": 0.9999999475081268, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4532.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2006.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6931783556938171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30682164430618286, \"precision\": 1.0, \"recall\": 0.6931783556938171, \"specificity\": 1.0, \"npv\": 0.9817179441452026, \"accuracy\": 0.98244309425354, \"f1\": 0.8187895212285456, \"f2\": 0.7384956329031417, \"f0_5\": 0.9186734776615584, \"p4\": 0.89660914944604, \"phi\": 0.8249276176736345}, {\"truth_threshold\": 24.205164761699024, \"match_probability\": 0.9999999482965725, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4530.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2008.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6928724646568298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30712756514549255, \"precision\": 1.0, \"recall\": 0.6928724646568298, \"specificity\": 1.0, \"npv\": 0.98170006275177, \"accuracy\": 0.9824255704879761, \"f1\": 0.8185760751716661, \"f2\": 0.7382178475979402, \"f0_5\": 0.9185659826425501, \"p4\": 0.8964774304623321, \"phi\": 0.8247380820013593}, {\"truth_threshold\": 24.209119320021966, \"match_probability\": 0.9999999484381022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4529.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2009.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6927194595336914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3072805106639862, \"precision\": 1.0, \"recall\": 0.6927194595336914, \"specificity\": 1.0, \"npv\": 0.9816910624504089, \"accuracy\": 0.9824168086051941, \"f1\": 0.8184693232131562, \"f2\": 0.7380789413643624, \"f0_5\": 0.9185122089721749, \"p4\": 0.8964115431052897, \"phi\": 0.8246433004207517}, {\"truth_threshold\": 24.213691132763675, \"match_probability\": 0.9999999486012401, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4527.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2011.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6924135684967041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3075864315032959, \"precision\": 1.0, \"recall\": 0.6924135684967041, \"specificity\": 1.0, \"npv\": 0.9816731810569763, \"accuracy\": 0.9823993444442749, \"f1\": 0.8182557614098509, \"f2\": 0.7378011017308257, \"f0_5\": 0.9184046092672239, \"p4\": 0.8962797126188659, \"phi\": 0.8244536556525464}, {\"truth_threshold\": 24.219498376495032, \"match_probability\": 0.9999999488077184, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4526.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2012.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6922606229782104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30773937702178955, \"precision\": 1.0, \"recall\": 0.6922606229782104, \"specificity\": 1.0, \"npv\": 0.98166424036026, \"accuracy\": 0.9823905825614929, \"f1\": 0.8181489515545914, \"f2\": 0.7376621683290958, \"f0_5\": 0.9183507832156481, \"p4\": 0.8962137694726843, \"phi\": 0.8243588465548116}, {\"truth_threshold\": 24.226377719936924, \"match_probability\": 0.9999999490512425, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4524.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2014.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6919547319412231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30804526805877686, \"precision\": 1.0, \"recall\": 0.6919547319412231, \"specificity\": 1.0, \"npv\": 0.9816463589668274, \"accuracy\": 0.982373058795929, \"f1\": 0.8179352739106852, \"f2\": 0.7373842743512844, \"f0_5\": 0.9182430786717545, \"p4\": 0.8960818273323442, \"phi\": 0.8241692008254549}, {\"truth_threshold\": 24.255581457808105, \"match_probability\": 0.9999999500722038, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4523.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2015.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6918017864227295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3081982135772705, \"precision\": 1.0, \"recall\": 0.6918017864227295, \"specificity\": 1.0, \"npv\": 0.9816374182701111, \"accuracy\": 0.982364296913147, \"f1\": 0.8178284061115632, \"f2\": 0.7372453137734312, \"f0_5\": 0.9181892001624036, \"p4\": 0.8960158283213552, \"phi\": 0.8240743100624576}, {\"truth_threshold\": 24.277949270836558, \"match_probability\": 0.9999999508403237, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4520.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2018.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6913428902626038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30865707993507385, \"precision\": 1.0, \"recall\": 0.6913428902626038, \"specificity\": 1.0, \"npv\": 0.9816105961799622, \"accuracy\": 0.9823380708694458, \"f1\": 0.8175076867426297, \"f2\": 0.7368283776734481, \"f0_5\": 0.9180274595824194, \"p4\": 0.8958177194240237, \"phi\": 0.8237897449989583}, {\"truth_threshold\": 24.278294081552094, \"match_probability\": 0.9999999508520716, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4517.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2021.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6908840537071228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3091159462928772, \"precision\": 1.0, \"recall\": 0.6908840537071228, \"specificity\": 1.0, \"npv\": 0.9815837144851685, \"accuracy\": 0.9823117852210999, \"f1\": 0.8171867933061963, \"f2\": 0.736411360005217, \"f0_5\": 0.9178655612452248, \"p4\": 0.8956194425530005, \"phi\": 0.8235050430101849}, {\"truth_threshold\": 24.2930696100624, \"match_probability\": 0.999999951352857, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4515.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2023.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6905781626701355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3094218373298645, \"precision\": 1.0, \"recall\": 0.6905781626701355, \"specificity\": 1.0, \"npv\": 0.9815658330917358, \"accuracy\": 0.9822943210601807, \"f1\": 0.8169727675744142, \"f2\": 0.7361333028988816, \"f0_5\": 0.9177575412635174, \"p4\": 0.8954871645409753, \"phi\": 0.823315231755038}, {\"truth_threshold\": 24.304700435249938, \"match_probability\": 0.9999999517434675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4511.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2027.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6899663209915161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3100336492061615, \"precision\": 1.0, \"recall\": 0.6899663209915161, \"specificity\": 1.0, \"npv\": 0.9815300703048706, \"accuracy\": 0.9822592735290527, \"f1\": 0.8165444836636799, \"f2\": 0.7355770798682452, \"f0_5\": 0.9175412903750712, \"p4\": 0.8952223839770627, \"phi\": 0.8229354444766908}, {\"truth_threshold\": 24.32632730685774, \"match_probability\": 0.999999952461467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4510.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2028.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6898133754730225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31018659472465515, \"precision\": 1.0, \"recall\": 0.6898133754730225, \"specificity\": 1.0, \"npv\": 0.9815211296081543, \"accuracy\": 0.9822505116462708, \"f1\": 0.8164373642288197, \"f2\": 0.7354380014350009, \"f0_5\": 0.9174871836601839, \"p4\": 0.8951561420075093, \"phi\": 0.8228404881446673}, {\"truth_threshold\": 24.330695643782885, \"match_probability\": 0.9999999526051913, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4508.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2030.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6895074844360352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31049251556396484, \"precision\": 1.0, \"recall\": 0.6895074844360352, \"specificity\": 1.0, \"npv\": 0.9815032482147217, \"accuracy\": 0.9822330474853516, \"f1\": 0.8162230671736375, \"f2\": 0.7351598173515982, \"f0_5\": 0.9173789173789174, \"p4\": 0.8950236018147071, \"phi\": 0.8226504935805291}, {\"truth_threshold\": 24.35872723222088, \"match_probability\": 0.9999999535171844, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4503.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2035.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6887427568435669, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3112572729587555, \"precision\": 1.0, \"recall\": 0.6887427568435669, \"specificity\": 1.0, \"npv\": 0.9814585447311401, \"accuracy\": 0.9821892976760864, \"f1\": 0.8156869848745585, \"f2\": 0.7344641983363236, \"f0_5\": 0.9171079429735234, \"p4\": 0.8946919227893931, \"phi\": 0.8221754267593597}, {\"truth_threshold\": 24.366906572994264, \"match_probability\": 0.9999999537799724, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4501.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2037.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6884368062019348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3115631639957428, \"precision\": 1.0, \"recall\": 0.6884368062019348, \"specificity\": 1.0, \"npv\": 0.9814406633377075, \"accuracy\": 0.9821717739105225, \"f1\": 0.8154724159797083, \"f2\": 0.7341858871888559, \"f0_5\": 0.916999429549344, \"p4\": 0.8945591195831363, \"phi\": 0.8219853569791136}, {\"truth_threshold\": 24.371058675228042, \"match_probability\": 0.9999999539128033, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4500.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2038.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6882838606834412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31171610951423645, \"precision\": 1.0, \"recall\": 0.6882838606834412, \"specificity\": 1.0, \"npv\": 0.9814317226409912, \"accuracy\": 0.9821630120277405, \"f1\": 0.8153651023736184, \"f2\": 0.7340467179955631, \"f0_5\": 0.9169451463036923, \"p4\": 0.8944926897467268, \"phi\": 0.821890253946512}, {\"truth_threshold\": 24.384900956226154, \"match_probability\": 0.9999999543528832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4494.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2044.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6873661875724792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31263384222984314, \"precision\": 1.0, \"recall\": 0.6873661875724792, \"specificity\": 1.0, \"npv\": 0.9813780784606934, \"accuracy\": 0.9821105003356934, \"f1\": 0.8147208121827412, \"f2\": 0.7332115121059845, \"f0_5\": 0.9166190748143918, \"p4\": 0.8940937149239648, \"phi\": 0.8213197123719184}, {\"truth_threshold\": 24.410987942252824, \"match_probability\": 0.9999999551708622, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4493.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2045.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6872132420539856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3127867877483368, \"precision\": 1.0, \"recall\": 0.6872132420539856, \"specificity\": 1.0, \"npv\": 0.981369137763977, \"accuracy\": 0.9821017384529114, \"f1\": 0.8146133623424894, \"f2\": 0.733072279327786, \"f0_5\": 0.9165646674826602, \"p4\": 0.8940271530729078, \"phi\": 0.8212245986891323}, {\"truth_threshold\": 24.415860373470082, \"match_probability\": 0.9999999553220088, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4492.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2046.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6870602369308472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31293973326683044, \"precision\": 1.0, \"recall\": 0.6870602369308472, \"specificity\": 1.0, \"npv\": 0.9813601970672607, \"accuracy\": 0.9820929765701294, \"f1\": 0.814505893019039, \"f2\": 0.7329330374624723, \"f0_5\": 0.9165102423896189, \"p4\": 0.8939605723283506, \"phi\": 0.8211294757224106}, {\"truth_threshold\": 24.422725163805545, \"match_probability\": 0.9999999555340955, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4487.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2051.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6862955093383789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3137044906616211, \"precision\": 1.0, \"recall\": 0.6862955093383789, \"specificity\": 1.0, \"npv\": 0.9813154935836792, \"accuracy\": 0.9820492267608643, \"f1\": 0.813968253968254, \"f2\": 0.7322366917980352, \"f0_5\": 0.9162378502001144, \"p4\": 0.8936273849025149, \"phi\": 0.8206536671823789}, {\"truth_threshold\": 24.441469931265743, \"match_probability\": 0.9999999561080988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4483.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2055.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6856836676597595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3143163025379181, \"precision\": 1.0, \"recall\": 0.6856836676597595, \"specificity\": 1.0, \"npv\": 0.981279730796814, \"accuracy\": 0.9820142388343811, \"f1\": 0.8135377914889755, \"f2\": 0.7316794516076384, \"f0_5\": 0.9160196158561504, \"p4\": 0.8933604940021109, \"phi\": 0.8202728419920186}, {\"truth_threshold\": 24.459572345605793, \"match_probability\": 0.9999999566553975, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4481.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2057.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6853777766227722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3146222233772278, \"precision\": 1.0, \"recall\": 0.6853777766227722, \"specificity\": 1.0, \"npv\": 0.9812618494033813, \"accuracy\": 0.9819967150688171, \"f1\": 0.8133224430529086, \"f2\": 0.7314007769399015, \"f0_5\": 0.9159103916278309, \"p4\": 0.8932269347090918, \"phi\": 0.8200823463081678}, {\"truth_threshold\": 24.46819916753282, \"match_probability\": 0.99999995691381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4480.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2058.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6852248311042786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31477516889572144, \"precision\": 1.0, \"recall\": 0.6852248311042786, \"specificity\": 1.0, \"npv\": 0.981252908706665, \"accuracy\": 0.9819879531860352, \"f1\": 0.8132147395171537, \"f2\": 0.7312614259597806, \"f0_5\": 0.9158557527189468, \"p4\": 0.8931601265716639, \"phi\": 0.8199871116608445}, {\"truth_threshold\": 24.47964330103325, \"match_probability\": 0.9999999572542378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4479.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2059.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6850718855857849, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3149281144142151, \"precision\": 1.0, \"recall\": 0.6850718855857849, \"specificity\": 1.0, \"npv\": 0.9812439680099487, \"accuracy\": 0.981979250907898, \"f1\": 0.813107016429155, \"f2\": 0.7311220658809703, \"f0_5\": 0.9158010959352253, \"p4\": 0.8930932994287665, \"phi\": 0.8198918676868715}, {\"truth_threshold\": 24.48425811430474, \"match_probability\": 0.9999999573907522, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4477.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2061.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6847659945487976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3152340054512024, \"precision\": 1.0, \"recall\": 0.6847659945487976, \"specificity\": 1.0, \"npv\": 0.9812260866165161, \"accuracy\": 0.981961727142334, \"f1\": 0.8128915115751248, \"f2\": 0.7308433184237161, \"f0_5\": 0.9156917287081732, \"p4\": 0.8929595880919594, \"phi\": 0.8197012973548873}, {\"truth_threshold\": 24.49311449169694, \"match_probability\": 0.9999999576515195, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4476.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2062.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.684613049030304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31538698077201843, \"precision\": 1.0, \"recall\": 0.684613049030304, \"specificity\": 1.0, \"npv\": 0.9812171459197998, \"accuracy\": 0.981952965259552, \"f1\": 0.8127837297984384, \"f2\": 0.7307039310434896, \"f0_5\": 0.9156370182472793, \"p4\": 0.8928927038807348, \"phi\": 0.819606025375341}, {\"truth_threshold\": 24.493114491696943, \"match_probability\": 0.9999999576515195, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4475.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2063.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6844601035118103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3155399262905121, \"precision\": 1.0, \"recall\": 0.6844601035118103, \"specificity\": 1.0, \"npv\": 0.9812082052230835, \"accuracy\": 0.98194420337677, \"f1\": 0.8126759284481976, \"f2\": 0.7305645345610082, \"f0_5\": 0.915582289876422, \"p4\": 0.892825800629411, \"phi\": 0.8195107440559394}, {\"truth_threshold\": 24.4965895573119, \"match_probability\": 0.9999999577534029, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4474.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2064.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6843070983886719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31569287180900574, \"precision\": 1.0, \"recall\": 0.6843070983886719, \"specificity\": 1.0, \"npv\": 0.9811992645263672, \"accuracy\": 0.981935441493988, \"f1\": 0.8125681075190702, \"f2\": 0.7304251289753804, \"f0_5\": 0.9155275435868053, \"p4\": 0.8927588783293171, \"phi\": 0.8194154533933771}, {\"truth_threshold\": 24.520329640026112, \"match_probability\": 0.9999999584428978, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4471.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2067.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6838482618331909, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3161517381668091, \"precision\": 1.0, \"recall\": 0.6838482618331909, \"specificity\": 1.0, \"npv\": 0.9811724424362183, \"accuracy\": 0.9819092154502869, \"f1\": 0.812244527205014, \"f2\": 0.7300068575906998, \"f0_5\": 0.9153631971173533, \"p4\": 0.8925579970496316, \"phi\": 0.8191294708877498}, {\"truth_threshold\": 24.527092856586385, \"match_probability\": 0.9999999586372575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4469.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2069.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6835423707962036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3164576292037964, \"precision\": 1.0, \"recall\": 0.6835423707962036, \"specificity\": 1.0, \"npv\": 0.9811545610427856, \"accuracy\": 0.9818916916847229, \"f1\": 0.8120287090033615, \"f2\": 0.7297279644688286, \"f0_5\": 0.9152535430490703, \"p4\": 0.8924239807934611, \"phi\": 0.8189388053797546}, {\"truth_threshold\": 24.542903195609416, \"match_probability\": 0.9999999590880726, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4466.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2072.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6830835342407227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31691649556159973, \"precision\": 1.0, \"recall\": 0.6830835342407227, \"specificity\": 1.0, \"npv\": 0.9811277985572815, \"accuracy\": 0.9818654656410217, \"f1\": 0.811704834605598, \"f2\": 0.7293095564700502, \"f0_5\": 0.9150889271371199, \"p4\": 0.8922228131306441, \"phi\": 0.8186526824315871}, {\"truth_threshold\": 24.547790786426443, \"match_probability\": 0.9999999592264404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4464.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2074.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6827775835990906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31722238659858704, \"precision\": 1.0, \"recall\": 0.6827775835990906, \"specificity\": 1.0, \"npv\": 0.9811099171638489, \"accuracy\": 0.9818479418754578, \"f1\": 0.8114888202145064, \"f2\": 0.729030572249804, \"f0_5\": 0.9149790932196442, \"p4\": 0.8920886057347432, \"phi\": 0.8184618687649213}, {\"truth_threshold\": 24.569214173458224, \"match_probability\": 0.9999999598274365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4462.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2076.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6824716925621033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31752830743789673, \"precision\": 1.0, \"recall\": 0.6824716925621033, \"specificity\": 1.0, \"npv\": 0.9810920357704163, \"accuracy\": 0.9818304181098938, \"f1\": 0.8112727272727273, \"f2\": 0.7287515515777095, \"f0_5\": 0.9148691872385795, \"p4\": 0.8919543217608605, \"phi\": 0.8182710720347601}, {\"truth_threshold\": 24.585476957330574, \"match_probability\": 0.999999960277739, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4460.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2078.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.682165801525116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31783419847488403, \"precision\": 1.0, \"recall\": 0.682165801525116, \"specificity\": 1.0, \"npv\": 0.9810741543769836, \"accuracy\": 0.9818129539489746, \"f1\": 0.8110565557374068, \"f2\": 0.7284724944466222, \"f0_5\": 0.9147592091229797, \"p4\": 0.8918199611391033, \"phi\": 0.8180802377593632}, {\"truth_threshold\": 24.59604262581211, \"match_probability\": 0.9999999605675848, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4459.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2079.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6820128560066223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3179871439933777, \"precision\": 1.0, \"recall\": 0.6820128560066223, \"specificity\": 1.0, \"npv\": 0.9810652136802673, \"accuracy\": 0.9818041920661926, \"f1\": 0.8109484404837684, \"f2\": 0.7283329522067231, \"f0_5\": 0.914704192992533, \"p4\": 0.8917527520634071, \"phi\": 0.8179847520377724}, {\"truth_threshold\": 24.59923885591458, \"match_probability\": 0.999999960654849, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4458.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2080.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6818599104881287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31814008951187134, \"precision\": 1.0, \"recall\": 0.6818599104881287, \"specificity\": 1.0, \"npv\": 0.981056272983551, \"accuracy\": 0.9817954301834106, \"f1\": 0.8108403055656602, \"f2\": 0.7281934008493957, \"f0_5\": 0.9146491588018055, \"p4\": 0.891685523799494, \"phi\": 0.8178893114101077}, {\"truth_threshold\": 24.612434583345422, \"match_probability\": 0.9999999610130818, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4457.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2081.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.681706964969635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3182930648326874, \"precision\": 1.0, \"recall\": 0.681706964969635, \"specificity\": 1.0, \"npv\": 0.9810473322868347, \"accuracy\": 0.9817866683006287, \"f1\": 0.8107321509777171, \"f2\": 0.7280538403737463, \"f0_5\": 0.9145941065419027, \"p4\": 0.8916182763386034, \"phi\": 0.8177938613827944}, {\"truth_threshold\": 24.61546868489242, \"match_probability\": 0.9999999610949882, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4455.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2083.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6814010143280029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3185989558696747, \"precision\": 1.0, \"recall\": 0.6814010143280029, \"specificity\": 1.0, \"npv\": 0.9810295104980469, \"accuracy\": 0.9817691445350647, \"f1\": 0.8105157827708542, \"f2\": 0.727774692063907, \"f0_5\": 0.9144839477789638, \"p4\": 0.8914837237908213, \"phi\": 0.8176029331158644}, {\"truth_threshold\": 24.618866206555964, \"match_probability\": 0.999999961186501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4452.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2086.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.680942177772522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.319057822227478, \"precision\": 1.0, \"recall\": 0.680942177772522, \"specificity\": 1.0, \"npv\": 0.981002688407898, \"accuracy\": 0.9817429184913635, \"f1\": 0.8101910828025478, \"f2\": 0.727355901189387, \"f0_5\": 0.9143185738930419, \"p4\": 0.8912817507724984, \"phi\": 0.8173164155973799}, {\"truth_threshold\": 24.631054574376886, \"match_probability\": 0.9999999615130291, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4451.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2087.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6807892322540283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3192107677459717, \"precision\": 1.0, \"recall\": 0.6807892322540283, \"specificity\": 1.0, \"npv\": 0.9809937477111816, \"accuracy\": 0.9817341566085815, \"f1\": 0.8100828100828101, \"f2\": 0.7272162859850342, \"f0_5\": 0.9142634130309752, \"p4\": 0.891214387945474, \"phi\": 0.8172209090961103}, {\"truth_threshold\": 24.634093081061835, \"match_probability\": 0.9999999615940024, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4450.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2088.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6806362867355347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31936371326446533, \"precision\": 1.0, \"recall\": 0.6806362867355347, \"specificity\": 1.0, \"npv\": 0.9809848070144653, \"accuracy\": 0.9817253947257996, \"f1\": 0.8099745176556243, \"f2\": 0.7270766616561009, \"f0_5\": 0.9142082340373079, \"p4\": 0.8911470058599993, \"phi\": 0.8171253386228329}, {\"truth_threshold\": 24.645860253698, \"match_probability\": 0.9999999619059824, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4446.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2092.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6800244450569153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31997552514076233, \"precision\": 1.0, \"recall\": 0.6800244450569153, \"specificity\": 1.0, \"npv\": 0.9809491038322449, \"accuracy\": 0.9816904067993164, \"f1\": 0.8095411507647488, \"f2\": 0.7265180730766717, \"f0_5\": 0.9139873365677165, \"p4\": 0.8908772847574521, \"phi\": 0.8167431806042408}, {\"truth_threshold\": 24.647011142458847, \"match_probability\": 0.9999999619363592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4444.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2094.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.679718554019928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.320281445980072, \"precision\": 1.0, \"recall\": 0.679718554019928, \"specificity\": 1.0, \"npv\": 0.9809312224388123, \"accuracy\": 0.9816728830337524, \"f1\": 0.8093243489346202, \"f2\": 0.7262387240162113, \"f0_5\": 0.9138767788105618, \"p4\": 0.8907423084263375, \"phi\": 0.8165519903850311}, {\"truth_threshold\": 24.692986770115404, \"match_probability\": 0.9999999631302423, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4443.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2095.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6795656085014343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3204343914985657, \"precision\": 1.0, \"recall\": 0.6795656085014343, \"specificity\": 1.0, \"npv\": 0.980922281742096, \"accuracy\": 0.9816641211509705, \"f1\": 0.8092159184045169, \"f2\": 0.7260990357901618, \"f0_5\": 0.913821472645002, \"p4\": 0.8906747912849193, \"phi\": 0.8164564083934875}, {\"truth_threshold\": 24.708107109341242, \"match_probability\": 0.9999999635146423, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4442.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2096.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6794126629829407, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3205873370170593, \"precision\": 1.0, \"recall\": 0.6794126629829407, \"specificity\": 1.0, \"npv\": 0.9809133410453796, \"accuracy\": 0.9816554188728333, \"f1\": 0.8091074681238616, \"f2\": 0.7259593384323724, \"f0_5\": 0.9137661482761458, \"p4\": 0.8906072548144748, \"phi\": 0.8163608169520036}, {\"truth_threshold\": 24.709666486418048, \"match_probability\": 0.9999999635540572, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4440.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2098.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6791067719459534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32089322805404663, \"precision\": 1.0, \"recall\": 0.6791067719459534, \"specificity\": 1.0, \"npv\": 0.9808955192565918, \"accuracy\": 0.9816378951072693, \"f1\": 0.8088905082893059, \"f2\": 0.7256799163179917, \"f0_5\": 0.9136554448925838, \"p4\": 0.8904721238511157, \"phi\": 0.8161695510978907}, {\"truth_threshold\": 24.715004358443334, \"match_probability\": 0.9999999636886555, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4439.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2099.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6789538264274597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32104620337486267, \"precision\": 1.0, \"recall\": 0.6789538264274597, \"specificity\": 1.0, \"npv\": 0.9808865785598755, \"accuracy\": 0.9816291332244873, \"f1\": 0.808781998724606, \"f2\": 0.725540191559609, \"f0_5\": 0.9136000658598831, \"p4\": 0.8904045293404927, \"phi\": 0.8160739312804706}, {\"truth_threshold\": 24.72856076285693, \"match_probability\": 0.9999999640282601, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4437.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6786478757858276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32135209441185, \"precision\": 1.0, \"recall\": 0.6786478757858276, \"specificity\": 1.0, \"npv\": 0.9808686971664429, \"accuracy\": 0.9816116094589233, \"f1\": 0.8085649202733485, \"f2\": 0.7252607146359803, \"f0_5\": 0.913489253067611, \"p4\": 0.8902692822170475, \"phi\": 0.8158826632519829}, {\"truth_threshold\": 24.76422132710324, \"match_probability\": 0.9999999649065111, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4434.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2104.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6781890392303467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3218109607696533, \"precision\": 1.0, \"recall\": 0.6781890392303467, \"specificity\": 1.0, \"npv\": 0.980841875076294, \"accuracy\": 0.9815853834152222, \"f1\": 0.8082391542107182, \"f2\": 0.7248414307199372, \"f0_5\": 0.913322896926753, \"p4\": 0.8900662661432835, \"phi\": 0.8155956355311823}, {\"truth_threshold\": 24.783494265802236, \"match_probability\": 0.9999999653722069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4432.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2106.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6778831481933594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3221168518066406, \"precision\": 1.0, \"recall\": 0.6778831481933594, \"specificity\": 1.0, \"npv\": 0.9808240532875061, \"accuracy\": 0.9815678596496582, \"f1\": 0.8080218778486782, \"f2\": 0.7245618624117185, \"f0_5\": 0.9132119014258634, \"p4\": 0.8899308250647295, \"phi\": 0.8154042727383861}, {\"truth_threshold\": 24.786096174506884, \"match_probability\": 0.999999965434602, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4431.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2107.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6777302026748657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3222697973251343, \"precision\": 1.0, \"recall\": 0.6777302026748657, \"specificity\": 1.0, \"npv\": 0.9808151125907898, \"accuracy\": 0.9815590977668762, \"f1\": 0.8079132099553287, \"f2\": 0.7244220645456626, \"f0_5\": 0.9131563762261974, \"p4\": 0.8898630753899543, \"phi\": 0.8153085224520004}, {\"truth_threshold\": 24.79483195590517, \"match_probability\": 0.9999999656432694, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4427.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2111.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6771183609962463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3228816092014313, \"precision\": 1.0, \"recall\": 0.6771183609962463, \"specificity\": 1.0, \"npv\": 0.9807794094085693, \"accuracy\": 0.9815241098403931, \"f1\": 0.8074783401732786, \"f2\": 0.7238627816475359, \"f0_5\": 0.9129340922213973, \"p4\": 0.889591882246335, \"phi\": 0.8149255903034694}, {\"truth_threshold\": 24.817602881625263, \"match_probability\": 0.9999999661812854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4426.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2112.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6769654154777527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3230345547199249, \"precision\": 1.0, \"recall\": 0.6769654154777527, \"specificity\": 1.0, \"npv\": 0.980770468711853, \"accuracy\": 0.9815153479576111, \"f1\": 0.807369573148486, \"f2\": 0.7237229380600432, \"f0_5\": 0.912878475373319, \"p4\": 0.8895240353047037, \"phi\": 0.814829847179938}, {\"truth_threshold\": 24.81851765219926, \"match_probability\": 0.999999966202722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4425.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2113.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.676812469959259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32318753004074097, \"precision\": 1.0, \"recall\": 0.676812469959259, \"specificity\": 1.0, \"npv\": 0.9807615280151367, \"accuracy\": 0.9815065860748291, \"f1\": 0.8072607862811274, \"f2\": 0.7235830853255715, \"f0_5\": 0.9128228401683307, \"p4\": 0.8894561688829239, \"phi\": 0.8147340945489494}, {\"truth_threshold\": 24.83921421328821, \"match_probability\": 0.9999999666841085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4423.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2115.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6765065789222717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32349342107772827, \"precision\": 1.0, \"recall\": 0.6765065789222717, \"specificity\": 1.0, \"npv\": 0.9807436466217041, \"accuracy\": 0.9814891219139099, \"f1\": 0.8070431529969894, \"f2\": 0.7233033524121014, \"f0_5\": 0.9127115146512588, \"p4\": 0.8893203775631601, \"phi\": 0.8145425607509975}, {\"truth_threshold\": 24.85598294780823, \"match_probability\": 0.9999999670691041, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4422.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2116.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6763536334037781, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3236463665962219, \"precision\": 1.0, \"recall\": 0.6763536334037781, \"specificity\": 1.0, \"npv\": 0.9807347655296326, \"accuracy\": 0.9814803600311279, \"f1\": 0.8069343065693431, \"f2\": 0.7231634722313076, \"f0_5\": 0.9126558243209775, \"p4\": 0.8892524526472827, \"phi\": 0.8144467248628313}, {\"truth_threshold\": 24.867668228412967, \"match_probability\": 0.9999999673347545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4421.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2117.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6762006878852844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3237993121147156, \"precision\": 1.0, \"recall\": 0.6762006878852844, \"specificity\": 1.0, \"npv\": 0.9807258248329163, \"accuracy\": 0.981471598148346, \"f1\": 0.8068254402773976, \"f2\": 0.7230235828999444, \"f0_5\": 0.9126001155973908, \"p4\": 0.8891845082154702, \"phi\": 0.8143509341620541}, {\"truth_threshold\": 24.867995304282488, \"match_probability\": 0.9999999673421592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4418.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2120.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6757417917251587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3242581784725189, \"precision\": 1.0, \"recall\": 0.6757417917251587, \"specificity\": 1.0, \"npv\": 0.9806990027427673, \"accuracy\": 0.9814453125, \"f1\": 0.8064987221613727, \"f2\": 0.7226038599934577, \"f0_5\": 0.9124328789756299, \"p4\": 0.8889805577347927, \"phi\": 0.8140634501610414}, {\"truth_threshold\": 24.878503090726213, \"match_probability\": 0.9999999675791567, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4417.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2121.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.675588846206665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3244111239910126, \"precision\": 1.0, \"recall\": 0.675588846206665, \"specificity\": 1.0, \"npv\": 0.9806901216506958, \"accuracy\": 0.9814366102218628, \"f1\": 0.8063897763578275, \"f2\": 0.7224639340508359, \"f0_5\": 0.9123770965876229, \"p4\": 0.8889125351495824, \"phi\": 0.8139676213359331}, {\"truth_threshold\": 24.8856318480578, \"match_probability\": 0.9999999677389618, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4415.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2123.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6752829551696777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32471704483032227, \"precision\": 1.0, \"recall\": 0.6752829551696777, \"specificity\": 1.0, \"npv\": 0.9806722402572632, \"accuracy\": 0.9814190864562988, \"f1\": 0.8061718250707569, \"f2\": 0.7221840546995125, \"f0_5\": 0.9122654764856599, \"p4\": 0.8887764312877998, \"phi\": 0.813775935067902}, {\"truth_threshold\": 24.893856607519833, \"match_probability\": 0.9999999679223578, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4414.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2124.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6751300096511841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3248699903488159, \"precision\": 1.0, \"recall\": 0.6751300096511841, \"specificity\": 1.0, \"npv\": 0.9806632995605469, \"accuracy\": 0.9814103245735168, \"f1\": 0.8060628195763331, \"f2\": 0.722044101289014, \"f0_5\": 0.91220963875341, \"p4\": 0.8887083499932467, \"phi\": 0.813680077618142}, {\"truth_threshold\": 24.89873004062361, \"match_probability\": 0.9999999680305334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4413.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2125.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6749770641326904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32502293586730957, \"precision\": 1.0, \"recall\": 0.6749770641326904, \"specificity\": 1.0, \"npv\": 0.9806543588638306, \"accuracy\": 0.9814015626907349, \"f1\": 0.805953794174048, \"f2\": 0.7219041387207591, \"f0_5\": 0.9121537825547748, \"p4\": 0.8886402491109222, \"phi\": 0.8135841558520731}, {\"truth_threshold\": 24.902875411260187, \"match_probability\": 0.9999999681222611, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4412.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2126.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6748241186141968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3251758813858032, \"precision\": 1.0, \"recall\": 0.6748241186141968, \"specificity\": 1.0, \"npv\": 0.980645477771759, \"accuracy\": 0.9813928008079529, \"f1\": 0.8058447488584475, \"f2\": 0.7217641669938489, \"f0_5\": 0.9120979078805921, \"p4\": 0.8885721286318223, \"phi\": 0.8134882792961506}, {\"truth_threshold\": 24.908151990975785, \"match_probability\": 0.9999999682386392, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4411.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2127.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6746711730957031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32532885670661926, \"precision\": 1.0, \"recall\": 0.6746711730957031, \"specificity\": 1.0, \"npv\": 0.9806365370750427, \"accuracy\": 0.9813840985298157, \"f1\": 0.8057356836240752, \"f2\": 0.7216241861073848, \"f0_5\": 0.9120420147216938, \"p4\": 0.8885039885469372, \"phi\": 0.8133923931849862}, {\"truth_threshold\": 24.94213035586523, \"match_probability\": 0.9999999689779429, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4408.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2130.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6742122769355774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3257876932621002, \"precision\": 1.0, \"recall\": 0.6742122769355774, \"specificity\": 1.0, \"npv\": 0.9806097745895386, \"accuracy\": 0.9813578128814697, \"f1\": 0.8054083683537365, \"f2\": 0.7212041884816754, \"f0_5\": 0.9118742242449317, \"p4\": 0.8882994505673901, \"phi\": 0.8131046226880362}, {\"truth_threshold\": 24.956021175949196, \"match_probability\": 0.9999999692752017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4405.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2133.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6737534403800964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32624655961990356, \"precision\": 1.0, \"recall\": 0.6737534403800964, \"specificity\": 1.0, \"npv\": 0.9805829524993896, \"accuracy\": 0.9813315868377686, \"f1\": 0.8050808736178379, \"f2\": 0.7207841083876035, \"f0_5\": 0.911706267075089, \"p4\": 0.8880947358108937, \"phi\": 0.8128168208502239}, {\"truth_threshold\": 24.977146310232218, \"match_probability\": 0.9999999697218217, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4401.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2137.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6731416583061218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32685837149620056, \"precision\": 1.0, \"recall\": 0.6731416583061218, \"specificity\": 1.0, \"npv\": 0.9805472493171692, \"accuracy\": 0.9812965393066406, \"f1\": 0.8046439345461194, \"f2\": 0.7202238732694007, \"f0_5\": 0.9114820644519924, \"p4\": 0.8878215073937973, \"phi\": 0.8124328961009883}, {\"truth_threshold\": 24.982772340362576, \"match_probability\": 0.9999999698396667, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4400.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2138.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6729886531829834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3270113170146942, \"precision\": 1.0, \"recall\": 0.6729886531829834, \"specificity\": 1.0, \"npv\": 0.9805383086204529, \"accuracy\": 0.9812877774238586, \"f1\": 0.8045346498445786, \"f2\": 0.7200837915684735, \"f0_5\": 0.911425967354379, \"p4\": 0.8877531510490483, \"phi\": 0.812336849798047}, {\"truth_threshold\": 24.985265964753193, \"match_probability\": 0.9999999698917522, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4397.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2141.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6725298166275024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32747018337249756, \"precision\": 1.0, \"recall\": 0.6725298166275024, \"specificity\": 1.0, \"npv\": 0.9805115461349487, \"accuracy\": 0.9812615513801575, \"f1\": 0.8042066758116141, \"f2\": 0.7196634914399817, \"f0_5\": 0.9112575644532869, \"p4\": 0.8875479636924638, \"phi\": 0.8120488178150013}, {\"truth_threshold\": 25.00320138614058, \"match_probability\": 0.9999999702637374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4395.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2143.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6722239255905151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32777607440948486, \"precision\": 1.0, \"recall\": 0.6722239255905151, \"specificity\": 1.0, \"npv\": 0.9804937243461609, \"accuracy\": 0.9812440276145935, \"f1\": 0.8039879264611726, \"f2\": 0.7193832454905555, \"f0_5\": 0.9111452027531305, \"p4\": 0.8874110734285715, \"phi\": 0.8118566935889477}, {\"truth_threshold\": 25.018322422694812, \"match_probability\": 0.9999999705737787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4393.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2145.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6719180345535278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32808199524879456, \"precision\": 1.0, \"recall\": 0.6719180345535278, \"specificity\": 1.0, \"npv\": 0.9804758429527283, \"accuracy\": 0.9812265038490295, \"f1\": 0.8037690970633977, \"f2\": 0.7191029628417089, \"f0_5\": 0.9110327664869349, \"p4\": 0.8872741041254774, \"phi\": 0.8116645857712452}, {\"truth_threshold\": 25.02527653067695, \"match_probability\": 0.9999999707152782, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4391.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2147.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6716121435165405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32838788628578186, \"precision\": 1.0, \"recall\": 0.6716121435165405, \"specificity\": 1.0, \"npv\": 0.9804580211639404, \"accuracy\": 0.9812090396881104, \"f1\": 0.8035501875743435, \"f2\": 0.7188226434862325, \"f0_5\": 0.9109202555804498, \"p4\": 0.8871370557102812, \"phi\": 0.8114724394707225}, {\"truth_threshold\": 25.034416451247317, \"match_probability\": 0.9999999709002196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4390.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2148.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6714591383934021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3285408318042755, \"precision\": 1.0, \"recall\": 0.6714591383934021, \"specificity\": 1.0, \"npv\": 0.9804490804672241, \"accuracy\": 0.9812002778053284, \"f1\": 0.8034407027818448, \"f2\": 0.7186824700412546, \"f0_5\": 0.9108639721138684, \"p4\": 0.8870685018128391, \"phi\": 0.8113762969752887}, {\"truth_threshold\": 25.04001749379413, \"match_probability\": 0.999999971012976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4388.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2150.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6711532473564148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3288467526435852, \"precision\": 1.0, \"recall\": 0.6711532473564148, \"specificity\": 1.0, \"npv\": 0.9804312586784363, \"accuracy\": 0.9811827540397644, \"f1\": 0.8032216730734029, \"f2\": 0.7184020956123117, \"f0_5\": 0.9107513491075135, \"p4\": 0.8869313345926061, \"phi\": 0.8111840928865293}, {\"truth_threshold\": 25.040148128731435, \"match_probability\": 0.9999999710156007, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4387.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2151.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6710003018379211, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32899969816207886, \"precision\": 1.0, \"recall\": 0.6710003018379211, \"specificity\": 1.0, \"npv\": 0.98042231798172, \"accuracy\": 0.9811739921569824, \"f1\": 0.803112128146453, \"f2\": 0.7182618946265431, \"f0_5\": 0.9106950095491156, \"p4\": 0.8868627212515341, \"phi\": 0.811087976386811}, {\"truth_threshold\": 25.056985779529633, \"match_probability\": 0.9999999713519103, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4386.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2152.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6708473563194275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3291526436805725, \"precision\": 1.0, \"recall\": 0.6708473563194275, \"specificity\": 1.0, \"npv\": 0.9804133772850037, \"accuracy\": 0.9811652898788452, \"f1\": 0.8030025631636764, \"f2\": 0.7181216844587072, \"f0_5\": 0.910638651274811, \"p4\": 0.8867940880776283, \"phi\": 0.8109917953160852}, {\"truth_threshold\": 25.060155084420835, \"match_probability\": 0.9999999714147753, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4385.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2153.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6706944108009338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32930558919906616, \"precision\": 1.0, \"recall\": 0.6706944108009338, \"specificity\": 1.0, \"npv\": 0.9804044961929321, \"accuracy\": 0.9811565279960632, \"f1\": 0.8028929781195642, \"f2\": 0.7179814651079018, \"f0_5\": 0.910582274275272, \"p4\": 0.8867254350617342, \"phi\": 0.8108956595238282}, {\"truth_threshold\": 25.06292766186364, \"match_probability\": 0.9999999714696577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4384.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2154.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6705414652824402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3294585645198822, \"precision\": 1.0, \"recall\": 0.6705414652824402, \"specificity\": 1.0, \"npv\": 0.9803955554962158, \"accuracy\": 0.9811477661132812, \"f1\": 0.8027833730086065, \"f2\": 0.7178412365732251, \"f0_5\": 0.9105258785411647, \"p4\": 0.8866567621946915, \"phi\": 0.8107995140830896}, {\"truth_threshold\": 25.067329644599354, \"match_probability\": 0.9999999715565774, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4383.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2155.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6703885197639465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32961151003837585, \"precision\": 1.0, \"recall\": 0.6703885197639465, \"specificity\": 1.0, \"npv\": 0.9803866147994995, \"accuracy\": 0.9811390042304993, \"f1\": 0.8026737478252908, \"f2\": 0.7177009988537744, \"f0_5\": 0.9104694640631491, \"p4\": 0.8865880694673343, \"phi\": 0.8107033589903885}, {\"truth_threshold\": 25.108024269394246, \"match_probability\": 0.9999999723476815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4382.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2156.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6702355742454529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3297644555568695, \"precision\": 1.0, \"recall\": 0.6702355742454529, \"specificity\": 1.0, \"npv\": 0.9803776741027832, \"accuracy\": 0.9811302423477173, \"f1\": 0.8025641025641026, \"f2\": 0.7175607519486474, \"f0_5\": 0.910413030831879, \"p4\": 0.8865193568704911, \"phi\": 0.8106071942422426}, {\"truth_threshold\": 25.109967484254494, \"match_probability\": 0.9999999723849022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4379.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2159.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6697766780853271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33022332191467285, \"precision\": 1.0, \"recall\": 0.6697766780853271, \"specificity\": 1.0, \"npv\": 0.980350911617279, \"accuracy\": 0.9811040163040161, \"f1\": 0.8022350462581295, \"f2\": 0.7171399561101831, \"f0_5\": 0.9102436185249855, \"p4\": 0.8863130997712464, \"phi\": 0.8103185870586613}, {\"truth_threshold\": 25.12814288340729, \"match_probability\": 0.9999999727306212, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4376.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2162.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6693178415298462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3306821584701538, \"precision\": 1.0, \"recall\": 0.6693178415298462, \"specificity\": 1.0, \"npv\": 0.9803241491317749, \"accuracy\": 0.9810777306556702, \"f1\": 0.801905809052593, \"f2\": 0.7167190775681341, \"f0_5\": 0.9100740371017386, \"p4\": 0.886106663515912, \"phi\": 0.8100298928143327}, {\"truth_threshold\": 25.170495202145602, \"match_probability\": 0.9999999735195155, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4375.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2163.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6691648960113525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33083510398864746, \"precision\": 1.0, \"recall\": 0.6691648960113525, \"specificity\": 1.0, \"npv\": 0.9803152680397034, \"accuracy\": 0.9810689687728882, \"f1\": 0.8017960230917255, \"f2\": 0.7165787663379959, \"f0_5\": 0.9100174723354688, \"p4\": 0.886037811575391, \"phi\": 0.8099336603683243}, {\"truth_threshold\": 25.171186396809578, \"match_probability\": 0.9999999735321993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4372.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2166.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6687059998512268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3312939703464508, \"precision\": 1.0, \"recall\": 0.6687059998512268, \"specificity\": 1.0, \"npv\": 0.9802885055541992, \"accuracy\": 0.981042742729187, \"f1\": 0.8014665444546287, \"f2\": 0.716157777486568, \"f0_5\": 0.9098476650295513, \"p4\": 0.885831136058564, \"phi\": 0.8096448499021484}, {\"truth_threshold\": 25.18517600037523, \"match_probability\": 0.9999999737876133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4371.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2167.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6685530543327332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33144691586494446, \"precision\": 1.0, \"recall\": 0.6685530543327332, \"specificity\": 1.0, \"npv\": 0.9802795648574829, \"accuracy\": 0.981033980846405, \"f1\": 0.8013566779723165, \"f2\": 0.7160174294794089, \"f0_5\": 0.9097910248938473, \"p4\": 0.8857622042904402, \"phi\": 0.809548578695559}, {\"truth_threshold\": 25.191777015523844, \"match_probability\": 0.9999999739072735, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4370.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2168.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6684001088142395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3315998911857605, \"precision\": 1.0, \"recall\": 0.6684001088142395, \"specificity\": 1.0, \"npv\": 0.9802706241607666, \"accuracy\": 0.981025218963623, \"f1\": 0.8012467913458012, \"f2\": 0.7158770722757355, \"f0_5\": 0.9097343658922474, \"p4\": 0.8856932525423311, \"phi\": 0.8094522977915711}, {\"truth_threshold\": 25.1963602766165, \"match_probability\": 0.9999999739900353, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4369.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2169.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6682471632957458, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33175283670425415, \"precision\": 1.0, \"recall\": 0.6682471632957458, \"specificity\": 1.0, \"npv\": 0.9802617430686951, \"accuracy\": 0.9810164570808411, \"f1\": 0.8011368845695425, \"f2\": 0.7157367058746437, \"f0_5\": 0.9096776880153244, \"p4\": 0.8856242808049918, \"phi\": 0.8093560071866763}, {\"truth_threshold\": 25.205164761699024, \"match_probability\": 0.9999999741482856, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6679412722587585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33205872774124146, \"precision\": 1.0, \"recall\": 0.6679412722587585, \"specificity\": 1.0, \"npv\": 0.9802438616752625, \"accuracy\": 0.9809989929199219, \"f1\": 0.8009170105456213, \"f2\": 0.7154559454765883, \"f0_5\": 0.9095642755977672, \"p4\": 0.8854862773256129, \"phi\": 0.8091633418160329}, {\"truth_threshold\": 25.221223708470944, \"match_probability\": 0.9999999744344509, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4361.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2177.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6670235395431519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33297643065452576, \"precision\": 1.0, \"recall\": 0.6670235395431519, \"specificity\": 1.0, \"npv\": 0.9801903367042542, \"accuracy\": 0.9809464812278748, \"f1\": 0.8002569043031471, \"f2\": 0.7146134434503326, \"f0_5\": 0.9092235843549329, \"p4\": 0.8850717861826829, \"phi\": 0.808585222532287}, {\"truth_threshold\": 25.222479354981203, \"match_probability\": 0.9999999744566921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4360.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2178.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6668705940246582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3331294059753418, \"precision\": 1.0, \"recall\": 0.6668705940246582, \"specificity\": 1.0, \"npv\": 0.9801814556121826, \"accuracy\": 0.9809377193450928, \"f1\": 0.8001468159295283, \"f2\": 0.7144729942317777, \"f0_5\": 0.9091667361748269, \"p4\": 0.8850026341252966, \"phi\": 0.8084888444488754}, {\"truth_threshold\": 25.230080085863147, \"match_probability\": 0.9999999745909113, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4359.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2179.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6667176485061646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33328235149383545, \"precision\": 1.0, \"recall\": 0.6667176485061646, \"specificity\": 1.0, \"npv\": 0.9801725149154663, \"accuracy\": 0.9809289574623108, \"f1\": 0.8000367073506469, \"f2\": 0.7143325358067583, \"f0_5\": 0.9091098690247769, \"p4\": 0.884933461985914, \"phi\": 0.8083924566293547}, {\"truth_threshold\": 25.233995211887393, \"match_probability\": 0.9999999746597719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4357.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2181.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6664117574691772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33358824253082275, \"precision\": 1.0, \"recall\": 0.6664117574691772, \"specificity\": 1.0, \"npv\": 0.9801546931266785, \"accuracy\": 0.9809114336967468, \"f1\": 0.7998164295548417, \"f2\": 0.7140515913337048, \"f0_5\": 0.9089960777768505, \"p4\": 0.8847950574239227, \"phi\": 0.8081995966631487}, {\"truth_threshold\": 25.237625121581395, \"match_probability\": 0.9999999747234494, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4356.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2182.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6662588119506836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3337412178516388, \"precision\": 1.0, \"recall\": 0.6662588119506836, \"specificity\": 1.0, \"npv\": 0.9801457524299622, \"accuracy\": 0.9809027314186096, \"f1\": 0.7997062603267854, \"f2\": 0.7139111052838599, \"f0_5\": 0.9089391536599616, \"p4\": 0.8847258249826805, \"phi\": 0.8081031796080334}, {\"truth_threshold\": 25.282611936995597, \"match_probability\": 0.999999975499473, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4355.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2183.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6661058664321899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33389416337013245, \"precision\": 1.0, \"recall\": 0.6661058664321899, \"specificity\": 1.0, \"npv\": 0.9801368713378906, \"accuracy\": 0.9808939695358276, \"f1\": 0.7995960708712017, \"f2\": 0.7137706100239289, \"f0_5\": 0.9088822105351031, \"p4\": 0.8846565724221752, \"phi\": 0.808006752802671}, {\"truth_threshold\": 25.283737840136986, \"match_probability\": 0.9999999755185861, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4354.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2184.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6659528613090515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3340471088886261, \"precision\": 1.0, \"recall\": 0.6659528613090515, \"specificity\": 1.0, \"npv\": 0.9801279306411743, \"accuracy\": 0.9808852076530457, \"f1\": 0.7994858611825193, \"f2\": 0.713630105553006, \"f0_5\": 0.9088252483927528, \"p4\": 0.884587299733076, \"phi\": 0.8079102611205818}, {\"truth_threshold\": 25.304700435249938, \"match_probability\": 0.9999999758717332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4353.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2185.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6657999157905579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33420005440711975, \"precision\": 1.0, \"recall\": 0.6657999157905579, \"specificity\": 1.0, \"npv\": 0.980118989944458, \"accuracy\": 0.9808764457702637, \"f1\": 0.7993756312551649, \"f2\": 0.7134895918701852, \"f0_5\": 0.908768267223382, \"p4\": 0.8845180069060459, \"phi\": 0.8078138147980257}, {\"truth_threshold\": 25.31916478849406, \"match_probability\": 0.9999999761124327, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4352.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2186.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6656469702720642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3343529999256134, \"precision\": 1.0, \"recall\": 0.6656469702720642, \"specificity\": 1.0, \"npv\": 0.9801101088523865, \"accuracy\": 0.9808676838874817, \"f1\": 0.7992653810835629, \"f2\": 0.7133490689745607, \"f0_5\": 0.908711267017456, \"p4\": 0.8844486939317423, \"phi\": 0.807717358714597}, {\"truth_threshold\": 25.32464104045845, \"match_probability\": 0.9999999762029345, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4351.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2187.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6654940247535706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33450597524642944, \"precision\": 1.0, \"recall\": 0.6654940247535706, \"specificity\": 1.0, \"npv\": 0.9801011681556702, \"accuracy\": 0.9808589220046997, \"f1\": 0.7991551106621361, \"f2\": 0.7132085368652263, \"f0_5\": 0.9086542477654331, \"p4\": 0.8843793608008168, \"phi\": 0.8076208928667507}, {\"truth_threshold\": 25.32561953436201, \"match_probability\": 0.9999999762190691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4349.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2189.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6651881337165833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33481186628341675, \"precision\": 1.0, \"recall\": 0.6651881337165833, \"specificity\": 1.0, \"npv\": 0.9800833463668823, \"accuracy\": 0.9808414578437805, \"f1\": 0.7989345090474879, \"f2\": 0.7129274450018033, \"f0_5\": 0.9085401520849001, \"p4\": 0.8842406340316775, \"phi\": 0.8074278767102492}, {\"truth_threshold\": 25.336105004246328, \"match_probability\": 0.9999999763912817, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4348.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2190.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6650351881980896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3349648118019104, \"precision\": 1.0, \"recall\": 0.6650351881980896, \"specificity\": 1.0, \"npv\": 0.980074405670166, \"accuracy\": 0.9808326959609985, \"f1\": 0.7988241778431012, \"f2\": 0.7127868852459016, \"f0_5\": 0.9084830756372754, \"p4\": 0.884171240374738, \"phi\": 0.8073313815417668}, {\"truth_threshold\": 25.371058675228042, \"match_probability\": 0.9999999769564011, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4347.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2191.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.664882242679596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33511778712272644, \"precision\": 1.0, \"recall\": 0.664882242679596, \"specificity\": 1.0, \"npv\": 0.9800655245780945, \"accuracy\": 0.9808239340782166, \"f1\": 0.7987138263665595, \"f2\": 0.7126463162726647, \"f0_5\": 0.9084259801053247, \"p4\": 0.8841018265237253, \"phi\": 0.8072348765946628}, {\"truth_threshold\": 25.39062702956712, \"match_probability\": 0.9999999772668485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4341.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2197.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6639645099639893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33603549003601074, \"precision\": 1.0, \"recall\": 0.6639645099639893, \"specificity\": 1.0, \"npv\": 0.9800119996070862, \"accuracy\": 0.9807714223861694, \"f1\": 0.7980512914789962, \"f2\": 0.7118027088184173, \"f0_5\": 0.9080830056062255, \"p4\": 0.8836849188165722, \"phi\": 0.8066555861595919}, {\"truth_threshold\": 25.44886484945019, \"match_probability\": 0.9999999781662509, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4340.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2198.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6638115644454956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3361884355545044, \"precision\": 1.0, \"recall\": 0.6638115644454956, \"specificity\": 1.0, \"npv\": 0.9800031185150146, \"accuracy\": 0.9807626605033875, \"f1\": 0.797940797940798, \"f2\": 0.711662075298439, \"f0_5\": 0.9080257762155829, \"p4\": 0.8836153633441558, \"phi\": 0.8065589574481024}, {\"truth_threshold\": 25.46819916753282, \"match_probability\": 0.9999999784569046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.663658618927002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33634138107299805, \"precision\": 1.0, \"recall\": 0.663658618927002, \"specificity\": 1.0, \"npv\": 0.9799941778182983, \"accuracy\": 0.9807538986206055, \"f1\": 0.7978302840856853, \"f2\": 0.7115214325538683, \"f0_5\": 0.9079685276638486, \"p4\": 0.8835457876024848, \"phi\": 0.8064623741316385}, {\"truth_threshold\": 25.470594348778956, \"match_probability\": 0.999999978492641, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4336.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2202.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.663199782371521, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3368002474308014, \"precision\": 1.0, \"recall\": 0.663199782371521, \"specificity\": 1.0, \"npv\": 0.9799674153327942, \"accuracy\": 0.9807276725769043, \"f1\": 0.7974986205628104, \"f2\": 0.7110994489635266, \"f0_5\": 0.907796666945817, \"p4\": 0.8833369386676766, \"phi\": 0.8061725100710413}, {\"truth_threshold\": 25.48187542821854, \"match_probability\": 0.9999999786601609, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4335.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2203.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6630467772483826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33695319294929504, \"precision\": 1.0, \"recall\": 0.6630467772483826, \"specificity\": 1.0, \"npv\": 0.9799585342407227, \"accuracy\": 0.9807189106941223, \"f1\": 0.7973880253839787, \"f2\": 0.7109587693115098, \"f0_5\": 0.9077393416534049, \"p4\": 0.8832672817546903, \"phi\": 0.806075887484211}, {\"truth_threshold\": 25.495323366532308, \"match_probability\": 0.9999999788581538, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4334.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2204.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6628938317298889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3371061384677887, \"precision\": 1.0, \"recall\": 0.6628938317298889, \"specificity\": 1.0, \"npv\": 0.9799495935440063, \"accuracy\": 0.9807101488113403, \"f1\": 0.7972774098601914, \"f2\": 0.7108180804303614, \"f0_5\": 0.9076819971517132, \"p4\": 0.8831976045252717, \"phi\": 0.8059792550723712}, {\"truth_threshold\": 25.502284907033253, \"match_probability\": 0.9999999789599254, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4333.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2205.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6627408862113953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33725911378860474, \"precision\": 1.0, \"recall\": 0.6627408862113953, \"specificity\": 1.0, \"npv\": 0.9799407124519348, \"accuracy\": 0.9807013869285583, \"f1\": 0.7971667739858339, \"f2\": 0.7106773823191733, \"f0_5\": 0.907624633431085, \"p4\": 0.8831279069699679, \"phi\": 0.8058826128319398}, {\"truth_threshold\": 25.510730325665932, \"match_probability\": 0.9999999790827324, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4331.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2207.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.662434995174408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33756500482559204, \"precision\": 1.0, \"recall\": 0.662434995174408, \"specificity\": 1.0, \"npv\": 0.9799228310585022, \"accuracy\": 0.9806839227676392, \"f1\": 0.7969454411629405, \"f2\": 0.7103959584030444, \"f0_5\": 0.9075098482943592, \"p4\": 0.8829884508438625, \"phi\": 0.8056892435876309}, {\"truth_threshold\": 25.512064778725627, \"match_probability\": 0.9999999791020714, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4330.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2208.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6622820496559143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3377179503440857, \"precision\": 1.0, \"recall\": 0.6622820496559143, \"specificity\": 1.0, \"npv\": 0.9799139499664307, \"accuracy\": 0.9806751608848572, \"f1\": 0.7968347442031652, \"f2\": 0.7102552325962863, \"f0_5\": 0.9074524268589153, \"p4\": 0.8829186922541254, \"phi\": 0.8055925718337799}, {\"truth_threshold\": 25.52235928050094, \"match_probability\": 0.99999997925066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4329.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2209.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6621291041374207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33787089586257935, \"precision\": 1.0, \"recall\": 0.6621291041374207, \"specificity\": 1.0, \"npv\": 0.9799050092697144, \"accuracy\": 0.9806663990020752, \"f1\": 0.7967240268703414, \"f2\": 0.7101144975558544, \"f0_5\": 0.9073949861658422, \"p4\": 0.8828489133006322, \"phi\": 0.805495890236985}, {\"truth_threshold\": 25.547033461794896, \"match_probability\": 0.9999999796025152, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4328.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2210.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.661976158618927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3380238711833954, \"precision\": 1.0, \"recall\": 0.661976158618927, \"specificity\": 1.0, \"npv\": 0.9798961281776428, \"accuracy\": 0.9806576371192932, \"f1\": 0.7966132891588441, \"f2\": 0.7099737532808399, \"f0_5\": 0.9073375262054507, \"p4\": 0.8827791139739002, \"phi\": 0.8053991987936534}, {\"truth_threshold\": 25.548148647637706, \"match_probability\": 0.9999999796182761, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4327.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2211.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6618232131004333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33817681670188904, \"precision\": 1.0, \"recall\": 0.6618232131004333, \"specificity\": 1.0, \"npv\": 0.9798871874809265, \"accuracy\": 0.9806488752365112, \"f1\": 0.7965025310630465, \"f2\": 0.7098329997703337, \"f0_5\": 0.907280046968045, \"p4\": 0.8827092942644413, \"phi\": 0.8053024975001903}, {\"truth_threshold\": 25.56545901551577, \"match_probability\": 0.9999999798613676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4325.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2213.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6615172624588013, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33848270773887634, \"precision\": 1.0, \"recall\": 0.6615172624588013, \"specificity\": 1.0, \"npv\": 0.9798693656921387, \"accuracy\": 0.980631411075592, \"f1\": 0.7962809536960324, \"f2\": 0.7095514650392098, \"f0_5\": 0.9071650306233744, \"p4\": 0.8825695936593599, \"phi\": 0.8051090100483389}, {\"truth_threshold\": 25.57306802294324, \"match_probability\": 0.9999999799673024, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4324.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2214.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6613643169403076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3386356830596924, \"precision\": 1.0, \"recall\": 0.6613643169403076, \"specificity\": 1.0, \"npv\": 0.9798604846000671, \"accuracy\": 0.9806226491928101, \"f1\": 0.7961701344135518, \"f2\": 0.7094106838167739, \"f0_5\": 0.9071074934966854, \"p4\": 0.8824997127447315, \"phi\": 0.8050122791767493}, {\"truth_threshold\": 25.5765187794145, \"match_probability\": 0.999999980015161, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4321.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2217.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6609054803848267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33909451961517334, \"precision\": 1.0, \"recall\": 0.6609054803848267, \"specificity\": 1.0, \"npv\": 0.979833722114563, \"accuracy\": 0.9805963635444641, \"f1\": 0.7958375541025877, \"f2\": 0.7089882847110557, \"f0_5\": 0.9069347661825203, \"p4\": 0.8822899474383348, \"phi\": 0.8047219720356307}, {\"truth_threshold\": 25.584459977445828, \"match_probability\": 0.9999999801248637, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4319.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2219.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6605995893478394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33940044045448303, \"precision\": 1.0, \"recall\": 0.6605995893478394, \"specificity\": 1.0, \"npv\": 0.9798159003257751, \"accuracy\": 0.9805788993835449, \"f1\": 0.7956157317859446, \"f2\": 0.7087066390994716, \"f0_5\": 0.9068195179306291, \"p4\": 0.8821500016700593, \"phi\": 0.8045284214416308}, {\"truth_threshold\": 25.612311792387143, \"match_probability\": 0.9999999805048813, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4318.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2220.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6604466438293457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3395533859729767, \"precision\": 1.0, \"recall\": 0.6604466438293457, \"specificity\": 1.0, \"npv\": 0.9798069596290588, \"accuracy\": 0.9805701375007629, \"f1\": 0.7955047899778924, \"f2\": 0.7085658024286183, \"f0_5\": 0.9067618647627047, \"p4\": 0.8820799980881119, \"phi\": 0.8044316313225631}, {\"truth_threshold\": 25.632994077940044, \"match_probability\": 0.999999980782367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4315.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2223.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.65998774766922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34001222252845764, \"precision\": 1.0, \"recall\": 0.65998774766922, \"specificity\": 1.0, \"npv\": 0.9797802567481995, \"accuracy\": 0.980543851852417, \"f1\": 0.7951718418870358, \"f2\": 0.7081432369448912, \"f0_5\": 0.9065887889738633, \"p4\": 0.8818698644364441, \"phi\": 0.8041411462720289}, {\"truth_threshold\": 25.634093081061835, \"match_probability\": 0.9999999807970008, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4314.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2224.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6598348021507263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3401651978492737, \"precision\": 1.0, \"recall\": 0.6598348021507263, \"specificity\": 1.0, \"npv\": 0.9797713160514832, \"accuracy\": 0.980535089969635, \"f1\": 0.7950608182823443, \"f2\": 0.7080023632902251, \"f0_5\": 0.906531058249979, \"p4\": 0.8817997788854157, \"phi\": 0.8040443165802865}, {\"truth_threshold\": 25.64250114289423, \"match_probability\": 0.9999999809085909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4313.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2225.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6596818566322327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34031814336776733, \"precision\": 1.0, \"recall\": 0.6596818566322327, \"specificity\": 1.0, \"npv\": 0.9797624349594116, \"accuracy\": 0.980526328086853, \"f1\": 0.7949497742143581, \"f2\": 0.7078614803873298, \"f0_5\": 0.9064733081126524, \"p4\": 0.8817296728182041, \"phi\": 0.8039474216138629}, {\"truth_threshold\": 25.645117585141993, \"match_probability\": 0.9999999809431833, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4312.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2226.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.659528911113739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.340471088886261, \"precision\": 1.0, \"recall\": 0.659528911113739, \"specificity\": 1.0, \"npv\": 0.9797534942626953, \"accuracy\": 0.9805176258087158, \"f1\": 0.7948387096774193, \"f2\": 0.7077205882352942, \"f0_5\": 0.9064155385520895, \"p4\": 0.8816595462252325, \"phi\": 0.8038505721109559}, {\"truth_threshold\": 25.679580871542, \"match_probability\": 0.9999999813930207, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4311.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2227.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6593759655952454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34062403440475464, \"precision\": 1.0, \"recall\": 0.6593759655952454, \"specificity\": 1.0, \"npv\": 0.9797446131706238, \"accuracy\": 0.9805088639259338, \"f1\": 0.7947276246658678, \"f2\": 0.7075796868332075, \"f0_5\": 0.9063577495584896, \"p4\": 0.8815893990969175, \"phi\": 0.8037537127001069}, {\"truth_threshold\": 25.683310335650486, \"match_probability\": 0.999999981441059, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4310.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2228.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6592230200767517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3407770097255707, \"precision\": 1.0, \"recall\": 0.6592230200767517, \"specificity\": 1.0, \"npv\": 0.9797356724739075, \"accuracy\": 0.9805001020431519, \"f1\": 0.7946165191740413, \"f2\": 0.7074387761801589, \"f0_5\": 0.9062999411220456, \"p4\": 0.8815192314236704, \"phi\": 0.8036568433776858}, {\"truth_threshold\": 25.684741037239565, \"match_probability\": 0.9999999814594545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4309.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2229.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6590700745582581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34092995524406433, \"precision\": 1.0, \"recall\": 0.6590700745582581, \"specificity\": 1.0, \"npv\": 0.9797267913818359, \"accuracy\": 0.9804913401603699, \"f1\": 0.7945053931962754, \"f2\": 0.7072978562752372, \"f0_5\": 0.9062421132329436, \"p4\": 0.8814490431958961, \"phi\": 0.8035599641400597}, {\"truth_threshold\": 25.692986770115404, \"match_probability\": 0.9999999815651208, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4308.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2230.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6589171290397644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.341082900762558, \"precision\": 1.0, \"recall\": 0.6589171290397644, \"specificity\": 1.0, \"npv\": 0.9797178506851196, \"accuracy\": 0.9804825782775879, \"f1\": 0.794394246726904, \"f2\": 0.7071569271175312, \"f0_5\": 0.906184265881363, \"p4\": 0.8813788344039939, \"phi\": 0.8034630195787326}, {\"truth_threshold\": 25.695836730396387, \"match_probability\": 0.9999999816015019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4301.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2237.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6578464508056641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34215354919433594, \"precision\": 1.0, \"recall\": 0.6578464508056641, \"specificity\": 1.0, \"npv\": 0.9796555042266846, \"accuracy\": 0.9804213047027588, \"f1\": 0.7936156471999262, \"f2\": 0.7061701638590615, \"f0_5\": 0.905778788644596, \"p4\": 0.880886796257363, \"phi\": 0.8027844619587337}, {\"truth_threshold\": 25.710492995555434, \"match_probability\": 0.9999999817874651, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4300.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2238.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6576935052871704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.342306524515152, \"precision\": 1.0, \"recall\": 0.6576935052871704, \"specificity\": 1.0, \"npv\": 0.9796465635299683, \"accuracy\": 0.9804126024246216, \"f1\": 0.7935043365934674, \"f2\": 0.706029160646263, \"f0_5\": 0.9057207852388576, \"p4\": 0.8808164226060866, \"phi\": 0.8026874933080562}, {\"truth_threshold\": 25.72129731160559, \"match_probability\": 0.9999999819233489, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4299.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2239.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6575405597686768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34245947003364563, \"precision\": 1.0, \"recall\": 0.6575405597686768, \"specificity\": 1.0, \"npv\": 0.9796376824378967, \"accuracy\": 0.9804038405418396, \"f1\": 0.7933930054443111, \"f2\": 0.7058881481724738, \"f0_5\": 0.9056627622819584, \"p4\": 0.8807460283040047, \"phi\": 0.8025904592451701}, {\"truth_threshold\": 25.757533032169356, \"match_probability\": 0.9999999823717202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4297.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2241.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6572346091270447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34276536107063293, \"precision\": 1.0, \"recall\": 0.6572346091270447, \"specificity\": 1.0, \"npv\": 0.9796198606491089, \"accuracy\": 0.9803863167762756, \"f1\": 0.7931702814951546, \"f2\": 0.7056060954382738, \"f0_5\": 0.9055466576751243, \"p4\": 0.8806051777087751, \"phi\": 0.8023964721585278}, {\"truth_threshold\": 25.75844170351212, \"match_probability\": 0.9999999823828197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4296.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2242.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.657081663608551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.342918336391449, \"precision\": 1.0, \"recall\": 0.657081663608551, \"specificity\": 1.0, \"npv\": 0.9796109795570374, \"accuracy\": 0.9803775548934937, \"f1\": 0.7930588886837733, \"f2\": 0.7054650551760379, \"f0_5\": 0.9054885760053958, \"p4\": 0.8805347213962876, \"phi\": 0.8022994636730937}, {\"truth_threshold\": 25.759330353660246, \"match_probability\": 0.9999999823936679, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4295.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2243.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6569287180900574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3430712819099426, \"precision\": 1.0, \"recall\": 0.6569287180900574, \"specificity\": 1.0, \"npv\": 0.979602038860321, \"accuracy\": 0.9803687930107117, \"f1\": 0.7929474753069325, \"f2\": 0.7053240056491609, \"f0_5\": 0.9054304747449194, \"p4\": 0.8804642443943153, \"phi\": 0.8022024452213683}, {\"truth_threshold\": 25.771382045413525, \"match_probability\": 0.9999999825401316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4294.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2244.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6567757725715637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3432242274284363, \"precision\": 1.0, \"recall\": 0.6567757725715637, \"specificity\": 1.0, \"npv\": 0.9795931577682495, \"accuracy\": 0.9803600907325745, \"f1\": 0.7928360413589365, \"f2\": 0.70518294685673, \"f0_5\": 0.9053723538837817, \"p4\": 0.8803937466931729, \"phi\": 0.8021053613081119}, {\"truth_threshold\": 25.788791207998276, \"match_probability\": 0.9999999827495556, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4292.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2246.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6564698815345764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3435301184654236, \"precision\": 1.0, \"recall\": 0.6564698815345764, \"specificity\": 1.0, \"npv\": 0.9795753359794617, \"accuracy\": 0.9803425669670105, \"f1\": 0.7926131117266851, \"f2\": 0.7049008014715543, \"f0_5\": 0.9052560533198346, \"p4\": 0.8802526891546087, \"phi\": 0.8019112745277908}, {\"truth_threshold\": 25.80157139592061, \"match_probability\": 0.9999999829016947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4291.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2247.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6563169360160828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3436830937862396, \"precision\": 1.0, \"recall\": 0.6563169360160828, \"specificity\": 1.0, \"npv\": 0.9795663952827454, \"accuracy\": 0.9803338050842285, \"f1\": 0.7925016160310278, \"f2\": 0.7047597148769832, \"f0_5\": 0.9051978735971647, \"p4\": 0.8801821292977866, \"phi\": 0.8018142161680188}, {\"truth_threshold\": 25.805431498370275, \"match_probability\": 0.9999999829473821, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4288.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2250.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.655858039855957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3441419303417206, \"precision\": 1.0, \"recall\": 0.655858039855957, \"specificity\": 1.0, \"npv\": 0.979539692401886, \"accuracy\": 0.9803075790405273, \"f1\": 0.7921670053574728, \"f2\": 0.7043363994743759, \"f0_5\": 0.9050232165470663, \"p4\": 0.8799703252606328, \"phi\": 0.8015229256373037}, {\"truth_threshold\": 25.831686766630874, \"match_probability\": 0.9999999832549119, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4287.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2251.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6557050943374634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3442949056625366, \"precision\": 1.0, \"recall\": 0.6557050943374634, \"specificity\": 1.0, \"npv\": 0.9795307517051697, \"accuracy\": 0.9802988171577454, \"f1\": 0.7920554272517321, \"f2\": 0.7041952757974966, \"f0_5\": 0.904964958203158, \"p4\": 0.8798996823936148, \"phi\": 0.8014258273106972}, {\"truth_threshold\": 25.89176303787631, \"match_probability\": 0.9999999839378869, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4286.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2252.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6555521488189697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3444478511810303, \"precision\": 1.0, \"recall\": 0.6555521488189697, \"specificity\": 1.0, \"npv\": 0.9795218706130981, \"accuracy\": 0.9802900552749634, \"f1\": 0.7919438285291944, \"f2\": 0.7040541428477561, \"f0_5\": 0.904906680179039, \"p4\": 0.8798290187497295, \"phi\": 0.8013287189847369}, {\"truth_threshold\": 25.909538764836512, \"match_probability\": 0.9999999841345771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4285.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2253.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6553992033004761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3446007966995239, \"precision\": 1.0, \"recall\": 0.6553992033004761, \"specificity\": 1.0, \"npv\": 0.9795129895210266, \"accuracy\": 0.9802812933921814, \"f1\": 0.7918322091841449, \"f2\": 0.7039130006242402, \"f0_5\": 0.9048483824647352, \"p4\": 0.8797583343192376, \"phi\": 0.8012315451081912}, {\"truth_threshold\": 25.93739677977978, \"match_probability\": 0.9999999844379949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4284.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2254.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6552462577819824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3447537422180176, \"precision\": 1.0, \"recall\": 0.6552462577819824, \"specificity\": 1.0, \"npv\": 0.9795040488243103, \"accuracy\": 0.9802725315093994, \"f1\": 0.7917205692108668, \"f2\": 0.703771849126035, \"f0_5\": 0.9047900650502662, \"p4\": 0.8796876290923934, \"phi\": 0.8011344167662386}, {\"truth_threshold\": 25.937441979254935, \"match_probability\": 0.9999999844384825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4283.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2255.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6550933122634888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34490668773651123, \"precision\": 1.0, \"recall\": 0.6550933122634888, \"specificity\": 1.0, \"npv\": 0.9794951677322388, \"accuracy\": 0.9802637696266174, \"f1\": 0.7916089086036411, \"f2\": 0.7036306883522261, \"f0_5\": 0.9047317279256443, \"p4\": 0.8796169030594453, \"phi\": 0.8010372784138717}, {\"truth_threshold\": 25.94213035586523, \"match_probability\": 0.9999999844889712, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4282.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2256.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6549403667449951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34505966305732727, \"precision\": 1.0, \"recall\": 0.6549403667449951, \"specificity\": 1.0, \"npv\": 0.9794862270355225, \"accuracy\": 0.9802550673484802, \"f1\": 0.7914972273567468, \"f2\": 0.7034895183018992, \"f0_5\": 0.9046733710808755, \"p4\": 0.8795461562106356, \"phi\": 0.8009401300474002}, {\"truth_threshold\": 25.956021175949196, \"match_probability\": 0.9999999846376006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4281.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2257.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6547874212265015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3452126085758209, \"precision\": 1.0, \"recall\": 0.6547874212265015, \"specificity\": 1.0, \"npv\": 0.9794773459434509, \"accuracy\": 0.9802463054656982, \"f1\": 0.7913855254644607, \"f2\": 0.70334833897414, \"f0_5\": 0.904614994505959, \"p4\": 0.8794753885362004, \"phi\": 0.8008429160906496}, {\"truth_threshold\": 25.98619288187395, \"match_probability\": 0.9999999849555449, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4280.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2258.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.654634416103363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3453655540943146, \"precision\": 1.0, \"recall\": 0.654634416103363, \"specificity\": 1.0, \"npv\": 0.9794684052467346, \"accuracy\": 0.9802375435829163, \"f1\": 0.7912738029210575, \"f2\": 0.7032071503680336, \"f0_5\": 0.9045565981908869, \"p4\": 0.8794046000263699, \"phi\": 0.8007457476786494}, {\"truth_threshold\": 25.99363928040026, \"match_probability\": 0.999999985032996, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4279.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2259.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6544814705848694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3455184996128082, \"precision\": 1.0, \"recall\": 0.6544814705848694, \"specificity\": 1.0, \"npv\": 0.9794595241546631, \"accuracy\": 0.9802287817001343, \"f1\": 0.7911620597208099, \"f2\": 0.7030659524826657, \"f0_5\": 0.9044981821256447, \"p4\": 0.8793337906713681, \"phi\": 0.800648569241458}, {\"truth_threshold\": 26.00115399711557, \"match_probability\": 0.9999999851107535, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4278.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2260.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6543285250663757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3456714451313019, \"precision\": 1.0, \"recall\": 0.6543285250663757, \"specificity\": 1.0, \"npv\": 0.9794506430625916, \"accuracy\": 0.9802200198173523, \"f1\": 0.7910502958579881, \"f2\": 0.7029247453171212, \"f0_5\": 0.9044397463002114, \"p4\": 0.8792629604614127, \"phi\": 0.8005513807753761}, {\"truth_threshold\": 26.029049672223483, \"match_probability\": 0.9999999853958836, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4276.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2262.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6540226340293884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3459773659706116, \"precision\": 1.0, \"recall\": 0.6540226340293884, \"specificity\": 1.0, \"npv\": 0.9794328212738037, \"accuracy\": 0.9802025556564331, \"f1\": 0.7908267061216941, \"f2\": 0.7026423031418431, \"f0_5\": 0.9043228153286524, \"p4\": 0.8791212374374825, \"phi\": 0.8003569181380357}, {\"truth_threshold\": 26.04146510222635, \"match_probability\": 0.9999999855210234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4274.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2264.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6537167429924011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3462832570075989, \"precision\": 1.0, \"recall\": 0.6537167429924011, \"specificity\": 1.0, \"npv\": 0.9794149994850159, \"accuracy\": 0.9801850318908691, \"f1\": 0.7906030336662967, \"f2\": 0.702359823834878, \"f0_5\": 0.9042058051959042, \"p4\": 0.8789794308761998, \"phi\": 0.8001624709318871}, {\"truth_threshold\": 26.042512871539437, \"match_probability\": 0.999999985531535, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4272.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2266.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6534108519554138, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34658917784690857, \"precision\": 1.0, \"recall\": 0.6534108519554138, \"specificity\": 1.0, \"npv\": 0.979397177696228, \"accuracy\": 0.9801675081253052, \"f1\": 0.7903792784458834, \"f2\": 0.7020773073889035, \"f0_5\": 0.9040887158215525, \"p4\": 0.8788375406990871, \"phi\": 0.7999679279073415}, {\"truth_threshold\": 26.06554036071372, \"match_probability\": 0.9999999857606393, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4271.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2267.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6532579064369202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3467421233654022, \"precision\": 1.0, \"recall\": 0.6532579064369202, \"specificity\": 1.0, \"npv\": 0.9793882966041565, \"accuracy\": 0.9801587462425232, \"f1\": 0.7902673697844389, \"f2\": 0.7019360352364987, \"f0_5\": 0.9040301413936161, \"p4\": 0.8787665642300436, \"phi\": 0.7998706691227528}, {\"truth_threshold\": 26.073216300423315, \"match_probability\": 0.9999999858361994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4270.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2268.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6531049013137817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3468950688838959, \"precision\": 1.0, \"recall\": 0.6531049013137817, \"specificity\": 1.0, \"npv\": 0.9793793559074402, \"accuracy\": 0.9801499843597412, \"f1\": 0.7901554404145078, \"f2\": 0.7017947537965946, \"f0_5\": 0.9039715471250741, \"p4\": 0.8786955668275691, \"phi\": 0.7997734002795983}, {\"truth_threshold\": 26.07637261993636, \"match_probability\": 0.999999985867153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6529519557952881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3470480144023895, \"precision\": 1.0, \"recall\": 0.6529519557952881, \"specificity\": 1.0, \"npv\": 0.9793704748153687, \"accuracy\": 0.980141282081604, \"f1\": 0.7900434903303415, \"f2\": 0.7016534630682753, \"f0_5\": 0.903912933005844, \"p4\": 0.8786245484818261, \"phi\": 0.7996761213741597}, {\"truth_threshold\": 26.082365194791453, \"match_probability\": 0.9999999859257354, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4268.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2270.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6527990102767944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34720098972320557, \"precision\": 1.0, \"recall\": 0.6527990102767944, \"specificity\": 1.0, \"npv\": 0.9793615937232971, \"accuracy\": 0.980132520198822, \"f1\": 0.7899315195261891, \"f2\": 0.7015121630506246, \"f0_5\": 0.9038542990258365, \"p4\": 0.8785535091829714, \"phi\": 0.7995788324027157}, {\"truth_threshold\": 26.092083880098805, \"match_probability\": 0.9999999860202278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4267.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2271.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6526460647583008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3473539352416992, \"precision\": 1.0, \"recall\": 0.6526460647583008, \"specificity\": 1.0, \"npv\": 0.9793526530265808, \"accuracy\": 0.98012375831604, \"f1\": 0.7898195279962981, \"f2\": 0.7013708537427266, \"f0_5\": 0.9037956451749555, \"p4\": 0.8784824489211551, \"phi\": 0.7994814777015129}, {\"truth_threshold\": 26.09497601947209, \"match_probability\": 0.9999999860482246, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4265.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2273.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6523401737213135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3476598262786865, \"precision\": 1.0, \"recall\": 0.6523401737213135, \"specificity\": 1.0, \"npv\": 0.979334831237793, \"accuracy\": 0.9801062345504761, \"f1\": 0.789595482736277, \"f2\": 0.7010882072525233, \"f0_5\": 0.9036782778201542, \"p4\": 0.8783402654692086, \"phi\": 0.7992868493825377}, {\"truth_threshold\": 26.108024269394246, \"match_probability\": 0.9999999861738406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4263.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2275.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6520342826843262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3479657471179962, \"precision\": 1.0, \"recall\": 0.6520342826843262, \"specificity\": 1.0, \"npv\": 0.9793170690536499, \"accuracy\": 0.9800887703895569, \"f1\": 0.7893713545042126, \"f2\": 0.7008055235903338, \"f0_5\": 0.9035608308605341, \"p4\": 0.8781979980470662, \"phi\": 0.7990921807399088}, {\"truth_threshold\": 26.112055357307543, \"match_probability\": 0.9999999862124188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4261.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2277.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6517283320426941, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3482716381549835, \"precision\": 1.0, \"recall\": 0.6517283320426941, \"specificity\": 1.0, \"npv\": 0.9792992472648621, \"accuracy\": 0.9800712466239929, \"f1\": 0.789147143254005, \"f2\": 0.7005228027488245, \"f0_5\": 0.9034433042150793, \"p4\": 0.8780556465757082, \"phi\": 0.7988974160460772}, {\"truth_threshold\": 26.127879854043822, \"match_probability\": 0.9999999863628243, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4260.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2278.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6515753865242004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3484245836734772, \"precision\": 1.0, \"recall\": 0.6515753865242004, \"specificity\": 1.0, \"npv\": 0.9792903661727905, \"accuracy\": 0.9800624847412109, \"f1\": 0.789035006482682, \"f2\": 0.7003814283835328, \"f0_5\": 0.9033845109848163, \"p4\": 0.8779844392968528, \"phi\": 0.7988000463998096}, {\"truth_threshold\": 26.166700118423464, \"match_probability\": 0.9999999867248826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6514224410057068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3485775589942932, \"precision\": 1.0, \"recall\": 0.6514224410057068, \"specificity\": 1.0, \"npv\": 0.9792814254760742, \"accuracy\": 0.980053722858429, \"f1\": 0.7889228489395202, \"f2\": 0.7002400447206603, \"f0_5\": 0.9033256978026639, \"p4\": 0.8779132109760162, \"phi\": 0.7987026666539457}, {\"truth_threshold\": 26.17352687649972, \"match_probability\": 0.9999999867875513, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4258.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2280.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6512694954872131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34873050451278687, \"precision\": 1.0, \"recall\": 0.6512694954872131, \"specificity\": 1.0, \"npv\": 0.9792725443840027, \"accuracy\": 0.980044960975647, \"f1\": 0.7888106706187477, \"f2\": 0.7000986517592898, \"f0_5\": 0.9032668646584642, \"p4\": 0.8778419616032932, \"phi\": 0.7986052210881993}, {\"truth_threshold\": 26.202071084623608, \"match_probability\": 0.999999987046395, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4257.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2281.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6511165499687195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3488834500312805, \"precision\": 1.0, \"recall\": 0.6511165499687195, \"specificity\": 1.0, \"npv\": 0.9792636632919312, \"accuracy\": 0.9800362586975098, \"f1\": 0.78869847151459, \"f2\": 0.6999572494985037, \"f0_5\": 0.9032080115420521, \"p4\": 0.8777706911687722, \"phi\": 0.7985078211256216}, {\"truth_threshold\": 26.205164761699024, \"match_probability\": 0.9999999870741426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4256.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2282.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6509636044502258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34903639554977417, \"precision\": 1.0, \"recall\": 0.6509636044502258, \"specificity\": 1.0, \"npv\": 0.9792547225952148, \"accuracy\": 0.9800274968147278, \"f1\": 0.788586251621271, \"f2\": 0.6998158379373849, \"f0_5\": 0.9031491384432561, \"p4\": 0.8776993996625355, \"phi\": 0.7984104110522102}, {\"truth_threshold\": 26.23396124919682, \"match_probability\": 0.9999999873295875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4252.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2286.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6503517627716064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34964820742607117, \"precision\": 1.0, \"recall\": 0.6503517627716064, \"specificity\": 1.0, \"npv\": 0.9792191386222839, \"accuracy\": 0.9799924492835999, \"f1\": 0.7881371640407785, \"f2\": 0.6992500986712274, \"f0_5\": 0.9029134460205555, \"p4\": 0.877414022721859, \"phi\": 0.7980206138208848}, {\"truth_threshold\": 26.23455345222314, \"match_probability\": 0.9999999873347875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4251.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2287.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6501988172531128, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3498011529445648, \"precision\": 1.0, \"recall\": 0.6501988172531128, \"specificity\": 1.0, \"npv\": 0.9792101979255676, \"accuracy\": 0.9799837470054626, \"f1\": 0.7880248401149319, \"f2\": 0.6991086405946781, \"f0_5\": 0.9028544728570215, \"p4\": 0.8773426257080597, \"phi\": 0.7979231531307144}, {\"truth_threshold\": 26.235765495192634, \"match_probability\": 0.9999999873454233, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4250.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2288.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6500458717346191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34995412826538086, \"precision\": 1.0, \"recall\": 0.6500458717346191, \"specificity\": 1.0, \"npv\": 0.9792013168334961, \"accuracy\": 0.9799749851226807, \"f1\": 0.7879124953652206, \"f2\": 0.6989671732122886, \"f0_5\": 0.9027954796499278, \"p4\": 0.8772712075629072, \"phi\": 0.7978256823071779}, {\"truth_threshold\": 26.268249185535414, \"match_probability\": 0.9999999876271697, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4248.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2290.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6497399806976318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35026001930236816, \"precision\": 1.0, \"recall\": 0.6497399806976318, \"specificity\": 1.0, \"npv\": 0.9791834950447083, \"accuracy\": 0.9799574613571167, \"f1\": 0.7876877433710365, \"f2\": 0.6986842105263158, \"f0_5\": 0.9026774330641734, \"p4\": 0.8771283078386916, \"phi\": 0.7976306544654038}, {\"truth_threshold\": 26.268272836371644, \"match_probability\": 0.9999999876273725, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4245.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2293.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6492811441421509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3507188856601715, \"precision\": 1.0, \"recall\": 0.6492811441421509, \"specificity\": 1.0, \"npv\": 0.9791567921638489, \"accuracy\": 0.9799312353134155, \"f1\": 0.7873504590559214, \"f2\": 0.6982596966805935, \"f0_5\": 0.9025002126031125, \"p4\": 0.8769137995179822, \"phi\": 0.7973381202587335}, {\"truth_threshold\": 26.26884181219698, \"match_probability\": 0.9999999876322512, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4242.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2296.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6488222479820251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35117772221565247, \"precision\": 1.0, \"recall\": 0.6488222479820251, \"specificity\": 1.0, \"npv\": 0.9791300892829895, \"accuracy\": 0.9799049496650696, \"f1\": 0.787012987012987, \"f2\": 0.6978350990327038, \"f0_5\": 0.9023228111971412, \"p4\": 0.8766991004762974, \"phi\": 0.7970454388307819}, {\"truth_threshold\": 26.28851741586445, \"match_probability\": 0.9999999877997786, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4241.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2297.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6486693024635315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3513306677341461, \"precision\": 1.0, \"recall\": 0.6486693024635315, \"specificity\": 1.0, \"npv\": 0.979121208190918, \"accuracy\": 0.9798961877822876, \"f1\": 0.786900454587624, \"f2\": 0.6976935478564144, \"f0_5\": 0.9022636371372649, \"p4\": 0.8766274916999535, \"phi\": 0.7969478766247048}, {\"truth_threshold\": 26.289004093919655, \"match_probability\": 0.9999999878038935, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4240.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2298.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6485163569450378, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35148364305496216, \"precision\": 1.0, \"recall\": 0.6485163569450378, \"specificity\": 1.0, \"npv\": 0.9791123270988464, \"accuracy\": 0.9798874258995056, \"f1\": 0.786787901280386, \"f2\": 0.697551987365096, \"f0_5\": 0.9022044429313133, \"p4\": 0.8765558616923605, \"phi\": 0.7968503042475288}, {\"truth_threshold\": 26.307192323343216, \"match_probability\": 0.9999999879566862, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4239.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2299.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6483634114265442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3516365885734558, \"precision\": 1.0, \"recall\": 0.6483634114265442, \"specificity\": 1.0, \"npv\": 0.9791034460067749, \"accuracy\": 0.9798787236213684, \"f1\": 0.7866753270854597, \"f2\": 0.6974104175578296, \"f0_5\": 0.9021452285689964, \"p4\": 0.8764842104434943, \"phi\": 0.7967526658590209}, {\"truth_threshold\": 26.33223879329377, \"match_probability\": 0.9999999881639643, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4236.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2302.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6479045748710632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35209545493125916, \"precision\": 1.0, \"recall\": 0.6479045748710632, \"specificity\": 1.0, \"npv\": 0.9790767431259155, \"accuracy\": 0.9798524379730225, \"f1\": 0.7863374791163913, \"f2\": 0.6969856522311438, \"f0_5\": 0.9019674644408483, \"p4\": 0.8762691291489205, \"phi\": 0.7964598570966458}, {\"truth_threshold\": 26.371058675228042, \"match_probability\": 0.9999999884782004, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4235.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2303.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6477516293525696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3522484004497528, \"precision\": 1.0, \"recall\": 0.6477516293525696, \"specificity\": 1.0, \"npv\": 0.9790678024291992, \"accuracy\": 0.9798436760902405, \"f1\": 0.7862248213125406, \"f2\": 0.6968440451508869, \"f0_5\": 0.9019081693500298, \"p4\": 0.8761973928345937, \"phi\": 0.7963621779390186}, {\"truth_threshold\": 26.371483037758743, \"match_probability\": 0.999999988481589, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4233.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2305.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6474456787109375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3525542914867401, \"precision\": 1.0, \"recall\": 0.6474456787109375, \"specificity\": 1.0, \"npv\": 0.9790500402450562, \"accuracy\": 0.9798261523246765, \"f1\": 0.7859994429486584, \"f2\": 0.6965608030278098, \"f0_5\": 0.9017895185342991, \"p4\": 0.8760538563214122, \"phi\": 0.7961669007493325}, {\"truth_threshold\": 26.4000354063084, \"match_probability\": 0.9999999887073089, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4232.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2306.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6472927331924438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35270723700523376, \"precision\": 1.0, \"recall\": 0.6472927331924438, \"specificity\": 1.0, \"npv\": 0.9790410995483398, \"accuracy\": 0.9798174500465393, \"f1\": 0.7858867223769731, \"f2\": 0.6964191679831491, \"f0_5\": 0.9017301627887155, \"p4\": 0.875982056102427, \"phi\": 0.7960692468542192}, {\"truth_threshold\": 26.40924913152829, \"match_probability\": 0.9999999887791994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4230.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2308.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6469868421554565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35301315784454346, \"precision\": 1.0, \"recall\": 0.6469868421554565, \"specificity\": 1.0, \"npv\": 0.9790233373641968, \"accuracy\": 0.9797999262809753, \"f1\": 0.7856612184249628, \"f2\": 0.6961358699229807, \"f0_5\": 0.9016113905703811, \"p4\": 0.8758383916892938, \"phi\": 0.7958738525509056}, {\"truth_threshold\": 26.410532900124004, \"match_probability\": 0.9999999887891797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4229.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2309.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6468338966369629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3531661033630371, \"precision\": 1.0, \"recall\": 0.6468338966369629, \"specificity\": 1.0, \"npv\": 0.9790144562721252, \"accuracy\": 0.9797911643981934, \"f1\": 0.7855484350329711, \"f2\": 0.6959942069056319, \"f0_5\": 0.9015519740769166, \"p4\": 0.8757665274749773, \"phi\": 0.7957761680222691}, {\"truth_threshold\": 26.420421631827477, \"match_probability\": 0.9999999888657598, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4227.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2311.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6465280055999756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3534720242023468, \"precision\": 1.0, \"recall\": 0.6465280055999756, \"specificity\": 1.0, \"npv\": 0.9789966344833374, \"accuracy\": 0.9797736406326294, \"f1\": 0.785322805387831, \"f2\": 0.6957108528918002, \"f0_5\": 0.9014330802695556, \"p4\": 0.8756227349803758, \"phi\": 0.7955807683111575}, {\"truth_threshold\": 26.461786504699866, \"match_probability\": 0.999999989180467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4223.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2315.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6459161639213562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3540838062763214, \"precision\": 1.0, \"recall\": 0.6459161639213562, \"specificity\": 1.0, \"npv\": 0.9789610505104065, \"accuracy\": 0.9797386527061462, \"f1\": 0.7848712944893598, \"f2\": 0.6951440329218107, \"f0_5\": 0.901195049082373, \"p4\": 0.8753348934442717, \"phi\": 0.7951897902287046}, {\"truth_threshold\": 26.46348871942636, \"match_probability\": 0.9999999891932252, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4222.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2316.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6457632184028625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35423678159713745, \"precision\": 1.0, \"recall\": 0.6457632184028625, \"specificity\": 1.0, \"npv\": 0.978952169418335, \"accuracy\": 0.9797298908233643, \"f1\": 0.7847583643122676, \"f2\": 0.6950023046026207, \"f0_5\": 0.9011354904806625, \"p4\": 0.8752628795539364, \"phi\": 0.7950920340968354}, {\"truth_threshold\": 26.46599688970399, \"match_probability\": 0.9999999892119968, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4219.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2319.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6453043818473816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3546956181526184, \"precision\": 1.0, \"recall\": 0.6453043818473816, \"specificity\": 1.0, \"npv\": 0.9789254665374756, \"accuracy\": 0.9797036647796631, \"f1\": 0.7844194478014316, \"f2\": 0.6945770636462415, \"f0_5\": 0.9009566925770907, \"p4\": 0.8750467093055992, \"phi\": 0.7947986482619004}, {\"truth_threshold\": 26.466115649763886, \"match_probability\": 0.9999999892128848, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4218.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2320.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6451514363288879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35484856367111206, \"precision\": 1.0, \"recall\": 0.6451514363288879, \"specificity\": 1.0, \"npv\": 0.978916585445404, \"accuracy\": 0.9796949028968811, \"f1\": 0.7843064336184455, \"f2\": 0.6944352979914389, \"f0_5\": 0.9008970525416489, \"p4\": 0.8749746096632058, \"phi\": 0.794700851127033}, {\"truth_threshold\": 26.470206580696168, \"match_probability\": 0.9999999892434296, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4215.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2323.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6446925401687622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3553074300289154, \"precision\": 1.0, \"recall\": 0.6446925401687622, \"specificity\": 1.0, \"npv\": 0.9788898825645447, \"accuracy\": 0.9796686172485352, \"f1\": 0.7839672649493165, \"f2\": 0.6940099450060921, \"f0_5\": 0.9007180100863321, \"p4\": 0.8747581819148863, \"phi\": 0.794407342165567}, {\"truth_threshold\": 26.486935793599606, \"match_probability\": 0.9999999893674404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4214.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2324.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6445395946502686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35546037554740906, \"precision\": 1.0, \"recall\": 0.6445395946502686, \"specificity\": 1.0, \"npv\": 0.9788810014724731, \"accuracy\": 0.979659914970398, \"f1\": 0.7838541666666666, \"f2\": 0.6938681420009221, \"f0_5\": 0.9006582884500299, \"p4\": 0.8746859963578106, \"phi\": 0.7943095039663245}, {\"truth_threshold\": 26.490366636605927, \"match_probability\": 0.9999999893926954, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4213.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2325.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6443866491317749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3556133508682251, \"precision\": 1.0, \"recall\": 0.6443866491317749, \"specificity\": 1.0, \"npv\": 0.9788720607757568, \"accuracy\": 0.979651153087616, \"f1\": 0.7837410473444331, \"f2\": 0.6937263296558538, \"f0_5\": 0.900598546387345, \"p4\": 0.8746137892966063, \"phi\": 0.7942116554929786}, {\"truth_threshold\": 26.49311449169694, \"match_probability\": 0.9999999894128795, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4211.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2327.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6440807580947876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3559192419052124, \"precision\": 1.0, \"recall\": 0.6440807580947876, \"specificity\": 1.0, \"npv\": 0.9788542985916138, \"accuracy\": 0.979633629322052, \"f1\": 0.7835147455577263, \"f2\": 0.6934426769423311, \"f0_5\": 0.9004790009408947, \"p4\": 0.8744693106210204, \"phi\": 0.7940158716939409}, {\"truth_threshold\": 26.50810827749781, \"match_probability\": 0.9999999895223406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4210.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2328.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.643927812576294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35607218742370605, \"precision\": 1.0, \"recall\": 0.643927812576294, \"specificity\": 1.0, \"npv\": 0.9788454174995422, \"accuracy\": 0.97962486743927, \"f1\": 0.7834015630815035, \"f2\": 0.6933008365720308, \"f0_5\": 0.9004191975361451, \"p4\": 0.8743970389862273, \"phi\": 0.7939179923688005}, {\"truth_threshold\": 26.527092856586385, \"match_probability\": 0.999999989659314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4208.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2330.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6436219215393066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35637810826301575, \"precision\": 1.0, \"recall\": 0.6436219215393066, \"specificity\": 1.0, \"npv\": 0.9788275957107544, \"accuracy\": 0.9796074032783508, \"f1\": 0.7831751349339289, \"f2\": 0.6930171277997365, \"f0_5\": 0.9002995293110826, \"p4\": 0.8742524310715637, \"phi\": 0.7937221468123012}, {\"truth_threshold\": 26.55203849975345, \"match_probability\": 0.9999999898365779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4203.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2335.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6428571343421936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3571428656578064, \"precision\": 1.0, \"recall\": 0.6428571343421936, \"specificity\": 1.0, \"npv\": 0.978783130645752, \"accuracy\": 0.9795635938644409, \"f1\": 0.782608695652174, \"f2\": 0.6923076923076923, \"f0_5\": 0.9, \"p4\": 0.8738905337111442, \"phi\": 0.7932324366388247}, {\"truth_threshold\": 26.55994624012194, \"match_probability\": 0.9999999898921336, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4201.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2337.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6425512433052063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3574487566947937, \"precision\": 1.0, \"recall\": 0.6425512433052063, \"specificity\": 1.0, \"npv\": 0.9787653684616089, \"accuracy\": 0.9795461297035217, \"f1\": 0.7823819722506751, \"f2\": 0.6920238526669522, \"f0_5\": 0.8998800445548796, \"p4\": 0.8737456235222686, \"phi\": 0.793036502794218}, {\"truth_threshold\": 26.578979399461634, \"match_probability\": 0.9999999900246087, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4200.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2338.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6423982977867126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35760170221328735, \"precision\": 1.0, \"recall\": 0.6423982977867126, \"specificity\": 1.0, \"npv\": 0.9787564873695374, \"accuracy\": 0.9795373678207397, \"f1\": 0.7822685788787483, \"f2\": 0.6918819188191881, \"f0_5\": 0.8998200359928015, \"p4\": 0.8736731359771946, \"phi\": 0.7929385203874136}, {\"truth_threshold\": 26.60878141631559, \"match_probability\": 0.9999999902285583, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4198.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2340.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6420924067497253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35790762305259705, \"precision\": 1.0, \"recall\": 0.6420924067497253, \"specificity\": 1.0, \"npv\": 0.9787386655807495, \"accuracy\": 0.9795198440551758, \"f1\": 0.7820417287630402, \"f2\": 0.6915980230642504, \"f0_5\": 0.8996999571367338, \"p4\": 0.8735280959343731, \"phi\": 0.792742468487423}, {\"truth_threshold\": 26.611405439353224, \"match_probability\": 0.9999999902463149, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4197.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2341.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6419394016265869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3580605685710907, \"precision\": 1.0, \"recall\": 0.6419394016265869, \"specificity\": 1.0, \"npv\": 0.978729784488678, \"accuracy\": 0.9795110821723938, \"f1\": 0.7819282720074523, \"f2\": 0.6914560611552275, \"f0_5\": 0.8996398868215725, \"p4\": 0.8734555434160455, \"phi\": 0.7926444550780476}, {\"truth_threshold\": 26.617422789686294, \"match_probability\": 0.9999999902869119, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4196.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2342.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6417864561080933, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35821351408958435, \"precision\": 1.0, \"recall\": 0.6417864561080933, \"specificity\": 1.0, \"npv\": 0.9787209033966064, \"accuracy\": 0.9795023202896118, \"f1\": 0.7818147941121669, \"f2\": 0.6913140898906024, \"f0_5\": 0.8995797959008661, \"p4\": 0.8733829692193759, \"phi\": 0.7925464313288588}, {\"truth_threshold\": 26.636328094745867, \"match_probability\": 0.9999999904133634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4195.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2343.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6416335105895996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.358366459608078, \"precision\": 1.0, \"recall\": 0.6416335105895996, \"specificity\": 1.0, \"npv\": 0.9787120223045349, \"accuracy\": 0.9794936180114746, \"f1\": 0.7817012950712755, \"f2\": 0.69117210926945, \"f0_5\": 0.8995196843640106, \"p4\": 0.8733103733340579, \"phi\": 0.7924483972359709}, {\"truth_threshold\": 26.646273590016424, \"match_probability\": 0.9999999904792235, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4194.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2344.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.641480565071106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35851943492889404, \"precision\": 1.0, \"recall\": 0.641480565071106, \"specificity\": 1.0, \"npv\": 0.9787030816078186, \"accuracy\": 0.9794848561286926, \"f1\": 0.781587774878867, \"f2\": 0.6910301192908456, \"f0_5\": 0.8994595522003946, \"p4\": 0.8732377557497789, \"phi\": 0.7923502966717725}, {\"truth_threshold\": 26.64628478005436, \"match_probability\": 0.9999999904792973, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4191.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2347.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.641021728515625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.358978271484375, \"precision\": 1.0, \"recall\": 0.641021728515625, \"specificity\": 1.0, \"npv\": 0.978676438331604, \"accuracy\": 0.9794585704803467, \"f1\": 0.7812470873333954, \"f2\": 0.6906040932010677, \"f0_5\": 0.8992790318427603, \"p4\": 0.8730197726999487, \"phi\": 0.792056101206594}, {\"truth_threshold\": 26.6579156052419, \"match_probability\": 0.9999999905557434, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4190.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2348.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6408687829971313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35913124680519104, \"precision\": 1.0, \"recall\": 0.6408687829971313, \"specificity\": 1.0, \"npv\": 0.9786675572395325, \"accuracy\": 0.9794498085975647, \"f1\": 0.7811334824757643, \"f2\": 0.6904620657834025, \"f0_5\": 0.8992188170658426, \"p4\": 0.8729470682165661, \"phi\": 0.7919580153304014}, {\"truth_threshold\": 26.66931285478463, \"match_probability\": 0.9999999906300588, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4187.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2351.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6404098868370056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.359590083360672, \"precision\": 1.0, \"recall\": 0.6404098868370056, \"specificity\": 1.0, \"npv\": 0.9786408543586731, \"accuracy\": 0.9794235825538635, \"f1\": 0.7807925407925408, \"f2\": 0.6900359273542306, \"f0_5\": 0.8990380486129005, \"p4\": 0.872728824221264, \"phi\": 0.7916636393149981}, {\"truth_threshold\": 26.669463988963585, \"match_probability\": 0.9999999906310404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4186.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2352.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.640256941318512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35974302887916565, \"precision\": 1.0, \"recall\": 0.640256941318512, \"specificity\": 1.0, \"npv\": 0.9786319732666016, \"accuracy\": 0.9794148206710815, \"f1\": 0.7806788511749347, \"f2\": 0.689893862482695, \"f0_5\": 0.8989777510523151, \"p4\": 0.8726560326732495, \"phi\": 0.791565511940676}, {\"truth_threshold\": 26.67827264102204, \"match_probability\": 0.9999999906880701, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4184.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2354.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6399510502815247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36004894971847534, \"precision\": 1.0, \"recall\": 0.6399510502815247, \"specificity\": 1.0, \"npv\": 0.9786142110824585, \"accuracy\": 0.9793972969055176, \"f1\": 0.7804514083193435, \"f2\": 0.6896097046413502, \"f0_5\": 0.8988570937526854, \"p4\": 0.8725103841906293, \"phi\": 0.7913691698518565}, {\"truth_threshold\": 26.692986770115404, \"match_probability\": 0.9999999907825603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4183.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2355.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.639798104763031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.360201895236969, \"precision\": 1.0, \"recall\": 0.639798104763031, \"specificity\": 1.0, \"npv\": 0.978605329990387, \"accuracy\": 0.9793885946273804, \"f1\": 0.7803376550694898, \"f2\": 0.6894676116696885, \"f0_5\": 0.8987967339922647, \"p4\": 0.8724375272352601, \"phi\": 0.791271011311274}, {\"truth_threshold\": 26.711457758776564, \"match_probability\": 0.99999999089982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4182.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2356.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6396451592445374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36035484075546265, \"precision\": 1.0, \"recall\": 0.6396451592445374, \"specificity\": 1.0, \"npv\": 0.9785963892936707, \"accuracy\": 0.9793798327445984, \"f1\": 0.780223880597015, \"f2\": 0.6893255093294652, \"f0_5\": 0.898736353477177, \"p4\": 0.8723646484566651, \"phi\": 0.7911728423762604}, {\"truth_threshold\": 26.732782115731837, \"match_probability\": 0.9999999910333398, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4179.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2359.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6391863226890564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.360813707113266, \"precision\": 1.0, \"recall\": 0.6391863226890564, \"specificity\": 1.0, \"npv\": 0.978569746017456, \"accuracy\": 0.9793535470962524, \"f1\": 0.7798824297844547, \"f2\": 0.6888991460881606, \"f0_5\": 0.8985550872968091, \"p4\": 0.8721458810775106, \"phi\": 0.7908782169449111}, {\"truth_threshold\": 26.737556347342377, \"match_probability\": 0.9999999910629637, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4178.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2360.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.639033317565918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36096665263175964, \"precision\": 1.0, \"recall\": 0.639033317565918, \"specificity\": 1.0, \"npv\": 0.9785608649253845, \"accuracy\": 0.9793447852134705, \"f1\": 0.7797685703620754, \"f2\": 0.6887570062644247, \"f0_5\": 0.8984946236559139, \"p4\": 0.8720729149019647, \"phi\": 0.7907800063864939}, {\"truth_threshold\": 26.749221726660256, \"match_probability\": 0.9999999911349355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4176.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2362.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6387274265289307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36127257347106934, \"precision\": 1.0, \"recall\": 0.6387274265289307, \"specificity\": 1.0, \"npv\": 0.9785430431365967, \"accuracy\": 0.9793273210525513, \"f1\": 0.7795407877543401, \"f2\": 0.6884726984964389, \"f0_5\": 0.8983736339385595, \"p4\": 0.8719269169145942, \"phi\": 0.7905835540235836}, {\"truth_threshold\": 26.7874544519105, \"match_probability\": 0.9999999913667822, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4175.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2363.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.638574481010437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.361425518989563, \"precision\": 1.0, \"recall\": 0.638574481010437, \"specificity\": 1.0, \"npv\": 0.9785341620445251, \"accuracy\": 0.9793185591697693, \"f1\": 0.7794268645570802, \"f2\": 0.6883305305503347, \"f0_5\": 0.8983131078406059, \"p4\": 0.8718538850819005, \"phi\": 0.790485255964797}, {\"truth_threshold\": 26.788152392368918, \"match_probability\": 0.9999999913709577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4174.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2364.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6384215354919434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36157846450805664, \"precision\": 1.0, \"recall\": 0.6384215354919434, \"specificity\": 1.0, \"npv\": 0.9785252809524536, \"accuracy\": 0.9793097972869873, \"f1\": 0.7793129200896192, \"f2\": 0.688188353228253, \"f0_5\": 0.8982525609021262, \"p4\": 0.871780831342611, \"phi\": 0.7903870037201133}, {\"truth_threshold\": 26.79012726242018, \"match_probability\": 0.9999999913827617, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4173.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2365.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6382685899734497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3617314100265503, \"precision\": 1.0, \"recall\": 0.6382685899734497, \"specificity\": 1.0, \"npv\": 0.9785163998603821, \"accuracy\": 0.9793010354042053, \"f1\": 0.7791989543459994, \"f2\": 0.6880461665292663, \"f0_5\": 0.8981919931123548, \"p4\": 0.8717077556862742, \"phi\": 0.7902887410456438}, {\"truth_threshold\": 26.79214060558032, \"match_probability\": 0.999999991394779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4172.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2366.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.638115644454956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36188435554504395, \"precision\": 1.0, \"recall\": 0.638115644454956, \"specificity\": 1.0, \"npv\": 0.9785075187683105, \"accuracy\": 0.9792922735214233, \"f1\": 0.7790849673202614, \"f2\": 0.6879039704524469, \"f0_5\": 0.8981314044605184, \"p4\": 0.8716346581024328, \"phi\": 0.7901904679374488}, {\"truth_threshold\": 26.79596408263954, \"match_probability\": 0.9999999914175547, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4171.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2367.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6379626989364624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36203733086586, \"precision\": 1.0, \"recall\": 0.6379626989364624, \"specificity\": 1.0, \"npv\": 0.978498637676239, \"accuracy\": 0.9792835712432861, \"f1\": 0.7789709590064432, \"f2\": 0.687761764996867, \"f0_5\": 0.8980707949358367, \"p4\": 0.8715615385806221, \"phi\": 0.7900921281192147}, {\"truth_threshold\": 26.815042586584305, \"match_probability\": 0.9999999915303036, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4170.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2368.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6378097534179688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36219027638435364, \"precision\": 1.0, \"recall\": 0.6378097534179688, \"specificity\": 1.0, \"npv\": 0.9784897565841675, \"accuracy\": 0.9792748093605042, \"f1\": 0.7788569293985805, \"f2\": 0.6876195501615988, \"f0_5\": 0.8980101645275218, \"p4\": 0.8714883971103714, \"phi\": 0.7899938341252497}, {\"truth_threshold\": 26.81534096331088, \"match_probability\": 0.9999999915320551, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4169.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2369.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6376567482948303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3623432219028473, \"precision\": 1.0, \"recall\": 0.6376567482948303, \"specificity\": 1.0, \"npv\": 0.978480875492096, \"accuracy\": 0.9792660474777222, \"f1\": 0.778742878490707, \"f2\": 0.6874773259457142, \"f0_5\": 0.8979495132247781, \"p4\": 0.8714152336812029, \"phi\": 0.7898955296857241}, {\"truth_threshold\": 26.81959589024284, \"match_probability\": 0.9999999915569927, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4168.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2370.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6375038027763367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36249616742134094, \"precision\": 1.0, \"recall\": 0.6375038027763367, \"specificity\": 1.0, \"npv\": 0.9784719347953796, \"accuracy\": 0.9792572855949402, \"f1\": 0.778628806276854, \"f2\": 0.6873350923482849, \"f0_5\": 0.8978888410168031, \"p4\": 0.8713420482826322, \"phi\": 0.7897972147966886}, {\"truth_threshold\": 26.828995542282772, \"match_probability\": 0.9999999916118231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4166.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2372.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6371979117393494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36280208826065063, \"precision\": 1.0, \"recall\": 0.6371979117393494, \"specificity\": 1.0, \"npv\": 0.9784541726112366, \"accuracy\": 0.9792397618293762, \"f1\": 0.7784005979073244, \"f2\": 0.6870505970050795, \"f0_5\": 0.8977674338419102, \"p4\": 0.8711956115353137, \"phi\": 0.789600497349428}, {\"truth_threshold\": 26.836321954156453, \"match_probability\": 0.9999999916543125, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4163.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2375.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6367390751838684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3632609248161316, \"precision\": 1.0, \"recall\": 0.6367390751838684, \"specificity\": 1.0, \"npv\": 0.978427529335022, \"accuracy\": 0.979213535785675, \"f1\": 0.7780581254088403, \"f2\": 0.6866237836054758, \"f0_5\": 0.8975851660198362, \"p4\": 0.870975791381328, \"phi\": 0.7893054271461115}, {\"truth_threshold\": 26.869809001604093, \"match_probability\": 0.9999999918457971, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6364331841468811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3635668456554413, \"precision\": 1.0, \"recall\": 0.6364331841468811, \"specificity\": 1.0, \"npv\": 0.9784097671508789, \"accuracy\": 0.9791960120201111, \"f1\": 0.7778297037106272, \"f2\": 0.6863391944050408, \"f0_5\": 0.8974635493054957, \"p4\": 0.870829134467292, \"phi\": 0.78910860498016}, {\"truth_threshold\": 26.883614801129124, \"match_probability\": 0.9999999919234562, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4160.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2378.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6362801790237427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36371979117393494, \"precision\": 1.0, \"recall\": 0.6362801790237427, \"specificity\": 1.0, \"npv\": 0.9784008860588074, \"accuracy\": 0.9791872501373291, \"f1\": 0.7777154608338007, \"f2\": 0.6861968857218264, \"f0_5\": 0.8974027094658729, \"p4\": 0.8707557729352671, \"phi\": 0.7890102063395632}, {\"truth_threshold\": 26.885980995139597, \"match_probability\": 0.9999999919366919, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4159.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2379.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.636127233505249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3638727366924286, \"precision\": 1.0, \"recall\": 0.636127233505249, \"specificity\": 1.0, \"npv\": 0.9783920049667358, \"accuracy\": 0.9791785478591919, \"f1\": 0.7776011965971767, \"f2\": 0.6860545676487084, \"f0_5\": 0.8973418486234573, \"p4\": 0.8706823893391803, \"phi\": 0.7889117972138026}, {\"truth_threshold\": 26.890738248637916, \"match_probability\": 0.9999999919632367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4156.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2382.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6356683969497681, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36433160305023193, \"precision\": 1.0, \"recall\": 0.6356683969497681, \"specificity\": 1.0, \"npv\": 0.9783653020858765, \"accuracy\": 0.979152262210846, \"f1\": 0.7772582756685992, \"f2\": 0.6856275570806388, \"f0_5\": 0.8971591399706416, \"p4\": 0.870462106061003, \"phi\": 0.7886164505158065}, {\"truth_threshold\": 26.89446236971989, \"match_probability\": 0.9999999919839557, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4155.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2383.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6355154514312744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3644845485687256, \"precision\": 1.0, \"recall\": 0.6355154514312744, \"specificity\": 1.0, \"npv\": 0.9783564209938049, \"accuracy\": 0.979143500328064, \"f1\": 0.7771439259328533, \"f2\": 0.6854852014386116, \"f0_5\": 0.8970981950082045, \"p4\": 0.8703886341030894, \"phi\": 0.7885179994031104}, {\"truth_threshold\": 26.91360411806599, \"match_probability\": 0.9999999920896105, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4154.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2384.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6353625059127808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36463749408721924, \"precision\": 1.0, \"recall\": 0.6353625059127808, \"specificity\": 1.0, \"npv\": 0.9783475399017334, \"accuracy\": 0.979134738445282, \"f1\": 0.7770295548073326, \"f2\": 0.6853428364020326, \"f0_5\": 0.8970372289885117, \"p4\": 0.8703151400282904, \"phi\": 0.7884195377853596}, {\"truth_threshold\": 26.93739677977978, \"match_probability\": 0.9999999922189974, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4152.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2386.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6350566148757935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36494341492652893, \"precision\": 1.0, \"recall\": 0.6350566148757935, \"specificity\": 1.0, \"npv\": 0.9783297777175903, \"accuracy\": 0.9791172742843628, \"f1\": 0.776800748362956, \"f2\": 0.6850580781414994, \"f0_5\": 0.8969152337336905, \"p4\": 0.87016808548569, \"phi\": 0.7882225266226375}, {\"truth_threshold\": 26.938105277811175, \"match_probability\": 0.9999999922228177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4151.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2387.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6349036693572998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3650963604450226, \"precision\": 1.0, \"recall\": 0.6349036693572998, \"specificity\": 1.0, \"npv\": 0.9783208966255188, \"accuracy\": 0.9791085124015808, \"f1\": 0.776686313032089, \"f2\": 0.6849156849156849, \"f0_5\": 0.896854204476709, \"p4\": 0.8700945249966987, \"phi\": 0.7881240334592654}, {\"truth_threshold\": 26.94213035586523, \"match_probability\": 0.9999999922444855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4150.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2388.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6347506642341614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36524930596351624, \"precision\": 1.0, \"recall\": 0.6347506642341614, \"specificity\": 1.0, \"npv\": 0.9783120155334473, \"accuracy\": 0.9790997505187988, \"f1\": 0.7765718562874252, \"f2\": 0.684773282291598, \"f0_5\": 0.8967931541187657, \"p4\": 0.8700209423484419, \"phi\": 0.7880255297748815}, {\"truth_threshold\": 26.942464314723768, \"match_probability\": 0.9999999922462806, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4146.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2392.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6341388821601868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36586111783981323, \"precision\": 1.0, \"recall\": 0.6341388821601868, \"specificity\": 1.0, \"npv\": 0.9782764911651611, \"accuracy\": 0.9790647625923157, \"f1\": 0.7761138150505429, \"f2\": 0.6842035777939138, \"f0_5\": 0.8965487414583514, \"p4\": 0.8697263899504202, \"phi\": 0.7876313533119303}, {\"truth_threshold\": 26.956021175949196, \"match_probability\": 0.9999999923188002, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4145.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2393.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6339859366416931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3660140633583069, \"precision\": 1.0, \"recall\": 0.6339859366416931, \"specificity\": 1.0, \"npv\": 0.9782676100730896, \"accuracy\": 0.9790560007095337, \"f1\": 0.7759992511466817, \"f2\": 0.6840611281645047, \"f0_5\": 0.8964875854312657, \"p4\": 0.8696526963465218, \"phi\": 0.7875327969559681}, {\"truth_threshold\": 26.95977531876513, \"match_probability\": 0.9999999923387621, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4144.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2394.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6338329911231995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36616700887680054, \"precision\": 1.0, \"recall\": 0.6338329911231995, \"specificity\": 1.0, \"npv\": 0.9782586693763733, \"accuracy\": 0.9790472388267517, \"f1\": 0.7758846657929227, \"f2\": 0.6839186691312384, \"f0_5\": 0.8964264082374318, \"p4\": 0.8695789805195847, \"phi\": 0.7874341736065152}, {\"truth_threshold\": 26.972185325919448, \"match_probability\": 0.9999999924043811, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4143.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2395.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6336800456047058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3663199841976166, \"precision\": 1.0, \"recall\": 0.6336800456047058, \"specificity\": 1.0, \"npv\": 0.9782497882843018, \"accuracy\": 0.9790384769439697, \"f1\": 0.7757700589832413, \"f2\": 0.6837762006931837, \"f0_5\": 0.8963652098658589, \"p4\": 0.8695052424589563, \"phi\": 0.7873355961499513}, {\"truth_threshold\": 26.976926286376056, \"match_probability\": 0.9999999924293007, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4141.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2397.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6333740949630737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3666258752346039, \"precision\": 1.0, \"recall\": 0.6333740949630737, \"specificity\": 1.0, \"npv\": 0.9782320261001587, \"accuracy\": 0.9790209531784058, \"f1\": 0.7755407809720011, \"f2\": 0.6834912355989833, \"f0_5\": 0.8962427495454939, \"p4\": 0.8693576995939812, \"phi\": 0.787138409573684}, {\"truth_threshold\": 26.98081070717968, \"match_probability\": 0.9999999924496572, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4140.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2398.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6332211494445801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36677882075309753, \"precision\": 1.0, \"recall\": 0.6332211494445801, \"specificity\": 1.0, \"npv\": 0.9782231450080872, \"accuracy\": 0.9790122509002686, \"f1\": 0.7754261097583817, \"f2\": 0.6833487389409745, \"f0_5\": 0.8961814875746817, \"p4\": 0.8692838947682952, \"phi\": 0.7870398004459503}, {\"truth_threshold\": 26.984344853568345, \"match_probability\": 0.9999999924681305, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4138.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2400.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6329152584075928, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3670847415924072, \"precision\": 1.0, \"recall\": 0.6329152584075928, \"specificity\": 1.0, \"npv\": 0.9782053828239441, \"accuracy\": 0.9789947271347046, \"f1\": 0.7751967028849757, \"f2\": 0.6830637173984814, \"f0_5\": 0.8960588999566912, \"p4\": 0.8691362182771268, \"phi\": 0.7868424940033452}, {\"truth_threshold\": 27.02168594487773, \"match_probability\": 0.9999999926605757, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4137.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2401.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6327623128890991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3672376871109009, \"precision\": 1.0, \"recall\": 0.6327623128890991, \"specificity\": 1.0, \"npv\": 0.9781965017318726, \"accuracy\": 0.9789859652519226, \"f1\": 0.7750819672131147, \"f2\": 0.6829211925121331, \"f0_5\": 0.895997574287447, \"p4\": 0.8690623465902643, \"phi\": 0.7867438531617014}, {\"truth_threshold\": 27.040378935010125, \"match_probability\": 0.9999999927550591, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4136.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2402.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6326093673706055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36739063262939453, \"precision\": 1.0, \"recall\": 0.6326093673706055, \"specificity\": 1.0, \"npv\": 0.978187620639801, \"accuracy\": 0.9789772033691406, \"f1\": 0.7749672100430953, \"f2\": 0.6827786582144744, \"f0_5\": 0.8959362273633134, \"p4\": 0.8689884525949514, \"phi\": 0.7866452017428924}, {\"truth_threshold\": 27.060095802189785, \"match_probability\": 0.9999999928534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4135.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2403.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6324564218521118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3675435781478882, \"precision\": 1.0, \"recall\": 0.6324564218521118, \"specificity\": 1.0, \"npv\": 0.9781787395477295, \"accuracy\": 0.9789684414863586, \"f1\": 0.7748524313688747, \"f2\": 0.682636114504573, \"f0_5\": 0.8958748591732386, \"p4\": 0.8689145362804808, \"phi\": 0.7865465397428899}, {\"truth_threshold\": 27.06685135306275, \"match_probability\": 0.9999999928867864, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4134.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2404.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6323034763336182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3676965534687042, \"precision\": 1.0, \"recall\": 0.6323034763336182, \"specificity\": 1.0, \"npv\": 0.978169858455658, \"accuracy\": 0.9789597392082214, \"f1\": 0.7747376311844077, \"f2\": 0.6824935613814964, \"f0_5\": 0.8958134697061628, \"p4\": 0.8688405976361385, \"phi\": 0.7864478106435241}, {\"truth_threshold\": 27.068652634817106, \"match_probability\": 0.9999999928956621, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4133.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2405.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6321505308151245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3678494989871979, \"precision\": 1.0, \"recall\": 0.6321505308151245, \"specificity\": 1.0, \"npv\": 0.9781609773635864, \"accuracy\": 0.9789509773254395, \"f1\": 0.7746228094836473, \"f2\": 0.6823509988443124, \"f0_5\": 0.8957520589510186, \"p4\": 0.8687666366512037, \"phi\": 0.7863491274624583}, {\"truth_threshold\": 27.07810012039709, \"match_probability\": 0.9999999929420328, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4132.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2406.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6319975256919861, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36800244450569153, \"precision\": 1.0, \"recall\": 0.6319975256919861, \"specificity\": 1.0, \"npv\": 0.9781520962715149, \"accuracy\": 0.9789422154426575, \"f1\": 0.7745079662605436, \"f2\": 0.6822084268920883, \"f0_5\": 0.8956906268967311, \"p4\": 0.8686926533149485, \"phi\": 0.7862504336880957}, {\"truth_threshold\": 27.108024269394246, \"match_probability\": 0.9999999930869202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4130.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2408.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6316916346549988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3683083653450012, \"precision\": 1.0, \"recall\": 0.6316916346549988, \"specificity\": 1.0, \"npv\": 0.9781343340873718, \"accuracy\": 0.9789246916770935, \"f1\": 0.7742782152230971, \"f2\": 0.6819232547387887, \"f0_5\": 0.8955676988463873, \"p4\": 0.8685446195455321, \"phi\": 0.7860529578028508}, {\"truth_threshold\": 27.133762966958646, \"match_probability\": 0.9999999932091608, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4128.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2410.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6313857436180115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3686142563819885, \"precision\": 1.0, \"recall\": 0.6313857436180115, \"specificity\": 1.0, \"npv\": 0.9781165719032288, \"accuracy\": 0.9789072275161743, \"f1\": 0.7740483780236265, \"f2\": 0.6816380449141347, \"f0_5\": 0.8954446854663775, \"p4\": 0.8683964962419299, \"phi\": 0.7858554960232152}, {\"truth_threshold\": 27.138550585974613, \"match_probability\": 0.999999993231659, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6312327980995178, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3687672019004822, \"precision\": 1.0, \"recall\": 0.6312327980995178, \"specificity\": 1.0, \"npv\": 0.9781076908111572, \"accuracy\": 0.9788984656333923, \"f1\": 0.7739334270979841, \"f2\": 0.681495425872717, \"f0_5\": 0.8953831467499783, \"p4\": 0.8683224009879167, \"phi\": 0.7857567492151473}, {\"truth_threshold\": 27.141267560630403, \"match_probability\": 0.9999999932443936, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4126.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2412.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6310798525810242, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36892014741897583, \"precision\": 1.0, \"recall\": 0.6310798525810242, \"specificity\": 1.0, \"npv\": 0.9780988097190857, \"accuracy\": 0.9788897037506104, \"f1\": 0.7738184546136534, \"f2\": 0.6813527974106612, \"f0_5\": 0.895321586667824, \"p4\": 0.8682482833180725, \"phi\": 0.785657991789512}, {\"truth_threshold\": 27.14339908497792, \"match_probability\": 0.9999999932543673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4125.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2413.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6309269070625305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36907312273979187, \"precision\": 1.0, \"recall\": 0.6309269070625305, \"specificity\": 1.0, \"npv\": 0.9780899286270142, \"accuracy\": 0.9788809418678284, \"f1\": 0.7737034605645691, \"f2\": 0.6812101595270337, \"f0_5\": 0.8952600052087855, \"p4\": 0.8681741432216213, \"phi\": 0.7855591671688115}, {\"truth_threshold\": 27.14350662950132, \"match_probability\": 0.9999999932548702, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4123.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2415.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6306209564208984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3693790137767792, \"precision\": 1.0, \"recall\": 0.6306209564208984, \"specificity\": 1.0, \"npv\": 0.9780721664428711, \"accuracy\": 0.9788634181022644, \"f1\": 0.7734734077478661, \"f2\": 0.6809248554913295, \"f0_5\": 0.8951367781155015, \"p4\": 0.86802579570576, \"phi\": 0.7853615991800073}, {\"truth_threshold\": 27.144291501226068, \"match_probability\": 0.9999999932585387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4120.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2418.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6301621198654175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3698378801345825, \"precision\": 1.0, \"recall\": 0.6301621198654175, \"specificity\": 1.0, \"npv\": 0.9780455231666565, \"accuracy\": 0.9788371920585632, \"f1\": 0.7731281666353913, \"f2\": 0.6804968287526427, \"f0_5\": 0.8949517768702754, \"p4\": 0.8678031059626213, \"phi\": 0.7850651108266782}, {\"truth_threshold\": 27.15812843162824, \"match_probability\": 0.9999999933228872, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4119.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2419.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6300091743469238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36999082565307617, \"precision\": 1.0, \"recall\": 0.6300091743469238, \"specificity\": 1.0, \"npv\": 0.978036642074585, \"accuracy\": 0.9788284301757812, \"f1\": 0.7730130430702824, \"f2\": 0.6803541343199763, \"f0_5\": 0.8948900669157904, \"p4\": 0.8677288310798478, \"phi\": 0.7849662789512152}, {\"truth_threshold\": 27.17517707707577, \"match_probability\": 0.9999999934013277, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4118.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2420.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6298562288284302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3701437711715698, \"precision\": 1.0, \"recall\": 0.6298562288284302, \"specificity\": 1.0, \"npv\": 0.9780277609825134, \"accuracy\": 0.9788196682929993, \"f1\": 0.7728978978978979, \"f2\": 0.6802114304592005, \"f0_5\": 0.8948283355063016, \"p4\": 0.8676545336948426, \"phi\": 0.7848674364256847}, {\"truth_threshold\": 27.188823488405024, \"match_probability\": 0.9999999934634501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4116.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2422.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6295503377914429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3704496920108795, \"precision\": 1.0, \"recall\": 0.6295503377914429, \"specificity\": 1.0, \"npv\": 0.9780099987983704, \"accuracy\": 0.9788021445274353, \"f1\": 0.7726675427069645, \"f2\": 0.6799259944495837, \"f0_5\": 0.8947048082775411, \"p4\": 0.8675058713748048, \"phi\": 0.7846696627751788}, {\"truth_threshold\": 27.190210929413546, \"match_probability\": 0.9999999934697333, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4115.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2423.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6293973922729492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37060263752937317, \"precision\": 1.0, \"recall\": 0.6293973922729492, \"specificity\": 1.0, \"npv\": 0.9780011177062988, \"accuracy\": 0.9787934422492981, \"f1\": 0.7725523326762415, \"f2\": 0.6797832622988733, \"f0_5\": 0.894643012435864, \"p4\": 0.867431506418089, \"phi\": 0.7845707882683742}, {\"truth_threshold\": 27.193114612280294, \"match_probability\": 0.9999999934828634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4114.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2424.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6292444467544556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3707555830478668, \"precision\": 1.0, \"recall\": 0.6292444467544556, \"specificity\": 1.0, \"npv\": 0.9779922366142273, \"accuracy\": 0.9787846803665161, \"f1\": 0.7724371010138941, \"f2\": 0.6796405207163153, \"f0_5\": 0.8945811950943724, \"p4\": 0.8673571189157748, \"phi\": 0.7844719030951928}, {\"truth_threshold\": 27.213524660653924, \"match_probability\": 0.9999999935744133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4113.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2425.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6290914416313171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3709085285663605, \"precision\": 1.0, \"recall\": 0.6290914416313171, \"specificity\": 1.0, \"npv\": 0.9779833555221558, \"accuracy\": 0.9787759184837341, \"f1\": 0.7723218477138297, \"f2\": 0.6794977697009748, \"f0_5\": 0.8945193562418443, \"p4\": 0.8672827088570031, \"phi\": 0.7843730072515512}, {\"truth_threshold\": 27.220655728262155, \"match_probability\": 0.9999999936060958, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4111.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2427.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6287855505943298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37121444940567017, \"precision\": 1.0, \"recall\": 0.6287855505943298, \"specificity\": 1.0, \"npv\": 0.9779655933380127, \"accuracy\": 0.9787583947181702, \"f1\": 0.7720912761761668, \"f2\": 0.6792122393682054, \"f0_5\": 0.8943956139587503, \"p4\": 0.867133821026616, \"phi\": 0.7841751268704521}, {\"truth_threshold\": 27.2469604430306, \"match_probability\": 0.9999999937216197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4110.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2428.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6286326050758362, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3713673949241638, \"precision\": 1.0, \"recall\": 0.6286326050758362, \"specificity\": 1.0, \"npv\": 0.9779567122459412, \"accuracy\": 0.9787496328353882, \"f1\": 0.7719759579263712, \"f2\": 0.6790694600489062, \"f0_5\": 0.8943337105057011, \"p4\": 0.8670593432332477, \"phi\": 0.7840761989842715}, {\"truth_threshold\": 27.256098422375082, \"match_probability\": 0.9999999937612611, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4109.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2429.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6284796595573425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37152034044265747, \"precision\": 1.0, \"recall\": 0.6284796595573425, \"specificity\": 1.0, \"npv\": 0.9779478311538696, \"accuracy\": 0.978740930557251, \"f1\": 0.7718606180144642, \"f2\": 0.6789266712930835, \"f0_5\": 0.8942717854966484, \"p4\": 0.8669848428399158, \"phi\": 0.7839772604112715}, {\"truth_threshold\": 27.256356720660342, \"match_probability\": 0.999999993762378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4108.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2430.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6283267140388489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3716732859611511, \"precision\": 1.0, \"recall\": 0.6283267140388489, \"specificity\": 1.0, \"npv\": 0.9779389500617981, \"accuracy\": 0.978732168674469, \"f1\": 0.7717452564343416, \"f2\": 0.6787838730998017, \"f0_5\": 0.8942098389203309, \"p4\": 0.8669103198357266, \"phi\": 0.7838783111473565}, {\"truth_threshold\": 27.256388006018028, \"match_probability\": 0.9999999937625133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4107.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2431.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6281737685203552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37182626128196716, \"precision\": 1.0, \"recall\": 0.6281737685203552, \"specificity\": 1.0, \"npv\": 0.9779300689697266, \"accuracy\": 0.978723406791687, \"f1\": 0.7716298731798966, \"f2\": 0.6786410654681252, \"f0_5\": 0.8941478707654794, \"p4\": 0.866835774209779, \"phi\": 0.7837792944957782}, {\"truth_threshold\": 27.269860320959094, \"match_probability\": 0.9999999938204897, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4104.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2434.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6277148723602295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3722850978374481, \"precision\": 1.0, \"recall\": 0.6277148723602295, \"specificity\": 1.0, \"npv\": 0.9779034852981567, \"accuracy\": 0.9786971211433411, \"f1\": 0.7712835933095283, \"f2\": 0.6782125859333686, \"f0_5\": 0.8939618367169121, \"p4\": 0.8666120014922712, \"phi\": 0.7834823503879537}, {\"truth_threshold\": 27.27130243224411, \"match_probability\": 0.9999999938266636, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4101.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2437.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6272560358047485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37274396419525146, \"precision\": 1.0, \"recall\": 0.6272560358047485, \"specificity\": 1.0, \"npv\": 0.9778768420219421, \"accuracy\": 0.9786708950996399, \"f1\": 0.770937118150202, \"f2\": 0.6777840214193633, \"f0_5\": 0.8937756080550955, \"p4\": 0.8663880247858311, \"phi\": 0.7831852531446588}, {\"truth_threshold\": 27.295608721759763, \"match_probability\": 0.9999999939297997, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4099.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2439.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6269501447677612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37304985523223877, \"precision\": 1.0, \"recall\": 0.6269501447677612, \"specificity\": 1.0, \"npv\": 0.9778590798377991, \"accuracy\": 0.9786533713340759, \"f1\": 0.7707060261351885, \"f2\": 0.6774982645201811, \"f0_5\": 0.893651347344554, \"p4\": 0.8662385935084692, \"phi\": 0.782987172512176}, {\"truth_threshold\": 27.31405543486952, \"match_probability\": 0.999999994006921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4098.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2440.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6267971992492676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3732028007507324, \"precision\": 1.0, \"recall\": 0.6267971992492676, \"specificity\": 1.0, \"npv\": 0.9778501987457275, \"accuracy\": 0.978644609451294, \"f1\": 0.7705904475366679, \"f2\": 0.6773553719008264, \"f0_5\": 0.8935891844744875, \"p4\": 0.8661638437949964, \"phi\": 0.7828880593474237}, {\"truth_threshold\": 27.314777219713502, \"match_probability\": 0.9999999940099186, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4097.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2441.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6266442537307739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37335577607154846, \"precision\": 1.0, \"recall\": 0.6266442537307739, \"specificity\": 1.0, \"npv\": 0.977841317653656, \"accuracy\": 0.9786359071731567, \"f1\": 0.7704748472026328, \"f2\": 0.6772124698337135, \"f0_5\": 0.8935269999127629, \"p4\": 0.8660890713503697, \"phi\": 0.7827889921924188}, {\"truth_threshold\": 27.320035929345238, \"match_probability\": 0.999999994031713, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4093.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2445.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6260324120521545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37396758794784546, \"precision\": 1.0, \"recall\": 0.6260324120521545, \"specificity\": 1.0, \"npv\": 0.9778057932853699, \"accuracy\": 0.9786008596420288, \"f1\": 0.7700122283886747, \"f2\": 0.676640767068937, \"f0_5\": 0.8932780445220427, \"p4\": 0.8657897540406532, \"phi\": 0.7823925593425438}, {\"truth_threshold\": 27.32134972788163, \"match_probability\": 0.9999999940371456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4091.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2447.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6257265210151672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37427347898483276, \"precision\": 1.0, \"recall\": 0.6257265210151672, \"specificity\": 1.0, \"npv\": 0.9777880907058716, \"accuracy\": 0.9785833954811096, \"f1\": 0.7697807884090695, \"f2\": 0.6763548589756307, \"f0_5\": 0.8931534363811021, \"p4\": 0.8656399587131012, \"phi\": 0.7821943067729809}, {\"truth_threshold\": 27.34341978560399, \"match_probability\": 0.9999999941276699, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4090.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2448.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6255735754966736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3744264245033264, \"precision\": 1.0, \"recall\": 0.6255735754966736, \"specificity\": 1.0, \"npv\": 0.9777792096138, \"accuracy\": 0.9785746335983276, \"f1\": 0.7696650357546104, \"f2\": 0.6762118907479664, \"f0_5\": 0.8930910996593588, \"p4\": 0.8655650268426102, \"phi\": 0.7820951643426587}, {\"truth_threshold\": 27.34737940584616, \"match_probability\": 0.9999999941437651, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4088.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2450.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6252676844596863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3747323453426361, \"precision\": 1.0, \"recall\": 0.6252676844596863, \"specificity\": 1.0, \"npv\": 0.977761447429657, \"accuracy\": 0.9785571098327637, \"f1\": 0.769433465085639, \"f2\": 0.6759259259259259, \"f0_5\": 0.8929663608562691, \"p4\": 0.8654150946330591, \"phi\": 0.7818967903508708}, {\"truth_threshold\": 27.37050804921578, \"match_probability\": 0.999999994236901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4087.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2451.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6251147389411926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37488529086112976, \"precision\": 1.0, \"recall\": 0.6251147389411926, \"specificity\": 1.0, \"npv\": 0.9777525663375854, \"accuracy\": 0.9785483479499817, \"f1\": 0.7693176470588236, \"f2\": 0.6757829293296737, \"f0_5\": 0.8929039587520755, \"p4\": 0.8653400942719219, \"phi\": 0.7817976155937618}, {\"truth_threshold\": 27.381957010081074, \"match_probability\": 0.9999999942824549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4086.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2452.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6249617338180542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3750382363796234, \"precision\": 1.0, \"recall\": 0.6249617338180542, \"specificity\": 1.0, \"npv\": 0.9777436852455139, \"accuracy\": 0.9785395860671997, \"f1\": 0.7692018072289156, \"f2\": 0.6756399232753489, \"f0_5\": 0.8928415348308715, \"p4\": 0.8652650710584807, \"phi\": 0.7816984300549873}, {\"truth_threshold\": 27.404145429255284, \"match_probability\": 0.9999999943697171, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4085.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6248087882995605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37519118189811707, \"precision\": 1.0, \"recall\": 0.6248087882995605, \"specificity\": 1.0, \"npv\": 0.9777348041534424, \"accuracy\": 0.9785308837890625, \"f1\": 0.7690859455897581, \"f2\": 0.6754969077620134, \"f0_5\": 0.8927790890812134, \"p4\": 0.8651900249816791, \"phi\": 0.7815992337303932}, {\"truth_threshold\": 27.408391099463078, \"match_probability\": 0.999999994386262, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4083.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2455.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6245028972625732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37549710273742676, \"precision\": 1.0, \"recall\": 0.6245028972625732, \"specificity\": 1.0, \"npv\": 0.9777170419692993, \"accuracy\": 0.9785133600234985, \"f1\": 0.7688541568590528, \"f2\": 0.675210848354556, \"f0_5\": 0.8926541320507214, \"p4\": 0.8650398641937337, \"phi\": 0.7814007518542858}, {\"truth_threshold\": 27.41630388906224, \"match_probability\": 0.9999999944169675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4082.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2456.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6243499517440796, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3756500482559204, \"precision\": 1.0, \"recall\": 0.6243499517440796, \"specificity\": 1.0, \"npv\": 0.9777082204818726, \"accuracy\": 0.9785045981407166, \"f1\": 0.7687382297551789, \"f2\": 0.6750678044585566, \"f0_5\": 0.8925916207469605, \"p4\": 0.8649647494604418, \"phi\": 0.7813015231405803}, {\"truth_threshold\": 27.420637401425605, \"match_probability\": 0.9999999944337125, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4081.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2457.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6241970062255859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37580299377441406, \"precision\": 1.0, \"recall\": 0.6241970062255859, \"specificity\": 1.0, \"npv\": 0.977699339389801, \"accuracy\": 0.9784958362579346, \"f1\": 0.7686222808174028, \"f2\": 0.6749247510997917, \"f0_5\": 0.8925290875688916, \"p4\": 0.8648896118194931, \"phi\": 0.7812022836244131}, {\"truth_threshold\": 27.448035619290987, \"match_probability\": 0.9999999945384244, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4079.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2459.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6238911151885986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37610891461372375, \"precision\": 1.0, \"recall\": 0.6238911151885986, \"specificity\": 1.0, \"npv\": 0.977681577205658, \"accuracy\": 0.9784783720970154, \"f1\": 0.7683903174154658, \"f2\": 0.6746386159902087, \"f0_5\": 0.8924039555438873, \"p4\": 0.8647392677702501, \"phi\": 0.7810037152883537}, {\"truth_threshold\": 27.449856064951835, \"match_probability\": 0.9999999945453116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4078.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2460.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.623738169670105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3762618601322174, \"precision\": 1.0, \"recall\": 0.623738169670105, \"specificity\": 1.0, \"npv\": 0.9776726961135864, \"accuracy\": 0.9784696102142334, \"f1\": 0.76827430293896, \"f2\": 0.6744955342375124, \"f0_5\": 0.8923413566739606, \"p4\": 0.8646640613397505, \"phi\": 0.7809044433330758}, {\"truth_threshold\": 27.454115730846745, \"match_probability\": 0.9999999945613932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4076.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2462.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6234322190284729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3765677511692047, \"precision\": 1.0, \"recall\": 0.6234322190284729, \"specificity\": 1.0, \"npv\": 0.9776549339294434, \"accuracy\": 0.9784520864486694, \"f1\": 0.7680422084039947, \"f2\": 0.6742093423316131, \"f0_5\": 0.8922160931617197, \"p4\": 0.8645135796114279, \"phi\": 0.7807058669609062}, {\"truth_threshold\": 27.461486890139373, \"match_probability\": 0.9999999945891098, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4073.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2465.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6229733824729919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37702661752700806, \"precision\": 1.0, \"recall\": 0.6229733824729919, \"specificity\": 1.0, \"npv\": 0.9776283502578735, \"accuracy\": 0.9784258008003235, \"f1\": 0.7676939025539534, \"f2\": 0.6737799834574029, \"f0_5\": 0.8920280332895313, \"p4\": 0.8642876846837186, \"phi\": 0.7804078642659276}, {\"truth_threshold\": 27.469078869515748, \"match_probability\": 0.9999999946175091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4072.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2466.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6228204369544983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3771795630455017, \"precision\": 1.0, \"recall\": 0.6228204369544983, \"specificity\": 1.0, \"npv\": 0.977619469165802, \"accuracy\": 0.9784170985221863, \"f1\": 0.7675777568331762, \"f2\": 0.673636844891477, \"f0_5\": 0.8919653027249628, \"p4\": 0.8642123403738607, \"phi\": 0.7803085273263426}, {\"truth_threshold\": 27.499449112431428, \"match_probability\": 0.9999999947296319, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4071.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2467.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6226674914360046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37733250856399536, \"precision\": 1.0, \"recall\": 0.6226674914360046, \"specificity\": 1.0, \"npv\": 0.9776105880737305, \"accuracy\": 0.9784083366394043, \"f1\": 0.7674615892167028, \"f2\": 0.6734936968533898, \"f0_5\": 0.8919025501708877, \"p4\": 0.8641369730451038, \"phi\": 0.7802091795425106}, {\"truth_threshold\": 27.501537040679224, \"match_probability\": 0.9999999947372539, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4070.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.622514545917511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3774854838848114, \"precision\": 1.0, \"recall\": 0.622514545917511, \"specificity\": 1.0, \"npv\": 0.9776017069816589, \"accuracy\": 0.9783995747566223, \"f1\": 0.7673453996983409, \"f2\": 0.673350539342201, \"f0_5\": 0.8918397756157419, \"p4\": 0.8640615826862841, \"phi\": 0.7801097639700403}, {\"truth_threshold\": 27.52131857506525, \"match_probability\": 0.9999999948089217, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4069.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2469.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6223616003990173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37763842940330505, \"precision\": 1.0, \"recall\": 0.6223616003990173, \"specificity\": 1.0, \"npv\": 0.9775928258895874, \"accuracy\": 0.9783908128738403, \"f1\": 0.7672291882718959, \"f2\": 0.6732073723569704, \"f0_5\": 0.8917769790479531, \"p4\": 0.8639861692862306, \"phi\": 0.7800103944783967}, {\"truth_threshold\": 27.523856802137306, \"match_probability\": 0.9999999948180466, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4068.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2470.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6222086548805237, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3777913749217987, \"precision\": 1.0, \"recall\": 0.6222086548805237, \"specificity\": 1.0, \"npv\": 0.9775839447975159, \"accuracy\": 0.9783820509910583, \"f1\": 0.767112954931171, \"f2\": 0.6730641958967571, \"f0_5\": 0.8917141604559404, \"p4\": 0.8639107328337652, \"phi\": 0.7799110141299193}, {\"truth_threshold\": 27.526248624247643, \"match_probability\": 0.9999999948266306, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4066.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2472.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6219027042388916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.378097265958786, \"precision\": 1.0, \"recall\": 0.6219027042388916, \"specificity\": 1.0, \"npv\": 0.9775662422180176, \"accuracy\": 0.9783645868301392, \"f1\": 0.7668804224820822, \"f2\": 0.6727778145476206, \"f0_5\": 0.8915884571528814, \"p4\": 0.8637597907268497, \"phi\": 0.779712163878494}, {\"truth_threshold\": 27.52833447092199, \"match_probability\": 0.9999999948341048, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4065.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2473.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.621749758720398, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37825024127960205, \"precision\": 1.0, \"recall\": 0.621749758720398, \"specificity\": 1.0, \"npv\": 0.977557361125946, \"accuracy\": 0.9783558249473572, \"f1\": 0.7667641233613128, \"f2\": 0.6726346096568157, \"f0_5\": 0.8915255724186332, \"p4\": 0.863684285050007, \"phi\": 0.7796127509275564}, {\"truth_threshold\": 27.53057162992721, \"match_probability\": 0.9999999948421092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4064.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2474.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6215968132019043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3784031867980957, \"precision\": 1.0, \"recall\": 0.6215968132019043, \"specificity\": 1.0, \"npv\": 0.9775484800338745, \"accuracy\": 0.9783470630645752, \"f1\": 0.7666478023014526, \"f2\": 0.672491395287265, \"f0_5\": 0.891462665613758, \"p4\": 0.8636087562759674, \"phi\": 0.7795133271029667}, {\"truth_threshold\": 27.541828905766792, \"match_probability\": 0.9999999948821994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4062.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2476.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.621290922164917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.378709077835083, \"precision\": 1.0, \"recall\": 0.621290922164917, \"specificity\": 1.0, \"npv\": 0.9775307178497314, \"accuracy\": 0.9783295392990112, \"f1\": 0.7664150943396226, \"f2\": 0.6722049381081617, \"f0_5\": 0.8913367857456332, \"p4\": 0.8634576293914326, \"phi\": 0.779314446815988}, {\"truth_threshold\": 27.55103403868128, \"match_probability\": 0.9999999949147497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4061.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2477.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6211379766464233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37886202335357666, \"precision\": 1.0, \"recall\": 0.6211379766464233, \"specificity\": 1.0, \"npv\": 0.9775218963623047, \"accuracy\": 0.9783207774162292, \"f1\": 0.7662987074252288, \"f2\": 0.6720616952967265, \"f0_5\": 0.8912738126591169, \"p4\": 0.8633820312584869, \"phi\": 0.7792149333442386}, {\"truth_threshold\": 27.5611657819868, \"match_probability\": 0.9999999949503372, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4060.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2478.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6209850311279297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3790149986743927, \"precision\": 1.0, \"recall\": 0.6209850311279297, \"specificity\": 1.0, \"npv\": 0.9775130152702332, \"accuracy\": 0.978312075138092, \"f1\": 0.7661822985468957, \"f2\": 0.6719184430027804, \"f0_5\": 0.8912108174554395, \"p4\": 0.8633064099834431, \"phi\": 0.7791154659761512}, {\"truth_threshold\": 27.579454939487274, \"match_probability\": 0.9999999950139481, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4059.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2479.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.620832085609436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37916794419288635, \"precision\": 1.0, \"recall\": 0.620832085609436, \"specificity\": 1.0, \"npv\": 0.9775041341781616, \"accuracy\": 0.9783033132553101, \"f1\": 0.7660658676984052, \"f2\": 0.6717751812253815, \"f0_5\": 0.8911478001229473, \"p4\": 0.863230765555058, \"phi\": 0.7790159877133318}, {\"truth_threshold\": 27.583635429193183, \"match_probability\": 0.9999999950283752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4056.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2482.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6203731894493103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3796268105506897, \"precision\": 1.0, \"recall\": 0.6203731894493103, \"specificity\": 1.0, \"npv\": 0.977477490901947, \"accuracy\": 0.9782770276069641, \"f1\": 0.7657164432697754, \"f2\": 0.6713453389830508, \"f0_5\": 0.8909586152359195, \"p4\": 0.8630036932373106, \"phi\": 0.7787174304794727}, {\"truth_threshold\": 27.599613274356862, \"match_probability\": 0.9999999950831322, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4055.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2483.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6202202439308167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37977975606918335, \"precision\": 1.0, \"recall\": 0.6202202439308167, \"specificity\": 1.0, \"npv\": 0.9774686694145203, \"accuracy\": 0.9782682657241821, \"f1\": 0.7655999244784292, \"f2\": 0.6712020392624226, \"f0_5\": 0.890895509271465, \"p4\": 0.8629279560829801, \"phi\": 0.778617908588691}, {\"truth_threshold\": 27.61171995842965, \"match_probability\": 0.9999999951242204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4054.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2484.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.620067298412323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.379932701587677, \"precision\": 1.0, \"recall\": 0.620067298412323, \"specificity\": 1.0, \"npv\": 0.9774597883224487, \"accuracy\": 0.9782595634460449, \"f1\": 0.7654833836858006, \"f2\": 0.6710587300536317, \"f0_5\": 0.8908323811198031, \"p4\": 0.8628521957189819, \"phi\": 0.7785183757820315}, {\"truth_threshold\": 27.625589293580777, \"match_probability\": 0.9999999951708691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4053.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2485.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6199143528938293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38008564710617065, \"precision\": 1.0, \"recall\": 0.6199143528938293, \"specificity\": 1.0, \"npv\": 0.9774509072303772, \"accuracy\": 0.9782508015632629, \"f1\": 0.7653668208856577, \"f2\": 0.6709154113557358, \"f0_5\": 0.8907692307692308, \"p4\": 0.8627764121340287, \"phi\": 0.7784188320552579}, {\"truth_threshold\": 27.62634995074694, \"match_probability\": 0.9999999951734146, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4051.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2487.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.619608461856842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38039156794548035, \"precision\": 1.0, \"recall\": 0.619608461856842, \"specificity\": 1.0, \"npv\": 0.9774331450462341, \"accuracy\": 0.978233277797699, \"f1\": 0.7651336292378884, \"f2\": 0.6706287454888588, \"f0_5\": 0.8906428634245009, \"p4\": 0.8626247752560724, \"phi\": 0.7782196547557557}, {\"truth_threshold\": 27.6611991276631, \"match_probability\": 0.9999999952886068, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4050.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2488.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6194555163383484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.380544513463974, \"precision\": 1.0, \"recall\": 0.6194555163383484, \"specificity\": 1.0, \"npv\": 0.9774243235588074, \"accuracy\": 0.978224515914917, \"f1\": 0.7650170003777862, \"f2\": 0.6704853983179921, \"f0_5\": 0.8905796464068959, \"p4\": 0.8625489219404584, \"phi\": 0.7781200782364079}, {\"truth_threshold\": 27.685881140762806, \"match_probability\": 0.999999995368525, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4049.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2489.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.61930251121521, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38069745898246765, \"precision\": 1.0, \"recall\": 0.61930251121521, \"specificity\": 1.0, \"npv\": 0.9774154424667358, \"accuracy\": 0.978215754032135, \"f1\": 0.7649003494852177, \"f2\": 0.6703420416542498, \"f0_5\": 0.8905164071434856, \"p4\": 0.8624730453586676, \"phi\": 0.7780204907799714}, {\"truth_threshold\": 27.69926725714003, \"match_probability\": 0.9999999954112997, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4048.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2490.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6191495656967163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3808504045009613, \"precision\": 1.0, \"recall\": 0.6191495656967163, \"specificity\": 1.0, \"npv\": 0.9774065613746643, \"accuracy\": 0.9782070517539978, \"f1\": 0.7647836765539392, \"f2\": 0.6701986754966888, \"f0_5\": 0.8904531456225253, \"p4\": 0.8623971454993764, \"phi\": 0.7779208923821961}, {\"truth_threshold\": 27.720959040123592, \"match_probability\": 0.9999999954797775, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4047.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2491.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6189966201782227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38100337982177734, \"precision\": 1.0, \"recall\": 0.6189966201782227, \"specificity\": 1.0, \"npv\": 0.9773976802825928, \"accuracy\": 0.9781982898712158, \"f1\": 0.7646669815777043, \"f2\": 0.6700552998443657, \"f0_5\": 0.8903898618322627, \"p4\": 0.8623212223512535, \"phi\": 0.7778212259430172}, {\"truth_threshold\": 27.734901196412206, \"match_probability\": 0.9999999955232504, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4046.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2492.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.618843674659729, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.381156325340271, \"precision\": 1.0, \"recall\": 0.618843674659729, \"specificity\": 1.0, \"npv\": 0.9773887991905212, \"accuracy\": 0.9781895279884338, \"f1\": 0.7645502645502645, \"f2\": 0.6699119146963375, \"f0_5\": 0.8903265557609366, \"p4\": 0.8622452759029605, \"phi\": 0.7777216056430091}, {\"truth_threshold\": 27.763816158416088, \"match_probability\": 0.9999999956120816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4043.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.618384838104248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38161516189575195, \"precision\": 1.0, \"recall\": 0.618384838104248, \"specificity\": 1.0, \"npv\": 0.9773622155189514, \"accuracy\": 0.9781632423400879, \"f1\": 0.7641999810981949, \"f2\": 0.6694817022685875, \"f0_5\": 0.8901365037428446, \"p4\": 0.8620172966435659, \"phi\": 0.7774226218782927}, {\"truth_threshold\": 27.774251576214503, \"match_probability\": 0.9999999956437061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4042.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2496.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6182318925857544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.381768137216568, \"precision\": 1.0, \"recall\": 0.6182318925857544, \"specificity\": 1.0, \"npv\": 0.9773533344268799, \"accuracy\": 0.9781545400619507, \"f1\": 0.7640831758034027, \"f2\": 0.6693382791283037, \"f0_5\": 0.8900731084294901, \"p4\": 0.8619412568810606, \"phi\": 0.777322957729483}, {\"truth_threshold\": 27.79616255952142, \"match_probability\": 0.9999999957093676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4040.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2498.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6179259419441223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3820740282535553, \"precision\": 1.0, \"recall\": 0.6179259419441223, \"specificity\": 1.0, \"npv\": 0.9773356318473816, \"accuracy\": 0.9781370162963867, \"f1\": 0.7638494989601059, \"f2\": 0.669051404345522, \"f0_5\": 0.889946250770993, \"p4\": 0.8617891072737487, \"phi\": 0.7771235965140976}, {\"truth_threshold\": 27.80793156437737, \"match_probability\": 0.9999999957442267, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4039.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2499.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6177729964256287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38222697377204895, \"precision\": 1.0, \"recall\": 0.6177729964256287, \"specificity\": 1.0, \"npv\": 0.9773267507553101, \"accuracy\": 0.9781282544136047, \"f1\": 0.7637326273990734, \"f2\": 0.6689079527011361, \"f0_5\": 0.8898827884022209, \"p4\": 0.8617129974061694, \"phi\": 0.777023899438978}, {\"truth_threshold\": 27.812625027645407, \"match_probability\": 0.9999999957580494, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4038.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2500.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.617620050907135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3823799192905426, \"precision\": 1.0, \"recall\": 0.617620050907135, \"specificity\": 1.0, \"npv\": 0.9773178696632385, \"accuracy\": 0.9781194925308228, \"f1\": 0.7636157337367625, \"f2\": 0.6687644915534945, \"f0_5\": 0.8898193036579991, \"p4\": 0.861636864147447, \"phi\": 0.7769241342228009}, {\"truth_threshold\": 27.81626643406245, \"match_probability\": 0.9999999957687428, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4037.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2501.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6174671053886414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38253289461135864, \"precision\": 1.0, \"recall\": 0.6174671053886414, \"specificity\": 1.0, \"npv\": 0.977308988571167, \"accuracy\": 0.9781107306480408, \"f1\": 0.7634988179669031, \"f2\": 0.6686210209016529, \"f0_5\": 0.8897557965264921, \"p4\": 0.8615607074861765, \"phi\": 0.7768244151686123}, {\"truth_threshold\": 27.824915808559847, \"match_probability\": 0.9999999957940344, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4036.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2502.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6173141598701477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3826858401298523, \"precision\": 1.0, \"recall\": 0.6173141598701477, \"specificity\": 1.0, \"npv\": 0.9773001670837402, \"accuracy\": 0.9781019687652588, \"f1\": 0.763381880083223, \"f2\": 0.6684775407446668, \"f0_5\": 0.8896922669958558, \"p4\": 0.8614845274109458, \"phi\": 0.7767246851218759}, {\"truth_threshold\": 27.82602443964515, \"match_probability\": 0.9999999957972653, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4031.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2507.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6165494322776794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38345059752464294, \"precision\": 1.0, \"recall\": 0.6165494322776794, \"specificity\": 1.0, \"npv\": 0.9772558212280273, \"accuracy\": 0.9780582189559937, \"f1\": 0.7627968587378181, \"f2\": 0.6677599973495014, \"f0_5\": 0.8893742829406054, \"p4\": 0.8611032754254401, \"phi\": 0.7762258126450746}, {\"truth_threshold\": 27.832900939899755, \"match_probability\": 0.9999999958172496, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4030.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2508.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.616396427154541, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3836035430431366, \"precision\": 1.0, \"recall\": 0.616396427154541, \"specificity\": 1.0, \"npv\": 0.9772469401359558, \"accuracy\": 0.9780494570732117, \"f1\": 0.7626797880393641, \"f2\": 0.6676164601418064, \"f0_5\": 0.8893106187659988, \"p4\": 0.8610269546263746, \"phi\": 0.7761260165461534}, {\"truth_threshold\": 27.842949564502202, \"match_probability\": 0.999999995846282, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4029.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2509.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6162434816360474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38375648856163025, \"precision\": 1.0, \"recall\": 0.6162434816360474, \"specificity\": 1.0, \"npv\": 0.9772380590438843, \"accuracy\": 0.9780407547950745, \"f1\": 0.7625626951831173, \"f2\": 0.6674729134223518, \"f0_5\": 0.8892469321091198, \"p4\": 0.8609506103332549, \"phi\": 0.7760261522060977}, {\"truth_threshold\": 27.84559103355047, \"match_probability\": 0.9999999958538802, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4028.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2510.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6160905361175537, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3839094638824463, \"precision\": 1.0, \"recall\": 0.6160905361175537, \"specificity\": 1.0, \"npv\": 0.9772292375564575, \"accuracy\": 0.9780319929122925, \"f1\": 0.7624455801627863, \"f2\": 0.6673293571901922, \"f0_5\": 0.8891832229580574, \"p4\": 0.8608742425346095, \"phi\": 0.7759263340508405}, {\"truth_threshold\": 27.846359396859334, \"match_probability\": 0.9999999958560878, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4027.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2511.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6159375905990601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38406240940093994, \"precision\": 1.0, \"recall\": 0.6159375905990601, \"specificity\": 1.0, \"npv\": 0.977220356464386, \"accuracy\": 0.9780232310295105, \"f1\": 0.7623284429720776, \"f2\": 0.6671857914443818, \"f0_5\": 0.889119491300892, \"p4\": 0.8607978512189591, \"phi\": 0.7758265048643772}, {\"truth_threshold\": 27.848742372083386, \"match_probability\": 0.9999999958629269, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4026.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2512.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6157846450805664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3842153549194336, \"precision\": 1.0, \"recall\": 0.6157846450805664, \"specificity\": 1.0, \"npv\": 0.9772114753723145, \"accuracy\": 0.9780144691467285, \"f1\": 0.7622112836046951, \"f2\": 0.6670422161839751, \"f0_5\": 0.8890557371256956, \"p4\": 0.8607214363748169, \"phi\": 0.7757266646423998}, {\"truth_threshold\": 27.868540690116525, \"match_probability\": 0.9999999959193127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4024.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2514.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6154787540435791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3845212459564209, \"precision\": 1.0, \"recall\": 0.6154787540435791, \"specificity\": 1.0, \"npv\": 0.9771937727928162, \"accuracy\": 0.9779969453811646, \"f1\": 0.7619768983147132, \"f2\": 0.6667550371155886, \"f0_5\": 0.8889281611734559, \"p4\": 0.8605685360550732, \"phi\": 0.775526893821878}, {\"truth_threshold\": 27.884312597808183, \"match_probability\": 0.9999999959636808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4023.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2515.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6153258085250854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38467422127723694, \"precision\": 1.0, \"recall\": 0.6153258085250854, \"specificity\": 1.0, \"npv\": 0.9771848917007446, \"accuracy\": 0.9779882431030273, \"f1\": 0.7618596723795095, \"f2\": 0.6666114333057167, \"f0_5\": 0.8888643393725144, \"p4\": 0.8604920505564609, \"phi\": 0.7754270204606262}, {\"truth_threshold\": 27.888625792751785, \"match_probability\": 0.9999999959757301, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4022.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2516.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6151728630065918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3848271667957306, \"precision\": 1.0, \"recall\": 0.6151728630065918, \"specificity\": 1.0, \"npv\": 0.9771760106086731, \"accuracy\": 0.9779794812202454, \"f1\": 0.7617424242424242, \"f2\": 0.6664678199774641, \"f0_5\": 0.8888004950057456, \"p4\": 0.8604155414833354, \"phi\": 0.7753271360465982}, {\"truth_threshold\": 27.895057415962327, \"match_probability\": 0.9999999959936307, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4020.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2518.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6148669123649597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3851330578327179, \"precision\": 1.0, \"recall\": 0.6148669123649597, \"specificity\": 1.0, \"npv\": 0.9771583080291748, \"accuracy\": 0.9779619574546814, \"f1\": 0.7615078613373745, \"f2\": 0.666180564762031, \"f0_5\": 0.888672738526837, \"p4\": 0.8602624525674406, \"phi\": 0.775127276762708}, {\"truth_threshold\": 27.900977433142756, \"match_probability\": 0.9999999960100369, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4019.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2519.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6147139668464661, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38528603315353394, \"precision\": 1.0, \"recall\": 0.6147139668464661, \"specificity\": 1.0, \"npv\": 0.9771494269371033, \"accuracy\": 0.9779531955718994, \"f1\": 0.761390546556787, \"f2\": 0.6660369228729575, \"f0_5\": 0.8886088263907314, \"p4\": 0.8601858727016005, \"phi\": 0.7750273591575443}, {\"truth_threshold\": 27.901910074963958, \"match_probability\": 0.9999999960126154, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4018.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2520.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6145610213279724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3854389786720276, \"precision\": 1.0, \"recall\": 0.6145610213279724, \"specificity\": 1.0, \"npv\": 0.9771406054496765, \"accuracy\": 0.9779444336891174, \"f1\": 0.7612732095490716, \"f2\": 0.665893271461717, \"f0_5\": 0.8885448916408669, \"p4\": 0.8601092692151058, \"phi\": 0.7749274304822988}, {\"truth_threshold\": 27.907244314106414, \"match_probability\": 0.9999999960273311, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4017.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2521.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6144080758094788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38559192419052124, \"precision\": 1.0, \"recall\": 0.6144080758094788, \"specificity\": 1.0, \"npv\": 0.977131724357605, \"accuracy\": 0.9779357314109802, \"f1\": 0.761155850307911, \"f2\": 0.6657496105273625, \"f0_5\": 0.8884809342652393, \"p4\": 0.8600326420964021, \"phi\": 0.7748274907326392}, {\"truth_threshold\": 27.90924540116658, \"match_probability\": 0.9999999960328376, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4016.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2522.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6142551302909851, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3857448697090149, \"precision\": 1.0, \"recall\": 0.6142551302909851, \"specificity\": 1.0, \"npv\": 0.9771228432655334, \"accuracy\": 0.9779269695281982, \"f1\": 0.761038468826985, \"f2\": 0.6656059400689472, \"f0_5\": 0.8884169542518361, \"p4\": 0.8599559913339276, \"phi\": 0.7747274825965356}, {\"truth_threshold\": 27.921672556188383, \"match_probability\": 0.9999999960668634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4013.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2525.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6137962937355042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38620373606681824, \"precision\": 1.0, \"recall\": 0.6137962937355042, \"specificity\": 1.0, \"npv\": 0.9770962595939636, \"accuracy\": 0.9779006838798523, \"f1\": 0.7606861908823808, \"f2\": 0.6651748715398641, \"f0_5\": 0.8882248782647189, \"p4\": 0.8597258970681508, \"phi\": 0.7744275635747844}, {\"truth_threshold\": 27.922919073122298, \"match_probability\": 0.9999999960702602, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4012.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2526.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6136432886123657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3863566815853119, \"precision\": 1.0, \"recall\": 0.6136432886123657, \"specificity\": 1.0, \"npv\": 0.9770873785018921, \"accuracy\": 0.9778919219970703, \"f1\": 0.7605687203791469, \"f2\": 0.6650311629757326, \"f0_5\": 0.8881608075799168, \"p4\": 0.8596491516148261, \"phi\": 0.7743275683810885}, {\"truth_threshold\": 27.929655298338947, \"match_probability\": 0.9999999960885662, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4011.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2527.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6134903430938721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38650962710380554, \"precision\": 1.0, \"recall\": 0.6134903430938721, \"specificity\": 1.0, \"npv\": 0.9770785570144653, \"accuracy\": 0.9778832197189331, \"f1\": 0.7604512276045122, \"f2\": 0.6648874448828034, \"f0_5\": 0.8880967141971482, \"p4\": 0.8595723824598093, \"phi\": 0.7742275047448219}, {\"truth_threshold\": 27.93065483774305, \"match_probability\": 0.9999999960912752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4009.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2529.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6131844520568848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38681554794311523, \"precision\": 1.0, \"recall\": 0.6131844520568848, \"specificity\": 1.0, \"npv\": 0.9770607948303223, \"accuracy\": 0.9778656959533691, \"f1\": 0.7602161752157012, \"f2\": 0.6645999801067604, \"f0_5\": 0.887968459289448, \"p4\": 0.8594187729982632, \"phi\": 0.7740274588238988}, {\"truth_threshold\": 27.938269936690094, \"match_probability\": 0.9999999961118526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4007.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2531.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6128785610198975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38712143898010254, \"precision\": 1.0, \"recall\": 0.6128785610198975, \"specificity\": 1.0, \"npv\": 0.977043092250824, \"accuracy\": 0.9778481721878052, \"f1\": 0.7599810336652442, \"f2\": 0.6643124772041513, \"f0_5\": 0.8878401134450058, \"p4\": 0.8592650685905656, \"phi\": 0.7738273684488389}, {\"truth_threshold\": 27.951446969003808, \"match_probability\": 0.9999999961472038, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4006.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2532.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6127256155014038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3872743844985962, \"precision\": 1.0, \"recall\": 0.6127256155014038, \"specificity\": 1.0, \"npv\": 0.9770342111587524, \"accuracy\": 0.9778394103050232, \"f1\": 0.7598634294385432, \"f2\": 0.6641687114530141, \"f0_5\": 0.8877759063912773, \"p4\": 0.8591881807528309, \"phi\": 0.7737272492035319}, {\"truth_threshold\": 27.96654439068527, \"match_probability\": 0.9999999961873121, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4005.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2533.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6125726699829102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38742735981941223, \"precision\": 1.0, \"recall\": 0.6125726699829102, \"specificity\": 1.0, \"npv\": 0.9770253896713257, \"accuracy\": 0.977830708026886, \"f1\": 0.7597458029023997, \"f2\": 0.6640249361673907, \"f0_5\": 0.8877116765670715, \"p4\": 0.8591112691436482, \"phi\": 0.7736271762012769}, {\"truth_threshold\": 27.970839719459985, \"match_probability\": 0.9999999961986467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4002.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2536.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6121137738227844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3878861963748932, \"precision\": 1.0, \"recall\": 0.6121137738227844, \"specificity\": 1.0, \"npv\": 0.9769987463951111, \"accuracy\": 0.97780442237854, \"f1\": 0.759392789373814, \"f2\": 0.6635935530941168, \"f0_5\": 0.8875188503503948, \"p4\": 0.8588803915708494, \"phi\": 0.7733268329868804}, {\"truth_threshold\": 27.98349750105386, \"match_probability\": 0.9999999962318528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4001.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2537.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6119608283042908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38803914189338684, \"precision\": 1.0, \"recall\": 0.6119608283042908, \"specificity\": 1.0, \"npv\": 0.9769899249076843, \"accuracy\": 0.9777956604957581, \"f1\": 0.7592750735363887, \"f2\": 0.6634497396610619, \"f0_5\": 0.8874545293230415, \"p4\": 0.8588033847592735, \"phi\": 0.7732267154275141}, {\"truth_threshold\": 27.985265964753193, \"match_probability\": 0.999999996236469, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4000.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2538.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6118078827857971, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3881921172142029, \"precision\": 1.0, \"recall\": 0.6118078827857971, \"specificity\": 1.0, \"npv\": 0.9769810438156128, \"accuracy\": 0.9777868986129761, \"f1\": 0.7591573353577529, \"f2\": 0.6633059166887768, \"f0_5\": 0.8873901854645487, \"p4\": 0.8587263541179111, \"phi\": 0.7731265867196552}, {\"truth_threshold\": 27.99309362467632, \"match_probability\": 0.9999999962568334, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3999.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2539.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6116549372673035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38834506273269653, \"precision\": 1.0, \"recall\": 0.6116549372673035, \"specificity\": 1.0, \"npv\": 0.9769721627235413, \"accuracy\": 0.9777781963348389, \"f1\": 0.7590395748315459, \"f2\": 0.6631620841763125, \"f0_5\": 0.8873258187627585, \"p4\": 0.8586492996350712, \"phi\": 0.7730264468589226}, {\"truth_threshold\": 27.996240999406517, \"match_probability\": 0.9999999962649907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3998.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2540.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6115019917488098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3884980082511902, \"precision\": 1.0, \"recall\": 0.6115019917488098, \"specificity\": 1.0, \"npv\": 0.9769633412361145, \"accuracy\": 0.9777694344520569, \"f1\": 0.7589217919514047, \"f2\": 0.6630182421227198, \"f0_5\": 0.8872614292055038, \"p4\": 0.8585722212990557, \"phi\": 0.7729262958409315}, {\"truth_threshold\": 28.00332789282897, \"match_probability\": 0.9999999962832931, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3995.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2543.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6110431551933289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38895687460899353, \"precision\": 1.0, \"recall\": 0.6110431551933289, \"specificity\": 1.0, \"npv\": 0.9769367575645447, \"accuracy\": 0.9777431488037109, \"f1\": 0.7585683091237064, \"f2\": 0.6625866587056756, \"f0_5\": 0.8870681232791544, \"p4\": 0.8583408430548581, \"phi\": 0.7726257183468777}, {\"truth_threshold\": 28.011913633982907, \"match_probability\": 0.9999999963053461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3992.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2546.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6105842590332031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3894157111644745, \"precision\": 1.0, \"recall\": 0.6105842590332031, \"specificity\": 1.0, \"npv\": 0.9769101738929749, \"accuracy\": 0.9777169227600098, \"f1\": 0.7582146248812915, \"f2\": 0.6621549893842887, \"f0_5\": 0.8868746112147872, \"p4\": 0.8581092497102074, \"phi\": 0.7723250402377952}, {\"truth_threshold\": 28.0177134423648, \"match_probability\": 0.9999999963201692, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3991.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2547.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6104313135147095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3895686864852905, \"precision\": 1.0, \"recall\": 0.6104313135147095, \"specificity\": 1.0, \"npv\": 0.9769012928009033, \"accuracy\": 0.9777081608772278, \"f1\": 0.758096685345237, \"f2\": 0.662011080516206, \"f0_5\": 0.886810061327882, \"p4\": 0.8580320040737679, \"phi\": 0.7722248109821251}, {\"truth_threshold\": 28.025816729464346, \"match_probability\": 0.9999999963407801, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3987.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2551.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6098195314407349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39018046855926514, \"precision\": 1.0, \"recall\": 0.6098195314407349, \"specificity\": 1.0, \"npv\": 0.9768658876419067, \"accuracy\": 0.9776731133460999, \"f1\": 0.757624703087886, \"f2\": 0.6614353495470985, \"f0_5\": 0.8865516321266566, \"p4\": 0.8577227819399225, \"phi\": 0.7718237244827935}, {\"truth_threshold\": 28.055943287836403, \"match_probability\": 0.9999999964164001, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3985.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2553.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6095136404037476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39048638939857483, \"precision\": 1.0, \"recall\": 0.6095136404037476, \"specificity\": 1.0, \"npv\": 0.9768481850624084, \"accuracy\": 0.9776556491851807, \"f1\": 0.7573885774018816, \"f2\": 0.6611474267511697, \"f0_5\": 0.8864222795622386, \"p4\": 0.857568026955216, \"phi\": 0.7716231427304209}, {\"truth_threshold\": 28.06124849461163, \"match_probability\": 0.9999999964295538, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3981.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2557.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6089017987251282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3910982012748718, \"precision\": 1.0, \"recall\": 0.6089017987251282, \"specificity\": 1.0, \"npv\": 0.9768127202987671, \"accuracy\": 0.9776206016540527, \"f1\": 0.7569160566593782, \"f2\": 0.6605714664985232, \"f0_5\": 0.8861632980144244, \"p4\": 0.857258228678154, \"phi\": 0.7712217870130799}, {\"truth_threshold\": 28.083123012527185, \"match_probability\": 0.9999999964832815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3978.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2560.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6084429621696472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3915570378303528, \"precision\": 1.0, \"recall\": 0.6084429621696472, \"specificity\": 1.0, \"npv\": 0.9767861366271973, \"accuracy\": 0.9775943756103516, \"f1\": 0.7565614302015976, \"f2\": 0.6601393959508796, \"f0_5\": 0.8859688195991091, \"p4\": 0.8570256273286085, \"phi\": 0.7709206378263606}, {\"truth_threshold\": 28.087993046949492, \"match_probability\": 0.9999999964951327, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3977.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2561.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6082900166511536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3917100131511688, \"precision\": 1.0, \"recall\": 0.6082900166511536, \"specificity\": 1.0, \"npv\": 0.9767773151397705, \"accuracy\": 0.9775856137275696, \"f1\": 0.7564431764146458, \"f2\": 0.6599953533140828, \"f0_5\": 0.8859039472511806, \"p4\": 0.856948045360007, \"phi\": 0.7708202514533881}, {\"truth_threshold\": 28.106573263076744, \"match_probability\": 0.999999996539982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3975.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2563.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6079840660095215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39201590418815613, \"precision\": 1.0, \"recall\": 0.6079840660095215, \"specificity\": 1.0, \"npv\": 0.9767595529556274, \"accuracy\": 0.9775680899620056, \"f1\": 0.7562066013507086, \"f2\": 0.6597072393534039, \"f0_5\": 0.885774133166949, \"p4\": 0.8567928090734785, \"phi\": 0.770619444939712}, {\"truth_threshold\": 28.115565416006053, \"match_probability\": 0.9999999965614808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3974.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2564.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6078311204910278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3921688497066498, \"precision\": 1.0, \"recall\": 0.6078311204910278, \"specificity\": 1.0, \"npv\": 0.9767507314682007, \"accuracy\": 0.9775593876838684, \"f1\": 0.7560882800608828, \"f2\": 0.6595631680276174, \"f0_5\": 0.8857091914059018, \"p4\": 0.8567151547317924, \"phi\": 0.7705189671913475}, {\"truth_threshold\": 28.118121848461122, \"match_probability\": 0.9999999965675683, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3972.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2566.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6075252294540405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3924747705459595, \"precision\": 1.0, \"recall\": 0.6075252294540405, \"specificity\": 1.0, \"npv\": 0.9767330288887024, \"accuracy\": 0.9775418639183044, \"f1\": 0.7558515699333967, \"f2\": 0.6592749966803877, \"f0_5\": 0.8855792383840185, \"p4\": 0.8565597735921193, \"phi\": 0.7703180930703655}, {\"truth_threshold\": 28.122649039275775, \"match_probability\": 0.9999999965783225, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3971.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2567.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6073722839355469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3926277160644531, \"precision\": 1.0, \"recall\": 0.6073722839355469, \"specificity\": 1.0, \"npv\": 0.9767241477966309, \"accuracy\": 0.9775331020355225, \"f1\": 0.7557331810828813, \"f2\": 0.6591308966570395, \"f0_5\": 0.8855142270983856, \"p4\": 0.8564820467703264, \"phi\": 0.7702176390970545}, {\"truth_threshold\": 28.129080662486313, \"match_probability\": 0.9999999965935426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3970.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2568.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6072193384170532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3927806615829468, \"precision\": 1.0, \"recall\": 0.6072193384170532, \"specificity\": 1.0, \"npv\": 0.9767153263092041, \"accuracy\": 0.9775243401527405, \"f1\": 0.7556147696992768, \"f2\": 0.6589867870659318, \"f0_5\": 0.8854491926130788, \"p4\": 0.8564042957646788, \"phi\": 0.7701171162158551}, {\"truth_threshold\": 28.157546437996302, \"match_probability\": 0.9999999966600965, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3969.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2569.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6070663928985596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39293360710144043, \"precision\": 1.0, \"recall\": 0.6070663928985596, \"specificity\": 1.0, \"npv\": 0.9767064452171326, \"accuracy\": 0.9775155782699585, \"f1\": 0.7554963357761493, \"f2\": 0.658842667906112, \"f0_5\": 0.8853841349156777, \"p4\": 0.8563265205632541, \"phi\": 0.770016639668757}, {\"truth_threshold\": 28.161322439344367, \"match_probability\": 0.9999999966688267, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3968.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2570.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6069134473800659, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39308658242225647, \"precision\": 1.0, \"recall\": 0.6069134473800659, \"specificity\": 1.0, \"npv\": 0.976697564125061, \"accuracy\": 0.9775068759918213, \"f1\": 0.7553778793070627, \"f2\": 0.6586985391766268, \"f0_5\": 0.8853190539937528, \"p4\": 0.8562487211541217, \"phi\": 0.7699161518315607}, {\"truth_threshold\": 28.163546251888228, \"match_probability\": 0.9999999966739576, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3967.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2571.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6067605018615723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3932395279407501, \"precision\": 1.0, \"recall\": 0.6067605018615723, \"specificity\": 1.0, \"npv\": 0.9766887426376343, \"accuracy\": 0.9774981141090393, \"f1\": 0.7552594002855783, \"f2\": 0.6585544008765232, \"f0_5\": 0.8852539498348656, \"p4\": 0.8561708975253434, \"phi\": 0.7698156526997958}, {\"truth_threshold\": 28.172128524335164, \"match_probability\": 0.9999999966936847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3963.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2575.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6061486601829529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3938513398170471, \"precision\": 1.0, \"recall\": 0.6061486601829529, \"specificity\": 1.0, \"npv\": 0.9766533374786377, \"accuracy\": 0.9774630665779114, \"f1\": 0.7547852585468051, \"f2\": 0.6579777519508551, \"f0_5\": 0.8849933005806163, \"p4\": 0.855859360574732, \"phi\": 0.7694134854617637}, {\"truth_threshold\": 28.174140455006494, \"match_probability\": 0.9999999966982923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3962.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2576.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6059957146644592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39400428533554077, \"precision\": 1.0, \"recall\": 0.6059957146644592, \"specificity\": 1.0, \"npv\": 0.9766444563865662, \"accuracy\": 0.9774543642997742, \"f1\": 0.7546666666666667, \"f2\": 0.6578335657833566, \"f0_5\": 0.8849280800500313, \"p4\": 0.855781415668376, \"phi\": 0.7693129297829762}, {\"truth_threshold\": 28.184575775078017, \"match_probability\": 0.9999999967220881, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3960.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2578.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6056898236274719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3943101763725281, \"precision\": 1.0, \"recall\": 0.6056898236274719, \"specificity\": 1.0, \"npv\": 0.9766267538070679, \"accuracy\": 0.9774368405342102, \"f1\": 0.7544294151266908, \"f2\": 0.6575451647183846, \"f0_5\": 0.8847975690410225, \"p4\": 0.8556254529693497, \"phi\": 0.7691117267597165}, {\"truth_threshold\": 28.1932019289156, \"match_probability\": 0.9999999967416289, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3959.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2579.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6055368781089783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3944631516933441, \"precision\": 1.0, \"recall\": 0.6055368781089783, \"specificity\": 1.0, \"npv\": 0.9766178727149963, \"accuracy\": 0.9774280786514282, \"f1\": 0.7543107554539392, \"f2\": 0.657400949819003, \"f0_5\": 0.8847322785375883, \"p4\": 0.855547435152685, \"phi\": 0.769011137096061}, {\"truth_threshold\": 28.20347213472196, \"match_probability\": 0.9999999967647422, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3958.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2580.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6053839325904846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39461609721183777, \"precision\": 1.0, \"recall\": 0.6053839325904846, \"specificity\": 1.0, \"npv\": 0.9766090512275696, \"accuracy\": 0.9774193167686462, \"f1\": 0.7541920731707317, \"f2\": 0.6572567253404185, \"f0_5\": 0.8846669646848457, \"p4\": 0.8554693930085767, \"phi\": 0.7689105360974662}, {\"truth_threshold\": 28.22264146621819, \"match_probability\": 0.9999999968074452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3952.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2586.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6044661998748779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39553380012512207, \"precision\": 1.0, \"recall\": 0.6044661998748779, \"specificity\": 1.0, \"npv\": 0.9765558838844299, \"accuracy\": 0.9773668050765991, \"f1\": 0.7534795042897998, \"f2\": 0.6563911772521924, \"f0_5\": 0.8842745905307438, \"p4\": 0.8550006285941026, \"phi\": 0.7683065763138128}, {\"truth_threshold\": 28.24386672641603, \"match_probability\": 0.9999999968540709, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3949.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2589.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.604007363319397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3959926664829254, \"precision\": 1.0, \"recall\": 0.604007363319397, \"specificity\": 1.0, \"npv\": 0.9765293598175049, \"accuracy\": 0.977340579032898, \"f1\": 0.7531229140841041, \"f2\": 0.6559582738115013, \"f0_5\": 0.884078087221277, \"p4\": 0.8547659169912186, \"phi\": 0.768004500746026}, {\"truth_threshold\": 28.259114749445427, \"match_probability\": 0.9999999968871456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3948.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2590.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6038544178009033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39614561200141907, \"precision\": 1.0, \"recall\": 0.6038544178009033, \"specificity\": 1.0, \"npv\": 0.9765204787254333, \"accuracy\": 0.977331817150116, \"f1\": 0.753004005340454, \"f2\": 0.6558139534883721, \"f0_5\": 0.8840125391849529, \"p4\": 0.8546876309104322, \"phi\": 0.7679037861359972}, {\"truth_threshold\": 28.28293325743165, \"match_probability\": 0.999999996938116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3947.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2591.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6037014126777649, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3962985575199127, \"precision\": 1.0, \"recall\": 0.6037014126777649, \"specificity\": 1.0, \"npv\": 0.9765116572380066, \"accuracy\": 0.977323055267334, \"f1\": 0.7528850739151168, \"f2\": 0.655669623575534, \"f0_5\": 0.883946967661023, \"p4\": 0.8546093203695795, \"phi\": 0.7678030023530158}, {\"truth_threshold\": 28.300492541733533, \"match_probability\": 0.999999996975157, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3945.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2593.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6033955216407776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3966044783592224, \"precision\": 1.0, \"recall\": 0.6033955216407776, \"specificity\": 1.0, \"npv\": 0.9764939546585083, \"accuracy\": 0.97730553150177, \"f1\": 0.752647142993418, \"f2\": 0.655380934976908, \"f0_5\": 0.8838157540998297, \"p4\": 0.8544526258592495, \"phi\": 0.767601516177739}, {\"truth_threshold\": 28.342774853640275, \"match_probability\": 0.9999999970625221, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3943.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2595.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6030896306037903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3969103693962097, \"precision\": 1.0, \"recall\": 0.6030896306037903, \"specificity\": 1.0, \"npv\": 0.97647625207901, \"accuracy\": 0.9772880673408508, \"f1\": 0.7524091212670547, \"f2\": 0.6550922080079747, \"f0_5\": 0.8836844464365755, \"p4\": 0.8542958333632984, \"phi\": 0.7673999844096676}, {\"truth_threshold\": 28.36687052925774, \"match_probability\": 0.9999999971111759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3941.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2597.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.602783739566803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.397216260433197, \"precision\": 1.0, \"recall\": 0.602783739566803, \"specificity\": 1.0, \"npv\": 0.9764585494995117, \"accuracy\": 0.9772705435752869, \"f1\": 0.7521710086840347, \"f2\": 0.6548034426610839, \"f0_5\": 0.8835530445699937, \"p4\": 0.854138942784668, \"phi\": 0.7671983491817154}, {\"truth_threshold\": 28.381114460599942, \"match_probability\": 0.9999999971395575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3940.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2598.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6026307940483093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39736923575401306, \"precision\": 1.0, \"recall\": 0.6026307940483093, \"specificity\": 1.0, \"npv\": 0.9764496684074402, \"accuracy\": 0.9772617816925049, \"f1\": 0.75205191830502, \"f2\": 0.6546590455935132, \"f0_5\": 0.8834873082787694, \"p4\": 0.8540604606839822, \"phi\": 0.767097543353757}, {\"truth_threshold\": 28.384444762760914, \"match_probability\": 0.9999999971461528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3937.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2601.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6021718978881836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.397828072309494, \"precision\": 1.0, \"recall\": 0.6021718978881836, \"specificity\": 1.0, \"npv\": 0.9764231443405151, \"accuracy\": 0.9772355556488037, \"f1\": 0.7516945107398568, \"f2\": 0.6542257968028183, \"f0_5\": 0.8832899578210536, \"p4\": 0.8538248669904956, \"phi\": 0.766794999467021}, {\"truth_threshold\": 28.39399187225683, \"match_probability\": 0.9999999971649759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3936.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2602.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6020189523696899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39798104763031006, \"precision\": 1.0, \"recall\": 0.6020189523696899, \"specificity\": 1.0, \"npv\": 0.9764142632484436, \"accuracy\": 0.9772267937660217, \"f1\": 0.7515753293870536, \"f2\": 0.6540813613400691, \"f0_5\": 0.883224127098106, \"p4\": 0.8537462865882691, \"phi\": 0.7666941479209324}, {\"truth_threshold\": 28.403397547869716, \"match_probability\": 0.9999999971833988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3933.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2605.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.601560115814209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.398439884185791, \"precision\": 1.0, \"recall\": 0.601560115814209, \"specificity\": 1.0, \"npv\": 0.9763877391815186, \"accuracy\": 0.9772005081176758, \"f1\": 0.7512176487441505, \"f2\": 0.6536479973408675, \"f0_5\": 0.883026493039964, \"p4\": 0.8535103976977018, \"phi\": 0.7663914667419781}, {\"truth_threshold\": 28.406278448950836, \"match_probability\": 0.9999999971890177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3932.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2606.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6014071702957153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39859282970428467, \"precision\": 1.0, \"recall\": 0.6014071702957153, \"specificity\": 1.0, \"npv\": 0.976378858089447, \"accuracy\": 0.9771917462348938, \"f1\": 0.751098376313276, \"f2\": 0.653503523467624, \"f0_5\": 0.8829605676816671, \"p4\": 0.853431718798855, \"phi\": 0.7662905694047347}, {\"truth_threshold\": 28.40786858148439, \"match_probability\": 0.9999999971921142, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3931.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2607.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6012542247772217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3987458050251007, \"precision\": 1.0, \"recall\": 0.6012542247772217, \"specificity\": 1.0, \"npv\": 0.9763700366020203, \"accuracy\": 0.9771830439567566, \"f1\": 0.7509790810965709, \"f2\": 0.6533590399893627, \"f0_5\": 0.8828946186326475, \"p4\": 0.8533530152453115, \"phi\": 0.766189660610046}, {\"truth_threshold\": 28.413524504896575, \"match_probability\": 0.9999999972031006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3928.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2610.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.600795328617096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39920464158058167, \"precision\": 1.0, \"recall\": 0.600795328617096, \"specificity\": 1.0, \"npv\": 0.9763434529304504, \"accuracy\": 0.9771567583084106, \"f1\": 0.750621058666157, \"f2\": 0.6529255319148937, \"f0_5\": 0.8826966292134831, \"p4\": 0.8531167565341332, \"phi\": 0.7658868075125552}, {\"truth_threshold\": 28.414039120661617, \"match_probability\": 0.9999999972040982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3927.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2611.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6006423830986023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3993575870990753, \"precision\": 1.0, \"recall\": 0.6006423830986023, \"specificity\": 1.0, \"npv\": 0.9763346314430237, \"accuracy\": 0.9771479964256287, \"f1\": 0.7505016722408027, \"f2\": 0.6527810100069816, \"f0_5\": 0.882630585273757, \"p4\": 0.8530379542393945, \"phi\": 0.7657858528351709}, {\"truth_threshold\": 28.41730067220245, \"match_probability\": 0.9999999972104118, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3926.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2612.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6004894375801086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39951056241989136, \"precision\": 1.0, \"recall\": 0.6004894375801086, \"specificity\": 1.0, \"npv\": 0.9763258099555969, \"accuracy\": 0.9771392345428467, \"f1\": 0.7503822629969419, \"f2\": 0.6526364784892612, \"f0_5\": 0.8825645175793544, \"p4\": 0.8529591272287145, \"phi\": 0.7656848866774228}, {\"truth_threshold\": 28.420149034511482, \"match_probability\": 0.9999999972159139, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3925.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2613.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.600336492061615, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.399663507938385, \"precision\": 1.0, \"recall\": 0.600336492061615, \"specificity\": 1.0, \"npv\": 0.9763169288635254, \"accuracy\": 0.9771305322647095, \"f1\": 0.7502628309280321, \"f2\": 0.652491937360774, \"f0_5\": 0.8824984261174567, \"p4\": 0.8528802754898196, \"phi\": 0.7655839090347192}, {\"truth_threshold\": 28.422846734929013, \"match_probability\": 0.999999997221115, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3924.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2614.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.6001835465431213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39981645345687866, \"precision\": 1.0, \"recall\": 0.6001835465431213, \"specificity\": 1.0, \"npv\": 0.9763081073760986, \"accuracy\": 0.9771217703819275, \"f1\": 0.7501433760275282, \"f2\": 0.6523473866205612, \"f0_5\": 0.8824323108752361, \"p4\": 0.8528013990104287, \"phi\": 0.7654828619510358}, {\"truth_threshold\": 28.425153573619923, \"match_probability\": 0.9999999972255549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3918.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2620.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5992658138275146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40073415637016296, \"precision\": 1.0, \"recall\": 0.5992658138275146, \"specificity\": 1.0, \"npv\": 0.9762549996376038, \"accuracy\": 0.9770692586898804, \"f1\": 0.7494261667941852, \"f2\": 0.6514798802793482, \"f0_5\": 0.8820351193156236, \"p4\": 0.852327619894882, \"phi\": 0.7648766275822798}, {\"truth_threshold\": 28.42671295069673, \"match_probability\": 0.999999997228552, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3916.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2622.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5989599227905273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40104007720947266, \"precision\": 1.0, \"recall\": 0.5989599227905273, \"specificity\": 1.0, \"npv\": 0.9762372970581055, \"accuracy\": 0.9770517349243164, \"f1\": 0.749186914099866, \"f2\": 0.6511906345616603, \"f0_5\": 0.8819025313034862, \"p4\": 0.8521694950409895, \"phi\": 0.7646744766512789}, {\"truth_threshold\": 28.428154497213864, \"match_probability\": 0.9999999972313199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3915.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2623.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5988069772720337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4011930227279663, \"precision\": 1.0, \"recall\": 0.5988069772720337, \"specificity\": 1.0, \"npv\": 0.9762284755706787, \"accuracy\": 0.9770429730415344, \"f1\": 0.7490672534200707, \"f2\": 0.6510459972727575, \"f0_5\": 0.881836201459591, \"p4\": 0.8520903953431279, \"phi\": 0.76457332587589}, {\"truth_threshold\": 28.431269014064465, \"match_probability\": 0.9999999972372906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3913.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2625.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5985010862350464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.401498943567276, \"precision\": 1.0, \"recall\": 0.5985010862350464, \"specificity\": 1.0, \"npv\": 0.9762107729911804, \"accuracy\": 0.9770254492759705, \"f1\": 0.7488278633623576, \"f2\": 0.6507566938300349, \"f0_5\": 0.8817034700315457, \"p4\": 0.8519321213437594, \"phi\": 0.7643711057304575}, {\"truth_threshold\": 28.43395086671377, \"match_probability\": 0.9999999972424215, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3912.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2626.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5983481407165527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40165188908576965, \"precision\": 1.0, \"recall\": 0.5983481407165527, \"specificity\": 1.0, \"npv\": 0.9762018918991089, \"accuracy\": 0.9770167469978333, \"f1\": 0.7487081339712919, \"f2\": 0.6506120276742948, \"f0_5\": 0.8816370684215271, \"p4\": 0.8518529470175019, \"phi\": 0.7642699783426657}, {\"truth_threshold\": 28.43814794276714, \"match_probability\": 0.9999999972504321, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3911.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2627.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5981951951980591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4018048346042633, \"precision\": 1.0, \"recall\": 0.5981951951980591, \"specificity\": 1.0, \"npv\": 0.9761930704116821, \"accuracy\": 0.9770079851150513, \"f1\": 0.7485883816633171, \"f2\": 0.6504673518943552, \"f0_5\": 0.8815706428635831, \"p4\": 0.8517737477903484, \"phi\": 0.7641688394053135}, {\"truth_threshold\": 28.45118571687977, \"match_probability\": 0.9999999972751683, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3910.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2628.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5980421900749207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40195778012275696, \"precision\": 1.0, \"recall\": 0.5980421900749207, \"specificity\": 1.0, \"npv\": 0.9761841893196106, \"accuracy\": 0.9769992232322693, \"f1\": 0.748468606431853, \"f2\": 0.6503226664892555, \"f0_5\": 0.881504193344756, \"p4\": 0.851694523649903, \"phi\": 0.7640676308623618}, {\"truth_threshold\": 28.454258108220408, \"match_probability\": 0.999999997280965, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3909.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2629.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.597889244556427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4021107256412506, \"precision\": 1.0, \"recall\": 0.597889244556427, \"specificity\": 1.0, \"npv\": 0.9761753678321838, \"accuracy\": 0.9769904613494873, \"f1\": 0.7483488082703168, \"f2\": 0.6501779714580354, \"f0_5\": 0.881437719852079, \"p4\": 0.8516152745837616, \"phi\": 0.7639664688048151}, {\"truth_threshold\": 28.48001991668348, \"match_probability\": 0.9999999973290871, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3908.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2630.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5977362990379333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40226370096206665, \"precision\": 1.0, \"recall\": 0.5977362990379333, \"specificity\": 1.0, \"npv\": 0.9761665463447571, \"accuracy\": 0.9769816994667053, \"f1\": 0.7482289871721233, \"f2\": 0.6500332667997338, \"f0_5\": 0.8813712223725756, \"p4\": 0.8515360005795122, \"phi\": 0.7638652951837877}, {\"truth_threshold\": 28.48659477380916, \"match_probability\": 0.9999999973412317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3907.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2631.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5975833535194397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4024166464805603, \"precision\": 1.0, \"recall\": 0.5975833535194397, \"specificity\": 1.0, \"npv\": 0.9761576652526855, \"accuracy\": 0.9769729375839233, \"f1\": 0.7481091431306846, \"f2\": 0.6498885525133903, \"f0_5\": 0.88130470089326, \"p4\": 0.8514567016247342, \"phi\": 0.7637641099946338}, {\"truth_threshold\": 28.48729719306059, \"match_probability\": 0.9999999973425259, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3906.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2632.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.597430408000946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40256959199905396, \"precision\": 1.0, \"recall\": 0.597430408000946, \"specificity\": 1.0, \"npv\": 0.9761488437652588, \"accuracy\": 0.9769642353057861, \"f1\": 0.7479892761394102, \"f2\": 0.6497438285980438, \"f0_5\": 0.881238155401137, \"p4\": 0.8513773777069991, \"phi\": 0.7636628551526391}, {\"truth_threshold\": 28.511590106362533, \"match_probability\": 0.9999999973868993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3905.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2633.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5972774624824524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4027225375175476, \"precision\": 1.0, \"recall\": 0.5972774624824524, \"specificity\": 1.0, \"npv\": 0.9761399626731873, \"accuracy\": 0.9769554734230042, \"f1\": 0.7478693861917074, \"f2\": 0.6495990950527332, \"f0_5\": 0.8811715858832024, \"p4\": 0.8512980288138696, \"phi\": 0.7635616468061126}, {\"truth_threshold\": 28.526422214395293, \"match_probability\": 0.9999999974136264, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3903.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2635.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5969715714454651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4030284583568573, \"precision\": 1.0, \"recall\": 0.5969715714454651, \"specificity\": 1.0, \"npv\": 0.9761223196983337, \"accuracy\": 0.9769379496574402, \"f1\": 0.7476295374006321, \"f2\": 0.6493095990683746, \"f0_5\": 0.881038374717833, \"p4\": 0.8511392560516392, \"phi\": 0.7633591953621551}, {\"truth_threshold\": 28.54235594635611, \"match_probability\": 0.9999999974420343, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3902.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2636.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5968186259269714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40318140387535095, \"precision\": 1.0, \"recall\": 0.5968186259269714, \"specificity\": 1.0, \"npv\": 0.9761134386062622, \"accuracy\": 0.9769291877746582, \"f1\": 0.7475095785440613, \"f2\": 0.649164836627404, \"f0_5\": 0.8809717330443421, \"p4\": 0.851059832157623, \"phi\": 0.7632579522554069}, {\"truth_threshold\": 28.544605762571113, \"match_probability\": 0.9999999974460202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3901.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2637.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.596665620803833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4033343493938446, \"precision\": 1.0, \"recall\": 0.596665620803833, \"specificity\": 1.0, \"npv\": 0.9761046171188354, \"accuracy\": 0.9769204258918762, \"f1\": 0.7473895967046652, \"f2\": 0.6490200645526237, \"f0_5\": 0.8809050672929275, \"p4\": 0.8509803832383823, \"phi\": 0.7631566394366359}, {\"truth_threshold\": 28.55203849975345, \"match_probability\": 0.9999999974591445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3900.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2638.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5965126752853394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40348729491233826, \"precision\": 1.0, \"recall\": 0.5965126752853394, \"specificity\": 1.0, \"npv\": 0.9760957360267639, \"accuracy\": 0.976911723613739, \"f1\": 0.7472695918758383, \"f2\": 0.648875282843072, \"f0_5\": 0.8808383774505375, \"p4\": 0.8509009092814388, \"phi\": 0.7630553731259085}, {\"truth_threshold\": 28.55620878140685, \"match_probability\": 0.9999999974664785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3896.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2642.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5959008932113647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40409910678863525, \"precision\": 1.0, \"recall\": 0.5959008932113647, \"specificity\": 1.0, \"npv\": 0.9760603904724121, \"accuracy\": 0.9768766760826111, \"f1\": 0.7467893425340234, \"f2\": 0.6482960596379127, \"f0_5\": 0.8805713769098635, \"p4\": 0.8505827628267802, \"phi\": 0.7626501336303291}, {\"truth_threshold\": 28.557652558261417, \"match_probability\": 0.9999999974690127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3895.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2643.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5957479476928711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4042520523071289, \"precision\": 1.0, \"recall\": 0.5957479476928711, \"specificity\": 1.0, \"npv\": 0.9760515689849854, \"accuracy\": 0.9768679141998291, \"f1\": 0.7466692226588709, \"f2\": 0.6481512297400739, \"f0_5\": 0.8805045664164933, \"p4\": 0.8505031634938579, \"phi\": 0.7625488092386434}, {\"truth_threshold\": 28.57229715719506, \"match_probability\": 0.9999999974945744, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3894.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2644.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5955950021743774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40440502762794495, \"precision\": 1.0, \"recall\": 0.5955950021743774, \"specificity\": 1.0, \"npv\": 0.9760426878929138, \"accuracy\": 0.9768592119216919, \"f1\": 0.7465490797546013, \"f2\": 0.6480063902016907, \"f0_5\": 0.8804377317536403, \"p4\": 0.8504235390481887, \"phi\": 0.7624474732181628}, {\"truth_threshold\": 28.578715808082247, \"match_probability\": 0.9999999975056965, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3893.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2645.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5954420566558838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4045579731464386, \"precision\": 1.0, \"recall\": 0.5954420566558838, \"specificity\": 1.0, \"npv\": 0.9760338664054871, \"accuracy\": 0.9768504500389099, \"f1\": 0.7464289138145911, \"f2\": 0.6478615410218006, \"f0_5\": 0.8803708729081864, \"p4\": 0.8503438894772363, \"phi\": 0.7623461255642}, {\"truth_threshold\": 28.588276282693723, \"match_probability\": 0.9999999975221711, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3892.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2646.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5952890515327454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40471091866493225, \"precision\": 1.0, \"recall\": 0.5952890515327454, \"specificity\": 1.0, \"npv\": 0.9760249853134155, \"accuracy\": 0.9768416881561279, \"f1\": 0.7463087248322148, \"f2\": 0.6477166821994408, \"f0_5\": 0.8803039898670044, \"p4\": 0.8502642147684557, \"phi\": 0.7622447080913217}, {\"truth_threshold\": 28.590041943615752, \"match_probability\": 0.9999999975252017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3890.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2648.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5949831604957581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40501683950424194, \"precision\": 1.0, \"recall\": 0.5949831604957581, \"specificity\": 1.0, \"npv\": 0.976007342338562, \"accuracy\": 0.976824164390564, \"f1\": 0.7460682777138473, \"f2\": 0.6474269356234605, \"f0_5\": 0.8801701511448999, \"p4\": 0.8501047898871894, \"phi\": 0.7620419545593305}, {\"truth_threshold\": 28.596507529516867, \"match_probability\": 0.999999997536268, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3889.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2649.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5948302149772644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4051697850227356, \"precision\": 1.0, \"recall\": 0.5948302149772644, \"specificity\": 1.0, \"npv\": 0.9759984612464905, \"accuracy\": 0.976815402507782, \"f1\": 0.7459480195645919, \"f2\": 0.6472820478679139, \"f0_5\": 0.8801031954376753, \"p4\": 0.8500250396895723, \"phi\": 0.7619405603172883}, {\"truth_threshold\": 28.598932283698527, \"match_probability\": 0.9999999975404054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3888.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2650.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5946772694587708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40532273054122925, \"precision\": 1.0, \"recall\": 0.5946772694587708, \"specificity\": 1.0, \"npv\": 0.9759896397590637, \"accuracy\": 0.9768067002296448, \"f1\": 0.7458277383464416, \"f2\": 0.6471371504660453, \"f0_5\": 0.8800362154821186, \"p4\": 0.8499452643038645, \"phi\": 0.7618390962086703}, {\"truth_threshold\": 28.600145476226125, \"match_probability\": 0.9999999975424728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3886.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2652.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5943713784217834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40562862157821655, \"precision\": 1.0, \"recall\": 0.5943713784217834, \"specificity\": 1.0, \"npv\": 0.9759719371795654, \"accuracy\": 0.9767891764640808, \"f1\": 0.7455871066768994, \"f2\": 0.6468473267194886, \"f0_5\": 0.8799021827732996, \"p4\": 0.849785637917822, \"phi\": 0.7616362494064776}, {\"truth_threshold\": 28.608063444299443, \"match_probability\": 0.9999999975559236, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3884.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2654.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5940654873847961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40593454241752625, \"precision\": 1.0, \"recall\": 0.5940654873847961, \"specificity\": 1.0, \"npv\": 0.9759542346000671, \"accuracy\": 0.9767716526985168, \"f1\": 0.7453463826520821, \"f2\": 0.6465574643760821, \"f0_5\": 0.8797680529129293, \"p4\": 0.8496259106282685, \"phi\": 0.7614333559199022}, {\"truth_threshold\": 28.60956640283664, \"match_probability\": 0.9999999975584684, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3883.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2655.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5939124822616577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4060874879360199, \"precision\": 1.0, \"recall\": 0.5939124822616577, \"specificity\": 1.0, \"npv\": 0.9759454131126404, \"accuracy\": 0.9767628908157349, \"f1\": 0.7452259859898283, \"f2\": 0.6464125187281505, \"f0_5\": 0.8797009515178976, \"p4\": 0.8495460091131407, \"phi\": 0.7613318334124279}, {\"truth_threshold\": 28.610741024934615, \"match_probability\": 0.9999999975604554, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3882.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2656.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5937595367431641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40624043345451355, \"precision\": 1.0, \"recall\": 0.5937595367431641, \"specificity\": 1.0, \"npv\": 0.9759365916252136, \"accuracy\": 0.9767541885375977, \"f1\": 0.74510556621881, \"f2\": 0.6462675634281148, \"f0_5\": 0.8796338257953412, \"p4\": 0.8494660823342767, \"phi\": 0.7612303574582229}, {\"truth_threshold\": 28.6183378082423, \"match_probability\": 0.9999999975732676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3880.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2658.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5934536457061768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40654635429382324, \"precision\": 1.0, \"recall\": 0.5934536457061768, \"specificity\": 1.0, \"npv\": 0.9759188890457153, \"accuracy\": 0.9767366647720337, \"f1\": 0.7448646573238625, \"f2\": 0.6459776238678743, \"f0_5\": 0.8794995013147158, \"p4\": 0.8493061529347844, \"phi\": 0.7610273704751629}, {\"truth_threshold\": 28.630050994448734, \"match_probability\": 0.9999999975928904, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3878.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2660.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5931477546691895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40685224533081055, \"precision\": 1.0, \"recall\": 0.5931477546691895, \"specificity\": 1.0, \"npv\": 0.975901186466217, \"accuracy\": 0.9767191410064697, \"f1\": 0.7446236559139785, \"f2\": 0.6456876456876457, \"f0_5\": 0.8793650793650793, \"p4\": 0.8491461223285948, \"phi\": 0.7608242784124046}, {\"truth_threshold\": 28.630428310593654, \"match_probability\": 0.9999999975935199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3877.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2661.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5929948091506958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4070051908493042, \"precision\": 1.0, \"recall\": 0.5929948091506958, \"specificity\": 1.0, \"npv\": 0.9758923649787903, \"accuracy\": 0.9767103791236877, \"f1\": 0.7445031204992799, \"f2\": 0.6455426421126245, \"f0_5\": 0.8792978318062233, \"p4\": 0.8490660690413276, \"phi\": 0.7607227439537775}, {\"truth_threshold\": 28.632315433525832, \"match_probability\": 0.9999999975966656, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3876.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2662.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5928418636322021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40715816617012024, \"precision\": 1.0, \"recall\": 0.5928418636322021, \"specificity\": 1.0, \"npv\": 0.9758835434913635, \"accuracy\": 0.9767016172409058, \"f1\": 0.7443825619358556, \"f2\": 0.6453976288797123, \"f0_5\": 0.8792305598403048, \"p4\": 0.8489859904143763, \"phi\": 0.7606211977815087}, {\"truth_threshold\": 28.641116128210022, \"match_probability\": 0.9999999976112817, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3874.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2664.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5925359725952148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40746405720710754, \"precision\": 1.0, \"recall\": 0.5925359725952148, \"specificity\": 1.0, \"npv\": 0.9758658409118652, \"accuracy\": 0.9766841530799866, \"f1\": 0.7441413753361505, \"f2\": 0.6451075734363552, \"f0_5\": 0.879095942634111, \"p4\": 0.8488257570906619, \"phi\": 0.7604180119660786}, {\"truth_threshold\": 28.6465523516987, \"match_probability\": 0.9999999976202657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3872.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2666.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5922300219535828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40776994824409485, \"precision\": 1.0, \"recall\": 0.5922300219535828, \"specificity\": 1.0, \"npv\": 0.9758481383323669, \"accuracy\": 0.9766666293144226, \"f1\": 0.7439000960614793, \"f2\": 0.6448174793498535, \"f0_5\": 0.8789612276400618, \"p4\": 0.8486654222558493, \"phi\": 0.7602148375356029}, {\"truth_threshold\": 28.64669859613874, \"match_probability\": 0.999999997620507, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3865.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2673.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5911594033241272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4088406264781952, \"precision\": 1.0, \"recall\": 0.5911594033241272, \"specificity\": 1.0, \"npv\": 0.9757862687110901, \"accuracy\": 0.9766053557395935, \"f1\": 0.7430548880130732, \"f2\": 0.6438018456208149, \"f0_5\": 0.878488953541231, \"p4\": 0.8481034494640387, \"phi\": 0.7595032402983519}, {\"truth_threshold\": 28.647547751420564, \"match_probability\": 0.999999997621907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3864.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2674.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5910063982009888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40899357199668884, \"precision\": 1.0, \"recall\": 0.5910063982009888, \"specificity\": 1.0, \"npv\": 0.9757774472236633, \"accuracy\": 0.9765965938568115, \"f1\": 0.7429340511440108, \"f2\": 0.6436567164179104, \"f0_5\": 0.8784213876511776, \"p4\": 0.8480230657688187, \"phi\": 0.7594015531697503}, {\"truth_threshold\": 28.65668912809848, \"match_probability\": 0.9999999976369278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3863.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2675.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5908534526824951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4091465175151825, \"precision\": 1.0, \"recall\": 0.5908534526824951, \"specificity\": 1.0, \"npv\": 0.9757686257362366, \"accuracy\": 0.9765878915786743, \"f1\": 0.7428131910393232, \"f2\": 0.643511577544561, \"f0_5\": 0.8783537971805366, \"p4\": 0.8479426565683135, \"phi\": 0.7592998542656106}, {\"truth_threshold\": 28.658981513635382, \"match_probability\": 0.9999999976406796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3862.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2676.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5907005071640015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40929949283599854, \"precision\": 1.0, \"recall\": 0.5907005071640015, \"specificity\": 1.0, \"npv\": 0.975759744644165, \"accuracy\": 0.9765791296958923, \"f1\": 0.7426923076923077, \"f2\": 0.6433664289998001, \"f0_5\": 0.8782861821158919, \"p4\": 0.847862221849725, \"phi\": 0.7591981435811503}, {\"truth_threshold\": 28.69025958127338, \"match_probability\": 0.9999999976912799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3859.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2679.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5902416706085205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4097583293914795, \"precision\": 1.0, \"recall\": 0.5902416706085205, \"specificity\": 1.0, \"npv\": 0.9757332801818848, \"accuracy\": 0.9765528440475464, \"f1\": 0.7423295181302298, \"f2\": 0.6429309253273799, \"f0_5\": 0.8780831892236279, \"p4\": 0.8476207644573502, \"phi\": 0.7588928823777326}, {\"truth_threshold\": 28.696389159228556, \"match_probability\": 0.9999999977010682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3857.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2681.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5899357795715332, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4100642502307892, \"precision\": 1.0, \"recall\": 0.5899357795715332, \"specificity\": 1.0, \"npv\": 0.9757155776023865, \"accuracy\": 0.9765353798866272, \"f1\": 0.7420875420875421, \"f2\": 0.642640541170982, \"f0_5\": 0.8779477374123645, \"p4\": 0.847459665036999, \"phi\": 0.7586893548515842}, {\"truth_threshold\": 28.699588497143356, \"match_probability\": 0.9999999977061607, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3856.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2682.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5897828340530396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41021719574928284, \"precision\": 1.0, \"recall\": 0.5897828340530396, \"specificity\": 1.0, \"npv\": 0.9757067561149597, \"accuracy\": 0.9765266180038452, \"f1\": 0.7419665191456609, \"f2\": 0.642495334577446, \"f0_5\": 0.8778799745014115, \"p4\": 0.8473790769406699, \"phi\": 0.7585875733772868}, {\"truth_threshold\": 28.7027028910647, \"match_probability\": 0.9999999977111071, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3855.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2683.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5896298289299011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4103701412677765, \"precision\": 1.0, \"recall\": 0.5896298289299011, \"specificity\": 1.0, \"npv\": 0.9756978750228882, \"accuracy\": 0.9765178561210632, \"f1\": 0.7418454729144617, \"f2\": 0.6423501183057286, \"f0_5\": 0.8778121869022679, \"p4\": 0.8472984632364305, \"phi\": 0.758485721639616}, {\"truth_threshold\": 28.707907447092808, \"match_probability\": 0.9999999977193494, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3852.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2686.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5891709923744202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41082900762557983, \"precision\": 1.0, \"recall\": 0.5891709923744202, \"specificity\": 1.0, \"npv\": 0.9756714105606079, \"accuracy\": 0.9764915704727173, \"f1\": 0.7414821944177094, \"f2\": 0.6419144114118117, \"f0_5\": 0.8776086758406999, \"p4\": 0.847056468347539, \"phi\": 0.7581802708216949}, {\"truth_threshold\": 28.713134336583945, \"match_probability\": 0.9999999977275973, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3850.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2688.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5888651013374329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41113489866256714, \"precision\": 1.0, \"recall\": 0.5888651013374329, \"specificity\": 1.0, \"npv\": 0.9756537079811096, \"accuracy\": 0.9764741063117981, \"f1\": 0.7412398921832885, \"f2\": 0.6416238917405507, \"f0_5\": 0.8774728781110402, \"p4\": 0.8468950101459382, \"phi\": 0.757976519299313}, {\"truth_threshold\": 28.713900112865225, \"match_probability\": 0.9999999977288032, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3847.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2691.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5884062647819519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4115937650203705, \"precision\": 1.0, \"recall\": 0.5884062647819519, \"specificity\": 1.0, \"npv\": 0.9756271839141846, \"accuracy\": 0.9764478206634521, \"f1\": 0.7408762638420799, \"f2\": 0.6411880396013201, \"f0_5\": 0.8772689957128523, \"p4\": 0.8466526301719145, \"phi\": 0.7576708908899685}, {\"truth_threshold\": 28.728112431940694, \"match_probability\": 0.9999999977510674, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3846.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2692.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5882532596588135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41174671053886414, \"precision\": 1.0, \"recall\": 0.5882532596588135, \"specificity\": 1.0, \"npv\": 0.9756183624267578, \"accuracy\": 0.9764390587806702, \"f1\": 0.7407550077041603, \"f2\": 0.6410427361824121, \"f0_5\": 0.8772009853115592, \"p4\": 0.8465717854164403, \"phi\": 0.7575689325299713}, {\"truth_threshold\": 28.733883633894994, \"match_probability\": 0.9999999977600458, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3844.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2694.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5879473686218262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41205260157585144, \"precision\": 1.0, \"recall\": 0.5879473686218262, \"specificity\": 1.0, \"npv\": 0.9756007194519043, \"accuracy\": 0.976421594619751, \"f1\": 0.74051242535157, \"f2\": 0.6407521002800374, \"f0_5\": 0.8770648900246418, \"p4\": 0.8464100186816378, \"phi\": 0.7573650972350298}, {\"truth_threshold\": 28.73567620424842, \"match_probability\": 0.9999999977628272, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3843.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2695.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5877944231033325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4122055768966675, \"precision\": 1.0, \"recall\": 0.5877944231033325, \"specificity\": 1.0, \"npv\": 0.9755918383598328, \"accuracy\": 0.976412832736969, \"f1\": 0.7403910991233985, \"f2\": 0.6406067677946324, \"f0_5\": 0.8769968051118211, \"p4\": 0.8463290966763943, \"phi\": 0.7572631617822958}, {\"truth_threshold\": 28.740293486995178, \"match_probability\": 0.9999999977699758, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3842.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2696.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5876414775848389, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41235852241516113, \"precision\": 1.0, \"recall\": 0.5876414775848389, \"specificity\": 1.0, \"npv\": 0.975583016872406, \"accuracy\": 0.976404070854187, \"f1\": 0.7402697495183044, \"f2\": 0.640461425618457, \"f0_5\": 0.8769286953346115, \"p4\": 0.8462481488952981, \"phi\": 0.7571611559080843}, {\"truth_threshold\": 28.759102955727652, \"match_probability\": 0.9999999977988615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3841.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2697.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5874885320663452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4125114679336548, \"precision\": 1.0, \"recall\": 0.5874885320663452, \"specificity\": 1.0, \"npv\": 0.9755741953849792, \"accuracy\": 0.976395308971405, \"f1\": 0.7401483765295308, \"f2\": 0.6403160737505418, \"f0_5\": 0.87686056067939, \"p4\": 0.8461671753253698, \"phi\": 0.7570591966898776}, {\"truth_threshold\": 28.773780596271845, \"match_probability\": 0.9999999978211419, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3840.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2698.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5873355865478516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41266441345214844, \"precision\": 1.0, \"recall\": 0.5873355865478516, \"specificity\": 1.0, \"npv\": 0.9755653738975525, \"accuracy\": 0.976386547088623, \"f1\": 0.740026980150318, \"f2\": 0.6401707121899173, \"f0_5\": 0.8767924011325235, \"p4\": 0.8460861759536213, \"phi\": 0.7569572255853338}, {\"truth_threshold\": 28.776078949734387, \"match_probability\": 0.9999999978246102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3838.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2700.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5870296955108643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41297033429145813, \"precision\": 1.0, \"recall\": 0.5870296955108643, \"specificity\": 1.0, \"npv\": 0.9755476713180542, \"accuracy\": 0.9763690829277039, \"f1\": 0.7397841171935235, \"f2\": 0.6398799599866623, \"f0_5\": 0.8766560073092736, \"p4\": 0.845924099752668, \"phi\": 0.7567532476978144}, {\"truth_threshold\": 28.776550478958242, \"match_probability\": 0.9999999978253211, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3835.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2703.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5865707993507385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4134291708469391, \"precision\": 1.0, \"recall\": 0.5865707993507385, \"specificity\": 1.0, \"npv\": 0.9755212068557739, \"accuracy\": 0.9763427972793579, \"f1\": 0.7394196471608985, \"f2\": 0.639443758962217, \"f0_5\": 0.8764512295456623, \"p4\": 0.8456807916123841, \"phi\": 0.756447133001149}, {\"truth_threshold\": 28.778837667152292, \"match_probability\": 0.999999997828766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3834.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2704.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5864178538322449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4135821461677551, \"precision\": 1.0, \"recall\": 0.5864178538322449, \"specificity\": 1.0, \"npv\": 0.9755123257637024, \"accuracy\": 0.9763340353965759, \"f1\": 0.7392981102969534, \"f2\": 0.6392983392249717, \"f0_5\": 0.8763829203620737, \"p4\": 0.845599637156477, \"phi\": 0.7563450904691512}, {\"truth_threshold\": 28.782810816090638, \"match_probability\": 0.9999999978347374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3833.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2705.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5862649083137512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4137350916862488, \"precision\": 1.0, \"recall\": 0.5862649083137512, \"specificity\": 1.0, \"npv\": 0.9755035042762756, \"accuracy\": 0.976325273513794, \"f1\": 0.7391765499951789, \"f2\": 0.6391529097882275, \"f0_5\": 0.8763145861911295, \"p4\": 0.845518456807589, \"phi\": 0.7562429774056183}, {\"truth_threshold\": 28.78990565448946, \"match_probability\": 0.9999999978453594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3832.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2706.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5861119627952576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41388803720474243, \"precision\": 1.0, \"recall\": 0.5861119627952576, \"specificity\": 1.0, \"npv\": 0.9754946827888489, \"accuracy\": 0.9763165712356567, \"f1\": 0.7390549662487946, \"f2\": 0.6390074706510138, \"f0_5\": 0.8762462270191165, \"p4\": 0.8454372505526621, \"phi\": 0.7561409110205852}, {\"truth_threshold\": 28.793516204697703, \"match_probability\": 0.999999997850745, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3828.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2710.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.585500180721283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41449984908103943, \"precision\": 1.0, \"recall\": 0.585500180721283, \"specificity\": 1.0, \"npv\": 0.9754593372344971, \"accuracy\": 0.9762815237045288, \"f1\": 0.7385683966814586, \"f2\": 0.638425617078052, \"f0_5\": 0.8759725400457666, \"p4\": 0.8451121662110986, \"phi\": 0.7557324674820383}, {\"truth_threshold\": 28.796407749444807, \"match_probability\": 0.9999999978550483, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3827.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2711.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5853471755981445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4146527945995331, \"precision\": 1.0, \"recall\": 0.5853471755981445, \"specificity\": 1.0, \"npv\": 0.9754505157470703, \"accuracy\": 0.9762727618217468, \"f1\": 0.7384466956102267, \"f2\": 0.6382801294239301, \"f0_5\": 0.8759040556623638, \"p4\": 0.8450308302298003, \"phi\": 0.7556303413900036}, {\"truth_threshold\": 28.798008984851464, \"match_probability\": 0.9999999978574278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3826.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2712.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5851942300796509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41480574011802673, \"precision\": 1.0, \"recall\": 0.5851942300796509, \"specificity\": 1.0, \"npv\": 0.9754416942596436, \"accuracy\": 0.9762640595436096, \"f1\": 0.7383249710536472, \"f2\": 0.6381346320635133, \"f0_5\": 0.8758355461954034, \"p4\": 0.8449494682639307, \"phi\": 0.7555282033433696}, {\"truth_threshold\": 28.812176696729168, \"match_probability\": 0.9999999978783655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3825.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2713.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5850412845611572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4149587154388428, \"precision\": 1.0, \"recall\": 0.5850412845611572, \"specificity\": 1.0, \"npv\": 0.9754328727722168, \"accuracy\": 0.9762552976608276, \"f1\": 0.7382032230049214, \"f2\": 0.6379891249958302, \"f0_5\": 0.8757670116311017, \"p4\": 0.8448680803003703, \"phi\": 0.7554260533372371}, {\"truth_threshold\": 28.81300264598562, \"match_probability\": 0.9999999978795798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3823.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2715.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5847353935241699, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4152646064758301, \"precision\": 1.0, \"recall\": 0.5847353935241699, \"specificity\": 1.0, \"npv\": 0.9754151701927185, \"accuracy\": 0.9762377738952637, \"f1\": 0.737959656403822, \"f2\": 0.6376980817347789, \"f0_5\": 0.8756298671552909, \"p4\": 0.844705226327655, \"phi\": 0.7552216587417682}, {\"truth_threshold\": 28.835296109170763, \"match_probability\": 0.999999997912094, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3822.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2716.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5845824480056763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41541755199432373, \"precision\": 1.0, \"recall\": 0.5845824480056763, \"specificity\": 1.0, \"npv\": 0.9754063487052917, \"accuracy\": 0.9762290120124817, \"f1\": 0.7378378378378379, \"f2\": 0.6375525455394675, \"f0_5\": 0.8755612572161642, \"p4\": 0.8446237602922168, \"phi\": 0.7551194728203013}, {\"truth_threshold\": 28.84665444383559, \"match_probability\": 0.9999999979284676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3821.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2717.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5844295024871826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4155704975128174, \"precision\": 1.0, \"recall\": 0.5844295024871826, \"specificity\": 1.0, \"npv\": 0.975397527217865, \"accuracy\": 0.9762202501296997, \"f1\": 0.7377159957524858, \"f2\": 0.6374069996330031, \"f0_5\": 0.8754926221244616, \"p4\": 0.8445422682065213, \"phi\": 0.7550172749197037}, {\"truth_threshold\": 28.850321753488377, \"match_probability\": 0.9999999979337267, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3820.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2718.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.584276556968689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4157234728336334, \"precision\": 1.0, \"recall\": 0.584276556968689, \"specificity\": 1.0, \"npv\": 0.9753887057304382, \"accuracy\": 0.9762115478515625, \"f1\": 0.7375941301409539, \"f2\": 0.6372614440144134, \"f0_5\": 0.8754239618663489, \"p4\": 0.844460750057405, \"phi\": 0.7549150650350601}, {\"truth_threshold\": 28.867689807388533, \"match_probability\": 0.9999999979584526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3819.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2719.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5841236114501953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4158764183521271, \"precision\": 1.0, \"recall\": 0.5841236114501953, \"specificity\": 1.0, \"npv\": 0.9753798246383667, \"accuracy\": 0.9762027859687805, \"f1\": 0.7374722409964275, \"f2\": 0.6371158786827267, \"f0_5\": 0.875355276427982, \"p4\": 0.8443792058316949, \"phi\": 0.7548127844466948}, {\"truth_threshold\": 28.87134962389495, \"match_probability\": 0.999999997963625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3818.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2720.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5839706063270569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4160293638706207, \"precision\": 1.0, \"recall\": 0.5839706063270569, \"specificity\": 1.0, \"npv\": 0.9753710031509399, \"accuracy\": 0.9761940240859985, \"f1\": 0.7373503283120896, \"f2\": 0.6369703036369703, \"f0_5\": 0.8752865657955067, \"p4\": 0.8442976355162098, \"phi\": 0.7547105505717768}, {\"truth_threshold\": 28.879721193549596, \"match_probability\": 0.9999999979754074, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3817.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2721.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5838176608085632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4161823093891144, \"precision\": 1.0, \"recall\": 0.5838176608085632, \"specificity\": 1.0, \"npv\": 0.9753621816635132, \"accuracy\": 0.9761852622032166, \"f1\": 0.7372283920811202, \"f2\": 0.6368247188761721, \"f0_5\": 0.8752178299550583, \"p4\": 0.8442160390977593, \"phi\": 0.7546083046980446}, {\"truth_threshold\": 28.882897882437977, \"match_probability\": 0.9999999979798604, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3814.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2724.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5833588242530823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4166411757469177, \"precision\": 1.0, \"recall\": 0.5833588242530823, \"specificity\": 1.0, \"npv\": 0.9753357172012329, \"accuracy\": 0.9761590361595154, \"f1\": 0.7368624420401855, \"f2\": 0.6363879062937996, \"f0_5\": 0.8750114710470772, \"p4\": 0.8439710930925787, \"phi\": 0.7543014362827604}, {\"truth_threshold\": 28.88763838206225, \"match_probability\": 0.9999999979864874, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3812.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2726.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.583052933216095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41694706678390503, \"precision\": 1.0, \"recall\": 0.583052933216095, \"specificity\": 1.0, \"npv\": 0.9753180146217346, \"accuracy\": 0.9761415123939514, \"f1\": 0.7366183574879227, \"f2\": 0.6360966493125083, \"f0_5\": 0.8748737721472505, \"p4\": 0.8438076649987414, \"phi\": 0.7540968364077811}, {\"truth_threshold\": 28.89764310154686, \"match_probability\": 0.9999999980004023, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3810.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2728.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5827470421791077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4172529876232147, \"precision\": 1.0, \"recall\": 0.5827470421791077, \"specificity\": 1.0, \"npv\": 0.9753003716468811, \"accuracy\": 0.9761239886283875, \"f1\": 0.7363741785852339, \"f2\": 0.6358053534477004, \"f0_5\": 0.8747359720819176, \"p4\": 0.8436441321757178, \"phi\": 0.7538921296373852}, {\"truth_threshold\": 28.90792373219121, \"match_probability\": 0.9999999980146008, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3807.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2731.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5822881460189819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4177118241786957, \"precision\": 1.0, \"recall\": 0.5822881460189819, \"specificity\": 1.0, \"npv\": 0.9752739071846008, \"accuracy\": 0.9760977625846863, \"f1\": 0.7360077332044466, \"f2\": 0.63536833672686, \"f0_5\": 0.8745290820545806, \"p4\": 0.8433986363419187, \"phi\": 0.7535850673320306}, {\"truth_threshold\": 28.910104468278206, \"match_probability\": 0.9999999980175996, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3806.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2732.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5821352005004883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4178647994995117, \"precision\": 1.0, \"recall\": 0.5821352005004883, \"specificity\": 1.0, \"npv\": 0.9752650260925293, \"accuracy\": 0.9760890007019043, \"f1\": 0.7358855375096675, \"f2\": 0.6352226450363843, \"f0_5\": 0.8744600680084551, \"p4\": 0.8433167519177396, \"phi\": 0.7534826891304373}, {\"truth_threshold\": 28.910781732376886, \"match_probability\": 0.99999999801853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3805.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2733.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5819822549819946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41801774501800537, \"precision\": 1.0, \"recall\": 0.5819822549819946, \"specificity\": 1.0, \"npv\": 0.9752562046051025, \"accuracy\": 0.9760802388191223, \"f1\": 0.7357633181862129, \"f2\": 0.6350769436191875, \"f0_5\": 0.8743910285871863, \"p4\": 0.8432348412316156, \"phi\": 0.7533802400517227}, {\"truth_threshold\": 28.93642644074824, \"match_probability\": 0.9999999980534405, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3804.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2734.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.581829309463501, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.418170690536499, \"precision\": 1.0, \"recall\": 0.581829309463501, \"specificity\": 1.0, \"npv\": 0.9752473831176758, \"accuracy\": 0.9760714769363403, \"f1\": 0.7356410752272288, \"f2\": 0.6349312324742956, \"f0_5\": 0.8743219637767767, \"p4\": 0.8431529042702406, \"phi\": 0.7532778377213474}, {\"truth_threshold\": 28.948775310757174, \"match_probability\": 0.9999999980700311, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3802.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2736.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5815234184265137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4184766113758087, \"precision\": 1.0, \"recall\": 0.5815234184265137, \"specificity\": 1.0, \"npv\": 0.9752297401428223, \"accuracy\": 0.9760540127754211, \"f1\": 0.7353965183752418, \"f2\": 0.6346397809975295, \"f0_5\": 0.8741837579324934, \"p4\": 0.8429889514684664, \"phi\": 0.7530729968512748}, {\"truth_threshold\": 28.950504853277142, \"match_probability\": 0.9999999980723435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3801.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2737.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.58137047290802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41862955689430237, \"precision\": 1.0, \"recall\": 0.58137047290802, \"specificity\": 1.0, \"npv\": 0.9752209186553955, \"accuracy\": 0.9760452508926392, \"f1\": 0.7352742044685172, \"f2\": 0.6344940406637065, \"f0_5\": 0.8741146168705731, \"p4\": 0.8429069356014095, \"phi\": 0.7529704994528041}, {\"truth_threshold\": 28.959138880908963, \"match_probability\": 0.9999999980838454, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3799.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2739.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5810645222663879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4189354479312897, \"precision\": 1.0, \"recall\": 0.5810645222663879, \"specificity\": 1.0, \"npv\": 0.9752032160758972, \"accuracy\": 0.9760277271270752, \"f1\": 0.7350295056592822, \"f2\": 0.6342025308003072, \"f0_5\": 0.8739762583969817, \"p4\": 0.8427428248682439, \"phi\": 0.7527655860844228}, {\"truth_threshold\": 28.97801305404975, \"match_probability\": 0.9999999981087504, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3796.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2742.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.580605685710907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.419394314289093, \"precision\": 1.0, \"recall\": 0.580605685710907, \"specificity\": 1.0, \"npv\": 0.9751767516136169, \"accuracy\": 0.9760014414787292, \"f1\": 0.7346622798529128, \"f2\": 0.633765193001202, \"f0_5\": 0.8737685296013259, \"p4\": 0.8424964610704595, \"phi\": 0.7524580664354676}, {\"truth_threshold\": 28.9814953770641, \"match_probability\": 0.9999999981133099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3794.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2744.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5802997946739197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4197002053260803, \"precision\": 1.0, \"recall\": 0.5802997946739197, \"specificity\": 1.0, \"npv\": 0.9751591086387634, \"accuracy\": 0.9759839773178101, \"f1\": 0.7344173441734417, \"f2\": 0.6334735857877513, \"f0_5\": 0.8736299161831077, \"p4\": 0.84233208658383, \"phi\": 0.7522530320469739}, {\"truth_threshold\": 28.98733691354264, \"match_probability\": 0.9999999981209338, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3793.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2745.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.580146849155426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.41985318064689636, \"precision\": 1.0, \"recall\": 0.580146849155426, \"specificity\": 1.0, \"npv\": 0.9751502871513367, \"accuracy\": 0.9759752154350281, \"f1\": 0.7342948407704966, \"f2\": 0.6333277675738854, \"f0_5\": 0.8735605711653616, \"p4\": 0.8422498597138934, \"phi\": 0.7521504966782133}, {\"truth_threshold\": 28.99848524915354, \"match_probability\": 0.9999999981353982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3788.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2750.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.579382061958313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.420617938041687, \"precision\": 1.0, \"recall\": 0.579382061958313, \"specificity\": 1.0, \"npv\": 0.9751061201095581, \"accuracy\": 0.9759314656257629, \"f1\": 0.7336819678481503, \"f2\": 0.6325985303941216, \"f0_5\": 0.8732134624250807, \"p4\": 0.8418383285611317, \"phi\": 0.7516375789426464}, {\"truth_threshold\": 29.000380867078203, \"match_probability\": 0.9999999981378466, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3787.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2751.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5792291164398193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42077088356018066, \"precision\": 1.0, \"recall\": 0.5792291164398193, \"specificity\": 1.0, \"npv\": 0.9750972986221313, \"accuracy\": 0.975922703742981, \"f1\": 0.7335593220338983, \"f2\": 0.6324526537292495, \"f0_5\": 0.8731439638476436, \"p4\": 0.8417559428758697, \"phi\": 0.7515349117992819}, {\"truth_threshold\": 29.005838908662206, \"match_probability\": 0.9999999981448782, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3785.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2753.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.578923225402832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42107677459716797, \"precision\": 1.0, \"recall\": 0.578923225402832, \"specificity\": 1.0, \"npv\": 0.9750796556472778, \"accuracy\": 0.975905179977417, \"f1\": 0.7333139591204108, \"f2\": 0.6321608711627752, \"f0_5\": 0.8730048897499769, \"p4\": 0.8415910919429365, \"phi\": 0.7513296589406135}, {\"truth_threshold\": 29.019631339451074, \"match_probability\": 0.9999999981625289, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3783.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2755.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5786173343658447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42138269543647766, \"precision\": 1.0, \"recall\": 0.5786173343658447, \"specificity\": 1.0, \"npv\": 0.9750620126724243, \"accuracy\": 0.9758877158164978, \"f1\": 0.7330685011142332, \"f2\": 0.6318690496074829, \"f0_5\": 0.8728657129672358, \"p4\": 0.8414261348368892, \"phi\": 0.7511243574291459}, {\"truth_threshold\": 29.02163402343696, \"match_probability\": 0.9999999981650779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3782.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2756.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5784643888473511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4215356409549713, \"precision\": 1.0, \"recall\": 0.5784643888473511, \"specificity\": 1.0, \"npv\": 0.9750531911849976, \"accuracy\": 0.9758789539337158, \"f1\": 0.7329457364341085, \"f2\": 0.6317231242065878, \"f0_5\": 0.8727960860334164, \"p4\": 0.8413436164352004, \"phi\": 0.7510216294246325}, {\"truth_threshold\": 29.022456011614572, \"match_probability\": 0.9999999981661231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3780.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2758.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.578158438205719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4218415319919586, \"precision\": 1.0, \"recall\": 0.578158438205719, \"specificity\": 1.0, \"npv\": 0.975035548210144, \"accuracy\": 0.9758614301681519, \"f1\": 0.7327001356852103, \"f2\": 0.6314312441534145, \"f0_5\": 0.8726567550096962, \"p4\": 0.8411784998669178, \"phi\": 0.7508162548433001}, {\"truth_threshold\": 29.043932543797517, \"match_probability\": 0.9999999981932207, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3779.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2759.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5780054926872253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42199450731277466, \"precision\": 1.0, \"recall\": 0.5780054926872253, \"specificity\": 1.0, \"npv\": 0.9750267267227173, \"accuracy\": 0.9758526682853699, \"f1\": 0.7325772996025977, \"f2\": 0.6312852894991815, \"f0_5\": 0.8725870508912903, \"p4\": 0.8410959016732666, \"phi\": 0.7507135492725286}, {\"truth_threshold\": 29.05485280881293, \"match_probability\": 0.9999999982068452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3778.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2760.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5778525471687317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4221474528312683, \"precision\": 1.0, \"recall\": 0.5778525471687317, \"specificity\": 1.0, \"npv\": 0.9750179052352905, \"accuracy\": 0.9758439064025879, \"f1\": 0.7324544397053121, \"f2\": 0.6311393250918811, \"f0_5\": 0.8725173210161663, \"p4\": 0.841013276855222, \"phi\": 0.7506107724867458}, {\"truth_threshold\": 29.0594421552786, \"match_probability\": 0.9999999982125404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3777.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2761.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.577699601650238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42230039834976196, \"precision\": 1.0, \"recall\": 0.577699601650238, \"specificity\": 1.0, \"npv\": 0.975009024143219, \"accuracy\": 0.9758352041244507, \"f1\": 0.7323315559864275, \"f2\": 0.6309933509305355, \"f0_5\": 0.8724475653700453, \"p4\": 0.840930625399232, \"phi\": 0.7505080425164239}, {\"truth_threshold\": 29.065917902413123, \"match_probability\": 0.9999999982205456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3776.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2762.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5775466561317444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4224533438682556, \"precision\": 1.0, \"recall\": 0.5775466561317444, \"specificity\": 1.0, \"npv\": 0.9750002026557922, \"accuracy\": 0.9758264422416687, \"f1\": 0.7322086484390149, \"f2\": 0.6308473670141673, \"f0_5\": 0.8723777839386379, \"p4\": 0.8408479472917362, \"phi\": 0.7504053003425077}, {\"truth_threshold\": 29.081679315113345, \"match_probability\": 0.9999999982398803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3775.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2763.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5773937106132507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42260628938674927, \"precision\": 1.0, \"recall\": 0.5773937106132507, \"specificity\": 1.0, \"npv\": 0.9749913811683655, \"accuracy\": 0.9758176803588867, \"f1\": 0.7320857170561428, \"f2\": 0.6307013733417983, \"f0_5\": 0.8723079767076439, \"p4\": 0.8407652425191644, \"phi\": 0.7503025459599334}, {\"truth_threshold\": 29.085649838101766, \"match_probability\": 0.9999999982447177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3774.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2764.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5772407650947571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4227592647075653, \"precision\": 1.0, \"recall\": 0.5772407650947571, \"specificity\": 1.0, \"npv\": 0.9749825596809387, \"accuracy\": 0.9758089184761047, \"f1\": 0.7319627618308766, \"f2\": 0.6305553699124508, \"f0_5\": 0.8722381436627531, \"p4\": 0.8406825110679372, \"phi\": 0.7501997793636335}, {\"truth_threshold\": 29.086419070346537, \"match_probability\": 0.9999999982456534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3772.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2766.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.576934814453125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4230651557445526, \"precision\": 1.0, \"recall\": 0.576934814453125, \"specificity\": 1.0, \"npv\": 0.9749649167060852, \"accuracy\": 0.9757913947105408, \"f1\": 0.7317167798254122, \"f2\": 0.6302633337789065, \"f0_5\": 0.872098400073985, \"p4\": 0.8405169680751543, \"phi\": 0.7499941504427154}, {\"truth_threshold\": 29.090288179489256, \"match_probability\": 0.999999998250352, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3770.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2768.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5766289234161377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4233710467815399, \"precision\": 1.0, \"recall\": 0.5766289234161377, \"specificity\": 1.0, \"npv\": 0.9749472737312317, \"accuracy\": 0.9757739305496216, \"f1\": 0.7314707023670936, \"f2\": 0.6299712586057081, \"f0_5\": 0.8719585530576371, \"p4\": 0.8403513182045692, \"phi\": 0.749788531657732}, {\"truth_threshold\": 29.091043096871985, \"match_probability\": 0.9999999982512673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3769.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2769.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.576475977897644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42352402210235596, \"precision\": 1.0, \"recall\": 0.576475977897644, \"specificity\": 1.0, \"npv\": 0.9749384522438049, \"accuracy\": 0.9757651686668396, \"f1\": 0.7313476278257495, \"f2\": 0.6298252063767922, \"f0_5\": 0.8718885907282317, \"p4\": 0.8402684531560547, \"phi\": 0.7496856448195522}, {\"truth_threshold\": 29.120477529996343, \"match_probability\": 0.9999999982865841, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3766.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2772.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5760171413421631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4239828586578369, \"precision\": 1.0, \"recall\": 0.5760171413421631, \"specificity\": 1.0, \"npv\": 0.9749119877815247, \"accuracy\": 0.9757388830184937, \"f1\": 0.7309782608695652, \"f2\": 0.6293869911090314, \"f0_5\": 0.8716785482825664, \"p4\": 0.84001969739398, \"phi\": 0.7493770880653778}, {\"truth_threshold\": 29.13237242749523, \"match_probability\": 0.9999999983006531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3765.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2773.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5758641958236694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42413583397865295, \"precision\": 1.0, \"recall\": 0.5758641958236694, \"specificity\": 1.0, \"npv\": 0.9749031662940979, \"accuracy\": 0.9757301807403564, \"f1\": 0.7308550907502669, \"f2\": 0.6292408998228431, \"f0_5\": 0.8716084822668766, \"p4\": 0.8399367252222674, \"phi\": 0.7492742113018062}, {\"truth_threshold\": 29.1355756728367, \"match_probability\": 0.999999998304422, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3764.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2774.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5757112503051758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4242887794971466, \"precision\": 1.0, \"recall\": 0.5757112503051758, \"specificity\": 1.0, \"npv\": 0.9748943448066711, \"accuracy\": 0.9757214188575745, \"f1\": 0.7307318967190837, \"f2\": 0.629094798769889, \"f0_5\": 0.8715383902936, \"p4\": 0.8398537262355993, \"phi\": 0.7491712631461922}, {\"truth_threshold\": 29.154357899003113, \"match_probability\": 0.9999999983263533, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3762.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2776.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5754052996635437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4245946705341339, \"precision\": 1.0, \"recall\": 0.5754052996635437, \"specificity\": 1.0, \"npv\": 0.9748767018318176, \"accuracy\": 0.9757038950920105, \"f1\": 0.7304854368932039, \"f2\": 0.6288025673597647, \"f0_5\": 0.8713981284165663, \"p4\": 0.839687647762663, \"phi\": 0.7489654482605029}, {\"truth_threshold\": 29.156783052225038, \"match_probability\": 0.9999999983291644, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3761.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2777.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.57525235414505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42474761605262756, \"precision\": 1.0, \"recall\": 0.57525235414505, \"specificity\": 1.0, \"npv\": 0.9748678803443909, \"accuracy\": 0.9756951332092285, \"f1\": 0.7303621710845714, \"f2\": 0.6286564370006352, \"f0_5\": 0.8713279584839217, \"p4\": 0.8396045682490049, \"phi\": 0.7488625224003407}, {\"truth_threshold\": 29.163546251888228, \"match_probability\": 0.9999999983369787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3760.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2778.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5750994086265564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4249005913734436, \"precision\": 1.0, \"recall\": 0.5750994086265564, \"specificity\": 1.0, \"npv\": 0.9748590588569641, \"accuracy\": 0.9756863713264465, \"f1\": 0.7302388813361818, \"f2\": 0.628510296870821, \"f0_5\": 0.8712577625359162, \"p4\": 0.8395214618656113, \"phi\": 0.7487595250973234}, {\"truth_threshold\": 29.168745453865228, \"match_probability\": 0.9999999983429612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3755.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2783.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5743346810340881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42566534876823425, \"precision\": 1.0, \"recall\": 0.5743346810340881, \"specificity\": 1.0, \"npv\": 0.9748149514198303, \"accuracy\": 0.9756426215171814, \"f1\": 0.7296220732536676, \"f2\": 0.6277794496271776, \"f0_5\": 0.8709063920586325, \"p4\": 0.8391055264221458, \"phi\": 0.748244590682764}, {\"truth_threshold\": 29.17828081601203, \"match_probability\": 0.9999999983538771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3754.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2784.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5741817355155945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4258182942867279, \"precision\": 1.0, \"recall\": 0.5741817355155945, \"specificity\": 1.0, \"npv\": 0.9748061299324036, \"accuracy\": 0.9756338596343994, \"f1\": 0.729498639720171, \"f2\": 0.6276332508526717, \"f0_5\": 0.8708360397142062, \"p4\": 0.8390222585319291, \"phi\": 0.7481415787045593}, {\"truth_threshold\": 29.180106271303917, \"match_probability\": 0.9999999983559587, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3752.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2786.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5738757848739624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4261241853237152, \"precision\": 1.0, \"recall\": 0.5738757848739624, \"specificity\": 1.0, \"npv\": 0.97478848695755, \"accuracy\": 0.9756163954734802, \"f1\": 0.7292517006802721, \"f2\": 0.6273408239700374, \"f0_5\": 0.8706952566601689, \"p4\": 0.8388556418398339, \"phi\": 0.7479355177802038}, {\"truth_threshold\": 29.185572558218226, \"match_probability\": 0.999999998362176, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3751.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2787.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5737228393554688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42627716064453125, \"precision\": 1.0, \"recall\": 0.5737228393554688, \"specificity\": 1.0, \"npv\": 0.9747796654701233, \"accuracy\": 0.9756076335906982, \"f1\": 0.7291281951598795, \"f2\": 0.6271945958599472, \"f0_5\": 0.8706248259214557, \"p4\": 0.8387722930103781, \"phi\": 0.7478324688237654}, {\"truth_threshold\": 29.1855759208005, \"match_probability\": 0.9999999983621799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3749.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2789.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5734169483184814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42658305168151855, \"precision\": 1.0, \"recall\": 0.5734169483184814, \"specificity\": 1.0, \"npv\": 0.9747620224952698, \"accuracy\": 0.9755901098251343, \"f1\": 0.7288811120832118, \"f2\": 0.6269021102973145, \"f0_5\": 0.8704838859478035, \"p4\": 0.8386055143156383, \"phi\": 0.7476262746550216}, {\"truth_threshold\": 29.18979532747235, \"match_probability\": 0.999999998366963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3748.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2790.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5732640027999878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4267359972000122, \"precision\": 1.0, \"recall\": 0.5732640027999878, \"specificity\": 1.0, \"npv\": 0.974753201007843, \"accuracy\": 0.9755813479423523, \"f1\": 0.7287575345129302, \"f2\": 0.6267558528428093, \"f0_5\": 0.8704133766836971, \"p4\": 0.8385220844227209, \"phi\": 0.7475231886663741}, {\"truth_threshold\": 29.200454313592566, \"match_probability\": 0.9999999983789838, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3747.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2791.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5731110572814941, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42688894271850586, \"precision\": 1.0, \"recall\": 0.5731110572814941, \"specificity\": 1.0, \"npv\": 0.9747443795204163, \"accuracy\": 0.9755725860595703, \"f1\": 0.7286339329120077, \"f2\": 0.6266095856048697, \"f0_5\": 0.8703428412152745, \"p4\": 0.8384386274810006, \"phi\": 0.7474200903258847}, {\"truth_threshold\": 29.20347026436943, \"match_probability\": 0.999999998382369, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3742.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2796.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5723462700843811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4276537299156189, \"precision\": 1.0, \"recall\": 0.5723462700843811, \"specificity\": 1.0, \"npv\": 0.9747002720832825, \"accuracy\": 0.9755288362503052, \"f1\": 0.7280155642023346, \"f2\": 0.6258781026292901, \"f0_5\": 0.8699897702966614, \"p4\": 0.8380209365556186, \"phi\": 0.746904353869884}, {\"truth_threshold\": 29.203958708103077, \"match_probability\": 0.9999999983829165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3741.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2797.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5721933245658875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42780667543411255, \"precision\": 1.0, \"recall\": 0.5721933245658875, \"specificity\": 1.0, \"npv\": 0.9746914505958557, \"accuracy\": 0.9755200743675232, \"f1\": 0.7278918182702597, \"f2\": 0.6257317766701235, \"f0_5\": 0.8699190772951353, \"p4\": 0.8379373170301065, \"phi\": 0.7468011219993842}, {\"truth_threshold\": 29.204769382496394, \"match_probability\": 0.9999999983838249, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3740.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2798.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5720403790473938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4279596209526062, \"precision\": 1.0, \"recall\": 0.5720403790473938, \"specificity\": 1.0, \"npv\": 0.974682629108429, \"accuracy\": 0.975511372089386, \"f1\": 0.727768048258416, \"f2\": 0.6255854409206477, \"f0_5\": 0.8698483579867895, \"p4\": 0.8378536703587118, \"phi\": 0.7466979370359311}, {\"truth_threshold\": 29.21314492727479, \"match_probability\": 0.9999999983931804, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3738.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2800.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5717344880104065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4282655119895935, \"precision\": 1.0, \"recall\": 0.5717344880104065, \"specificity\": 1.0, \"npv\": 0.9746649861335754, \"accuracy\": 0.975493848323822, \"f1\": 0.7275204359673024, \"f2\": 0.6252927400468384, \"f0_5\": 0.8697068403908795, \"p4\": 0.8376862955226396, \"phi\": 0.7464915299240925}, {\"truth_threshold\": 29.222969063656215, \"match_probability\": 0.999999998404085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3736.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2802.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5714285969734192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4285714328289032, \"precision\": 1.0, \"recall\": 0.5714285969734192, \"specificity\": 1.0, \"npv\": 0.9746473431587219, \"accuracy\": 0.9754763245582581, \"f1\": 0.7272727272727273, \"f2\": 0.625, \"f0_5\": 0.8695652173913043, \"p4\": 0.8375188119360367, \"phi\": 0.7462850138566316}, {\"truth_threshold\": 29.23636220431382, \"match_probability\": 0.999999998418832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3734.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2804.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5711226463317871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4288773238658905, \"precision\": 1.0, \"recall\": 0.5711226463317871, \"specificity\": 1.0, \"npv\": 0.9746297001838684, \"accuracy\": 0.9754588603973389, \"f1\": 0.7270249221183801, \"f2\": 0.6247072207722679, \"f0_5\": 0.8694234888702617, \"p4\": 0.837351219487386, \"phi\": 0.746078507458783}, {\"truth_threshold\": 29.24270765975989, \"match_probability\": 0.9999999984257713, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3732.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2806.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5708167552947998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4291832447052002, \"precision\": 1.0, \"recall\": 0.5708167552947998, \"specificity\": 1.0, \"npv\": 0.9746120572090149, \"accuracy\": 0.9754413366317749, \"f1\": 0.7267770204479065, \"f2\": 0.6244144023557756, \"f0_5\": 0.8692816547097736, \"p4\": 0.8371835180650179, \"phi\": 0.745871891991337}, {\"truth_threshold\": 29.24407836621418, \"match_probability\": 0.9999999984272662, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3731.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2807.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5706638097763062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42933619022369385, \"precision\": 1.0, \"recall\": 0.5706638097763062, \"specificity\": 1.0, \"npv\": 0.9746032357215881, \"accuracy\": 0.9754325747489929, \"f1\": 0.7266530334014997, \"f2\": 0.6242679784492855, \"f0_5\": 0.8692106979778212, \"p4\": 0.8370996264537511, \"phi\": 0.7457685952861298}, {\"truth_threshold\": 29.245290440064053, \"match_probability\": 0.999999998428587, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3729.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2809.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5703579187393188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42964208126068115, \"precision\": 1.0, \"recall\": 0.5703579187393188, \"specificity\": 1.0, \"npv\": 0.9745856523513794, \"accuracy\": 0.975415050983429, \"f1\": 0.7264049868510762, \"f2\": 0.6239751012348984, \"f0_5\": 0.8690687051365713, \"p4\": 0.8369317613610922, \"phi\": 0.74556196455021}, {\"truth_threshold\": 29.25083830773089, \"match_probability\": 0.9999999984346183, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3725.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2813.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5697460770606995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43025389313697815, \"precision\": 1.0, \"recall\": 0.5697460770606995, \"specificity\": 1.0, \"npv\": 0.9745503664016724, \"accuracy\": 0.9753800630569458, \"f1\": 0.7259086037221085, \"f2\": 0.6233892291729424, \"f0_5\": 0.8687844015299935, \"p4\": 0.8365957033028891, \"phi\": 0.7451484942043216}, {\"truth_threshold\": 29.277986554608844, \"match_probability\": 0.9999999984637997, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3724.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2814.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5695931315422058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4304068386554718, \"precision\": 1.0, \"recall\": 0.5695931315422058, \"specificity\": 1.0, \"npv\": 0.9745415449142456, \"accuracy\": 0.9753713011741638, \"f1\": 0.7257844474761255, \"f2\": 0.6232427366447985, \"f0_5\": 0.8687132593076421, \"p4\": 0.8365116203996292, \"phi\": 0.7450451103009579}, {\"truth_threshold\": 29.290249498664714, \"match_probability\": 0.9999999984768021, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3723.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2815.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5694401860237122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43055981397628784, \"precision\": 1.0, \"recall\": 0.5694401860237122, \"specificity\": 1.0, \"npv\": 0.9745327234268188, \"accuracy\": 0.9753625392913818, \"f1\": 0.7256602670305039, \"f2\": 0.6230962343096235, \"f0_5\": 0.8686420905272981, \"p4\": 0.8364275101127815, \"phi\": 0.7449416544797596}, {\"truth_threshold\": 29.29671053138886, \"match_probability\": 0.9999999984836084, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3721.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2817.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5691342949867249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43086570501327515, \"precision\": 1.0, \"recall\": 0.5691342949867249, \"specificity\": 1.0, \"npv\": 0.9745150804519653, \"accuracy\": 0.9753450751304626, \"f1\": 0.7254118335120382, \"f2\": 0.6228032002142403, \"f0_5\": 0.8684996732331248, \"p4\": 0.8362592073320378, \"phi\": 0.7447348242529777}, {\"truth_threshold\": 29.308107103724605, \"match_probability\": 0.99999999849554, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3720.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2818.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5689813494682312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4310186505317688, \"precision\": 1.0, \"recall\": 0.5689813494682312, \"specificity\": 1.0, \"npv\": 0.9745062589645386, \"accuracy\": 0.9753363132476807, \"f1\": 0.7252875804250342, \"f2\": 0.6226566684520621, \"f0_5\": 0.8684284246895135, \"p4\": 0.8361750148099752, \"phi\": 0.7446313904034938}, {\"truth_threshold\": 29.313169044559356, \"match_probability\": 0.9999999985008095, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3719.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2819.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5688284039497375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43117162585258484, \"precision\": 1.0, \"recall\": 0.5688284039497375, \"specificity\": 1.0, \"npv\": 0.9744974374771118, \"accuracy\": 0.9753275513648987, \"f1\": 0.7251633031100712, \"f2\": 0.6225101268789126, \"f0_5\": 0.868357149528346, \"p4\": 0.8360907948479916, \"phi\": 0.7445279440562728}, {\"truth_threshold\": 29.32242994363757, \"match_probability\": 0.9999999985104021, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3718.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2820.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5686754584312439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4313245713710785, \"precision\": 1.0, \"recall\": 0.5686754584312439, \"specificity\": 1.0, \"npv\": 0.9744886159896851, \"accuracy\": 0.9753187894821167, \"f1\": 0.7250390015600624, \"f2\": 0.6223635754938065, \"f0_5\": 0.8682858477347034, \"p4\": 0.8360065474319796, \"phi\": 0.744424425726335}, {\"truth_threshold\": 29.32632701215496, \"match_probability\": 0.9999999985144205, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3716.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2822.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5683695077896118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4316304624080658, \"precision\": 1.0, \"recall\": 0.5683695077896118, \"specificity\": 1.0, \"npv\": 0.9744710326194763, \"accuracy\": 0.9753012657165527, \"f1\": 0.7247903257265458, \"f2\": 0.622070443283782, \"f0_5\": 0.8681431641902626, \"p4\": 0.835837970181392, \"phi\": 0.7442174704803747}, {\"truth_threshold\": 29.339790995201454, \"match_probability\": 0.9999999985282202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3714.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2824.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5680636167526245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4319363832473755, \"precision\": 1.0, \"recall\": 0.5680636167526245, \"specificity\": 1.0, \"npv\": 0.9744533896446228, \"accuracy\": 0.9752838015556335, \"f1\": 0.7245415528677331, \"f2\": 0.621777271814103, \"f0_5\": 0.8680003739366178, \"p4\": 0.83566928294516, \"phi\": 0.7440104056485258}, {\"truth_threshold\": 29.34177954829491, \"match_probability\": 0.9999999985302475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3711.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2827.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5676047801971436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43239521980285645, \"precision\": 1.0, \"recall\": 0.5676047801971436, \"specificity\": 1.0, \"npv\": 0.9744269251823425, \"accuracy\": 0.9752575159072876, \"f1\": 0.7241682115328325, \"f2\": 0.6213374409804775, \"f0_5\": 0.8677859882143859, \"p4\": 0.8354160456200433, \"phi\": 0.7436998036600961}, {\"truth_threshold\": 29.37576979562524, \"match_probability\": 0.9999999985644704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3708.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2830.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5671459436416626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4328540861606598, \"precision\": 1.0, \"recall\": 0.5671459436416626, \"specificity\": 1.0, \"npv\": 0.974400520324707, \"accuracy\": 0.9752312898635864, \"f1\": 0.7237946515713449, \"f2\": 0.6208975217682519, \"f0_5\": 0.8675713617220402, \"p4\": 0.8351625601897401, \"phi\": 0.7433890292074891}, {\"truth_threshold\": 29.38220141883578, \"match_probability\": 0.9999999985708559, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3706.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2832.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5668399930000305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4331599771976471, \"precision\": 1.0, \"recall\": 0.5668399930000305, \"specificity\": 1.0, \"npv\": 0.9743828773498535, \"accuracy\": 0.9752137660980225, \"f1\": 0.723545490042952, \"f2\": 0.620604193181057, \"f0_5\": 0.8674281434322629, \"p4\": 0.8349934318772964, \"phi\": 0.7431818231316165}, {\"truth_threshold\": 29.39661827319536, \"match_probability\": 0.9999999985850662, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3705.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2833.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5666870474815369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43331295251846313, \"precision\": 1.0, \"recall\": 0.5666870474815369, \"specificity\": 1.0, \"npv\": 0.9743740558624268, \"accuracy\": 0.9752050042152405, \"f1\": 0.7234208727911745, \"f2\": 0.6204575141507854, \"f0_5\": 0.8673564940537504, \"p4\": 0.8349088262707302, \"phi\": 0.7430781416582735}, {\"truth_threshold\": 29.423494554895395, \"match_probability\": 0.9999999986111813, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3702.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2836.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5662282109260559, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4337717890739441, \"precision\": 1.0, \"recall\": 0.5662282109260559, \"specificity\": 1.0, \"npv\": 0.9743475914001465, \"accuracy\": 0.9751787781715393, \"f1\": 0.723046875, \"f2\": 0.620017418101427, \"f0_5\": 0.8671413848027734, \"p4\": 0.8346548434787033, \"phi\": 0.7427672004728656}, {\"truth_threshold\": 29.437493510893415, \"match_probability\": 0.9999999986245923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3700.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2838.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5659223198890686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4340777099132538, \"precision\": 1.0, \"recall\": 0.5659223198890686, \"specificity\": 1.0, \"npv\": 0.9743300080299377, \"accuracy\": 0.9751612544059753, \"f1\": 0.7227974213713616, \"f2\": 0.619723971593193, \"f0_5\": 0.8669978442215766, \"p4\": 0.8344853831644236, \"phi\": 0.7425597837737898}, {\"truth_threshold\": 29.438211482909562, \"match_probability\": 0.9999999986252766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3699.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2839.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.565769374370575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43423065543174744, \"precision\": 1.0, \"recall\": 0.565769374370575, \"specificity\": 1.0, \"npv\": 0.974321186542511, \"accuracy\": 0.9751524925231934, \"f1\": 0.722672658005275, \"f2\": 0.6195772335935145, \"f0_5\": 0.8669260335614513, \"p4\": 0.8344006114285571, \"phi\": 0.7424560863233415}, {\"truth_threshold\": 29.439332513046285, \"match_probability\": 0.9999999986263444, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3698.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2840.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5656163692474365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4343836009502411, \"precision\": 1.0, \"recall\": 0.5656163692474365, \"specificity\": 1.0, \"npv\": 0.9743123650550842, \"accuracy\": 0.9751437306404114, \"f1\": 0.722547870261821, \"f2\": 0.6194304857621441, \"f0_5\": 0.86685419596812, \"p4\": 0.8343158119544732, \"phi\": 0.7423523762639097}, {\"truth_threshold\": 29.440670199781795, \"match_probability\": 0.9999999986276175, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3697.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2841.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5654634237289429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43453654646873474, \"precision\": 1.0, \"recall\": 0.5654634237289429, \"specificity\": 1.0, \"npv\": 0.9743035435676575, \"accuracy\": 0.9751350283622742, \"f1\": 0.7224230581338544, \"f2\": 0.6192837280980937, \"f0_5\": 0.8667823314264278, \"p4\": 0.8342309847278598, \"phi\": 0.7422486535901587}, {\"truth_threshold\": 29.44196361777067, \"match_probability\": 0.9999999986288474, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3696.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2842.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5653104782104492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4346895217895508, \"precision\": 1.0, \"recall\": 0.5653104782104492, \"specificity\": 1.0, \"npv\": 0.9742947220802307, \"accuracy\": 0.9751262664794922, \"f1\": 0.7222982216142271, \"f2\": 0.6191369606003753, \"f0_5\": 0.8667104399212081, \"p4\": 0.834146129734395, \"phi\": 0.7421448586462049}, {\"truth_threshold\": 29.442813081781246, \"match_probability\": 0.9999999986296544, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3695.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2843.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5651575326919556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43484246730804443, \"precision\": 1.0, \"recall\": 0.5651575326919556, \"specificity\": 1.0, \"npv\": 0.974285900592804, \"accuracy\": 0.9751175045967102, \"f1\": 0.7221733606957882, \"f2\": 0.6189901832680001, \"f0_5\": 0.866638521437283, \"p4\": 0.8340612469597467, \"phi\": 0.7420411107199901}, {\"truth_threshold\": 29.449244704991788, \"match_probability\": 0.99999999863575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3693.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2845.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5648516416549683, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43514835834503174, \"precision\": 1.0, \"recall\": 0.5648516416549683, \"specificity\": 1.0, \"npv\": 0.9742683172225952, \"accuracy\": 0.9750999808311462, \"f1\": 0.7219235656338578, \"f2\": 0.6186965990953258, \"f0_5\": 0.8664946034725481, \"p4\": 0.8338913980095238, \"phi\": 0.74183357697115}, {\"truth_threshold\": 29.45379693033631, \"match_probability\": 0.9999999986400478, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3691.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2847.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.564545750617981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43545427918434143, \"precision\": 1.0, \"recall\": 0.564545750617981, \"specificity\": 1.0, \"npv\": 0.9742506742477417, \"accuracy\": 0.975082516670227, \"f1\": 0.7216736728908006, \"f2\": 0.618402975572161, \"f0_5\": 0.8663505774105718, \"p4\": 0.8337214377623395, \"phi\": 0.7416259329684901}, {\"truth_threshold\": 29.46072623297321, \"match_probability\": 0.9999999986465641, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3689.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2849.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5642397999763489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43576017022132874, \"precision\": 1.0, \"recall\": 0.5642397999763489, \"specificity\": 1.0, \"npv\": 0.9742330312728882, \"accuracy\": 0.9750649929046631, \"f1\": 0.7214236824093087, \"f2\": 0.6181093126905934, \"f0_5\": 0.86620644312952, \"p4\": 0.8335513661031841, \"phi\": 0.7414182980326581}, {\"truth_threshold\": 29.4676828614005, \"match_probability\": 0.9999999986530745, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3688.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2850.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5640868544578552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4359131157398224, \"precision\": 1.0, \"recall\": 0.5640868544578552, \"specificity\": 1.0, \"npv\": 0.9742242693901062, \"accuracy\": 0.9750562310218811, \"f1\": 0.7212986504987288, \"f2\": 0.6179624664879356, \"f0_5\": 0.8661343353687178, \"p4\": 0.8334662884581334, \"phi\": 0.7413144615736531}, {\"truth_threshold\": 29.47122321910575, \"match_probability\": 0.9999999986563759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3684.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2854.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5634750723838806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4365249276161194, \"precision\": 1.0, \"recall\": 0.5634750723838806, \"specificity\": 1.0, \"npv\": 0.9741889834403992, \"accuracy\": 0.975021243095398, \"f1\": 0.7207982782234397, \"f2\": 0.6173749832417215, \"f0_5\": 0.8658456331672464, \"p4\": 0.8331256987717405, \"phi\": 0.7408989292605943}, {\"truth_threshold\": 29.47950586227227, \"match_probability\": 0.9999999986640676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3683.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2855.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.563322126865387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43667787313461304, \"precision\": 1.0, \"recall\": 0.563322126865387, \"specificity\": 1.0, \"npv\": 0.9741801619529724, \"accuracy\": 0.975012481212616, \"f1\": 0.7206731239604736, \"f2\": 0.6172280878163231, \"f0_5\": 0.8657733897508227, \"p4\": 0.8330404815014162, \"phi\": 0.7407950294005071}, {\"truth_threshold\": 29.485505790063648, \"match_probability\": 0.999999998669612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3681.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2857.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5630162358283997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43698379397392273, \"precision\": 1.0, \"recall\": 0.5630162358283997, \"specificity\": 1.0, \"npv\": 0.9741625785827637, \"accuracy\": 0.974994957447052, \"f1\": 0.7204227419512672, \"f2\": 0.6169342674219823, \"f0_5\": 0.8656288213714608, \"p4\": 0.832869963041107, \"phi\": 0.7405871318226059}, {\"truth_threshold\": 29.49667487100124, \"match_probability\": 0.9999999986798719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3680.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2858.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.562863290309906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4371367394924164, \"precision\": 1.0, \"recall\": 0.562863290309906, \"specificity\": 1.0, \"npv\": 0.9741537570953369, \"accuracy\": 0.97498619556427, \"f1\": 0.7202975141906439, \"f2\": 0.6167873424510593, \"f0_5\": 0.8655564963778343, \"p4\": 0.8327846618221711, \"phi\": 0.7404831938540516}, {\"truth_threshold\": 29.501943969024992, \"match_probability\": 0.9999999986846845, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3677.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2861.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5624043941497803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4375956058502197, \"precision\": 1.0, \"recall\": 0.5624043941497803, \"specificity\": 1.0, \"npv\": 0.9741273522377014, \"accuracy\": 0.9749599695205688, \"f1\": 0.7199216837983358, \"f2\": 0.6163465084313923, \"f0_5\": 0.8653393579967994, \"p4\": 0.8325285900363216, \"phi\": 0.7401712438613917}, {\"truth_threshold\": 29.50694341920096, \"match_probability\": 0.9999999986892346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3676.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2862.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5622514486312866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4377485513687134, \"precision\": 1.0, \"recall\": 0.5622514486312866, \"specificity\": 1.0, \"npv\": 0.9741185307502747, \"accuracy\": 0.9749512076377869, \"f1\": 0.7197963579400822, \"f2\": 0.616199544052568, \"f0_5\": 0.865266924018454, \"p4\": 0.8324431766829895, \"phi\": 0.7400672550084928}, {\"truth_threshold\": 29.50711277204797, \"match_probability\": 0.9999999986893885, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3671.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2867.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5614867210388184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.43851330876350403, \"precision\": 1.0, \"recall\": 0.5614867210388184, \"specificity\": 1.0, \"npv\": 0.9740744829177856, \"accuracy\": 0.9749074578285217, \"f1\": 0.7191693603683025, \"f2\": 0.6154645743218321, \"f0_5\": 0.8649043445481105, \"p4\": 0.832015688576862, \"phi\": 0.7395470597991384}, {\"truth_threshold\": 29.51995814454107, \"match_probability\": 0.9999999987010061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3670.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2868.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5613337159156799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4386662542819977, \"precision\": 1.0, \"recall\": 0.5613337159156799, \"specificity\": 1.0, \"npv\": 0.9740656614303589, \"accuracy\": 0.9748986959457397, \"f1\": 0.7190438871473355, \"f2\": 0.6153175508014218, \"f0_5\": 0.8648317466302197, \"p4\": 0.8319301065858186, \"phi\": 0.7394429944610366}, {\"truth_threshold\": 29.532777889622388, \"match_probability\": 0.9999999987124978, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3667.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2871.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.560874879360199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.439125120639801, \"precision\": 1.0, \"recall\": 0.560874879360199, \"specificity\": 1.0, \"npv\": 0.9740392565727234, \"accuracy\": 0.9748724102973938, \"f1\": 0.7186673199412053, \"f2\": 0.614876421073812, \"f0_5\": 0.8646137885504103, \"p4\": 0.8316731916105079, \"phi\": 0.7391306619554299}, {\"truth_threshold\": 29.546576878637392, \"match_probability\": 0.9999999987247536, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3666.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2872.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5607219338417053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4392780661582947, \"precision\": 1.0, \"recall\": 0.5607219338417053, \"specificity\": 1.0, \"npv\": 0.9740304350852966, \"accuracy\": 0.9748637080192566, \"f1\": 0.7185417483339867, \"f2\": 0.6147293581058421, \"f0_5\": 0.8645410810300915, \"p4\": 0.8315874969026409, \"phi\": 0.7390265455158072}, {\"truth_threshold\": 29.55480973046622, \"match_probability\": 0.9999999987320102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3664.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2874.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.560416042804718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.439583957195282, \"precision\": 1.0, \"recall\": 0.560416042804718, \"specificity\": 1.0, \"npv\": 0.9740127921104431, \"accuracy\": 0.9748461842536926, \"f1\": 0.7182905312683787, \"f2\": 0.6144352025757982, \"f0_5\": 0.8643955836557516, \"p4\": 0.8314160228249897, \"phi\": 0.7388182742699986}, {\"truth_threshold\": 29.556984101700557, \"match_probability\": 0.9999999987339199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3663.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2875.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5602630972862244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.439736932516098, \"precision\": 1.0, \"recall\": 0.5602630972862244, \"specificity\": 1.0, \"npv\": 0.9740040302276611, \"accuracy\": 0.9748374223709106, \"f1\": 0.7181648857955103, \"f2\": 0.6142881100117391, \"f0_5\": 0.8643227937706466, \"p4\": 0.8313302434259128, \"phi\": 0.7387140595431966}, {\"truth_threshold\": 29.561359713682428, \"match_probability\": 0.999999998737754, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3661.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2877.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5599571466445923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4400428235530853, \"precision\": 1.0, \"recall\": 0.5599571466445923, \"specificity\": 1.0, \"npv\": 0.9739863872528076, \"accuracy\": 0.9748198986053467, \"f1\": 0.7179135209334249, \"f2\": 0.6139938952805823, \"f0_5\": 0.864177131526768, \"p4\": 0.8311585998339484, \"phi\": 0.7385057114774382}, {\"truth_threshold\": 29.565083834764398, \"match_probability\": 0.9999999987410081, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3658.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2880.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5594983100891113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44050168991088867, \"precision\": 1.0, \"recall\": 0.5594983100891113, \"specificity\": 1.0, \"npv\": 0.9739599823951721, \"accuracy\": 0.9747936725616455, \"f1\": 0.7175362887406826, \"f2\": 0.6135524991613552, \"f0_5\": 0.8639584317430326, \"p4\": 0.8309009222412477, \"phi\": 0.738193033308094}, {\"truth_threshold\": 29.565167274976723, \"match_probability\": 0.9999999987410809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3656.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2882.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.559192419052124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.440807580947876, \"precision\": 1.0, \"recall\": 0.559192419052124, \"specificity\": 1.0, \"npv\": 0.9739423990249634, \"accuracy\": 0.9747761487960815, \"f1\": 0.717284677261134, \"f2\": 0.6132581857219538, \"f0_5\": 0.863812494093186, \"p4\": 0.8307289955380855, \"phi\": 0.7379845570006338}, {\"truth_threshold\": 29.570483795416102, \"match_probability\": 0.9999999987457117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3654.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2884.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5588865280151367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44111350178718567, \"precision\": 1.0, \"recall\": 0.5588865280151367, \"specificity\": 1.0, \"npv\": 0.9739247560501099, \"accuracy\": 0.9747586846351624, \"f1\": 0.717032967032967, \"f2\": 0.6129638327853453, \"f0_5\": 0.8636664460622104, \"p4\": 0.8305569553844, \"phi\": 0.7377759693450276}, {\"truth_threshold\": 29.571169289033005, \"match_probability\": 0.9999999987463075, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3652.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2886.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5585805773735046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.441419392824173, \"precision\": 1.0, \"recall\": 0.5585805773735046, \"specificity\": 1.0, \"npv\": 0.9739071726799011, \"accuracy\": 0.9747411608695984, \"f1\": 0.7167811579980373, \"f2\": 0.6126694403435781, \"f0_5\": 0.8635202875248273, \"p4\": 0.8303848016622067, \"phi\": 0.7375673902434011}, {\"truth_threshold\": 29.571598898187265, \"match_probability\": 0.9999999987466808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3650.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2888.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5582746863365173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4417252838611603, \"precision\": 1.0, \"recall\": 0.5582746863365173, \"specificity\": 1.0, \"npv\": 0.9738895297050476, \"accuracy\": 0.9747236371040344, \"f1\": 0.7165292500981547, \"f2\": 0.6123750083886987, \"f0_5\": 0.8633740183555682, \"p4\": 0.8302125342533578, \"phi\": 0.7373586996738279}, {\"truth_threshold\": 29.572423090979523, \"match_probability\": 0.9999999987473965, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3648.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2890.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.55796879529953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44203120470046997, \"precision\": 1.0, \"recall\": 0.55796879529953, \"specificity\": 1.0, \"npv\": 0.9738719463348389, \"accuracy\": 0.9747061729431152, \"f1\": 0.7162772432750835, \"f2\": 0.6120805369127517, \"f0_5\": 0.8632276384287743, \"p4\": 0.8300401530395416, \"phi\": 0.7371500176018306}, {\"truth_threshold\": 29.57329979449861, \"match_probability\": 0.9999999987481575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3646.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2892.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5576629042625427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4423370957374573, \"precision\": 1.0, \"recall\": 0.5576629042625427, \"specificity\": 1.0, \"npv\": 0.9738543033599854, \"accuracy\": 0.9746886491775513, \"f1\": 0.716025137470542, \"f2\": 0.6117860259077791, \"f0_5\": 0.8630811476185968, \"p4\": 0.8298676579022826, \"phi\": 0.7369412839863791}, {\"truth_threshold\": 29.577865779150923, \"match_probability\": 0.9999999987521132, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3644.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2894.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5573570132255554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44264301657676697, \"precision\": 1.0, \"recall\": 0.5573570132255554, \"specificity\": 1.0, \"npv\": 0.9738367199897766, \"accuracy\": 0.9746711254119873, \"f1\": 0.7157729326262031, \"f2\": 0.6114914753658209, \"f0_5\": 0.862934545798996, \"p4\": 0.8296950487229404, \"phi\": 0.7367324387227325}, {\"truth_threshold\": 29.578088702972796, \"match_probability\": 0.999999998752306, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3643.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2895.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5572040677070618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4427959620952606, \"precision\": 1.0, \"recall\": 0.5572040677070618, \"specificity\": 1.0, \"npv\": 0.9738278985023499, \"accuracy\": 0.9746623635292053, \"f1\": 0.7156467930458698, \"f2\": 0.6113441852659842, \"f0_5\": 0.8628612032212222, \"p4\": 0.8296087013303682, \"phi\": 0.7366280267539852}, {\"truth_threshold\": 29.583907709056053, \"match_probability\": 0.9999999987573284, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3642.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2896.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5570510625839233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4429489076137543, \"precision\": 1.0, \"recall\": 0.5570510625839233, \"specificity\": 1.0, \"npv\": 0.9738190770149231, \"accuracy\": 0.9746536612510681, \"f1\": 0.7155206286836935, \"f2\": 0.6111968852789152, \"f0_5\": 0.8627878328437412, \"p4\": 0.8295223253827105, \"phi\": 0.7365236018717058}, {\"truth_threshold\": 29.584158732313178, \"match_probability\": 0.9999999987575445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3640.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2898.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.556745171546936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44325482845306396, \"precision\": 1.0, \"recall\": 0.556745171546936, \"specificity\": 1.0, \"npv\": 0.9738014936447144, \"accuracy\": 0.9746361374855042, \"f1\": 0.7152682255845942, \"f2\": 0.6109022556390977, \"f0_5\": 0.8626410086264101, \"p4\": 0.8293494877626233, \"phi\": 0.7363146532519432}, {\"truth_threshold\": 29.604832826751196, \"match_probability\": 0.9999999987752222, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3639.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2899.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5565922260284424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4434077739715576, \"precision\": 1.0, \"recall\": 0.5565922260284424, \"specificity\": 1.0, \"npv\": 0.9737926721572876, \"accuracy\": 0.9746273756027222, \"f1\": 0.715141986833055, \"f2\": 0.6107549259843577, \"f0_5\": 0.8625675547549067, \"p4\": 0.82926302606041, \"phi\": 0.7362101895877999}, {\"truth_threshold\": 29.607418512335727, \"match_probability\": 0.9999999987774154, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3638.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2900.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5564392805099487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44356071949005127, \"precision\": 1.0, \"recall\": 0.5564392805099487, \"specificity\": 1.0, \"npv\": 0.9737839102745056, \"accuracy\": 0.9746186137199402, \"f1\": 0.7150157232704403, \"f2\": 0.6106075864384022, \"f0_5\": 0.8624940730203888, \"p4\": 0.8291765357435438, \"phi\": 0.7361057129879197}, {\"truth_threshold\": 29.614949829884683, \"match_probability\": 0.999999998783781, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3635.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2903.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5559804439544678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4440195858478546, \"precision\": 1.0, \"recall\": 0.5559804439544678, \"specificity\": 1.0, \"npv\": 0.9737575054168701, \"accuracy\": 0.974592387676239, \"f1\": 0.7146367836429766, \"f2\": 0.6101655084432807, \"f0_5\": 0.8622734604801214, \"p4\": 0.8289168929557991, \"phi\": 0.7357921453858569}, {\"truth_threshold\": 29.621894810023033, \"match_probability\": 0.9999999987896216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3634.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2904.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5558274984359741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44417253136634827, \"precision\": 1.0, \"recall\": 0.5558274984359741, \"specificity\": 1.0, \"npv\": 0.9737486839294434, \"accuracy\": 0.974583625793457, \"f1\": 0.7145104207628785, \"f2\": 0.6100181293225005, \"f0_5\": 0.8621998671348581, \"p4\": 0.8288302880310406, \"phi\": 0.7356876169793893}, {\"truth_threshold\": 29.622977870525524, \"match_probability\": 0.99999999879053, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3633.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2905.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5556744933128357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4443254768848419, \"precision\": 1.0, \"recall\": 0.5556744933128357, \"specificity\": 1.0, \"npv\": 0.9737398624420166, \"accuracy\": 0.974574863910675, \"f1\": 0.7143840330350998, \"f2\": 0.6098707403055229, \"f0_5\": 0.8621262458471761, \"p4\": 0.828743654416937, \"phi\": 0.7355830756093431}, {\"truth_threshold\": 29.623145385414844, \"match_probability\": 0.9999999987906705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3632.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2906.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.555521547794342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44447842240333557, \"precision\": 1.0, \"recall\": 0.555521547794342, \"specificity\": 1.0, \"npv\": 0.9737311005592346, \"accuracy\": 0.9745661020278931, \"f1\": 0.7142576204523107, \"f2\": 0.6097233413913511, \"f0_5\": 0.8620525966011583, \"p4\": 0.8286569920985186, \"phi\": 0.7354784611137439}, {\"truth_threshold\": 29.628355549604617, \"match_probability\": 0.99999999879503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3630.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2908.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5552156567573547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44478434324264526, \"precision\": 1.0, \"recall\": 0.5552156567573547, \"specificity\": 1.0, \"npv\": 0.9737134575843811, \"accuracy\": 0.9745485782623291, \"f1\": 0.7140047206923682, \"f2\": 0.6094285138674367, \"f0_5\": 0.8619052141703866, \"p4\": 0.8284835812888068, \"phi\": 0.7352693134894999}, {\"truth_threshold\": 29.62929761239644, \"match_probability\": 0.9999999987958165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3628.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2910.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5549097657203674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44509023427963257, \"precision\": 1.0, \"recall\": 0.5549097657203674, \"specificity\": 1.0, \"npv\": 0.9736958742141724, \"accuracy\": 0.9745311141014099, \"f1\": 0.7137517214243557, \"f2\": 0.6091336467427804, \"f0_5\": 0.8617577197149644, \"p4\": 0.8283100554819401, \"phi\": 0.7350601139215637}, {\"truth_threshold\": 29.63890883314669, \"match_probability\": 0.9999999988038121, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3626.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2912.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5546038746833801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44539615511894226, \"precision\": 1.0, \"recall\": 0.5546038746833801, \"specificity\": 1.0, \"npv\": 0.9736782908439636, \"accuracy\": 0.974513590335846, \"f1\": 0.7134986225895317, \"f2\": 0.608838740009403, \"f0_5\": 0.8616101131071191, \"p4\": 0.8281364145577861, \"phi\": 0.7348508021606498}, {\"truth_threshold\": 29.641889782934182, \"match_probability\": 0.9999999988062812, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3624.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2914.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.554297924041748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44570204615592957, \"precision\": 1.0, \"recall\": 0.554297924041748, \"specificity\": 1.0, \"npv\": 0.9736606478691101, \"accuracy\": 0.974496066570282, \"f1\": 0.7132454241291084, \"f2\": 0.608543793659323, \"f0_5\": 0.8614623942188837, \"p4\": 0.8279626583960454, \"phi\": 0.7346414985548824}, {\"truth_threshold\": 29.64394438836084, \"match_probability\": 0.99999999880798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3623.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2915.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5541449785232544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4458549916744232, \"precision\": 1.0, \"recall\": 0.5541449785232544, \"specificity\": 1.0, \"npv\": 0.9736518859863281, \"accuracy\": 0.9744873642921448, \"f1\": 0.7131187875209133, \"f2\": 0.6083963056255247, \"f0_5\": 0.8613884926295768, \"p4\": 0.8278757370634406, \"phi\": 0.7345368272254783}, {\"truth_threshold\": 29.654887724627184, \"match_probability\": 0.9999999988169876, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3621.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2917.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5538390874862671, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4461609125137329, \"precision\": 1.0, \"recall\": 0.5538390874862671, \"specificity\": 1.0, \"npv\": 0.9736342430114746, \"accuracy\": 0.9744698405265808, \"f1\": 0.712865439511763, \"f2\": 0.6081012998354214, \"f0_5\": 0.861240605080392, \"p4\": 0.8277018078193917, \"phi\": 0.7343273852408364}, {\"truth_threshold\": 29.65491910294371, \"match_probability\": 0.9999999988170134, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3620.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2918.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5536861419677734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44631385803222656, \"precision\": 1.0, \"recall\": 0.5536861419677734, \"specificity\": 1.0, \"npv\": 0.9736254811286926, \"accuracy\": 0.9744610786437988, \"f1\": 0.7127387280960819, \"f2\": 0.6079537820771195, \"f0_5\": 0.8611666190884004, \"p4\": 0.827614799877768, \"phi\": 0.7342226748110058}, {\"truth_threshold\": 29.654966318612857, \"match_probability\": 0.9999999988170521, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3619.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2919.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5535331964492798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4464668035507202, \"precision\": 1.0, \"recall\": 0.5535331964492798, \"specificity\": 1.0, \"npv\": 0.9736166596412659, \"accuracy\": 0.9744523167610168, \"f1\": 0.7126119917298415, \"f2\": 0.6078062544086528, \"f0_5\": 0.8610926049300467, \"p4\": 0.827527763036274, \"phi\": 0.7341179513391249}, {\"truth_threshold\": 29.657026278090623, \"match_probability\": 0.99999999881874, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3617.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2921.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5532273054122925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4467727243900299, \"precision\": 1.0, \"recall\": 0.5532273054122925, \"specificity\": 1.0, \"npv\": 0.9735990762710571, \"accuracy\": 0.9744348526000977, \"f1\": 0.7123584441161989, \"f2\": 0.60751116933723, \"f0_5\": 0.8609444920498905, \"p4\": 0.8273536025931999, \"phi\": 0.733908404969758}, {\"truth_threshold\": 29.66060390424601, \"match_probability\": 0.9999999988216657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3615.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2923.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5529213547706604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4470786154270172, \"precision\": 1.0, \"recall\": 0.5529213547706604, \"specificity\": 1.0, \"npv\": 0.9735814332962036, \"accuracy\": 0.9744173288345337, \"f1\": 0.7121047966118389, \"f2\": 0.6072160446131623, \"f0_5\": 0.8607962663110772, \"p4\": 0.8271793263691141, \"phi\": 0.7336988666253258}, {\"truth_threshold\": 29.66384944157847, \"match_probability\": 0.9999999988243135, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3614.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2924.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5527684092521667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44723156094551086, \"precision\": 1.0, \"recall\": 0.5527684092521667, \"specificity\": 1.0, \"npv\": 0.9735726714134216, \"accuracy\": 0.9744085669517517, \"f1\": 0.7119779353821907, \"f2\": 0.6070684673788886, \"f0_5\": 0.860722111079356, \"p4\": 0.8270921448013157, \"phi\": 0.7335940778505434}, {\"truth_threshold\": 29.67345847855419, \"match_probability\": 0.9999999988321181, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3612.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2926.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5524625182151794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44753748178482056, \"precision\": 1.0, \"recall\": 0.5524625182151794, \"specificity\": 1.0, \"npv\": 0.9735550880432129, \"accuracy\": 0.9743910431861877, \"f1\": 0.7117241379310345, \"f2\": 0.6067732831608654, \"f0_5\": 0.8605737158105403, \"p4\": 0.8269176946783633, \"phi\": 0.7333844007503214}, {\"truth_threshold\": 29.67548126835372, \"match_probability\": 0.9999999988337545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3611.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2927.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5523095726966858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4476904273033142, \"precision\": 1.0, \"recall\": 0.5523095726966858, \"specificity\": 1.0, \"npv\": 0.9735462665557861, \"accuracy\": 0.9743823409080505, \"f1\": 0.7115972016947483, \"f2\": 0.6066256761751168, \"f0_5\": 0.8604994757411114, \"p4\": 0.8268304260928397, \"phi\": 0.7332795727227438}, {\"truth_threshold\": 29.68441237788024, \"match_probability\": 0.9999999988409519, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3610.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2928.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5521566271781921, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44784337282180786, \"precision\": 1.0, \"recall\": 0.5521566271781921, \"specificity\": 1.0, \"npv\": 0.9735374450683594, \"accuracy\": 0.9743735790252686, \"f1\": 0.7114702404414663, \"f2\": 0.6064780592702104, \"f0_5\": 0.8604252073600915, \"p4\": 0.8267431284710206, \"phi\": 0.733174731602266}, {\"truth_threshold\": 29.68453415142107, \"match_probability\": 0.9999999988410497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3609.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2929.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5520036816596985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4479963183403015, \"precision\": 1.0, \"recall\": 0.5520036816596985, \"specificity\": 1.0, \"npv\": 0.9735286831855774, \"accuracy\": 0.9743648171424866, \"f1\": 0.7113432541637923, \"f2\": 0.6063304324451463, \"f0_5\": 0.8603509106512826, \"p4\": 0.8266558017976945, \"phi\": 0.7330698170417139}, {\"truth_threshold\": 29.69230740992224, \"match_probability\": 0.9999999988472773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3608.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2930.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5518507361412048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44814929366111755, \"precision\": 1.0, \"recall\": 0.5518507361412048, \"specificity\": 1.0, \"npv\": 0.9735198616981506, \"accuracy\": 0.9743560552597046, \"f1\": 0.7112162428543268, \"f2\": 0.6061827956989247, \"f0_5\": 0.860276585598474, \"p4\": 0.8265684460576396, \"phi\": 0.7329649497103361}, {\"truth_threshold\": 29.694358149487, \"match_probability\": 0.9999999988489148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3607.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2931.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5516977906227112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4483022391796112, \"precision\": 1.0, \"recall\": 0.5516977906227112, \"specificity\": 1.0, \"npv\": 0.9735110998153687, \"accuracy\": 0.9743472933769226, \"f1\": 0.7110892065056679, \"f2\": 0.6060351490305453, \"f0_5\": 0.8602022321854431, \"p4\": 0.8264810612356233, \"phi\": 0.7328600692690361}, {\"truth_threshold\": 29.70170610792449, \"match_probability\": 0.9999999988547625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3605.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2933.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5513918399810791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4486081302165985, \"precision\": 1.0, \"recall\": 0.5513918399810791, \"specificity\": 1.0, \"npv\": 0.9734934568405151, \"accuracy\": 0.9743298292160034, \"f1\": 0.7108350586611456, \"f2\": 0.6057398259233122, \"f0_5\": 0.8600534402137608, \"p4\": 0.8263062042847231, \"phi\": 0.7326502690339428}, {\"truth_threshold\": 29.716501880079704, \"match_probability\": 0.9999999988664476, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3602.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2936.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5509330034255981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44906699657440186, \"precision\": 1.0, \"recall\": 0.5509330034255981, \"specificity\": 1.0, \"npv\": 0.9734671115875244, \"accuracy\": 0.9743035435676575, \"f1\": 0.7104536489151874, \"f2\": 0.6052967668212678, \"f0_5\": 0.859830039148286, \"p4\": 0.8260437003622371, \"phi\": 0.7323354098165404}, {\"truth_threshold\": 29.717219769046345, \"match_probability\": 0.9999999988670116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3601.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2937.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5507800579071045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4492199420928955, \"precision\": 1.0, \"recall\": 0.5507800579071045, \"specificity\": 1.0, \"npv\": 0.9734582901000977, \"accuracy\": 0.9742947816848755, \"f1\": 0.710326462175757, \"f2\": 0.6051490605989313, \"f0_5\": 0.859755515232547, \"p4\": 0.8259561407279729, \"phi\": 0.7322304505881606}, {\"truth_threshold\": 29.718546368082727, \"match_probability\": 0.9999999988680529, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3600.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2938.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5506271123886108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44937288761138916, \"precision\": 1.0, \"recall\": 0.5506271123886108, \"specificity\": 1.0, \"npv\": 0.9734494686126709, \"accuracy\": 0.9742860198020935, \"f1\": 0.7101992503452358, \"f2\": 0.6050013444474321, \"f0_5\": 0.8596809628426784, \"p4\": 0.8258685519048211, \"phi\": 0.7321254782100067}, {\"truth_threshold\": 29.73020784994289, \"match_probability\": 0.9999999988771657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3599.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2939.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5504741668701172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4495258629322052, \"precision\": 1.0, \"recall\": 0.5504741668701172, \"specificity\": 1.0, \"npv\": 0.9734407067298889, \"accuracy\": 0.9742772579193115, \"f1\": 0.7100720134161981, \"f2\": 0.6048536183657692, \"f0_5\": 0.8596063819623578, \"p4\": 0.8257809338774641, \"phi\": 0.7320204322538229}, {\"truth_threshold\": 29.737708224626047, \"match_probability\": 0.9999999988829881, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3597.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2941.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5501682758331299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4498317539691925, \"precision\": 1.0, \"recall\": 0.5501682758331299, \"specificity\": 1.0, \"npv\": 0.9734231233596802, \"accuracy\": 0.9742597937583923, \"f1\": 0.7098174642328564, \"f2\": 0.6045581364079465, \"f0_5\": 0.8594571346650101, \"p4\": 0.8256056101488087, \"phi\": 0.7318104216809993}, {\"truth_threshold\": 29.75157050868302, \"match_probability\": 0.9999999988936695, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3594.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2944.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5497093796730042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45029062032699585, \"precision\": 1.0, \"recall\": 0.5497093796730042, \"specificity\": 1.0, \"npv\": 0.9733967185020447, \"accuracy\": 0.9742335081100464, \"f1\": 0.7094354520331623, \"f2\": 0.6041148389699456, \"f0_5\": 0.8592330496318256, \"p4\": 0.8253424051407218, \"phi\": 0.7314952465494802}, {\"truth_threshold\": 29.760887468032315, \"match_probability\": 0.9999999989007913, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3593.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2945.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5495564341545105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4504435658454895, \"precision\": 1.0, \"recall\": 0.5495564341545105, \"specificity\": 1.0, \"npv\": 0.9733878970146179, \"accuracy\": 0.9742247462272644, \"f1\": 0.7093080643569243, \"f2\": 0.6039670532862667, \"f0_5\": 0.8591582974653276, \"p4\": 0.8252546115658562, \"phi\": 0.7313901819465662}, {\"truth_threshold\": 29.761978038235846, \"match_probability\": 0.9999999989016218, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3591.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2947.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5492505431175232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4507494568824768, \"precision\": 1.0, \"recall\": 0.5492505431175232, \"specificity\": 1.0, \"npv\": 0.9733703136444092, \"accuracy\": 0.9742072820663452, \"f1\": 0.7090532135452661, \"f2\": 0.603671452106378, \"f0_5\": 0.8590087073007368, \"p4\": 0.8250789364655284, \"phi\": 0.731180013148316}, {\"truth_threshold\": 29.773344676133153, \"match_probability\": 0.9999999989102417, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3589.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2949.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5489446520805359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4510553777217865, \"precision\": 1.0, \"recall\": 0.5489446520805359, \"specificity\": 1.0, \"npv\": 0.9733527302742004, \"accuracy\": 0.9741897583007812, \"f1\": 0.7087982620716895, \"f2\": 0.6033758111697657, \"f0_5\": 0.858859002584474, \"p4\": 0.8249031439949916, \"phi\": 0.7309697310179464}, {\"truth_threshold\": 29.77962686771524, \"match_probability\": 0.9999999989149767, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3586.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2952.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5484857559204102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45151421427726746, \"precision\": 1.0, \"recall\": 0.5484857559204102, \"specificity\": 1.0, \"npv\": 0.9733263254165649, \"accuracy\": 0.9741635322570801, \"f1\": 0.7084156459897274, \"f2\": 0.6029322752034434, \"f0_5\": 0.8586342304376975, \"p4\": 0.8246392349499584, \"phi\": 0.7306542388718904}, {\"truth_threshold\": 29.781999642530522, \"match_probability\": 0.9999999989167598, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3584.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2954.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5481798648834229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45182013511657715, \"precision\": 1.0, \"recall\": 0.5481798648834229, \"specificity\": 1.0, \"npv\": 0.9733087420463562, \"accuracy\": 0.9741460084915161, \"f1\": 0.7081604426002767, \"f2\": 0.6026365348399246, \"f0_5\": 0.8584842387659289, \"p4\": 0.8244631485134423, \"phi\": 0.7304438849408985}, {\"truth_threshold\": 29.782810816090638, \"match_probability\": 0.9999999989173687, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3583.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2955.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5480269193649292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4519730806350708, \"precision\": 1.0, \"recall\": 0.5480269193649292, \"specificity\": 1.0, \"npv\": 0.9732999801635742, \"accuracy\": 0.9741372466087341, \"f1\": 0.7080328030826993, \"f2\": 0.6024886497393643, \"f0_5\": 0.8584091998083373, \"p4\": 0.8243750611267974, \"phi\": 0.7303386881072236}, {\"truth_threshold\": 29.788717601011168, \"match_probability\": 0.9999999989217923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3582.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2956.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5478739738464355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45212602615356445, \"precision\": 1.0, \"recall\": 0.5478739738464355, \"specificity\": 1.0, \"npv\": 0.9732911586761475, \"accuracy\": 0.9741284847259521, \"f1\": 0.707905138339921, \"f2\": 0.6023407546915989, \"f0_5\": 0.8583341320808971, \"p4\": 0.8242869442738966, \"phi\": 0.7302334780203951}, {\"truth_threshold\": 29.791709767475975, \"match_probability\": 0.9999999989240261, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3581.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2957.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5477210283279419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4522789716720581, \"precision\": 1.0, \"recall\": 0.5477210283279419, \"specificity\": 1.0, \"npv\": 0.9732823967933655, \"accuracy\": 0.9741197228431702, \"f1\": 0.7077774483644629, \"f2\": 0.6021928496956244, \"f0_5\": 0.8582590355670597, \"p4\": 0.8241987979392277, \"phi\": 0.7301281941053431}, {\"truth_threshold\": 29.793166341176033, \"match_probability\": 0.9999999989251118, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3580.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2958.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5475680828094482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45243194699287415, \"precision\": 1.0, \"recall\": 0.5475680828094482, \"specificity\": 1.0, \"npv\": 0.9732735753059387, \"accuracy\": 0.974111020565033, \"f1\": 0.7076497331488436, \"f2\": 0.6020449347504372, \"f0_5\": 0.8581839102502636, \"p4\": 0.8241106221072677, \"phi\": 0.7300229574866758}, {\"truth_threshold\": 29.796407749444807, \"match_probability\": 0.9999999989275242, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3579.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2959.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5474151372909546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4525848925113678, \"precision\": 1.0, \"recall\": 0.5474151372909546, \"specificity\": 1.0, \"npv\": 0.9732648134231567, \"accuracy\": 0.974102258682251, \"f1\": 0.7075219926855787, \"f2\": 0.6018970098550335, \"f0_5\": 0.858108756113935, \"p4\": 0.8240224167624829, \"phi\": 0.7299177075974966}, {\"truth_threshold\": 29.798920600026904, \"match_probability\": 0.9999999989293906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3578.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2960.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5472621321678162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45273783802986145, \"precision\": 1.0, \"recall\": 0.5472621321678162, \"specificity\": 1.0, \"npv\": 0.97325599193573, \"accuracy\": 0.974093496799469, \"f1\": 0.7073942269671807, \"f2\": 0.601749075008409, \"f0_5\": 0.8580335731414868, \"p4\": 0.8239341818893282, \"phi\": 0.7298124444320129}, {\"truth_threshold\": 29.81018026029652, \"match_probability\": 0.9999999989377137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3577.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2961.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5471091866493225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4528907835483551, \"precision\": 1.0, \"recall\": 0.5471091866493225, \"specificity\": 1.0, \"npv\": 0.9732471704483032, \"accuracy\": 0.974084734916687, \"f1\": 0.7072664359861591, \"f2\": 0.6016011302095597, \"f0_5\": 0.8579583613163196, \"p4\": 0.823845917472248, \"phi\": 0.729707107382377}, {\"truth_threshold\": 29.815622948467922, \"match_probability\": 0.9999999989417138, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3576.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2962.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5469562411308289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45304375886917114, \"precision\": 1.0, \"recall\": 0.5469562411308289, \"specificity\": 1.0, \"npv\": 0.9732384085655212, \"accuracy\": 0.974075973033905, \"f1\": 0.7071386197350208, \"f2\": 0.6014531754574811, \"f0_5\": 0.8578831206218214, \"p4\": 0.8237576234956758, \"phi\": 0.7296018176386897}, {\"truth_threshold\": 29.818180108484636, \"match_probability\": 0.9999999989435879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3575.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2963.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5468032956123352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4531967043876648, \"precision\": 1.0, \"recall\": 0.5468032956123352, \"specificity\": 1.0, \"npv\": 0.9732295870780945, \"accuracy\": 0.974067211151123, \"f1\": 0.7070107782062691, \"f2\": 0.6013052107511689, \"f0_5\": 0.8578078510413667, \"p4\": 0.823669299944034, \"phi\": 0.7294965146012907}, {\"truth_threshold\": 29.82082215044492, \"match_probability\": 0.9999999989455207, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3574.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2964.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5466503500938416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45334964990615845, \"precision\": 1.0, \"recall\": 0.5466503500938416, \"specificity\": 1.0, \"npv\": 0.9732208251953125, \"accuracy\": 0.9740585088729858, \"f1\": 0.7068829113924051, \"f2\": 0.6011572360896185, \"f0_5\": 0.8577325525583182, \"p4\": 0.823580946801734, \"phi\": 0.7293911982643712}, {\"truth_threshold\": 29.82182238446134, \"match_probability\": 0.9999999989462516, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3572.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2966.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5463444590568542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45365554094314575, \"precision\": 1.0, \"recall\": 0.5463444590568542, \"specificity\": 1.0, \"npv\": 0.9732032418251038, \"accuracy\": 0.9740409851074219, \"f1\": 0.7066271018793274, \"f2\": 0.6008612568967837, \"f0_5\": 0.8575818688178238, \"p4\": 0.8234041516827509, \"phi\": 0.7291804650256315}, {\"truth_threshold\": 29.83885607327518, \"match_probability\": 0.9999999989586199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3571.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2967.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5461915135383606, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4538085162639618, \"precision\": 1.0, \"recall\": 0.5461915135383606, \"specificity\": 1.0, \"npv\": 0.973194420337677, \"accuracy\": 0.9740322232246399, \"f1\": 0.7064991591651004, \"f2\": 0.6007132523634896, \"f0_5\": 0.8575064835270387, \"p4\": 0.823315709674836, \"phi\": 0.7290751087470365}, {\"truth_threshold\": 29.850388366628597, \"match_probability\": 0.999999998966911, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3570.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2968.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5460385680198669, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45396146178245544, \"precision\": 1.0, \"recall\": 0.5460385680198669, \"specificity\": 1.0, \"npv\": 0.973185658454895, \"accuracy\": 0.9740234613418579, \"f1\": 0.7063711911357341, \"f2\": 0.6005652378709374, \"f0_5\": 0.8574310692669805, \"p4\": 0.8232272380137995, \"phi\": 0.7289697391456393}, {\"truth_threshold\": 29.85253101017226, \"match_probability\": 0.9999999989684443, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3568.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2970.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5457326173782349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45426735281944275, \"precision\": 1.0, \"recall\": 0.5457326173782349, \"specificity\": 1.0, \"npv\": 0.9731680750846863, \"accuracy\": 0.9740059971809387, \"f1\": 0.7061151791015239, \"f2\": 0.6002691790040376, \"f0_5\": 0.8572801537722249, \"p4\": 0.8230502056697772, \"phi\": 0.728758899275148}, {\"truth_threshold\": 29.856600179782504, \"match_probability\": 0.9999999989713496, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3567.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2971.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5455796718597412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4544202983379364, \"precision\": 1.0, \"recall\": 0.5455796718597412, \"specificity\": 1.0, \"npv\": 0.9731592535972595, \"accuracy\": 0.9739972352981567, \"f1\": 0.7059871350816428, \"f2\": 0.6001211346276792, \"f0_5\": 0.8572046525040854, \"p4\": 0.8229616449554716, \"phi\": 0.7286534896621191}, {\"truth_threshold\": 29.857850581060088, \"match_probability\": 0.9999999989722408, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3565.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2973.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5452737808227539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4547262191772461, \"precision\": 1.0, \"recall\": 0.5452737808227539, \"specificity\": 1.0, \"npv\": 0.9731416702270508, \"accuracy\": 0.9739797115325928, \"f1\": 0.7057309709987133, \"f2\": 0.5998250159841169, \"f0_5\": 0.857053562842581, \"p4\": 0.8227844343638901, \"phi\": 0.7284426303917672}, {\"truth_threshold\": 29.86708970896558, \"match_probability\": 0.9999999989788017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3564.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2974.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5451208353042603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45487916469573975, \"precision\": 1.0, \"recall\": 0.5451208353042603, \"specificity\": 1.0, \"npv\": 0.9731329083442688, \"accuracy\": 0.9739709496498108, \"f1\": 0.7056028509206098, \"f2\": 0.599676941714901, \"f0_5\": 0.8569779744156968, \"p4\": 0.8226957844552285, \"phi\": 0.7283371807227479}, {\"truth_threshold\": 29.87007260284283, \"match_probability\": 0.9999999989809109, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3563.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2975.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5449678897857666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4550321102142334, \"precision\": 1.0, \"recall\": 0.5449678897857666, \"specificity\": 1.0, \"npv\": 0.973124086856842, \"accuracy\": 0.9739621877670288, \"f1\": 0.7054747054747055, \"f2\": 0.5995288574793876, \"f0_5\": 0.8569023569023569, \"p4\": 0.8226071047837106, \"phi\": 0.728231656972874}, {\"truth_threshold\": 29.871070385782737, \"match_probability\": 0.9999999989816154, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3562.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2976.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.544814944267273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45518508553504944, \"precision\": 1.0, \"recall\": 0.544814944267273, \"specificity\": 1.0, \"npv\": 0.9731153249740601, \"accuracy\": 0.9739534854888916, \"f1\": 0.7053465346534653, \"f2\": 0.59938076327657, \"f0_5\": 0.8568267102857693, \"p4\": 0.822518395333616, \"phi\": 0.728126180562348}, {\"truth_threshold\": 29.871518716698972, \"match_probability\": 0.9999999989819318, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3560.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2978.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5445090532302856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45549097657203674, \"precision\": 1.0, \"recall\": 0.5445090532302856, \"specificity\": 1.0, \"npv\": 0.9730977416038513, \"accuracy\": 0.9739359617233276, \"f1\": 0.7050901168548227, \"f2\": 0.5990845449649973, \"f0_5\": 0.8566753296756184, \"p4\": 0.8223408870347593, \"phi\": 0.7279151876091554}, {\"truth_threshold\": 29.878055238762546, \"match_probability\": 0.999999998986534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3559.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2979.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5443560481071472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4556439220905304, \"precision\": 1.0, \"recall\": 0.5443560481071472, \"specificity\": 1.0, \"npv\": 0.9730889201164246, \"accuracy\": 0.9739271998405457, \"f1\": 0.7049618698623353, \"f2\": 0.598936420854229, \"f0_5\": 0.8565995956484067, \"p4\": 0.8222520881545008, \"phi\": 0.7278096710547509}, {\"truth_threshold\": 29.878498461491883, \"match_probability\": 0.9999999989868453, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3556.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2982.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5438972115516663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45610278844833374, \"precision\": 1.0, \"recall\": 0.5438972115516663, \"specificity\": 1.0, \"npv\": 0.9730625748634338, \"accuracy\": 0.9739009141921997, \"f1\": 0.7045769764216366, \"f2\": 0.5984919886899152, \"f0_5\": 0.856372218476062, \"p4\": 0.8219855124011936, \"phi\": 0.7274929802348269}, {\"truth_threshold\": 29.88927291081957, \"match_probability\": 0.9999999989943837, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3555.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2983.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5437442660331726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4562557339668274, \"precision\": 1.0, \"recall\": 0.5437442660331726, \"specificity\": 1.0, \"npv\": 0.9730538129806519, \"accuracy\": 0.9738922119140625, \"f1\": 0.7044486277618152, \"f2\": 0.598343824687784, \"f0_5\": 0.8562963676654783, \"p4\": 0.8218965940599572, \"phi\": 0.727387410064708}, {\"truth_threshold\": 29.893004760159368, \"match_probability\": 0.9999999989969816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3554.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2984.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.543591320514679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45640867948532104, \"precision\": 1.0, \"recall\": 0.543591320514679, \"specificity\": 1.0, \"npv\": 0.9730449914932251, \"accuracy\": 0.9738834500312805, \"f1\": 0.7043202536662703, \"f2\": 0.5981956507102942, \"f0_5\": 0.856220487616845, \"p4\": 0.8218076458139809, \"phi\": 0.7272817656864927}, {\"truth_threshold\": 29.911289512876117, \"match_probability\": 0.9999999990096137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3552.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2986.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5432854294776917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45671460032463074, \"precision\": 1.0, \"recall\": 0.5432854294776917, \"specificity\": 1.0, \"npv\": 0.9730274081230164, \"accuracy\": 0.9738659262657166, \"f1\": 0.7040634291377602, \"f2\": 0.5978992728252087, \"f0_5\": 0.8560686397377808, \"p4\": 0.821629659544516, \"phi\": 0.7270705582231906}, {\"truth_threshold\": 29.91265200260983, \"match_probability\": 0.9999999990105485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3551.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2987.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.543132483959198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4568675458431244, \"precision\": 1.0, \"recall\": 0.543132483959198, \"specificity\": 1.0, \"npv\": 0.9730186462402344, \"accuracy\": 0.9738571643829346, \"f1\": 0.703934978689662, \"f2\": 0.5977510689155977, \"f0_5\": 0.8559926718734934, \"p4\": 0.8215406214893529, \"phi\": 0.7269649343430621}, {\"truth_threshold\": 29.917206686869264, \"match_probability\": 0.9999999990136673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3550.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2988.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5429794788360596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45702049136161804, \"precision\": 1.0, \"recall\": 0.5429794788360596, \"specificity\": 1.0, \"npv\": 0.9730098247528076, \"accuracy\": 0.9738484025001526, \"f1\": 0.703806502775575, \"f2\": 0.5976028550265975, \"f0_5\": 0.8559166747034429, \"p4\": 0.8214515534661013, \"phi\": 0.7268592970227391}, {\"truth_threshold\": 29.918360713999267, \"match_probability\": 0.999999999014456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3547.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2991.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5425206422805786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4574793577194214, \"precision\": 1.0, \"recall\": 0.5425206422805786, \"specificity\": 1.0, \"npv\": 0.9729834794998169, \"accuracy\": 0.9738221764564514, \"f1\": 0.7034209221616262, \"f2\": 0.5971581534731809, \"f0_5\": 0.8556885071890379, \"p4\": 0.8211841694291084, \"phi\": 0.7265422435119094}, {\"truth_threshold\": 29.92086037858589, \"match_probability\": 0.9999999990161621, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3546.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2992.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.542367696762085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45763230323791504, \"precision\": 1.0, \"recall\": 0.542367696762085, \"specificity\": 1.0, \"npv\": 0.9729746580123901, \"accuracy\": 0.9738134145736694, \"f1\": 0.7032923443078144, \"f2\": 0.5970098996565425, \"f0_5\": 0.8556123926261944, \"p4\": 0.8210949813747397, \"phi\": 0.726436552363336}, {\"truth_threshold\": 29.9260120063931, \"match_probability\": 0.999999999019669, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3544.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2994.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5420618057250977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45793819427490234, \"precision\": 1.0, \"recall\": 0.5420618057250977, \"specificity\": 1.0, \"npv\": 0.9729571342468262, \"accuracy\": 0.9737958908081055, \"f1\": 0.7030351120809363, \"f2\": 0.5967133620689655, \"f0_5\": 0.8554600753113836, \"p4\": 0.8209165151075031, \"phi\": 0.7262250687763769}, {\"truth_threshold\": 29.935495724954286, \"match_probability\": 0.9999999990260922, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3543.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2995.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.541908860206604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4580911695957184, \"precision\": 1.0, \"recall\": 0.541908860206604, \"specificity\": 1.0, \"npv\": 0.9729483127593994, \"accuracy\": 0.9737871885299683, \"f1\": 0.7029064576926892, \"f2\": 0.5965650782960095, \"f0_5\": 0.8553838725253501, \"p4\": 0.8208272368627817, \"phi\": 0.7261193371922755}, {\"truth_threshold\": 29.945924782270477, \"match_probability\": 0.9999999990331071, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3540.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 2998.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5414499640464783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45855000615119934, \"precision\": 1.0, \"recall\": 0.5414499640464783, \"specificity\": 1.0, \"npv\": 0.9729219675064087, \"accuracy\": 0.9737609028816223, \"f1\": 0.702520341337567, \"f2\": 0.5961201670483632, \"f0_5\": 0.8551550874480626, \"p4\": 0.8205592214928471, \"phi\": 0.7258020005827134}, {\"truth_threshold\": 29.946400454944406, \"match_probability\": 0.9999999990334258, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3538.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3000.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.541144073009491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45885592699050903, \"precision\": 1.0, \"recall\": 0.541144073009491, \"specificity\": 1.0, \"npv\": 0.9729043841362, \"accuracy\": 0.9737433791160583, \"f1\": 0.7022628026994839, \"f2\": 0.5958235095991916, \"f0_5\": 0.8550024166263895, \"p4\": 0.820380393890059, \"phi\": 0.7255904159140767}, {\"truth_threshold\": 29.953356058773455, \"match_probability\": 0.9999999990380747, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3537.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3001.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5409911274909973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4590088725090027, \"precision\": 1.0, \"recall\": 0.5409911274909973, \"specificity\": 1.0, \"npv\": 0.972895622253418, \"accuracy\": 0.9737346768379211, \"f1\": 0.7021339950372208, \"f2\": 0.5956751658863552, \"f0_5\": 0.8549260369331916, \"p4\": 0.8202909348338492, \"phi\": 0.7254846033066463}, {\"truth_threshold\": 29.96051739895452, \"match_probability\": 0.9999999990428378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3536.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3002.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5408381819725037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45916181802749634, \"precision\": 1.0, \"recall\": 0.5408381819725037, \"specificity\": 1.0, \"npv\": 0.9728868007659912, \"accuracy\": 0.9737259149551392, \"f1\": 0.7020051618026603, \"f2\": 0.5955268121800054, \"f0_5\": 0.8548496276955807, \"p4\": 0.8202014455864174, \"phi\": 0.7253787771758531}, {\"truth_threshold\": 29.963890952166157, \"match_probability\": 0.9999999990450733, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3535.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3003.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.54068523645401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45931476354599, \"precision\": 1.0, \"recall\": 0.54068523645401, \"specificity\": 1.0, \"npv\": 0.9728780388832092, \"accuracy\": 0.9737171530723572, \"f1\": 0.7018763029881863, \"f2\": 0.5953784484791322, \"f0_5\": 0.8547731888964116, \"p4\": 0.8201119261317411, \"phi\": 0.725272876566289}, {\"truth_threshold\": 29.96623018680427, \"match_probability\": 0.9999999990466204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3533.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3005.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5403793454170227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4596206843852997, \"precision\": 1.0, \"recall\": 0.5403793454170227, \"specificity\": 1.0, \"npv\": 0.9728604555130005, \"accuracy\": 0.9736996293067932, \"f1\": 0.701618508589018, \"f2\": 0.5950816910897759, \"f0_5\": 0.8546202225447509, \"p4\": 0.8199327965365075, \"phi\": 0.7250611566174249}, {\"truth_threshold\": 29.97656351463005, \"match_probability\": 0.9999999990534246, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3532.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3006.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5402263402938843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.45977362990379333, \"precision\": 1.0, \"recall\": 0.5402263402938843, \"specificity\": 1.0, \"npv\": 0.9728516340255737, \"accuracy\": 0.9736908674240112, \"f1\": 0.7014895729890764, \"f2\": 0.5949332973992724, \"f0_5\": 0.8545436949579018, \"p4\": 0.8198431863638481, \"phi\": 0.7249552763250682}, {\"truth_threshold\": 29.977077569041263, \"match_probability\": 0.9999999990537618, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3529.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3009.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5397675037384033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4602324962615967, \"precision\": 1.0, \"recall\": 0.5397675037384033, \"specificity\": 1.0, \"npv\": 0.972825288772583, \"accuracy\": 0.9736646413803101, \"f1\": 0.7011026124962749, \"f2\": 0.5944880563323338, \"f0_5\": 0.8543139343468578, \"p4\": 0.8195741741528487, \"phi\": 0.7246374931048497}, {\"truth_threshold\": 29.98909511433834, \"match_probability\": 0.9999999990616112, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3528.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3010.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5396145582199097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46038544178009033, \"precision\": 1.0, \"recall\": 0.5396145582199097, \"specificity\": 1.0, \"npv\": 0.972816526889801, \"accuracy\": 0.9736558794975281, \"f1\": 0.7009735744089013, \"f2\": 0.5943396226415094, \"f0_5\": 0.8542372881355932, \"p4\": 0.8194844427978726, \"phi\": 0.7245315585550851}, {\"truth_threshold\": 30.00582697882435, \"match_probability\": 0.9999999990724314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3526.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3012.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5393086671829224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46069133281707764, \"precision\": 1.0, \"recall\": 0.5393086671829224, \"specificity\": 1.0, \"npv\": 0.9727989435195923, \"accuracy\": 0.9736383557319641, \"f1\": 0.7007154213036566, \"f2\": 0.5940427252510277, \"f0_5\": 0.8540839065981979, \"p4\": 0.8193048890642911, \"phi\": 0.7243195876930544}, {\"truth_threshold\": 30.010116074341077, \"match_probability\": 0.999999999075185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3525.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3013.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5391557216644287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4608443081378937, \"precision\": 1.0, \"recall\": 0.5391557216644287, \"specificity\": 1.0, \"npv\": 0.9727901816368103, \"accuracy\": 0.9736296534538269, \"f1\": 0.7005863062704959, \"f2\": 0.593894261549348, \"f0_5\": 0.854007171237523, \"p4\": 0.8192150666534244, \"phi\": 0.724213612385077}, {\"truth_threshold\": 30.012187676160742, \"match_probability\": 0.9999999990765119, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3523.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3015.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5388498306274414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.461150199174881, \"precision\": 1.0, \"recall\": 0.5388498306274414, \"specificity\": 1.0, \"npv\": 0.9727725982666016, \"accuracy\": 0.9736121296882629, \"f1\": 0.7003279992048504, \"f2\": 0.5935973041280539, \"f0_5\": 0.8538536112457586, \"p4\": 0.8190353306627995, \"phi\": 0.7240016209771624}, {\"truth_threshold\": 30.012542811735617, \"match_probability\": 0.9999999990767393, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3521.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3017.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5385438799858093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4614560902118683, \"precision\": 1.0, \"recall\": 0.5385438799858093, \"specificity\": 1.0, \"npv\": 0.9727550148963928, \"accuracy\": 0.973594605922699, \"f1\": 0.7000695894224078, \"f2\": 0.5933003066761029, \"f0_5\": 0.8536999321113374, \"p4\": 0.8188554730058669, \"phi\": 0.7237895140731685}, {\"truth_threshold\": 30.02294445534822, \"match_probability\": 0.9999999990833719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3517.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3021.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5379320979118347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4620679020881653, \"precision\": 1.0, \"recall\": 0.5379320979118347, \"specificity\": 1.0, \"npv\": 0.9727199077606201, \"accuracy\": 0.9735596179962158, \"f1\": 0.6995524614619593, \"f2\": 0.5927061916478479, \"f0_5\": 0.8533922158594585, \"p4\": 0.8184953921748803, \"phi\": 0.723365197783088}, {\"truth_threshold\": 30.039641475507302, \"match_probability\": 0.9999999990939193, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3516.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3022.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5377791523933411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4622208774089813, \"precision\": 1.0, \"recall\": 0.5377791523933411, \"specificity\": 1.0, \"npv\": 0.9727110862731934, \"accuracy\": 0.9735508561134338, \"f1\": 0.6994231151780386, \"f2\": 0.5925576378589726, \"f0_5\": 0.8533152121153286, \"p4\": 0.8184052957231194, \"phi\": 0.7232590998832982}, {\"truth_threshold\": 30.04633397748052, \"match_probability\": 0.9999999990981128, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3515.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3023.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5376262068748474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.462373822927475, \"precision\": 1.0, \"recall\": 0.5376262068748474, \"specificity\": 1.0, \"npv\": 0.9727023243904114, \"accuracy\": 0.9735420942306519, \"f1\": 0.6992937431612454, \"f2\": 0.5924090740553477, \"f0_5\": 0.8532381784639286, \"p4\": 0.8183151687412676, \"phi\": 0.72315298833383}, {\"truth_threshold\": 30.047351062452144, \"match_probability\": 0.9999999990987484, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3514.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3024.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5374732613563538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46252676844596863, \"precision\": 1.0, \"recall\": 0.5374732613563538, \"specificity\": 1.0, \"npv\": 0.9726935625076294, \"accuracy\": 0.9735333323478699, \"f1\": 0.6991643454038997, \"f2\": 0.5922605002359603, \"f0_5\": 0.8531611148878314, \"p4\": 0.8182250112130622, \"phi\": 0.7230468631286219}, {\"truth_threshold\": 30.049646194991908, \"match_probability\": 0.999999999100181, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3513.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3025.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5373202562332153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4626797139644623, \"precision\": 1.0, \"recall\": 0.5373202562332153, \"specificity\": 1.0, \"npv\": 0.9726847410202026, \"accuracy\": 0.9735245704650879, \"f1\": 0.6990349218983186, \"f2\": 0.5921119163997978, \"f0_5\": 0.8530840213695969, \"p4\": 0.818134823122229, \"phi\": 0.7229406631276966}, {\"truth_threshold\": 30.050289680586438, \"match_probability\": 0.9999999991005823, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3512.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3026.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5371673107147217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46283265948295593, \"precision\": 1.0, \"recall\": 0.5371673107147217, \"specificity\": 1.0, \"npv\": 0.9726759791374207, \"accuracy\": 0.9735158681869507, \"f1\": 0.6989054726368159, \"f2\": 0.5919633225458468, \"f0_5\": 0.8530068978917711, \"p4\": 0.8180446044524821, \"phi\": 0.7228345105843802}, {\"truth_threshold\": 30.050324180673154, \"match_probability\": 0.9999999991006038, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3511.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3027.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.537014365196228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.462985634803772, \"precision\": 1.0, \"recall\": 0.537014365196228, \"specificity\": 1.0, \"npv\": 0.9726671576499939, \"accuracy\": 0.9735071063041687, \"f1\": 0.6987759976117026, \"f2\": 0.5918147186730944, \"f0_5\": 0.8529297444368866, \"p4\": 0.8179543551875241, \"phi\": 0.7227283443671101}, {\"truth_threshold\": 30.06416379464137, \"match_probability\": 0.9999999991091904, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3510.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3028.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5368614196777344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4631385803222656, \"precision\": 1.0, \"recall\": 0.5368614196777344, \"specificity\": 1.0, \"npv\": 0.9726583957672119, \"accuracy\": 0.9734983444213867, \"f1\": 0.6986464968152867, \"f2\": 0.5916661047805273, \"f0_5\": 0.8528525609874623, \"p4\": 0.8178640753110461, \"phi\": 0.7226221644698073}, {\"truth_threshold\": 30.06420930031312, \"match_probability\": 0.9999999991092184, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3508.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3030.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5365555286407471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46344447135925293, \"precision\": 1.0, \"recall\": 0.5365555286407471, \"specificity\": 1.0, \"npv\": 0.9726408123970032, \"accuracy\": 0.9734808206558228, \"f1\": 0.6983874178777623, \"f2\": 0.5913688469318948, \"f0_5\": 0.8526981040350025, \"p4\": 0.8176834236582362, \"phi\": 0.7224097024346842}, {\"truth_threshold\": 30.06882967359603, \"match_probability\": 0.9999999991120667, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3507.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3031.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5364025831222534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4635974168777466, \"precision\": 1.0, \"recall\": 0.5364025831222534, \"specificity\": 1.0, \"npv\": 0.9726320505142212, \"accuracy\": 0.9734720587730408, \"f1\": 0.6982578397212543, \"f2\": 0.5912202029738022, \"f0_5\": 0.8526208304969367, \"p4\": 0.8175930518492285, \"phi\": 0.7223034814523221}, {\"truth_threshold\": 30.074656087748238, \"match_probability\": 0.9999999991156454, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3504.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3034.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5359436869621277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4640562832355499, \"precision\": 1.0, \"recall\": 0.5359436869621277, \"specificity\": 1.0, \"npv\": 0.9726057052612305, \"accuracy\": 0.9734458327293396, \"f1\": 0.6978689504082852, \"f2\": 0.5907742109522525, \"f0_5\": 0.8523888294249294, \"p4\": 0.8173217522954945, \"phi\": 0.7219846750445739}, {\"truth_threshold\": 30.07577346044003, \"match_probability\": 0.9999999991163301, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3503.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3035.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.535790741443634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4642092287540436, \"precision\": 1.0, \"recall\": 0.535790741443634, \"specificity\": 1.0, \"npv\": 0.9725969433784485, \"accuracy\": 0.9734370708465576, \"f1\": 0.6977392689971118, \"f2\": 0.5906255268925982, \"f0_5\": 0.8523114355231144, \"p4\": 0.8172312576807509, \"phi\": 0.7218783991995509}, {\"truth_threshold\": 30.077195387747324, \"match_probability\": 0.9999999991172006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3502.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3036.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5356377959251404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4643622040748596, \"precision\": 1.0, \"recall\": 0.5356377959251404, \"specificity\": 1.0, \"npv\": 0.9725881218910217, \"accuracy\": 0.9734283089637756, \"f1\": 0.697609561752988, \"f2\": 0.5904768328050178, \"f0_5\": 0.8522340114864208, \"p4\": 0.8171407323235976, \"phi\": 0.7217721096257007}, {\"truth_threshold\": 30.079145798035366, \"match_probability\": 0.9999999991183933, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3501.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3037.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5354848504066467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46451514959335327, \"precision\": 1.0, \"recall\": 0.5354848504066467, \"specificity\": 1.0, \"npv\": 0.9725793600082397, \"accuracy\": 0.9734195470809937, \"f1\": 0.697479828668194, \"f2\": 0.5903281286884969, \"f0_5\": 0.8521565572972447, \"p4\": 0.8170501762076212, \"phi\": 0.7216658063169052}, {\"truth_threshold\": 30.084411613152586, \"match_probability\": 0.9999999991216053, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3500.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3038.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5353319048881531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4646680951118469, \"precision\": 1.0, \"recall\": 0.5353319048881531, \"specificity\": 1.0, \"npv\": 0.9725705981254578, \"accuracy\": 0.9734108448028564, \"f1\": 0.697350069735007, \"f2\": 0.5901794145420207, \"f0_5\": 0.8520790729379687, \"p4\": 0.8169595893163962, \"phi\": 0.7215594892670418}, {\"truth_threshold\": 30.08594809040388, \"match_probability\": 0.9999999991225403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3498.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3040.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5350260138511658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46497398614883423, \"precision\": 1.0, \"recall\": 0.5350260138511658, \"specificity\": 1.0, \"npv\": 0.972553014755249, \"accuracy\": 0.9733933210372925, \"f1\": 0.6970904742925468, \"f2\": 0.5898819561551434, \"f0_5\": 0.8519240136385777, \"p4\": 0.8167783231424411, \"phi\": 0.7213467526589007}, {\"truth_threshold\": 30.095714084013544, \"match_probability\": 0.99999999912846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3495.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3043.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.53456711769104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4654328525066376, \"precision\": 1.0, \"recall\": 0.53456711769104, \"specificity\": 1.0, \"npv\": 0.9725266695022583, \"accuracy\": 0.9733670353889465, \"f1\": 0.6967008870726602, \"f2\": 0.5894356933247883, \"f0_5\": 0.8516911979725119, \"p4\": 0.8165061926558406, \"phi\": 0.7210276364009572}, {\"truth_threshold\": 30.103836123423946, \"match_probability\": 0.9999999991333528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3492.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3046.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5341082811355591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4658917188644409, \"precision\": 1.0, \"recall\": 0.5341082811355591, \"specificity\": 1.0, \"npv\": 0.9725003242492676, \"accuracy\": 0.9733408093452454, \"f1\": 0.6963110667996012, \"f2\": 0.5889893401700176, \"f0_5\": 0.8514581098215157, \"p4\": 0.8162337843027561, \"phi\": 0.7207083348302528}, {\"truth_threshold\": 30.105784395213465, \"match_probability\": 0.9999999991345223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3491.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3047.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5339553356170654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46604466438293457, \"precision\": 1.0, \"recall\": 0.5339553356170654, \"specificity\": 1.0, \"npv\": 0.9724915623664856, \"accuracy\": 0.9733320474624634, \"f1\": 0.6961810748828398, \"f2\": 0.5888405357082617, \"f0_5\": 0.8513803531362794, \"p4\": 0.8161429196932255, \"phi\": 0.7206018938175329}, {\"truth_threshold\": 30.113637862363337, \"match_probability\": 0.9999999991392209, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3486.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3052.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5331905484199524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4668094217777252, \"precision\": 1.0, \"recall\": 0.5331905484199524, \"specificity\": 1.0, \"npv\": 0.9724476337432861, \"accuracy\": 0.9732882976531982, \"f1\": 0.6955307262569832, \"f2\": 0.5880963627775153, \"f0_5\": 0.8509911141490089, \"p4\": 0.8156881322121218, \"phi\": 0.7200694202295865}, {\"truth_threshold\": 30.118657084335496, \"match_probability\": 0.9999999991422104, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3484.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3054.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5328846573829651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4671153128147125, \"precision\": 1.0, \"recall\": 0.5328846573829651, \"specificity\": 1.0, \"npv\": 0.9724301099777222, \"accuracy\": 0.9732707738876343, \"f1\": 0.6952704051087607, \"f2\": 0.5877986232959913, \"f0_5\": 0.8508352056266484, \"p4\": 0.8155060001745581, \"phi\": 0.7198562971518575}, {\"truth_threshold\": 30.120477529996343, \"match_probability\": 0.9999999991432921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3483.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3055.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5327317118644714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46726828813552856, \"precision\": 1.0, \"recall\": 0.5327317118644714, \"specificity\": 1.0, \"npv\": 0.9724213480949402, \"accuracy\": 0.9732620120048523, \"f1\": 0.6951402055683066, \"f2\": 0.5876497384848997, \"f0_5\": 0.8507572056668296, \"p4\": 0.8154148875796767, \"phi\": 0.7197497455286932}, {\"truth_threshold\": 30.120884986893884, \"match_probability\": 0.999999999143534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3482.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3056.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5325787663459778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4674212336540222, \"precision\": 1.0, \"recall\": 0.5325787663459778, \"specificity\": 1.0, \"npv\": 0.9724125266075134, \"accuracy\": 0.9732532501220703, \"f1\": 0.6950099800399202, \"f2\": 0.5875008436255652, \"f0_5\": 0.8506791752174337, \"p4\": 0.8153237439118833, \"phi\": 0.7196431800534863}, {\"truth_threshold\": 30.128468667289134, \"match_probability\": 0.9999999991480243, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3479.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3059.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5321199297904968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46788010001182556, \"precision\": 1.0, \"recall\": 0.5321199297904968, \"specificity\": 1.0, \"npv\": 0.9723862409591675, \"accuracy\": 0.9732270240783691, \"f1\": 0.6946191474493362, \"f2\": 0.5870540987479329, \"f0_5\": 0.850444900752909, \"p4\": 0.8150501263044805, \"phi\": 0.7193233390310336}, {\"truth_threshold\": 30.13041030805879, \"match_probability\": 0.9999999991491701, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3478.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3060.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5319669842720032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4680330455303192, \"precision\": 1.0, \"recall\": 0.5319669842720032, \"specificity\": 1.0, \"npv\": 0.9723774194717407, \"accuracy\": 0.9732182621955872, \"f1\": 0.6944888178913738, \"f2\": 0.586905163685454, \"f0_5\": 0.8503667481662591, \"p4\": 0.8149588581784288, \"phi\": 0.7192167180769916}, {\"truth_threshold\": 30.13684451224454, \"match_probability\": 0.9999999991529562, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3477.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3061.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5318140387535095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46818599104881287, \"precision\": 1.0, \"recall\": 0.5318140387535095, \"specificity\": 1.0, \"npv\": 0.9723686575889587, \"accuracy\": 0.9732095003128052, \"f1\": 0.6943584623065402, \"f2\": 0.5867562185696445, \"f0_5\": 0.8502885650004891, \"p4\": 0.8148675588961007, \"phi\": 0.7191100832398247}, {\"truth_threshold\": 30.13969504073124, \"match_probability\": 0.9999999991546282, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3476.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3062.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5316610336303711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4683389365673065, \"precision\": 1.0, \"recall\": 0.5316610336303711, \"specificity\": 1.0, \"npv\": 0.9723598957061768, \"accuracy\": 0.9732007384300232, \"f1\": 0.6942280806870381, \"f2\": 0.586607263399487, \"f0_5\": 0.850210351237648, \"p4\": 0.8147762284407872, \"phi\": 0.7190033730651502}, {\"truth_threshold\": 30.141267560630403, \"match_probability\": 0.9999999991555492, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3474.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3064.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5313551425933838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4686448574066162, \"precision\": 1.0, \"recall\": 0.5313551425933838, \"specificity\": 1.0, \"npv\": 0.972342312335968, \"accuracy\": 0.973183274269104, \"f1\": 0.6939672393128246, \"f2\": 0.5863093228920543, \"f0_5\": 0.8500538318488793, \"p4\": 0.8145934739443104, \"phi\": 0.7187900339019772}, {\"truth_threshold\": 30.142488255622922, \"match_probability\": 0.9999999991562634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3473.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3065.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5312021970748901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46879780292510986, \"precision\": 1.0, \"recall\": 0.5312021970748901, \"specificity\": 1.0, \"npv\": 0.972333550453186, \"accuracy\": 0.973174512386322, \"f1\": 0.6938367795425032, \"f2\": 0.5861603375527427, \"f0_5\": 0.8499755261869799, \"p4\": 0.8145020498696698, \"phi\": 0.7186833434614038}, {\"truth_threshold\": 30.15656139890842, \"match_probability\": 0.9999999991644538, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3472.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3066.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5310492515563965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4689507484436035, \"precision\": 1.0, \"recall\": 0.5310492515563965, \"specificity\": 1.0, \"npv\": 0.972324788570404, \"accuracy\": 0.97316575050354, \"f1\": 0.6937062937062937, \"f2\": 0.5860113421550095, \"f0_5\": 0.8498971898560658, \"p4\": 0.8144105945550898, \"phi\": 0.7185766391065113}, {\"truth_threshold\": 30.158359692312548, \"match_probability\": 0.9999999991654946, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3470.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3068.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5307433605194092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4692566394805908, \"precision\": 1.0, \"recall\": 0.5307433605194092, \"specificity\": 1.0, \"npv\": 0.9723072052001953, \"accuracy\": 0.9731482267379761, \"f1\": 0.693445243804956, \"f2\": 0.5857133211802039, \"f0_5\": 0.8497404251150945, \"p4\": 0.8142275901390258, \"phi\": 0.7183631271291663}, {\"truth_threshold\": 30.162568255740226, \"match_probability\": 0.9999999991679255, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3467.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3071.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5302844643592834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.46971550583839417, \"precision\": 1.0, \"recall\": 0.5302844643592834, \"specificity\": 1.0, \"npv\": 0.9722809195518494, \"accuracy\": 0.9731220006942749, \"f1\": 0.6930534732633683, \"f2\": 0.5852662142543638, \"f0_5\": 0.8495050475350387, \"p4\": 0.8139528487957827, \"phi\": 0.7180427853475728}, {\"truth_threshold\": 30.163546251888228, \"match_probability\": 0.9999999991684894, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3466.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3072.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5301315188407898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4698684513568878, \"precision\": 1.0, \"recall\": 0.5301315188407898, \"specificity\": 1.0, \"npv\": 0.9722720980644226, \"accuracy\": 0.9731132388114929, \"f1\": 0.6929228308676529, \"f2\": 0.5851171584847052, \"f0_5\": 0.849426526811097, \"p4\": 0.8138612056890083, \"phi\": 0.7179359973581266}, {\"truth_threshold\": 30.16664999082449, \"match_probability\": 0.9999999991702764, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3465.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3073.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5299785733222961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47002142667770386, \"precision\": 1.0, \"recall\": 0.5299785733222961, \"specificity\": 1.0, \"npv\": 0.9722633361816406, \"accuracy\": 0.9731044769287109, \"f1\": 0.6927921623512946, \"f2\": 0.5849680926494919, \"f0_5\": 0.8493479752916953, \"p4\": 0.8137695312246631, \"phi\": 0.7178291954104967}, {\"truth_threshold\": 30.16739275087918, \"match_probability\": 0.9999999991707034, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3464.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3074.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5298256278038025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4701743721961975, \"precision\": 1.0, \"recall\": 0.5298256278038025, \"specificity\": 1.0, \"npv\": 0.9722545742988586, \"accuracy\": 0.973095715045929, \"f1\": 0.6926614677064588, \"f2\": 0.584819016747704, \"f0_5\": 0.8492693929587134, \"p4\": 0.8136778253858944, \"phi\": 0.7177223794983998}, {\"truth_threshold\": 30.171191391225708, \"match_probability\": 0.9999999991728841, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3461.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3077.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5293667912483215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47063320875167847, \"precision\": 1.0, \"recall\": 0.5293667912483215, \"specificity\": 1.0, \"npv\": 0.9722282290458679, \"accuracy\": 0.9730694890022278, \"f1\": 0.6922692269226922, \"f2\": 0.5843717286326952, \"f0_5\": 0.8490334608968698, \"p4\": 0.8134025194543393, \"phi\": 0.7174017863354041}, {\"truth_threshold\": 30.190326407630224, \"match_probability\": 0.999999999183782, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3459.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3079.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5290609002113342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47093912959098816, \"precision\": 1.0, \"recall\": 0.5290609002113342, \"specificity\": 1.0, \"npv\": 0.972210705280304, \"accuracy\": 0.9730519652366638, \"f1\": 0.6920076022806843, \"f2\": 0.5840734862044511, \"f0_5\": 0.8488760184548935, \"p4\": 0.8132188249850094, \"phi\": 0.7171880286564263}, {\"truth_threshold\": 30.1945289035578, \"match_probability\": 0.9999999991861561, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3455.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3083.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5284490585327148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47155094146728516, \"precision\": 1.0, \"recall\": 0.5284490585327148, \"specificity\": 1.0, \"npv\": 0.9721755981445312, \"accuracy\": 0.9730169773101807, \"f1\": 0.691484038827179, \"f2\": 0.583476880467457, \"f0_5\": 0.8485607623538658, \"p4\": 0.8128510582012468, \"phi\": 0.7167602835919327}, {\"truth_threshold\": 30.198516019931677, \"match_probability\": 0.9999999991884022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3454.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3084.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5282961130142212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4717038869857788, \"precision\": 1.0, \"recall\": 0.5282961130142212, \"specificity\": 1.0, \"npv\": 0.9721668362617493, \"accuracy\": 0.9730082154273987, \"f1\": 0.6913530824659728, \"f2\": 0.5833277038438155, \"f0_5\": 0.8484818708853297, \"p4\": 0.8127590376886866, \"phi\": 0.7166533276712865}, {\"truth_threshold\": 30.1989559359665, \"match_probability\": 0.9999999991886497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3452.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3086.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5279902219772339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4720097780227661, \"precision\": 1.0, \"recall\": 0.5279902219772339, \"specificity\": 1.0, \"npv\": 0.9721492528915405, \"accuracy\": 0.9729906916618347, \"f1\": 0.6910910910910911, \"f2\": 0.5830293203621132, \"f0_5\": 0.8483239948884301, \"p4\": 0.8125749019647632, \"phi\": 0.7164393120672594}, {\"truth_threshold\": 30.19976054342248, \"match_probability\": 0.999999999189102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3450.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3088.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5276843309402466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4723156988620758, \"precision\": 1.0, \"recall\": 0.5276843309402466, \"specificity\": 1.0, \"npv\": 0.9721317291259766, \"accuracy\": 0.9729732275009155, \"f1\": 0.6908289947937525, \"f2\": 0.5827308965610432, \"f0_5\": 0.8481659946897433, \"p4\": 0.8123906398623869, \"phi\": 0.7162253019143285}, {\"truth_threshold\": 30.203265463337722, \"match_probability\": 0.9999999991910696, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3448.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3090.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5273783802986145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4726215898990631, \"precision\": 1.0, \"recall\": 0.5273783802986145, \"specificity\": 1.0, \"npv\": 0.9721142053604126, \"accuracy\": 0.9729557037353516, \"f1\": 0.6905667935109153, \"f2\": 0.5824324324324325, \"f0_5\": 0.8480078701426463, \"p4\": 0.8122062512453282, \"phi\": 0.7160111738349232}, {\"truth_threshold\": 30.203973195252967, \"match_probability\": 0.9999999991914664, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3447.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3091.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5272254347801208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47277453541755676, \"precision\": 1.0, \"recall\": 0.5272254347801208, \"specificity\": 1.0, \"npv\": 0.9721053838729858, \"accuracy\": 0.9729469418525696, \"f1\": 0.6904356534802203, \"f2\": 0.5822831852427447, \"f0_5\": 0.8479287611925612, \"p4\": 0.8121140094511675, \"phi\": 0.7159041195264125}, {\"truth_threshold\": 30.21011810506329, \"match_probability\": 0.9999999991949029, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3445.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3093.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5269195437431335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47308045625686646, \"precision\": 1.0, \"recall\": 0.5269195437431335, \"specificity\": 1.0, \"npv\": 0.9720878601074219, \"accuracy\": 0.9729294776916504, \"f1\": 0.6901732946008214, \"f2\": 0.581984660607494, \"f0_5\": 0.8477704498474259, \"p4\": 0.8119294308062261, \"phi\": 0.7156899686679181}, {\"truth_threshold\": 30.222213276162094, \"match_probability\": 0.9999999992016244, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3442.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3096.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5264607071876526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4735393226146698, \"precision\": 1.0, \"recall\": 0.5264607071876526, \"specificity\": 1.0, \"npv\": 0.9720615148544312, \"accuracy\": 0.9729031920433044, \"f1\": 0.6897795591182365, \"f2\": 0.5815367979995945, \"f0_5\": 0.8475327489411997, \"p4\": 0.8116523249408221, \"phi\": 0.7153685749394366}, {\"truth_threshold\": 30.23321760776348, \"match_probability\": 0.9999999992076909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3437.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5256959199905396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47430408000946045, \"precision\": 1.0, \"recall\": 0.5256959199905396, \"specificity\": 1.0, \"npv\": 0.9720177054405212, \"accuracy\": 0.9728594422340393, \"f1\": 0.6891228070175439, \"f2\": 0.5807901585048498, \"f0_5\": 0.8471359558316081, \"p4\": 0.8111898462951758, \"phi\": 0.7148326775085354}, {\"truth_threshold\": 30.24279382752436, \"match_probability\": 0.9999999992129326, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3435.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3103.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5253900289535522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47460997104644775, \"precision\": 1.0, \"recall\": 0.5253900289535522, \"specificity\": 1.0, \"npv\": 0.9720001220703125, \"accuracy\": 0.9728419184684753, \"f1\": 0.6888599217888298, \"f2\": 0.5804914320478588, \"f0_5\": 0.8469770194299241, \"p4\": 0.8110046319985322, \"phi\": 0.7146181824792037}, {\"truth_threshold\": 30.247140244459008, \"match_probability\": 0.9999999992153003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3434.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3104.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5252370834350586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4747629165649414, \"precision\": 1.0, \"recall\": 0.5252370834350586, \"specificity\": 1.0, \"npv\": 0.9719913601875305, \"accuracy\": 0.9728331565856934, \"f1\": 0.6887284396309667, \"f2\": 0.580342053674035, \"f0_5\": 0.8468975041925619, \"p4\": 0.8109119770303244, \"phi\": 0.714510944627508}, {\"truth_threshold\": 30.251827893076488, \"match_probability\": 0.9999999992178458, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3432.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3106.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5249311923980713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4750688374042511, \"precision\": 1.0, \"recall\": 0.5249311923980713, \"specificity\": 1.0, \"npv\": 0.9719738364219666, \"accuracy\": 0.9728156924247742, \"f1\": 0.6884653961885657, \"f2\": 0.5800432666306111, \"f0_5\": 0.846738379551959, \"p4\": 0.8107265713679772, \"phi\": 0.7142964264329973}, {\"truth_threshold\": 30.252139058890652, \"match_probability\": 0.9999999992180145, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3431.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3107.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5247782468795776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47522178292274475, \"precision\": 1.0, \"recall\": 0.5247782468795776, \"specificity\": 1.0, \"npv\": 0.9719650745391846, \"accuracy\": 0.9728069305419922, \"f1\": 0.6883338348881533, \"f2\": 0.5798938579589629, \"f0_5\": 0.8466587701115389, \"p4\": 0.810633820639337, \"phi\": 0.7141891460773149}, {\"truth_threshold\": 30.25872514217858, \"match_probability\": 0.9999999992215762, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3428.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3110.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5243193507194519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4756806492805481, \"precision\": 1.0, \"recall\": 0.5243193507194519, \"specificity\": 1.0, \"npv\": 0.9719387292861938, \"accuracy\": 0.9727806448936462, \"f1\": 0.6879389925747542, \"f2\": 0.579445571331981, \"f0_5\": 0.8464197530864197, \"p4\": 0.8103553766562828, \"phi\": 0.713867158035787}, {\"truth_threshold\": 30.262126424382856, \"match_probability\": 0.9999999992234092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3426.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3112.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5240134596824646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4759865403175354, \"precision\": 1.0, \"recall\": 0.5240134596824646, \"specificity\": 1.0, \"npv\": 0.9719212055206299, \"accuracy\": 0.972763180732727, \"f1\": 0.6876756322761943, \"f2\": 0.5791466630603828, \"f0_5\": 0.8462602509633436, \"p4\": 0.8101695873303307, \"phi\": 0.7136524076949271}, {\"truth_threshold\": 30.265639085455856, \"match_probability\": 0.9999999992252978, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3425.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3113.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.523860514163971, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47613948583602905, \"precision\": 1.0, \"recall\": 0.523860514163971, \"specificity\": 1.0, \"npv\": 0.9719124436378479, \"accuracy\": 0.9727544188499451, \"f1\": 0.6875439124761618, \"f2\": 0.5789971937654258, \"f0_5\": 0.8461804526138946, \"p4\": 0.810076644614223, \"phi\": 0.713545042139731}, {\"truth_threshold\": 30.272038616328356, \"match_probability\": 0.9999999992287266, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3424.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3114.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5237075686454773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4762924313545227, \"precision\": 1.0, \"recall\": 0.5237075686454773, \"specificity\": 1.0, \"npv\": 0.9719036817550659, \"accuracy\": 0.9727456569671631, \"f1\": 0.6874121662316803, \"f2\": 0.578847714362997, \"f0_5\": 0.8461006227142434, \"p4\": 0.8099836698395732, \"phi\": 0.7134376623649114}, {\"truth_threshold\": 30.272397625706432, \"match_probability\": 0.9999999992289185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3423.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3115.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5235546231269836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47644540667533875, \"precision\": 1.0, \"recall\": 0.5235546231269836, \"specificity\": 1.0, \"npv\": 0.9718949198722839, \"accuracy\": 0.9727368950843811, \"f1\": 0.6872803935347856, \"f2\": 0.578698224852071, \"f0_5\": 0.8460207612456747, \"p4\": 0.8098906629890247, \"phi\": 0.7133302683639942}, {\"truth_threshold\": 30.273089525523986, \"match_probability\": 0.9999999992292883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3420.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3118.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5230957269668579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4769042432308197, \"precision\": 1.0, \"recall\": 0.5230957269668579, \"specificity\": 1.0, \"npv\": 0.9718685746192932, \"accuracy\": 0.9727106690406799, \"f1\": 0.6868849166499297, \"f2\": 0.578249695658055, \"f0_5\": 0.8457809872390939, \"p4\": 0.8096114498082349, \"phi\": 0.7130079390063012}, {\"truth_threshold\": 30.290208966350892, \"match_probability\": 0.9999999992383797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3419.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3119.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5229427814483643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47705721855163574, \"precision\": 1.0, \"recall\": 0.5229427814483643, \"specificity\": 1.0, \"npv\": 0.9718598127365112, \"accuracy\": 0.972701907157898, \"f1\": 0.6867530380636738, \"f2\": 0.5781001657028846, \"f0_5\": 0.8457009993074107, \"p4\": 0.8095183144802767, \"phi\": 0.7129004880273809}, {\"truth_threshold\": 30.296458552339917, \"match_probability\": 0.9999999992416718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3418.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3120.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5227898359298706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4772101640701294, \"precision\": 1.0, \"recall\": 0.5227898359298706, \"specificity\": 1.0, \"npv\": 0.9718510508537292, \"accuracy\": 0.972693145275116, \"f1\": 0.6866211329851346, \"f2\": 0.5779506256340886, \"f0_5\": 0.8456209797130133, \"p4\": 0.8094251469894496, \"phi\": 0.7127930227899175}, {\"truth_threshold\": 30.312775835523663, \"match_probability\": 0.9999999992502003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3417.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3121.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.522636890411377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47736310958862305, \"precision\": 1.0, \"recall\": 0.522636890411377, \"specificity\": 1.0, \"npv\": 0.9718422889709473, \"accuracy\": 0.972684383392334, \"f1\": 0.6864892014063285, \"f2\": 0.5778010754506409, \"f0_5\": 0.8455409284370979, \"p4\": 0.8093319473183217, \"phi\": 0.7126854813275217}, {\"truth_threshold\": 30.33002500159179, \"match_probability\": 0.9999999992591118, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3415.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3123.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5223309993743896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47766900062561035, \"precision\": 1.0, \"recall\": 0.5223309993743896, \"specificity\": 1.0, \"npv\": 0.9718247652053833, \"accuracy\": 0.97266685962677, \"f1\": 0.6862252587159651, \"f2\": 0.5775019447356851, \"f0_5\": 0.8453807307654223, \"p4\": 0.8091454513653739, \"phi\": 0.7124704794837511}, {\"truth_threshold\": 30.33574858065862, \"match_probability\": 0.9999999992620452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3414.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3124.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.522178053855896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4778219759464264, \"precision\": 1.0, \"recall\": 0.522178053855896, \"specificity\": 1.0, \"npv\": 0.9718160033226013, \"accuracy\": 0.9726581573486328, \"f1\": 0.6860932475884244, \"f2\": 0.5773523642021241, \"f0_5\": 0.8453005843319797, \"p4\": 0.8090521550486274, \"phi\": 0.7123629571382454}, {\"truth_threshold\": 30.336030283699785, \"match_probability\": 0.9999999992621893, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3413.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3125.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5220251083374023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47797492146492004, \"precision\": 1.0, \"recall\": 0.5220251083374023, \"specificity\": 1.0, \"npv\": 0.9718072414398193, \"accuracy\": 0.9726493954658508, \"f1\": 0.6859612099286504, \"f2\": 0.5772027735498055, \"f0_5\": 0.8452204061416543, \"p4\": 0.8089588264817272, \"phi\": 0.7122554205016317}, {\"truth_threshold\": 30.337053418748017, \"match_probability\": 0.9999999992627124, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3412.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3126.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5218721032142639, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4781278669834137, \"precision\": 1.0, \"recall\": 0.5218721032142639, \"specificity\": 1.0, \"npv\": 0.9717984795570374, \"accuracy\": 0.9726406335830688, \"f1\": 0.6858291457286432, \"f2\": 0.5770531727777026, \"f0_5\": 0.8451401961755672, \"p4\": 0.8088654656471784, \"phi\": 0.7121478075635137}, {\"truth_threshold\": 30.34995937611911, \"match_probability\": 0.9999999992692785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3411.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3127.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5217191576957703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47828081250190735, \"precision\": 1.0, \"recall\": 0.5217191576957703, \"specificity\": 1.0, \"npv\": 0.9717897176742554, \"accuracy\": 0.9726318717002869, \"f1\": 0.6856970549804, \"f2\": 0.5769035618847884, \"f0_5\": 0.8450599544148251, \"p4\": 0.8087720725274737, \"phi\": 0.7120402423162918}, {\"truth_threshold\": 30.35042591310734, \"match_probability\": 0.9999999992695148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3410.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3128.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5215662121772766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.478433758020401, \"precision\": 1.0, \"recall\": 0.5215662121772766, \"specificity\": 1.0, \"npv\": 0.9717808961868286, \"accuracy\": 0.9726231098175049, \"f1\": 0.6855649376759148, \"f2\": 0.5767539408700358, \"f0_5\": 0.8449796808405193, \"p4\": 0.808678647105093, \"phi\": 0.7119326627583642}, {\"truth_threshold\": 30.38551453473293, \"match_probability\": 0.9999999992870671, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3409.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3129.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.521413266658783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47858673334121704, \"precision\": 1.0, \"recall\": 0.521413266658783, \"specificity\": 1.0, \"npv\": 0.9717721343040466, \"accuracy\": 0.9726143479347229, \"f1\": 0.685432793807178, \"f2\": 0.5766043097324177, \"f0_5\": 0.8448993754337266, \"p4\": 0.8085851893625032, \"phi\": 0.7118250688831901}, {\"truth_threshold\": 30.39685152639607, \"match_probability\": 0.9999999992926475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3406.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3132.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.520954430103302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.479045569896698, \"precision\": 1.0, \"recall\": 0.520954430103302, \"specificity\": 1.0, \"npv\": 0.9717458486557007, \"accuracy\": 0.9725881218910217, \"f1\": 0.6850362027353177, \"f2\": 0.5761553555720955, \"f0_5\": 0.8446582680289654, \"p4\": 0.8083046220379625, \"phi\": 0.7115021392319263}, {\"truth_threshold\": 30.401246701641064, \"match_probability\": 0.9999999992947991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3404.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3134.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5206485390663147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4793514907360077, \"precision\": 1.0, \"recall\": 0.5206485390663147, \"specificity\": 1.0, \"npv\": 0.9717283248901367, \"accuracy\": 0.9725705981254578, \"f1\": 0.6847716757191712, \"f2\": 0.575856002165381, \"f0_5\": 0.8444973702490821, \"p4\": 0.8081174152318853, \"phi\": 0.711286822444901}, {\"truth_threshold\": 30.40690519105999, \"match_probability\": 0.9999999992975597, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3403.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3135.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.520495593547821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.47950443625450134, \"precision\": 1.0, \"recall\": 0.520495593547821, \"specificity\": 1.0, \"npv\": 0.9717195630073547, \"accuracy\": 0.9725618362426758, \"f1\": 0.6846393722965497, \"f2\": 0.57570631026899, \"f0_5\": 0.8444168734491315, \"p4\": 0.8080237631991427, \"phi\": 0.7111790804364895}, {\"truth_threshold\": 30.40888167354663, \"match_probability\": 0.9999999992985213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3402.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3136.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5203425884246826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.479657381772995, \"precision\": 1.0, \"recall\": 0.5203425884246826, \"specificity\": 1.0, \"npv\": 0.9717108011245728, \"accuracy\": 0.9725530743598938, \"f1\": 0.6845070422535211, \"f2\": 0.5755566082425391, \"f0_5\": 0.8443363446838082, \"p4\": 0.8079300787231061, \"phi\": 0.7110713861393491}, {\"truth_threshold\": 30.411478636722844, \"match_probability\": 0.9999999992997829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3400.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3138.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5200366973876953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4799633026123047, \"precision\": 1.0, \"recall\": 0.5200366973876953, \"specificity\": 1.0, \"npv\": 0.9716932773590088, \"accuracy\": 0.9725356101989746, \"f1\": 0.6842423022740994, \"f2\": 0.5752571737953438, \"f0_5\": 0.8441751911808522, \"p4\": 0.8077426123705994, \"phi\": 0.7108559544292155}, {\"truth_threshold\": 30.412711656622058, \"match_probability\": 0.9999999993003811, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3395.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3143.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.519271969795227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48072806000709534, \"precision\": 1.0, \"recall\": 0.519271969795227, \"specificity\": 1.0, \"npv\": 0.9716494083404541, \"accuracy\": 0.9724918603897095, \"f1\": 0.6835799859055673, \"f2\": 0.5745084103293059, \"f0_5\": 0.8437717466945024, \"p4\": 0.8072733774957009, \"phi\": 0.710317061182975}, {\"truth_threshold\": 30.416921324894247, \"match_probability\": 0.9999999993024196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3394.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3144.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5191190242767334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.480881005525589, \"precision\": 1.0, \"recall\": 0.5191190242767334, \"specificity\": 1.0, \"npv\": 0.9716406464576721, \"accuracy\": 0.9724830985069275, \"f1\": 0.6834474426097463, \"f2\": 0.5743586272253436, \"f0_5\": 0.8436909615193398, \"p4\": 0.8071794328373931, \"phi\": 0.7102091895712481}, {\"truth_threshold\": 30.424791661267246, \"match_probability\": 0.9999999993062147, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3389.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3149.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5183542370796204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48164576292037964, \"precision\": 1.0, \"recall\": 0.5183542370796204, \"specificity\": 1.0, \"npv\": 0.9715968370437622, \"accuracy\": 0.9724393486976624, \"f1\": 0.68278432557671, \"f2\": 0.5736095595951389, \"f0_5\": 0.8432865531999602, \"p4\": 0.8067092201536737, \"phi\": 0.7096698636047037}, {\"truth_threshold\": 30.444402061316353, \"match_probability\": 0.9999999993155815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3382.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3156.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.51728355884552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48271644115448, \"precision\": 1.0, \"recall\": 0.51728355884552, \"specificity\": 1.0, \"npv\": 0.9715355038642883, \"accuracy\": 0.9723780751228333, \"f1\": 0.6818548387096774, \"f2\": 0.5725604388162795, \"f0_5\": 0.8427190272102063, \"p4\": 0.8060495488596582, \"phi\": 0.7089142246818185}, {\"truth_threshold\": 30.445502219011725, \"match_probability\": 0.9999999993161032, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3381.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3157.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5171306133270264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48286938667297363, \"precision\": 1.0, \"recall\": 0.5171306133270264, \"specificity\": 1.0, \"npv\": 0.9715267419815063, \"accuracy\": 0.9723693132400513, \"f1\": 0.6817219477769937, \"f2\": 0.5724105238208106, \"f0_5\": 0.8426378227494766, \"p4\": 0.8059551789811081, \"phi\": 0.7088062271948494}, {\"truth_threshold\": 30.44635637896529, \"match_probability\": 0.999999999316508, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3378.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3160.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5166717767715454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4833282232284546, \"precision\": 1.0, \"recall\": 0.5166717767715454, \"specificity\": 1.0, \"npv\": 0.9715004563331604, \"accuracy\": 0.9723430275917053, \"f1\": 0.6813231141589351, \"f2\": 0.5719607179139857, \"f0_5\": 0.8423940149625935, \"p4\": 0.8056718722684358, \"phi\": 0.7084820853471676}, {\"truth_threshold\": 30.44734129684976, \"match_probability\": 0.9999999993169744, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3377.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3161.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5165188312530518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48348119854927063, \"precision\": 1.0, \"recall\": 0.5165188312530518, \"specificity\": 1.0, \"npv\": 0.9714916944503784, \"accuracy\": 0.9723343253135681, \"f1\": 0.68119011598588, \"f2\": 0.5718107623014663, \"f0_5\": 0.8423126808340816, \"p4\": 0.8055773709454334, \"phi\": 0.7083740297748117}, {\"truth_threshold\": 30.449244704991788, \"match_probability\": 0.999999999317875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3374.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3164.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.516059935092926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4839400351047516, \"precision\": 1.0, \"recall\": 0.516059935092926, \"specificity\": 1.0, \"npv\": 0.9714654088020325, \"accuracy\": 0.9723080396652222, \"f1\": 0.6807909604519774, \"f2\": 0.5713608345187292, \"f0_5\": 0.8420684835779175, \"p4\": 0.8052936694686873, \"phi\": 0.7080497134743848}, {\"truth_threshold\": 30.449477593464895, \"match_probability\": 0.999999999317985, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3372.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3166.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5157540440559387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4842459559440613, \"precision\": 1.0, \"recall\": 0.5157540440559387, \"specificity\": 1.0, \"npv\": 0.9714478850364685, \"accuracy\": 0.9722905158996582, \"f1\": 0.6805247225025227, \"f2\": 0.5710608318656009, \"f0_5\": 0.8419055228203336, \"p4\": 0.8051043703812066, \"phi\": 0.7078334713816281}, {\"truth_threshold\": 30.450068897784046, \"match_probability\": 0.9999999993182646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3371.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3167.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5156010985374451, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48439890146255493, \"precision\": 1.0, \"recall\": 0.5156010985374451, \"specificity\": 1.0, \"npv\": 0.9714391231536865, \"accuracy\": 0.972281813621521, \"f1\": 0.6803915632253507, \"f2\": 0.5709108152965484, \"f0_5\": 0.8418239936070323, \"p4\": 0.8050096713525421, \"phi\": 0.7077252661161771}, {\"truth_threshold\": 30.45828416339825, \"match_probability\": 0.9999999993221356, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3369.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3169.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5152952075004578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48470479249954224, \"precision\": 1.0, \"recall\": 0.5152952075004578, \"specificity\": 1.0, \"npv\": 0.9714215993881226, \"accuracy\": 0.972264289855957, \"f1\": 0.6801251640254365, \"f2\": 0.5706107516683039, \"f0_5\": 0.8416608374138104, \"p4\": 0.8048201742351851, \"phi\": 0.7075089365685601}, {\"truth_threshold\": 30.460228553546848, \"match_probability\": 0.9999999993230485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3368.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3170.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5151422619819641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4848577678203583, \"precision\": 1.0, \"recall\": 0.5151422619819641, \"specificity\": 1.0, \"npv\": 0.9714128375053406, \"accuracy\": 0.972255527973175, \"f1\": 0.6799919240864123, \"f2\": 0.5704607046070461, \"f0_5\": 0.8415792103948025, \"p4\": 0.8047253761103813, \"phi\": 0.7074007499136212}, {\"truth_threshold\": 30.461628429447618, \"match_probability\": 0.9999999993237051, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5149893164634705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48501071333885193, \"precision\": 1.0, \"recall\": 0.5149893164634705, \"specificity\": 1.0, \"npv\": 0.9714040756225586, \"accuracy\": 0.9722467660903931, \"f1\": 0.6798586572438162, \"f2\": 0.5703106473796538, \"f0_5\": 0.8414975507347796, \"p4\": 0.8046305449173977, \"phi\": 0.7072925486622671}, {\"truth_threshold\": 30.46322137566589, \"match_probability\": 0.9999999993244514, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3366.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3172.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5148363709449768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4851636588573456, \"precision\": 1.0, \"recall\": 0.5148363709449768, \"specificity\": 1.0, \"npv\": 0.9713953137397766, \"accuracy\": 0.9722380042076111, \"f1\": 0.6797253634894992, \"f2\": 0.5701605799850938, \"f0_5\": 0.8414158584141586, \"p4\": 0.804535680638146, \"phi\": 0.7071842703945866}, {\"truth_threshold\": 30.46856894084926, \"match_probability\": 0.9999999993269508, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3365.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3173.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5146833658218384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48531660437583923, \"precision\": 1.0, \"recall\": 0.5146833658218384, \"specificity\": 1.0, \"npv\": 0.9713865518569946, \"accuracy\": 0.9722293019294739, \"f1\": 0.6795920428153085, \"f2\": 0.5700105024223329, \"f0_5\": 0.8413341334133413, \"p4\": 0.8044407832545242, \"phi\": 0.7070760399211466}, {\"truth_threshold\": 30.475338304296468, \"match_probability\": 0.9999999993301014, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3362.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3176.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5142245292663574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4857754707336426, \"precision\": 1.0, \"recall\": 0.5142245292663574, \"specificity\": 1.0, \"npv\": 0.9713602662086487, \"accuracy\": 0.9722030162811279, \"f1\": 0.6791919191919192, \"f2\": 0.5695602087145084, \"f0_5\": 0.8410887621334935, \"p4\": 0.8041558922962231, \"phi\": 0.7067511983244452}, {\"truth_threshold\": 30.47855302942188, \"match_probability\": 0.9999999993315924, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3361.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3177.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5140715837478638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48592841625213623, \"precision\": 1.0, \"recall\": 0.5140715837478638, \"specificity\": 1.0, \"npv\": 0.9713515639305115, \"accuracy\": 0.972194254398346, \"f1\": 0.679058490756642, \"f2\": 0.569410090468607, \"f0_5\": 0.841006906215594, \"p4\": 0.8040608623138396, \"phi\": 0.7066429093345995}, {\"truth_threshold\": 30.48969358702708, \"match_probability\": 0.9999999993367341, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3359.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3179.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5137656927108765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4862343370914459, \"precision\": 1.0, \"recall\": 0.5137656927108765, \"specificity\": 1.0, \"npv\": 0.9713340401649475, \"accuracy\": 0.972176730632782, \"f1\": 0.6787915529958574, \"f2\": 0.5691098234556606, \"f0_5\": 0.8408430960248323, \"p4\": 0.8038707027456604, \"phi\": 0.706426287416725}, {\"truth_threshold\": 30.50098558968272, \"match_probability\": 0.9999999993419052, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3358.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3180.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5136127471923828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4863872826099396, \"precision\": 1.0, \"recall\": 0.5136127471923828, \"specificity\": 1.0, \"npv\": 0.9713252782821655, \"accuracy\": 0.9721680283546448, \"f1\": 0.6786580436540016, \"f2\": 0.568959674686547, \"f0_5\": 0.8407611417125689, \"p4\": 0.8037755731234892, \"phi\": 0.706317954475115}, {\"truth_threshold\": 30.503584407111045, \"match_probability\": 0.9999999993430896, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3357.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3181.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5134598016738892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4865402281284332, \"precision\": 1.0, \"recall\": 0.5134598016738892, \"specificity\": 1.0, \"npv\": 0.9713165163993835, \"accuracy\": 0.9721592664718628, \"f1\": 0.6785245073269328, \"f2\": 0.5688095157409604, \"f0_5\": 0.8406791545627567, \"p4\": 0.803680410251658, \"phi\": 0.7062095443750974}, {\"truth_threshold\": 30.506156220311905, \"match_probability\": 0.9999999993442596, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3353.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3185.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5128479599952698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4871520400047302, \"precision\": 1.0, \"recall\": 0.5128479599952698, \"specificity\": 1.0, \"npv\": 0.9712814688682556, \"accuracy\": 0.9721242189407349, \"f1\": 0.6779900920028309, \"f2\": 0.5682087781731909, \"f0_5\": 0.8403508771929824, \"p4\": 0.8032994259031124, \"phi\": 0.7057759446075211}, {\"truth_threshold\": 30.519195013919227, \"match_probability\": 0.9999999993501594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3351.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3187.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5125420689582825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48745793104171753, \"precision\": 1.0, \"recall\": 0.5125420689582825, \"specificity\": 1.0, \"npv\": 0.9712639451026917, \"accuracy\": 0.9721067547798157, \"f1\": 0.6777227222166043, \"f2\": 0.5679083483035624, \"f0_5\": 0.8401865409688095, \"p4\": 0.803108733756501, \"phi\": 0.7055590878086045}, {\"truth_threshold\": 30.519254177341587, \"match_probability\": 0.999999999350186, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3349.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3189.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5122361779212952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4877638518810272, \"precision\": 1.0, \"recall\": 0.5122361779212952, \"specificity\": 1.0, \"npv\": 0.9712464213371277, \"accuracy\": 0.9720892310142517, \"f1\": 0.6774552442601396, \"f2\": 0.5676078776990611, \"f0_5\": 0.8400220728403732, \"p4\": 0.8029179080999294, \"phi\": 0.7053421721620184}, {\"truth_threshold\": 30.526864221508326, \"match_probability\": 0.9999999993536047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3348.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3190.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5120832324028015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4879167973995209, \"precision\": 1.0, \"recall\": 0.5120832324028015, \"specificity\": 1.0, \"npv\": 0.9712376594543457, \"accuracy\": 0.9720804691314697, \"f1\": 0.6773214646975521, \"f2\": 0.5674576271186441, \"f0_5\": 0.8399397892624184, \"p4\": 0.8028224451596141, \"phi\": 0.7052336296781164}, {\"truth_threshold\": 30.539823550542373, \"match_probability\": 0.9999999993593851, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3347.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3191.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5119302272796631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4880697429180145, \"precision\": 1.0, \"recall\": 0.5119302272796631, \"specificity\": 1.0, \"npv\": 0.9712288975715637, \"accuracy\": 0.9720717072486877, \"f1\": 0.6771876580677795, \"f2\": 0.5673073663514018, \"f0_5\": 0.8398574726488005, \"p4\": 0.8027269487868288, \"phi\": 0.7051251350283327}, {\"truth_threshold\": 30.544101381630117, \"match_probability\": 0.9999999993612818, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3345.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3193.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5116243362426758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4883756637573242, \"precision\": 1.0, \"recall\": 0.5116243362426758, \"specificity\": 1.0, \"npv\": 0.9712114334106445, \"accuracy\": 0.9720542430877686, \"f1\": 0.6769199635738136, \"f2\": 0.5670068142522968, \"f0_5\": 0.8396927402349633, \"p4\": 0.8025358556704164, \"phi\": 0.7049081015039842}, {\"truth_threshold\": 30.548119955074593, \"match_probability\": 0.9999999993630585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3344.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3194.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5114713907241821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48852860927581787, \"precision\": 1.0, \"recall\": 0.5114713907241821, \"specificity\": 1.0, \"npv\": 0.9712026715278625, \"accuracy\": 0.9720454812049866, \"f1\": 0.6767860756931795, \"f2\": 0.5668565229183619, \"f0_5\": 0.839610324394898, \"p4\": 0.8024402588900399, \"phi\": 0.7047995626156951}, {\"truth_threshold\": 30.56472192241172, \"match_probability\": 0.9999999993703461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3342.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3196.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5111654996871948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4888345003128052, \"precision\": 1.0, \"recall\": 0.5111654996871948, \"specificity\": 1.0, \"npv\": 0.9711851477622986, \"accuracy\": 0.9720279574394226, \"f1\": 0.6765182186234818, \"f2\": 0.5665559096765443, \"f0_5\": 0.839445393348739, \"p4\": 0.8022489647929718, \"phi\": 0.704582377922453}, {\"truth_threshold\": 30.567421459802098, \"match_probability\": 0.9999999993715232, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3341.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3197.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5110125541687012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48898744583129883, \"precision\": 1.0, \"recall\": 0.5110125541687012, \"specificity\": 1.0, \"npv\": 0.9711763858795166, \"accuracy\": 0.9720191955566406, \"f1\": 0.6763842494179573, \"f2\": 0.5664055877665887, \"f0_5\": 0.8393628781027033, \"p4\": 0.80215326743945, \"phi\": 0.7044737947247398}, {\"truth_threshold\": 30.57018350488745, \"match_probability\": 0.9999999993727253, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3340.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3198.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5108596086502075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48914042115211487, \"precision\": 1.0, \"recall\": 0.5108596086502075, \"specificity\": 1.0, \"npv\": 0.9711676239967346, \"accuracy\": 0.9720104932785034, \"f1\": 0.6762502530876696, \"f2\": 0.5662552556625525, \"f0_5\": 0.839280329681375, \"p4\": 0.8020575365246938, \"phi\": 0.7043651967464803}, {\"truth_threshold\": 30.571598898187265, \"match_probability\": 0.9999999993733404, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5107066631317139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4892933666706085, \"precision\": 1.0, \"recall\": 0.5107066631317139, \"specificity\": 1.0, \"npv\": 0.9711588621139526, \"accuracy\": 0.9720017313957214, \"f1\": 0.6761162296243799, \"f2\": 0.566104913363399, \"f0_5\": 0.8391977480647431, \"p4\": 0.8019617720302543, \"phi\": 0.7042565213234174}, {\"truth_threshold\": 30.57378745301678, \"match_probability\": 0.9999999993742903, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3338.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3200.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5105536580085754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4894463121891022, \"precision\": 1.0, \"recall\": 0.5105536580085754, \"specificity\": 1.0, \"npv\": 0.9711501002311707, \"accuracy\": 0.9719929695129395, \"f1\": 0.6759821790198461, \"f2\": 0.5659545608680909, \"f0_5\": 0.8391151332327803, \"p4\": 0.8018659739376692, \"phi\": 0.7041478937542865}, {\"truth_threshold\": 30.586203521704686, \"match_probability\": 0.9999999993796521, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3337.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3201.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5104007124900818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4895992577075958, \"precision\": 1.0, \"recall\": 0.5104007124900818, \"specificity\": 1.0, \"npv\": 0.9711413383483887, \"accuracy\": 0.9719842076301575, \"f1\": 0.6758481012658227, \"f2\": 0.5658041981755909, \"f0_5\": 0.839032485165443, \"p4\": 0.8017701422284628, \"phi\": 0.7040392513839182}, {\"truth_threshold\": 30.59252184366681, \"match_probability\": 0.9999999993823631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3333.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3205.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5097889304161072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4902110695838928, \"precision\": 1.0, \"recall\": 0.5097889304161072, \"specificity\": 1.0, \"npv\": 0.9711063504219055, \"accuracy\": 0.9719492197036743, \"f1\": 0.6753115185898085, \"f2\": 0.5652026454129219, \"f0_5\": 0.8387015601409159, \"p4\": 0.8013864788554304, \"phi\": 0.7036044710398272}, {\"truth_threshold\": 30.592673293226845, \"match_probability\": 0.9999999993824279, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3331.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3207.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5094830393791199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4905169904232025, \"precision\": 1.0, \"recall\": 0.5094830393791199, \"specificity\": 1.0, \"npv\": 0.9710888266563416, \"accuracy\": 0.9719316959381104, \"f1\": 0.6750430641402371, \"f2\": 0.5649018078214564, \"f0_5\": 0.8385358976940892, \"p4\": 0.8011944449878166, \"phi\": 0.7033870232183134}, {\"truth_threshold\": 30.597505312456775, \"match_probability\": 0.9999999993844928, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3329.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3209.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5091770887374878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4908228814601898, \"precision\": 1.0, \"recall\": 0.5091770887374878, \"specificity\": 1.0, \"npv\": 0.9710713028907776, \"accuracy\": 0.9719141721725464, \"f1\": 0.6747745008614574, \"f2\": 0.5646009294121638, \"f0_5\": 0.8383701017427219, \"p4\": 0.8010022761348599, \"phi\": 0.703169453249443}, {\"truth_threshold\": 30.59796453183821, \"match_probability\": 0.9999999993846888, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3328.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3210.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5090241432189941, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49097582697868347, \"precision\": 1.0, \"recall\": 0.5090241432189941, \"specificity\": 1.0, \"npv\": 0.9710626006126404, \"accuracy\": 0.9719054698944092, \"f1\": 0.6746401783904318, \"f2\": 0.5644504748982361, \"f0_5\": 0.8382871536523929, \"p4\": 0.8009061410424081, \"phi\": 0.7030606773382495}, {\"truth_threshold\": 30.59904832160844, \"match_probability\": 0.9999999993851508, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3324.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3214.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5084123611450195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49158763885498047, \"precision\": 1.0, \"recall\": 0.5084123611450195, \"specificity\": 1.0, \"npv\": 0.9710275530815125, \"accuracy\": 0.9718704223632812, \"f1\": 0.6741026161022105, \"f2\": 0.563848554756412, \"f0_5\": 0.8379550267217909, \"p4\": 0.8005212624650092, \"phi\": 0.7026253621241138}, {\"truth_threshold\": 30.599194664197253, \"match_probability\": 0.9999999993852131, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3323.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3215.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5082594156265259, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4917405843734741, \"precision\": 1.0, \"recall\": 0.5082594156265259, \"specificity\": 1.0, \"npv\": 0.9710187911987305, \"accuracy\": 0.9718616604804993, \"f1\": 0.6739681573876889, \"f2\": 0.5636980491942324, \"f0_5\": 0.8378719112455875, \"p4\": 0.8004249581755316, \"phi\": 0.7025165117814118}, {\"truth_threshold\": 30.61537150699391, \"match_probability\": 0.9999999993920682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3321.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3217.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5079535245895386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4920465052127838, \"precision\": 1.0, \"recall\": 0.5079535245895386, \"specificity\": 1.0, \"npv\": 0.9710013270378113, \"accuracy\": 0.9718441963195801, \"f1\": 0.6736991581296278, \"f2\": 0.5633970074305297, \"f0_5\": 0.8377055796589647, \"p4\": 0.8002322478917089, \"phi\": 0.7022987035510101}, {\"truth_threshold\": 30.627858422449396, \"match_probability\": 0.9999999993973073, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3319.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3219.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5076475739479065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4923523962497711, \"precision\": 1.0, \"recall\": 0.5076475739479065, \"specificity\": 1.0, \"npv\": 0.9709838032722473, \"accuracy\": 0.9718266725540161, \"f1\": 0.6734300497108654, \"f2\": 0.5630959248074379, \"f0_5\": 0.8375391137579489, \"p4\": 0.8000394018767011, \"phi\": 0.702080898446629}, {\"truth_threshold\": 30.628437172008667, \"match_probability\": 0.999999999397549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3318.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3220.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5074946284294128, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49250534176826477, \"precision\": 1.0, \"recall\": 0.5074946284294128, \"specificity\": 1.0, \"npv\": 0.9709750413894653, \"accuracy\": 0.9718179106712341, \"f1\": 0.6732954545454546, \"f2\": 0.5629453681710214, \"f0_5\": 0.8374558303886925, \"p4\": 0.7999429279231904, \"phi\": 0.7019719734978919}, {\"truth_threshold\": 30.63716585572978, \"match_probability\": 0.999999999401183, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3315.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3223.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5070357918739319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4929642081260681, \"precision\": 1.0, \"recall\": 0.5070357918739319, \"specificity\": 1.0, \"npv\": 0.9709487557411194, \"accuracy\": 0.971791684627533, \"f1\": 0.6728915051253426, \"f2\": 0.5624936369498083, \"f0_5\": 0.8372057783614506, \"p4\": 0.7996533020536017, \"phi\": 0.7016450461044386}, {\"truth_threshold\": 30.63998637479216, \"match_probability\": 0.9999999994023526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3314.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3224.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5068828463554382, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49311715364456177, \"precision\": 1.0, \"recall\": 0.5068828463554382, \"specificity\": 1.0, \"npv\": 0.9709400534629822, \"accuracy\": 0.971782922744751, \"f1\": 0.6727568006496143, \"f2\": 0.5623430394352813, \"f0_5\": 0.8371223603112055, \"p4\": 0.7995566920314646, \"phi\": 0.7015360613429292}, {\"truth_threshold\": 30.640574512754075, \"match_probability\": 0.9999999994025962, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3309.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3229.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5061180591583252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4938819110393524, \"precision\": 1.0, \"recall\": 0.5061180591583252, \"specificity\": 1.0, \"npv\": 0.970896303653717, \"accuracy\": 0.9717391729354858, \"f1\": 0.6720828678785417, \"f2\": 0.5615898985098945, \"f0_5\": 0.8367047638312937, \"p4\": 0.7990731305822184, \"phi\": 0.7009908499356429}, {\"truth_threshold\": 30.642406731018554, \"match_probability\": 0.9999999994033544, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3307.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3231.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5058121681213379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4941878318786621, \"precision\": 1.0, \"recall\": 0.5058121681213379, \"specificity\": 1.0, \"npv\": 0.9708787798881531, \"accuracy\": 0.9717216491699219, \"f1\": 0.6718131030980193, \"f2\": 0.5612885705556876, \"f0_5\": 0.8365374886168168, \"p4\": 0.7988794670260048, \"phi\": 0.700772622600135}, {\"truth_threshold\": 30.644446942950896, \"match_probability\": 0.9999999994041976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3306.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3232.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5056592226028442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49434077739715576, \"precision\": 1.0, \"recall\": 0.5056592226028442, \"specificity\": 1.0, \"npv\": 0.9708700180053711, \"accuracy\": 0.9717128872871399, \"f1\": 0.6716781796017879, \"f2\": 0.5611378912349786, \"f0_5\": 0.8364538002226495, \"p4\": 0.7987825839631225, \"phi\": 0.7006635178753393}, {\"truth_threshold\": 30.649126295362525, \"match_probability\": 0.9999999994061269, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3304.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3234.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5053533315658569, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49464666843414307, \"precision\": 1.0, \"recall\": 0.5053533315658569, \"specificity\": 1.0, \"npv\": 0.9708524942398071, \"accuracy\": 0.9716953635215759, \"f1\": 0.6714082503556188, \"f2\": 0.5608365019011406, \"f0_5\": 0.8362863217576187, \"p4\": 0.7985887151732305, \"phi\": 0.7004452633440684}, {\"truth_threshold\": 30.650006468292798, \"match_probability\": 0.9999999994064891, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3302.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3236.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5050474405288696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49495258927345276, \"precision\": 1.0, \"recall\": 0.5050474405288696, \"specificity\": 1.0, \"npv\": 0.9708350300788879, \"accuracy\": 0.9716778993606567, \"f1\": 0.6711382113821138, \"f2\": 0.5605350716371291, \"f0_5\": 0.8361187075863467, \"p4\": 0.79839470937157, \"phi\": 0.7002268856597657}, {\"truth_threshold\": 30.65132391872644, \"match_probability\": 0.9999999994070309, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3299.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3239.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5045885443687439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4954114556312561, \"precision\": 1.0, \"recall\": 0.5045885443687439, \"specificity\": 1.0, \"npv\": 0.9708088040351868, \"accuracy\": 0.9716516137123108, \"f1\": 0.6707329470366982, \"f2\": 0.5600828494787953, \"f0_5\": 0.8358670315192054, \"p4\": 0.7981034434400787, \"phi\": 0.6998993006841575}, {\"truth_threshold\": 30.657393911346126, \"match_probability\": 0.9999999994095204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3298.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3240.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5044355988502502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49556440114974976, \"precision\": 1.0, \"recall\": 0.5044355988502502, \"specificity\": 1.0, \"npv\": 0.9708000421524048, \"accuracy\": 0.9716428518295288, \"f1\": 0.67059780398536, \"f2\": 0.5599320882852292, \"f0_5\": 0.8357830714647745, \"p4\": 0.7980062861258653, \"phi\": 0.6997900125187532}, {\"truth_threshold\": 30.658983383987913, \"match_probability\": 0.9999999994101707, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3296.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3242.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5041297078132629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49587029218673706, \"precision\": 1.0, \"recall\": 0.5041297078132629, \"specificity\": 1.0, \"npv\": 0.9707825183868408, \"accuracy\": 0.9716253876686096, \"f1\": 0.6703274354281066, \"f2\": 0.5596305351806574, \"f0_5\": 0.8356150491836528, \"p4\": 0.7978118683777218, \"phi\": 0.6995715169853702}, {\"truth_threshold\": 30.663715089720828, \"match_probability\": 0.999999999412102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3295.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3243.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5039767622947693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4960232377052307, \"precision\": 1.0, \"recall\": 0.5039767622947693, \"specificity\": 1.0, \"npv\": 0.9707737565040588, \"accuracy\": 0.9716166257858276, \"f1\": 0.6701922099054205, \"f2\": 0.5594797432675654, \"f0_5\": 0.8355309869155086, \"p4\": 0.797714607905695, \"phi\": 0.6994622465784336}, {\"truth_threshold\": 30.666896857408265, \"match_probability\": 0.9999999994133971, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3291.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3247.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5033649206161499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4966350495815277, \"precision\": 1.0, \"recall\": 0.5033649206161499, \"specificity\": 1.0, \"npv\": 0.9707387685775757, \"accuracy\": 0.9715816378593445, \"f1\": 0.6696510326584597, \"f2\": 0.5588764731854771, \"f0_5\": 0.8351943965079688, \"p4\": 0.7973252215861033, \"phi\": 0.6990249507503107}, {\"truth_threshold\": 30.673666362955025, \"match_probability\": 0.9999999994161431, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3290.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3248.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5032119750976562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49678799510002136, \"precision\": 1.0, \"recall\": 0.5032119750976562, \"specificity\": 1.0, \"npv\": 0.9707300662994385, \"accuracy\": 0.9715728759765625, \"f1\": 0.6695156695156695, \"f2\": 0.5587256300523062, \"f0_5\": 0.8351101634683724, \"p4\": 0.797227788802811, \"phi\": 0.6989156047476659}, {\"truth_threshold\": 30.682630210576008, \"match_probability\": 0.9999999994197596, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3283.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3255.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5021413564682007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4978586733341217, \"precision\": 1.0, \"recall\": 0.5021413564682007, \"specificity\": 1.0, \"npv\": 0.9706687927246094, \"accuracy\": 0.9715116024017334, \"f1\": 0.6685673556664291, \"f2\": 0.5576694411414982, \"f0_5\": 0.8345195729537367, \"p4\": 0.7965447916968783, \"phi\": 0.6981496320960834}, {\"truth_threshold\": 30.68437841518967, \"match_probability\": 0.9999999994204622, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3282.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3256.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5019883513450623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49801161885261536, \"precision\": 1.0, \"recall\": 0.5019883513450623, \"specificity\": 1.0, \"npv\": 0.9706600308418274, \"accuracy\": 0.9715028405189514, \"f1\": 0.6684317718940936, \"f2\": 0.5575185160019026, \"f0_5\": 0.8344350655954439, \"p4\": 0.7964470822195441, \"phi\": 0.6980401647640598}, {\"truth_threshold\": 30.684599036159387, \"match_probability\": 0.999999999420551, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3281.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3257.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5018354058265686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.498164564371109, \"precision\": 1.0, \"recall\": 0.5018354058265686, \"specificity\": 1.0, \"npv\": 0.9706513285636902, \"accuracy\": 0.9714940786361694, \"f1\": 0.6682961605051431, \"f2\": 0.5573675806068019, \"f0_5\": 0.8343505238531177, \"p4\": 0.796349338068963, \"phi\": 0.6979306822358464}, {\"truth_threshold\": 30.685410160820147, \"match_probability\": 0.9999999994208766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3280.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3258.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.501682460308075, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49831753969192505, \"precision\": 1.0, \"recall\": 0.501682460308075, \"specificity\": 1.0, \"npv\": 0.9706425666809082, \"accuracy\": 0.9714853167533875, \"f1\": 0.6681605214911387, \"f2\": 0.5572166349551508, \"f0_5\": 0.8342659477057687, \"p4\": 0.7962515592258673, \"phi\": 0.6978211845042371}, {\"truth_threshold\": 30.68685297983013, \"match_probability\": 0.9999999994214555, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3277.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3261.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.501223623752594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.498776376247406, \"precision\": 1.0, \"recall\": 0.501223623752594, \"specificity\": 1.0, \"npv\": 0.970616340637207, \"accuracy\": 0.9714590907096863, \"f1\": 0.6677534386143658, \"f2\": 0.5567637364504401, \"f0_5\": 0.8340120126234348, \"p4\": 0.7959580143486003, \"phi\": 0.6974925367872427}, {\"truth_threshold\": 30.68938553527332, \"match_probability\": 0.9999999994224702, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3274.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3264.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.500764787197113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.49923524260520935, \"precision\": 1.0, \"recall\": 0.500764787197113, \"specificity\": 1.0, \"npv\": 0.9705901145935059, \"accuracy\": 0.9714328050613403, \"f1\": 0.6673461068079902, \"f2\": 0.5563107455991301, \"f0_5\": 0.833757767138637, \"p4\": 0.7956641565436894, \"phi\": 0.6971637519235312}, {\"truth_threshold\": 30.69230740992224, \"match_probability\": 0.9999999994236387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3273.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3265.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5006117820739746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.499388188123703, \"precision\": 1.0, \"recall\": 0.5006117820739746, \"specificity\": 1.0, \"npv\": 0.9705813527107239, \"accuracy\": 0.9714240431785583, \"f1\": 0.6672102741820406, \"f2\": 0.5561597281223449, \"f0_5\": 0.8336729495669893, \"p4\": 0.7955661343122926, \"phi\": 0.6970541475471684}, {\"truth_threshold\": 30.694283892408876, \"match_probability\": 0.9999999994244277, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3271.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3267.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5003058910369873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4996941089630127, \"precision\": 1.0, \"recall\": 0.5003058910369873, \"specificity\": 1.0, \"npv\": 0.9705638289451599, \"accuracy\": 0.9714065790176392, \"f1\": 0.666938525843613, \"f2\": 0.5558576623729735, \"f0_5\": 0.8335032106818877, \"p4\": 0.7953699852885869, \"phi\": 0.6968348930034365}, {\"truth_threshold\": 30.712995992492047, \"match_probability\": 0.9999999994318448, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.5, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5, \"precision\": 1.0, \"recall\": 0.5, \"specificity\": 1.0, \"npv\": 0.9705463647842407, \"accuracy\": 0.9713890552520752, \"f1\": 0.6666666666666666, \"f2\": 0.5555555555555556, \"f0_5\": 0.8333333333333334, \"p4\": 0.7951736967209484, \"phi\": 0.6966155140519399}, {\"truth_threshold\": 30.714318977439525, \"match_probability\": 0.9999999994323656, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3268.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3270.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49984705448150635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5001529455184937, \"precision\": 1.0, \"recall\": 0.49984705448150635, \"specificity\": 1.0, \"npv\": 0.9705376029014587, \"accuracy\": 0.9713802933692932, \"f1\": 0.6665306954925556, \"f2\": 0.5554044867437118, \"f0_5\": 0.833248342682305, \"p4\": 0.7950755000595817, \"phi\": 0.696505833287314}, {\"truth_threshold\": 30.721320439584577, \"match_probability\": 0.9999999994351138, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3264.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3274.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49923524260520935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.500764787197113, \"precision\": 1.0, \"recall\": 0.49923524260520935, \"specificity\": 1.0, \"npv\": 0.9705026149749756, \"accuracy\": 0.9713453054428101, \"f1\": 0.6659865333605387, \"f2\": 0.554800108784335, \"f0_5\": 0.8329080330713484, \"p4\": 0.794682363776362, \"phi\": 0.6960668938283271}, {\"truth_threshold\": 30.721807012965698, \"match_probability\": 0.9999999994353042, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3262.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3276.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49892932176589966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5010706782341003, \"precision\": 1.0, \"recall\": 0.49892932176589966, \"specificity\": 1.0, \"npv\": 0.9704851508140564, \"accuracy\": 0.9713277816772461, \"f1\": 0.6657142857142857, \"f2\": 0.5544978581627796, \"f0_5\": 0.8327376697641172, \"p4\": 0.7944855855791834, \"phi\": 0.6958473638244942}, {\"truth_threshold\": 30.72462681767959, \"match_probability\": 0.9999999994364068, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4984704852104187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5015295147895813, \"precision\": 1.0, \"recall\": 0.4984704852104187, \"specificity\": 1.0, \"npv\": 0.9704589247703552, \"accuracy\": 0.9713015556335449, \"f1\": 0.6653057058283148, \"f2\": 0.554044405154534, \"f0_5\": 0.8324818636967406, \"p4\": 0.7941901552745226, \"phi\": 0.6955178903412138}, {\"truth_threshold\": 30.7298042801786, \"match_probability\": 0.9999999994384258, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3258.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3280.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49831753969192505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.501682460308075, \"precision\": 1.0, \"recall\": 0.49831753969192505, \"specificity\": 1.0, \"npv\": 0.9704501628875732, \"accuracy\": 0.9712927937507629, \"f1\": 0.6651694569211923, \"f2\": 0.5538932335940157, \"f0_5\": 0.832396525293817, \"p4\": 0.7940916082923312, \"phi\": 0.6954080562533791}, {\"truth_threshold\": 30.73586299616028, \"match_probability\": 0.9999999994407792, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3257.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3281.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.498164564371109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5018354058265686, \"precision\": 1.0, \"recall\": 0.498164564371109, \"specificity\": 1.0, \"npv\": 0.970441460609436, \"accuracy\": 0.971284031867981, \"f1\": 0.6650331801939765, \"f2\": 0.5537420517528647, \"f0_5\": 0.8323111519983645, \"p4\": 0.7939930261705007, \"phi\": 0.6952981433770843}, {\"truth_threshold\": 30.73980800053022, \"match_probability\": 0.9999999994423063, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3256.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3282.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49801161885261536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5019883513450623, \"precision\": 1.0, \"recall\": 0.49801161885261536, \"specificity\": 1.0, \"npv\": 0.970432698726654, \"accuracy\": 0.971275269985199, \"f1\": 0.6648968756381458, \"f2\": 0.5535908596300326, \"f0_5\": 0.8322257437889786, \"p4\": 0.7938944088894174, \"phi\": 0.6951882785310854}, {\"truth_threshold\": 30.744931126453995, \"match_probability\": 0.9999999994442832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3255.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3283.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4978586733341217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5021413564682007, \"precision\": 1.0, \"recall\": 0.4978586733341217, \"specificity\": 1.0, \"npv\": 0.9704239368438721, \"accuracy\": 0.971266508102417, \"f1\": 0.6647605432451751, \"f2\": 0.5534396572244704, \"f0_5\": 0.8321403006442376, \"p4\": 0.7937957564294527, \"phi\": 0.6950783982997107}, {\"truth_threshold\": 30.74640445155345, \"match_probability\": 0.9999999994448504, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3253.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3285.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4975527822971344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.502447247505188, \"precision\": 1.0, \"recall\": 0.4975527822971344, \"specificity\": 1.0, \"npv\": 0.9704064726829529, \"accuracy\": 0.9712490439414978, \"f1\": 0.6644877949136963, \"f2\": 0.553137221560959, \"f0_5\": 0.8319693094629156, \"p4\": 0.7935983458942917, \"phi\": 0.6948585916514235}, {\"truth_threshold\": 30.756164195505352, \"match_probability\": 0.9999999994485933, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3252.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3286.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49739980697631836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5026001930236816, \"precision\": 1.0, \"recall\": 0.49739980697631836, \"specificity\": 1.0, \"npv\": 0.9703977108001709, \"accuracy\": 0.9712402820587158, \"f1\": 0.6643513789581206, \"f2\": 0.5529859883009114, \"f0_5\": 0.8318837613834033, \"p4\": 0.7934995877797655, \"phi\": 0.6947486017547124}, {\"truth_threshold\": 30.765068772025074, \"match_probability\": 0.9999999994519863, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3250.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3288.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49709391593933105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.502906084060669, \"precision\": 1.0, \"recall\": 0.49709391593933105, \"specificity\": 1.0, \"npv\": 0.9703802466392517, \"accuracy\": 0.9712227582931519, \"f1\": 0.6640784634246015, \"f2\": 0.552683490918985, \"f0_5\": 0.8317125601392159, \"p4\": 0.7933019657583864, \"phi\": 0.6945287026206776}, {\"truth_threshold\": 30.76787232101212, \"match_probability\": 0.9999999994530501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3249.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3289.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4969409704208374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5030590295791626, \"precision\": 1.0, \"recall\": 0.4969409704208374, \"specificity\": 1.0, \"npv\": 0.9703714847564697, \"accuracy\": 0.9712139964103699, \"f1\": 0.6639419638295698, \"f2\": 0.552532226795007, \"f0_5\": 0.8316269069315041, \"p4\": 0.7932031018121155, \"phi\": 0.694418729912991}, {\"truth_threshold\": 30.777320511808334, \"match_probability\": 0.9999999994566204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3243.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3295.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4960232377052307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5039767622947693, \"precision\": 1.0, \"recall\": 0.4960232377052307, \"specificity\": 1.0, \"npv\": 0.9703190326690674, \"accuracy\": 0.9711614847183228, \"f1\": 0.6631223801247316, \"f2\": 0.5516244259227759, \"f0_5\": 0.8311122501281394, \"p4\": 0.7926091757923721, \"phi\": 0.6937584421308587}, {\"truth_threshold\": 30.789498563620036, \"match_probability\": 0.9999999994611879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3242.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3296.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49587029218673706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5041297078132629, \"precision\": 1.0, \"recall\": 0.49587029218673706, \"specificity\": 1.0, \"npv\": 0.9703103303909302, \"accuracy\": 0.9711527228355408, \"f1\": 0.6629856850715746, \"f2\": 0.5514730897462067, \"f0_5\": 0.8310263508664001, \"p4\": 0.7925100642140914, \"phi\": 0.6936483611900273}, {\"truth_threshold\": 30.791771737310935, \"match_probability\": 0.9999999994620361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3241.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3297.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4957173466682434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5042826533317566, \"precision\": 1.0, \"recall\": 0.4957173466682434, \"specificity\": 1.0, \"npv\": 0.9703015685081482, \"accuracy\": 0.9711440205574036, \"f1\": 0.6628489620615605, \"f2\": 0.5513217432722076, \"f0_5\": 0.830940416367552, \"p4\": 0.7924109171805906, \"phi\": 0.6935382647603717}, {\"truth_threshold\": 30.794001578983966, \"match_probability\": 0.999999999462867, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3240.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3298.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49556440114974976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5044355988502502, \"precision\": 1.0, \"recall\": 0.49556440114974976, \"specificity\": 1.0, \"npv\": 0.970292866230011, \"accuracy\": 0.9711352586746216, \"f1\": 0.6627122110861117, \"f2\": 0.5511703864997278, \"f0_5\": 0.8308544466099087, \"p4\": 0.7923117346720208, \"phi\": 0.693428152834461}, {\"truth_threshold\": 30.798107427995944, \"match_probability\": 0.9999999994643934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3236.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3302.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49495258927345276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5050474405288696, \"precision\": 1.0, \"recall\": 0.49495258927345276, \"specificity\": 1.0, \"npv\": 0.9702578783035278, \"accuracy\": 0.9711002111434937, \"f1\": 0.6621649273582976, \"f2\": 0.5505648564039745, \"f0_5\": 0.830510214557027, \"p4\": 0.7919146494895525, \"phi\": 0.6929874864022426}, {\"truth_threshold\": 30.813505200575676, \"match_probability\": 0.9999999994700796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3234.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3304.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49464666843414307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5053533315658569, \"precision\": 1.0, \"recall\": 0.49464666843414307, \"specificity\": 1.0, \"npv\": 0.9702404141426086, \"accuracy\": 0.9710827469825745, \"f1\": 0.66189111747851, \"f2\": 0.5502620295378752, \"f0_5\": 0.8303378864126527, \"p4\": 0.7917158935307406, \"phi\": 0.6927670281681787}, {\"truth_threshold\": 30.82551250199841, \"match_probability\": 0.9999999994744717, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3233.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3305.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4944937229156494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5055062770843506, \"precision\": 1.0, \"recall\": 0.4944937229156494, \"specificity\": 1.0, \"npv\": 0.9702316522598267, \"accuracy\": 0.9710739850997925, \"f1\": 0.6617541705045543, \"f2\": 0.5501106006465883, \"f0_5\": 0.83025166923472, \"p4\": 0.79161646213967, \"phi\": 0.6926568075408162}, {\"truth_threshold\": 30.827756328245517, \"match_probability\": 0.9999999994752884, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3232.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3306.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49434077739715576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5056592226028442, \"precision\": 1.0, \"recall\": 0.49434077739715576, \"specificity\": 1.0, \"npv\": 0.9702229499816895, \"accuracy\": 0.9710652232170105, \"f1\": 0.6616171954964176, \"f2\": 0.5499591614484073, \"f0_5\": 0.830165416623857, \"p4\": 0.7915169951142041, \"phi\": 0.6925465713575323}, {\"truth_threshold\": 30.83710155961181, \"match_probability\": 0.9999999994786763, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3229.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3309.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4938819110393524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5061180591583252, \"precision\": 1.0, \"recall\": 0.4938819110393524, \"specificity\": 1.0, \"npv\": 0.9701967239379883, \"accuracy\": 0.9710389971733093, \"f1\": 0.661206102180813, \"f2\": 0.5495047820019741, \"f0_5\": 0.8299064459751208, \"p4\": 0.7912183800315329, \"phi\": 0.6922157057131824}, {\"truth_threshold\": 30.855800749350784, \"match_probability\": 0.9999999994853898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3227.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3311.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4935760200023651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5064240097999573, \"precision\": 1.0, \"recall\": 0.4935760200023651, \"specificity\": 1.0, \"npv\": 0.9701792597770691, \"accuracy\": 0.9710214734077454, \"f1\": 0.6609318996415771, \"f2\": 0.5492018108172504, \"f0_5\": 0.8297336213102952, \"p4\": 0.7910191247710269, \"phi\": 0.6919950931369112}, {\"truth_threshold\": 30.858202701332452, \"match_probability\": 0.9999999994862458, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3226.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3312.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49342307448387146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5065769553184509, \"precision\": 1.0, \"recall\": 0.49342307448387146, \"specificity\": 1.0, \"npv\": 0.9701704978942871, \"accuracy\": 0.9710127115249634, \"f1\": 0.6607947562474396, \"f2\": 0.5490503097555994, \"f0_5\": 0.8296471556424236, \"p4\": 0.7909194435190284, \"phi\": 0.6918847634511635}, {\"truth_threshold\": 30.8689352793018, \"match_probability\": 0.9999999994900536, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3224.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3314.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49311715364456177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5068828463554382, \"precision\": 1.0, \"recall\": 0.49311715364456177, \"specificity\": 1.0, \"npv\": 0.9701530337333679, \"accuracy\": 0.9709951877593994, \"f1\": 0.660520385166974, \"f2\": 0.5487472766884531, \"f0_5\": 0.8294741175259854, \"p4\": 0.790719973671178, \"phi\": 0.6916639935148141}, {\"truth_threshold\": 30.86915323012559, \"match_probability\": 0.9999999994901306, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3223.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3315.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4929642081260681, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5070357918739319, \"precision\": 1.0, \"recall\": 0.4929642081260681, \"specificity\": 1.0, \"npv\": 0.9701442718505859, \"accuracy\": 0.9709864854812622, \"f1\": 0.6603831574633746, \"f2\": 0.548595744680851, \"f0_5\": 0.8293875450334535, \"p4\": 0.7906201850351359, \"phi\": 0.6915536169715977}, {\"truth_threshold\": 30.873321662677096, \"match_probability\": 0.9999999994916017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3222.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3316.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49281126260757446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5071887373924255, \"precision\": 1.0, \"recall\": 0.49281126260757446, \"specificity\": 1.0, \"npv\": 0.9701355695724487, \"accuracy\": 0.9709777235984802, \"f1\": 0.6602459016393443, \"f2\": 0.5484442023558249, \"f0_5\": 0.8293009368887059, \"p4\": 0.790520360564197, \"phi\": 0.6914432247973568}, {\"truth_threshold\": 30.88388041761067, \"match_probability\": 0.9999999994953089, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3221.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3317.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4926583170890808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5073416829109192, \"precision\": 1.0, \"recall\": 0.4926583170890808, \"specificity\": 1.0, \"npv\": 0.9701268076896667, \"accuracy\": 0.9709689617156982, \"f1\": 0.6601086176862383, \"f2\": 0.5482926497123208, \"f0_5\": 0.8292142930697147, \"p4\": 0.7904205002382291, \"phi\": 0.6913328169845496}, {\"truth_threshold\": 30.88673964978889, \"match_probability\": 0.9999999994963081, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3220.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3318.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49250534176826477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5074946284294128, \"precision\": 1.0, \"recall\": 0.49250534176826477, \"specificity\": 1.0, \"npv\": 0.9701180458068848, \"accuracy\": 0.9709601998329163, \"f1\": 0.6599713055954088, \"f2\": 0.5481410867492851, \"f0_5\": 0.829127613554434, \"p4\": 0.7903206040370839, \"phi\": 0.6912223297551658}, {\"truth_threshold\": 30.893590528700724, \"match_probability\": 0.9999999994986943, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3219.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3319.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4923523962497711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5076475739479065, \"precision\": 1.0, \"recall\": 0.4923523962497711, \"specificity\": 1.0, \"npv\": 0.9701093435287476, \"accuracy\": 0.9709514379501343, \"f1\": 0.6598339653582044, \"f2\": 0.5479895134656634, \"f0_5\": 0.8290408983207994, \"p4\": 0.790220671940599, \"phi\": 0.6911118906329603}, {\"truth_threshold\": 30.906457869939672, \"match_probability\": 0.9999999995031457, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3212.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3326.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49128174781799316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5087182521820068, \"precision\": 1.0, \"recall\": 0.49128174781799316, \"specificity\": 1.0, \"npv\": 0.970048189163208, \"accuracy\": 0.9708901643753052, \"f1\": 0.6588717948717949, \"f2\": 0.5469282114153385, \"f0_5\": 0.8284328897142268, \"p4\": 0.7895201404988273, \"phi\": 0.6903383139914608}, {\"truth_threshold\": 30.910991512443022, \"match_probability\": 0.9999999995047045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3211.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3327.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4911287724971771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5088711977005005, \"precision\": 1.0, \"recall\": 0.4911287724971771, \"specificity\": 1.0, \"npv\": 0.970039427280426, \"accuracy\": 0.970881462097168, \"f1\": 0.6587342291517079, \"f2\": 0.5467765555290672, \"f0_5\": 0.8283458879372614, \"p4\": 0.7894199205119434, \"phi\": 0.6902276855004151}, {\"truth_threshold\": 30.91397897725203, \"match_probability\": 0.9999999995057292, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3209.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3329.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4908228814601898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5091770887374878, \"precision\": 1.0, \"recall\": 0.4908228814601898, \"specificity\": 1.0, \"npv\": 0.9700219631195068, \"accuracy\": 0.970863938331604, \"f1\": 0.6584590130296502, \"f2\": 0.5464732127652328, \"f0_5\": 0.8281717766078249, \"p4\": 0.7892193722853995, \"phi\": 0.6900065090399863}, {\"truth_threshold\": 30.918401661713656, \"match_probability\": 0.999999999507242, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3207.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3331.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4905169904232025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5094830393791199, \"precision\": 1.0, \"recall\": 0.4905169904232025, \"specificity\": 1.0, \"npv\": 0.9700044989585876, \"accuracy\": 0.97084641456604, \"f1\": 0.6581836839404823, \"f2\": 0.5461698286726387, \"f0_5\": 0.827997521429309, \"p4\": 0.7890186795863141, \"phi\": 0.6897852696309179}, {\"truth_threshold\": 30.92704759304172, \"match_probability\": 0.9999999995101863, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3206.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3332.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4903640151023865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5096359848976135, \"precision\": 1.0, \"recall\": 0.4903640151023865, \"specificity\": 1.0, \"npv\": 0.9699957966804504, \"accuracy\": 0.9708376526832581, \"f1\": 0.6580459770114943, \"f2\": 0.5460181211254173, \"f0_5\": 0.8279103398409255, \"p4\": 0.7889182790086962, \"phi\": 0.6896745623960597}, {\"truth_threshold\": 30.927409178239394, \"match_probability\": 0.9999999995103089, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3204.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3334.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.49005812406539917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5099418759346008, \"precision\": 1.0, \"recall\": 0.49005812406539917, \"specificity\": 1.0, \"npv\": 0.9699782729148865, \"accuracy\": 0.9708201885223389, \"f1\": 0.6577704783412031, \"f2\": 0.5457146750238452, \"f0_5\": 0.827735868554304, \"p4\": 0.7887173692954318, \"phi\": 0.6894532284302227}, {\"truth_threshold\": 30.934168977571975, \"match_probability\": 0.9999999995125981, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3203.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3335.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4899051785469055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5100948214530945, \"precision\": 1.0, \"recall\": 0.4899051785469055, \"specificity\": 1.0, \"npv\": 0.9699695706367493, \"accuracy\": 0.9708114266395569, \"f1\": 0.6576326865824864, \"f2\": 0.5455629364673821, \"f0_5\": 0.8276485788113696, \"p4\": 0.7886168601189881, \"phi\": 0.6893425377881104}, {\"truth_threshold\": 30.935388413828495, \"match_probability\": 0.9999999995130099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3202.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3336.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4897522032260895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5102477669715881, \"precision\": 1.0, \"recall\": 0.4897522032260895, \"specificity\": 1.0, \"npv\": 0.9699608087539673, \"accuracy\": 0.9708026647567749, \"f1\": 0.6574948665297742, \"f2\": 0.5454111875723922, \"f0_5\": 0.8275612529721906, \"p4\": 0.7885163147021134, \"phi\": 0.6892317674187273}, {\"truth_threshold\": 30.93598071781173, \"match_probability\": 0.9999999995132097, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3201.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3337.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4895992577075958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5104007124900818, \"precision\": 1.0, \"recall\": 0.4895992577075958, \"specificity\": 1.0, \"npv\": 0.9699521064758301, \"accuracy\": 0.9707939028739929, \"f1\": 0.6573570181743505, \"f2\": 0.5452594283378189, \"f0_5\": 0.8274738910143729, \"p4\": 0.7884157330243704, \"phi\": 0.6891210451932556}, {\"truth_threshold\": 30.936726137588686, \"match_probability\": 0.9999999995134612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3200.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3338.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4894463121891022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5105536580085754, \"precision\": 1.0, \"recall\": 0.4894463121891022, \"specificity\": 1.0, \"npv\": 0.9699433445930481, \"accuracy\": 0.9707851409912109, \"f1\": 0.6572191415074964, \"f2\": 0.5451076587626056, \"f0_5\": 0.8273864929155031, \"p4\": 0.7883151150653072, \"phi\": 0.6890103071694528}, {\"truth_threshold\": 30.93935088457366, \"match_probability\": 0.9999999995143456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3197.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3341.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48898744583129883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5110125541687012, \"precision\": 1.0, \"recall\": 0.48898744583129883, \"specificity\": 1.0, \"npv\": 0.9699171781539917, \"accuracy\": 0.9707589149475098, \"f1\": 0.6568053415511043, \"f2\": 0.5446522879825547, \"f0_5\": 0.8271240815481734, \"p4\": 0.7880130432954418, \"phi\": 0.6886779342384878}, {\"truth_threshold\": 30.941459713674135, \"match_probability\": 0.9999999995150549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3196.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3342.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4888345003128052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5111654996871948, \"precision\": 1.0, \"recall\": 0.4888345003128052, \"specificity\": 1.0, \"npv\": 0.9699084162712097, \"accuracy\": 0.9707501530647278, \"f1\": 0.6566673515512637, \"f2\": 0.5445004770342101, \"f0_5\": 0.8270365386605941, \"p4\": 0.7879122800062667, \"phi\": 0.6885671329348528}, {\"truth_threshold\": 30.948444566653944, \"match_probability\": 0.9999999995173972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3191.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3347.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4880697429180145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5119302272796631, \"precision\": 1.0, \"recall\": 0.4880697429180145, \"specificity\": 1.0, \"npv\": 0.9698647856712341, \"accuracy\": 0.9707064032554626, \"f1\": 0.6559769760509816, \"f2\": 0.5437412670824388, \"f0_5\": 0.8265982799709874, \"p4\": 0.7874079173920773, \"phi\": 0.688012824659941}, {\"truth_threshold\": 30.951358174740374, \"match_probability\": 0.9999999995183708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3190.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3348.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4879167973995209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5120832324028015, \"precision\": 1.0, \"recall\": 0.4879167973995209, \"specificity\": 1.0, \"npv\": 0.9698560237884521, \"accuracy\": 0.9706976413726807, \"f1\": 0.6558388157894737, \"f2\": 0.5435893940426693, \"f0_5\": 0.8265105192247901, \"p4\": 0.7873069354915468, \"phi\": 0.6879019282103451}, {\"truth_threshold\": 30.955625796746567, \"match_probability\": 0.9999999995197935, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3188.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3350.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4876108765602112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5123891234397888, \"precision\": 1.0, \"recall\": 0.4876108765602112, \"specificity\": 1.0, \"npv\": 0.969838559627533, \"accuracy\": 0.9706801176071167, \"f1\": 0.6555624100349579, \"f2\": 0.5432856169052488, \"f0_5\": 0.8263348885432866, \"p4\": 0.7871048621479093, \"phi\": 0.6876800235737225}, {\"truth_threshold\": 30.95638565543662, \"match_probability\": 0.9999999995200463, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3186.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3352.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4873049855232239, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5126950144767761, \"precision\": 1.0, \"recall\": 0.4873049855232239, \"specificity\": 1.0, \"npv\": 0.9698210954666138, \"accuracy\": 0.9706626534461975, \"f1\": 0.6552858905800082, \"f2\": 0.5429817983502625, \"f0_5\": 0.8261591121252982, \"p4\": 0.7869026426098404, \"phi\": 0.6874581194038282}, {\"truth_threshold\": 30.972660700051183, \"match_probability\": 0.9999999995254302, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3185.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3353.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4871520400047302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5128479599952698, \"precision\": 1.0, \"recall\": 0.4871520400047302, \"specificity\": 1.0, \"npv\": 0.9698123931884766, \"accuracy\": 0.9706538915634155, \"f1\": 0.6551475881929446, \"f2\": 0.542829873538535, \"f0_5\": 0.8260711692084242, \"p4\": 0.7868014779662125, \"phi\": 0.6873471434516591}, {\"truth_threshold\": 30.979536285913497, \"match_probability\": 0.9999999995276866, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3184.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3354.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4869990944862366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5130009055137634, \"precision\": 1.0, \"recall\": 0.4869990944862366, \"specificity\": 1.0, \"npv\": 0.9698036313056946, \"accuracy\": 0.9706451296806335, \"f1\": 0.6550092573544538, \"f2\": 0.5426779383692392, \"f0_5\": 0.8259831897893535, \"p4\": 0.7867002767119274, \"phi\": 0.6872360874580921}, {\"truth_threshold\": 30.983790509603864, \"match_probability\": 0.9999999995290773, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3183.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3355.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48684611916542053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5131538510322571, \"precision\": 1.0, \"recall\": 0.48684611916542053, \"specificity\": 1.0, \"npv\": 0.9697949290275574, \"accuracy\": 0.9706363677978516, \"f1\": 0.6548708980557556, \"f2\": 0.5425259928413159, \"f0_5\": 0.8258951738453555, \"p4\": 0.7865990388262697, \"phi\": 0.6871250796447094}, {\"truth_threshold\": 30.993126202251638, \"match_probability\": 0.9999999995321147, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3180.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3358.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4863872826099396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5136127471923828, \"precision\": 1.0, \"recall\": 0.4863872826099396, \"specificity\": 1.0, \"npv\": 0.9697687029838562, \"accuracy\": 0.9706101417541504, \"f1\": 0.6544556493105578, \"f2\": 0.5420700940951861, \"f0_5\": 0.8256309066362031, \"p4\": 0.7862951051736703, \"phi\": 0.6867919605491447}, {\"truth_threshold\": 30.993211222810572, \"match_probability\": 0.9999999995321424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3178.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3360.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4860813617706299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5139186382293701, \"precision\": 1.0, \"recall\": 0.4860813617706299, \"specificity\": 1.0, \"npv\": 0.969751238822937, \"accuracy\": 0.9705926179885864, \"f1\": 0.654178674351585, \"f2\": 0.5417661097852029, \"f0_5\": 0.8254545454545454, \"p4\": 0.7860922992012515, \"phi\": 0.686569737183025}, {\"truth_threshold\": 30.99387910151993, \"match_probability\": 0.9999999995323589, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3177.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3361.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48592841625213623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5140715837478638, \"precision\": 1.0, \"recall\": 0.48592841625213623, \"specificity\": 1.0, \"npv\": 0.9697425365447998, \"accuracy\": 0.9705838561058044, \"f1\": 0.6540401441070509, \"f2\": 0.5416141020832623, \"f0_5\": 0.825366309882573, \"p4\": 0.7859908410914547, \"phi\": 0.6864586336186975}, {\"truth_threshold\": 31.014164158647382, \"match_probability\": 0.9999999995388882, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3176.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3362.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4857754707336426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5142245292663574, \"precision\": 1.0, \"recall\": 0.4857754707336426, \"specificity\": 1.0, \"npv\": 0.9697337746620178, \"accuracy\": 0.9705750942230225, \"f1\": 0.6539015853407453, \"f2\": 0.5414620840152755, \"f0_5\": 0.8252780376260264, \"p4\": 0.785889346204838, \"phi\": 0.6863475140702014}, {\"truth_threshold\": 31.038759431057464, \"match_probability\": 0.9999999995466826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3173.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3365.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48531660437583923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5146833658218384, \"precision\": 1.0, \"recall\": 0.48531660437583923, \"specificity\": 1.0, \"npv\": 0.9697076082229614, \"accuracy\": 0.9705488681793213, \"f1\": 0.6534857378230873, \"f2\": 0.5410059676044331, \"f0_5\": 0.8250130005200208, \"p4\": 0.78558464067558, \"phi\": 0.6860139952140483}, {\"truth_threshold\": 31.051955614658027, \"match_probability\": 0.9999999995508102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3172.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3366.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4851636588573456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5148363709449768, \"precision\": 1.0, \"recall\": 0.4851636588573456, \"specificity\": 1.0, \"npv\": 0.9696989059448242, \"accuracy\": 0.9705401062965393, \"f1\": 0.6533470648815654, \"f2\": 0.540853908061656, \"f0_5\": 0.8249245812961614, \"p4\": 0.7854829984731164, \"phi\": 0.6859028116407936}, {\"truth_threshold\": 31.052203355008622, \"match_probability\": 0.9999999995508873, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3171.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3367.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48501071333885193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5149893164634705, \"precision\": 1.0, \"recall\": 0.48501071333885193, \"specificity\": 1.0, \"npv\": 0.9696901440620422, \"accuracy\": 0.9705313444137573, \"f1\": 0.6532083633741889, \"f2\": 0.5407018381475293, \"f0_5\": 0.8248361252731246, \"p4\": 0.7853813193894706, \"phi\": 0.6857916120442096}, {\"truth_threshold\": 31.058959238613262, \"match_probability\": 0.9999999995529855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3170.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3368.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4848577678203583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5151422619819641, \"precision\": 1.0, \"recall\": 0.4848577678203583, \"specificity\": 1.0, \"npv\": 0.969681441783905, \"accuracy\": 0.9705225825309753, \"f1\": 0.6530696332921302, \"f2\": 0.5405497578609918, \"f0_5\": 0.8247476324279321, \"p4\": 0.7852796034037227, \"phi\": 0.6856803321594958}, {\"truth_threshold\": 31.060958370126322, \"match_probability\": 0.9999999995536045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3169.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3369.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48470479249954224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5152952075004578, \"precision\": 1.0, \"recall\": 0.48470479249954224, \"specificity\": 1.0, \"npv\": 0.969672679901123, \"accuracy\": 0.9705138206481934, \"f1\": 0.6529308746265582, \"f2\": 0.5403976672009823, \"f0_5\": 0.8246591027375871, \"p4\": 0.7851778504949372, \"phi\": 0.6855691004828495}, {\"truth_threshold\": 31.069382903295978, \"match_probability\": 0.9999999995562036, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3168.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3370.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4845518469810486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5154481530189514, \"precision\": 1.0, \"recall\": 0.4845518469810486, \"specificity\": 1.0, \"npv\": 0.9696639776229858, \"accuracy\": 0.9705051183700562, \"f1\": 0.6527920873686379, \"f2\": 0.5402455661664393, \"f0_5\": 0.8245705361790734, \"p4\": 0.7850760606421624, \"phi\": 0.6854578527593012}, {\"truth_threshold\": 31.074019012914224, \"match_probability\": 0.9999999995576274, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3167.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3371.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48439890146255493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5156010985374451, \"precision\": 1.0, \"recall\": 0.48439890146255493, \"specificity\": 1.0, \"npv\": 0.9696552157402039, \"accuracy\": 0.9704963564872742, \"f1\": 0.6526532715095311, \"f2\": 0.5400934547563013, \"f0_5\": 0.8244819327293554, \"p4\": 0.7849742338244312, \"phi\": 0.6853465889809823}, {\"truth_threshold\": 31.074923431508704, \"match_probability\": 0.9999999995579046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3166.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3372.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4842459559440613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5157540440559387, \"precision\": 1.0, \"recall\": 0.4842459559440613, \"specificity\": 1.0, \"npv\": 0.9696465134620667, \"accuracy\": 0.9704875946044922, \"f1\": 0.6525144270403958, \"f2\": 0.5399413329695067, \"f0_5\": 0.8243932923653786, \"p4\": 0.7848723700207604, \"phi\": 0.6852353091400185}, {\"truth_threshold\": 31.076899913995344, \"match_probability\": 0.9999999995585099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3164.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3374.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4839400351047516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.516059935092926, \"precision\": 1.0, \"recall\": 0.4839400351047516, \"specificity\": 1.0, \"npv\": 0.9696290493011475, \"accuracy\": 0.9704700708389282, \"f1\": 0.6522366522366523, \"f2\": 0.5396370582617, \"f0_5\": 0.8242159008023341, \"p4\": 0.7846685313715879, \"phi\": 0.6850126369225139}, {\"truth_threshold\": 31.0784900465289, \"match_probability\": 0.9999999995589962, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3163.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3375.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48378708958625793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5162128806114197, \"precision\": 1.0, \"recall\": 0.48378708958625793, \"specificity\": 1.0, \"npv\": 0.9696203470230103, \"accuracy\": 0.9704613089561462, \"f1\": 0.6520977218843418, \"f2\": 0.5394849053385639, \"f0_5\": 0.824127149557061, \"p4\": 0.7845665564840406, \"phi\": 0.6849013088364273}, {\"truth_threshold\": 31.084345000012366, \"match_probability\": 0.9999999995607823, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48348119854927063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5165188312530518, \"precision\": 1.0, \"recall\": 0.48348119854927063, \"specificity\": 1.0, \"npv\": 0.9696028828620911, \"accuracy\": 0.970443844795227, \"f1\": 0.6518197752345603, \"f2\": 0.5391805683485144, \"f0_5\": 0.8239495360233552, \"p4\": 0.7843624954777899, \"phi\": 0.6846785400279592}, {\"truth_threshold\": 31.084624832701, \"match_probability\": 0.9999999995608676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3160.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3378.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4833282232284546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5166717767715454, \"precision\": 1.0, \"recall\": 0.4833282232284546, \"specificity\": 1.0, \"npv\": 0.9695941209793091, \"accuracy\": 0.9704350829124451, \"f1\": 0.6516807589193648, \"f2\": 0.539028384279476, \"f0_5\": 0.8238606736886015, \"p4\": 0.7842604093169454, \"phi\": 0.6845671636256241}, {\"truth_threshold\": 31.090776623222904, \"match_probability\": 0.9999999995627361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3159.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3379.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48317527770996094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5168247222900391, \"precision\": 1.0, \"recall\": 0.48317527770996094, \"specificity\": 1.0, \"npv\": 0.9695854187011719, \"accuracy\": 0.9704263210296631, \"f1\": 0.651541713932144, \"f2\": 0.5388761898263451, \"f0_5\": 0.8237717742776677, \"p4\": 0.7841582860228339, \"phi\": 0.6844557711053362}, {\"truth_threshold\": 31.093490271469687, \"match_probability\": 0.9999999995635578, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3158.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3380.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4830223321914673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5169776678085327, \"precision\": 1.0, \"recall\": 0.4830223321914673, \"specificity\": 1.0, \"npv\": 0.9695766568183899, \"accuracy\": 0.9704175591468811, \"f1\": 0.6514026402640264, \"f2\": 0.5387239849880587, \"f0_5\": 0.8236828377673449, \"p4\": 0.7840561255743448, \"phi\": 0.6843443624591709}, {\"truth_threshold\": 31.098731905142937, \"match_probability\": 0.9999999995651406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3157.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3381.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48286938667297363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5171306133270264, \"precision\": 1.0, \"recall\": 0.48286938667297363, \"specificity\": 1.0, \"npv\": 0.9695679545402527, \"accuracy\": 0.9704087972640991, \"f1\": 0.6512635379061372, \"f2\": 0.5385717697635538, \"f0_5\": 0.8235938641344047, \"p4\": 0.7839539279503516, \"phi\": 0.6842329376791968}, {\"truth_threshold\": 31.101890479108977, \"match_probability\": 0.9999999995660916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3155.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3383.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48256346583366394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5174365043640137, \"precision\": 1.0, \"recall\": 0.48256346583366394, \"specificity\": 1.0, \"npv\": 0.9695504903793335, \"accuracy\": 0.9703913331031799, \"f1\": 0.6509852470855256, \"f2\": 0.5382673081516361, \"f0_5\": 0.8234158054076626, \"p4\": 0.7837494210912668, \"phi\": 0.6840099752808945}, {\"truth_threshold\": 31.104572331758277, \"match_probability\": 0.9999999995668974, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3152.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3386.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.482104629278183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5178954005241394, \"precision\": 1.0, \"recall\": 0.482104629278183, \"specificity\": 1.0, \"npv\": 0.9695243239402771, \"accuracy\": 0.970365047454834, \"f1\": 0.6505675954592364, \"f2\": 0.5378105378105378, \"f0_5\": 0.8231484383160974, \"p4\": 0.7834423814572735, \"phi\": 0.6836755070592195}, {\"truth_threshold\": 31.109321391687722, \"match_probability\": 0.9999999995683208, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3144.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3394.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.480881005525589, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5191190242767334, \"precision\": 1.0, \"recall\": 0.480881005525589, \"specificity\": 1.0, \"npv\": 0.9694545269012451, \"accuracy\": 0.9702950119972229, \"f1\": 0.6494525924395786, \"f2\": 0.536592026215183, \"f0_5\": 0.8224338181437689, \"p4\": 0.782621966225782, \"phi\": 0.6827827501991185}, {\"truth_threshold\": 31.12847924853699, \"match_probability\": 0.9999999995740153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3141.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3397.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48042213916778564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5195778608322144, \"precision\": 1.0, \"recall\": 0.48042213916778564, \"specificity\": 1.0, \"npv\": 0.9694283604621887, \"accuracy\": 0.9702687859535217, \"f1\": 0.6490339911147845, \"f2\": 0.5361349127777968, \"f0_5\": 0.8221652183017485, \"p4\": 0.7823136927964057, \"phi\": 0.6824476823273743}, {\"truth_threshold\": 31.129784865695175, \"match_probability\": 0.9999999995744006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3139.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3399.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.48011624813079834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5198837518692017, \"precision\": 1.0, \"recall\": 0.48011624813079834, \"specificity\": 1.0, \"npv\": 0.9694108963012695, \"accuracy\": 0.9702512621879578, \"f1\": 0.6487547793737729, \"f2\": 0.5358301184664231, \"f0_5\": 0.8219859641772285, \"p4\": 0.7821079895268753, \"phi\": 0.6822242654211578}, {\"truth_threshold\": 31.148489448288483, \"match_probability\": 0.999999999579883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3137.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3401.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47981032729148865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.520189642906189, \"precision\": 1.0, \"recall\": 0.47981032729148865, \"specificity\": 1.0, \"npv\": 0.9693934321403503, \"accuracy\": 0.9702337980270386, \"f1\": 0.6484754521963825, \"f2\": 0.5355252825292772, \"f0_5\": 0.8218065597820392, \"p4\": 0.7819021359374572, \"phi\": 0.6820007187875776}, {\"truth_threshold\": 31.15012977569788, \"match_probability\": 0.9999999995803603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3135.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3403.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47950443625450134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.520495593547821, \"precision\": 1.0, \"recall\": 0.47950443625450134, \"specificity\": 1.0, \"npv\": 0.9693760275840759, \"accuracy\": 0.9702162742614746, \"f1\": 0.64819600951101, \"f2\": 0.5352204049578311, \"f0_5\": 0.8216270049271412, \"p4\": 0.781696131856489, \"phi\": 0.6817771715110291}, {\"truth_threshold\": 31.150409171926825, \"match_probability\": 0.9999999995804416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3132.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3406.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.479045569896698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.520954430103302, \"precision\": 1.0, \"recall\": 0.479045569896698, \"specificity\": 1.0, \"npv\": 0.9693498015403748, \"accuracy\": 0.9701899886131287, \"f1\": 0.6477766287487073, \"f2\": 0.5347630105176888, \"f0_5\": 0.8213573901185356, \"p4\": 0.7813868431872253, \"phi\": 0.6814416635564177}, {\"truth_threshold\": 31.1539184473997, \"match_probability\": 0.9999999995814609, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3131.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3407.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47889262437820435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5211073756217957, \"precision\": 1.0, \"recall\": 0.47889262437820435, \"specificity\": 1.0, \"npv\": 0.9693410992622375, \"accuracy\": 0.9701812863349915, \"f1\": 0.6476367773296101, \"f2\": 0.5346105248779155, \"f0_5\": 0.8212674430804743, \"p4\": 0.7812836715319451, \"phi\": 0.6813298164326013}, {\"truth_threshold\": 31.16282827987208, \"match_probability\": 0.9999999995840377, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3130.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3408.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4787396788597107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5212603211402893, \"precision\": 1.0, \"recall\": 0.4787396788597107, \"specificity\": 1.0, \"npv\": 0.9693323969841003, \"accuracy\": 0.9701725244522095, \"f1\": 0.6474968969797269, \"f2\": 0.5344580288231678, \"f0_5\": 0.8211774582852346, \"p4\": 0.7811804621246423, \"phi\": 0.6812179529583992}, {\"truth_threshold\": 31.17375059607682, \"match_probability\": 0.999999999587175, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3129.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3409.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47858673334121704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.521413266658783, \"precision\": 1.0, \"recall\": 0.47858673334121704, \"specificity\": 1.0, \"npv\": 0.9693236351013184, \"accuracy\": 0.9701637625694275, \"f1\": 0.6473569876900797, \"f2\": 0.5343055223523787, \"f0_5\": 0.8210874357090375, \"p4\": 0.781077214943736, \"phi\": 0.6811060084610657}, {\"truth_threshold\": 31.175713001056742, \"match_probability\": 0.9999999995877361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47828081250190735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5217191576957703, \"precision\": 1.0, \"recall\": 0.47828081250190735, \"specificity\": 1.0, \"npv\": 0.969306230545044, \"accuracy\": 0.9701462388038635, \"f1\": 0.6470770822555613, \"f2\": 0.534000478158407, \"f0_5\": 0.820907277118555, \"p4\": 0.7808706071747088, \"phi\": 0.6808821996676125}, {\"truth_threshold\": 31.177635793948003, \"match_probability\": 0.9999999995882852, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3125.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3413.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47797492146492004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5220251083374023, \"precision\": 1.0, \"recall\": 0.47797492146492004, \"specificity\": 1.0, \"npv\": 0.9692887663841248, \"accuracy\": 0.9701287746429443, \"f1\": 0.646797060954155, \"f2\": 0.5336953922874611, \"f0_5\": 0.8207269671183948, \"p4\": 0.7806638480518895, \"phi\": 0.6806583253426677}, {\"truth_threshold\": 31.181155689228145, \"match_probability\": 0.9999999995892885, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3123.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3415.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47766900062561035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5223309993743896, \"precision\": 1.0, \"recall\": 0.47766900062561035, \"specificity\": 1.0, \"npv\": 0.9692713022232056, \"accuracy\": 0.9701112508773804, \"f1\": 0.6465169237139012, \"f2\": 0.5333902647309992, \"f0_5\": 0.8205465055176038, \"p4\": 0.7804569374020403, \"phi\": 0.6804343206961365}, {\"truth_threshold\": 31.187604481116544, \"match_probability\": 0.9999999995911203, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3122.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3416.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4775160551071167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5224839448928833, \"precision\": 1.0, \"recall\": 0.4775160551071167, \"specificity\": 1.0, \"npv\": 0.9692625999450684, \"accuracy\": 0.9701024889945984, \"f1\": 0.6463768115942029, \"f2\": 0.5332376853180296, \"f0_5\": 0.8204562178072112, \"p4\": 0.7803534252002704, \"phi\": 0.6803223261061784}, {\"truth_threshold\": 31.21444773093839, \"match_probability\": 0.9999999995986577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3119.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3419.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47705721855163574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5229427814483643, \"precision\": 1.0, \"recall\": 0.47705721855163574, \"specificity\": 1.0, \"npv\": 0.969236433506012, \"accuracy\": 0.9700762033462524, \"f1\": 0.6459563011287149, \"f2\": 0.5327798845273479, \"f0_5\": 0.8201851267487115, \"p4\": 0.7800426608269787, \"phi\": 0.6799861789965743}, {\"truth_threshold\": 31.21560364414702, \"match_probability\": 0.9999999995989791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3118.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3420.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4769042432308197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5230957269668579, \"precision\": 1.0, \"recall\": 0.4769042432308197, \"specificity\": 1.0, \"npv\": 0.9692277312278748, \"accuracy\": 0.9700675010681152, \"f1\": 0.6458160729080364, \"f2\": 0.5326272634096344, \"f0_5\": 0.8200946870068385, \"p4\": 0.7799389967074019, \"phi\": 0.6798741186529842}, {\"truth_threshold\": 31.218993689203046, \"match_probability\": 0.9999999995999204, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3115.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3423.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47644540667533875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5235546231269836, \"precision\": 1.0, \"recall\": 0.47644540667533875, \"specificity\": 1.0, \"npv\": 0.9692015647888184, \"accuracy\": 0.9700412154197693, \"f1\": 0.6453952139231327, \"f2\": 0.532169337479072, \"f0_5\": 0.8198231392778187, \"p4\": 0.7796277760583266, \"phi\": 0.6795377740456474}, {\"truth_threshold\": 31.227774919592076, \"match_probability\": 0.9999999996023481, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3110.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3428.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4756806492805481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5243193507194519, \"precision\": 1.0, \"recall\": 0.4756806492805481, \"specificity\": 1.0, \"npv\": 0.9691579341888428, \"accuracy\": 0.9699974656105042, \"f1\": 0.6446932006633499, \"f2\": 0.5314059189392386, \"f0_5\": 0.8193697966065971, \"p4\": 0.7791083126989861, \"phi\": 0.6789769130739228}, {\"truth_threshold\": 31.232313866131065, \"match_probability\": 0.9999999996035972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3108.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3430.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4753747284412384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5246252417564392, \"precision\": 1.0, \"recall\": 0.4753747284412384, \"specificity\": 1.0, \"npv\": 0.9691405296325684, \"accuracy\": 0.9699799418449402, \"f1\": 0.6444121915820029, \"f2\": 0.5311004784688995, \"f0_5\": 0.8191881918819188, \"p4\": 0.7789002600476957, \"phi\": 0.6787524790104239}, {\"truth_threshold\": 31.24083529934015, \"match_probability\": 0.9999999996059317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3103.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3435.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47460997104644775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5253900289535522, \"precision\": 1.0, \"recall\": 0.47460997104644775, \"specificity\": 1.0, \"npv\": 0.9690968990325928, \"accuracy\": 0.969936192035675, \"f1\": 0.6437091588009543, \"f2\": 0.5303366945821227, \"f0_5\": 0.8187335092348285, \"p4\": 0.7783794586149535, \"phi\": 0.6781910393539246}, {\"truth_threshold\": 31.245566404967168, \"match_probability\": 0.9999999996072219, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3100.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3438.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4741511046886444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5258488655090332, \"precision\": 1.0, \"recall\": 0.4741511046886444, \"specificity\": 1.0, \"npv\": 0.9690707921981812, \"accuracy\": 0.9699099659919739, \"f1\": 0.6432869890018676, \"f2\": 0.529878298919732, \"f0_5\": 0.8184602386735663, \"p4\": 0.7780665175807584, \"phi\": 0.6778539506343896}, {\"truth_threshold\": 31.249337273126756, \"match_probability\": 0.9999999996082471, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3097.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3441.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47369226813316345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5263077616691589, \"precision\": 1.0, \"recall\": 0.47369226813316345, \"specificity\": 1.0, \"npv\": 0.9690446257591248, \"accuracy\": 0.9698836803436279, \"f1\": 0.6428645563051375, \"f2\": 0.529419809224247, \"f0_5\": 0.8181866215787805, \"p4\": 0.7777532306878228, \"phi\": 0.6775167124095838}, {\"truth_threshold\": 31.252139058890652, \"match_probability\": 0.9999999996090072, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3096.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3442.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4735393226146698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5264607071876526, \"precision\": 1.0, \"recall\": 0.4735393226146698, \"specificity\": 1.0, \"npv\": 0.9690359234809875, \"accuracy\": 0.969874918460846, \"f1\": 0.6427236869420802, \"f2\": 0.5292669584245077, \"f0_5\": 0.8180953387591163, \"p4\": 0.7776487247628511, \"phi\": 0.6774042880719763}, {\"truth_threshold\": 31.254070849212205, \"match_probability\": 0.9999999996095305, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3095.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3443.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47338634729385376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5266136527061462, \"precision\": 1.0, \"recall\": 0.47338634729385376, \"specificity\": 1.0, \"npv\": 0.9690271615982056, \"accuracy\": 0.969866156578064, \"f1\": 0.6425827883317762, \"f2\": 0.5291140971723596, \"f0_5\": 0.818004017337985, \"p4\": 0.7775441803206495, \"phi\": 0.6772918470961586}, {\"truth_threshold\": 31.260968098314297, \"match_probability\": 0.9999999996113927, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3092.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3446.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4729275107383728, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5270724892616272, \"precision\": 1.0, \"recall\": 0.4729275107383728, \"specificity\": 1.0, \"npv\": 0.969001054763794, \"accuracy\": 0.9698399305343628, \"f1\": 0.6421599169262721, \"f2\": 0.5286554506907399, \"f0_5\": 0.8177298212207764, \"p4\": 0.7772303156689258, \"phi\": 0.6769543592164265}, {\"truth_threshold\": 31.26127897946102, \"match_probability\": 0.9999999996114765, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3091.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3447.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47277453541755676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5272254347801208, \"precision\": 1.0, \"recall\": 0.47277453541755676, \"specificity\": 1.0, \"npv\": 0.968992292881012, \"accuracy\": 0.9698311686515808, \"f1\": 0.64201890123585, \"f2\": 0.5285025476182335, \"f0_5\": 0.8176383451486615, \"p4\": 0.7771256169359797, \"phi\": 0.6768418515940474}, {\"truth_threshold\": 31.266897595926345, \"match_probability\": 0.9999999996129867, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3090.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3448.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4726215898990631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5273783802986145, \"precision\": 1.0, \"recall\": 0.4726215898990631, \"specificity\": 1.0, \"npv\": 0.9689835906028748, \"accuracy\": 0.9698224067687988, \"f1\": 0.6418778562525966, \"f2\": 0.5283496340879557, \"f0_5\": 0.8175468303524183, \"p4\": 0.7770208795748063, \"phi\": 0.6767293272916723}, {\"truth_threshold\": 31.270372661541305, \"match_probability\": 0.9999999996139177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3088.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3450.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4723156988620758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5276843309402466, \"precision\": 1.0, \"recall\": 0.4723156988620758, \"specificity\": 1.0, \"npv\": 0.9689661860466003, \"accuracy\": 0.9698049426078796, \"f1\": 0.6415956783710783, \"f2\": 0.5280437756497948, \"f0_5\": 0.8173636844891476, \"p4\": 0.7768112888787575, \"phi\": 0.6765042286134217}, {\"truth_threshold\": 31.286601721649568, \"match_probability\": 0.9999999996182365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3087.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3451.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47216275334358215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5278372764587402, \"precision\": 1.0, \"recall\": 0.47216275334358215, \"specificity\": 1.0, \"npv\": 0.9689574241638184, \"accuracy\": 0.9697961807250977, \"f1\": 0.6414545454545455, \"f2\": 0.5278908307397654, \"f0_5\": 0.8172720533728688, \"p4\": 0.7767064354993295, \"phi\": 0.6763915891300272}, {\"truth_threshold\": 31.290208966350892, \"match_probability\": 0.9999999996191898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3086.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3452.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4720097780227661, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5279902219772339, \"precision\": 1.0, \"recall\": 0.4720097780227661, \"specificity\": 1.0, \"npv\": 0.9689487218856812, \"accuracy\": 0.9697874188423157, \"f1\": 0.6413133832086451, \"f2\": 0.5277378753676722, \"f0_5\": 0.8171803834339583, \"p4\": 0.776601543402569, \"phi\": 0.6762789980135829}, {\"truth_threshold\": 31.290223993533814, \"match_probability\": 0.9999999996191938, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3085.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47185683250427246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5281431674957275, \"precision\": 1.0, \"recall\": 0.47185683250427246, \"specificity\": 1.0, \"npv\": 0.968940019607544, \"accuracy\": 0.9697786569595337, \"f1\": 0.6411721916242336, \"f2\": 0.5275849095324417, \"f0_5\": 0.8170886746477382, \"p4\": 0.776496612566157, \"phi\": 0.676166390175187}, {\"truth_threshold\": 31.292398967871303, \"match_probability\": 0.9999999996197675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3083.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3455.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47155094146728516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5284490585327148, \"precision\": 1.0, \"recall\": 0.47155094146728516, \"specificity\": 1.0, \"npv\": 0.9689226150512695, \"accuracy\": 0.9697611331939697, \"f1\": 0.6408897204032845, \"f2\": 0.5272789464682743, \"f0_5\": 0.8169051404345522, \"p4\": 0.776286634585016, \"phi\": 0.6759410591671053}, {\"truth_threshold\": 31.29343938337884, \"match_probability\": 0.9999999996200416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3082.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3456.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4713979661464691, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5286020040512085, \"precision\": 1.0, \"recall\": 0.4713979661464691, \"specificity\": 1.0, \"npv\": 0.9689138531684875, \"accuracy\": 0.9697523713111877, \"f1\": 0.6407484407484407, \"f2\": 0.5271259492371896, \"f0_5\": 0.8168133149581257, \"p4\": 0.7761815873955632, \"phi\": 0.6758284011020907}, {\"truth_threshold\": 31.299941148937112, \"match_probability\": 0.9999999996217501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3078.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3460.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4707861840724945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5292138457298279, \"precision\": 1.0, \"recall\": 0.4707861840724945, \"specificity\": 1.0, \"npv\": 0.9688790440559387, \"accuracy\": 0.9697173833847046, \"f1\": 0.6401830282861897, \"f2\": 0.5265138556277796, \"f0_5\": 0.8164456233421751, \"p4\": 0.7757610101226212, \"phi\": 0.6753775360180153}, {\"truth_threshold\": 31.304083346716208, \"match_probability\": 0.9999999996228345, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3076.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3462.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4704802632331848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5295197367668152, \"precision\": 1.0, \"recall\": 0.4704802632331848, \"specificity\": 1.0, \"npv\": 0.9688615798950195, \"accuracy\": 0.9696998596191406, \"f1\": 0.6399001456209694, \"f2\": 0.5262077459969892, \"f0_5\": 0.8162615433605774, \"p4\": 0.77555048806298, \"phi\": 0.6751520353441841}, {\"truth_threshold\": 31.308068454198107, \"match_probability\": 0.9999999996238749, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3075.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3463.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.47032731771469116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5296726822853088, \"precision\": 1.0, \"recall\": 0.47032731771469116, \"specificity\": 1.0, \"npv\": 0.9688528776168823, \"accuracy\": 0.9696911573410034, \"f1\": 0.6397586601477167, \"f2\": 0.5260546754713108, \"f0_5\": 0.8161694447393566, \"p4\": 0.7754451685987229, \"phi\": 0.6750392598019394}, {\"truth_threshold\": 31.310436774578594, \"match_probability\": 0.9999999996244918, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3074.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3464.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4701743721961975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5298256278038025, \"precision\": 1.0, \"recall\": 0.4701743721961975, \"specificity\": 1.0, \"npv\": 0.9688441753387451, \"accuracy\": 0.9696823954582214, \"f1\": 0.6396171452351228, \"f2\": 0.5259015944706767, \"f0_5\": 0.8160773069979824, \"p4\": 0.7753398101481692, \"phi\": 0.6749264022204162}, {\"truth_threshold\": 31.318977693670195, \"match_probability\": 0.9999999996267084, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3072.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3466.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4698684513568878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5301315188407898, \"precision\": 1.0, \"recall\": 0.4698684513568878, \"specificity\": 1.0, \"npv\": 0.9688267111778259, \"accuracy\": 0.9696648716926575, \"f1\": 0.6393340270551509, \"f2\": 0.5255954010402409, \"f0_5\": 0.8158929140550303, \"p4\": 0.775128976198051, \"phi\": 0.6747007670070503}, {\"truth_threshold\": 31.3204133440409, \"match_probability\": 0.9999999996270796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3070.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4695625603199005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5304374694824219, \"precision\": 1.0, \"recall\": 0.4695625603199005, \"specificity\": 1.0, \"npv\": 0.9688093066215515, \"accuracy\": 0.9696473479270935, \"f1\": 0.6390507910074937, \"f2\": 0.5252891656970775, \"f0_5\": 0.8157083643320225, \"p4\": 0.7749179860322096, \"phi\": 0.6744750644323116}, {\"truth_threshold\": 31.3235797107016, \"match_probability\": 0.9999999996278972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3068.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3470.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4692566394805908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5307433605194092, \"precision\": 1.0, \"recall\": 0.4692566394805908, \"specificity\": 1.0, \"npv\": 0.9687919020652771, \"accuracy\": 0.9696298837661743, \"f1\": 0.6387674370185301, \"f2\": 0.5249828884325805, \"f0_5\": 0.8155236576289208, \"p4\": 0.7747068394699516, \"phi\": 0.6742492291417069}, {\"truth_threshold\": 31.334627203260602, \"match_probability\": 0.9999999996307357, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3067.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3471.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46910369396209717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5308963060379028, \"precision\": 1.0, \"recall\": 0.46910369396209717, \"specificity\": 1.0, \"npv\": 0.9687831401824951, \"accuracy\": 0.9696211218833923, \"f1\": 0.6386257157730348, \"f2\": 0.5248297340771416, \"f0_5\": 0.8154312453472297, \"p4\": 0.7746012074836233, \"phi\": 0.6741363188219058}, {\"truth_threshold\": 31.336394646636663, \"match_probability\": 0.9999999996311878, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3066.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3472.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4689507484436035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5310492515563965, \"precision\": 1.0, \"recall\": 0.4689507484436035, \"specificity\": 1.0, \"npv\": 0.9687744379043579, \"accuracy\": 0.9696123600006104, \"f1\": 0.6384839650145773, \"f2\": 0.5246765692381409, \"f0_5\": 0.8153387937453462, \"p4\": 0.7744955363303043, \"phi\": 0.6740233916191525}, {\"truth_threshold\": 31.337486857399842, \"match_probability\": 0.9999999996314669, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3064.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3474.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4686448574066162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5313551425933838, \"precision\": 1.0, \"recall\": 0.4686448574066162, \"specificity\": 1.0, \"npv\": 0.9687570333480835, \"accuracy\": 0.9695948362350464, \"f1\": 0.6382003749218913, \"f2\": 0.5243702081051479, \"f0_5\": 0.8151537724805789, \"p4\": 0.7742840764320168, \"phi\": 0.6737974212027803}, {\"truth_threshold\": 31.35176363686753, \"match_probability\": 0.9999999996350959, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3062.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3476.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4683389365673065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5316610336303711, \"precision\": 1.0, \"recall\": 0.4683389365673065, \"specificity\": 1.0, \"npv\": 0.9687396287918091, \"accuracy\": 0.9695773720741272, \"f1\": 0.6379166666666667, \"f2\": 0.5240638050249881, \"f0_5\": 0.8149685936335569, \"p4\": 0.7740724595935576, \"phi\": 0.673571448459094}, {\"truth_threshold\": 31.360793729682584, \"match_probability\": 0.9999999996373727, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3057.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3481.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46757417917251587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5324258208274841, \"precision\": 1.0, \"recall\": 0.46757417917251587, \"specificity\": 1.0, \"npv\": 0.9686960577964783, \"accuracy\": 0.9695336222648621, \"f1\": 0.6372068785825951, \"f2\": 0.5232976137491869, \"f0_5\": 0.8145049557710754, \"p4\": 0.7735427296903316, \"phi\": 0.6730061548487215}, {\"truth_threshold\": 31.36255488774698, \"match_probability\": 0.9999999996378152, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3055.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3483.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46726828813552856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5327317118644714, \"precision\": 1.0, \"recall\": 0.46726828813552856, \"specificity\": 1.0, \"npv\": 0.9686785936355591, \"accuracy\": 0.9695160984992981, \"f1\": 0.6369227561763786, \"f2\": 0.5229910637860786, \"f0_5\": 0.8143192237978463, \"p4\": 0.773330562127664, \"phi\": 0.6727798794019572}, {\"truth_threshold\": 31.367606737592073, \"match_probability\": 0.9999999996390813, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3054.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3484.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4671153128147125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5328846573829651, \"precision\": 1.0, \"recall\": 0.4671153128147125, \"specificity\": 1.0, \"npv\": 0.9686698913574219, \"accuracy\": 0.9695073366165161, \"f1\": 0.6367806505421184, \"f2\": 0.5228377730603301, \"f0_5\": 0.8142262983896769, \"p4\": 0.7732244191975648, \"phi\": 0.6726667489042449}, {\"truth_threshold\": 31.370379315034878, \"match_probability\": 0.9999999996397742, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3051.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3487.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46665647625923157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5333435535430908, \"precision\": 1.0, \"recall\": 0.46665647625923157, \"specificity\": 1.0, \"npv\": 0.9686437845230103, \"accuracy\": 0.9694811105728149, \"f1\": 0.6363541558035248, \"f2\": 0.5223778378933671, \"f0_5\": 0.8139472841745812, \"p4\": 0.772905753537639, \"phi\": 0.6723271899461563}, {\"truth_threshold\": 31.37170242602705, \"match_probability\": 0.9999999996401043, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3050.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3488.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4665035307407379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5334964990615845, \"precision\": 1.0, \"recall\": 0.4665035307407379, \"specificity\": 1.0, \"npv\": 0.968635082244873, \"accuracy\": 0.969472348690033, \"f1\": 0.6362119315811431, \"f2\": 0.5222245051708787, \"f0_5\": 0.813854200021347, \"p4\": 0.7727994526180831, \"phi\": 0.6722139914079287}, {\"truth_threshold\": 31.383710657805942, \"match_probability\": 0.9999999996430875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3049.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3489.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4663505554199219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5336494445800781, \"precision\": 1.0, \"recall\": 0.4663505554199219, \"specificity\": 1.0, \"npv\": 0.9686263799667358, \"accuracy\": 0.969463586807251, \"f1\": 0.6360696776885365, \"f2\": 0.5220711619465087, \"f0_5\": 0.8137610761182876, \"p4\": 0.7726931121438403, \"phi\": 0.6721007758405564}, {\"truth_threshold\": 31.38975966708473, \"match_probability\": 0.9999999996445809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3048.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3490.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4661976099014282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5338023900985718, \"precision\": 1.0, \"recall\": 0.4661976099014282, \"specificity\": 1.0, \"npv\": 0.9686176180839539, \"accuracy\": 0.969454824924469, \"f1\": 0.6359273941164197, \"f2\": 0.5219178082191781, \"f0_5\": 0.813667912439936, \"p4\": 0.7725867320919457, \"phi\": 0.6719875432353776}, {\"truth_threshold\": 31.393861179596552, \"match_probability\": 0.9999999996455899, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3046.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3492.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4658917188644409, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5341082811355591, \"precision\": 1.0, \"recall\": 0.4658917188644409, \"specificity\": 1.0, \"npv\": 0.9686002135276794, \"accuracy\": 0.969437301158905, \"f1\": 0.6356427378964942, \"f2\": 0.5216110692513186, \"f0_5\": 0.8134814656553787, \"p4\": 0.7723738531632545, \"phi\": 0.671760961361645}, {\"truth_threshold\": 31.398828008882706, \"match_probability\": 0.999999999646808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3045.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3493.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4657387435436249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5342612266540527, \"precision\": 1.0, \"recall\": 0.4657387435436249, \"specificity\": 1.0, \"npv\": 0.9685915112495422, \"accuracy\": 0.969428539276123, \"f1\": 0.635500365230095, \"f2\": 0.521457684008631, \"f0_5\": 0.8133881824981302, \"p4\": 0.7722673542404395, \"phi\": 0.67164767758054}, {\"truth_threshold\": 31.404059303197744, \"match_probability\": 0.9999999996480863, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3044.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3494.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4655857980251312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5344141721725464, \"precision\": 1.0, \"recall\": 0.4655857980251312, \"specificity\": 1.0, \"npv\": 0.968582808971405, \"accuracy\": 0.9694198369979858, \"f1\": 0.6353579628470049, \"f2\": 0.5213042882586656, \"f0_5\": 0.8132948594635032, \"p4\": 0.7721608156479366, \"phi\": 0.6715343767269034}, {\"truth_threshold\": 31.404505098939506, \"match_probability\": 0.9999999996481951, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3043.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4654328525066376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.53456711769104, \"precision\": 1.0, \"recall\": 0.4654328525066376, \"specificity\": 1.0, \"npv\": 0.9685741066932678, \"accuracy\": 0.9694110751152039, \"f1\": 0.6352155307379188, \"f2\": 0.5211508820003425, \"f0_5\": 0.813201496525922, \"p4\": 0.7720542373626921, \"phi\": 0.6714210587920374}, {\"truth_threshold\": 31.407658090328283, \"match_probability\": 0.999999999648963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3042.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3496.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4652799069881439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5347201228141785, \"precision\": 1.0, \"recall\": 0.4652799069881439, \"specificity\": 1.0, \"npv\": 0.9685654044151306, \"accuracy\": 0.9694023132324219, \"f1\": 0.6350730688935282, \"f2\": 0.5209974652325821, \"f0_5\": 0.8131080936597883, \"p4\": 0.7719476193616345, \"phi\": 0.6713076582100853}, {\"truth_threshold\": 31.40787618529124, \"match_probability\": 0.9999999996490161, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3041.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3497.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46512696146965027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5348730683326721, \"precision\": 1.0, \"recall\": 0.46512696146965027, \"specificity\": 1.0, \"npv\": 0.9685567021369934, \"accuracy\": 0.9693935513496399, \"f1\": 0.6349305773045203, \"f2\": 0.5208440379543041, \"f0_5\": 0.8130146508394824, \"p4\": 0.7718409616216744, \"phi\": 0.671194306076155}, {\"truth_threshold\": 31.413164181531673, \"match_probability\": 0.9999999996503003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3039.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3499.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4648210406303406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5351789593696594, \"precision\": 1.0, \"recall\": 0.4648210406303406, \"specificity\": 1.0, \"npv\": 0.9685392379760742, \"accuracy\": 0.9693760275840759, \"f1\": 0.6346455048553827, \"f2\": 0.5205371518618752, \"f0_5\": 0.8128276452337648, \"p4\": 0.7716275268325997, \"phi\": 0.670967550477454}, {\"truth_threshold\": 31.41328207290607, \"match_probability\": 0.9999999996503288, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3037.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3501.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46451514959335327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5354848504066467, \"precision\": 1.0, \"recall\": 0.46451514959335327, \"specificity\": 1.0, \"npv\": 0.9685218334197998, \"accuracy\": 0.9693585634231567, \"f1\": 0.6343603133159269, \"f2\": 0.520230223714413, \"f0_5\": 0.8126404795033715, \"p4\": 0.7714139328103952, \"phi\": 0.6707406607697995}, {\"truth_threshold\": 31.419595804742215, \"match_probability\": 0.9999999996518557, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3035.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3503.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4642092287540436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.535790741443634, \"precision\": 1.0, \"recall\": 0.4642092287540436, \"specificity\": 1.0, \"npv\": 0.9685044288635254, \"accuracy\": 0.9693410396575928, \"f1\": 0.6340750026115115, \"f2\": 0.519923253503272, \"f0_5\": 0.8124531534425528, \"p4\": 0.7712001793697006, \"phi\": 0.6705137680814501}, {\"truth_threshold\": 31.431579842779353, \"match_probability\": 0.9999999996547357, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3033.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3505.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4639033377170563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5360966920852661, \"precision\": 1.0, \"recall\": 0.4639033377170563, \"specificity\": 1.0, \"npv\": 0.968487024307251, \"accuracy\": 0.9693235158920288, \"f1\": 0.6337895726674329, \"f2\": 0.5196162412198047, \"f0_5\": 0.8122656668452062, \"p4\": 0.7709862663248682, \"phi\": 0.6702867411020274}, {\"truth_threshold\": 31.43765435718904, \"match_probability\": 0.9999999996561864, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3030.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3508.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46344447135925293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5365555286407471, \"precision\": 1.0, \"recall\": 0.46344447135925293, \"specificity\": 1.0, \"npv\": 0.9684609174728394, \"accuracy\": 0.9692972898483276, \"f1\": 0.6333612040133779, \"f2\": 0.5191556438900692, \"f0_5\": 0.8119841354914782, \"p4\": 0.7706650970930474, \"phi\": 0.6699461702264043}, {\"truth_threshold\": 31.43823216762333, \"match_probability\": 0.999999999656324, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3028.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3510.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4631385803222656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5368614196777344, \"precision\": 1.0, \"recall\": 0.4631385803222656, \"specificity\": 1.0, \"npv\": 0.9684434533119202, \"accuracy\": 0.9692797660827637, \"f1\": 0.6330754756429019, \"f2\": 0.518848526387937, \"f0_5\": 0.8117962466487936, \"p4\": 0.7704507842237689, \"phi\": 0.6697189712673881}, {\"truth_threshold\": 31.43946999338005, \"match_probability\": 0.9999999996566188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3025.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3513.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4626797139644623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5373202562332153, \"precision\": 1.0, \"recall\": 0.4626797139644623, \"specificity\": 1.0, \"npv\": 0.9684173464775085, \"accuracy\": 0.9692535400390625, \"f1\": 0.6326466589982224, \"f2\": 0.5183877711896356, \"f0_5\": 0.8115141109561111, \"p4\": 0.7701290143811069, \"phi\": 0.6693781421712574}, {\"truth_threshold\": 31.442227086978864, \"match_probability\": 0.9999999996572744, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3023.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3515.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.462373822927475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5376262068748474, \"precision\": 1.0, \"recall\": 0.462373822927475, \"specificity\": 1.0, \"npv\": 0.9683999419212341, \"accuracy\": 0.9692360162734985, \"f1\": 0.6323606317330823, \"f2\": 0.5180805484147386, \"f0_5\": 0.8113258185721954, \"p4\": 0.7699143005207628, \"phi\": 0.6691507707919098}, {\"truth_threshold\": 31.459542673868743, \"match_probability\": 0.9999999996613633, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3022.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3516.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4622208774089813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5377791523933411, \"precision\": 1.0, \"recall\": 0.4622208774089813, \"specificity\": 1.0, \"npv\": 0.9683912396430969, \"accuracy\": 0.9692272543907166, \"f1\": 0.6322175732217573, \"f2\": 0.5179269212312333, \"f0_5\": 0.8112316117255449, \"p4\": 0.7698068833307777, \"phi\": 0.6690370920763302}, {\"truth_threshold\": 31.461327186173406, \"match_probability\": 0.9999999996617819, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3020.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3518.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46191495656967163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5380850434303284, \"precision\": 1.0, \"recall\": 0.46191495656967163, \"specificity\": 1.0, \"npv\": 0.9683738350868225, \"accuracy\": 0.9692097902297974, \"f1\": 0.6319313663946432, \"f2\": 0.5176196352666941, \"f0_5\": 0.8110430765925448, \"p4\": 0.7695919283139291, \"phi\": 0.6688096828129914}, {\"truth_threshold\": 31.467528525341724, \"match_probability\": 0.9999999996632326, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3018.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3520.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4616090655326843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5383909344673157, \"precision\": 1.0, \"recall\": 0.4616090655326843, \"specificity\": 1.0, \"npv\": 0.9683564305305481, \"accuracy\": 0.9691922664642334, \"f1\": 0.6316450397655923, \"f2\": 0.5173123071648954, \"f0_5\": 0.8108543793659323, \"p4\": 0.7693768122913596, \"phi\": 0.6685821385707433}, {\"truth_threshold\": 31.468533126391353, \"match_probability\": 0.9999999996634671, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3016.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3522.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46130314469337463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.538696825504303, \"precision\": 1.0, \"recall\": 0.46130314469337463, \"specificity\": 1.0, \"npv\": 0.9683390259742737, \"accuracy\": 0.9691747426986694, \"f1\": 0.6313585932593678, \"f2\": 0.5170049369171695, \"f0_5\": 0.8106655198365768, \"p4\": 0.769161535074954, \"phi\": 0.668354590877693}, {\"truth_threshold\": 31.478638049980816, \"match_probability\": 0.999999999665816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3013.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3525.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4608443081378937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5391557216644287, \"precision\": 1.0, \"recall\": 0.4608443081378937, \"specificity\": 1.0, \"npv\": 0.9683129191398621, \"accuracy\": 0.9691485166549683, \"f1\": 0.6309286985655952, \"f2\": 0.5165438025030001, \"f0_5\": 0.8103819257665411, \"p4\": 0.7688383165996795, \"phi\": 0.6680130734944429}, {\"truth_threshold\": 31.479313686588043, \"match_probability\": 0.9999999996659724, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3009.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3529.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4602324962615967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5397675037384033, \"precision\": 1.0, \"recall\": 0.4602324962615967, \"specificity\": 1.0, \"npv\": 0.9682781100273132, \"accuracy\": 0.9691134691238403, \"f1\": 0.630355085367131, \"f2\": 0.5159288090257536, \"f0_5\": 0.8100032303219554, \"p4\": 0.76840679269328, \"phi\": 0.6675574958480318}, {\"truth_threshold\": 31.479462682778856, \"match_probability\": 0.999999999666007, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3008.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3530.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.46007952094078064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.539920449256897, \"precision\": 1.0, \"recall\": 0.46007952094078064, \"specificity\": 1.0, \"npv\": 0.9682693481445312, \"accuracy\": 0.9691047668457031, \"f1\": 0.630211606955793, \"f2\": 0.5157750342935528, \"f0_5\": 0.8099084544964997, \"p4\": 0.7682988104983981, \"phi\": 0.6674435744489396}, {\"truth_threshold\": 31.486324611766445, \"match_probability\": 0.9999999996675917, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3007.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3531.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.459926575422287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5400733947753906, \"precision\": 1.0, \"recall\": 0.459926575422287, \"specificity\": 1.0, \"npv\": 0.968260645866394, \"accuracy\": 0.9690960049629211, \"f1\": 0.6300680984808801, \"f2\": 0.5156212490140265, \"f0_5\": 0.8098136378325972, \"p4\": 0.7681907877688161, \"phi\": 0.6673296356506098}, {\"truth_threshold\": 31.52134187829354, \"match_probability\": 0.9999999996755629, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3006.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3532.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45977362990379333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5402263402938843, \"precision\": 1.0, \"recall\": 0.45977362990379333, \"specificity\": 1.0, \"npv\": 0.9682519435882568, \"accuracy\": 0.9690872430801392, \"f1\": 0.6299245599329422, \"f2\": 0.5154674531860896, \"f0_5\": 0.8097187803038466, \"p4\": 0.7680827244808082, \"phi\": 0.6672156794440733}, {\"truth_threshold\": 31.537531739034385, \"match_probability\": 0.9999999996791833, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3005.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3533.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4596206843852997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5403793454170227, \"precision\": 1.0, \"recall\": 0.4596206843852997, \"specificity\": 1.0, \"npv\": 0.9682432413101196, \"accuracy\": 0.9690784811973572, \"f1\": 0.6297809913025254, \"f2\": 0.5153136468086565, \"f0_5\": 0.8096238818838237, \"p4\": 0.7679746206106296, \"phi\": 0.6671016398718098}, {\"truth_threshold\": 31.53756277200049, \"match_probability\": 0.9999999996791902, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3003.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3535.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45931476354599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.54068523645401, \"precision\": 1.0, \"recall\": 0.45931476354599, \"specificity\": 1.0, \"npv\": 0.9682258367538452, \"accuracy\": 0.9690609574317932, \"f1\": 0.6294937637564196, \"f2\": 0.5150060024009604, \"f0_5\": 0.809433962264151, \"p4\": 0.7677582910286904, \"phi\": 0.6668736403155147}, {\"truth_threshold\": 31.576469924042225, \"match_probability\": 0.9999999996877263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3001.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3537.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4590088725090027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5409911274909973, \"precision\": 1.0, \"recall\": 0.4590088725090027, \"specificity\": 1.0, \"npv\": 0.9682084321975708, \"accuracy\": 0.969043493270874, \"f1\": 0.6292064157668519, \"f2\": 0.5146983157822522, \"f0_5\": 0.8092438787617301, \"p4\": 0.767541798832672, \"phi\": 0.6666455049912671}, {\"truth_threshold\": 31.57817372353173, \"match_probability\": 0.9999999996880948, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2999.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3539.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4587029814720154, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5412970185279846, \"precision\": 1.0, \"recall\": 0.4587029814720154, \"specificity\": 1.0, \"npv\": 0.9681910276412964, \"accuracy\": 0.9690259695053101, \"f1\": 0.6289189472580476, \"f2\": 0.5143905869438441, \"f0_5\": 0.8090536311643466, \"p4\": 0.7673251438319505, \"phi\": 0.6664173657881661}, {\"truth_threshold\": 31.585553253897327, \"match_probability\": 0.9999999996896862, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2997.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3541.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4583970606327057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5416029095649719, \"precision\": 1.0, \"recall\": 0.4583970606327057, \"specificity\": 1.0, \"npv\": 0.968173623085022, \"accuracy\": 0.9690084457397461, \"f1\": 0.6286313581541688, \"f2\": 0.5140828158770455, \"f0_5\": 0.8088632192594192, \"p4\": 0.7671083258356038, \"phi\": 0.6661891566641012}, {\"truth_threshold\": 31.58684632633656, \"match_probability\": 0.9999999996899642, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2995.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3543.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4580911695957184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.541908860206604, \"precision\": 1.0, \"recall\": 0.4580911695957184, \"specificity\": 1.0, \"npv\": 0.9681562185287476, \"accuracy\": 0.9689909815788269, \"f1\": 0.628343648379314, \"f2\": 0.5137750025731637, \"f0_5\": 0.8086726428339993, \"p4\": 0.7668913446524119, \"phi\": 0.665960811491167}, {\"truth_threshold\": 31.592771736371326, \"match_probability\": 0.999999999691235, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2993.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3545.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4577852487564087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5422147512435913, \"precision\": 1.0, \"recall\": 0.4577852487564087, \"specificity\": 1.0, \"npv\": 0.9681388139724731, \"accuracy\": 0.9689734578132629, \"f1\": 0.6280558178575176, \"f2\": 0.5134671470235032, \"f0_5\": 0.8084819016747704, \"p4\": 0.7666742000908553, \"phi\": 0.6657324622866095}, {\"truth_threshold\": 31.608891401734603, \"match_probability\": 0.9999999996946657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2992.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3546.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45763230323791504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.542367696762085, \"precision\": 1.0, \"recall\": 0.45763230323791504, \"specificity\": 1.0, \"npv\": 0.9681301116943359, \"accuracy\": 0.968964695930481, \"f1\": 0.6279118572927597, \"f2\": 0.513313203403788, \"f0_5\": 0.8083864692532152, \"p4\": 0.7665655664832586, \"phi\": 0.6656181952992025}, {\"truth_threshold\": 31.62116190556611, \"match_probability\": 0.9999999996972516, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2991.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3547.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4574793577194214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5425206422805786, \"precision\": 1.0, \"recall\": 0.4574793577194214, \"specificity\": 1.0, \"npv\": 0.9681214094161987, \"accuracy\": 0.968955934047699, \"f1\": 0.6277678665127505, \"f2\": 0.5131592492193666, \"f0_5\": 0.8082909955680467, \"p4\": 0.766456891959115, \"phi\": 0.6655039768451836}, {\"truth_threshold\": 31.625536900894772, \"match_probability\": 0.9999999996981683, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2990.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3548.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45732641220092773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5426735877990723, \"precision\": 1.0, \"recall\": 0.45732641220092773, \"specificity\": 1.0, \"npv\": 0.9681127667427063, \"accuracy\": 0.968947172164917, \"f1\": 0.6276238455079765, \"f2\": 0.5130052844691511, \"f0_5\": 0.8081954805924965, \"p4\": 0.7663481764944006, \"phi\": 0.6653897408384091}, {\"truth_threshold\": 31.629926790149153, \"match_probability\": 0.9999999996990854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2987.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3551.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4568675458431244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.543132483959198, \"precision\": 1.0, \"recall\": 0.4568675458431244, \"specificity\": 1.0, \"npv\": 0.9680866599082947, \"accuracy\": 0.9689209461212158, \"f1\": 0.6271916010498688, \"f2\": 0.5125433268128625, \"f0_5\": 0.8079086876555232, \"p4\": 0.7660217842163062, \"phi\": 0.6650468612689369}, {\"truth_threshold\": 31.63716585572978, \"match_probability\": 0.9999999997005915, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2984.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3554.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45640867948532104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.543591320514679, \"precision\": 1.0, \"recall\": 0.45640867948532104, \"specificity\": 1.0, \"npv\": 0.9680605530738831, \"accuracy\": 0.9688946604728699, \"f1\": 0.6267590842260029, \"f2\": 0.5120812740252608, \"f0_5\": 0.8076215221392227, \"p4\": 0.7656950226063917, \"phi\": 0.6647038895059508}, {\"truth_threshold\": 31.642341438928263, \"match_probability\": 0.9999999997016638, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2982.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3556.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45610278844833374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5438972115516663, \"precision\": 1.0, \"recall\": 0.45610278844833374, \"specificity\": 1.0, \"npv\": 0.9680431485176086, \"accuracy\": 0.9688771963119507, \"f1\": 0.6264705882352941, \"f2\": 0.5117731859682845, \"f0_5\": 0.8074298711144806, \"p4\": 0.7654769760270022, \"phi\": 0.6644750874006243}, {\"truth_threshold\": 31.64293984732276, \"match_probability\": 0.9999999997017874, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2981.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3557.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4559498429298401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5440501570701599, \"precision\": 1.0, \"recall\": 0.4559498429298401, \"specificity\": 1.0, \"npv\": 0.9680344462394714, \"accuracy\": 0.9688684344291687, \"f1\": 0.6263262947788634, \"f2\": 0.5116191260769574, \"f0_5\": 0.8073339833170837, \"p4\": 0.7653678910129478, \"phi\": 0.6643606929871361}, {\"truth_threshold\": 31.647184082603694, \"match_probability\": 0.9999999997026634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2980.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3558.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45579686760902405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5442031025886536, \"precision\": 1.0, \"recall\": 0.45579686760902405, \"specificity\": 1.0, \"npv\": 0.9680257439613342, \"accuracy\": 0.9688596725463867, \"f1\": 0.6261819710023114, \"f2\": 0.5114650556089524, \"f0_5\": 0.8072380539603424, \"p4\": 0.7652587648170425, \"phi\": 0.6642462809295618}, {\"truth_threshold\": 31.650006468292798, \"match_probability\": 0.9999999997032446, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2979.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3559.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4556439220905304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5443560481071472, \"precision\": 1.0, \"recall\": 0.4556439220905304, \"specificity\": 1.0, \"npv\": 0.968017041683197, \"accuracy\": 0.9688509106636047, \"f1\": 0.6260376168960807, \"f2\": 0.5113109745631801, \"f0_5\": 0.807142083017232, \"p4\": 0.7651495974150542, \"phi\": 0.6641318512187272}, {\"truth_threshold\": 31.659885932229862, \"match_probability\": 0.9999999997052698, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2976.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3562.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45518508553504944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.544814944267273, \"precision\": 1.0, \"recall\": 0.45518508553504944, \"specificity\": 1.0, \"npv\": 0.9679909348487854, \"accuracy\": 0.9688246846199036, \"f1\": 0.6256043725036788, \"f2\": 0.5108486679483658, \"f0_5\": 0.806853920399089, \"p4\": 0.7648218477299853, \"phi\": 0.6637883898143523}, {\"truth_threshold\": 31.66060390424601, \"match_probability\": 0.9999999997054164, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2973.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3565.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4547262191772461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5452737808227539, \"precision\": 1.0, \"recall\": 0.4547262191772461, \"specificity\": 1.0, \"npv\": 0.9679648280143738, \"accuracy\": 0.9687983989715576, \"f1\": 0.6251708547997056, \"f2\": 0.5103862660944206, \"f0_5\": 0.8065653825284862, \"p4\": 0.7644937263159873, \"phi\": 0.6634447691345605}, {\"truth_threshold\": 31.665274466797634, \"match_probability\": 0.9999999997063685, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2972.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3566.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45457327365875244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5454267263412476, \"precision\": 1.0, \"recall\": 0.45457327365875244, \"specificity\": 1.0, \"npv\": 0.9679561257362366, \"accuracy\": 0.9687896370887756, \"f1\": 0.6250262881177707, \"f2\": 0.5102321109737673, \"f0_5\": 0.8064691197221318, \"p4\": 0.7643842697913206, \"phi\": 0.6633302155716665}, {\"truth_threshold\": 31.675739123944062, \"match_probability\": 0.9999999997084907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2970.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3568.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45426735281944275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5457326173782349, \"precision\": 1.0, \"recall\": 0.45426735281944275, \"specificity\": 1.0, \"npv\": 0.9679387807846069, \"accuracy\": 0.9687721729278564, \"f1\": 0.6247370635254522, \"f2\": 0.5099237689719113, \"f0_5\": 0.8062764686719514, \"p4\": 0.7641652325157068, \"phi\": 0.6631010552558011}, {\"truth_threshold\": 31.68382118128504, \"match_probability\": 0.9999999997101192, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2969.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3569.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4541144073009491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5458855628967285, \"precision\": 1.0, \"recall\": 0.4541144073009491, \"specificity\": 1.0, \"npv\": 0.9679300785064697, \"accuracy\": 0.9687634110450745, \"f1\": 0.6245924055958767, \"f2\": 0.5097695820885272, \"f0_5\": 0.8061800803736288, \"p4\": 0.764055651715933, \"phi\": 0.6629863821479035}, {\"truth_threshold\": 31.689534832479435, \"match_probability\": 0.999999999711265, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2967.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3571.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4538085162639618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5461915135383606, \"precision\": 1.0, \"recall\": 0.4538085162639618, \"specificity\": 1.0, \"npv\": 0.9679126739501953, \"accuracy\": 0.9687458872795105, \"f1\": 0.6243029984218832, \"f2\": 0.5094611765513926, \"f0_5\": 0.8059871780940997, \"p4\": 0.7638363656702406, \"phi\": 0.6627571153098418}, {\"truth_threshold\": 31.691988759869112, \"match_probability\": 0.9999999997117557, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2964.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3574.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45334964990615845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5466503500938416, \"precision\": 1.0, \"recall\": 0.45334964990615845, \"specificity\": 1.0, \"npv\": 0.9678865671157837, \"accuracy\": 0.9687196612358093, \"f1\": 0.6238686592296359, \"f2\": 0.508998488803407, \"f0_5\": 0.8056975100576275, \"p4\": 0.7635071251191308, \"phi\": 0.6624130153392872}, {\"truth_threshold\": 31.69966157148797, \"match_probability\": 0.9999999997132846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2963.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3575.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4531967043876648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5468032956123352, \"precision\": 1.0, \"recall\": 0.4531967043876648, \"specificity\": 1.0, \"npv\": 0.9678778648376465, \"accuracy\": 0.9687108993530273, \"f1\": 0.6237238185454163, \"f2\": 0.508844238365104, \"f0_5\": 0.8056008700380641, \"p4\": 0.7633972951086846, \"phi\": 0.6622983018786384}, {\"truth_threshold\": 31.70879553271081, \"match_probability\": 0.9999999997150941, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2961.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3577.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4528907835483551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5471091866493225, \"precision\": 1.0, \"recall\": 0.4528907835483551, \"specificity\": 1.0, \"npv\": 0.9678604602813721, \"accuracy\": 0.9686933755874634, \"f1\": 0.6234340456890199, \"f2\": 0.5085357056984852, \"f0_5\": 0.8054074638233054, \"p4\": 0.7631775102003606, \"phi\": 0.6620688215167208}, {\"truth_threshold\": 31.71230874424871, \"match_probability\": 0.999999999715787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2960.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3578.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45273783802986145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5472621321678162, \"precision\": 1.0, \"recall\": 0.45273783802986145, \"specificity\": 1.0, \"npv\": 0.9678517580032349, \"accuracy\": 0.9686846137046814, \"f1\": 0.6232891134975784, \"f2\": 0.5083814234679858, \"f0_5\": 0.8053106975731853, \"p4\": 0.7630675552533093, \"phi\": 0.6619540545968146}, {\"truth_threshold\": 31.715372808779946, \"match_probability\": 0.9999999997163901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2959.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3579.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4525848925113678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5474151372909546, \"precision\": 1.0, \"recall\": 0.4525848925113678, \"specificity\": 1.0, \"npv\": 0.9678431153297424, \"accuracy\": 0.9686758518218994, \"f1\": 0.6231441507844583, \"f2\": 0.5082271306379031, \"f0_5\": 0.8052138891912485, \"p4\": 0.7629575586115174, \"phi\": 0.6618392033930622}, {\"truth_threshold\": 31.720136401832153, \"match_probability\": 0.999999999717325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2956.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3582.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45212602615356445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5478739738464355, \"precision\": 1.0, \"recall\": 0.45212602615356445, \"specificity\": 1.0, \"npv\": 0.9678170084953308, \"accuracy\": 0.9686496257781982, \"f1\": 0.6227090794185801, \"f2\": 0.5077641885392332, \"f0_5\": 0.8049232109791962, \"p4\": 0.7626273182712489, \"phi\": 0.6614947419614777}, {\"truth_threshold\": 31.72547427385744, \"match_probability\": 0.999999999718369, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2955.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3583.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4519730806350708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5480269193649292, \"precision\": 1.0, \"recall\": 0.4519730806350708, \"specificity\": 1.0, \"npv\": 0.9678083062171936, \"accuracy\": 0.9686408638954163, \"f1\": 0.6225639945222796, \"f2\": 0.5076098532998935, \"f0_5\": 0.804826233794531, \"p4\": 0.7625171546039488, \"phi\": 0.661379819255938}, {\"truth_threshold\": 31.749767263079875, \"match_probability\": 0.9999999997230715, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2954.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3584.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45182013511657715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5481798648834229, \"precision\": 1.0, \"recall\": 0.45182013511657715, \"specificity\": 1.0, \"npv\": 0.9677996039390564, \"accuracy\": 0.9686321020126343, \"f1\": 0.6224188790560472, \"f2\": 0.5074555074555075, \"f0_5\": 0.8047292143401983, \"p4\": 0.7624069491185381, \"phi\": 0.6612649451434676}, {\"truth_threshold\": 31.76960181142527, \"match_probability\": 0.9999999997268527, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2953.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3585.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4516671895980835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5483328104019165, \"precision\": 1.0, \"recall\": 0.4516671895980835, \"specificity\": 1.0, \"npv\": 0.9677909016609192, \"accuracy\": 0.9686233401298523, \"f1\": 0.6222737330102202, \"f2\": 0.507301151004982, \"f0_5\": 0.8046321525885558, \"p4\": 0.7622967017902846, \"phi\": 0.6611500531364327}, {\"truth_threshold\": 31.773005184882663, \"match_probability\": 0.9999999997274963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2951.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3587.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4513612687587738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5486387014389038, \"precision\": 1.0, \"recall\": 0.4513612687587738, \"specificity\": 1.0, \"npv\": 0.9677734971046448, \"accuracy\": 0.9686058759689331, \"f1\": 0.6219833491411108, \"f2\": 0.5069924062811394, \"f0_5\": 0.8044379020826519, \"p4\": 0.7620760815062225, \"phi\": 0.6609202154011163}, {\"truth_threshold\": 31.794333366530267, \"match_probability\": 0.9999999997314952, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2950.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3588.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45120832324028015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5487917065620422, \"precision\": 1.0, \"recall\": 0.45120832324028015, \"specificity\": 1.0, \"npv\": 0.9677648544311523, \"accuracy\": 0.9685971140861511, \"f1\": 0.6218381112984823, \"f2\": 0.5068380180056353, \"f0_5\": 0.8043407132729851, \"p4\": 0.7619657085008517, \"phi\": 0.6608052031100058}, {\"truth_threshold\": 31.796577661146312, \"match_probability\": 0.9999999997319127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2949.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3589.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4510553777217865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5489446520805359, \"precision\": 1.0, \"recall\": 0.4510553777217865, \"specificity\": 1.0, \"npv\": 0.9677561521530151, \"accuracy\": 0.9685883522033691, \"f1\": 0.6216928428375672, \"f2\": 0.5066836191196179, \"f0_5\": 0.804243482055198, \"p4\": 0.7618552935535137, \"phi\": 0.660690239419788}, {\"truth_threshold\": 31.815484278419635, \"match_probability\": 0.999999999735403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2948.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3590.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45090240240097046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5490975975990295, \"precision\": 1.0, \"recall\": 0.45090240240097046, \"specificity\": 1.0, \"npv\": 0.9677474498748779, \"accuracy\": 0.9685795903205872, \"f1\": 0.6215475437486823, \"f2\": 0.5065292096219931, \"f0_5\": 0.8041462084015275, \"p4\": 0.7617448366393784, \"phi\": 0.6605752577879891}, {\"truth_threshold\": 31.817472630691682, \"match_probability\": 0.9999999997357675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2947.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3591.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4507494568824768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5492505431175232, \"precision\": 1.0, \"recall\": 0.4507494568824768, \"specificity\": 1.0, \"npv\": 0.9677387475967407, \"accuracy\": 0.9685708284378052, \"f1\": 0.6214022140221402, \"f2\": 0.506374789511667, \"f0_5\": 0.8040488922841864, \"p4\": 0.7616343377335965, \"phi\": 0.6604602582051827}, {\"truth_threshold\": 31.818180108484636, \"match_probability\": 0.9999999997358969, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2946.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3592.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.45059651136398315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5494034886360168, \"precision\": 1.0, \"recall\": 0.45059651136398315, \"specificity\": 1.0, \"npv\": 0.9677300453186035, \"accuracy\": 0.968562126159668, \"f1\": 0.6212568536482497, \"f2\": 0.5062203587875456, \"f0_5\": 0.803951533675363, \"p4\": 0.7615237968112986, \"phi\": 0.6603451740739378}, {\"truth_threshold\": 31.821440742944887, \"match_probability\": 0.9999999997364932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2945.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3593.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4504435658454895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5495564341545105, \"precision\": 1.0, \"recall\": 0.4504435658454895, \"specificity\": 1.0, \"npv\": 0.9677213430404663, \"accuracy\": 0.968553364276886, \"f1\": 0.6211114626173152, \"f2\": 0.5060659174485342, \"f0_5\": 0.8038541325472213, \"p4\": 0.7614132138475959, \"phi\": 0.6602301385498008}, {\"truth_threshold\": 31.822692703221882, \"match_probability\": 0.9999999997367218, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2943.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3595.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4501376450061798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5498623251914978, \"precision\": 1.0, \"recall\": 0.4501376450061798, \"specificity\": 1.0, \"npv\": 0.9677039980888367, \"accuracy\": 0.968535840511322, \"f1\": 0.620820588545512, \"f2\": 0.5057570029214642, \"f0_5\": 0.8036592026215182, \"p4\": 0.7611919216963228, \"phi\": 0.6600000135540484}, {\"truth_threshold\": 31.829810933672174, \"match_probability\": 0.9999999997380176, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2941.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3597.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4498317539691925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5501682758331299, \"precision\": 1.0, \"recall\": 0.4498317539691925, \"specificity\": 1.0, \"npv\": 0.9676865935325623, \"accuracy\": 0.9685183167457581, \"f1\": 0.6205295917290854, \"f2\": 0.5054480459216993, \"f0_5\": 0.8034641022839034, \"p4\": 0.7609704610802733, \"phi\": 0.6597697499221495}, {\"truth_threshold\": 31.833546726817715, \"match_probability\": 0.9999999997386951, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2939.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3599.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4495258629322052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5504741668701172, \"precision\": 1.0, \"recall\": 0.4495258629322052, \"specificity\": 1.0, \"npv\": 0.9676691889762878, \"accuracy\": 0.9685008525848389, \"f1\": 0.6202384720903239, \"f2\": 0.5051390464404799, \"f0_5\": 0.8032688313108123, \"p4\": 0.7607488317996283, \"phi\": 0.6595394808423615}, {\"truth_threshold\": 31.83520141426254, \"match_probability\": 0.9999999997389947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2938.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3600.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44937288761138916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5506271123886108, \"precision\": 1.0, \"recall\": 0.44937288761138916, \"specificity\": 1.0, \"npv\": 0.9676604866981506, \"accuracy\": 0.9684920907020569, \"f1\": 0.6200928661882651, \"f2\": 0.5049845307665864, \"f0_5\": 0.8031711317659923, \"p4\": 0.7606379538475525, \"phi\": 0.659424319252891}, {\"truth_threshold\": 31.84566728391601, \"match_probability\": 0.9999999997408812, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2937.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3601.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4492199420928955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5507800579071045, \"precision\": 1.0, \"recall\": 0.4492199420928955, \"specificity\": 1.0, \"npv\": 0.9676518440246582, \"accuracy\": 0.9684833288192749, \"f1\": 0.6199472295514512, \"f2\": 0.5048300044690432, \"f0_5\": 0.8030733894782894, \"p4\": 0.7605270336542524, \"phi\": 0.6593090729304493}, {\"truth_threshold\": 31.846241480182176, \"match_probability\": 0.9999999997409843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2936.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3602.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44906699657440186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5509330034255981, \"precision\": 1.0, \"recall\": 0.44906699657440186, \"specificity\": 1.0, \"npv\": 0.967643141746521, \"accuracy\": 0.9684745669364929, \"f1\": 0.6198015621701499, \"f2\": 0.5046754675467546, \"f0_5\": 0.8029756044196478, \"p4\": 0.7604160711946618, \"phi\": 0.6591938752289593}, {\"truth_threshold\": 31.8466173420582, \"match_probability\": 0.9999999997410518, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2935.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3603.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4489140510559082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5510859489440918, \"precision\": 1.0, \"recall\": 0.4489140510559082, \"specificity\": 1.0, \"npv\": 0.9676344394683838, \"accuracy\": 0.9684658050537109, \"f1\": 0.6196558640346247, \"f2\": 0.5045209199986248, \"f0_5\": 0.8028777765619871, \"p4\": 0.7603050664436943, \"phi\": 0.6590786594627013}, {\"truth_threshold\": 31.861881668973385, \"match_probability\": 0.9999999997437772, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2934.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3604.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44876107573509216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5512388944625854, \"precision\": 1.0, \"recall\": 0.44876107573509216, \"specificity\": 1.0, \"npv\": 0.9676257371902466, \"accuracy\": 0.9684571027755737, \"f1\": 0.6195101351351351, \"f2\": 0.5043663618235578, \"f0_5\": 0.8027799058772026, \"p4\": 0.7601940193762441, \"phi\": 0.6589634256221439}, {\"truth_threshold\": 31.868313292183927, \"match_probability\": 0.9999999997449168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2932.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3606.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44845518469810486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5515447854995728, \"precision\": 1.0, \"recall\": 0.44845518469810486, \"specificity\": 1.0, \"npv\": 0.9676083326339722, \"accuracy\": 0.9684395790100098, \"f1\": 0.6192185850052798, \"f2\": 0.5040572135882272, \"f0_5\": 0.8025840359137195, \"p4\": 0.7599717981913714, \"phi\": 0.658732836937379}, {\"truth_threshold\": 31.869137484976186, \"match_probability\": 0.9999999997450625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2930.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3608.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44814929366111755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5518507361412048, \"precision\": 1.0, \"recall\": 0.44814929366111755, \"specificity\": 1.0, \"npv\": 0.9675909876823425, \"accuracy\": 0.9684220552444458, \"f1\": 0.6189269117025771, \"f2\": 0.5037480228319923, \"f0_5\": 0.8023879943038668, \"p4\": 0.7597494074387979, \"phi\": 0.6585022425612467}, {\"truth_threshold\": 31.875298145163732, \"match_probability\": 0.9999999997461488, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2929.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3609.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4479963183403015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5520036816596985, \"precision\": 1.0, \"recall\": 0.4479963183403015, \"specificity\": 1.0, \"npv\": 0.9675822854042053, \"accuracy\": 0.9684132933616638, \"f1\": 0.6187810288370128, \"f2\": 0.5035934115057942, \"f0_5\": 0.8022899090610277, \"p4\": 0.7596381484116469, \"phi\": 0.6583869181948401}, {\"truth_threshold\": 31.88070970941248, \"match_probability\": 0.9999999997470993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2927.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3611.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4476904273033142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5523095726966858, \"precision\": 1.0, \"recall\": 0.4476904273033142, \"specificity\": 1.0, \"npv\": 0.9675648808479309, \"accuracy\": 0.9683958292007446, \"f1\": 0.6184891706286318, \"f2\": 0.5032841569517521, \"f0_5\": 0.8020936095582594, \"p4\": 0.7594155029294887, \"phi\": 0.6581561482593766}, {\"truth_threshold\": 31.88217991042183, \"match_probability\": 0.9999999997473569, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2926.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3612.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44753748178482056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5524625182151794, \"precision\": 1.0, \"recall\": 0.44753748178482056, \"specificity\": 1.0, \"npv\": 0.9675561785697937, \"accuracy\": 0.9683870673179626, \"f1\": 0.6183431952662722, \"f2\": 0.503129513721714, \"f0_5\": 0.8019953952417498, \"p4\": 0.7593041164239706, \"phi\": 0.6580407694580882}, {\"truth_threshold\": 31.885844968586504, \"match_probability\": 0.9999999997479979, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2924.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3614.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44723156094551086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5527684092521667, \"precision\": 1.0, \"recall\": 0.44723156094551086, \"specificity\": 1.0, \"npv\": 0.9675388336181641, \"accuracy\": 0.9683695435523987, \"f1\": 0.6180511519763263, \"f2\": 0.5028201953501169, \"f0_5\": 0.8017988373368432, \"p4\": 0.7590812157576285, \"phi\": 0.6578099573645146}, {\"truth_threshold\": 31.889486130367988, \"match_probability\": 0.9999999997486331, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2923.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3615.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4470786154270172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5529213547706604, \"precision\": 1.0, \"recall\": 0.4470786154270172, \"specificity\": 1.0, \"npv\": 0.9675301313400269, \"accuracy\": 0.9683607816696167, \"f1\": 0.6179050840291724, \"f2\": 0.5026655202063629, \"f0_5\": 0.8017004936917169, \"p4\": 0.7589697015461735, \"phi\": 0.6576944572104385}, {\"truth_threshold\": 31.893004760159368, \"match_probability\": 0.9999999997492454, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2922.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3616.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44692566990852356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5530743598937988, \"precision\": 1.0, \"recall\": 0.44692566990852356, \"specificity\": 1.0, \"npv\": 0.9675214290618896, \"accuracy\": 0.9683520197868347, \"f1\": 0.6177589852008457, \"f2\": 0.5025108344225081, \"f0_5\": 0.8016021068802809, \"p4\": 0.7588581447154082, \"phi\": 0.6575790056984562}, {\"truth_threshold\": 31.900101818419092, \"match_probability\": 0.9999999997504759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2920.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3618.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44661974906921387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5533802509307861, \"precision\": 1.0, \"recall\": 0.44661974906921387, \"specificity\": 1.0, \"npv\": 0.96750408411026, \"accuracy\": 0.9683345556259155, \"f1\": 0.617466694861493, \"f2\": 0.5022014309301046, \"f0_5\": 0.801405203644747, \"p4\": 0.7586349030944634, \"phi\": 0.657348048067936}, {\"truth_threshold\": 31.904933837649022, \"match_probability\": 0.9999999997513103, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2917.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3621.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4461609125137329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5538390874862671, \"precision\": 1.0, \"recall\": 0.4461609125137329, \"specificity\": 1.0, \"npv\": 0.9674779772758484, \"accuracy\": 0.9683082699775696, \"f1\": 0.6170280274986779, \"f2\": 0.5017372458632908, \"f0_5\": 0.8011095243326376, \"p4\": 0.7582997203834195, \"phi\": 0.6570014080514842}, {\"truth_threshold\": 31.914699831258687, \"match_probability\": 0.999999999752988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2912.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3626.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44539615511894226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5546038746833801, \"precision\": 1.0, \"recall\": 0.44539615511894226, \"specificity\": 1.0, \"npv\": 0.9674345254898071, \"accuracy\": 0.9682645201683044, \"f1\": 0.6162962962962963, \"f2\": 0.5009633911368016, \"f0_5\": 0.8006158583525789, \"p4\": 0.7577402267552361, \"phi\": 0.6564233541101494}, {\"truth_threshold\": 31.920976416495805, \"match_probability\": 0.9999999997540603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2909.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3629.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4449372887611389, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5550627112388611, \"precision\": 1.0, \"recall\": 0.4449372887611389, \"specificity\": 1.0, \"npv\": 0.9674084782600403, \"accuracy\": 0.9682382941246033, \"f1\": 0.6158568857838467, \"f2\": 0.5004989504834658, \"f0_5\": 0.8003191372290085, \"p4\": 0.7574040159892557, \"phi\": 0.6560762754198488}, {\"truth_threshold\": 31.936726137588686, \"match_probability\": 0.9999999997567306, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2908.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3630.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44478434324264526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5552156567573547, \"precision\": 1.0, \"recall\": 0.44478434324264526, \"specificity\": 1.0, \"npv\": 0.9673997759819031, \"accuracy\": 0.9682295322418213, \"f1\": 0.6157103535888206, \"f2\": 0.5003441156228493, \"f0_5\": 0.8002201430930105, \"p4\": 0.757291859815554, \"phi\": 0.6559605682077871}, {\"truth_threshold\": 31.947019239016036, \"match_probability\": 0.9999999997584601, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2906.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3632.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44447842240333557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.555521547794342, \"precision\": 1.0, \"recall\": 0.44447842240333557, \"specificity\": 1.0, \"npv\": 0.9673824310302734, \"accuracy\": 0.9682120084762573, \"f1\": 0.615417196103346, \"f2\": 0.5000344139307592, \"f0_5\": 0.8000220240061667, \"p4\": 0.7570674184367234, \"phi\": 0.6557290987695157}, {\"truth_threshold\": 31.948444566653944, \"match_probability\": 0.9999999997586986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2904.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3634.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44417253136634827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5558274984359741, \"precision\": 1.0, \"recall\": 0.44417253136634827, \"specificity\": 1.0, \"npv\": 0.967365026473999, \"accuracy\": 0.9681944847106934, \"f1\": 0.61512391442491, \"f2\": 0.49972466960352424, \"f0_5\": 0.7998237303073703, \"p4\": 0.7568428048447559, \"phi\": 0.6554974888587717}, {\"truth_threshold\": 31.951358174740374, \"match_probability\": 0.9999999997591854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2903.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3635.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4440195858478546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5559804439544678, \"precision\": 1.0, \"recall\": 0.4440195858478546, \"specificity\": 1.0, \"npv\": 0.9673563838005066, \"accuracy\": 0.9681857824325562, \"f1\": 0.6149772269886664, \"f2\": 0.49956978144897607, \"f0_5\": 0.7997245179063361, \"p4\": 0.7567304334045563, \"phi\": 0.65538168986377}, {\"truth_threshold\": 31.955341815756032, \"match_probability\": 0.9999999997598494, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2901.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3637.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4437136650085449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5562863349914551, \"precision\": 1.0, \"recall\": 0.4437136650085449, \"specificity\": 1.0, \"npv\": 0.9673389792442322, \"accuracy\": 0.9681682586669922, \"f1\": 0.6146837588727619, \"f2\": 0.49925997315251436, \"f0_5\": 0.7995259618564656, \"p4\": 0.756505561106968, \"phi\": 0.6551500367128543}, {\"truth_threshold\": 31.955830259489684, \"match_probability\": 0.9999999997599307, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2897.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3641.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4431018531322479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5568981170654297, \"precision\": 1.0, \"recall\": 0.4431018531322479, \"specificity\": 1.0, \"npv\": 0.9673042297363281, \"accuracy\": 0.968133270740509, \"f1\": 0.6140964493905671, \"f2\": 0.4986402285792971, \"f0_5\": 0.7991283239545405, \"p4\": 0.7560552981206983, \"phi\": 0.6546864423585217}, {\"truth_threshold\": 31.97047087298394, \"match_probability\": 0.9999999997623547, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2895.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3643.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4427959620952606, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5572040677070618, \"precision\": 1.0, \"recall\": 0.4427959620952606, \"specificity\": 1.0, \"npv\": 0.9672868847846985, \"accuracy\": 0.9681157469749451, \"f1\": 0.6138026078660024, \"f2\": 0.49833029228491754, \"f0_5\": 0.7989292416381499, \"p4\": 0.7558299070185127, \"phi\": 0.6544545009525728}, {\"truth_threshold\": 31.979536285913497, \"match_probability\": 0.9999999997638432, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2894.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3644.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44264301657676697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5573570132255554, \"precision\": 1.0, \"recall\": 0.44264301657676697, \"specificity\": 1.0, \"npv\": 0.9672781825065613, \"accuracy\": 0.9681069850921631, \"f1\": 0.6136556403731976, \"f2\": 0.4981753081319287, \"f0_5\": 0.7988296345368223, \"p4\": 0.7557171464745409, \"phi\": 0.6543385361279335}, {\"truth_threshold\": 31.981481930228465, \"match_probability\": 0.9999999997641615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2891.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3647.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4421841502189636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5578158497810364, \"precision\": 1.0, \"recall\": 0.4421841502189636, \"specificity\": 1.0, \"npv\": 0.9672521352767944, \"accuracy\": 0.9680807590484619, \"f1\": 0.6132145508537491, \"f2\": 0.4977102916365389, \"f0_5\": 0.7985305491105955, \"p4\": 0.7553786045598058, \"phi\": 0.6539904635790339}, {\"truth_threshold\": 31.98259553475947, \"match_probability\": 0.9999999997643435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2890.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3648.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44203120470046997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.55796879529953, \"precision\": 1.0, \"recall\": 0.44203120470046997, \"specificity\": 1.0, \"npv\": 0.9672434329986572, \"accuracy\": 0.9680719971656799, \"f1\": 0.6130674586338566, \"f2\": 0.49755526478892637, \"f0_5\": 0.7984307658304785, \"p4\": 0.7552656704073598, \"phi\": 0.6538744247946571}, {\"truth_threshold\": 31.983790509603864, \"match_probability\": 0.9999999997645386, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2889.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3649.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4418782591819763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5581217408180237, \"precision\": 1.0, \"recall\": 0.4418782591819763, \"specificity\": 1.0, \"npv\": 0.96723473072052, \"accuracy\": 0.968063235282898, \"f1\": 0.6129203352073831, \"f2\": 0.49740022726490135, \"f0_5\": 0.7983309384326296, \"p4\": 0.7551526927877981, \"phi\": 0.6537583674984219}, {\"truth_threshold\": 31.999111824250257, \"match_probability\": 0.999999999767026, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2888.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3650.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4417252838611603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5582746863365173, \"precision\": 1.0, \"recall\": 0.4417252838611603, \"specificity\": 1.0, \"npv\": 0.9672260880470276, \"accuracy\": 0.968054473400116, \"f1\": 0.6127731805643963, \"f2\": 0.4972451790633609, \"f0_5\": 0.7982310668877833, \"p4\": 0.7550396716750798, \"phi\": 0.6536422916804118}, {\"truth_threshold\": 32.00017981258006, \"match_probability\": 0.9999999997671983, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2886.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3652.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.441419392824173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5585805773735046, \"precision\": 1.0, \"recall\": 0.441419392824173, \"specificity\": 1.0, \"npv\": 0.9672086834907532, \"accuracy\": 0.968036949634552, \"f1\": 0.6124787775891342, \"f2\": 0.49693505062332116, \"f0_5\": 0.7980311912399071, \"p4\": 0.7548134988659079, \"phi\": 0.653410017180862}, {\"truth_threshold\": 32.010825186427034, \"match_probability\": 0.9999999997689099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2881.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3657.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4406546354293823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5593453645706177, \"precision\": 1.0, \"recall\": 0.4406546354293823, \"specificity\": 1.0, \"npv\": 0.9671652913093567, \"accuracy\": 0.9679931998252869, \"f1\": 0.6117422231659412, \"f2\": 0.49615954258946715, \"f0_5\": 0.7975307274941867, \"p4\": 0.7542473038858983, \"phi\": 0.6528291068791763}, {\"truth_threshold\": 32.01280166891367, \"match_probability\": 0.9999999997692263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2880.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3658.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.44050168991088867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5594983100891113, \"precision\": 1.0, \"recall\": 0.44050168991088867, \"specificity\": 1.0, \"npv\": 0.9671565890312195, \"accuracy\": 0.9679844379425049, \"f1\": 0.6115948184327883, \"f2\": 0.49600440892807934, \"f0_5\": 0.7974305017166906, \"p4\": 0.7541339338879713, \"phi\": 0.6527128825061593}, {\"truth_threshold\": 32.01351465080295, \"match_probability\": 0.9999999997693403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2878.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3660.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.440195769071579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5598042011260986, \"precision\": 1.0, \"recall\": 0.440195769071579, \"specificity\": 1.0, \"npv\": 0.9671392440795898, \"accuracy\": 0.9679669737815857, \"f1\": 0.6112999150382328, \"f2\": 0.4956941095418533, \"f0_5\": 0.7972299168975069, \"p4\": 0.7539070626804909, \"phi\": 0.6524803779158413}, {\"truth_threshold\": 32.02131302136335, \"match_probability\": 0.9999999997705837, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2871.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3667.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.439125120639801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.560874879360199, \"precision\": 1.0, \"recall\": 0.439125120639801, \"specificity\": 1.0, \"npv\": 0.967078447341919, \"accuracy\": 0.9679057002067566, \"f1\": 0.6102667658624721, \"f2\": 0.4946077249078317, \"f0_5\": 0.7965264676506492, \"p4\": 0.7531116329716343, \"phi\": 0.6516658895736979}, {\"truth_threshold\": 32.0462644852488, \"match_probability\": 0.9999999997745174, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2869.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3669.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43881919980049133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5611807703971863, \"precision\": 1.0, \"recall\": 0.43881919980049133, \"specificity\": 1.0, \"npv\": 0.9670611023902893, \"accuracy\": 0.9678881764411926, \"f1\": 0.6099712979695971, \"f2\": 0.49429723303814477, \"f0_5\": 0.7963250804929499, \"p4\": 0.7528839720472086, \"phi\": 0.6514330489390783}, {\"truth_threshold\": 32.056596116203245, \"match_probability\": 0.9999999997761263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2868.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3670.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4386662542819977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5613337159156799, \"precision\": 1.0, \"recall\": 0.4386662542819977, \"specificity\": 1.0, \"npv\": 0.9670524001121521, \"accuracy\": 0.9678794145584106, \"f1\": 0.6098235169041037, \"f2\": 0.4941419710544452, \"f0_5\": 0.7962243198223209, \"p4\": 0.7527700755706852, \"phi\": 0.6513165330801018}, {\"truth_threshold\": 32.05693693109407, \"match_probability\": 0.9999999997761793, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2867.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3671.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43851330876350403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5614867210388184, \"precision\": 1.0, \"recall\": 0.43851330876350403, \"specificity\": 1.0, \"npv\": 0.9670436978340149, \"accuracy\": 0.9678706526756287, \"f1\": 0.6096757044125465, \"f2\": 0.49398669837003345, \"f0_5\": 0.7961235143840942, \"p4\": 0.7526561350493198, \"phi\": 0.6512000659413805}, {\"truth_threshold\": 32.06699059575799, \"match_probability\": 0.9999999997777336, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2866.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3672.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4383603632450104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.561639666557312, \"precision\": 1.0, \"recall\": 0.4383603632450104, \"specificity\": 1.0, \"npv\": 0.9670350551605225, \"accuracy\": 0.9678619503974915, \"f1\": 0.6095278604849, \"f2\": 0.4938314149838032, \"f0_5\": 0.7960226641484279, \"p4\": 0.7525421504566097, \"phi\": 0.6510835800604858}, {\"truth_threshold\": 32.0705900638008, \"match_probability\": 0.9999999997782874, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2864.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3674.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4380544424057007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5619455575942993, \"precision\": 1.0, \"recall\": 0.4380544424057007, \"specificity\": 1.0, \"npv\": 0.967017650604248, \"accuracy\": 0.9678444266319275, \"f1\": 0.6092320782812167, \"f2\": 0.49352081610146126, \"f0_5\": 0.7958208291652773, \"p4\": 0.7523140489510376, \"phi\": 0.6508504845220404}, {\"truth_threshold\": 32.085948090403875, \"match_probability\": 0.999999999780635, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2863.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3675.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43790149688720703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.562098503112793, \"precision\": 1.0, \"recall\": 0.43790149688720703, \"specificity\": 1.0, \"npv\": 0.9670090079307556, \"accuracy\": 0.9678356647491455, \"f1\": 0.609084139985108, \"f2\": 0.49336550060313633, \"f0_5\": 0.7957198443579766, \"p4\": 0.7521999319850639, \"phi\": 0.6507339423423993}, {\"truth_threshold\": 32.09333378323962, \"match_probability\": 0.9999999997817552, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2862.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3676.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4377485513687134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5622514486312866, \"precision\": 1.0, \"recall\": 0.4377485513687134, \"specificity\": 1.0, \"npv\": 0.9670003056526184, \"accuracy\": 0.9678269028663635, \"f1\": 0.6089361702127659, \"f2\": 0.49321017439856624, \"f0_5\": 0.795618814633604, \"p4\": 0.7520857708415215, \"phi\": 0.6506173813800551}, {\"truth_threshold\": 32.096972594484036, \"match_probability\": 0.999999999782305, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2861.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3677.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4375956058502197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5624043941497803, \"precision\": 1.0, \"recall\": 0.4375956058502197, \"specificity\": 1.0, \"npv\": 0.966991662979126, \"accuracy\": 0.9678181409835815, \"f1\": 0.608788168954144, \"f2\": 0.4930548374866439, \"f0_5\": 0.7955177399621844, \"p4\": 0.7519715654938014, \"phi\": 0.6505008016248548}, {\"truth_threshold\": 32.10613021477604, \"match_probability\": 0.9999999997836825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2859.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3679.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43728968501091003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5627102851867676, \"precision\": 1.0, \"recall\": 0.43728968501091003, \"specificity\": 1.0, \"npv\": 0.9669742584228516, \"accuracy\": 0.9678006768226624, \"f1\": 0.6084920719378525, \"f2\": 0.4927441315363138, \"f0_5\": 0.795315455658173, \"p4\": 0.7517430220792836, \"phi\": 0.6502675181280797}, {\"truth_threshold\": 32.10932139168772, \"match_probability\": 0.9999999997841604, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2858.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3680.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4371367394924164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.562863290309906, \"precision\": 1.0, \"recall\": 0.4371367394924164, \"specificity\": 1.0, \"npv\": 0.9669656157493591, \"accuracy\": 0.9677919149398804, \"f1\": 0.6083439761600681, \"f2\": 0.49258876249569117, \"f0_5\": 0.7952142459654981, \"p4\": 0.7516286839591605, \"phi\": 0.6501508819217858}, {\"truth_threshold\": 32.115094436063394, \"match_probability\": 0.9999999997850224, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2857.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3681.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43698379397392273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5630162358283997, \"precision\": 1.0, \"recall\": 0.43698379397392273, \"specificity\": 1.0, \"npv\": 0.9669569134712219, \"accuracy\": 0.9677831530570984, \"f1\": 0.6081958488557744, \"f2\": 0.4924333827432866, \"f0_5\": 0.7951129912056106, \"p4\": 0.7515143015282088, \"phi\": 0.6500342268819277}, {\"truth_threshold\": 32.11774039034354, \"match_probability\": 0.9999999997854163, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2856.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3682.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4368308484554291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5631691813468933, \"precision\": 1.0, \"recall\": 0.4368308484554291, \"specificity\": 1.0, \"npv\": 0.9669482111930847, \"accuracy\": 0.9677743911743164, \"f1\": 0.6080476900149031, \"f2\": 0.4922779922779923, \"f0_5\": 0.7950116913484022, \"p4\": 0.751399874759712, \"phi\": 0.6499175529983076}, {\"truth_threshold\": 32.11957745866777, \"match_probability\": 0.9999999997856893, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2855.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3683.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43667787313461304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.563322126865387, \"precision\": 1.0, \"recall\": 0.43667787313461304, \"specificity\": 1.0, \"npv\": 0.9669395685195923, \"accuracy\": 0.9677656292915344, \"f1\": 0.6078994996273821, \"f2\": 0.4921225910987003, \"f0_5\": 0.7949103463637376, \"p4\": 0.7512854036269325, \"phi\": 0.6498008602607184}, {\"truth_threshold\": 32.12539866221455, \"match_probability\": 0.9999999997865523, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2854.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3684.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4365249276161194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5634750723838806, \"precision\": 1.0, \"recall\": 0.4365249276161194, \"specificity\": 1.0, \"npv\": 0.9669308662414551, \"accuracy\": 0.9677569270133972, \"f1\": 0.6077512776831345, \"f2\": 0.49196717920430255, \"f0_5\": 0.7948089562214549, \"p4\": 0.751170888103111, \"phi\": 0.6496840810341534}, {\"truth_threshold\": 32.12668895106654, \"match_probability\": 0.9999999997867431, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2853.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3685.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43637198209762573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5636280179023743, \"precision\": 1.0, \"recall\": 0.43637198209762573, \"specificity\": 1.0, \"npv\": 0.9669221639633179, \"accuracy\": 0.9677481651306152, \"f1\": 0.6076030241720797, \"f2\": 0.49181175659369075, \"f0_5\": 0.7947075208913649, \"p4\": 0.7510563281614667, \"phi\": 0.649567350546423}, {\"truth_threshold\": 32.13168703278462, \"match_probability\": 0.9999999997874807, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2852.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3686.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4362190365791321, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5637809634208679, \"precision\": 1.0, \"recall\": 0.4362190365791321, \"specificity\": 1.0, \"npv\": 0.9669135212898254, \"accuracy\": 0.9677394032478333, \"f1\": 0.6074547390841321, \"f2\": 0.4916563232657564, \"f0_5\": 0.794606040343252, \"p4\": 0.7509417237751975, \"phi\": 0.6494506011740433}, {\"truth_threshold\": 32.134567072056115, \"match_probability\": 0.9999999997879045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2850.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3688.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4359131157398224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5640868544578552, \"precision\": 1.0, \"recall\": 0.4359131157398224, \"specificity\": 1.0, \"npv\": 0.9668961763381958, \"accuracy\": 0.9677218794822693, \"f1\": 0.6071580741371965, \"f2\": 0.49134542445348595, \"f0_5\": 0.7944029434719589, \"p4\": 0.7507123815614669, \"phi\": 0.6492169780633402}, {\"truth_threshold\": 32.13761457898138, \"match_probability\": 0.9999999997883521, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2849.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3689.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43576017022132874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5642397999763489, \"precision\": 1.0, \"recall\": 0.43576017022132874, \"specificity\": 1.0, \"npv\": 0.9668874740600586, \"accuracy\": 0.9677131175994873, \"f1\": 0.6070096942580164, \"f2\": 0.4911899589669322, \"f0_5\": 0.7943013270882123, \"p4\": 0.7505976436802931, \"phi\": 0.6491001719639483}, {\"truth_threshold\": 32.145312759400106, \"match_probability\": 0.9999999997894784, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2843.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3695.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43484246730804443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5651575326919556, \"precision\": 1.0, \"recall\": 0.43484246730804443, \"specificity\": 1.0, \"npv\": 0.9668353796005249, \"accuracy\": 0.9676606059074402, \"f1\": 0.6061187506662403, \"f2\": 0.490256940851871, \"f0_5\": 0.7936906756002233, \"p4\": 0.7499082798575823, \"phi\": 0.6483988698160777}, {\"truth_threshold\": 32.14924540416892, \"match_probability\": 0.9999999997900515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2841.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3697.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43453654646873474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5654634237289429, \"precision\": 1.0, \"recall\": 0.43453654646873474, \"specificity\": 1.0, \"npv\": 0.9668180346488953, \"accuracy\": 0.967643141746521, \"f1\": 0.605821516153108, \"f2\": 0.489945848998034, \"f0_5\": 0.7934867612557256, \"p4\": 0.7496781344939074, \"phi\": 0.6481649054289754}, {\"truth_threshold\": 32.149684423132875, \"match_probability\": 0.9999999997901153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2839.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3699.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43423065543174744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.565769374370575, \"precision\": 1.0, \"recall\": 0.43423065543174744, \"specificity\": 1.0, \"npv\": 0.9668006896972656, \"accuracy\": 0.967625617980957, \"f1\": 0.605524154846966, \"f2\": 0.489634714221655, \"f0_5\": 0.7932826645803063, \"p4\": 0.7494478100584503, \"phi\": 0.6479309327612945}, {\"truth_threshold\": 32.15075895345059, \"match_probability\": 0.9999999997902717, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2838.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3700.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4340777099132538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5659223198890686, \"precision\": 1.0, \"recall\": 0.4340777099132538, \"specificity\": 1.0, \"npv\": 0.9667920470237732, \"accuracy\": 0.967616856098175, \"f1\": 0.6053754266211604, \"f2\": 0.4894791307347361, \"f0_5\": 0.7931805477920626, \"p4\": 0.7493325806210791, \"phi\": 0.6478139178892978}, {\"truth_threshold\": 32.15781731093189, \"match_probability\": 0.9999999997912952, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2836.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3702.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4337717890739441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5662282109260559, \"precision\": 1.0, \"recall\": 0.4337717890739441, \"specificity\": 1.0, \"npv\": 0.9667746424674988, \"accuracy\": 0.9675993323326111, \"f1\": 0.6050778749733305, \"f2\": 0.489167931557886, \"f0_5\": 0.7929761771613913, \"p4\": 0.7491019871714122, \"phi\": 0.6475797631835636}, {\"truth_threshold\": 32.15981232909522, \"match_probability\": 0.9999999997915836, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2835.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3703.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43361884355545044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5663811564445496, \"precision\": 1.0, \"recall\": 0.43361884355545044, \"specificity\": 1.0, \"npv\": 0.9667659997940063, \"accuracy\": 0.9675906300544739, \"f1\": 0.6049290515309933, \"f2\": 0.4890123158657329, \"f0_5\": 0.7928739232576351, \"p4\": 0.7489866231047949, \"phi\": 0.6474626911509783}, {\"truth_threshold\": 32.16077274207861, \"match_probability\": 0.9999999997917223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2833.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3705.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43331295251846313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5666870474815369, \"precision\": 1.0, \"recall\": 0.43331295251846313, \"specificity\": 1.0, \"npv\": 0.9667486548423767, \"accuracy\": 0.9675731062889099, \"f1\": 0.6046313093586597, \"f2\": 0.4887010522684147, \"f0_5\": 0.7926692781197537, \"p4\": 0.7487557601520244, \"phi\": 0.6472284898641033}, {\"truth_threshold\": 32.161165951114306, \"match_probability\": 0.9999999997917791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2831.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3707.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43300703167915344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5669929385185242, \"precision\": 1.0, \"recall\": 0.43300703167915344, \"specificity\": 1.0, \"npv\": 0.9667313098907471, \"accuracy\": 0.967555582523346, \"f1\": 0.6043334400683104, \"f2\": 0.4883897457130042, \"f0_5\": 0.7924644496696899, \"p4\": 0.7485247172583255, \"phi\": 0.6469941443202669}, {\"truth_threshold\": 32.16894512336425, \"match_probability\": 0.9999999997928988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2830.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3708.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4328540861606598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5671459436416626, \"precision\": 1.0, \"recall\": 0.4328540861606598, \"specificity\": 1.0, \"npv\": 0.9667226076126099, \"accuracy\": 0.967546820640564, \"f1\": 0.6041844577284372, \"f2\": 0.4882340763232351, \"f0_5\": 0.792361966625602, \"p4\": 0.7484091282654652, \"phi\": 0.6468769768196694}, {\"truth_threshold\": 32.17000396433572, \"match_probability\": 0.9999999997930508, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2829.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3709.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43270114064216614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5672988891601562, \"precision\": 1.0, \"recall\": 0.43270114064216614, \"specificity\": 1.0, \"npv\": 0.9667139053344727, \"accuracy\": 0.9675381183624268, \"f1\": 0.6040354435785203, \"f2\": 0.48807839619060767, \"f0_5\": 0.7922594376610284, \"p4\": 0.7482934942055337, \"phi\": 0.6467597901965068}, {\"truth_threshold\": 32.17119139122571, \"match_probability\": 0.999999999793221, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2826.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3712.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4322422742843628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5677577257156372, \"precision\": 1.0, \"recall\": 0.4322422742843628, \"specificity\": 1.0, \"npv\": 0.9666879177093506, \"accuracy\": 0.9675118327140808, \"f1\": 0.6035882101665955, \"f2\": 0.487611291324453, \"f0_5\": 0.7919515749355454, \"p4\": 0.747946321349944, \"phi\": 0.6464080475366123}, {\"truth_threshold\": 32.17643558754626, \"match_probability\": 0.9999999997939713, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2822.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3716.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4316304624080658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5683695077896118, \"precision\": 1.0, \"recall\": 0.4316304624080658, \"specificity\": 1.0, \"npv\": 0.9666532278060913, \"accuracy\": 0.9674768447875977, \"f1\": 0.602991452991453, \"f2\": 0.4869883343687444, \"f0_5\": 0.7915404465387637, \"p4\": 0.747482791609874, \"phi\": 0.6459388115286042}, {\"truth_threshold\": 32.17773423709248, \"match_probability\": 0.9999999997941567, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2821.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3717.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43147751688957214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5685225129127502, \"precision\": 1.0, \"recall\": 0.43147751688957214, \"specificity\": 1.0, \"npv\": 0.9666445255279541, \"accuracy\": 0.9674680829048157, \"f1\": 0.6028421839940165, \"f2\": 0.48683256825320126, \"f0_5\": 0.7914375490966221, \"p4\": 0.7473667960277898, \"phi\": 0.6458214715243408}, {\"truth_threshold\": 32.18246781317793, \"match_probability\": 0.9999999997948309, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2819.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3719.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43117162585258484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5688284039497375, \"precision\": 1.0, \"recall\": 0.43117162585258484, \"specificity\": 1.0, \"npv\": 0.9666271805763245, \"accuracy\": 0.9674505591392517, \"f1\": 0.6025435502832104, \"f2\": 0.48652100376238305, \"f0_5\": 0.7912316155832492, \"p4\": 0.7471346688946984, \"phi\": 0.6455867338543081}, {\"truth_threshold\": 32.18548376395479, \"match_probability\": 0.9999999997952594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2816.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3722.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4307127594947815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5692872405052185, \"precision\": 1.0, \"recall\": 0.4307127594947815, \"specificity\": 1.0, \"npv\": 0.9666011333465576, \"accuracy\": 0.9674243330955505, \"f1\": 0.6020953602736797, \"f2\": 0.48605357636012153, \"f0_5\": 0.7909223682732277, \"p4\": 0.7467861378595411, \"phi\": 0.6452344149693713}, {\"truth_threshold\": 32.20192870724995, \"match_probability\": 0.9999999997975799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2815.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3723.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43055981397628784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5694401860237122, \"precision\": 1.0, \"recall\": 0.43055981397628784, \"specificity\": 1.0, \"npv\": 0.9665924906730652, \"accuracy\": 0.9674155712127686, \"f1\": 0.6019458997113226, \"f2\": 0.48589774571063626, \"f0_5\": 0.7908191931677716, \"p4\": 0.7466698699813368, \"phi\": 0.6451169594931451}, {\"truth_threshold\": 32.20794037124668, \"match_probability\": 0.9999999997984217, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2813.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3725.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.43025389313697815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5697460770606995, \"precision\": 1.0, \"recall\": 0.43025389313697815, \"specificity\": 1.0, \"npv\": 0.9665751457214355, \"accuracy\": 0.9673980474472046, \"f1\": 0.6016468826863437, \"f2\": 0.48558605213188333, \"f0_5\": 0.7906127037661608, \"p4\": 0.746437197759413, \"phi\": 0.6448819225857251}, {\"truth_threshold\": 32.21423332440894, \"match_probability\": 0.999999999799299, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2810.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3728.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4297950565814972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5702049732208252, \"precision\": 1.0, \"recall\": 0.4297950565814972, \"specificity\": 1.0, \"npv\": 0.9665490984916687, \"accuracy\": 0.9673718214035034, \"f1\": 0.6011981172443304, \"f2\": 0.48511843104757957, \"f0_5\": 0.7903026212172348, \"p4\": 0.746087847847513, \"phi\": 0.6445293245559033}, {\"truth_threshold\": 32.2142601131176, \"match_probability\": 0.9999999997993028, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2808.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3730.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4294891357421875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5705108642578125, \"precision\": 1.0, \"recall\": 0.4294891357421875, \"specificity\": 1.0, \"npv\": 0.9665317535400391, \"accuracy\": 0.9673542976379395, \"f1\": 0.600898780226835, \"f2\": 0.48480662983425415, \"f0_5\": 0.7900956668542487, \"p4\": 0.7458547198634264, \"phi\": 0.6442940943908843}, {\"truth_threshold\": 32.219571196434224, \"match_probability\": 0.9999999998000403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2807.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3731.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42933619022369385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5706638097763062, \"precision\": 1.0, \"recall\": 0.42933619022369385, \"specificity\": 1.0, \"npv\": 0.9665231108665466, \"accuracy\": 0.9673455357551575, \"f1\": 0.600749063670412, \"f2\": 0.484650713077109, \"f0_5\": 0.7899921197793538, \"p4\": 0.7457380873752222, \"phi\": 0.6441764843509777}, {\"truth_threshold\": 32.222503476567894, \"match_probability\": 0.9999999998004463, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2806.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3732.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4291832447052002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5708167552947998, \"precision\": 1.0, \"recall\": 0.4291832447052002, \"specificity\": 1.0, \"npv\": 0.9665144085884094, \"accuracy\": 0.9673367738723755, \"f1\": 0.6005993150684932, \"f2\": 0.48449478555148834, \"f0_5\": 0.7898885260668843, \"p4\": 0.7456214091858293, \"phi\": 0.6440588549456879}, {\"truth_threshold\": 32.22664383757343, \"match_probability\": 0.9999999998010181, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2805.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3733.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42903029918670654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5709697008132935, \"precision\": 1.0, \"recall\": 0.42903029918670654, \"specificity\": 1.0, \"npv\": 0.966505765914917, \"accuracy\": 0.9673280119895935, \"f1\": 0.6004495344107889, \"f2\": 0.4843388472562766, \"f0_5\": 0.7897848856853249, \"p4\": 0.7455046852674084, \"phi\": 0.6439412061643452}, {\"truth_threshold\": 32.22686193253639, \"match_probability\": 0.9999999998010481, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2804.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3734.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4288773238658905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5711226463317871, \"precision\": 1.0, \"recall\": 0.4288773238658905, \"specificity\": 1.0, \"npv\": 0.9664970636367798, \"accuracy\": 0.9673193097114563, \"f1\": 0.600299721687005, \"f2\": 0.48418289819035776, \"f0_5\": 0.7896811986031317, \"p4\": 0.7453879155920976, \"phi\": 0.6438234697865179}, {\"truth_threshold\": 32.24039329222712, \"match_probability\": 0.9999999998029054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2802.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3736.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4285714328289032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5714285969734192, \"precision\": 1.0, \"recall\": 0.4285714328289032, \"specificity\": 1.0, \"npv\": 0.9664797186851501, \"accuracy\": 0.9673017859458923, \"f1\": 0.6, \"f2\": 0.4838709677419355, \"f0_5\": 0.7894736842105263, \"p4\": 0.7451542388592458, \"phi\": 0.6435880752236852}, {\"truth_threshold\": 32.24216616848648, \"match_probability\": 0.9999999998031476, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2799.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3739.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42811256647109985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5718874335289001, \"precision\": 1.0, \"recall\": 0.42811256647109985, \"specificity\": 1.0, \"npv\": 0.9664537310600281, \"accuracy\": 0.9672755002975464, \"f1\": 0.5995501767162901, \"f2\": 0.4834029912610963, \"f0_5\": 0.7891620615766325, \"p4\": 0.7448033798854444, \"phi\": 0.6432347694422615}, {\"truth_threshold\": 32.24533687668467, \"match_probability\": 0.9999999998035797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2796.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3742.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4276537299156189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5723462700843811, \"precision\": 1.0, \"recall\": 0.4276537299156189, \"specificity\": 1.0, \"npv\": 0.966427743434906, \"accuracy\": 0.9672492742538452, \"f1\": 0.5991000642811227, \"f2\": 0.48293491778361197, \"f0_5\": 0.788850016928112, \"p4\": 0.7444521075906719, \"phi\": 0.6428813568350915}, {\"truth_threshold\": 32.254070849212205, \"match_probability\": 0.9999999998047652, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2795.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3743.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42750075459480286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5724992156028748, \"precision\": 1.0, \"recall\": 0.42750075459480286, \"specificity\": 1.0, \"npv\": 0.9664190411567688, \"accuracy\": 0.9672405123710632, \"f1\": 0.5989499624986606, \"f2\": 0.48277887173109474, \"f0_5\": 0.7887459081160402, \"p4\": 0.7443349248458262, \"phi\": 0.6427634453637551}, {\"truth_threshold\": 32.260968098314294, \"match_probability\": 0.9999999998056963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2794.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3744.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4273478090763092, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5726521611213684, \"precision\": 1.0, \"recall\": 0.4273478090763092, \"specificity\": 1.0, \"npv\": 0.9664103984832764, \"accuracy\": 0.9672317504882812, \"f1\": 0.5987998285469353, \"f2\": 0.4826228148967042, \"f0_5\": 0.7886417522863272, \"p4\": 0.7442176960642235, \"phi\": 0.6426455827031654}, {\"truth_threshold\": 32.2649299733699, \"match_probability\": 0.9999999998062292, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2793.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3745.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42719486355781555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5728051662445068, \"precision\": 1.0, \"recall\": 0.42719486355781555, \"specificity\": 1.0, \"npv\": 0.9664016962051392, \"accuracy\": 0.9672229886054993, \"f1\": 0.5986496624156039, \"f2\": 0.48246674727932287, \"f0_5\": 0.7885375494071146, \"p4\": 0.7441004212177516, \"phi\": 0.6425277005377238}, {\"truth_threshold\": 32.265606993117814, \"match_probability\": 0.9999999998063202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2790.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3748.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4267359972000122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5732640027999878, \"precision\": 1.0, \"recall\": 0.4267359972000122, \"specificity\": 1.0, \"npv\": 0.9663757085800171, \"accuracy\": 0.9671967625617981, \"f1\": 0.5981989708404802, \"f2\": 0.4819984797180568, \"f0_5\": 0.7882246581534637, \"p4\": 0.7437483200076574, \"phi\": 0.6421738685279157}, {\"truth_threshold\": 32.272102151954456, \"match_probability\": 0.9999999998071901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2789.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3749.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42658305168151855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5734169483184814, \"precision\": 1.0, \"recall\": 0.42658305168151855, \"specificity\": 1.0, \"npv\": 0.9663670063018799, \"accuracy\": 0.9671880006790161, \"f1\": 0.5980486758872092, \"f2\": 0.4818423689575343, \"f0_5\": 0.7881202667570928, \"p4\": 0.7436308606201306, \"phi\": 0.6420559082230757}, {\"truth_threshold\": 32.273761124866255, \"match_probability\": 0.9999999998074117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2787.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3751.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42627716064453125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5737228393554688, \"precision\": 1.0, \"recall\": 0.42627716064453125, \"specificity\": 1.0, \"npv\": 0.9663496613502502, \"accuracy\": 0.9671704769134521, \"f1\": 0.5977479892761394, \"f2\": 0.4815301150696292, \"f0_5\": 0.7879113423046478, \"p4\": 0.7433958031995082, \"phi\": 0.6418199289257707}, {\"truth_threshold\": 32.28137430897613, \"match_probability\": 0.9999999998084254, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2786.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3752.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4261241853237152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5738757848739624, \"precision\": 1.0, \"recall\": 0.4261241853237152, \"specificity\": 1.0, \"npv\": 0.9663410186767578, \"accuracy\": 0.9671617746353149, \"f1\": 0.5975975975975976, \"f2\": 0.4813739719400097, \"f0_5\": 0.7878068091844814, \"p4\": 0.7432782051098901, \"phi\": 0.6417018414873894}, {\"truth_threshold\": 32.285978861182016, \"match_probability\": 0.9999999998090359, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2783.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3755.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42566534876823425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5743346810340881, \"precision\": 1.0, \"recall\": 0.42566534876823425, \"specificity\": 1.0, \"npv\": 0.9663150310516357, \"accuracy\": 0.967135488986969, \"f1\": 0.5971462289453922, \"f2\": 0.4809054777950579, \"f0_5\": 0.7874929258630448, \"p4\": 0.7429251329841902, \"phi\": 0.6413476668165461}, {\"truth_threshold\": 32.28666860864565, \"match_probability\": 0.9999999998091271, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2781.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3757.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42535942792892456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5746405720710754, \"precision\": 1.0, \"recall\": 0.42535942792892456, \"specificity\": 1.0, \"npv\": 0.9662976861000061, \"accuracy\": 0.967117965221405, \"f1\": 0.5968451550595557, \"f2\": 0.48059309439048836, \"f0_5\": 0.7872834333597554, \"p4\": 0.7426895197362084, \"phi\": 0.6411113837825939}, {\"truth_threshold\": 32.28961767242643, \"match_probability\": 0.9999999998095168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2780.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3758.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4252064824104309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5747935175895691, \"precision\": 1.0, \"recall\": 0.4252064824104309, \"specificity\": 1.0, \"npv\": 0.9662889838218689, \"accuracy\": 0.9671092629432678, \"f1\": 0.5966945696501396, \"f2\": 0.4804368864924651, \"f0_5\": 0.7871786159247933, \"p4\": 0.7425716434777986, \"phi\": 0.6409932470322207}, {\"truth_threshold\": 32.2957345159186, \"match_probability\": 0.9999999998103227, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2779.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3759.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42505353689193726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5749464631080627, \"precision\": 1.0, \"recall\": 0.42505353689193726, \"specificity\": 1.0, \"npv\": 0.9662803411483765, \"accuracy\": 0.9671005010604858, \"f1\": 0.5965439519158527, \"f2\": 0.48028066779579, \"f0_5\": 0.7870737509912767, \"p4\": 0.7424537207585377, \"phi\": 0.6408750906249675}, {\"truth_threshold\": 32.296128937894714, \"match_probability\": 0.9999999998103746, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2777.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3761.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42474761605262756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.57525235414505, \"precision\": 1.0, \"recall\": 0.42474761605262756, \"specificity\": 1.0, \"npv\": 0.9662629961967468, \"accuracy\": 0.9670829772949219, \"f1\": 0.5962426194310252, \"f2\": 0.4799681980020049, \"f0_5\": 0.7868638784993767, \"p4\": 0.7422177358236087, \"phi\": 0.6406386502638436}, {\"truth_threshold\": 32.29880594939105, \"match_probability\": 0.9999999998107262, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2776.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3762.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4245946705341339, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5754052996635437, \"precision\": 1.0, \"recall\": 0.4245946705341339, \"specificity\": 1.0, \"npv\": 0.9662543535232544, \"accuracy\": 0.9670742154121399, \"f1\": 0.5960919046596521, \"f2\": 0.4798119469026549, \"f0_5\": 0.7867588708763179, \"p4\": 0.7420996735509556, \"phi\": 0.6405204348082881}, {\"truth_threshold\": 32.3035395254765, \"match_probability\": 0.9999999998113461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2775.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3763.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42444172501564026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5755582451820374, \"precision\": 1.0, \"recall\": 0.42444172501564026, \"specificity\": 1.0, \"npv\": 0.9662456512451172, \"accuracy\": 0.9670654535293579, \"f1\": 0.5959411575217438, \"f2\": 0.47965568500017286, \"f0_5\": 0.7866538156253543, \"p4\": 0.741981564703481, \"phi\": 0.6404021996520616}, {\"truth_threshold\": 32.31476678089976, \"match_probability\": 0.9999999998128086, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2772.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3766.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4239828586578369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5760171413421631, \"precision\": 1.0, \"recall\": 0.4239828586578369, \"specificity\": 1.0, \"npv\": 0.9662196636199951, \"accuracy\": 0.9670392274856567, \"f1\": 0.5954887218045113, \"f2\": 0.4791868344627299, \"f0_5\": 0.7863383637807784, \"p4\": 0.7416269584265042, \"phi\": 0.6400473072771128}, {\"truth_threshold\": 32.32082549688143, \"match_probability\": 0.9999999998135931, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2771.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3767.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42382991313934326, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5761700868606567, \"precision\": 1.0, \"recall\": 0.42382991313934326, \"specificity\": 1.0, \"npv\": 0.9662110209465027, \"accuracy\": 0.9670304656028748, \"f1\": 0.5953378450961435, \"f2\": 0.4790305293365142, \"f0_5\": 0.7862331176937919, \"p4\": 0.7415086629940026, \"phi\": 0.6399289931963256}, {\"truth_threshold\": 32.32829814059049, \"match_probability\": 0.9999999998145561, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2770.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3768.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4236769676208496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5763230323791504, \"precision\": 1.0, \"recall\": 0.4236769676208496, \"specificity\": 1.0, \"npv\": 0.9662023186683655, \"accuracy\": 0.9670217037200928, \"f1\": 0.5951869359690589, \"f2\": 0.47887421340156283, \"f0_5\": 0.7861278238165512, \"p4\": 0.7413903208436922, \"phi\": 0.6398106593599069}, {\"truth_threshold\": 32.330025001591785, \"match_probability\": 0.9999999998147779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2768.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3770.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4233710467815399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5766289234161377, \"precision\": 1.0, \"recall\": 0.4233710467815399, \"specificity\": 1.0, \"npv\": 0.9661850333213806, \"accuracy\": 0.9670042395591736, \"f1\": 0.5948850204169354, \"f2\": 0.4785615491009682, \"f0_5\": 0.7859170925610448, \"p4\": 0.7411534962749502, \"phi\": 0.6395739323760822}, {\"truth_threshold\": 32.330995841008026, \"match_probability\": 0.9999999998149025, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2767.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3771.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42321810126304626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5767818689346313, \"precision\": 1.0, \"recall\": 0.42321810126304626, \"specificity\": 1.0, \"npv\": 0.9661763310432434, \"accuracy\": 0.9669954776763916, \"f1\": 0.5947340139709834, \"f2\": 0.47840520073308207, \"f0_5\": 0.7858116551175736, \"p4\": 0.741035013799113, \"phi\": 0.6394554705537145}, {\"truth_threshold\": 32.332753281314396, \"match_probability\": 0.9999999998151279, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2766.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3772.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4230651557445526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.576934814453125, \"precision\": 1.0, \"recall\": 0.4230651557445526, \"specificity\": 1.0, \"npv\": 0.966167688369751, \"accuracy\": 0.9669867157936096, \"f1\": 0.5945829750644884, \"f2\": 0.47824884155197456, \"f0_5\": 0.7857061697534371, \"p4\": 0.7409164844906554, \"phi\": 0.6393370575723621}, {\"truth_threshold\": 32.33447090662298, \"match_probability\": 0.9999999998153478, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2765.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3773.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42291221022605896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5770878195762634, \"precision\": 1.0, \"recall\": 0.42291221022605896, \"specificity\": 1.0, \"npv\": 0.9661589860916138, \"accuracy\": 0.9669779539108276, \"f1\": 0.5944319036869827, \"f2\": 0.47809247155652385, \"f0_5\": 0.7856006364359587, \"p4\": 0.7407979083208158, \"phi\": 0.6392186247801681}, {\"truth_threshold\": 32.33472976380103, \"match_probability\": 0.999999999815381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2762.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3776.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4224533438682556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5775466561317444, \"precision\": 1.0, \"recall\": 0.4224533438682556, \"specificity\": 1.0, \"npv\": 0.9661329984664917, \"accuracy\": 0.9669516682624817, \"f1\": 0.5939784946236559, \"f2\": 0.47762329667289205, \"f0_5\": 0.7852837484362561, \"p4\": 0.7404418983550352, \"phi\": 0.6388631387143181}, {\"truth_threshold\": 32.33748685739984, \"match_probability\": 0.9999999998157335, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2761.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3777.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42230039834976196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.577699601650238, \"precision\": 1.0, \"recall\": 0.42230039834976196, \"specificity\": 1.0, \"npv\": 0.9661243557929993, \"accuracy\": 0.9669429659843445, \"f1\": 0.5938272932573395, \"f2\": 0.47746688340884724, \"f0_5\": 0.7851780229780457, \"p4\": 0.7403231344515799, \"phi\": 0.6387446265558162}, {\"truth_threshold\": 32.337486857399846, \"match_probability\": 0.9999999998157335, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2760.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3778.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4221474528312683, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5778525471687317, \"precision\": 1.0, \"recall\": 0.4221474528312683, \"specificity\": 1.0, \"npv\": 0.9661156535148621, \"accuracy\": 0.9669342041015625, \"f1\": 0.5936760593676059, \"f2\": 0.47731045932484784, \"f0_5\": 0.7850722494026624, \"p4\": 0.740204323542581, \"phi\": 0.6386260945310119}, {\"truth_threshold\": 32.33992896577803, \"match_probability\": 0.9999999998160451, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2756.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3782.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4215356409549713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5784643888473511, \"precision\": 1.0, \"recall\": 0.4215356409549713, \"specificity\": 1.0, \"npv\": 0.9660810232162476, \"accuracy\": 0.9668991565704346, \"f1\": 0.5930707983645362, \"f2\": 0.47668465476684657, \"f0_5\": 0.784648673271837, \"p4\": 0.7397286092727273, \"phi\": 0.6381516987598292}, {\"truth_threshold\": 32.34610273339823, \"match_probability\": 0.9999999998168306, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2755.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3783.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42138269543647766, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5786173343658447, \"precision\": 1.0, \"recall\": 0.42138269543647766, \"specificity\": 1.0, \"npv\": 0.9660723805427551, \"accuracy\": 0.9668904542922974, \"f1\": 0.5929194017002044, \"f2\": 0.47652817656622964, \"f0_5\": 0.7845426586171546, \"p4\": 0.7396095629019868, \"phi\": 0.6380330672243195}, {\"truth_threshold\": 32.36249181405377, \"match_probability\": 0.9999999998188996, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2754.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3784.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4212297201156616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5787702798843384, \"precision\": 1.0, \"recall\": 0.4212297201156616, \"specificity\": 1.0, \"npv\": 0.9660636782646179, \"accuracy\": 0.9668816924095154, \"f1\": 0.5927679724494188, \"f2\": 0.47637168753891923, \"f0_5\": 0.7844365956477156, \"p4\": 0.7394904693519273, \"phi\": 0.6379143469448992}, {\"truth_threshold\": 32.36623641785398, \"match_probability\": 0.9999999998193692, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2753.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3785.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42107677459716797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.578923225402832, \"precision\": 1.0, \"recall\": 0.42107677459716797, \"specificity\": 1.0, \"npv\": 0.9660550355911255, \"accuracy\": 0.9668729305267334, \"f1\": 0.5926165106016575, \"f2\": 0.47621518768379173, \"f0_5\": 0.7843304843304844, \"p4\": 0.739371328593503, \"phi\": 0.6377956755196442}, {\"truth_threshold\": 32.36760673759207, \"match_probability\": 0.9999999998195406, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2752.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3786.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4209238290786743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5790761709213257, \"precision\": 1.0, \"recall\": 0.4209238290786743, \"specificity\": 1.0, \"npv\": 0.9660463929176331, \"accuracy\": 0.9668641686439514, \"f1\": 0.592465016146394, \"f2\": 0.4760586769997232, \"f0_5\": 0.7842243246323949, \"p4\": 0.7392521405976443, \"phi\": 0.6376769841388206}, {\"truth_threshold\": 32.37786724304153, \"match_probability\": 0.9999999998208194, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2749.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3789.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42046496272087097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5795350074768066, \"precision\": 1.0, \"recall\": 0.42046496272087097, \"specificity\": 1.0, \"npv\": 0.9660203456878662, \"accuracy\": 0.9668379426002502, \"f1\": 0.5920103370302573, \"f2\": 0.47558907996263106, \"f0_5\": 0.7839055549218661, \"p4\": 0.7388942928944088, \"phi\": 0.6373207212791342}, {\"truth_threshold\": 32.41467499124885, \"match_probability\": 0.9999999998253332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2748.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3790.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4203120172023773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5796879529953003, \"precision\": 1.0, \"recall\": 0.4203120172023773, \"specificity\": 1.0, \"npv\": 0.9660117030143738, \"accuracy\": 0.9668291807174683, \"f1\": 0.5918587120396296, \"f2\": 0.4754325259515571, \"f0_5\": 0.7837992013690815, \"p4\": 0.7387749156576395, \"phi\": 0.6372019499516882}, {\"truth_threshold\": 32.42933400353919, \"match_probability\": 0.9999999998270989, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2747.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3791.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42015907168388367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5798409581184387, \"precision\": 1.0, \"recall\": 0.42015907168388367, \"specificity\": 1.0, \"npv\": 0.9660030603408813, \"accuracy\": 0.9668204188346863, \"f1\": 0.5917070543887991, \"f2\": 0.47527596110592063, \"f0_5\": 0.7836927992696565, \"p4\": 0.7386554910377297, \"phi\": 0.6370831586125525}, {\"truth_threshold\": 32.434007581761605, \"match_probability\": 0.9999999998276581, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2746.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3792.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.42000612616539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5799939036369324, \"precision\": 1.0, \"recall\": 0.42000612616539, \"specificity\": 1.0, \"npv\": 0.9659943580627441, \"accuracy\": 0.9668116569519043, \"f1\": 0.5915553640672124, \"f2\": 0.47511938542459686, \"f0_5\": 0.7835863485903436, \"p4\": 0.7385360190054662, \"phi\": 0.6369643472504732}, {\"truth_threshold\": 32.44196361777067, \"match_probability\": 0.9999999998286059, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2743.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3795.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41954725980758667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5804527401924133, \"precision\": 1.0, \"recall\": 0.41954725980758667, \"specificity\": 1.0, \"npv\": 0.9659683704376221, \"accuracy\": 0.9667854309082031, \"f1\": 0.591100096972309, \"f2\": 0.47464959335525175, \"f0_5\": 0.7832667047401485, \"p4\": 0.7381773181420626, \"phi\": 0.6366077239687278}, {\"truth_threshold\": 32.442027153396765, \"match_probability\": 0.9999999998286134, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2741.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3797.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41924136877059937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5807586312294006, \"precision\": 1.0, \"recall\": 0.41924136877059937, \"specificity\": 1.0, \"npv\": 0.9659510850906372, \"accuracy\": 0.9667679071426392, \"f1\": 0.5907964220282358, \"f2\": 0.47433634444329076, \"f0_5\": 0.7830533653296766, \"p4\": 0.7379379466347035, \"phi\": 0.6363699207316411}, {\"truth_threshold\": 32.447341296849764, \"match_probability\": 0.9999999998292436, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2736.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3802.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4184766113758087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5815234184265137, \"precision\": 1.0, \"recall\": 0.4184766113758087, \"specificity\": 1.0, \"npv\": 0.9659077525138855, \"accuracy\": 0.966724157333374, \"f1\": 0.5900366616346776, \"f2\": 0.47355303240099694, \"f0_5\": 0.782519162567212, \"p4\": 0.7373386845593015, \"phi\": 0.635774922791229}, {\"truth_threshold\": 32.45155989380573, \"match_probability\": 0.9999999998297422, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2730.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3808.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.417558878660202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5824410915374756, \"precision\": 1.0, \"recall\": 0.417558878660202, \"specificity\": 1.0, \"npv\": 0.9658557772636414, \"accuracy\": 0.9666716456413269, \"f1\": 0.5891238670694864, \"f2\": 0.4726126999515269, \"f0_5\": 0.7818765036086608, \"p4\": 0.7366179944779263, \"phi\": 0.6350603566935609}, {\"truth_threshold\": 32.45659361008796, \"match_probability\": 0.9999999998303352, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2729.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3809.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4174059331417084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5825940370559692, \"precision\": 1.0, \"recall\": 0.4174059331417084, \"specificity\": 1.0, \"npv\": 0.9658471345901489, \"accuracy\": 0.9666628837585449, \"f1\": 0.5889716197259092, \"f2\": 0.472455939891278, \"f0_5\": 0.7817692219548528, \"p4\": 0.7364977119426882, \"phi\": 0.6349412031602194}, {\"truth_threshold\": 32.4613924782637, \"match_probability\": 0.9999999998308986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2728.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3810.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4172529876232147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5827470421791077, \"precision\": 1.0, \"recall\": 0.4172529876232147, \"specificity\": 1.0, \"npv\": 0.9658384919166565, \"accuracy\": 0.9666541218757629, \"f1\": 0.5888193395208289, \"f2\": 0.47229916897506924, \"f0_5\": 0.7816618911174785, \"p4\": 0.7363773814651314, \"phi\": 0.6348220293995702}, {\"truth_threshold\": 32.47714319064957, \"match_probability\": 0.9999999998327348, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2727.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3811.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41710004210472107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5828999876976013, \"precision\": 1.0, \"recall\": 0.41710004210472107, \"specificity\": 1.0, \"npv\": 0.9658298492431641, \"accuracy\": 0.966645359992981, \"f1\": 0.5886670264436049, \"f2\": 0.47214238720177293, \"f0_5\": 0.7815545110627078, \"p4\": 0.7362570030155825, \"phi\": 0.634702835400162}, {\"truth_threshold\": 32.482700836965975, \"match_probability\": 0.9999999998333778, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2726.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3812.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41694706678390503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.583052933216095, \"precision\": 1.0, \"recall\": 0.41694706678390503, \"specificity\": 1.0, \"npv\": 0.9658211469650269, \"accuracy\": 0.966636598110199, \"f1\": 0.5885146804835925, \"f2\": 0.4719855945702611, \"f0_5\": 0.7814470817566793, \"p4\": 0.7361365765643437, \"phi\": 0.634583551996002}, {\"truth_threshold\": 32.49244384950585, \"match_probability\": 0.9999999998344993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2724.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3814.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4166411757469177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5833588242530823, \"precision\": 1.0, \"recall\": 0.4166411757469177, \"specificity\": 1.0, \"npv\": 0.965803861618042, \"accuracy\": 0.9666191339492798, \"f1\": 0.5882098898725977, \"f2\": 0.4716719767280787, \"f0_5\": 0.7812320752552484, \"p4\": 0.7358955795378817, \"phi\": 0.6343450626754187}, {\"truth_threshold\": 32.507411858842154, \"match_probability\": 0.9999999998362076, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2722.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3816.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4163352847099304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5836647152900696, \"precision\": 1.0, \"recall\": 0.4163352847099304, \"specificity\": 1.0, \"npv\": 0.9657865166664124, \"accuracy\": 0.9666016101837158, \"f1\": 0.5879049676025918, \"f2\": 0.47135831543949575, \"f0_5\": 0.7810168713416734, \"p4\": 0.7356543901476711, \"phi\": 0.6341064230120349}, {\"truth_threshold\": 32.51162277161259, \"match_probability\": 0.9999999998366849, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2718.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3820.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4157234728336334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.584276556968689, \"precision\": 1.0, \"recall\": 0.4157234728336334, \"specificity\": 1.0, \"npv\": 0.9657518863677979, \"accuracy\": 0.9665666222572327, \"f1\": 0.5872947277441659, \"f2\": 0.47073086248701074, \"f0_5\": 0.7805858701895463, \"p4\": 0.73517143332174, \"phi\": 0.6336290382591456}, {\"truth_threshold\": 32.512010093762875, \"match_probability\": 0.9999999998367287, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2716.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3822.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41541755199432373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5845824480056763, \"precision\": 1.0, \"recall\": 0.41541755199432373, \"specificity\": 1.0, \"npv\": 0.965734601020813, \"accuracy\": 0.9665490984916687, \"f1\": 0.5869894099848714, \"f2\": 0.47041707080504364, \"f0_5\": 0.7803700724054706, \"p4\": 0.7349296654079013, \"phi\": 0.6333901545270677}, {\"truth_threshold\": 32.51234413500739, \"match_probability\": 0.9999999998367666, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2715.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3823.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4152646064758301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5847353935241699, \"precision\": 1.0, \"recall\": 0.4152646064758301, \"specificity\": 1.0, \"npv\": 0.9657258987426758, \"accuracy\": 0.9665403366088867, \"f1\": 0.5868367016102886, \"f2\": 0.470260158658676, \"f0_5\": 0.7802620990918496, \"p4\": 0.7348087089709808, \"phi\": 0.6332707167281583}, {\"truth_threshold\": 32.520943218532885, \"match_probability\": 0.9999999998377366, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2714.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3824.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4151116609573364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5848883390426636, \"precision\": 1.0, \"recall\": 0.4151116609573364, \"specificity\": 1.0, \"npv\": 0.9657172560691833, \"accuracy\": 0.9665315747261047, \"f1\": 0.5866839602248163, \"f2\": 0.47010323564054596, \"f0_5\": 0.7801540761182016, \"p4\": 0.7346877041740761, \"phi\": 0.6331512585406379}, {\"truth_threshold\": 32.52539835925679, \"match_probability\": 0.9999999998382368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2713.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3825.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4149587154388428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5850412845611572, \"precision\": 1.0, \"recall\": 0.4149587154388428, \"specificity\": 1.0, \"npv\": 0.9657086133956909, \"accuracy\": 0.9665228128433228, \"f1\": 0.5865311858177494, \"f2\": 0.4699463017495236, \"f0_5\": 0.7800460034502588, \"p4\": 0.7345666509871688, \"phi\": 0.6330317106369279}, {\"truth_threshold\": 32.52642221439529, \"match_probability\": 0.9999999998383516, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2712.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3826.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41480574011802673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5851942300796509, \"precision\": 1.0, \"recall\": 0.41480574011802673, \"specificity\": 1.0, \"npv\": 0.9656999707221985, \"accuracy\": 0.9665141105651855, \"f1\": 0.5863783783783784, \"f2\": 0.46978935698447893, \"f0_5\": 0.7799378810537214, \"p4\": 0.7344455493802154, \"phi\": 0.632912211624907}, {\"truth_threshold\": 32.566457877785254, \"match_probability\": 0.9999999998427759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2710.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3828.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41449984908103943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.585500180721283, \"precision\": 1.0, \"recall\": 0.41449984908103943, \"specificity\": 1.0, \"npv\": 0.9656826257705688, \"accuracy\": 0.9664965867996216, \"f1\": 0.5860726643598616, \"f2\": 0.46947543482780124, \"f0_5\": 0.7797214869375072, \"p4\": 0.7342032007858731, \"phi\": 0.6326731523188815}, {\"truth_threshold\": 32.58405451927022, \"match_probability\": 0.9999999998446818, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2705.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3833.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4137350916862488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5862649083137512, \"precision\": 1.0, \"recall\": 0.4137350916862488, \"specificity\": 1.0, \"npv\": 0.9656393527984619, \"accuracy\": 0.9664528369903564, \"f1\": 0.585307800497674, \"f2\": 0.46869043906157953, \"f0_5\": 0.7791796289895149, \"p4\": 0.7335964798413857, \"phi\": 0.6320750766160684}, {\"truth_threshold\": 32.60806344429945, \"match_probability\": 0.9999999998472452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2704.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3834.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4135821461677551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5864178538322449, \"precision\": 1.0, \"recall\": 0.4135821461677551, \"specificity\": 1.0, \"npv\": 0.9656307101249695, \"accuracy\": 0.9664440751075745, \"f1\": 0.5851547284137633, \"f2\": 0.468533407263654, \"f0_5\": 0.7790711075256425, \"p4\": 0.7334749897895149, \"phi\": 0.6319554138776109}, {\"truth_threshold\": 32.61556340839146, \"match_probability\": 0.9999999998480372, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2703.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3835.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4134291708469391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5865707993507385, \"precision\": 1.0, \"recall\": 0.4134291708469391, \"specificity\": 1.0, \"npv\": 0.9656220078468323, \"accuracy\": 0.9664353132247925, \"f1\": 0.5850016232009523, \"f2\": 0.4683763645815283, \"f0_5\": 0.7789625360230548, \"p4\": 0.7333534510460862, \"phi\": 0.6318356611813668}, {\"truth_threshold\": 32.62304140615162, \"match_probability\": 0.9999999998488229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2701.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3837.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4131232798099518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5868767499923706, \"precision\": 1.0, \"recall\": 0.4131232798099518, \"specificity\": 1.0, \"npv\": 0.9656047224998474, \"accuracy\": 0.9664177894592285, \"f1\": 0.5846953133456002, \"f2\": 0.4680622465601497, \"f0_5\": 0.7787452427632338, \"p4\": 0.7331102273633571, \"phi\": 0.6315962330483905}, {\"truth_threshold\": 32.62397752381796, \"match_probability\": 0.999999999848921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2697.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3841.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4125114679336548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5874885320663452, \"precision\": 1.0, \"recall\": 0.4125114679336548, \"specificity\": 1.0, \"npv\": 0.9655700922012329, \"accuracy\": 0.9663828015327454, \"f1\": 0.58408229561451, \"f2\": 0.46743387985718743, \"f0_5\": 0.7783100542537227, \"p4\": 0.7326231943646199, \"phi\": 0.6311170605478706}, {\"truth_threshold\": 32.62911528919491, \"match_probability\": 0.9999999998494581, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2694.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3844.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41205260157585144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5879473686218262, \"precision\": 1.0, \"recall\": 0.41205260157585144, \"specificity\": 1.0, \"npv\": 0.9655441045761108, \"accuracy\": 0.9663565754890442, \"f1\": 0.5836221837088388, \"f2\": 0.4669624904666158, \"f0_5\": 0.7779831350352316, \"p4\": 0.7322574062284474, \"phi\": 0.6307574474686217}, {\"truth_threshold\": 32.630153554989164, \"match_probability\": 0.9999999998495663, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2693.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3845.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4118996560573578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5881003141403198, \"precision\": 1.0, \"recall\": 0.4118996560573578, \"specificity\": 1.0, \"npv\": 0.9655354619026184, \"accuracy\": 0.9663478136062622, \"f1\": 0.583468746614668, \"f2\": 0.46680533888022185, \"f0_5\": 0.7778740612362796, \"p4\": 0.7321353788991624, \"phi\": 0.630637558361017}, {\"truth_threshold\": 32.63055612286693, \"match_probability\": 0.9999999998496083, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2692.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3846.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41174671053886414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5882532596588135, \"precision\": 1.0, \"recall\": 0.41174671053886414, \"specificity\": 1.0, \"npv\": 0.965526819229126, \"accuracy\": 0.9663390517234802, \"f1\": 0.5833152762730227, \"f2\": 0.466648176397171, \"f0_5\": 0.7777649370160638, \"p4\": 0.7320133025437089, \"phi\": 0.6305176486070635}, {\"truth_threshold\": 32.647184082603694, \"match_probability\": 0.9999999998513317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2689.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3849.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4112878441810608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5887121558189392, \"precision\": 1.0, \"recall\": 0.4112878441810608, \"specificity\": 1.0, \"npv\": 0.9655008316040039, \"accuracy\": 0.9663127660751343, \"f1\": 0.5828546656551425, \"f2\": 0.46617662355674216, \"f0_5\": 0.7774372614779692, \"p4\": 0.7316467790145015, \"phi\": 0.6301577257315278}, {\"truth_threshold\": 32.6539722641158, \"match_probability\": 0.9999999998520296, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2687.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3851.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4109819531440735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5890180468559265, \"precision\": 1.0, \"recall\": 0.4109819531440735, \"specificity\": 1.0, \"npv\": 0.965483546257019, \"accuracy\": 0.9662953019142151, \"f1\": 0.5825474254742548, \"f2\": 0.4658622004923888, \"f0_5\": 0.777218558370936, \"p4\": 0.7314021843030426, \"phi\": 0.6299177200848857}, {\"truth_threshold\": 32.65553164119261, \"match_probability\": 0.9999999998521895, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2685.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3853.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4106760621070862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5893239378929138, \"precision\": 1.0, \"recall\": 0.4106760621070862, \"specificity\": 1.0, \"npv\": 0.9654662609100342, \"accuracy\": 0.9662777781486511, \"f1\": 0.5822400520438036, \"f2\": 0.46554773381419706, \"f0_5\": 0.7769996527375854, \"p4\": 0.7311573927516559, \"phi\": 0.6296775619002775}, {\"truth_threshold\": 32.65988593222986, \"match_probability\": 0.9999999998526349, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2684.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3854.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.41052308678627014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5894768834114075, \"precision\": 1.0, \"recall\": 0.41052308678627014, \"specificity\": 1.0, \"npv\": 0.9654576182365417, \"accuracy\": 0.9662690162658691, \"f1\": 0.5820863153328996, \"f2\": 0.4653904841170759, \"f0_5\": 0.7768901238856084, \"p4\": 0.7310349230841641, \"phi\": 0.6295574865230562}, {\"truth_threshold\": 32.66306262111824, \"match_probability\": 0.9999999998529591, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2681.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3857.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4100642502307892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5899357795715332, \"precision\": 1.0, \"recall\": 0.4100642502307892, \"specificity\": 1.0, \"npv\": 0.9654316306114197, \"accuracy\": 0.966242790222168, \"f1\": 0.5816249050873197, \"f2\": 0.46491866957999517, \"f0_5\": 0.7765612327656123, \"p4\": 0.7306672181451194, \"phi\": 0.6291970661053011}, {\"truth_threshold\": 32.67138157106769, \"match_probability\": 0.9999999998538045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2679.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3859.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4097583293914795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5902416706085205, \"precision\": 1.0, \"recall\": 0.4097583293914795, \"specificity\": 1.0, \"npv\": 0.9654143452644348, \"accuracy\": 0.966225266456604, \"f1\": 0.5813171313876533, \"f2\": 0.46460407200582704, \"f0_5\": 0.7763417178625246, \"p4\": 0.7304218345969553, \"phi\": 0.6289567283544311}, {\"truth_threshold\": 32.68193509520519, \"match_probability\": 0.99999999985487, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2677.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3861.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4094524383544922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5905475616455078, \"precision\": 1.0, \"recall\": 0.4094524383544922, \"specificity\": 1.0, \"npv\": 0.9653970003128052, \"accuracy\": 0.96620774269104, \"f1\": 0.5810092240911557, \"f2\": 0.46428943078150475, \"f0_5\": 0.7761219993041865, \"p4\": 0.730176253222833, \"phi\": 0.6287163073510216}, {\"truth_threshold\": 32.68541016082015, \"match_probability\": 0.9999999998552191, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2676.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3862.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40929949283599854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5907005071640015, \"precision\": 1.0, \"recall\": 0.40929949283599854, \"specificity\": 1.0, \"npv\": 0.9653883576393127, \"accuracy\": 0.9661989808082581, \"f1\": 0.5808552203169091, \"f2\": 0.4641320937976967, \"f0_5\": 0.7760120635657116, \"p4\": 0.7300533882736988, \"phi\": 0.6285959958176558}, {\"truth_threshold\": 32.685544210259046, \"match_probability\": 0.9999999998552326, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2675.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3863.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4091465175151825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5908534526824951, \"precision\": 1.0, \"recall\": 0.4091465175151825, \"specificity\": 1.0, \"npv\": 0.9653797149658203, \"accuracy\": 0.9661902785301208, \"f1\": 0.5807011831108216, \"f2\": 0.4639747458979429, \"f0_5\": 0.7759020768070541, \"p4\": 0.7299304737752169, \"phi\": 0.6284757332043723}, {\"truth_threshold\": 32.69080903229617, \"match_probability\": 0.9999999998557599, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2674.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3864.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40899357199668884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5910063982009888, \"precision\": 1.0, \"recall\": 0.40899357199668884, \"specificity\": 1.0, \"npv\": 0.9653710722923279, \"accuracy\": 0.9661815166473389, \"f1\": 0.5805471124620061, \"f2\": 0.4638173870811073, \"f0_5\": 0.7757920389926889, \"p4\": 0.729807509696381, \"phi\": 0.6283554497299009}, {\"truth_threshold\": 32.69356592039273, \"match_probability\": 0.9999999998560353, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2673.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3865.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4088406264781952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5911594033241272, \"precision\": 1.0, \"recall\": 0.4088406264781952, \"specificity\": 1.0, \"npv\": 0.9653624296188354, \"accuracy\": 0.9661727547645569, \"f1\": 0.5803930083595701, \"f2\": 0.4636600173460538, \"f0_5\": 0.7756819500870574, \"p4\": 0.7296844960061585, \"phi\": 0.6282351453822009}, {\"truth_threshold\": 32.694283892408876, \"match_probability\": 0.9999999998561069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2671.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3867.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4085347056388855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5914652943611145, \"precision\": 1.0, \"recall\": 0.4085347056388855, \"specificity\": 1.0, \"npv\": 0.9653451442718506, \"accuracy\": 0.9661552309989929, \"f1\": 0.5800846997502443, \"f2\": 0.463345245116747, \"f0_5\": 0.7754616188595982, \"p4\": 0.7294383196672952, \"phi\": 0.6279944041732153}, {\"truth_threshold\": 32.70329997647937, \"match_probability\": 0.9999999998570034, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2666.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3872.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40776994824409485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5922300219535828, \"precision\": 1.0, \"recall\": 0.40776994824409485, \"specificity\": 1.0, \"npv\": 0.9653018712997437, \"accuracy\": 0.9661114811897278, \"f1\": 0.5793133420252065, \"f2\": 0.4625581233951003, \"f0_5\": 0.774909894198349, \"p4\": 0.7288220084436187, \"phi\": 0.6273922896649715}, {\"truth_threshold\": 32.719561128925676, \"match_probability\": 0.9999999998586061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2664.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3874.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40746405720710754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5925359725952148, \"precision\": 1.0, \"recall\": 0.40746405720710754, \"specificity\": 1.0, \"npv\": 0.9652845859527588, \"accuracy\": 0.9660939574241638, \"f1\": 0.5790045642251684, \"f2\": 0.4622431982232093, \"f0_5\": 0.7746888449459114, \"p4\": 0.72857513514859, \"phi\": 0.6271513250949664}, {\"truth_threshold\": 32.733437838153236, \"match_probability\": 0.9999999998599596, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2659.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3879.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4066992998123169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5933007001876831, \"precision\": 1.0, \"recall\": 0.4066992998123169, \"specificity\": 1.0, \"npv\": 0.9652413129806519, \"accuracy\": 0.9660502076148987, \"f1\": 0.578232032184408, \"f2\": 0.4614556940057617, \"f0_5\": 0.7741353208338185, \"p4\": 0.7279570777075623, \"phi\": 0.6265484760577673}, {\"truth_threshold\": 32.743335639869336, \"match_probability\": 0.999999999860917, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2657.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3881.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4063933789730072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5936065912246704, \"precision\": 1.0, \"recall\": 0.4063933789730072, \"specificity\": 1.0, \"npv\": 0.965224027633667, \"accuracy\": 0.9660327434539795, \"f1\": 0.5779227841218053, \"f2\": 0.46114061577979104, \"f0_5\": 0.7739135500407783, \"p4\": 0.7277095043909765, \"phi\": 0.6263071470907592}, {\"truth_threshold\": 32.74639492548454, \"match_probability\": 0.9999999998612117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2656.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3882.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40624043345451355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5937595367431641, \"precision\": 1.0, \"recall\": 0.40624043345451355, \"specificity\": 1.0, \"npv\": 0.9652153849601746, \"accuracy\": 0.9660239815711975, \"f1\": 0.5777681096367197, \"f2\": 0.4609830602610386, \"f0_5\": 0.7738025871110593, \"p4\": 0.727585642534042, \"phi\": 0.6261864859935173}, {\"truth_threshold\": 32.749767263079875, \"match_probability\": 0.9999999998615358, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2654.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3884.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40593454241752625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5940654873847961, \"precision\": 1.0, \"recall\": 0.40593454241752625, \"specificity\": 1.0, \"npv\": 0.9651980400085449, \"accuracy\": 0.9660064578056335, \"f1\": 0.5774586597040905, \"f2\": 0.4606679164063042, \"f0_5\": 0.7735805060044304, \"p4\": 0.7273377682653775, \"phi\": 0.6259451005109801}, {\"truth_threshold\": 32.767430313899084, \"match_probability\": 0.9999999998632206, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2651.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3887.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4054756760597229, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5945243239402771, \"precision\": 1.0, \"recall\": 0.4054756760597229, \"specificity\": 1.0, \"npv\": 0.9651721119880676, \"accuracy\": 0.9659802317619324, \"f1\": 0.5769942322341931, \"f2\": 0.46019511856403844, \"f0_5\": 0.7732469956831175, \"p4\": 0.7269655800020619, \"phi\": 0.6255827937806261}, {\"truth_threshold\": 32.771106427971496, \"match_probability\": 0.9999999998635687, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2646.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3892.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40471091866493225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5952890515327454, \"precision\": 1.0, \"recall\": 0.40471091866493225, \"specificity\": 1.0, \"npv\": 0.9651288986206055, \"accuracy\": 0.9659364223480225, \"f1\": 0.5762195121951219, \"f2\": 0.45940690325717065, \"f0_5\": 0.7726901062959934, \"p4\": 0.7263442591604768, \"phi\": 0.6249785726044751}, {\"truth_threshold\": 32.771996992671404, \"match_probability\": 0.999999999863653, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2642.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3896.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40409910678863525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5959008932113647, \"precision\": 1.0, \"recall\": 0.40409910678863525, \"specificity\": 1.0, \"npv\": 0.965094268321991, \"accuracy\": 0.9659014344215393, \"f1\": 0.575599128540305, \"f2\": 0.45877613391678823, \"f0_5\": 0.7722436571963054, \"p4\": 0.7258462938408399, \"phi\": 0.6244947997296172}, {\"truth_threshold\": 32.77950314619966, \"match_probability\": 0.9999999998643605, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2639.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3899.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4036402702331543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5963597297668457, \"precision\": 1.0, \"recall\": 0.4036402702331543, \"specificity\": 1.0, \"npv\": 0.9650683403015137, \"accuracy\": 0.9658751487731934, \"f1\": 0.5751334858886347, \"f2\": 0.45830294189156334, \"f0_5\": 0.7719082719082719, \"p4\": 0.7254722884709154, \"phi\": 0.6241317292057212}, {\"truth_threshold\": 32.78391843668766, \"match_probability\": 0.999999999864775, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2638.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3900.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40348729491233826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5965126752853394, \"precision\": 1.0, \"recall\": 0.40348729491233826, \"specificity\": 1.0, \"npv\": 0.9650596976280212, \"accuracy\": 0.9658664464950562, \"f1\": 0.5749782040104621, \"f2\": 0.4581451893018409, \"f0_5\": 0.7717963721474547, \"p4\": 0.7253475186288229, \"phi\": 0.6240106865167675}, {\"truth_threshold\": 32.796047468518175, \"match_probability\": 0.999999999865907, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2635.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3903.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4030284583568573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5969715714454651, \"precision\": 1.0, \"recall\": 0.4030284583568573, \"specificity\": 1.0, \"npv\": 0.965033769607544, \"accuracy\": 0.9658401608467102, \"f1\": 0.5745121552381991, \"f2\": 0.45767186577274466, \"f0_5\": 0.7714603583557794, \"p4\": 0.7249729044984493, \"phi\": 0.6236473602038536}, {\"truth_threshold\": 32.798107427995944, \"match_probability\": 0.9999999998660983, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2634.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3904.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40287548303604126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5971245169639587, \"precision\": 1.0, \"recall\": 0.40287548303604126, \"specificity\": 1.0, \"npv\": 0.9650251269340515, \"accuracy\": 0.9658313989639282, \"f1\": 0.5743567378979503, \"f2\": 0.45751406933926214, \"f0_5\": 0.771348248799344, \"p4\": 0.7248479314801746, \"phi\": 0.6235262321694639}, {\"truth_threshold\": 32.80048112430924, \"match_probability\": 0.9999999998663185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2631.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3907.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4024166464805603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5975833535194397, \"precision\": 1.0, \"recall\": 0.4024166464805603, \"specificity\": 1.0, \"npv\": 0.9649991989135742, \"accuracy\": 0.965805172920227, \"f1\": 0.5738902824735522, \"f2\": 0.45704061425146786, \"f0_5\": 0.7710116047356699, \"p4\": 0.7244727070516487, \"phi\": 0.6231627198301772}, {\"truth_threshold\": 32.80202328911765, \"match_probability\": 0.9999999998664614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2630.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3908.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40226370096206665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5977362990379333, \"precision\": 1.0, \"recall\": 0.40226370096206665, \"specificity\": 1.0, \"npv\": 0.9649905562400818, \"accuracy\": 0.9657964110374451, \"f1\": 0.5737347294938918, \"f2\": 0.4568827739559447, \"f0_5\": 0.770899284793059, \"p4\": 0.7243475303437614, \"phi\": 0.623041435888208}, {\"truth_threshold\": 32.811889025674915, \"match_probability\": 0.9999999998673714, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2628.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3910.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40195778012275696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5980421900749207, \"precision\": 1.0, \"recall\": 0.40195778012275696, \"specificity\": 1.0, \"npv\": 0.9649732708930969, \"accuracy\": 0.9657788872718811, \"f1\": 0.5734235217106699, \"f2\": 0.45656706045865186, \"f0_5\": 0.770674486803519, \"p4\": 0.7240970238872748, \"phi\": 0.622798944472279}, {\"truth_threshold\": 32.81747099639868, \"match_probability\": 0.9999999998678836, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2627.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3911.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4018048346042633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5981951951980591, \"precision\": 1.0, \"recall\": 0.4018048346042633, \"specificity\": 1.0, \"npv\": 0.9649646282196045, \"accuracy\": 0.9657701253890991, \"f1\": 0.5732678668848882, \"f2\": 0.45640918725459534, \"f0_5\": 0.7705620086823888, \"p4\": 0.7239716940741989, \"phi\": 0.6226776666111656}, {\"truth_threshold\": 32.84112310880659, \"match_probability\": 0.9999999998700319, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2620.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3918.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40073415637016296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5992658138275146, \"precision\": 1.0, \"recall\": 0.40073415637016296, \"specificity\": 1.0, \"npv\": 0.9649041295051575, \"accuracy\": 0.9657089114189148, \"f1\": 0.5721773312950426, \"f2\": 0.4553037675517865, \"f0_5\": 0.7697731813374075, \"p4\": 0.7230929527832506, \"phi\": 0.621827979202778}, {\"truth_threshold\": 32.8423863205628, \"match_probability\": 0.9999999998701457, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2619.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3919.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.4005812108516693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5994187593460083, \"precision\": 1.0, \"recall\": 0.4005812108516693, \"specificity\": 1.0, \"npv\": 0.964895486831665, \"accuracy\": 0.9657001495361328, \"f1\": 0.5720214043900841, \"f2\": 0.455145806541309, \"f0_5\": 0.7696602797696015, \"p4\": 0.7229672132674003, \"phi\": 0.6217065293441956}, {\"truth_threshold\": 32.84552967658508, \"match_probability\": 0.9999999998704282, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2618.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3920.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40042826533317566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.599571704864502, \"precision\": 1.0, \"recall\": 0.40042826533317566, \"specificity\": 1.0, \"npv\": 0.9648868441581726, \"accuracy\": 0.9656913876533508, \"f1\": 0.5718654434250765, \"f2\": 0.45498783454987834, \"f0_5\": 0.7695473251028807, \"p4\": 0.7228414223927526, \"phi\": 0.6215850579322457}, {\"truth_threshold\": 32.85182250118946, \"match_probability\": 0.9999999998709922, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2617.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3921.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.400275319814682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5997247099876404, \"precision\": 1.0, \"recall\": 0.400275319814682, \"specificity\": 1.0, \"npv\": 0.9648782014846802, \"accuracy\": 0.9656826257705688, \"f1\": 0.5717094483888585, \"f2\": 0.45482985157634953, \"f0_5\": 0.7694343172997765, \"p4\": 0.7227155801267827, \"phi\": 0.6214634944086874}, {\"truth_threshold\": 32.85700111704951, \"match_probability\": 0.9999999998714544, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2616.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3922.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.40012237429618835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.599877655506134, \"precision\": 1.0, \"recall\": 0.40012237429618835, \"specificity\": 1.0, \"npv\": 0.9648695588111877, \"accuracy\": 0.9656738638877869, \"f1\": 0.5715534192702644, \"f2\": 0.4546718576195773, \"f0_5\": 0.7693212563227856, \"p4\": 0.7225896864369384, \"phi\": 0.6213419798387336}, {\"truth_threshold\": 32.85706465267561, \"match_probability\": 0.99999999987146, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2615.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3923.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3999693989753723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6000306010246277, \"precision\": 1.0, \"recall\": 0.3999693989753723, \"specificity\": 1.0, \"npv\": 0.9648609161376953, \"accuracy\": 0.9656651020050049, \"f1\": 0.571397356058123, \"f2\": 0.45451385267841626, \"f0_5\": 0.7692081421343687, \"p4\": 0.7224637412906401, \"phi\": 0.6212204436772774}, {\"truth_threshold\": 32.869137484976186, \"match_probability\": 0.9999999998725313, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2614.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3924.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39981645345687866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6001835465431213, \"precision\": 1.0, \"recall\": 0.39981645345687866, \"specificity\": 1.0, \"npv\": 0.9648522734642029, \"accuracy\": 0.9656563997268677, \"f1\": 0.5712412587412588, \"f2\": 0.45435583675172075, \"f0_5\": 0.7690949746969519, \"p4\": 0.7223377446552804, \"phi\": 0.6210988859115851}, {\"truth_threshold\": 32.874580173147585, \"match_probability\": 0.9999999998730112, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2609.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3929.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.399051696062088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6009482741355896, \"precision\": 1.0, \"recall\": 0.399051696062088, \"specificity\": 1.0, \"npv\": 0.9648090600967407, \"accuracy\": 0.9656125903129578, \"f1\": 0.5704602601945993, \"f2\": 0.4535655922951219, \"f0_5\": 0.7685283374572877, \"p4\": 0.7217069879993826, \"phi\": 0.6204907019219661}, {\"truth_threshold\": 32.88601227635932, \"match_probability\": 0.9999999998740136, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2608.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3930.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39889875054359436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.601101279258728, \"precision\": 1.0, \"recall\": 0.39889875054359436, \"specificity\": 1.0, \"npv\": 0.9648004174232483, \"accuracy\": 0.9656038284301758, \"f1\": 0.5703039580144326, \"f2\": 0.4534075104311544, \"f0_5\": 0.7684148497348262, \"p4\": 0.7215806817433602, \"phi\": 0.6203689435852259}, {\"truth_threshold\": 32.88692897035127, \"match_probability\": 0.9999999998740936, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2607.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3931.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3987458050251007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6012542247772217, \"precision\": 1.0, \"recall\": 0.3987458050251007, \"specificity\": 1.0, \"npv\": 0.9647917747497559, \"accuracy\": 0.9655951261520386, \"f1\": 0.5701476216511755, \"f2\": 0.45324941757362913, \"f0_5\": 0.7683013084993516, \"p4\": 0.7214543237692533, \"phi\": 0.6202472342058436}, {\"truth_threshold\": 32.894997575888, \"match_probability\": 0.9999999998747957, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2604.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3934.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39828693866729736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6017130613327026, \"precision\": 1.0, \"recall\": 0.39828693866729736, \"specificity\": 1.0, \"npv\": 0.9647658467292786, \"accuracy\": 0.9655688405036926, \"f1\": 0.5696784073506891, \"f2\": 0.4527750730282376, \"f0_5\": 0.7679603633360859, \"p4\": 0.7210749392100042, \"phi\": 0.6198819757769412}, {\"truth_threshold\": 32.89813154528051, \"match_probability\": 0.9999999998750675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2601.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3937.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.397828072309494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6021718978881836, \"precision\": 1.0, \"recall\": 0.397828072309494, \"specificity\": 1.0, \"npv\": 0.9647399187088013, \"accuracy\": 0.9655426144599915, \"f1\": 0.5692088849983586, \"f2\": 0.4523006294995305, \"f0_5\": 0.7676189351906505, \"p4\": 0.7206950880045068, \"phi\": 0.6195164508846662}, {\"truth_threshold\": 32.910991512443026, \"match_probability\": 0.9999999998761762, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2600.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3938.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39767512679100037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6023248434066772, \"precision\": 1.0, \"recall\": 0.39767512679100037, \"specificity\": 1.0, \"npv\": 0.9647312760353088, \"accuracy\": 0.9655338525772095, \"f1\": 0.569052309039177, \"f2\": 0.4521424596549805, \"f0_5\": 0.7675050183020428, \"p4\": 0.7205683670830579, \"phi\": 0.6193945892759062}, {\"truth_threshold\": 32.91595834172918, \"match_probability\": 0.9999999998766017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2599.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3939.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3975221812725067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6024778485298157, \"precision\": 1.0, \"recall\": 0.3975221812725067, \"specificity\": 1.0, \"npv\": 0.9647226333618164, \"accuracy\": 0.9655250906944275, \"f1\": 0.5688956988070483, \"f2\": 0.45198427880769365, \"f0_5\": 0.7673910475965513, \"p4\": 0.7204415941801185, \"phi\": 0.6192727058704078}, {\"truth_threshold\": 32.922449358121, \"match_probability\": 0.9999999998771556, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2597.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3941.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.397216260433197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.602783739566803, \"precision\": 1.0, \"recall\": 0.397216260433197, \"specificity\": 1.0, \"npv\": 0.9647053480148315, \"accuracy\": 0.9655075669288635, \"f1\": 0.5685823754789272, \"f2\": 0.45166788410031655, \"f0_5\": 0.7671629445822994, \"p4\": 0.7201878922975345, \"phi\": 0.6190288028071357}, {\"truth_threshold\": 32.9260120063931, \"match_probability\": 0.9999999998774586, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2595.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3943.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3969103693962097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6030896306037903, \"precision\": 1.0, \"recall\": 0.3969103693962097, \"specificity\": 1.0, \"npv\": 0.9646880626678467, \"accuracy\": 0.9654901027679443, \"f1\": 0.5682689149239023, \"f2\": 0.4513514453682123, \"f0_5\": 0.7669346258422981, \"p4\": 0.7199339820920073, \"phi\": 0.61878488318525}, {\"truth_threshold\": 32.93106523411939, \"match_probability\": 0.9999999998778871, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2593.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3945.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3966044783592224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6033955216407776, \"precision\": 1.0, \"recall\": 0.3966044783592224, \"specificity\": 1.0, \"npv\": 0.9646707773208618, \"accuracy\": 0.9654725790023804, \"f1\": 0.5679553170518016, \"f2\": 0.45103496260219167, \"f0_5\": 0.7667060910703726, \"p4\": 0.7196798632983403, \"phi\": 0.6185408052535953}, {\"truth_threshold\": 32.932753584272156, \"match_probability\": 0.9999999998780299, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2590.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3948.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39614561200141907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6038544178009033, \"precision\": 1.0, \"recall\": 0.39614561200141907, \"specificity\": 1.0, \"npv\": 0.9646449089050293, \"accuracy\": 0.9654462933540344, \"f1\": 0.5674846625766872, \"f2\": 0.4505601558694593, \"f0_5\": 0.7663628831814416, \"p4\": 0.7192982934238524, \"phi\": 0.6181746304224813}, {\"truth_threshold\": 32.94371099056849, \"match_probability\": 0.9999999998789528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2589.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3949.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3959926664829254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.604007363319397, \"precision\": 1.0, \"recall\": 0.3959926664829254, \"specificity\": 1.0, \"npv\": 0.9646362662315369, \"accuracy\": 0.9654375910758972, \"f1\": 0.5673277089952887, \"f2\": 0.45040186493163076, \"f0_5\": 0.766248372203149, \"p4\": 0.7191709988835494, \"phi\": 0.6180524573924728}, {\"truth_threshold\": 32.955341815756036, \"match_probability\": 0.9999999998799247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2588.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3950.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39583972096443176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6041603088378906, \"precision\": 1.0, \"recall\": 0.39583972096443176, \"specificity\": 1.0, \"npv\": 0.9646276235580444, \"accuracy\": 0.9654288291931152, \"f1\": 0.5671707210168748, \"f2\": 0.45024356297842727, \"f0_5\": 0.7661338069863824, \"p4\": 0.7190436519966449, \"phi\": 0.6179303333264964}, {\"truth_threshold\": 32.95660032622652, \"match_probability\": 0.9999999998800294, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2587.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3951.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3956867456436157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6043132543563843, \"precision\": 1.0, \"recall\": 0.3956867456436157, \"specificity\": 1.0, \"npv\": 0.964618980884552, \"accuracy\": 0.9654200673103333, \"f1\": 0.567013698630137, \"f2\": 0.450085250008699, \"f0_5\": 0.7660191874925975, \"p4\": 0.7189162527297779, \"phi\": 0.6178081873077568}, {\"truth_threshold\": 32.96474051375829, \"match_probability\": 0.9999999998807044, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2583.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3955.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3950749337673187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6049250364303589, \"precision\": 1.0, \"recall\": 0.3950749337673187, \"specificity\": 1.0, \"npv\": 0.9645844101905823, \"accuracy\": 0.9653850793838501, \"f1\": 0.5663852647735994, \"f2\": 0.44945188794153473, \"f0_5\": 0.7655601659751037, \"p4\": 0.7184061311944682, \"phi\": 0.6173193124458229}, {\"truth_threshold\": 32.97105439024989, \"match_probability\": 0.9999999998812253, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2579.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3959.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3944631516933441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6055368781089783, \"precision\": 1.0, \"recall\": 0.3944631516933441, \"specificity\": 1.0, \"npv\": 0.9645498394966125, \"accuracy\": 0.9653500318527222, \"f1\": 0.5657562794778984, \"f2\": 0.4488183495179423, \"f0_5\": 0.7651002729322416, \"p4\": 0.7178951689034829, \"phi\": 0.6168300851832916}, {\"truth_threshold\": 32.9814953770641, \"match_probability\": 0.9999999998820819, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2578.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3960.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3943101763725281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6056898236274719, \"precision\": 1.0, \"recall\": 0.3943101763725281, \"specificity\": 1.0, \"npv\": 0.9645412564277649, \"accuracy\": 0.9653412699699402, \"f1\": 0.565598946906538, \"f2\": 0.44865993734772014, \"f0_5\": 0.7649851632047477, \"p4\": 0.7177672967110141, \"phi\": 0.61670774097254}, {\"truth_threshold\": 32.981814027117224, \"match_probability\": 0.9999999998821079, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2577.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3961.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3941572308540344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6058427691459656, \"precision\": 1.0, \"recall\": 0.3941572308540344, \"specificity\": 1.0, \"npv\": 0.9645326137542725, \"accuracy\": 0.965332567691803, \"f1\": 0.5654415798134942, \"f2\": 0.4485015141494657, \"f0_5\": 0.7648699988127745, \"p4\": 0.7176393718034074, \"phi\": 0.6165853746776151}, {\"truth_threshold\": 32.983790509603864, \"match_probability\": 0.9999999998822693, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2576.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3962.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39400428533554077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6059957146644592, \"precision\": 1.0, \"recall\": 0.39400428533554077, \"specificity\": 1.0, \"npv\": 0.96452397108078, \"accuracy\": 0.965323805809021, \"f1\": 0.565284178187404, \"f2\": 0.44834307992202727, \"f0_5\": 0.7647547797173733, \"p4\": 0.7175113941469882, \"phi\": 0.6164629862853069}, {\"truth_threshold\": 32.98563573806963, \"match_probability\": 0.9999999998824198, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2575.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3963.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3938513398170471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6061486601829529, \"precision\": 1.0, \"recall\": 0.3938513398170471, \"specificity\": 1.0, \"npv\": 0.9645153284072876, \"accuracy\": 0.965315043926239, \"f1\": 0.5651267420168989, \"f2\": 0.4481846346642531, \"f0_5\": 0.7646395058795581, \"p4\": 0.7173833637080532, \"phi\": 0.6163405046772267}, {\"truth_threshold\": 32.99124970647729, \"match_probability\": 0.9999999998828765, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2574.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3964.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3936983644962311, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6063016057014465, \"precision\": 1.0, \"recall\": 0.3936983644962311, \"specificity\": 1.0, \"npv\": 0.9645066857337952, \"accuracy\": 0.965306282043457, \"f1\": 0.5649692712906058, \"f2\": 0.4480261783749913, \"f0_5\": 0.7645241772603065, \"p4\": 0.7172552804528703, \"phi\": 0.6162180720369786}, {\"truth_threshold\": 32.994201175746106, \"match_probability\": 0.9999999998831158, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2573.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3965.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3935454189777374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6064545512199402, \"precision\": 1.0, \"recall\": 0.3935454189777374, \"specificity\": 1.0, \"npv\": 0.9644980430603027, \"accuracy\": 0.965297520160675, \"f1\": 0.5648117659971463, \"f2\": 0.44786771105308965, \"f0_5\": 0.7644087938205585, \"p4\": 0.7171271443476791, \"phi\": 0.6160956172596327}, {\"truth_threshold\": 32.9980432420405, \"match_probability\": 0.9999999998834267, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2571.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3967.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3932395279407501, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6067605018615723, \"precision\": 1.0, \"recall\": 0.3932395279407501, \"specificity\": 1.0, \"npv\": 0.9644807577133179, \"accuracy\": 0.9652800559997559, \"f1\": 0.5644966516631903, \"f2\": 0.44755074330675765, \"f0_5\": 0.7641778623231482, \"p4\": 0.7168707134520846, \"phi\": 0.6158505700814051}, {\"truth_threshold\": 32.99842050192115, \"match_probability\": 0.9999999998834571, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2570.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3968.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39308658242225647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6069134473800659, \"precision\": 1.0, \"recall\": 0.39308658242225647, \"specificity\": 1.0, \"npv\": 0.9644721150398254, \"accuracy\": 0.9652712941169739, \"f1\": 0.5643390425999122, \"f2\": 0.4473922428800223, \"f0_5\": 0.7640623141871804, \"p4\": 0.7167424185940161, \"phi\": 0.615728048799621}, {\"truth_threshold\": 33.009067746120664, \"match_probability\": 0.9999999998843141, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2567.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3971.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3926277160644531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6073722839355469, \"precision\": 1.0, \"recall\": 0.3926277160644531, \"specificity\": 1.0, \"npv\": 0.9644462466239929, \"accuracy\": 0.9652450084686279, \"f1\": 0.5638660076880835, \"f2\": 0.44691667537170515, \"f0_5\": 0.7637153397596097, \"p4\": 0.7163572159721271, \"phi\": 0.6153603517596272}, {\"truth_threshold\": 33.01280166891367, \"match_probability\": 0.9999999998846131, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2565.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3973.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3923218250274658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6076781749725342, \"precision\": 1.0, \"recall\": 0.3923218250274658, \"specificity\": 1.0, \"npv\": 0.9644289612770081, \"accuracy\": 0.965227484703064, \"f1\": 0.5635504778644403, \"f2\": 0.4465995751645367, \"f0_5\": 0.7634837480652459, \"p4\": 0.7161001488450548, \"phi\": 0.6151150380303532}, {\"truth_threshold\": 33.04148922381304, \"match_probability\": 0.9999999998868849, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2557.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3981.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3910982012748718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6089017987251282, \"precision\": 1.0, \"recall\": 0.3910982012748718, \"specificity\": 1.0, \"npv\": 0.9643598794937134, \"accuracy\": 0.9651575088500977, \"f1\": 0.5622869708631116, \"f2\": 0.44533073252290223, \"f0_5\": 0.7625551711797686, \"p4\": 0.7150697514028881, \"phi\": 0.6141330339187322}, {\"truth_threshold\": 33.04950752494362, \"match_probability\": 0.9999999998875119, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2556.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3982.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3909452557563782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6090547442436218, \"precision\": 1.0, \"recall\": 0.3909452557563782, \"specificity\": 1.0, \"npv\": 0.964351236820221, \"accuracy\": 0.9651487469673157, \"f1\": 0.5621288761820981, \"f2\": 0.44517207746969484, \"f0_5\": 0.7624388497792626, \"p4\": 0.7149407116541732, \"phi\": 0.6140102007165696}, {\"truth_threshold\": 33.05613599977744, \"match_probability\": 0.9999999998880275, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2553.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3985.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39048638939857483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6095136404037476, \"precision\": 1.0, \"recall\": 0.39048638939857483, \"specificity\": 1.0, \"npv\": 0.9643253684043884, \"accuracy\": 0.9651224613189697, \"f1\": 0.5616543834561655, \"f2\": 0.44469604598502005, \"f0_5\": 0.7620895522388059, \"p4\": 0.7145532714948498, \"phi\": 0.6136414953852602}, {\"truth_threshold\": 33.0642761873092, \"match_probability\": 0.9999999998886575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2551.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3987.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.39018046855926514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6098195314407349, \"precision\": 1.0, \"recall\": 0.39018046855926514, \"specificity\": 1.0, \"npv\": 0.9643080830574036, \"accuracy\": 0.9651049971580505, \"f1\": 0.5613378809550006, \"f2\": 0.4443786363794725, \"f0_5\": 0.761856409031179, \"p4\": 0.7142947102841597, \"phi\": 0.613395627336987}, {\"truth_threshold\": 33.06900976339465, \"match_probability\": 0.9999999998890222, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2550.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3988.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3900275230407715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6099724769592285, \"precision\": 1.0, \"recall\": 0.3900275230407715, \"specificity\": 1.0, \"npv\": 0.9642994403839111, \"accuracy\": 0.9650962352752686, \"f1\": 0.5611795774647887, \"f2\": 0.44421991498850255, \"f0_5\": 0.761739753853507, \"p4\": 0.7141653492442702, \"phi\": 0.6132726596514424}, {\"truth_threshold\": 33.08306832756443, \"match_probability\": 0.9999999998900984, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2549.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3989.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38987457752227783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6101254224777222, \"precision\": 1.0, \"recall\": 0.38987457752227783, \"specificity\": 1.0, \"npv\": 0.9642908573150635, \"accuracy\": 0.9650874733924866, \"f1\": 0.5610212391328271, \"f2\": 0.44406118253719384, \"f0_5\": 0.761623042906657, \"p4\": 0.7140359345354146, \"phi\": 0.6131496695068789}, {\"truth_threshold\": 33.09152990631263, \"match_probability\": 0.9999999998907411, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2548.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3990.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3897216320037842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6102783679962158, \"precision\": 1.0, \"recall\": 0.3897216320037842, \"specificity\": 1.0, \"npv\": 0.964282214641571, \"accuracy\": 0.9650787115097046, \"f1\": 0.5608628659476117, \"f2\": 0.44390243902439025, \"f0_5\": 0.7615062761506276, \"p4\": 0.7139064661231039, \"phi\": 0.6130265854174505}, {\"truth_threshold\": 33.1200990585094, \"match_probability\": 0.9999999998928835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2547.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3991.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3895686864852905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6104313135147095, \"precision\": 1.0, \"recall\": 0.3895686864852905, \"specificity\": 1.0, \"npv\": 0.9642735719680786, \"accuracy\": 0.9650699496269226, \"f1\": 0.5607044578976335, \"f2\": 0.4437436844489355, \"f0_5\": 0.7613894535453785, \"p4\": 0.7137769439728194, \"phi\": 0.6129035503003959}, {\"truth_threshold\": 33.13761457898138, \"match_probability\": 0.999999999894176, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2546.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3992.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3894157111644745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6105842590332031, \"precision\": 1.0, \"recall\": 0.3894157111644745, \"specificity\": 1.0, \"npv\": 0.9642649292945862, \"accuracy\": 0.9650612473487854, \"f1\": 0.5605460149713782, \"f2\": 0.44358491880967316, \"f0_5\": 0.7612725750508312, \"p4\": 0.7136473680500129, \"phi\": 0.6127804926835435}, {\"truth_threshold\": 33.139399091286045, \"match_probability\": 0.9999999998943069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2545.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3993.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38926276564598083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6107372045516968, \"precision\": 1.0, \"recall\": 0.38926276564598083, \"specificity\": 1.0, \"npv\": 0.9642562866210938, \"accuracy\": 0.9650524854660034, \"f1\": 0.5603875371573269, \"f2\": 0.44342614210544656, \"f0_5\": 0.7611556406268692, \"p4\": 0.7135177383201065, \"phi\": 0.6126574125532763}, {\"truth_threshold\": 33.14924540416892, \"match_probability\": 0.9999999998950257, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2543.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3995.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38895687460899353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6110431551933289, \"precision\": 1.0, \"recall\": 0.38895687460899353, \"specificity\": 1.0, \"npv\": 0.9642390608787537, \"accuracy\": 0.9650349617004395, \"f1\": 0.5600704768197335, \"f2\": 0.4431085554974734, \"f0_5\": 0.7609216038300419, \"p4\": 0.7132583173005339, \"phi\": 0.6124111131570651}, {\"truth_threshold\": 33.15647260464499, \"match_probability\": 0.9999999998955503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2541.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 3997.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38865095376968384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6113490462303162, \"precision\": 1.0, \"recall\": 0.38865095376968384, \"specificity\": 1.0, \"npv\": 0.9642217755317688, \"accuracy\": 0.9650174379348755, \"f1\": 0.5597532767925983, \"f2\": 0.4427909246157599, \"f0_5\": 0.7606873428331936, \"p4\": 0.7129986806368858, \"phi\": 0.6121647950568432}, {\"truth_threshold\": 33.159020115780656, \"match_probability\": 0.9999999998957346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2538.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4000.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3881921172142029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6118078827857971, \"precision\": 1.0, \"recall\": 0.3881921172142029, \"specificity\": 1.0, \"npv\": 0.9641959071159363, \"accuracy\": 0.9649912118911743, \"f1\": 0.5592772146319964, \"f2\": 0.44231439525967237, \"f0_5\": 0.7603355302576393, \"p4\": 0.7126088207011898, \"phi\": 0.6117950768996784}, {\"truth_threshold\": 33.16941166035249, \"match_probability\": 0.9999999998964829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2537.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4001.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38803914189338684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6119608283042908, \"precision\": 1.0, \"recall\": 0.38803914189338684, \"specificity\": 1.0, \"npv\": 0.9641872644424438, \"accuracy\": 0.9649824500083923, \"f1\": 0.5591184573002754, \"f2\": 0.44215552999407437, \"f0_5\": 0.7602181469495385, \"p4\": 0.7124787592661174, \"phi\": 0.6116718161426828}, {\"truth_threshold\": 33.19099418424258, \"match_probability\": 0.9999999998980199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2536.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4002.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3878861963748932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6121137738227844, \"precision\": 1.0, \"recall\": 0.3878861963748932, \"specificity\": 1.0, \"npv\": 0.9641786217689514, \"accuracy\": 0.9649736881256104, \"f1\": 0.558959664976857, \"f2\": 0.4419966536530954, \"f0_5\": 0.7601007073492387, \"p4\": 0.7123486437114066, \"phi\": 0.6115485327490965}, {\"truth_threshold\": 33.222457970896144, \"match_probability\": 0.9999999999002199, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2535.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4003.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38773325085639954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6122667193412781, \"precision\": 1.0, \"recall\": 0.38773325085639954, \"specificity\": 1.0, \"npv\": 0.964169979095459, \"accuracy\": 0.9649649262428284, \"f1\": 0.5588008376501709, \"f2\": 0.4418377662355771, \"f0_5\": 0.7599832114162369, \"p4\": 0.7122184740021817, \"phi\": 0.6114252267051674}, {\"truth_threshold\": 33.222503476567894, \"match_probability\": 0.9999999999002231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2534.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4004.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3875803053379059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6124197244644165, \"precision\": 1.0, \"recall\": 0.3875803053379059, \"specificity\": 1.0, \"npv\": 0.9641613364219666, \"accuracy\": 0.9649562239646912, \"f1\": 0.558641975308642, \"f2\": 0.44167886774036114, \"f0_5\": 0.7598656591099916, \"p4\": 0.7120882501035373, \"phi\": 0.6113018263321858}, {\"truth_threshold\": 33.22664383757343, \"match_probability\": 0.999999999900509, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2533.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4005.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38742735981941223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6125726699829102, \"precision\": 1.0, \"recall\": 0.38742735981941223, \"specificity\": 1.0, \"npv\": 0.9641527533531189, \"accuracy\": 0.9649474620819092, \"f1\": 0.5584830779406901, \"f2\": 0.44151995816628903, \"f0_5\": 0.759748050389922, \"p4\": 0.7119579719805376, \"phi\": 0.6111784749324359}, {\"truth_threshold\": 33.22790234804392, \"match_probability\": 0.9999999999005958, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2532.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4006.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3872743844985962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6127256155014038, \"precision\": 1.0, \"recall\": 0.3872743844985962, \"specificity\": 1.0, \"npv\": 0.9641441106796265, \"accuracy\": 0.9649387001991272, \"f1\": 0.5583241455347299, \"f2\": 0.4413610375122019, \"f0_5\": 0.7596303852154086, \"p4\": 0.7118276395982168, \"phi\": 0.6110551008409966}, {\"truth_threshold\": 33.237150252532295, \"match_probability\": 0.999999999901231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2531.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4007.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38712143898010254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6128785610198975, \"precision\": 1.0, \"recall\": 0.38712143898010254, \"specificity\": 1.0, \"npv\": 0.964135468006134, \"accuracy\": 0.9649299383163452, \"f1\": 0.5581651780791708, \"f2\": 0.441202105776941, \"f0_5\": 0.7595126635457928, \"p4\": 0.7116972529215795, \"phi\": 0.6109317040440615}, {\"truth_threshold\": 33.24682491543766, \"match_probability\": 0.9999999999018911, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2530.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4008.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3869684934616089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6130315065383911, \"precision\": 1.0, \"recall\": 0.3869684934616089, \"specificity\": 1.0, \"npv\": 0.9641268253326416, \"accuracy\": 0.9649211764335632, \"f1\": 0.5580061755624173, \"f2\": 0.4410431629593473, \"f0_5\": 0.759394885340377, \"p4\": 0.7115668119155997, \"phi\": 0.6108082128075204}, {\"truth_threshold\": 33.25616060808543, \"match_probability\": 0.9999999999025239, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2527.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4011.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38650962710380554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6134903430938721, \"precision\": 1.0, \"recall\": 0.38650962710380554, \"specificity\": 1.0, \"npv\": 0.9641009569168091, \"accuracy\": 0.9648949503898621, \"f1\": 0.5575289575289575, \"f2\": 0.4405662680009763, \"f0_5\": 0.7590412111017661, \"p4\": 0.7111751625708951, \"phi\": 0.6104378177628623}, {\"truth_threshold\": 33.2633878085615, \"match_probability\": 0.999999999903011, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2526.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4012.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3863566815853119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6136432886123657, \"precision\": 1.0, \"recall\": 0.3863566815853119, \"specificity\": 1.0, \"npv\": 0.9640923142433167, \"accuracy\": 0.9648861885070801, \"f1\": 0.557369814651368, \"f2\": 0.4404072808424576, \"f0_5\": 0.7589232063453912, \"p4\": 0.7110445038966843, \"phi\": 0.6103143072169854}, {\"truth_threshold\": 33.266897595926345, \"match_probability\": 0.9999999999032466, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2524.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4014.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3860507905483246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6139492392539978, \"precision\": 1.0, \"recall\": 0.3860507905483246, \"specificity\": 1.0, \"npv\": 0.9640750885009766, \"accuracy\": 0.9648686647415161, \"f1\": 0.5570514235268152, \"f2\": 0.4400892732598689, \"f0_5\": 0.7586870265720813, \"p4\": 0.7107830229982839, \"phi\": 0.6100671459418746}, {\"truth_threshold\": 33.272102151954456, \"match_probability\": 0.9999999999035951, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2523.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4015.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38589781522750854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6141021847724915, \"precision\": 1.0, \"recall\": 0.38589781522750854, \"specificity\": 1.0, \"npv\": 0.9640664458274841, \"accuracy\": 0.9648599028587341, \"f1\": 0.5568921752565942, \"f2\": 0.43993025283347864, \"f0_5\": 0.7585688514732412, \"p4\": 0.7106522007036498, \"phi\": 0.6099435669744708}, {\"truth_threshold\": 33.29239896787131, \"match_probability\": 0.9999999999049418, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2521.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4017.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38559192419052124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6144080758094788, \"precision\": 1.0, \"recall\": 0.38559192419052124, \"specificity\": 1.0, \"npv\": 0.9640491604804993, \"accuracy\": 0.9648424386978149, \"f1\": 0.5565735732420797, \"f2\": 0.43961217870470476, \"f0_5\": 0.7583323306461316, \"p4\": 0.7103903922471756, \"phi\": 0.6096962686892432}, {\"truth_threshold\": 33.29994114893711, \"match_probability\": 0.9999999999054375, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2520.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4018.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3854389786720276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6145610213279724, \"precision\": 1.0, \"recall\": 0.3854389786720276, \"specificity\": 1.0, \"npv\": 0.9640405774116516, \"accuracy\": 0.964833676815033, \"f1\": 0.5564142194744977, \"f2\": 0.439453125, \"f0_5\": 0.7582139848357203, \"p4\": 0.7102594060147089, \"phi\": 0.6095726211748876}, {\"truth_threshold\": 33.30124849761397, \"match_probability\": 0.9999999999055231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2519.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4019.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38528603315353394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6147139668464661, \"precision\": 1.0, \"recall\": 0.38528603315353394, \"specificity\": 1.0, \"npv\": 0.9640319347381592, \"accuracy\": 0.964824914932251, \"f1\": 0.5562548305178315, \"f2\": 0.4392940602002023, \"f0_5\": 0.758095582039244, \"p4\": 0.7101283650656208, \"phi\": 0.6094489507882578}, {\"truth_threshold\": 33.31476678089976, \"match_probability\": 0.9999999999064043, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2518.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4020.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3851330578327179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6148669123649597, \"precision\": 1.0, \"recall\": 0.3851330578327179, \"specificity\": 1.0, \"npv\": 0.9640232920646667, \"accuracy\": 0.964816153049469, \"f1\": 0.556095406360424, \"f2\": 0.43913498430415066, \"f0_5\": 0.7579771222155328, \"p4\": 0.7099972693645219, \"phi\": 0.6093252575153676}, {\"truth_threshold\": 33.3263976060873, \"match_probability\": 0.9999999999071558, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2516.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4022.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3848271667957306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6151728630065918, \"precision\": 1.0, \"recall\": 0.3848271667957306, \"specificity\": 1.0, \"npv\": 0.9640060663223267, \"accuracy\": 0.964798629283905, \"f1\": 0.5557764523967307, \"f2\": 0.438816799218641, \"f0_5\": 0.7577400313215276, \"p4\": 0.7097349135645813, \"phi\": 0.6090777303397451}, {\"truth_threshold\": 33.33472976380103, \"match_probability\": 0.9999999999076905, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2515.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4023.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38467422127723694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6153258085250854, \"precision\": 1.0, \"recall\": 0.38467422127723694, \"specificity\": 1.0, \"npv\": 0.9639974236488342, \"accuracy\": 0.9647899270057678, \"f1\": 0.5556169225671048, \"f2\": 0.43865769002686017, \"f0_5\": 0.7576214001686951, \"p4\": 0.7096036533948081, \"phi\": 0.608953968310044}, {\"truth_threshold\": 33.344384106501934, \"match_probability\": 0.9999999999083061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2510.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4028.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3839094638824463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6160905361175537, \"precision\": 1.0, \"recall\": 0.3839094638824463, \"specificity\": 1.0, \"npv\": 0.9639542698860168, \"accuracy\": 0.9647461175918579, \"f1\": 0.5548187444739169, \"f2\": 0.437861977531226, \"f0_5\": 0.7570273856918808, \"p4\": 0.7089465284265282, \"phi\": 0.6083347417458997}, {\"truth_threshold\": 33.346360588988574, \"match_probability\": 0.9999999999084317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2508.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4030.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3836035430431366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.616396427154541, \"precision\": 1.0, \"recall\": 0.3836035430431366, \"specificity\": 1.0, \"npv\": 0.9639370441436768, \"accuracy\": 0.9647286534309387, \"f1\": 0.554499226177316, \"f2\": 0.43754361479413817, \"f0_5\": 0.7567893783946892, \"p4\": 0.7086832931854103, \"phi\": 0.608086918901066}, {\"truth_threshold\": 33.356368189073414, \"match_probability\": 0.9999999999090646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2507.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4031.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38345059752464294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6165494322776794, \"precision\": 1.0, \"recall\": 0.38345059752464294, \"specificity\": 1.0, \"npv\": 0.9639284014701843, \"accuracy\": 0.9647198915481567, \"f1\": 0.5543394140409066, \"f2\": 0.4373844167626226, \"f0_5\": 0.7566702885427985, \"p4\": 0.708551592867742, \"phi\": 0.6079629008830308}, {\"truth_threshold\": 33.35876337031955, \"match_probability\": 0.9999999999092155, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2506.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4032.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3832976520061493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6167023777961731, \"precision\": 1.0, \"recall\": 0.3832976520061493, \"specificity\": 1.0, \"npv\": 0.9639197587966919, \"accuracy\": 0.9647111296653748, \"f1\": 0.5541795665634675, \"f2\": 0.43722520762090866, \"f0_5\": 0.7565511411665258, \"p4\": 0.7084198373710008, \"phi\": 0.6078389318368583}, {\"truth_threshold\": 33.36000700031783, \"match_probability\": 0.9999999999092938, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2504.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4034.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3829917311668396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6170082688331604, \"precision\": 1.0, \"recall\": 0.3829917311668396, \"specificity\": 1.0, \"npv\": 0.9639025330543518, \"accuracy\": 0.9646936058998108, \"f1\": 0.5538597655385976, \"f2\": 0.4369067560022334, \"f0_5\": 0.7563126736740365, \"p4\": 0.7081561606971141, \"phi\": 0.6075909245221891}, {\"truth_threshold\": 33.365924174310976, \"match_probability\": 0.999999999909665, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2503.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4035.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38283878564834595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.617161214351654, \"precision\": 1.0, \"recall\": 0.38283878564834595, \"specificity\": 1.0, \"npv\": 0.9638938903808594, \"accuracy\": 0.9646849036216736, \"f1\": 0.5536998119677027, \"f2\": 0.4367475135229454, \"f0_5\": 0.7561933534743203, \"p4\": 0.7080242394482984, \"phi\": 0.607466886225312}, {\"truth_threshold\": 33.37163782550537, \"match_probability\": 0.9999999999100221, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2502.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4036.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3826858401298523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6173141598701477, \"precision\": 1.0, \"recall\": 0.3826858401298523, \"specificity\": 1.0, \"npv\": 0.9638853073120117, \"accuracy\": 0.9646761417388916, \"f1\": 0.5535398230088495, \"f2\": 0.43658825992880573, \"f0_5\": 0.7560739755832225, \"p4\": 0.7078922628770695, \"phi\": 0.6073427527050126}, {\"truth_threshold\": 33.372355797521514, \"match_probability\": 0.9999999999100668, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2501.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4037.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38253289461135864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6174671053886414, \"precision\": 1.0, \"recall\": 0.38253289461135864, \"specificity\": 1.0, \"npv\": 0.9638766646385193, \"accuracy\": 0.9646673798561096, \"f1\": 0.5533797986502932, \"f2\": 0.43642899521865075, \"f0_5\": 0.7559545399588925, \"p4\": 0.707760230947515, \"phi\": 0.6072186681558732}, {\"truth_threshold\": 33.37865305972702, \"match_probability\": 0.9999999999104585, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2498.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4040.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3820740282535553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6179259419441223, \"precision\": 1.0, \"recall\": 0.3820740282535553, \"specificity\": 1.0, \"npv\": 0.9638507962226868, \"accuracy\": 0.9646410942077637, \"f1\": 0.5528995130588756, \"f2\": 0.43595113438045374, \"f0_5\": 0.7555958862673926, \"p4\": 0.7073638026493038, \"phi\": 0.6068462034408744}, {\"truth_threshold\": 33.37886502598143, \"match_probability\": 0.9999999999104717, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2496.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4042.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.381768137216568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6182318925857544, \"precision\": 1.0, \"recall\": 0.381768137216568, \"specificity\": 1.0, \"npv\": 0.9638335108757019, \"accuracy\": 0.9646236300468445, \"f1\": 0.5525791454505202, \"f2\": 0.4356325048869031, \"f0_5\": 0.7553564943711415, \"p4\": 0.7070992396657363, \"phi\": 0.606597825822048}, {\"truth_threshold\": 33.38042440305824, \"match_probability\": 0.9999999999105684, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2493.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4045.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38130927085876465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6186907291412354, \"precision\": 1.0, \"recall\": 0.38130927085876465, \"specificity\": 1.0, \"npv\": 0.9638076424598694, \"accuracy\": 0.9645973443984985, \"f1\": 0.5520983279813975, \"f2\": 0.4351544772211555, \"f0_5\": 0.7549969715324046, \"p4\": 0.706701978291566, \"phi\": 0.6062250130303464}, {\"truth_threshold\": 33.3854436250304, \"match_probability\": 0.999999999910879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2490.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4048.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3808504045009613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6191495656967163, \"precision\": 1.0, \"recall\": 0.3808504045009613, \"specificity\": 1.0, \"npv\": 0.9637817740440369, \"accuracy\": 0.9645711183547974, \"f1\": 0.5516171909614532, \"f2\": 0.43467634941694017, \"f0_5\": 0.7546369256879621, \"p4\": 0.7063042157707327, \"phi\": 0.6058520270000334}, {\"truth_threshold\": 33.39972520091721, \"match_probability\": 0.9999999999117569, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2486.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4052.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3802385926246643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6197614073753357, \"precision\": 1.0, \"recall\": 0.3802385926246643, \"specificity\": 1.0, \"npv\": 0.9637473225593567, \"accuracy\": 0.9645360708236694, \"f1\": 0.5509751773049646, \"f2\": 0.4340386898526433, \"f0_5\": 0.7541560490231768, \"p4\": 0.7057730844891498, \"phi\": 0.605354398042828}, {\"truth_threshold\": 33.403142609205794, \"match_probability\": 0.9999999999119656, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2485.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4053.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.38008564710617065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6199143528938293, \"precision\": 1.0, \"recall\": 0.38008564710617065, \"specificity\": 1.0, \"npv\": 0.9637386798858643, \"accuracy\": 0.9645273089408875, \"f1\": 0.5508145849495734, \"f2\": 0.4338792471278416, \"f0_5\": 0.754035683942226, \"p4\": 0.7056401619168076, \"phi\": 0.6052299053092018}, {\"truth_threshold\": 33.40628720575613, \"match_probability\": 0.9999999999121574, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2484.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4054.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.379932701587677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.620067298412323, \"precision\": 1.0, \"recall\": 0.379932701587677, \"specificity\": 1.0, \"npv\": 0.9637300372123718, \"accuracy\": 0.9645186066627502, \"f1\": 0.5506539569940146, \"f2\": 0.4337197932672161, \"f0_5\": 0.7539152604103436, \"p4\": 0.7055071833708432, \"phi\": 0.6051054253742801}, {\"truth_threshold\": 33.40787618529124, \"match_probability\": 0.9999999999122541, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2482.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4056.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3796268105506897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6203731894493103, \"precision\": 1.0, \"recall\": 0.3796268105506897, \"specificity\": 1.0, \"npv\": 0.9637128114700317, \"accuracy\": 0.9645010828971863, \"f1\": 0.5503325942350332, \"f2\": 0.4334008521338269, \"f0_5\": 0.7536742378233937, \"p4\": 0.7052410582121074, \"phi\": 0.604856359138195}, {\"truth_threshold\": 33.421066387555584, \"match_probability\": 0.9999999999130527, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2479.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4059.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37916794419288635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.620832085609436, \"precision\": 1.0, \"recall\": 0.37916794419288635, \"specificity\": 1.0, \"npv\": 0.9636869430541992, \"accuracy\": 0.9644747972488403, \"f1\": 0.5498502827991572, \"f2\": 0.4329223568858929, \"f0_5\": 0.7533122644949556, \"p4\": 0.7048414497588781, \"phi\": 0.6044826022003099}, {\"truth_threshold\": 33.437753319549, \"match_probability\": 0.9999999999140525, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2478.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4060.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3790149986743927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6209850311279297, \"precision\": 1.0, \"recall\": 0.3790149986743927, \"specificity\": 1.0, \"npv\": 0.9636783003807068, \"accuracy\": 0.9644660949707031, \"f1\": 0.5496894409937888, \"f2\": 0.43276283618581907, \"f0_5\": 0.7531914893617021, \"p4\": 0.70470813460405, \"phi\": 0.6043579454987251}, {\"truth_threshold\": 33.43798195462706, \"match_probability\": 0.9999999999140661, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2477.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4061.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37886202335357666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6211379766464233, \"precision\": 1.0, \"recall\": 0.37886202335357666, \"specificity\": 1.0, \"npv\": 0.9636697173118591, \"accuracy\": 0.9644573330879211, \"f1\": 0.549528563505269, \"f2\": 0.43260330434175137, \"f0_5\": 0.7530706554785358, \"p4\": 0.7045747632195931, \"phi\": 0.6042333015440192}, {\"truth_threshold\": 33.44026557064558, \"match_probability\": 0.9999999999142021, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2475.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4063.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37855613231658936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6214438676834106, \"precision\": 1.0, \"recall\": 0.37855613231658936, \"specificity\": 1.0, \"npv\": 0.963652491569519, \"accuracy\": 0.9644398093223572, \"f1\": 0.5492067014312659, \"f2\": 0.43228420721696303, \"f0_5\": 0.7528288112909113, \"p4\": 0.7043078516149618, \"phi\": 0.6039839069127737}, {\"truth_threshold\": 33.45678578577218, \"match_probability\": 0.9999999999151788, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2474.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4064.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3784031867980957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6215968132019043, \"precision\": 1.0, \"recall\": 0.3784031867980957, \"specificity\": 1.0, \"npv\": 0.9636438488960266, \"accuracy\": 0.9644310474395752, \"f1\": 0.5490457168220151, \"f2\": 0.43212464193390626, \"f0_5\": 0.752707800900572, \"p4\": 0.7041743113212922, \"phi\": 0.6038591561926872}, {\"truth_threshold\": 33.45954267386874, \"match_probability\": 0.9999999999153408, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2473.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4065.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37825024127960205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.621749758720398, \"precision\": 1.0, \"recall\": 0.37825024127960205, \"specificity\": 1.0, \"npv\": 0.9636352062225342, \"accuracy\": 0.9644222855567932, \"f1\": 0.5488846964820775, \"f2\": 0.4319650655021834, \"f0_5\": 0.7525867315885575, \"p4\": 0.7040407146510033, \"phi\": 0.6037344181896347}, {\"truth_threshold\": 33.461327186173406, \"match_probability\": 0.9999999999154455, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2472.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4066.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.378097265958786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6219027042388916, \"precision\": 1.0, \"recall\": 0.378097265958786, \"specificity\": 1.0, \"npv\": 0.9636266231536865, \"accuracy\": 0.964413583278656, \"f1\": 0.548723640399556, \"f2\": 0.43180547792062607, \"f0_5\": 0.7524656033118228, \"p4\": 0.7039070615672672, \"phi\": 0.603609656641488}, {\"truth_threshold\": 33.488094095736194, \"match_probability\": 0.9999999999169998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2470.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4068.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3777913749217987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6222086548805237, \"precision\": 1.0, \"recall\": 0.3777913749217987, \"specificity\": 1.0, \"npv\": 0.9636093378067017, \"accuracy\": 0.964396059513092, \"f1\": 0.5484014209591475, \"f2\": 0.4314862693033331, \"f0_5\": 0.7522231696918017, \"p4\": 0.7036395860119833, \"phi\": 0.6033600265679074}, {\"truth_threshold\": 33.500920842450334, \"match_probability\": 0.9999999999177345, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2468.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4070.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3774854838848114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.622514545917511, \"precision\": 1.0, \"recall\": 0.3774854838848114, \"specificity\": 1.0, \"npv\": 0.9635921120643616, \"accuracy\": 0.9643785357475281, \"f1\": 0.5480790584055074, \"f2\": 0.43116701607267643, \"f0_5\": 0.7519804996953078, \"p4\": 0.7033718843601773, \"phi\": 0.6031103021090555}, {\"truth_threshold\": 33.50342769806091, \"match_probability\": 0.9999999999178772, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2467.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4071.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37733250856399536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6226674914360046, \"precision\": 1.0, \"recall\": 0.37733250856399536, \"specificity\": 1.0, \"npv\": 0.9635835289955139, \"accuracy\": 0.9643697738647461, \"f1\": 0.547917823431427, \"f2\": 0.43100737272441386, \"f0_5\": 0.751859075947824, \"p4\": 0.7032379486556681, \"phi\": 0.6029853862959055}, {\"truth_threshold\": 33.50439590806529, \"match_probability\": 0.9999999999179324, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2465.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4073.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37702661752700806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6229733824729919, \"precision\": 1.0, \"recall\": 0.37702661752700806, \"specificity\": 1.0, \"npv\": 0.963566243648529, \"accuracy\": 0.9643523097038269, \"f1\": 0.5475952460291014, \"f2\": 0.43068805255617293, \"f0_5\": 0.7516160507378948, \"p4\": 0.7029699073043346, \"phi\": 0.6027355200310486}, {\"truth_threshold\": 33.50788283878481, \"match_probability\": 0.9999999999181305, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2464.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4074.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3768736720085144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6231263279914856, \"precision\": 1.0, \"recall\": 0.3768736720085144, \"specificity\": 1.0, \"npv\": 0.9635576605796814, \"accuracy\": 0.9643435478210449, \"f1\": 0.5474339035769828, \"f2\": 0.43052837573385516, \"f0_5\": 0.7514944491887275, \"p4\": 0.7028358015833723, \"phi\": 0.6026105695642091}, {\"truth_threshold\": 33.50985932127145, \"match_probability\": 0.9999999999182426, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2459.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4079.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37610891461372375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6238911151885986, \"precision\": 1.0, \"recall\": 0.37610891461372375, \"specificity\": 1.0, \"npv\": 0.9635145664215088, \"accuracy\": 0.9642997980117798, \"f1\": 0.5466266533288874, \"f2\": 0.42972982419349204, \"f0_5\": 0.7508855502626115, \"p4\": 0.7021644210399317, \"phi\": 0.6019853890443962}, {\"truth_threshold\": 33.52642221439529, \"match_probability\": 0.9999999999191759, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2458.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4080.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3759559392929077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6240440607070923, \"precision\": 1.0, \"recall\": 0.3759559392929077, \"specificity\": 1.0, \"npv\": 0.9635059237480164, \"accuracy\": 0.9642910361289978, \"f1\": 0.5464650955980436, \"f2\": 0.4295700803914715, \"f0_5\": 0.7507635919364691, \"p4\": 0.7020299742830142, \"phi\": 0.6018602599052941}, {\"truth_threshold\": 33.52993200176014, \"match_probability\": 0.9999999999193722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2456.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4082.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3756500482559204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6243499517440796, \"precision\": 1.0, \"recall\": 0.3756500482559204, \"specificity\": 1.0, \"npv\": 0.9634886980056763, \"accuracy\": 0.9642735123634338, \"f1\": 0.5461418723593506, \"f2\": 0.4292505592841163, \"f0_5\": 0.7505194963940839, \"p4\": 0.7017609098226462, \"phi\": 0.601609966653184}, {\"truth_threshold\": 33.53129449149385, \"match_probability\": 0.9999999999194483, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2454.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4084.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3753441274166107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6246558427810669, \"precision\": 1.0, \"recall\": 0.3753441274166107, \"specificity\": 1.0, \"npv\": 0.9634714722633362, \"accuracy\": 0.9642560482025146, \"f1\": 0.5458185053380783, \"f2\": 0.42893099349786756, \"f0_5\": 0.7502751620398679, \"p4\": 0.701491617184438, \"phi\": 0.6013596145851641}, {\"truth_threshold\": 33.53282919591504, \"match_probability\": 0.9999999999195339, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2452.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4086.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3750382363796234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6249617338180542, \"precision\": 1.0, \"recall\": 0.3750382363796234, \"specificity\": 1.0, \"npv\": 0.9634542465209961, \"accuracy\": 0.9642385244369507, \"f1\": 0.5454949944382648, \"f2\": 0.4286113830233534, \"f0_5\": 0.750030588523186, \"p4\": 0.7012220960689767, \"phi\": 0.6011091307986363}, {\"truth_threshold\": 33.537531739034385, \"match_probability\": 0.9999999999197958, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2450.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4088.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3747323453426361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6252676844596863, \"precision\": 1.0, \"recall\": 0.3747323453426361, \"specificity\": 1.0, \"npv\": 0.963437020778656, \"accuracy\": 0.9642210006713867, \"f1\": 0.5451713395638629, \"f2\": 0.42829172785119923, \"f0_5\": 0.7497857754927164, \"p4\": 0.7009523461763254, \"phi\": 0.6008585515582184}, {\"truth_threshold\": 33.54079276021084, \"match_probability\": 0.9999999999199769, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2447.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4091.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37427347898483276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6257265210151672, \"precision\": 1.0, \"recall\": 0.37427347898483276, \"specificity\": 1.0, \"npv\": 0.9634111523628235, \"accuracy\": 0.9641947746276855, \"f1\": 0.5446855870895938, \"f2\": 0.4278121612643799, \"f0_5\": 0.7494181060884478, \"p4\": 0.7005472917227136, \"phi\": 0.6004825216839352}, {\"truth_threshold\": 33.54156282694768, \"match_probability\": 0.9999999999200196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2446.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4092.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3741205334663391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6258794665336609, \"precision\": 1.0, \"recall\": 0.3741205334663391, \"specificity\": 1.0, \"npv\": 0.963402509689331, \"accuracy\": 0.9641860127449036, \"f1\": 0.5445235975066786, \"f2\": 0.4276522833764599, \"f0_5\": 0.7492954294816812, \"p4\": 0.70041215885708, \"phi\": 0.6003571062356501}, {\"truth_threshold\": 33.54332213760659, \"match_probability\": 0.9999999999201171, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2445.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4093.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37396758794784546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6260324120521545, \"precision\": 1.0, \"recall\": 0.37396758794784546, \"specificity\": 1.0, \"npv\": 0.9633939266204834, \"accuracy\": 0.9641772508621216, \"f1\": 0.5443615718579539, \"f2\": 0.4274923943070951, \"f0_5\": 0.7491726927319524, \"p4\": 0.700276968571416, \"phi\": 0.600231703290744}, {\"truth_threshold\": 33.54970301447944, \"match_probability\": 0.9999999999204696, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2444.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4094.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3738146126270294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6261853575706482, \"precision\": 1.0, \"recall\": 0.3738146126270294, \"specificity\": 1.0, \"npv\": 0.963385283946991, \"accuracy\": 0.9641684889793396, \"f1\": 0.5441995101313739, \"f2\": 0.4273324940551126, \"f0_5\": 0.7490498957950227, \"p4\": 0.7001417208279826, \"phi\": 0.6001062399128528}, {\"truth_threshold\": 33.55450188265518, \"match_probability\": 0.9999999999207337, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2442.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4096.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3735087215900421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6264913082122803, \"precision\": 1.0, \"recall\": 0.3735087215900421, \"specificity\": 1.0, \"npv\": 0.9633680582046509, \"accuracy\": 0.9641509652137756, \"f1\": 0.5438752783964366, \"f2\": 0.4270126599986011, \"f0_5\": 0.7488041211823868, \"p4\": 0.6998710528166869, \"phi\": 0.5998552776548705}, {\"truth_threshold\": 33.56875301032502, \"match_probability\": 0.9999999999215129, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2441.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4097.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37335577607154846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6266442537307739, \"precision\": 1.0, \"recall\": 0.37335577607154846, \"specificity\": 1.0, \"npv\": 0.9633594751358032, \"accuracy\": 0.9641422629356384, \"f1\": 0.5437131083639604, \"f2\": 0.42685272619172526, \"f0_5\": 0.7486811434179855, \"p4\": 0.6997356324731812, \"phi\": 0.5997297787591496}, {\"truth_threshold\": 33.59403024684182, \"match_probability\": 0.999999999922876, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2439.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4099.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37304985523223877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6269501447677612, \"precision\": 1.0, \"recall\": 0.37304985523223877, \"specificity\": 1.0, \"npv\": 0.9633421897888184, \"accuracy\": 0.9641247391700745, \"f1\": 0.5433886599086555, \"f2\": 0.42653282501486484, \"f0_5\": 0.7484350067509513, \"p4\": 0.6994646189210969, \"phi\": 0.5994786723788621}, {\"truth_threshold\": 33.59578768714819, \"match_probability\": 0.99999999992297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2438.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4100.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3728969097137451, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6271030902862549, \"precision\": 1.0, \"recall\": 0.3728969097137451, \"specificity\": 1.0, \"npv\": 0.9633336067199707, \"accuracy\": 0.9641159772872925, \"f1\": 0.5432263814616756, \"f2\": 0.42637285764253235, \"f0_5\": 0.7483118477593615, \"p4\": 0.699329025636676, \"phi\": 0.5993531013647886}, {\"truth_threshold\": 33.59670438114014, \"match_probability\": 0.9999999999230189, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2437.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37274396419525146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6272560358047485, \"precision\": 1.0, \"recall\": 0.37274396419525146, \"specificity\": 1.0, \"npv\": 0.9633249640464783, \"accuracy\": 0.9641072154045105, \"f1\": 0.5430640668523676, \"f2\": 0.42621287907936617, \"f0_5\": 0.7481886282696795, \"p4\": 0.6991933746293854, \"phi\": 0.5992274697605767}, {\"truth_threshold\": 33.612152088421176, \"match_probability\": 0.9999999999238388, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2435.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4103.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3724380433559418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6275619268417358, \"precision\": 1.0, \"recall\": 0.3724380433559418, \"specificity\": 1.0, \"npv\": 0.9633077383041382, \"accuracy\": 0.9640897512435913, \"f1\": 0.5427393290984063, \"f2\": 0.42589288837583517, \"f0_5\": 0.7479420076176434, \"p4\": 0.6989218992941443, \"phi\": 0.5989761707827284}, {\"truth_threshold\": 33.61556340839146, \"match_probability\": 0.9999999999240187, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2434.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4104.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3722850978374481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6277148723602295, \"precision\": 1.0, \"recall\": 0.3722850978374481, \"specificity\": 1.0, \"npv\": 0.9632991552352905, \"accuracy\": 0.9640809893608093, \"f1\": 0.5425769059295587, \"f2\": 0.4257328762331211, \"f0_5\": 0.7478186063659825, \"p4\": 0.6987860748900846, \"phi\": 0.5988505033933071}, {\"truth_threshold\": 33.62304140615162, \"match_probability\": 0.9999999999244115, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2432.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4106.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3719792068004608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6280208230018616, \"precision\": 1.0, \"recall\": 0.3719792068004608, \"specificity\": 1.0, \"npv\": 0.9632819294929504, \"accuracy\": 0.9640634655952454, \"f1\": 0.5422519509476031, \"f2\": 0.4254128183599216, \"f0_5\": 0.7475716217877781, \"p4\": 0.6985142524185642, \"phi\": 0.5985990596549794}, {\"truth_threshold\": 33.62645172453419, \"match_probability\": 0.9999999999245899, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2431.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4107.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37182626128196716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6281737685203552, \"precision\": 1.0, \"recall\": 0.37182626128196716, \"specificity\": 1.0, \"npv\": 0.963273286819458, \"accuracy\": 0.9640547037124634, \"f1\": 0.5420894191102688, \"f2\": 0.42525277262708605, \"f0_5\": 0.747448038371664, \"p4\": 0.6983782542747937, \"phi\": 0.5984733198276733}, {\"truth_threshold\": 33.6382947159693, \"match_probability\": 0.9999999999252064, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2430.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4108.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3716732859611511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6283267140388489, \"precision\": 1.0, \"recall\": 0.3716732859611511, \"specificity\": 1.0, \"npv\": 0.9632647037506104, \"accuracy\": 0.9640459418296814, \"f1\": 0.5419268510258698, \"f2\": 0.4250927156951928, \"f0_5\": 0.7473243941444212, \"p4\": 0.6982421981414206, \"phi\": 0.5983475192520868}, {\"truth_threshold\": 33.641899431815226, \"match_probability\": 0.9999999999253931, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2427.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4111.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37121444940567017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6287855505943298, \"precision\": 1.0, \"recall\": 0.37121444940567017, \"specificity\": 1.0, \"npv\": 0.9632388353347778, \"accuracy\": 0.9640197157859802, \"f1\": 0.5414389291689905, \"f2\": 0.42461247769341126, \"f0_5\": 0.7469530961467438, \"p4\": 0.697833681421131, \"phi\": 0.5979700454319264}, {\"truth_threshold\": 33.64847803086419, \"match_probability\": 0.9999999999257325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2425.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4113.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3709085285663605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6290914416313171, \"precision\": 1.0, \"recall\": 0.3709085285663605, \"specificity\": 1.0, \"npv\": 0.9632216095924377, \"accuracy\": 0.9640021920204163, \"f1\": 0.5411134664732791, \"f2\": 0.4242922630087133, \"f0_5\": 0.7467052592683828, \"p4\": 0.6975610462909851, \"phi\": 0.5977182628387501}, {\"truth_threshold\": 33.656187035255925, \"match_probability\": 0.9999999999261283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2424.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4114.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3707555830478668, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6292444467544556, \"precision\": 1.0, \"recall\": 0.3707555830478668, \"specificity\": 1.0, \"npv\": 0.9632130265235901, \"accuracy\": 0.9639934301376343, \"f1\": 0.5409506806516403, \"f2\": 0.4241321388577828, \"f0_5\": 0.7465812492300111, \"p4\": 0.6974246414158062, \"phi\": 0.5975923168303007}, {\"truth_threshold\": 33.67575323480047, \"match_probability\": 0.9999999999271234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2423.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4115.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.37060263752937317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6293973922729492, \"precision\": 1.0, \"recall\": 0.37060263752937317, \"specificity\": 1.0, \"npv\": 0.9632043838500977, \"accuracy\": 0.9639847278594971, \"f1\": 0.5407878584979355, \"f2\": 0.42397200349956254, \"f0_5\": 0.7464571780653112, \"p4\": 0.6972881782826466, \"phi\": 0.5974663831513505}, {\"truth_threshold\": 33.67649240703379, \"match_probability\": 0.9999999999271607, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2422.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4116.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3704496920108795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6295503377914429, \"precision\": 1.0, \"recall\": 0.3704496920108795, \"specificity\": 1.0, \"npv\": 0.96319580078125, \"accuracy\": 0.9639759659767151, \"f1\": 0.540625, \"f2\": 0.42381185693287604, \"f0_5\": 0.7463330457290768, \"p4\": 0.6971516568530315, \"phi\": 0.5973404251754091}, {\"truth_threshold\": 33.679984684917144, \"match_probability\": 0.9999999999273368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2420.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4118.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3701437711715698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6298562288284302, \"precision\": 1.0, \"recall\": 0.3701437711715698, \"specificity\": 1.0, \"npv\": 0.9631785750389099, \"accuracy\": 0.9639584422111511, \"f1\": 0.5402991739227506, \"f2\": 0.4234915301693966, \"f0_5\": 0.746084597360957, \"p4\": 0.6968784389503664, \"phi\": 0.5970883996227465}, {\"truth_threshold\": 33.68193509520519, \"match_probability\": 0.999999999927435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2419.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4119.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36999082565307617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6300091743469238, \"precision\": 1.0, \"recall\": 0.36999082565307617, \"specificity\": 1.0, \"npv\": 0.9631699323654175, \"accuracy\": 0.9639496803283691, \"f1\": 0.5401362063190801, \"f2\": 0.42333134997024957, \"f0_5\": 0.7459602812384359, \"p4\": 0.6967417424001974, \"phi\": 0.5969623320002889}, {\"truth_threshold\": 33.694283892408876, \"match_probability\": 0.9999999999280534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2417.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4121.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3696849048137665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6303150653839111, \"precision\": 1.0, \"recall\": 0.3696849048137665, \"specificity\": 1.0, \"npv\": 0.9631527066230774, \"accuracy\": 0.96393221616745, \"f1\": 0.5398101619207147, \"f2\": 0.42301095593125415, \"f0_5\": 0.7457114648895471, \"p4\": 0.6964681739091337, \"phi\": 0.5967101602891907}, {\"truth_threshold\": 33.71168776197209, \"match_probability\": 0.9999999999289162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2413.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4125.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36907312273979187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6309269070625305, \"precision\": 1.0, \"recall\": 0.36907312273979187, \"specificity\": 1.0, \"npv\": 0.9631182551383972, \"accuracy\": 0.963897168636322, \"f1\": 0.539157636018322, \"f2\": 0.42237003325748296, \"f0_5\": 0.7452130945027795, \"p4\": 0.695920334280865, \"phi\": 0.5962055606753658}, {\"truth_threshold\": 33.719561128925676, \"match_probability\": 0.9999999999293031, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2411.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4127.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3687672019004822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6312327980995178, \"precision\": 1.0, \"recall\": 0.3687672019004822, \"specificity\": 1.0, \"npv\": 0.9631010293960571, \"accuracy\": 0.9638797044754028, \"f1\": 0.5388311543189183, \"f2\": 0.42204950460385815, \"f0_5\": 0.7449635397355086, \"p4\": 0.6956460625234372, \"phi\": 0.595953095838523}, {\"truth_threshold\": 33.725070704093156, \"match_probability\": 0.9999999999295726, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2410.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4128.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3686142563819885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6313857436180115, \"precision\": 1.0, \"recall\": 0.3686142563819885, \"specificity\": 1.0, \"npv\": 0.9630924463272095, \"accuracy\": 0.9638709425926208, \"f1\": 0.538667858739383, \"f2\": 0.4218892234437364, \"f0_5\": 0.7448386697984918, \"p4\": 0.6955088385229568, \"phi\": 0.5958268083306304}, {\"truth_threshold\": 33.73027526012126, \"match_probability\": 0.9999999999298261, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2407.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4131.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3681553900241852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6318445801734924, \"precision\": 1.0, \"recall\": 0.3681553900241852, \"specificity\": 1.0, \"npv\": 0.963066577911377, \"accuracy\": 0.9638446569442749, \"f1\": 0.5381777529346004, \"f2\": 0.42140831261598793, \"f0_5\": 0.744463689224298, \"p4\": 0.69509681356733, \"phi\": 0.595447872150879}, {\"truth_threshold\": 33.73500883620671, \"match_probability\": 0.999999999930056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2406.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4132.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36800244450569153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6319975256919861, \"precision\": 1.0, \"recall\": 0.36800244450569153, \"specificity\": 1.0, \"npv\": 0.9630579948425293, \"accuracy\": 0.9638358950614929, \"f1\": 0.5380143112701252, \"f2\": 0.42124798655368023, \"f0_5\": 0.744338571958916, \"p4\": 0.694959354134103, \"phi\": 0.595321523260853}, {\"truth_threshold\": 33.74143510536614, \"match_probability\": 0.9999999999303668, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2403.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4135.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3675435781478882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6324564218521118, \"precision\": 1.0, \"recall\": 0.3675435781478882, \"specificity\": 1.0, \"npv\": 0.9630321860313416, \"accuracy\": 0.9638096690177917, \"f1\": 0.5375237669164523, \"f2\": 0.42076694099106987, \"f0_5\": 0.7439628482972136, \"p4\": 0.6945466219435883, \"phi\": 0.5949422556090549}, {\"truth_threshold\": 33.749767263079875, \"match_probability\": 0.9999999999307678, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2401.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4137.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3672376871109009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6327623128890991, \"precision\": 1.0, \"recall\": 0.3672376871109009, \"specificity\": 1.0, \"npv\": 0.9630149602890015, \"accuracy\": 0.9637921452522278, \"f1\": 0.5371965544244323, \"f2\": 0.4204461877911253, \"f0_5\": 0.7437120555073721, \"p4\": 0.6942711718495489, \"phi\": 0.5946892997035056}, {\"truth_threshold\": 33.76139808826741, \"match_probability\": 0.9999999999313237, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2399.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4139.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3669317960739136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6330682039260864, \"precision\": 1.0, \"recall\": 0.3669317960739136, \"specificity\": 1.0, \"npv\": 0.9629977345466614, \"accuracy\": 0.9637746214866638, \"f1\": 0.5368691954794674, \"f2\": 0.4201253896536023, \"f0_5\": 0.7434610140076856, \"p4\": 0.6939954851493275, \"phi\": 0.5944362820113545}, {\"truth_threshold\": 33.78667532478421, \"match_probability\": 0.9999999999325165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2396.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4142.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36647292971611023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6335271000862122, \"precision\": 1.0, \"recall\": 0.36647292971611023, \"specificity\": 1.0, \"npv\": 0.9629719257354736, \"accuracy\": 0.9637483954429626, \"f1\": 0.5363778822475934, \"f2\": 0.41964410816869835, \"f0_5\": 0.7430839846172932, \"p4\": 0.6935815107748391, \"phi\": 0.5940564967398064}, {\"truth_threshold\": 33.79546190233708, \"match_probability\": 0.9999999999329263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2394.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4144.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36616700887680054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6338329911231995, \"precision\": 1.0, \"recall\": 0.36616700887680054, \"specificity\": 1.0, \"npv\": 0.9629546999931335, \"accuracy\": 0.9637308716773987, \"f1\": 0.5360501567398119, \"f2\": 0.41932319764590487, \"f0_5\": 0.7428323197219809, \"p4\": 0.6933052311831188, \"phi\": 0.5938031952185874}, {\"truth_threshold\": 33.80048112430924, \"match_probability\": 0.9999999999331592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2393.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4145.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3660140633583069, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6339859366416931, \"precision\": 1.0, \"recall\": 0.3660140633583069, \"specificity\": 1.0, \"npv\": 0.9629460573196411, \"accuracy\": 0.9637221097946167, \"f1\": 0.5358862389430075, \"f2\": 0.419162725521107, \"f0_5\": 0.7427063935443824, \"p4\": 0.693167002266328, \"phi\": 0.593676525752701}, {\"truth_threshold\": 33.81818010848463, \"match_probability\": 0.9999999999339743, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2392.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4146.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36586111783981323, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6341388821601868, \"precision\": 1.0, \"recall\": 0.36586111783981323, \"specificity\": 1.0, \"npv\": 0.9629374742507935, \"accuracy\": 0.9637134075164795, \"f1\": 0.5357222844344904, \"f2\": 0.41900224215246634, \"f0_5\": 0.7425804048180802, \"p4\": 0.6930287138829183, \"phi\": 0.5935497946623827}, {\"truth_threshold\": 33.8189074819142, \"match_probability\": 0.9999999999340076, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2389.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4149.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3654022514820099, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6345977187156677, \"precision\": 1.0, \"recall\": 0.3654022514820099, \"specificity\": 1.0, \"npv\": 0.9629116654396057, \"accuracy\": 0.9636871218681335, \"f1\": 0.5352302005152907, \"f2\": 0.41852072457166883, \"f0_5\": 0.7422020628805767, \"p4\": 0.6926134915373781, \"phi\": 0.5931695262987335}, {\"truth_threshold\": 33.81909680247659, \"match_probability\": 0.9999999999340162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2388.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4150.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36524930596351624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6347506642341614, \"precision\": 1.0, \"recall\": 0.36524930596351624, \"specificity\": 1.0, \"npv\": 0.9629030227661133, \"accuracy\": 0.9636783599853516, \"f1\": 0.5350660990365225, \"f2\": 0.4183601962158374, \"f0_5\": 0.7420758234928527, \"p4\": 0.692474964891719, \"phi\": 0.5930427328227313}, {\"truth_threshold\": 33.81996042824699, \"match_probability\": 0.9999999999340556, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2386.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4152.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36494341492652893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6350566148757935, \"precision\": 1.0, \"recall\": 0.36494341492652893, \"specificity\": 1.0, \"npv\": 0.9628857970237732, \"accuracy\": 0.9636608958244324, \"f1\": 0.5347377857463022, \"f2\": 0.4180391057537319, \"f0_5\": 0.7418231563238403, \"p4\": 0.6921977325666381, \"phi\": 0.592789034411336}, {\"truth_threshold\": 33.82949228361905, \"match_probability\": 0.99999999993449, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2385.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4153.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3647904694080353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6352095603942871, \"precision\": 1.0, \"recall\": 0.3647904694080353, \"specificity\": 1.0, \"npv\": 0.9628772139549255, \"accuracy\": 0.9636521339416504, \"f1\": 0.53457357391012, \"f2\": 0.41787854364509236, \"f0_5\": 0.7416967284488121, \"p4\": 0.692059026807745, \"phi\": 0.5926621294287693}, {\"truth_threshold\": 33.83178741615881, \"match_probability\": 0.9999999999345941, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2383.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4155.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3644845485687256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6355154514312744, \"precision\": 1.0, \"recall\": 0.3644845485687256, \"specificity\": 1.0, \"npv\": 0.9628599882125854, \"accuracy\": 0.9636346101760864, \"f1\": 0.534245039793745, \"f2\": 0.41755738566672507, \"f0_5\": 0.7414436838830119, \"p4\": 0.6917814358983105, \"phi\": 0.5924083185678525}, {\"truth_threshold\": 33.8379558297279, \"match_probability\": 0.9999999999348731, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2381.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4157.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3641786575317383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6358213424682617, \"precision\": 1.0, \"recall\": 0.3641786575317383, \"specificity\": 1.0, \"npv\": 0.9628427624702454, \"accuracy\": 0.9636170864105225, \"f1\": 0.5339163583361364, \"f2\": 0.41723618266568535, \"f0_5\": 0.7411903872494086, \"p4\": 0.6915036055343424, \"phi\": 0.5921543710578516}, {\"truth_threshold\": 33.85580614220512, \"match_probability\": 0.999999999935674, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2379.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4159.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3638727366924286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.636127233505249, \"precision\": 1.0, \"recall\": 0.3638727366924286, \"specificity\": 1.0, \"npv\": 0.96282559633255, \"accuracy\": 0.9635996222496033, \"f1\": 0.5335875294381518, \"f2\": 0.416914934632505, \"f0_5\": 0.7409368381711723, \"p4\": 0.6912255353965413, \"phi\": 0.5919003236801111}, {\"truth_threshold\": 33.85954946641155, \"match_probability\": 0.9999999999358407, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2377.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4161.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3635668456554413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6364331841468811, \"precision\": 1.0, \"recall\": 0.3635668456554413, \"specificity\": 1.0, \"npv\": 0.96280837059021, \"accuracy\": 0.9635820984840393, \"f1\": 0.5332585530005608, \"f2\": 0.4165936415577132, \"f0_5\": 0.7406830362707216, \"p4\": 0.6909472251650404, \"phi\": 0.5916461763054965}, {\"truth_threshold\": 33.87636468545225, \"match_probability\": 0.9999999999365841, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2376.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4162.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36341390013694763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6365861296653748, \"precision\": 1.0, \"recall\": 0.36341390013694763, \"specificity\": 1.0, \"npv\": 0.9627997875213623, \"accuracy\": 0.9635733366012573, \"f1\": 0.5330940094233789, \"f2\": 0.4164329781267527, \"f0_5\": 0.7405560403939658, \"p4\": 0.6908079799140386, \"phi\": 0.5915190835682118}, {\"truth_threshold\": 33.88227835356631, \"match_probability\": 0.9999999999368435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2374.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4164.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36310797929763794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6368920207023621, \"precision\": 1.0, \"recall\": 0.36310797929763794, \"specificity\": 1.0, \"npv\": 0.9627825617790222, \"accuracy\": 0.9635558724403381, \"f1\": 0.5327648114901257, \"f2\": 0.4161116174717801, \"f0_5\": 0.7403018585505801, \"p4\": 0.690529308940993, \"phi\": 0.591264785963184}, {\"truth_threshold\": 33.884410020947115, \"match_probability\": 0.9999999999369368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2370.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4168.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36249616742134094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6375038027763367, \"precision\": 1.0, \"recall\": 0.36249616742134094, \"specificity\": 1.0, \"npv\": 0.962748110294342, \"accuracy\": 0.9635208249092102, \"f1\": 0.5321059721598563, \"f2\": 0.4154687609564547, \"f0_5\": 0.7397927331751779, \"p4\": 0.6899712439854614, \"phi\": 0.5907558896603526}, {\"truth_threshold\": 33.93530748669254, \"match_probability\": 0.9999999999391228, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36203733086586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6379626989364624, \"precision\": 1.0, \"recall\": 0.36203733086586, \"specificity\": 1.0, \"npv\": 0.9627223014831543, \"accuracy\": 0.963494598865509, \"f1\": 0.5316114542391914, \"f2\": 0.4149865002279182, \"f0_5\": 0.7394102211670623, \"p4\": 0.6895520613668025, \"phi\": 0.5903739719877868}, {\"truth_threshold\": 33.94496950103898, \"match_probability\": 0.9999999999395291, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2364.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4174.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36157846450805664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6384215354919434, \"precision\": 1.0, \"recall\": 0.36157846450805664, \"specificity\": 1.0, \"npv\": 0.9626964926719666, \"accuracy\": 0.9634683132171631, \"f1\": 0.5311166030105594, \"f2\": 0.41450413802777386, \"f0_5\": 0.7390271351756909, \"p4\": 0.6891323341919979, \"phi\": 0.58999179051865}, {\"truth_threshold\": 33.95660032622652, \"match_probability\": 0.9999999999400148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2362.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4176.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.36127257347106934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6387274265289307, \"precision\": 1.0, \"recall\": 0.36127257347106934, \"specificity\": 1.0, \"npv\": 0.9626793265342712, \"accuracy\": 0.9634507894515991, \"f1\": 0.5307865168539326, \"f2\": 0.41418250683874586, \"f0_5\": 0.7387714249968723, \"p4\": 0.6888522130043553, \"phi\": 0.5897368890313538}, {\"truth_threshold\": 33.970183201929686, \"match_probability\": 0.9999999999405769, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2349.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4189.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3592841923236847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6407158374786377, \"precision\": 1.0, \"recall\": 0.3592841923236847, \"specificity\": 1.0, \"npv\": 0.9625674486160278, \"accuracy\": 0.9633370637893677, \"f1\": 0.5286373354337797, \"f2\": 0.41209080383144453, \"f0_5\": 0.7371030500815865, \"p4\": 0.6870254915981087, \"phi\": 0.5880776147920178}, {\"truth_threshold\": 33.974704811760716, \"match_probability\": 0.9999999999407627, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2348.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4190.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35913124680519104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6408687829971313, \"precision\": 1.0, \"recall\": 0.35913124680519104, \"specificity\": 1.0, \"npv\": 0.9625588655471802, \"accuracy\": 0.9633283019065857, \"f1\": 0.528471753319829, \"f2\": 0.41192982456140353, \"f0_5\": 0.7369742623979912, \"p4\": 0.686884547033277, \"phi\": 0.587949777459298}, {\"truth_threshold\": 33.983790509603864, \"match_probability\": 0.9999999999411346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2345.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4193.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3586723804473877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6413276195526123, \"precision\": 1.0, \"recall\": 0.3586723804473877, \"specificity\": 1.0, \"npv\": 0.9625330567359924, \"accuracy\": 0.9633020162582397, \"f1\": 0.5279747832939322, \"f2\": 0.41144681896339963, \"f0_5\": 0.7365875109938435, \"p4\": 0.6864613454863914, \"phi\": 0.587566186731116}, {\"truth_threshold\": 33.98810698027948, \"match_probability\": 0.9999999999413105, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2344.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4194.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35851943492889404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.641480565071106, \"precision\": 1.0, \"recall\": 0.35851943492889404, \"specificity\": 1.0, \"npv\": 0.9625244736671448, \"accuracy\": 0.9632932543754578, \"f1\": 0.5278090520153119, \"f2\": 0.4112857944974733, \"f0_5\": 0.7364584642453186, \"p4\": 0.6863201555493134, \"phi\": 0.5874382844735767}, {\"truth_threshold\": 33.9928386860124, \"match_probability\": 0.9999999999415027, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2341.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4197.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3580605685710907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6419394016265869, \"precision\": 1.0, \"recall\": 0.3580605685710907, \"specificity\": 1.0, \"npv\": 0.962498664855957, \"accuracy\": 0.9632670283317566, \"f1\": 0.5273116341930397, \"f2\": 0.41080265328326254, \"f0_5\": 0.7360709344736511, \"p4\": 0.6858962168959567, \"phi\": 0.5870543497319478}, {\"truth_threshold\": 33.994201175746106, \"match_probability\": 0.9999999999415579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2340.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4198.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35790762305259705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6420924067497253, \"precision\": 1.0, \"recall\": 0.35790762305259705, \"specificity\": 1.0, \"npv\": 0.9624900817871094, \"accuracy\": 0.9632582664489746, \"f1\": 0.5271457535480965, \"f2\": 0.4106415836024147, \"f0_5\": 0.7359416278777204, \"p4\": 0.6857547809263183, \"phi\": 0.586926345087701}, {\"truth_threshold\": 34.00906774612066, \"match_probability\": 0.999999999942157, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3577546775341034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.642245352268219, \"precision\": 1.0, \"recall\": 0.3577546775341034, \"specificity\": 1.0, \"npv\": 0.9624814391136169, \"accuracy\": 0.9632495045661926, \"f1\": 0.5269798355300214, \"f2\": 0.41048050261486085, \"f0_5\": 0.7358122561973072, \"p4\": 0.6856132833450879, \"phi\": 0.5867982775449158}, {\"truth_threshold\": 34.01800087089067, \"match_probability\": 0.9999999999425141, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2338.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4200.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35760170221328735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6423982977867126, \"precision\": 1.0, \"recall\": 0.35760170221328735, \"specificity\": 1.0, \"npv\": 0.9624728560447693, \"accuracy\": 0.9632407426834106, \"f1\": 0.526813880126183, \"f2\": 0.4103194103194103, \"f0_5\": 0.73568281938326, \"p4\": 0.6854717241108108, \"phi\": 0.5866702216063993}, {\"truth_threshold\": 34.020494495281284, \"match_probability\": 0.9999999999426133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2337.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4201.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3574487566947937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6425512433052063, \"precision\": 1.0, \"recall\": 0.3574487566947937, \"specificity\": 1.0, \"npv\": 0.9624642729759216, \"accuracy\": 0.9632320404052734, \"f1\": 0.5266478873239436, \"f2\": 0.4101583067148724, \"f0_5\": 0.735553317386378, \"p4\": 0.685330103181995, \"phi\": 0.5865421027200236}, {\"truth_threshold\": 34.02692611849182, \"match_probability\": 0.9999999999428686, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2336.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4202.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35729581117630005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6427041888237, \"precision\": 1.0, \"recall\": 0.35729581117630005, \"specificity\": 1.0, \"npv\": 0.962455689907074, \"accuracy\": 0.9632232785224915, \"f1\": 0.5264818571106603, \"f2\": 0.40999719180005617, \"f0_5\": 0.7354237501574109, \"p4\": 0.6851884205171112, \"phi\": 0.5864139954197674}, {\"truth_threshold\": 34.04148922381304, \"match_probability\": 0.9999999999434425, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2335.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4203.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3571428656578064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6428571343421936, \"precision\": 1.0, \"recall\": 0.3571428656578064, \"specificity\": 1.0, \"npv\": 0.9624470472335815, \"accuracy\": 0.9632145166397095, \"f1\": 0.5263157894736842, \"f2\": 0.4098360655737705, \"f0_5\": 0.7352941176470589, \"p4\": 0.6850466760745927, \"phi\": 0.5862858624172032}, {\"truth_threshold\": 34.042323891071554, \"match_probability\": 0.9999999999434751, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2334.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4204.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35698989033699036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6430100798606873, \"precision\": 1.0, \"recall\": 0.35698989033699036, \"specificity\": 1.0, \"npv\": 0.9624384641647339, \"accuracy\": 0.9632057547569275, \"f1\": 0.5261496844003607, \"f2\": 0.40967492803482414, \"f0_5\": 0.735164419805972, \"p4\": 0.6849048698128357, \"phi\": 0.5861576663926279}, {\"truth_threshold\": 34.05613599977744, \"match_probability\": 0.9999999999440138, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2333.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4205.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3568369448184967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6431630253791809, \"precision\": 1.0, \"recall\": 0.3568369448184967, \"specificity\": 1.0, \"npv\": 0.9624298810958862, \"accuracy\": 0.9631969928741455, \"f1\": 0.5259835418780295, \"f2\": 0.40951377918202564, \"f0_5\": 0.7350346565847511, \"p4\": 0.6847630016901989, \"phi\": 0.586029481926852}, {\"truth_threshold\": 34.07050038312284, \"match_probability\": 0.9999999999445685, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2332.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4206.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35668399930000305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6433159708976746, \"precision\": 1.0, \"recall\": 0.35668399930000305, \"specificity\": 1.0, \"npv\": 0.9624212384223938, \"accuracy\": 0.9631882309913635, \"f1\": 0.5258173618940248, \"f2\": 0.4093526190141834, \"f0_5\": 0.7349048279339468, \"p4\": 0.6846210716650037, \"phi\": 0.5859012343895128}, {\"truth_threshold\": 34.08588334317149, \"match_probability\": 0.9999999999451563, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2331.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4207.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3565310537815094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.643468976020813, \"precision\": 1.0, \"recall\": 0.3565310537815094, \"specificity\": 1.0, \"npv\": 0.9624126553535461, \"accuracy\": 0.9631794691085815, \"f1\": 0.5256511444356748, \"f2\": 0.40919144753010567, \"f0_5\": 0.73477493380406, \"p4\": 0.6844790796955342, \"phi\": 0.585772998392692}, {\"truth_threshold\": 34.096972594484036, \"match_probability\": 0.9999999999455762, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2330.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4208.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35637810826301575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6436219215393066, \"precision\": 1.0, \"recall\": 0.35637810826301575, \"specificity\": 1.0, \"npv\": 0.9624040722846985, \"accuracy\": 0.9631707668304443, \"f1\": 0.5254848894903023, \"f2\": 0.40903026472860055, \"f0_5\": 0.7346449741455416, \"p4\": 0.6843370257400369, \"phi\": 0.5856446992746622}, {\"truth_threshold\": 34.09757891559142, \"match_probability\": 0.9999999999455991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2327.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4211.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3559192419052124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6440807580947876, \"precision\": 1.0, \"recall\": 0.3559192419052124, \"specificity\": 1.0, \"npv\": 0.9623782634735107, \"accuracy\": 0.9631444811820984, \"f1\": 0.5249858996051889, \"f2\": 0.4085466484075986, \"f0_5\": 0.7342547015019564, \"p4\": 0.6839104915392785, \"phi\": 0.5852597216490298}, {\"truth_threshold\": 34.10584653157502, \"match_probability\": 0.9999999999459099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2326.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4212.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35576629638671875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6442337036132812, \"precision\": 1.0, \"recall\": 0.35576629638671875, \"specificity\": 1.0, \"npv\": 0.9623696804046631, \"accuracy\": 0.9631357192993164, \"f1\": 0.5248194945848376, \"f2\": 0.408385420324461, \"f0_5\": 0.7341244792324202, \"p4\": 0.683768189221383, \"phi\": 0.5851313565307988}, {\"truth_threshold\": 34.10734490920108, \"match_probability\": 0.9999999999459661, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2325.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4213.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3556133508682251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6443866491317749, \"precision\": 1.0, \"recall\": 0.3556133508682251, \"specificity\": 1.0, \"npv\": 0.9623610973358154, \"accuracy\": 0.9631269574165344, \"f1\": 0.5246530520139907, \"f2\": 0.4082241809179338, \"f0_5\": 0.7339941911857558, \"p4\": 0.6836258247081283, \"phi\": 0.5850029281668369}, {\"truth_threshold\": 34.108603419671574, \"match_probability\": 0.9999999999460132, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2324.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4214.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35546037554740906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6445395946502686, \"precision\": 1.0, \"recall\": 0.35546037554740906, \"specificity\": 1.0, \"npv\": 0.962352454662323, \"accuracy\": 0.9631182551383972, \"f1\": 0.5244865718799369, \"f2\": 0.408062930186824, \"f0_5\": 0.7338638373121131, \"p4\": 0.6834833979575351, \"phi\": 0.5848745112789968}, {\"truth_threshold\": 34.14336883783225, \"match_probability\": 0.9999999999472986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2321.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4217.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3550015389919281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6449984908103943, \"precision\": 1.0, \"recall\": 0.3550015389919281, \"specificity\": 1.0, \"npv\": 0.96232670545578, \"accuracy\": 0.9630919694900513, \"f1\": 0.5239869059713286, \"f2\": 0.4075791100340674, \"f0_5\": 0.7334723802300595, \"p4\": 0.683055743861365, \"phi\": 0.5844890302977919}, {\"truth_threshold\": 34.17425942615465, \"match_probability\": 0.999999999948415, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2320.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4218.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35484856367111206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6451514363288879, \"precision\": 1.0, \"recall\": 0.35484856367111206, \"specificity\": 1.0, \"npv\": 0.9623180627822876, \"accuracy\": 0.9630832076072693, \"f1\": 0.5238202754572138, \"f2\": 0.40741781399269456, \"f0_5\": 0.7333417625489949, \"p4\": 0.682913067740869, \"phi\": 0.5843605096651042}, {\"truth_threshold\": 34.178528274669866, \"match_probability\": 0.9999999999485675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2319.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4219.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3546956181526184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6453043818473816, \"precision\": 1.0, \"recall\": 0.3546956181526184, \"specificity\": 1.0, \"npv\": 0.9623094797134399, \"accuracy\": 0.9630744457244873, \"f1\": 0.523653607316247, \"f2\": 0.407256506620772, \"f0_5\": 0.7332110787909447, \"p4\": 0.6827703291725707, \"phi\": 0.5842319630572063}, {\"truth_threshold\": 34.17899274756297, \"match_probability\": 0.999999999948584, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2318.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4220.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35454267263412476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6454573273658752, \"precision\": 1.0, \"recall\": 0.35454267263412476, \"specificity\": 1.0, \"npv\": 0.9623008966445923, \"accuracy\": 0.9630657434463501, \"f1\": 0.523486901535682, \"f2\": 0.40709518791710575, \"f0_5\": 0.7330803289057558, \"p4\": 0.6826275281142636, \"phi\": 0.5841033530282561}, {\"truth_threshold\": 34.18548376395479, \"match_probability\": 0.9999999999488148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2316.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4222.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35423678159713745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6457632184028625, \"precision\": 1.0, \"recall\": 0.35423678159713745, \"specificity\": 1.0, \"npv\": 0.962283730506897, \"accuracy\": 0.9630482196807861, \"f1\": 0.5231533770047436, \"f2\": 0.40677251650976537, \"f0_5\": 0.7328186305530946, \"p4\": 0.6823417383586065, \"phi\": 0.5838460923211396}, {\"truth_threshold\": 34.190326407630224, \"match_probability\": 0.9999999999489864, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2315.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4223.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3540838062763214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6459161639213562, \"precision\": 1.0, \"recall\": 0.3540838062763214, \"specificity\": 1.0, \"npv\": 0.9622750878334045, \"accuracy\": 0.9630394577980042, \"f1\": 0.522986558228849, \"f2\": 0.40661116380370255, \"f0_5\": 0.7326876819850614, \"p4\": 0.6821987495766529, \"phi\": 0.5837174416242652}, {\"truth_threshold\": 34.208003906872776, \"match_probability\": 0.9999999999496076, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2314.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4224.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35393086075782776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6460691094398499, \"precision\": 1.0, \"recall\": 0.35393086075782776, \"specificity\": 1.0, \"npv\": 0.9622665047645569, \"accuracy\": 0.9630306959152222, \"f1\": 0.5228197017623136, \"f2\": 0.4064497997611185, \"f0_5\": 0.7325566670887679, \"p4\": 0.6820556981354837, \"phi\": 0.5835887274056312}, {\"truth_threshold\": 34.219571196434224, \"match_probability\": 0.9999999999500101, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2313.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4225.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3537779152393341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6462221145629883, \"precision\": 1.0, \"recall\": 0.3537779152393341, \"specificity\": 1.0, \"npv\": 0.9622579216957092, \"accuracy\": 0.9630219340324402, \"f1\": 0.5226528075923624, \"f2\": 0.4062884243808185, \"f0_5\": 0.7324255858138062, \"p4\": 0.6819125839927016, \"phi\": 0.5834600245605978}, {\"truth_threshold\": 34.221169777894936, \"match_probability\": 0.9999999999500654, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2312.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4226.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35362496972084045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6463750600814819, \"precision\": 1.0, \"recall\": 0.35362496972084045, \"specificity\": 1.0, \"npv\": 0.9622493386268616, \"accuracy\": 0.963013231754303, \"f1\": 0.5224858757062147, \"f2\": 0.4061270376616076, \"f0_5\": 0.7322944381097175, \"p4\": 0.6817694071058713, \"phi\": 0.5833312956194692}, {\"truth_threshold\": 34.24039329222712, \"match_probability\": 0.9999999999507264, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2310.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4228.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35331904888153076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6466809511184692, \"precision\": 1.0, \"recall\": 0.35331904888153076, \"specificity\": 1.0, \"npv\": 0.9622321128845215, \"accuracy\": 0.962995707988739, \"f1\": 0.5221518987341772, \"f2\": 0.4058042302016724, \"f0_5\": 0.7320319432120674, \"p4\": 0.6814828649301329, \"phi\": 0.5830737218874922}, {\"truth_threshold\": 34.24682491543766, \"match_probability\": 0.9999999999509456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2307.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4231.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3528602123260498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6471397876739502, \"precision\": 1.0, \"recall\": 0.3528602123260498, \"specificity\": 1.0, \"npv\": 0.9622063636779785, \"accuracy\": 0.9629694223403931, \"f1\": 0.5216506500847937, \"f2\": 0.4053199339400541, \"f0_5\": 0.7316377013827223, \"p4\": 0.6810525800230756, \"phi\": 0.5826871463170251}, {\"truth_threshold\": 34.266897595926345, \"match_probability\": 0.9999999999516234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2301.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4237.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3519424796104431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6480575203895569, \"precision\": 1.0, \"recall\": 0.3519424796104431, \"specificity\": 1.0, \"npv\": 0.962154746055603, \"accuracy\": 0.962916910648346, \"f1\": 0.52064713202851, \"f2\": 0.4043510350402418, \"f0_5\": 0.7308474145597764, \"p4\": 0.6801903080686278, \"phi\": 0.5819133621325046}, {\"truth_threshold\": 34.29663290664808, \"match_probability\": 0.9999999999526102, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2295.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4243.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3510247766971588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6489751935005188, \"precision\": 1.0, \"recall\": 0.3510247766971588, \"specificity\": 1.0, \"npv\": 0.9621031880378723, \"accuracy\": 0.9628643989562988, \"f1\": 0.5196422506509679, \"f2\": 0.40338172742292683, \"f0_5\": 0.7300547143402468, \"p4\": 0.679325758884337, \"phi\": 0.5811385931451583}, {\"truth_threshold\": 34.304029793058845, \"match_probability\": 0.9999999999528526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2294.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4244.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35087183117866516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6491281986236572, \"precision\": 1.0, \"recall\": 0.35087183117866516, \"specificity\": 1.0, \"npv\": 0.9620946049690247, \"accuracy\": 0.9628556966781616, \"f1\": 0.5194746376811594, \"f2\": 0.4032201363987907, \"f0_5\": 0.7299223622247677, \"p4\": 0.6791814453043344, \"phi\": 0.581009391426241}, {\"truth_threshold\": 34.31960942457519, \"match_probability\": 0.999999999953359, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2293.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4245.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3507188856601715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6492811441421509, \"precision\": 1.0, \"recall\": 0.3507188856601715, \"specificity\": 1.0, \"npv\": 0.962086021900177, \"accuracy\": 0.9628469347953796, \"f1\": 0.5193069867512173, \"f2\": 0.40305853401300756, \"f0_5\": 0.7297899427116487, \"p4\": 0.6790370681666877, \"phi\": 0.5808801256505272}, {\"truth_threshold\": 34.346360588988574, \"match_probability\": 0.9999999999542158, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2290.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4248.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.35026001930236816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6497399806976318, \"precision\": 1.0, \"recall\": 0.35026001930236816, \"specificity\": 1.0, \"npv\": 0.962060272693634, \"accuracy\": 0.9628206491470337, \"f1\": 0.5188038060715904, \"f2\": 0.4025736586737923, \"f0_5\": 0.7293922792712447, \"p4\": 0.678603554975594, \"phi\": 0.5804922447805011}, {\"truth_threshold\": 34.35343323012778, \"match_probability\": 0.9999999999544398, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2288.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4250.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34995412826538086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6500458717346191, \"precision\": 1.0, \"recall\": 0.34995412826538086, \"specificity\": 1.0, \"npv\": 0.962043046951294, \"accuracy\": 0.9628031253814697, \"f1\": 0.5184681622479039, \"f2\": 0.4022503516174402, \"f0_5\": 0.7291268323773104, \"p4\": 0.6783142276000942, \"phi\": 0.5802335124813569}, {\"truth_threshold\": 34.356959493392566, \"match_probability\": 0.999999999954551, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2287.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4251.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3498011529445648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6501988172531128, \"precision\": 1.0, \"recall\": 0.3498011529445648, \"specificity\": 1.0, \"npv\": 0.9620344638824463, \"accuracy\": 0.9627944231033325, \"f1\": 0.518300283286119, \"f2\": 0.40208868103660467, \"f0_5\": 0.7289940073951294, \"p4\": 0.6781694682078143, \"phi\": 0.5801041253635822}, {\"truth_threshold\": 34.36000700031783, \"match_probability\": 0.9999999999546468, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2282.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4256.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34903639554977417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6509636044502258, \"precision\": 1.0, \"recall\": 0.34903639554977417, \"specificity\": 1.0, \"npv\": 0.9619914889335632, \"accuracy\": 0.9627506136894226, \"f1\": 0.5174603174603175, \"f2\": 0.4012801575578533, \"f0_5\": 0.7283288650580876, \"p4\": 0.6774447124621304, \"phi\": 0.5794566779690775}, {\"truth_threshold\": 34.37740730847346, \"match_probability\": 0.9999999999551906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2277.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4261.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3482716381549835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6517283320426941, \"precision\": 1.0, \"recall\": 0.3482716381549835, \"specificity\": 1.0, \"npv\": 0.961948573589325, \"accuracy\": 0.9627068638801575, \"f1\": 0.516619398752127, \"f2\": 0.40047134967814557, \"f0_5\": 0.7276620222421066, \"p4\": 0.6767183547456922, \"phi\": 0.5788086020214929}, {\"truth_threshold\": 34.38042440305824, \"match_probability\": 0.9999999999552842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2276.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4262.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34811869263648987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6518813371658325, \"precision\": 1.0, \"recall\": 0.34811869263648987, \"specificity\": 1.0, \"npv\": 0.9619399905204773, \"accuracy\": 0.9626981019973755, \"f1\": 0.516451100521897, \"f2\": 0.40030955396088364, \"f0_5\": 0.7275284490474364, \"p4\": 0.6765728904849718, \"phi\": 0.5786789217929637}, {\"truth_threshold\": 34.40405930319775, \"match_probability\": 0.9999999999560107, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2273.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4265.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3476598262786865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6523401737213135, \"precision\": 1.0, \"recall\": 0.3476598262786865, \"specificity\": 1.0, \"npv\": 0.9619141817092896, \"accuracy\": 0.9626718759536743, \"f1\": 0.515945976620134, \"f2\": 0.3998240985048373, \"f0_5\": 0.7271273192578375, \"p4\": 0.6761361114784421, \"phi\": 0.5782896449520921}, {\"truth_threshold\": 34.40787618529124, \"match_probability\": 0.999999999956127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2270.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4268.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34720098972320557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6527990102767944, \"precision\": 1.0, \"recall\": 0.34720098972320557, \"specificity\": 1.0, \"npv\": 0.9618884325027466, \"accuracy\": 0.9626455903053284, \"f1\": 0.5154405086285195, \"f2\": 0.3993385405671663, \"f0_5\": 0.7267255730567295, \"p4\": 0.6756987522117563, \"phi\": 0.5779001645839538}, {\"truth_threshold\": 34.41950701047878, \"match_probability\": 0.9999999999564793, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3470480144023895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6529519557952881, \"precision\": 1.0, \"recall\": 0.3470480144023895, \"specificity\": 1.0, \"npv\": 0.9618798494338989, \"accuracy\": 0.9626368880271912, \"f1\": 0.5152719427727944, \"f2\": 0.3991766651419725, \"f0_5\": 0.726591520430383, \"p4\": 0.6755528366372073, \"phi\": 0.5777702966968252}, {\"truth_threshold\": 34.4444223346429, \"match_probability\": 0.9999999999572244, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2268.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4270.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3468950688838959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6531049013137817, \"precision\": 1.0, \"recall\": 0.3468950688838959, \"specificity\": 1.0, \"npv\": 0.9618712663650513, \"accuracy\": 0.9626281261444092, \"f1\": 0.5151033386327504, \"f2\": 0.39901477832512317, \"f0_5\": 0.726457399103139, \"p4\": 0.6754068564129291, \"phi\": 0.5776403641017489}, {\"truth_threshold\": 34.44844138988388, \"match_probability\": 0.9999999999573435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2266.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4272.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34658917784690857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6534108519554138, \"precision\": 1.0, \"recall\": 0.34658917784690857, \"specificity\": 1.0, \"npv\": 0.961854100227356, \"accuracy\": 0.9626106023788452, \"f1\": 0.5147660154475239, \"f2\": 0.39869097051164754, \"f0_5\": 0.7261889501345982, \"p4\": 0.6751147018383366, \"phi\": 0.5773804560042608}, {\"truth_threshold\": 34.45017657443806, \"match_probability\": 0.9999999999573947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2265.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4273.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3464362323284149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6535637974739075, \"precision\": 1.0, \"recall\": 0.3464362323284149, \"specificity\": 1.0, \"npv\": 0.9618455171585083, \"accuracy\": 0.9626018404960632, \"f1\": 0.5145972963762354, \"f2\": 0.3985290495126157, \"f0_5\": 0.7260546223874855, \"p4\": 0.6749685273994978, \"phi\": 0.5772504804817293}, {\"truth_threshold\": 34.45954267386874, \"match_probability\": 0.9999999999576704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2262.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4276.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3459773659706116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6540226340293884, \"precision\": 1.0, \"recall\": 0.3459773659706116, \"specificity\": 1.0, \"npv\": 0.9618197083473206, \"accuracy\": 0.9625756144523621, \"f1\": 0.514090909090909, \"f2\": 0.3980432181319068, \"f0_5\": 0.725651225458745, \"p4\": 0.6745296149448158, \"phi\": 0.576860354259174}, {\"truth_threshold\": 34.45954267386875, \"match_probability\": 0.9999999999576704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3455184996128082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6544814705848694, \"precision\": 1.0, \"recall\": 0.3455184996128082, \"specificity\": 1.0, \"npv\": 0.9617939591407776, \"accuracy\": 0.9625493288040161, \"f1\": 0.5135841764237808, \"f2\": 0.39755728415050506, \"f0_5\": 0.7252472068832669, \"p4\": 0.6740901178499804, \"phi\": 0.5764699470355896}, {\"truth_threshold\": 34.47041754317585, \"match_probability\": 0.9999999999579883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2258.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4280.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3453655540943146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.654634416103363, \"precision\": 1.0, \"recall\": 0.3453655540943146, \"specificity\": 1.0, \"npv\": 0.9617853760719299, \"accuracy\": 0.9625405669212341, \"f1\": 0.5134151887221464, \"f2\": 0.39739528335093277, \"f0_5\": 0.7251123956326269, \"p4\": 0.6739434886906437, \"phi\": 0.5763397824512638}, {\"truth_threshold\": 34.488094095736194, \"match_probability\": 0.9999999999584999, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2254.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4284.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3447537422180176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6552462577819824, \"precision\": 1.0, \"recall\": 0.3447537422180176, \"specificity\": 1.0, \"npv\": 0.9617510437965393, \"accuracy\": 0.962505578994751, \"f1\": 0.5127388535031847, \"f2\": 0.39674716609167077, \"f0_5\": 0.7245724572457246, \"p4\": 0.6733563202248855, \"phi\": 0.5758187772511597}, {\"truth_threshold\": 34.50342769806091, \"match_probability\": 0.9999999999589386, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2253.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4285.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3446007966995239, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6553992033004761, \"precision\": 1.0, \"recall\": 0.3446007966995239, \"specificity\": 1.0, \"npv\": 0.9617424607276917, \"accuracy\": 0.962496817111969, \"f1\": 0.5125696735297464, \"f2\": 0.3965851082555888, \"f0_5\": 0.7244372990353698, \"p4\": 0.6732093649277989, \"phi\": 0.5756884770721106}, {\"truth_threshold\": 34.50439590806529, \"match_probability\": 0.9999999999589662, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2247.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4291.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3436830937862396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6563169360160828, \"precision\": 1.0, \"recall\": 0.3436830937862396, \"specificity\": 1.0, \"npv\": 0.9616909027099609, \"accuracy\": 0.9624443054199219, \"f1\": 0.5115537848605578, \"f2\": 0.39561252156766086, \"f0_5\": 0.7236248872858431, \"p4\": 0.6723262589758133, \"phi\": 0.5749059907460589}, {\"truth_threshold\": 34.50582287930705, \"match_probability\": 0.9999999999590068, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2244.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4294.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3432242274284363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6567757725715637, \"precision\": 1.0, \"recall\": 0.3432242274284363, \"specificity\": 1.0, \"npv\": 0.961665153503418, \"accuracy\": 0.9624180793762207, \"f1\": 0.5110453199726713, \"f2\": 0.39512607409494294, \"f0_5\": 0.7232177388165528, \"p4\": 0.6718838205812738, \"phi\": 0.574514398421881}, {\"truth_threshold\": 34.507411858842154, \"match_probability\": 0.9999999999590519, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2242.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4296.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.342918336391449, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.657081663608551, \"precision\": 1.0, \"recall\": 0.342918336391449, \"specificity\": 1.0, \"npv\": 0.9616479873657227, \"accuracy\": 0.9624005556106567, \"f1\": 0.5107061503416856, \"f2\": 0.3948017186729591, \"f0_5\": 0.7229459564039726, \"p4\": 0.671588532891971, \"phi\": 0.5742531875014265}, {\"truth_threshold\": 34.50837128251846, \"match_probability\": 0.9999999999590791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2241.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4297.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34276536107063293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6572346091270447, \"precision\": 1.0, \"recall\": 0.34276536107063293, \"specificity\": 1.0, \"npv\": 0.961639404296875, \"accuracy\": 0.9623917937278748, \"f1\": 0.5105365075748947, \"f2\": 0.3946395238262952, \"f0_5\": 0.7228099600051606, \"p4\": 0.6714407902837675, \"phi\": 0.5741225219475051}, {\"truth_threshold\": 34.512254502517585, \"match_probability\": 0.9999999999591891, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2239.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4299.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34245947003364563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6575405597686768, \"precision\": 1.0, \"recall\": 0.34245947003364563, \"specificity\": 1.0, \"npv\": 0.9616222381591797, \"accuracy\": 0.9623742699623108, \"f1\": 0.51019710607269, \"f2\": 0.39431509985558805, \"f0_5\": 0.7225377565509229, \"p4\": 0.6711451073137268, \"phi\": 0.5738611847261895}, {\"truth_threshold\": 34.516150454768415, \"match_probability\": 0.9999999999592991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2238.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4300.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.342306524515152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6576935052871704, \"precision\": 1.0, \"recall\": 0.342306524515152, \"specificity\": 1.0, \"npv\": 0.961613655090332, \"accuracy\": 0.9623655676841736, \"f1\": 0.5100273473108478, \"f2\": 0.39415287072912997, \"f0_5\": 0.7224015493867011, \"p4\": 0.670997166861153, \"phi\": 0.5737304368982933}, {\"truth_threshold\": 34.52993200176014, \"match_probability\": 0.9999999999596861, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2237.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4301.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34215354919433594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6578464508056641, \"precision\": 1.0, \"recall\": 0.34215354919433594, \"specificity\": 1.0, \"npv\": 0.9616050720214844, \"accuracy\": 0.9623568058013916, \"f1\": 0.5098575498575498, \"f2\": 0.3939906301736588, \"f0_5\": 0.7222652718584528, \"p4\": 0.6708491603696497, \"phi\": 0.5735996996890145}, {\"truth_threshold\": 34.5517603867003, \"match_probability\": 0.9999999999602914, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2235.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4303.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34184765815734863, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6581523418426514, \"precision\": 1.0, \"recall\": 0.34184765815734863, \"specificity\": 1.0, \"npv\": 0.9615879058837891, \"accuracy\": 0.9623392820358276, \"f1\": 0.5095178388236635, \"f2\": 0.3936661147708458, \"f0_5\": 0.7219925054916656, \"p4\": 0.6705529490879232, \"phi\": 0.5733381047384316}, {\"truth_threshold\": 34.55987927873629, \"match_probability\": 0.9999999999605144, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2234.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4304.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.341694712638855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.658305287361145, \"precision\": 1.0, \"recall\": 0.341694712638855, \"specificity\": 1.0, \"npv\": 0.9615793228149414, \"accuracy\": 0.9623305201530457, \"f1\": 0.5093479252165982, \"f2\": 0.39350383992108784, \"f0_5\": 0.7218560165438801, \"p4\": 0.6704047442066299, \"phi\": 0.5732072469426759}, {\"truth_threshold\": 34.56323377258601, \"match_probability\": 0.9999999999606061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2233.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4305.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34154176712036133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6584582328796387, \"precision\": 1.0, \"recall\": 0.34154176712036133, \"specificity\": 1.0, \"npv\": 0.9615707397460938, \"accuracy\": 0.9623217582702637, \"f1\": 0.5091779728651237, \"f2\": 0.3933415536374846, \"f0_5\": 0.7217194570135747, \"p4\": 0.6702564731042666, \"phi\": 0.5730763997234222}, {\"truth_threshold\": 34.57306948100064, \"match_probability\": 0.9999999999608736, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2231.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4307.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34123584628105164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.658764123916626, \"precision\": 1.0, \"recall\": 0.34123584628105164, \"specificity\": 1.0, \"npv\": 0.9615535736083984, \"accuracy\": 0.9623042941093445, \"f1\": 0.5088379518759265, \"f2\": 0.39301694676390797, \"f0_5\": 0.721446125986289, \"p4\": 0.6699597320537298, \"phi\": 0.572814584492628}, {\"truth_threshold\": 34.57935191472901, \"match_probability\": 0.9999999999610437, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2230.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4308.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.341082900762558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6589171290397644, \"precision\": 1.0, \"recall\": 0.341082900762558, \"specificity\": 1.0, \"npv\": 0.9615449905395508, \"accuracy\": 0.9622955322265625, \"f1\": 0.5086678832116789, \"f2\": 0.3928546261715172, \"f0_5\": 0.7213093543796093, \"p4\": 0.669811262014151, \"phi\": 0.5726836545714177}, {\"truth_threshold\": 34.62229446739377, \"match_probability\": 0.9999999999621861, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2229.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4309.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34092995524406433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6590700745582581, \"precision\": 1.0, \"recall\": 0.34092995524406433, \"specificity\": 1.0, \"npv\": 0.9615364074707031, \"accuracy\": 0.9622867703437805, \"f1\": 0.5084977757499715, \"f2\": 0.3926922941404461, \"f0_5\": 0.7211725119710107, \"p4\": 0.6696627255706916, \"phi\": 0.5725526588943507}, {\"truth_threshold\": 34.62645172453419, \"match_probability\": 0.9999999999622949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2228.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4310.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3407770097255707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6592230200767517, \"precision\": 1.0, \"recall\": 0.3407770097255707, \"specificity\": 1.0, \"npv\": 0.9615278244018555, \"accuracy\": 0.9622780084609985, \"f1\": 0.5083276294775269, \"f2\": 0.39252995066948554, \"f0_5\": 0.7210355987055016, \"p4\": 0.6695141226775441, \"phi\": 0.5724216737407932}, {\"truth_threshold\": 34.63467223133916, \"match_probability\": 0.9999999999625092, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2226.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4312.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.340471088886261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.659528911113739, \"precision\": 1.0, \"recall\": 0.340471088886261, \"specificity\": 1.0, \"npv\": 0.9615106582641602, \"accuracy\": 0.9622605443000793, \"f1\": 0.5079872204472844, \"f2\": 0.3922052294030587, \"f0_5\": 0.7207615593834995, \"p4\": 0.6692167173587429, \"phi\": 0.5721595823145086}, {\"truth_threshold\": 34.641899431815226, \"match_probability\": 0.9999999999626965, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2223.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4315.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.34001222252845764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.65998774766922, \"precision\": 1.0, \"recall\": 0.34001222252845764, \"specificity\": 1.0, \"npv\": 0.9614849090576172, \"accuracy\": 0.9622342586517334, \"f1\": 0.5074763154890994, \"f2\": 0.3917180616740088, \"f0_5\": 0.720349967595593, \"p4\": 0.6687701098602615, \"phi\": 0.5717662565763192}, {\"truth_threshold\": 34.6444469429509, \"match_probability\": 0.9999999999627623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2221.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4317.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33970633149147034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6602936387062073, \"precision\": 1.0, \"recall\": 0.33970633149147034, \"specificity\": 1.0, \"npv\": 0.9614677429199219, \"accuracy\": 0.9622167348861694, \"f1\": 0.5071355177531681, \"f2\": 0.3913932259542523, \"f0_5\": 0.7200752172221502, \"p4\": 0.6684720379775341, \"phi\": 0.5715038880011345}, {\"truth_threshold\": 34.66681475597935, \"match_probability\": 0.9999999999633352, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2220.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4318.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3395533859729767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6604466438293457, \"precision\": 1.0, \"recall\": 0.3395533859729767, \"specificity\": 1.0, \"npv\": 0.9614591598510742, \"accuracy\": 0.9622080326080322, \"f1\": 0.5069650605160996, \"f2\": 0.39123079092062596, \"f0_5\": 0.7199377351148009, \"p4\": 0.6683229018327375, \"phi\": 0.5713726429344299}, {\"truth_threshold\": 34.67084584389265, \"match_probability\": 0.9999999999634376, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2218.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4320.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.339247465133667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.660752534866333, \"precision\": 1.0, \"recall\": 0.339247465133667, \"specificity\": 1.0, \"npv\": 0.9614419937133789, \"accuracy\": 0.9621905088424683, \"f1\": 0.5066240292370946, \"f2\": 0.3909058864998238, \"f0_5\": 0.7196625567813109, \"p4\": 0.6680244289053351, \"phi\": 0.5711101075965154}, {\"truth_threshold\": 34.67575323480047, \"match_probability\": 0.9999999999635617, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2216.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4322.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3389415740966797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6610584259033203, \"precision\": 1.0, \"recall\": 0.3389415740966797, \"specificity\": 1.0, \"npv\": 0.9614248275756836, \"accuracy\": 0.9621729850769043, \"f1\": 0.5062828421293123, \"f2\": 0.39058093626621543, \"f0_5\": 0.7193870925853785, \"p4\": 0.667725688152433, \"phi\": 0.5708474991596277}, {\"truth_threshold\": 34.676868420643274, \"match_probability\": 0.9999999999635899, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2215.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4323.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33878862857818604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.661211371421814, \"precision\": 1.0, \"recall\": 0.33878862857818604, \"specificity\": 1.0, \"npv\": 0.9614162445068359, \"accuracy\": 0.9621642231941223, \"f1\": 0.5061121901062493, \"f2\": 0.3904184439665809, \"f0_5\": 0.7192492531497597, \"p4\": 0.6675762172256018, \"phi\": 0.570716114873599}, {\"truth_threshold\": 34.68193509520519, \"match_probability\": 0.9999999999637175, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2214.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4324.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3386356830596924, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6613643169403076, \"precision\": 1.0, \"recall\": 0.3386356830596924, \"specificity\": 1.0, \"npv\": 0.9614076614379883, \"accuracy\": 0.9621555209159851, \"f1\": 0.5059414990859232, \"f2\": 0.3902559402101107, \"f0_5\": 0.7191113420813304, \"p4\": 0.6674266792033287, \"phi\": 0.5705847409605964}, {\"truth_threshold\": 34.68614985711773, \"match_probability\": 0.9999999999638234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2211.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4327.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33817681670188904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6618232131004333, \"precision\": 1.0, \"recall\": 0.33817681670188904, \"specificity\": 1.0, \"npv\": 0.9613819122314453, \"accuracy\": 0.9621292352676392, \"f1\": 0.5054291919076466, \"f2\": 0.38976836018756833, \"f0_5\": 0.7186971785203484, \"p4\": 0.6669776620991965, \"phi\": 0.5701903750782656}, {\"truth_threshold\": 34.69441276251602, \"match_probability\": 0.99999999996403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2210.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4328.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3380238711833954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.661976158618927, \"precision\": 1.0, \"recall\": 0.3380238711833954, \"specificity\": 1.0, \"npv\": 0.9613733291625977, \"accuracy\": 0.9621204733848572, \"f1\": 0.5052583447645176, \"f2\": 0.3896058105916367, \"f0_5\": 0.7185589803615555, \"p4\": 0.6668278552302798, \"phi\": 0.5700588893952009}, {\"truth_threshold\": 34.7017609590447, \"match_probability\": 0.9999999999642127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2207.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4331.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33756500482559204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.662434995174408, \"precision\": 1.0, \"recall\": 0.33756500482559204, \"specificity\": 1.0, \"npv\": 0.9613476395606995, \"accuracy\": 0.962094247341156, \"f1\": 0.5047455688965123, \"f2\": 0.3891180930216157, \"f0_5\": 0.7181439541845633, \"p4\": 0.6663780304682799, \"phi\": 0.569664226008267}, {\"truth_threshold\": 34.72247861230797, \"match_probability\": 0.9999999999647229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2206.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4332.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3374120593070984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6625879406929016, \"precision\": 1.0, \"recall\": 0.3374120593070984, \"specificity\": 1.0, \"npv\": 0.9613390564918518, \"accuracy\": 0.962085485458374, \"f1\": 0.5045745654162854, \"f2\": 0.3889554975668242, \"f0_5\": 0.7180054680380159, \"p4\": 0.6662279540068546, \"phi\": 0.5695325899050255}, {\"truth_threshold\": 34.73420790489008, \"match_probability\": 0.9999999999650085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2205.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4333.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33725911378860474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6627408862113953, \"precision\": 1.0, \"recall\": 0.33725911378860474, \"specificity\": 1.0, \"npv\": 0.9613304734230042, \"accuracy\": 0.962076723575592, \"f1\": 0.5044035228182546, \"f2\": 0.38879289064428535, \"f0_5\": 0.7178669097538742, \"p4\": 0.6660778100304376, \"phi\": 0.5694009640764073}, {\"truth_threshold\": 34.73464692385404, \"match_probability\": 0.9999999999650192, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2204.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4334.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3371061384677887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6628938317298889, \"precision\": 1.0, \"recall\": 0.3371061384677887, \"specificity\": 1.0, \"npv\": 0.9613218903541565, \"accuracy\": 0.9620679616928101, \"f1\": 0.5042324410889957, \"f2\": 0.388630272252786, \"f0_5\": 0.7177282792757588, \"p4\": 0.6659275984921966, \"phi\": 0.5692692717986956}, {\"truth_threshold\": 34.75480923683253, \"match_probability\": 0.9999999999655047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2203.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4335.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33695319294929504, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6630467772483826, \"precision\": 1.0, \"recall\": 0.33695319294929504, \"specificity\": 1.0, \"npv\": 0.9613133072853088, \"accuracy\": 0.9620591998100281, \"f1\": 0.5040613202150783, \"f2\": 0.3884676423911127, \"f0_5\": 0.7175895765472313, \"p4\": 0.665777319345256, \"phi\": 0.5691375897735601}, {\"truth_threshold\": 34.76139808826741, \"match_probability\": 0.9999999999656619, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2202.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4336.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3368002474308014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.663199782371521, \"precision\": 1.0, \"recall\": 0.3368002474308014, \"specificity\": 1.0, \"npv\": 0.9613047242164612, \"accuracy\": 0.9620504379272461, \"f1\": 0.5038901601830663, \"f2\": 0.38830500105805177, \"f0_5\": 0.7174508015117946, \"p4\": 0.6656269725426968, \"phi\": 0.5690058412431219}, {\"truth_threshold\": 34.76395524828413, \"match_probability\": 0.9999999999657226, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2201.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4337.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33664730191230774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6633527278900146, \"precision\": 1.0, \"recall\": 0.33664730191230774, \"specificity\": 1.0, \"npv\": 0.9612961411476135, \"accuracy\": 0.9620417356491089, \"f1\": 0.5037189609795171, \"f2\": 0.3881423482523895, \"f0_5\": 0.7173119541128927, \"p4\": 0.6654765580375567, \"phi\": 0.5688741029431471}, {\"truth_threshold\": 34.764397255397164, \"match_probability\": 0.9999999999657332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2200.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4338.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3364943265914917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6635056734085083, \"precision\": 1.0, \"recall\": 0.3364943265914917, \"specificity\": 1.0, \"npv\": 0.9612875580787659, \"accuracy\": 0.9620329737663269, \"f1\": 0.5035477225909819, \"f2\": 0.38797968397291194, \"f0_5\": 0.7171730342939105, \"p4\": 0.6653260757828299, \"phi\": 0.5687422980815477}, {\"truth_threshold\": 34.774002967822575, \"match_probability\": 0.9999999999659606, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2199.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4339.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33634138107299805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.663658618927002, \"precision\": 1.0, \"recall\": 0.33634138107299805, \"specificity\": 1.0, \"npv\": 0.9612789750099182, \"accuracy\": 0.9620242118835449, \"f1\": 0.5033764450040059, \"f2\": 0.387817008218405, \"f0_5\": 0.717034041998174, \"p4\": 0.665175525731467, \"phi\": 0.5686105034282327}, {\"truth_threshold\": 34.77774901513684, \"match_probability\": 0.9999999999660488, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2198.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4340.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3361884355545044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6638115644454956, \"precision\": 1.0, \"recall\": 0.3361884355545044, \"specificity\": 1.0, \"npv\": 0.9612703919410706, \"accuracy\": 0.9620154500007629, \"f1\": 0.5032051282051282, \"f2\": 0.38765432098765434, \"f0_5\": 0.7168949771689498, \"p4\": 0.6650249078363751, \"phi\": 0.5684786805730362}, {\"truth_threshold\": 34.78916894917483, \"match_probability\": 0.9999999999663165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2197.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4341.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33603549003601074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6639645099639893, \"precision\": 1.0, \"recall\": 0.33603549003601074, \"specificity\": 1.0, \"npv\": 0.9612618088722229, \"accuracy\": 0.962006688117981, \"f1\": 0.5030337721808815, \"f2\": 0.3874916222794455, \"f0_5\": 0.7167558397494453, \"p4\": 0.6648742220504179, \"phi\": 0.5683467910715234}, {\"truth_threshold\": 34.82283547144635, \"match_probability\": 0.9999999999670934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2195.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4343.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33572956919670105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6642704010009766, \"precision\": 1.0, \"recall\": 0.33572956919670105, \"specificity\": 1.0, \"npv\": 0.9612446427345276, \"accuracy\": 0.9619892239570618, \"f1\": 0.5026909424023818, \"f2\": 0.38716619042579464, \"f0_5\": 0.7164773469121295, \"p4\": 0.6645726466171428, \"phi\": 0.5680829657153665}, {\"truth_threshold\": 34.83178741615881, \"match_probability\": 0.999999999967297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2194.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4344.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3355766236782074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6644233465194702, \"precision\": 1.0, \"recall\": 0.3355766236782074, \"specificity\": 1.0, \"npv\": 0.9612361192703247, \"accuracy\": 0.9619804620742798, \"f1\": 0.5025194686211636, \"f2\": 0.3870034572779228, \"f0_5\": 0.7163379913804362, \"p4\": 0.6644217568753334, \"phi\": 0.5679510298383776}, {\"truth_threshold\": 34.85706465267561, \"match_probability\": 0.999999999967865, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2193.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4345.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33542367815971375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6645763516426086, \"precision\": 1.0, \"recall\": 0.33542367815971375, \"specificity\": 1.0, \"npv\": 0.961227536201477, \"accuracy\": 0.9619717001914978, \"f1\": 0.5023479555606459, \"f2\": 0.3868407126477333, \"f0_5\": 0.7161985630306988, \"p4\": 0.6642707990536756, \"phi\": 0.5678190272017488}, {\"truth_threshold\": 34.863490921835044, \"match_probability\": 0.9999999999680078, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2191.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4347.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33511778712272644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.664882242679596, \"precision\": 1.0, \"recall\": 0.33511778712272644, \"specificity\": 1.0, \"npv\": 0.9612103700637817, \"accuracy\": 0.9619541764259338, \"f1\": 0.5020048115477145, \"f2\": 0.38651518893553966, \"f0_5\": 0.7159194876486734, \"p4\": 0.663968678981349, \"phi\": 0.5675550138485905}, {\"truth_threshold\": 34.877944985858406, \"match_probability\": 0.9999999999683268, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2187.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4351.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33450597524642944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6654940247535706, \"precision\": 1.0, \"recall\": 0.33450597524642944, \"specificity\": 1.0, \"npv\": 0.9611760377883911, \"accuracy\": 0.9619191884994507, \"f1\": 0.5013180515759312, \"f2\": 0.38586400366985424, \"f0_5\": 0.7153604605521392, \"p4\": 0.6633636197919355, \"phi\": 0.5670265696413479}, {\"truth_threshold\": 34.885844968586504, \"match_probability\": 0.9999999999684998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2186.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4352.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3343529999256134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6656469702720642, \"precision\": 1.0, \"recall\": 0.3343529999256134, \"specificity\": 1.0, \"npv\": 0.9611674547195435, \"accuracy\": 0.9619104266166687, \"f1\": 0.5011462631820266, \"f2\": 0.38570117862940223, \"f0_5\": 0.7152205208742312, \"p4\": 0.6632121840829268, \"phi\": 0.5668943682589802}, {\"truth_threshold\": 34.91595834172918, \"match_probability\": 0.9999999999691505, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2185.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4353.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33420005440711975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6657999157905579, \"precision\": 1.0, \"recall\": 0.33420005440711975, \"specificity\": 1.0, \"npv\": 0.9611588716506958, \"accuracy\": 0.9619016647338867, \"f1\": 0.5009744354006649, \"f2\": 0.38553834209690513, \"f0_5\": 0.7150805079198848, \"p4\": 0.6630606799139946, \"phi\": 0.5667621769277852}, {\"truth_threshold\": 34.934810971906785, \"match_probability\": 0.9999999999695509, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2182.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4356.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3337412178516388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6662588119506836, \"precision\": 1.0, \"recall\": 0.3337412178516388, \"specificity\": 1.0, \"npv\": 0.9611331820487976, \"accuracy\": 0.9618754386901855, \"f1\": 0.5004587155963303, \"f2\": 0.38504976353497566, \"f0_5\": 0.7146600288222194, \"p4\": 0.6626057561703558, \"phi\": 0.5663653934226227}, {\"truth_threshold\": 34.943927969264884, \"match_probability\": 0.9999999999697428, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2180.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4358.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3334352970123291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6665647029876709, \"precision\": 1.0, \"recall\": 0.3334352970123291, \"specificity\": 1.0, \"npv\": 0.9611160159111023, \"accuracy\": 0.9618579149246216, \"f1\": 0.5001147052076165, \"f2\": 0.38472398701115346, \"f0_5\": 0.7143793419845327, \"p4\": 0.6623021304991492, \"phi\": 0.566100715534868}, {\"truth_threshold\": 34.94496950103898, \"match_probability\": 0.9999999999697646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2179.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4359.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33328235149383545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6667176485061646, \"precision\": 1.0, \"recall\": 0.33328235149383545, \"specificity\": 1.0, \"npv\": 0.9611074328422546, \"accuracy\": 0.9618491530418396, \"f1\": 0.4999426408167948, \"f2\": 0.38456108150082946, \"f0_5\": 0.7142388881604825, \"p4\": 0.6621502145672548, \"phi\": 0.5659683144282392}, {\"truth_threshold\": 34.96654439068527, \"match_probability\": 0.9999999999702134, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2177.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4361.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33297643065452576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6670235395431519, \"precision\": 1.0, \"recall\": 0.33297643065452576, \"specificity\": 1.0, \"npv\": 0.9610902667045593, \"accuracy\": 0.9618316888809204, \"f1\": 0.4995983935742972, \"f2\": 0.3842352359772671, \"f0_5\": 0.7139577594123049, \"p4\": 0.6618461762710095, \"phi\": 0.5657034649402095}, {\"truth_threshold\": 34.97040612575155, \"match_probability\": 0.999999999970293, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2175.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4363.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33267053961753845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6673294305801392, \"precision\": 1.0, \"recall\": 0.33267053961753845, \"specificity\": 1.0, \"npv\": 0.9610731601715088, \"accuracy\": 0.9618141651153564, \"f1\": 0.49925398829335477, \"f2\": 0.3839093444416987, \"f0_5\": 0.7136763354770967, \"p4\": 0.6615418624111365, \"phi\": 0.5654385394710179}, {\"truth_threshold\": 34.9744320433824, \"match_probability\": 0.9999999999703758, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2174.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4364.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3325175940990448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6674824357032776, \"precision\": 1.0, \"recall\": 0.3325175940990448, \"specificity\": 1.0, \"npv\": 0.9610645771026611, \"accuracy\": 0.9618054032325745, \"f1\": 0.49908172635445364, \"f2\": 0.3837463814163666, \"f0_5\": 0.7135355126690298, \"p4\": 0.6613896020245397, \"phi\": 0.565305995101978}, {\"truth_threshold\": 34.983790509603864, \"match_probability\": 0.9999999999705673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2173.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4365.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33236464858055115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6676353812217712, \"precision\": 1.0, \"recall\": 0.33236464858055115, \"specificity\": 1.0, \"npv\": 0.9610559940338135, \"accuracy\": 0.9617966413497925, \"f1\": 0.4989094248651131, \"f2\": 0.38358340688437775, \"f0_5\": 0.7133946158896914, \"p4\": 0.6612372726025861, \"phi\": 0.5651734606468027}, {\"truth_threshold\": 35.003596117665744, \"match_probability\": 0.9999999999709687, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2171.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4367.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33205872774124146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6679412722587585, \"precision\": 1.0, \"recall\": 0.33205872774124146, \"specificity\": 1.0, \"npv\": 0.9610388278961182, \"accuracy\": 0.9617791175842285, \"f1\": 0.49856470318061774, \"f2\": 0.38325742329555484, \"f0_5\": 0.7131126001839443, \"p4\": 0.6609324064595911, \"phi\": 0.564908266902914}, {\"truth_threshold\": 35.029384835364056, \"match_probability\": 0.9999999999714829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2170.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4368.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3319057822227478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6680942177772522, \"precision\": 1.0, \"recall\": 0.3319057822227478, \"specificity\": 1.0, \"npv\": 0.9610302448272705, \"accuracy\": 0.9617704153060913, \"f1\": 0.4983922829581994, \"f2\": 0.38309441423628277, \"f0_5\": 0.7129714811407544, \"p4\": 0.6607798696419279, \"phi\": 0.5647756075561473}, {\"truth_threshold\": 35.04148922381304, \"match_probability\": 0.9999999999717212, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2168.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4370.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3315998911857605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6684001088142395, \"precision\": 1.0, \"recall\": 0.3315998911857605, \"specificity\": 1.0, \"npv\": 0.96101313829422, \"accuracy\": 0.9617528915405273, \"f1\": 0.4980473236848151, \"f2\": 0.3827683615819209, \"f0_5\": 0.7126890203813281, \"p4\": 0.6604745882723787, \"phi\": 0.5645102411193356}, {\"truth_threshold\": 35.06299460588807, \"match_probability\": 0.9999999999721396, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2162.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4376.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3306821584701538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6693178415298462, \"precision\": 1.0, \"recall\": 0.3306821584701538, \"specificity\": 1.0, \"npv\": 0.9609616994857788, \"accuracy\": 0.9617003798484802, \"f1\": 0.49701149425287355, \"f2\": 0.3817899272444727, \"f0_5\": 0.7118398524957198, \"p4\": 0.6595570787977644, \"phi\": 0.5637134879247409}, {\"truth_threshold\": 35.07305659645735, \"match_probability\": 0.9999999999723332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.33052921295166016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6694707870483398, \"precision\": 1.0, \"recall\": 0.33052921295166016, \"specificity\": 1.0, \"npv\": 0.9609531164169312, \"accuracy\": 0.9616916179656982, \"f1\": 0.49683871709391886, \"f2\": 0.3816268145374916, \"f0_5\": 0.7116980634962455, \"p4\": 0.6594039171756595, \"phi\": 0.5635805686901835}, {\"truth_threshold\": 35.08588334317149, \"match_probability\": 0.9999999999725782, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2160.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4378.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3303762674331665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6696237325668335, \"precision\": 1.0, \"recall\": 0.3303762674331665, \"specificity\": 1.0, \"npv\": 0.9609445333480835, \"accuracy\": 0.9616828560829163, \"f1\": 0.4966659002069441, \"f2\": 0.3814636903079966, \"f0_5\": 0.7115561997628146, \"p4\": 0.6592506858875138, \"phi\": 0.5634476592179212}, {\"truth_threshold\": 35.096972594484036, \"match_probability\": 0.9999999999727881, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2158.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4380.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3300703465938568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6699296236038208, \"precision\": 1.0, \"recall\": 0.3300703465938568, \"specificity\": 1.0, \"npv\": 0.9609273672103882, \"accuracy\": 0.9616653919219971, \"f1\": 0.4963201471941122, \"f2\": 0.3811374072765807, \"f0_5\": 0.7112722478576137, \"p4\": 0.6589440141177277, \"phi\": 0.5631817145289051}, {\"truth_threshold\": 35.108603419671574, \"match_probability\": 0.9999999999730066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2155.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4383.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32961151003837585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6703885197639465, \"precision\": 1.0, \"recall\": 0.32961151003837585, \"specificity\": 1.0, \"npv\": 0.96090167760849, \"accuracy\": 0.9616391062736511, \"f1\": 0.4958012193719084, \"f2\": 0.38064789628007206, \"f0_5\": 0.7108457580155694, \"p4\": 0.6584834827454654, \"phi\": 0.5627825990630115}, {\"truth_threshold\": 35.12249423975554, \"match_probability\": 0.9999999999732653, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2154.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4384.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3294585645198822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6705414652824402, \"precision\": 1.0, \"recall\": 0.3294585645198822, \"specificity\": 1.0, \"npv\": 0.9608930945396423, \"accuracy\": 0.9616303443908691, \"f1\": 0.4956281638288081, \"f2\": 0.38048470288984665, \"f0_5\": 0.7107034446350798, \"p4\": 0.6583298324340099, \"phi\": 0.5626494765443287}, {\"truth_threshold\": 35.13093751253785, \"match_probability\": 0.9999999999734213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2151.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4387.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32899969816207886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6710003018379211, \"precision\": 1.0, \"recall\": 0.32899969816207886, \"specificity\": 1.0, \"npv\": 0.9608674049377441, \"accuracy\": 0.961604118347168, \"f1\": 0.49510875820002304, \"f2\": 0.3799950535278946, \"f0_5\": 0.710276053361511, \"p4\": 0.6578684612500498, \"phi\": 0.5622500117861826}, {\"truth_threshold\": 35.144841779457444, \"match_probability\": 0.9999999999736762, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2150.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4388.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3288467526435852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6711532473564148, \"precision\": 1.0, \"recall\": 0.3288467526435852, \"specificity\": 1.0, \"npv\": 0.9608588218688965, \"accuracy\": 0.961595356464386, \"f1\": 0.4949355432780847, \"f2\": 0.3798318140060773, \"f0_5\": 0.7101334390276126, \"p4\": 0.6577145306082043, \"phi\": 0.5621168114815844}, {\"truth_threshold\": 35.147283887835634, \"match_probability\": 0.9999999999737207, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2149.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4389.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32869377732276917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6713061928749084, \"precision\": 1.0, \"recall\": 0.32869377732276917, \"specificity\": 1.0, \"npv\": 0.9608502388000488, \"accuracy\": 0.961586594581604, \"f1\": 0.49476228847703463, \"f2\": 0.3796685629483057, \"f0_5\": 0.709990749306198, \"p4\": 0.6575605297606504, \"phi\": 0.5619835431400421}, {\"truth_threshold\": 35.15371551104617, \"match_probability\": 0.9999999999738376, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2148.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4390.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3285408318042755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6714591383934021, \"precision\": 1.0, \"recall\": 0.3285408318042755, \"specificity\": 1.0, \"npv\": 0.9608416557312012, \"accuracy\": 0.961577832698822, \"f1\": 0.49458899378309923, \"f2\": 0.3795053003533569, \"f0_5\": 0.7098479841374752, \"p4\": 0.6574064586580515, \"phi\": 0.5618502844182309}, {\"truth_threshold\": 35.17899274756297, \"match_probability\": 0.999999999974292, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2147.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4391.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32838788628578186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6716121435165405, \"precision\": 1.0, \"recall\": 0.32838788628578186, \"specificity\": 1.0, \"npv\": 0.9608331322669983, \"accuracy\": 0.96156907081604, \"f1\": 0.4944156591824986, \"f2\": 0.3793420262200078, \"f0_5\": 0.7097051434615893, \"p4\": 0.6572523172510245, \"phi\": 0.5617169576000411}, {\"truth_threshold\": 35.18548376395479, \"match_probability\": 0.9999999999744075, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2139.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4399.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32716426253318787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6728357076644897, \"precision\": 1.0, \"recall\": 0.32716426253318787, \"specificity\": 1.0, \"npv\": 0.9607645273208618, \"accuracy\": 0.9614990949630737, \"f1\": 0.493027544082056, \"f2\": 0.37803541762397935, \"f0_5\": 0.7085596925930834, \"p4\": 0.6560166490941657, \"phi\": 0.560649482087336}, {\"truth_threshold\": 35.21963473206032, \"match_probability\": 0.9999999999750061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2137.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4401.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32685837149620056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6731416583061218, \"precision\": 1.0, \"recall\": 0.32685837149620056, \"specificity\": 1.0, \"npv\": 0.9607474207878113, \"accuracy\": 0.9614815711975098, \"f1\": 0.4926801152737752, \"f2\": 0.3777086500053024, \"f0_5\": 0.7082725705952538, \"p4\": 0.6557070255398346, \"phi\": 0.5603823095827879}, {\"truth_threshold\": 35.24682491543766, \"match_probability\": 0.9999999999754727, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2135.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4403.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32655245065689087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6734475493431091, \"precision\": 1.0, \"recall\": 0.32655245065689087, \"specificity\": 1.0, \"npv\": 0.960730254650116, \"accuracy\": 0.9614640474319458, \"f1\": 0.4923325262308313, \"f2\": 0.3773818361791636, \"f0_5\": 0.7079851439182916, \"p4\": 0.6553971185826346, \"phi\": 0.5601150191764075}, {\"truth_threshold\": 35.2480251218394, \"match_probability\": 0.9999999999754932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2133.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4405.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32624655961990356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6737534403800964, \"precision\": 1.0, \"recall\": 0.32624655961990356, \"specificity\": 1.0, \"npv\": 0.9607131481170654, \"accuracy\": 0.9614465832710266, \"f1\": 0.49198477684234804, \"f2\": 0.377054976135761, \"f0_5\": 0.7076974120769741, \"p4\": 0.6550869278228434, \"phi\": 0.559847610698813}, {\"truth_threshold\": 35.25865423247605, \"match_probability\": 0.999999999975673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2131.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4407.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32594066858291626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6740593314170837, \"precision\": 1.0, \"recall\": 0.32594066858291626, \"specificity\": 1.0, \"npv\": 0.9606959819793701, \"accuracy\": 0.9614290595054626, \"f1\": 0.4916368669973469, \"f2\": 0.3767280698652901, \"f0_5\": 0.7074093745850485, \"p4\": 0.6547764528599872, \"phi\": 0.5595800839802241}, {\"truth_threshold\": 35.261454907754946, \"match_probability\": 0.9999999999757202, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2129.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4409.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32563474774360657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.674365222454071, \"precision\": 1.0, \"recall\": 0.32563474774360657, \"specificity\": 1.0, \"npv\": 0.9606788754463196, \"accuracy\": 0.9614115357398987, \"f1\": 0.4912887965847467, \"f2\": 0.3764011173579435, \"f0_5\": 0.7071210309552278, \"p4\": 0.6544656932928387, \"phi\": 0.5593124388504612}, {\"truth_threshold\": 35.31955524048762, \"match_probability\": 0.9999999999766787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32532885670661926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6746711730957031, \"precision\": 1.0, \"recall\": 0.32532885670661926, \"specificity\": 1.0, \"npv\": 0.9606617093086243, \"accuracy\": 0.9613940715789795, \"f1\": 0.4909405654933641, \"f2\": 0.37607411860391105, \"f0_5\": 0.7068323806991892, \"p4\": 0.654154648719415, \"phi\": 0.5590447141786647}, {\"truth_threshold\": 35.31960942457519, \"match_probability\": 0.9999999999766794, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2126.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4412.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3251758813858032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6748241186141968, \"precision\": 1.0, \"recall\": 0.3251758813858032, \"specificity\": 1.0, \"npv\": 0.9606531858444214, \"accuracy\": 0.9613853096961975, \"f1\": 0.4907663896583564, \"f2\": 0.3759106018813212, \"f0_5\": 0.706687940433453, \"p4\": 0.6539990194295234, \"phi\": 0.5589107682859734}, {\"truth_threshold\": 35.33017756960308, \"match_probability\": 0.9999999999768497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2124.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4414.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3248699903488159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6751300096511841, \"precision\": 1.0, \"recall\": 0.3248699903488159, \"specificity\": 1.0, \"npv\": 0.9606360197067261, \"accuracy\": 0.9613677859306335, \"f1\": 0.4904179173401062, \"f2\": 0.37558353373885983, \"f0_5\": 0.7063988293202075, \"p4\": 0.6536875465913128, \"phi\": 0.558642826390119}, {\"truth_threshold\": 35.340896038871605, \"match_probability\": 0.999999999977021, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2121.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4417.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3244111239910126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.675588846206665, \"precision\": 1.0, \"recall\": 0.3244111239910126, \"specificity\": 1.0, \"npv\": 0.9606103301048279, \"accuracy\": 0.9613415598869324, \"f1\": 0.4898949070331447, \"f2\": 0.3750928447635553, \"f0_5\": 0.7059645852749301, \"p4\": 0.6532198009302984, \"phi\": 0.5582407098958618}, {\"truth_threshold\": 35.34891774900528, \"match_probability\": 0.9999999999771485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2120.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4418.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3242581784725189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6757417917251587, \"precision\": 1.0, \"recall\": 0.3242581784725189, \"specificity\": 1.0, \"npv\": 0.9606017470359802, \"accuracy\": 0.9613327980041504, \"f1\": 0.4897204897204897, \"f2\": 0.37492925863044707, \"f0_5\": 0.7058196830470103, \"p4\": 0.6530637424666061, \"phi\": 0.5581066244994424}, {\"truth_threshold\": 35.40405930319775, \"match_probability\": 0.9999999999780054, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2119.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4419.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32410523295402527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6758947968482971, \"precision\": 1.0, \"recall\": 0.32410523295402527, \"specificity\": 1.0, \"npv\": 0.9605932235717773, \"accuracy\": 0.9613240361213684, \"f1\": 0.4895460321127411, \"f2\": 0.3747656609246224, \"f0_5\": 0.705674703609964, \"p4\": 0.6529076122967776, \"phi\": 0.5579724701615435}, {\"truth_threshold\": 35.42908828420085, \"match_probability\": 0.9999999999783837, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2117.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4421.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3237993121147156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6762006878852844, \"precision\": 1.0, \"recall\": 0.3237993121147156, \"specificity\": 1.0, \"npv\": 0.960576057434082, \"accuracy\": 0.9613065123558044, \"f1\": 0.4891969959560947, \"f2\": 0.37443843078991124, \"f0_5\": 0.705384512861522, \"p4\": 0.6525951366356755, \"phi\": 0.5577041109865293}, {\"truth_threshold\": 35.500920842450334, \"match_probability\": 0.9999999999794336, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2116.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4422.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3236463665962219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6763536334037781, \"precision\": 1.0, \"recall\": 0.3236463665962219, \"specificity\": 1.0, \"npv\": 0.9605674743652344, \"accuracy\": 0.9612977504730225, \"f1\": 0.48902241737924657, \"f2\": 0.374274798358568, \"f0_5\": 0.7052393014264765, \"p4\": 0.6524387910427637, \"phi\": 0.5575699061242821}, {\"truth_threshold\": 35.507411858842154, \"match_probability\": 0.9999999999795259, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2115.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4423.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.32349342107772827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6765065789222717, \"precision\": 1.0, \"recall\": 0.32349342107772827, \"specificity\": 1.0, \"npv\": 0.9605589509010315, \"accuracy\": 0.9612890481948853, \"f1\": 0.48884779845140414, \"f2\": 0.3741111543495949, \"f0_5\": 0.7050940125350047, \"p4\": 0.6522823735404395, \"phi\": 0.5574356321978043}, {\"truth_threshold\": 35.51904268402969, \"match_probability\": 0.9999999999796904, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2114.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4424.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3233404755592346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6766595244407654, \"precision\": 1.0, \"recall\": 0.3233404755592346, \"specificity\": 1.0, \"npv\": 0.9605503678321838, \"accuracy\": 0.9612802863121033, \"f1\": 0.4886731391585761, \"f2\": 0.37394749876176325, \"f0_5\": 0.7049486461251168, \"p4\": 0.6521258840777638, \"phi\": 0.5573013674727734}, {\"truth_threshold\": 35.54879002742375, \"match_probability\": 0.9999999999801048, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2112.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4426.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3230345547199249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6769654154777527, \"precision\": 1.0, \"recall\": 0.3230345547199249, \"specificity\": 1.0, \"npv\": 0.9605332612991333, \"accuracy\": 0.9612627625465393, \"f1\": 0.4883236994219653, \"f2\": 0.373620152844608, \"f0_5\": 0.7046576805018017, \"p4\": 0.6518126890673613, \"phi\": 0.5570327089472744}, {\"truth_threshold\": 35.62645172453419, \"match_probability\": 0.9999999999811475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2110.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4428.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3227286636829376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6772713661193848, \"precision\": 1.0, \"recall\": 0.3227286636829376, \"specificity\": 1.0, \"npv\": 0.960516095161438, \"accuracy\": 0.9612452387809753, \"f1\": 0.4879740980573543, \"f2\": 0.3732927605972684, \"f0_5\": 0.704366404059287, \"p4\": 0.6514992056030807, \"phi\": 0.5567639303737417}, {\"truth_threshold\": 35.67084584389265, \"match_probability\": 0.9999999999817187, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2107.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4431.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3222697973251343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6777302026748657, \"precision\": 1.0, \"recall\": 0.3222697973251343, \"specificity\": 1.0, \"npv\": 0.9604904055595398, \"accuracy\": 0.9612190127372742, \"f1\": 0.4874493927125506, \"f2\": 0.3728015853356453, \"f0_5\": 0.7039289055191768, \"p4\": 0.6510284386601967, \"phi\": 0.5563605566521763}, {\"truth_threshold\": 35.670910591125036, \"match_probability\": 0.9999999999817196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2105.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4433.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.321963906288147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.678036093711853, \"precision\": 1.0, \"recall\": 0.321963906288147, \"specificity\": 1.0, \"npv\": 0.9604732990264893, \"accuracy\": 0.9612014889717102, \"f1\": 0.48709938678699527, \"f2\": 0.37247407721980397, \"f0_5\": 0.7036368498462361, \"p4\": 0.6507142322690667, \"phi\": 0.5560914772035386}, {\"truth_threshold\": 35.67649240703379, \"match_probability\": 0.9999999999817902, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2104.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4434.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3218109607696533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6781890392303467, \"precision\": 1.0, \"recall\": 0.3218109607696533, \"specificity\": 1.0, \"npv\": 0.9604647159576416, \"accuracy\": 0.9611927270889282, \"f1\": 0.48692432307336264, \"f2\": 0.37231030577576446, \"f0_5\": 0.7034907048281396, \"p4\": 0.6505570203906172, \"phi\": 0.5559568726182897}, {\"truth_threshold\": 35.69356592039273, \"match_probability\": 0.9999999999820044, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2103.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4435.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3216579854488373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6783419847488403, \"precision\": 1.0, \"recall\": 0.3216579854488373, \"specificity\": 1.0, \"npv\": 0.960456132888794, \"accuracy\": 0.961184024810791, \"f1\": 0.486749218840412, \"f2\": 0.3721465227393382, \"f0_5\": 0.7033444816053511, \"p4\": 0.6503997359882993, \"phi\": 0.5558222770944599}, {\"truth_threshold\": 35.70499802360446, \"match_probability\": 0.9999999999821465, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2094.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4444.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.320281445980072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.679718554019928, \"precision\": 1.0, \"recall\": 0.320281445980072, \"specificity\": 1.0, \"npv\": 0.9603790640830994, \"accuracy\": 0.961105227470398, \"f1\": 0.48517145505097314, \"f2\": 0.3706719535509453, \"f0_5\": 0.702024943006571, \"p4\": 0.6489809042764098, \"phi\": 0.5546093983741895}, {\"truth_threshold\": 35.70506155923056, \"match_probability\": 0.9999999999821473, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2093.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4445.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.320128470659256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6798714995384216, \"precision\": 1.0, \"recall\": 0.320128470659256, \"specificity\": 1.0, \"npv\": 0.9603705406188965, \"accuracy\": 0.961096465587616, \"f1\": 0.48499594484995945, \"f2\": 0.3705080545229244, \"f0_5\": 0.7018779342723005, \"p4\": 0.6488228917937312, \"phi\": 0.5544744998202121}, {\"truth_threshold\": 35.729804280178605, \"match_probability\": 0.9999999999824508, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2088.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4450.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31936371326446533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6806362867355347, \"precision\": 1.0, \"recall\": 0.31936371326446533, \"specificity\": 1.0, \"npv\": 0.9603277444839478, \"accuracy\": 0.9610527157783508, \"f1\": 0.48411778344539763, \"f2\": 0.3696883852691218, \"f0_5\": 0.7011417058428475, \"p4\": 0.6480317319391546, \"phi\": 0.5537994714927502}, {\"truth_threshold\": 35.74143510536614, \"match_probability\": 0.9999999999825917, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2085.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3189048767089844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6810951232910156, \"precision\": 1.0, \"recall\": 0.3189048767089844, \"specificity\": 1.0, \"npv\": 0.9603020548820496, \"accuracy\": 0.9610264301300049, \"f1\": 0.48359039777339674, \"f2\": 0.3691964443814853, \"f0_5\": 0.7006990186853072, \"p4\": 0.6475561561948451, \"phi\": 0.5533940566509867}, {\"truth_threshold\": 35.74772541930629, \"match_probability\": 0.9999999999826674, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2082.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4456.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31844601035118103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6815540194511414, \"precision\": 1.0, \"recall\": 0.31844601035118103, \"specificity\": 1.0, \"npv\": 0.9602763652801514, \"accuracy\": 0.9610002040863037, \"f1\": 0.48306264501160096, \"f2\": 0.3687043989516186, \"f0_5\": 0.7002556168438047, \"p4\": 0.6470799188498829, \"phi\": 0.5529884057457684}, {\"truth_threshold\": 35.75201572982439, \"match_probability\": 0.9999999999827189, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2079.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4459.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3179871439933777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6820128560066223, \"precision\": 1.0, \"recall\": 0.3179871439933777, \"specificity\": 1.0, \"npv\": 0.9602506756782532, \"accuracy\": 0.9609739184379578, \"f1\": 0.4825345247766044, \"f2\": 0.3682122489461939, \"f0_5\": 0.6998114985862394, \"p4\": 0.6466030184865763, \"phi\": 0.5525824787729293}, {\"truth_threshold\": 35.753117912515194, \"match_probability\": 0.9999999999827321, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2077.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4461.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3176812529563904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6823187470436096, \"precision\": 1.0, \"recall\": 0.3176812529563904, \"specificity\": 1.0, \"npv\": 0.9602335691452026, \"accuracy\": 0.9609564542770386, \"f1\": 0.48218224027858386, \"f2\": 0.36788409082858053, \"f0_5\": 0.6995150208810454, \"p4\": 0.6462847158655852, \"phi\": 0.5523116939526925}, {\"truth_threshold\": 35.786722654609264, \"match_probability\": 0.9999999999831297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2075.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4463.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3173753321170807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6826246380805969, \"precision\": 1.0, \"recall\": 0.3173753321170807, \"specificity\": 1.0, \"npv\": 0.9602164626121521, \"accuracy\": 0.9609389305114746, \"f1\": 0.48182979217461974, \"f2\": 0.3675558862082403, \"f0_5\": 0.6992182234802534, \"p4\": 0.645966117515711, \"phi\": 0.5520407859704944}, {\"truth_threshold\": 35.78916894917483, \"match_probability\": 0.9999999999831582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2073.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4465.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3170694410800934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.682930588722229, \"precision\": 1.0, \"recall\": 0.3170694410800934, \"specificity\": 1.0, \"npv\": 0.9601992964744568, \"accuracy\": 0.9609214067459106, \"f1\": 0.4814771803507142, \"f2\": 0.3672276350752879, \"f0_5\": 0.6989211058664868, \"p4\": 0.6456472230138873, \"phi\": 0.5517697546444078}, {\"truth_threshold\": 35.806984636525385, \"match_probability\": 0.999999999983365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2072.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4466.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31691649556159973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6830835342407227, \"precision\": 1.0, \"recall\": 0.31691649556159973, \"specificity\": 1.0, \"npv\": 0.9601907730102539, \"accuracy\": 0.9609127044677734, \"f1\": 0.4813008130081301, \"f2\": 0.36706349206349204, \"f0_5\": 0.6987724268177526, \"p4\": 0.6454876645735658, \"phi\": 0.5516341728980466}, {\"truth_threshold\": 35.83178741615881, \"match_probability\": 0.9999999999836485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2070.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31661057472229004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.68338942527771, \"precision\": 1.0, \"recall\": 0.31661057472229004, \"specificity\": 1.0, \"npv\": 0.9601736664772034, \"accuracy\": 0.9608951807022095, \"f1\": 0.4809479553903346, \"f2\": 0.36673517114307985, \"f0_5\": 0.6984748279119989, \"p4\": 0.6451683250488033, \"phi\": 0.551362995768197}, {\"truth_threshold\": 35.8518600966475, \"match_probability\": 0.9999999999838745, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2069.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4469.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3164576292037964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6835423707962036, \"precision\": 1.0, \"recall\": 0.3164576292037964, \"specificity\": 1.0, \"npv\": 0.9601650834083557, \"accuracy\": 0.9608864188194275, \"f1\": 0.48077146508655744, \"f2\": 0.3665709932319904, \"f0_5\": 0.6983259079249359, \"p4\": 0.6450085438580905, \"phi\": 0.5512273212306565}, {\"truth_threshold\": 35.85700111704951, \"match_probability\": 0.9999999999839319, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2068.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4470.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31630468368530273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6836953163146973, \"precision\": 1.0, \"recall\": 0.31630468368530273, \"specificity\": 1.0, \"npv\": 0.9601565003395081, \"accuracy\": 0.9608776569366455, \"f1\": 0.4805949337671392, \"f2\": 0.3664068036853296, \"f0_5\": 0.6981769074949359, \"p4\": 0.6448486883108909, \"phi\": 0.5510916552929509}, {\"truth_threshold\": 35.85706465267561, \"match_probability\": 0.9999999999839325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2067.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4471.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3161517381668091, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6838482618331909, \"precision\": 1.0, \"recall\": 0.3161517381668091, \"specificity\": 1.0, \"npv\": 0.9601479768753052, \"accuracy\": 0.9608688950538635, \"f1\": 0.4804183614177804, \"f2\": 0.36624260250186047, \"f0_5\": 0.6980278265568013, \"p4\": 0.6446887583539418, \"phi\": 0.5509559187769303}, {\"truth_threshold\": 35.85729597677891, \"match_probability\": 0.9999999999839351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2063.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4475.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3155399262905121, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6844601035118103, \"precision\": 1.0, \"recall\": 0.3155399262905121, \"specificity\": 1.0, \"npv\": 0.9601137042045593, \"accuracy\": 0.9608339071273804, \"f1\": 0.4797116614347169, \"f2\": 0.36558568137515507, \"f0_5\": 0.6974306964164977, \"p4\": 0.6440482933616116, \"phi\": 0.5504127810866375}, {\"truth_threshold\": 35.87864879459905, \"match_probability\": 0.9999999999841711, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2062.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4476.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31538698077201843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.684613049030304, \"precision\": 1.0, \"recall\": 0.31538698077201843, \"specificity\": 1.0, \"npv\": 0.9601051807403564, \"accuracy\": 0.9608251452445984, \"f1\": 0.4795348837209302, \"f2\": 0.36542142198908345, \"f0_5\": 0.6972812119572569, \"p4\": 0.64388799055519, \"phi\": 0.5502768892265018}, {\"truth_threshold\": 35.88159540736924, \"match_probability\": 0.9999999999842034, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2061.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4477.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3152340054512024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6847659945487976, \"precision\": 1.0, \"recall\": 0.3152340054512024, \"specificity\": 1.0, \"npv\": 0.9600965976715088, \"accuracy\": 0.9608163833618164, \"f1\": 0.4793580648912664, \"f2\": 0.36525715095877787, \"f0_5\": 0.6971316465972128, \"p4\": 0.6437276130183716, \"phi\": 0.550141005870857}, {\"truth_threshold\": 35.929849161813145, \"match_probability\": 0.999999999984723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2060.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4478.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31508105993270874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6849189400672913, \"precision\": 1.0, \"recall\": 0.31508105993270874, \"specificity\": 1.0, \"npv\": 0.9600880742073059, \"accuracy\": 0.9608076810836792, \"f1\": 0.4791812049313794, \"f2\": 0.36509286828300014, \"f0_5\": 0.6969820002706726, \"p4\": 0.6435671606975363, \"phi\": 0.550005051709556}, {\"truth_threshold\": 35.93612252345852, \"match_probability\": 0.9999999999847893, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2059.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4479.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3149281144142151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6850718855857849, \"precision\": 1.0, \"recall\": 0.3149281144142151, \"specificity\": 1.0, \"npv\": 0.9600794911384583, \"accuracy\": 0.9607989192008972, \"f1\": 0.4790043038269164, \"f2\": 0.36492857396051187, \"f0_5\": 0.6968322729118722, \"p4\": 0.6434066335390126, \"phi\": 0.5498691060253135}, {\"truth_threshold\": 35.94433848319274, \"match_probability\": 0.9999999999848757, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2057.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4481.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3146222233772278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6853777766227722, \"precision\": 1.0, \"recall\": 0.3146222233772278, \"specificity\": 1.0, \"npv\": 0.9600623846054077, \"accuracy\": 0.9607813954353333, \"f1\": 0.47865037812681793, \"f2\": 0.3645999503704491, \"f0_5\": 0.6965325748340783, \"p4\": 0.6430853544939577, \"phi\": 0.5495970813645152}, {\"truth_threshold\": 35.95660032622652, \"match_probability\": 0.9999999999850037, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2055.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4483.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3143163025379181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6856836676597595, \"precision\": 1.0, \"recall\": 0.3143163025379181, \"specificity\": 1.0, \"npv\": 0.9600452780723572, \"accuracy\": 0.9607638716697693, \"f1\": 0.47829628767601534, \"f2\": 0.36427128017867905, \"f0_5\": 0.6962325518362922, \"p4\": 0.6427637754528069, \"phi\": 0.5493249317025185}, {\"truth_threshold\": 36.00096547884328, \"match_probability\": 0.9999999999854579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2053.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4485.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3140104115009308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6859896183013916, \"precision\": 1.0, \"recall\": 0.3140104115009308, \"specificity\": 1.0, \"npv\": 0.9600281715393066, \"accuracy\": 0.9607464075088501, \"f1\": 0.47794203235944593, \"f2\": 0.3639425633752881, \"f0_5\": 0.6959322033898305, \"p4\": 0.6424418959843361, \"phi\": 0.5490526568529256}, {\"truth_threshold\": 36.02698965411792, \"match_probability\": 0.9999999999857178, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2052.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4486.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31385743618011475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6861425638198853, \"precision\": 1.0, \"recall\": 0.31385743618011475, \"specificity\": 1.0, \"npv\": 0.960019588470459, \"accuracy\": 0.9607376456260681, \"f1\": 0.47776484284051224, \"f2\": 0.363778187491136, \"f0_5\": 0.695781906957819, \"p4\": 0.6422808434548721, \"phi\": 0.5489164922911459}, {\"truth_threshold\": 36.03321907165408, \"match_probability\": 0.9999999999857794, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2049.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4489.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3133985996246338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6866014003753662, \"precision\": 1.0, \"recall\": 0.3133985996246338, \"specificity\": 1.0, \"npv\": 0.9599939584732056, \"accuracy\": 0.9607113599777222, \"f1\": 0.47723302666821943, \"f2\": 0.3632849898939754, \"f0_5\": 0.6953305280304058, \"p4\": 0.6417972340364017, \"phi\": 0.5485077308430812}, {\"truth_threshold\": 36.0445051745899, \"match_probability\": 0.9999999999858902, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2048.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4490.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31324565410614014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6867543458938599, \"precision\": 1.0, \"recall\": 0.31324565410614014, \"specificity\": 1.0, \"npv\": 0.9599853754043579, \"accuracy\": 0.9607025980949402, \"f1\": 0.4770556720242255, \"f2\": 0.36312056737588655, \"f0_5\": 0.6951799049558723, \"p4\": 0.6416358801062595, \"phi\": 0.5483714406916368}, {\"truth_threshold\": 36.08588334317149, \"match_probability\": 0.9999999999862891, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2046.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4492.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31293973326683044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6870602369308472, \"precision\": 1.0, \"recall\": 0.31293973326683044, \"specificity\": 1.0, \"npv\": 0.9599682688713074, \"accuracy\": 0.960685133934021, \"f1\": 0.4767008387698043, \"f2\": 0.36279168735371303, \"f0_5\": 0.6948784132590681, \"p4\": 0.6413129457343244, \"phi\": 0.5480987262205246}, {\"truth_threshold\": 36.107383972463644, \"match_probability\": 0.9999999999864919, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2044.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4494.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31263384222984314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6873661875724792, \"precision\": 1.0, \"recall\": 0.31263384222984314, \"specificity\": 1.0, \"npv\": 0.9599511623382568, \"accuracy\": 0.960667610168457, \"f1\": 0.4763458401305057, \"f2\": 0.3624627606752731, \"f0_5\": 0.6945765937202664, \"p4\": 0.6409897089843016, \"phi\": 0.5478258857173813}, {\"truth_threshold\": 36.108374784593515, \"match_probability\": 0.9999999999865011, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2043.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3124808669090271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6875191330909729, \"precision\": 1.0, \"recall\": 0.3124808669090271, \"specificity\": 1.0, \"npv\": 0.959942638874054, \"accuracy\": 0.960658848285675, \"f1\": 0.4761682787553898, \"f2\": 0.3622982798368505, \"f0_5\": 0.6944255608429639, \"p4\": 0.640827977081354, \"phi\": 0.5476894380544299}, {\"truth_threshold\": 36.133927986013425, \"match_probability\": 0.9999999999867382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2041.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4497.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3121749758720398, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6878250241279602, \"precision\": 1.0, \"recall\": 0.3121749758720398, \"specificity\": 1.0, \"npv\": 0.9599254727363586, \"accuracy\": 0.9606413841247559, \"f1\": 0.47581303182189066, \"f2\": 0.3619692831553932, \"f0_5\": 0.694123248537614, \"p4\": 0.640504285946822, \"phi\": 0.5474164081584411}, {\"truth_threshold\": 36.134520299144945, \"match_probability\": 0.9999999999867436, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2040.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4498.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31202203035354614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6879779696464539, \"precision\": 1.0, \"recall\": 0.31202203035354614, \"specificity\": 1.0, \"npv\": 0.9599169492721558, \"accuracy\": 0.9606326222419739, \"f1\": 0.4756353462345535, \"f2\": 0.36180476730987515, \"f0_5\": 0.6939719689753708, \"p4\": 0.6403423266059745, \"phi\": 0.5472798258588489}, {\"truth_threshold\": 36.14783529880649, \"match_probability\": 0.9999999999868654, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2039.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4499.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3118690848350525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6881309151649475, \"precision\": 1.0, \"recall\": 0.3118690848350525, \"specificity\": 1.0, \"npv\": 0.9599083662033081, \"accuracy\": 0.9606238603591919, \"f1\": 0.47545761921417745, \"f2\": 0.3616402397928417, \"f0_5\": 0.6938206070504968, \"p4\": 0.640180291343143, \"phi\": 0.5471432517572591}, {\"truth_threshold\": 36.15647260464499, \"match_probability\": 0.9999999999869438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2038.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4500.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31171610951423645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6882838606834412, \"precision\": 1.0, \"recall\": 0.31171610951423645, \"specificity\": 1.0, \"npv\": 0.9598998427391052, \"accuracy\": 0.9606150984764099, \"f1\": 0.47527985074626866, \"f2\": 0.36147570060305073, \"f0_5\": 0.6936691626957113, \"p4\": 0.6400181801035648, \"phi\": 0.5470066459914532}, {\"truth_threshold\": 36.15956668848266, \"match_probability\": 0.9999999999869718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2037.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4501.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3115631639957428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6884368062019348, \"precision\": 1.0, \"recall\": 0.3115631639957428, \"specificity\": 1.0, \"npv\": 0.9598912596702576, \"accuracy\": 0.9606063365936279, \"f1\": 0.4751020408163265, \"f2\": 0.36131114973926, \"f0_5\": 0.6935176358436607, \"p4\": 0.6398559928324241, \"phi\": 0.5468699686607986}, {\"truth_threshold\": 36.178322105371876, \"match_probability\": 0.9999999999871401, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2035.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4503.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3112572729587555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6887427568435669, \"precision\": 1.0, \"recall\": 0.3112572729587555, \"specificity\": 1.0, \"npv\": 0.959874153137207, \"accuracy\": 0.9605888724327087, \"f1\": 0.4747462965123061, \"f2\": 0.3609820129847093, \"f0_5\": 0.6932143343779806, \"p4\": 0.6395313899759298, \"phi\": 0.5465965586785062}, {\"truth_threshold\": 36.17899274756297, \"match_probability\": 0.9999999999871461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2032.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4506.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31079840660095215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6892015933990479, \"precision\": 1.0, \"recall\": 0.31079840660095215, \"specificity\": 1.0, \"npv\": 0.9598485231399536, \"accuracy\": 0.9605625867843628, \"f1\": 0.47421236872812134, \"f2\": 0.36048822026681804, \"f0_5\": 0.6927587617618983, \"p4\": 0.639043914081046, \"phi\": 0.54618622533863}, {\"truth_threshold\": 36.19190826155467, \"match_probability\": 0.9999999999872605, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2028.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4510.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.31018659472465515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6898133754730225, \"precision\": 1.0, \"recall\": 0.31018659472465515, \"specificity\": 1.0, \"npv\": 0.9598143100738525, \"accuracy\": 0.9605275988578796, \"f1\": 0.4734998832593976, \"f2\": 0.3598296664300923, \"f0_5\": 0.6921501706484642, \"p4\": 0.6383928769011322, \"phi\": 0.5456386417342095}, {\"truth_threshold\": 36.20321815809597, \"match_probability\": 0.99999999998736, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2026.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4512.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30988070368766785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6901193261146545, \"precision\": 1.0, \"recall\": 0.30988070368766785, \"specificity\": 1.0, \"npv\": 0.959797203540802, \"accuracy\": 0.9605100750923157, \"f1\": 0.47314339093881363, \"f2\": 0.359500319398112, \"f0_5\": 0.6918453763147111, \"p4\": 0.6380668990366003, \"phi\": 0.5453646584046214}, {\"truth_threshold\": 36.20799947715973, \"match_probability\": 0.9999999999874019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2025.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4513.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3097277581691742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6902722716331482, \"precision\": 1.0, \"recall\": 0.3097277581691742, \"specificity\": 1.0, \"npv\": 0.9597886800765991, \"accuracy\": 0.9605013132095337, \"f1\": 0.4729650823309588, \"f2\": 0.35933562834936295, \"f0_5\": 0.6916928542150567, \"p4\": 0.6379037950918405, \"phi\": 0.5452276387698947}, {\"truth_threshold\": 36.24416548675394, \"match_probability\": 0.9999999999877137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2024.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4514.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30957478284835815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6904252171516418, \"precision\": 1.0, \"recall\": 0.30957478284835815, \"specificity\": 1.0, \"npv\": 0.9597800970077515, \"accuracy\": 0.9604925513267517, \"f1\": 0.4727867320719458, \"f2\": 0.3591709256104486, \"f0_5\": 0.6915402487358207, \"p4\": 0.6377406143980945, \"phi\": 0.5450905871351106}, {\"truth_threshold\": 36.25865423247605, \"match_probability\": 0.9999999999878365, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2023.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4515.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3094218373298645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6905781626701355, \"precision\": 1.0, \"recall\": 0.3094218373298645, \"specificity\": 1.0, \"npv\": 0.9597715735435486, \"accuracy\": 0.9604838490486145, \"f1\": 0.47260834014717906, \"f2\": 0.3590062111801242, \"f0_5\": 0.6913875598086124, \"p4\": 0.6375773568998029, \"phi\": 0.5449534634639733}, {\"truth_threshold\": 36.26966829558612, \"match_probability\": 0.999999999987929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2022.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4516.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30926889181137085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6907311081886292, \"precision\": 1.0, \"recall\": 0.30926889181137085, \"specificity\": 1.0, \"npv\": 0.9597629904747009, \"accuracy\": 0.9604750871658325, \"f1\": 0.4724299065420561, \"f2\": 0.35884148505714486, \"f0_5\": 0.6912347873649665, \"p4\": 0.6374140225413524, \"phi\": 0.5448163477467038}, {\"truth_threshold\": 36.30452362964683, \"match_probability\": 0.9999999999882172, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2021.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4517.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3091159462928772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6908840537071228, \"precision\": 1.0, \"recall\": 0.3091159462928772, \"specificity\": 1.0, \"npv\": 0.959754467010498, \"accuracy\": 0.9604663252830505, \"f1\": 0.4722514312419675, \"f2\": 0.3586767472402655, \"f0_5\": 0.6910819313363425, \"p4\": 0.6372506112670763, \"phi\": 0.5446791599251299}, {\"truth_threshold\": 36.30506669559861, \"match_probability\": 0.9999999999882216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2020.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4518.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30896297097206116, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6910369992256165, \"precision\": 1.0, \"recall\": 0.30896297097206116, \"specificity\": 1.0, \"npv\": 0.9597458839416504, \"accuracy\": 0.9604575634002686, \"f1\": 0.47207291423229725, \"f2\": 0.3585119977282408, \"f0_5\": 0.690928991654125, \"p4\": 0.6370871230212538, \"phi\": 0.5445419800282711}, {\"truth_threshold\": 36.305090346434845, \"match_probability\": 0.9999999999882218, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2018.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4520.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30865707993507385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6913428902626038, \"precision\": 1.0, \"recall\": 0.30865707993507385, \"specificity\": 1.0, \"npv\": 0.9597287774085999, \"accuracy\": 0.9604400396347046, \"f1\": 0.47171575502571295, \"f2\": 0.35818246361377354, \"f0_5\": 0.6906228610540726, \"p4\": 0.6367599153918185, \"phi\": 0.5442674837852144}, {\"truth_threshold\": 36.35543184114977, \"match_probability\": 0.9999999999886257, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2017.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4521.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3085041344165802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6914958953857422, \"precision\": 1.0, \"recall\": 0.3085041344165802, \"specificity\": 1.0, \"npv\": 0.959720253944397, \"accuracy\": 0.9604313373565674, \"f1\": 0.4715371127995324, \"f2\": 0.3580176790088395, \"f0_5\": 0.6904696699986307, \"p4\": 0.6365961958964951, \"phi\": 0.5441301673707656}, {\"truth_threshold\": 36.36946166411376, \"match_probability\": 0.9999999999887358, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2014.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4524.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30804526805877686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6919547319412231, \"precision\": 1.0, \"recall\": 0.30804526805877686, \"specificity\": 1.0, \"npv\": 0.9596945643424988, \"accuracy\": 0.9604050517082214, \"f1\": 0.47100093545369504, \"f2\": 0.35752325498828375, \"f0_5\": 0.6900095929834178, \"p4\": 0.6361045740167038, \"phi\": 0.5437181049444143}, {\"truth_threshold\": 36.374131449895984, \"match_probability\": 0.9999999999887722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2013.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4525.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3078923225402832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6921076774597168, \"precision\": 1.0, \"recall\": 0.3078923225402832, \"specificity\": 1.0, \"npv\": 0.9596860408782959, \"accuracy\": 0.9603962898254395, \"f1\": 0.47082212606712665, \"f2\": 0.35735842357535946, \"f0_5\": 0.6898560657984921, \"p4\": 0.6359405454053514, \"phi\": 0.5435806996557009}, {\"truth_threshold\": 36.37886502598143, \"match_probability\": 0.999999999988809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2012.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4526.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30773937702178955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6922606229782104, \"precision\": 1.0, \"recall\": 0.30773937702178955, \"specificity\": 1.0, \"npv\": 0.959677517414093, \"accuracy\": 0.9603875279426575, \"f1\": 0.4706432748538012, \"f2\": 0.3571935804573214, \"f0_5\": 0.6897024544083368, \"p4\": 0.6357764393747449, \"phi\": 0.5434432219550489}, {\"truth_threshold\": 36.401655693782196, \"match_probability\": 0.9999999999889844, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2009.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4529.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3072805106639862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6927194595336914, \"precision\": 1.0, \"recall\": 0.3072805106639862, \"specificity\": 1.0, \"npv\": 0.9596518278121948, \"accuracy\": 0.9603613018989563, \"f1\": 0.4701064701064701, \"f2\": 0.3566989808600547, \"f0_5\": 0.6892411143131604, \"p4\": 0.6352836562050559, \"phi\": 0.5430306750315649}, {\"truth_threshold\": 36.427239435703946, \"match_probability\": 0.999999999989178, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2006.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4532.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30682164430618286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6931783556938171, \"precision\": 1.0, \"recall\": 0.30682164430618286, \"specificity\": 1.0, \"npv\": 0.9596261978149414, \"accuracy\": 0.9603350162506104, \"f1\": 0.4695692883895131, \"f2\": 0.35620427587186587, \"f0_5\": 0.6887790138717209, \"p4\": 0.6347901742353489, \"phi\": 0.542617836529322}, {\"truth_threshold\": 36.442027153396765, \"match_probability\": 0.9999999999892883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2005.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4533.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3066686987876892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6933313012123108, \"precision\": 1.0, \"recall\": 0.3066686987876892, \"specificity\": 1.0, \"npv\": 0.9596176743507385, \"accuracy\": 0.9603262543678284, \"f1\": 0.4693901439775255, \"f2\": 0.356039350783109, \"f0_5\": 0.6886248111004258, \"p4\": 0.6346255246931078, \"phi\": 0.5424801319925651}, {\"truth_threshold\": 36.49688975453704, \"match_probability\": 0.999999999989688, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2004.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4534.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30651575326919556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6934842467308044, \"precision\": 1.0, \"recall\": 0.30651575326919556, \"specificity\": 1.0, \"npv\": 0.9596090912818909, \"accuracy\": 0.9603175520896912, \"f1\": 0.469210957621166, \"f2\": 0.3558744139792584, \"f0_5\": 0.6884705235674041, \"p4\": 0.6344607972804271, \"phi\": 0.54234243514398}, {\"truth_threshold\": 36.500920842450334, \"match_probability\": 0.9999999999897168, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2003.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4535.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3063628077507019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6936371922492981, \"precision\": 1.0, \"recall\": 0.3063628077507019, \"specificity\": 1.0, \"npv\": 0.959600567817688, \"accuracy\": 0.9603087902069092, \"f1\": 0.4690317293057019, \"f2\": 0.3557094654590659, \"f0_5\": 0.6883161512027491, \"p4\": 0.6342959919406623, \"phi\": 0.5422046655727489}, {\"truth_threshold\": 36.51703732100558, \"match_probability\": 0.999999999989831, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2001.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4537.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3060568869113922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6939430832862854, \"precision\": 1.0, \"recall\": 0.3060568869113922, \"specificity\": 1.0, \"npv\": 0.9595834612846375, \"accuracy\": 0.9602912664413452, \"f1\": 0.468673146738494, \"f2\": 0.355379533264661, \"f0_5\": 0.6880071516985284, \"p4\": 0.6339661472530284, \"phi\": 0.5419290689545352}, {\"truth_threshold\": 36.53705146405978, \"match_probability\": 0.9999999999899711, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2000.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4538.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30590394139289856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.694096028804779, \"precision\": 1.0, \"recall\": 0.30590394139289856, \"specificity\": 1.0, \"npv\": 0.9595748782157898, \"accuracy\": 0.9602825045585632, \"f1\": 0.4684937924572499, \"f2\": 0.3552145495879511, \"f0_5\": 0.6878525244187647, \"p4\": 0.6338011077915954, \"phi\": 0.5417912418774673}, {\"truth_threshold\": 36.55503148599162, \"match_probability\": 0.9999999999900954, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1997.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4541.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3054451048374176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6945549249649048, \"precision\": 1.0, \"recall\": 0.3054451048374176, \"specificity\": 1.0, \"npv\": 0.9595492482185364, \"accuracy\": 0.9602562785148621, \"f1\": 0.46795547744581134, \"f2\": 0.35471952822480374, \"f0_5\": 0.6873881316260498, \"p4\": 0.633305520254292, \"phi\": 0.5413775245924146}, {\"truth_threshold\": 36.56999462466062, \"match_probability\": 0.9999999999901975, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1994.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4544.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30498623847961426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6950137615203857, \"precision\": 1.0, \"recall\": 0.30498623847961426, \"specificity\": 1.0, \"npv\": 0.959523618221283, \"accuracy\": 0.9602299928665161, \"f1\": 0.4674167838724801, \"f2\": 0.35422440133589145, \"f0_5\": 0.6869229709246245, \"p4\": 0.632809227790425, \"phi\": 0.540963472745431}, {\"truth_threshold\": 36.57151010392383, \"match_probability\": 0.9999999999902078, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1993.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4545.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3048332929611206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6951667070388794, \"precision\": 1.0, \"recall\": 0.3048332929611206, \"specificity\": 1.0, \"npv\": 0.9595150947570801, \"accuracy\": 0.9602212309837341, \"f1\": 0.4672371351541437, \"f2\": 0.354059335583585, \"f0_5\": 0.6867677463818056, \"p4\": 0.6326436400522588, \"phi\": 0.5408254168116612}, {\"truth_threshold\": 36.60792106692578, \"match_probability\": 0.9999999999904519, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1991.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4547.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3045273721218109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6954725980758667, \"precision\": 1.0, \"recall\": 0.3045273721218109, \"specificity\": 1.0, \"npv\": 0.9594979882240295, \"accuracy\": 0.9602037668228149, \"f1\": 0.4668777113377887, \"f2\": 0.3537291688874676, \"f0_5\": 0.6864570404082195, \"p4\": 0.6323122288571794, \"phi\": 0.5405491662223736}, {\"truth_threshold\": 36.60801547098346, \"match_probability\": 0.9999999999904525, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1989.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4549.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3042214810848236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6957785487174988, \"precision\": 1.0, \"recall\": 0.3042214810848236, \"specificity\": 1.0, \"npv\": 0.959480881690979, \"accuracy\": 0.960186243057251, \"f1\": 0.46651811891638323, \"f2\": 0.35339895526100706, \"f0_5\": 0.6861459914447358, \"p4\": 0.6319805029881053, \"phi\": 0.5402727842316072}, {\"truth_threshold\": 36.62595788794621, \"match_probability\": 0.9999999999905705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1988.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4550.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30406853556632996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6959314942359924, \"precision\": 1.0, \"recall\": 0.30406853556632996, \"specificity\": 1.0, \"npv\": 0.9594723582267761, \"accuracy\": 0.960177481174469, \"f1\": 0.4663382594417077, \"f2\": 0.35323383084577115, \"f0_5\": 0.6859903381642513, \"p4\": 0.6318145219072362, \"phi\": 0.5401345640757127}, {\"truth_threshold\": 36.64112964085645, \"match_probability\": 0.9999999999906691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1987.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4551.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3039155602455139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6960844397544861, \"precision\": 1.0, \"recall\": 0.3039155602455139, \"specificity\": 1.0, \"npv\": 0.9594637751579285, \"accuracy\": 0.960168719291687, \"f1\": 0.466158357771261, \"f2\": 0.35306869469419666, \"f0_5\": 0.6858345989230982, \"p4\": 0.6316484619854558, \"phi\": 0.5399962706370729}, {\"truth_threshold\": 36.641899431815226, \"match_probability\": 0.9999999999906741, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1986.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4552.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30376261472702026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6962373852729797, \"precision\": 1.0, \"recall\": 0.30376261472702026, \"specificity\": 1.0, \"npv\": 0.9594552516937256, \"accuracy\": 0.9601600170135498, \"f1\": 0.4659784138901924, \"f2\": 0.35290354680503233, \"f0_5\": 0.6856787736500484, \"p4\": 0.6314823231651768, \"phi\": 0.5398579846132543}, {\"truth_threshold\": 36.68193509520519, \"match_probability\": 0.9999999999909294, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1985.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4553.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3036096692085266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6963903307914734, \"precision\": 1.0, \"recall\": 0.3036096692085266, \"specificity\": 1.0, \"npv\": 0.9594467282295227, \"accuracy\": 0.9601512551307678, \"f1\": 0.4657984277836443, \"f2\": 0.3527383871770267, \"f0_5\": 0.6855228622737948, \"p4\": 0.6313161053887556, \"phi\": 0.5397196252359707}, {\"truth_threshold\": 36.682541416312574, \"match_probability\": 0.9999999999909331, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1984.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4554.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30345672369003296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.696543276309967, \"precision\": 1.0, \"recall\": 0.30345672369003296, \"specificity\": 1.0, \"npv\": 0.959438145160675, \"accuracy\": 0.9601424932479858, \"f1\": 0.46561839943675193, \"f2\": 0.3525732158089281, \"f0_5\": 0.6853668647229515, \"p4\": 0.6311498085984927, \"phi\": 0.5395812732426513}, {\"truth_threshold\": 36.70332147303232, \"match_probability\": 0.9999999999910628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1979.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4559.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3026919662952423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6973080635070801, \"precision\": 1.0, \"recall\": 0.3026919662952423, \"specificity\": 1.0, \"npv\": 0.9593954086303711, \"accuracy\": 0.9600987434387207, \"f1\": 0.46471762357637664, \"f2\": 0.35174718282321993, \"f0_5\": 0.6845855818458558, \"p4\": 0.630317137416123, \"phi\": 0.5388889366040781}, {\"truth_threshold\": 36.737753164534645, \"match_probability\": 0.9999999999912736, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1978.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4560.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30253899097442627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6974610090255737, \"precision\": 1.0, \"recall\": 0.30253899097442627, \"specificity\": 1.0, \"npv\": 0.9593868851661682, \"accuracy\": 0.9600899815559387, \"f1\": 0.46453734147487086, \"f2\": 0.3515819409882687, \"f0_5\": 0.6844290657439447, \"p4\": 0.6301503653279633, \"phi\": 0.5387503456437037}, {\"truth_threshold\": 36.76395524828413, \"match_probability\": 0.9999999999914306, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1975.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4563.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3020801544189453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6979198455810547, \"precision\": 1.0, \"recall\": 0.3020801544189453, \"specificity\": 1.0, \"npv\": 0.9593612551689148, \"accuracy\": 0.9600636959075928, \"f1\": 0.46399624104311055, \"f2\": 0.3510861449852455, \"f0_5\": 0.6839589970910098, \"p4\": 0.6296495723149178, \"phi\": 0.5383344544847051}, {\"truth_threshold\": 36.77620052352682, \"match_probability\": 0.9999999999915031, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1972.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4566.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30162128806114197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6983786821365356, \"precision\": 1.0, \"recall\": 0.30162128806114197, \"specificity\": 1.0, \"npv\": 0.9593356251716614, \"accuracy\": 0.9600374698638916, \"f1\": 0.463454759106933, \"f2\": 0.3505902432086474, \"f0_5\": 0.6834881464023291, \"p4\": 0.6291480629560556, \"phi\": 0.5379182640289267}, {\"truth_threshold\": 36.80185143269084, \"match_probability\": 0.9999999999916528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1971.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4567.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3014683425426483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6985316872596741, \"precision\": 1.0, \"recall\": 0.3014683425426483, \"specificity\": 1.0, \"npv\": 0.9593271017074585, \"accuracy\": 0.9600287079811096, \"f1\": 0.46327418027970385, \"f2\": 0.3504249191053586, \"f0_5\": 0.6833310220496464, \"p4\": 0.6289807337095074, \"phi\": 0.5377794402281589}, {\"truth_threshold\": 36.81182443325754, \"match_probability\": 0.9999999999917103, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1970.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4568.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30131539702415466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6986846327781677, \"precision\": 1.0, \"recall\": 0.30131539702415466, \"specificity\": 1.0, \"npv\": 0.9593185186386108, \"accuracy\": 0.9600199460983276, \"f1\": 0.463093559003291, \"f2\": 0.35025958324443496, \"f0_5\": 0.6831738105146344, \"p4\": 0.628813324635388, \"phi\": 0.5376406235925925}, {\"truth_threshold\": 36.82131155132907, \"match_probability\": 0.9999999999917647, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1967.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4571.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3008565306663513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6991434693336487, \"precision\": 1.0, \"recall\": 0.3008565306663513, \"specificity\": 1.0, \"npv\": 0.9592928886413574, \"accuracy\": 0.9599937200546265, \"f1\": 0.46255144032921813, \"f2\": 0.34976350510331095, \"f0_5\": 0.6827016520894071, \"p4\": 0.6283106178618147, \"phi\": 0.5372239327484674}, {\"truth_threshold\": 36.84488089119916, \"match_probability\": 0.9999999999918981, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1966.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4572.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30070358514785767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6992964148521423, \"precision\": 1.0, \"recall\": 0.30070358514785767, \"specificity\": 1.0, \"npv\": 0.9592843651771545, \"accuracy\": 0.9599849581718445, \"f1\": 0.46237064910630293, \"f2\": 0.3495981221993029, \"f0_5\": 0.6825440910984586, \"p4\": 0.6281428888913362, \"phi\": 0.5370849418585917}, {\"truth_threshold\": 36.8518600966475, \"match_probability\": 0.9999999999919372, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1965.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4573.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.300550639629364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.699449360370636, \"precision\": 1.0, \"recall\": 0.300550639629364, \"specificity\": 1.0, \"npv\": 0.9592758417129517, \"accuracy\": 0.9599761962890625, \"f1\": 0.46218981535928494, \"f2\": 0.3494327275313867, \"f0_5\": 0.6823864425614669, \"p4\": 0.6279750797999626, \"phi\": 0.5369459580545982}, {\"truth_threshold\": 36.85945983392175, \"match_probability\": 0.9999999999919796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1964.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4574.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.300397664308548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6996023058891296, \"precision\": 1.0, \"recall\": 0.300397664308548, \"specificity\": 1.0, \"npv\": 0.959267258644104, \"accuracy\": 0.9599674344062805, \"f1\": 0.46200893907315926, \"f2\": 0.349267321098307, \"f0_5\": 0.6822287064054467, \"p4\": 0.6278071905288566, \"phi\": 0.5368069001449104}, {\"truth_threshold\": 36.863490921835044, \"match_probability\": 0.999999999992002, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1963.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4575.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.3002447187900543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6997552514076233, \"precision\": 1.0, \"recall\": 0.3002447187900543, \"specificity\": 1.0, \"npv\": 0.9592587351799011, \"accuracy\": 0.9599586725234985, \"f1\": 0.46182802023291375, \"f2\": 0.3491019028988085, \"f0_5\": 0.6820708825573315, \"p4\": 0.6276392210191235, \"phi\": 0.5366678492891976}, {\"truth_threshold\": 36.86657596229848, \"match_probability\": 0.999999999992019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1962.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4576.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.30009177327156067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6999082565307617, \"precision\": 1.0, \"recall\": 0.30009177327156067, \"specificity\": 1.0, \"npv\": 0.9592502117156982, \"accuracy\": 0.9599499106407166, \"f1\": 0.4616470588235294, \"f2\": 0.3489364729316355, \"f0_5\": 0.6819129709439733, \"p4\": 0.627471171211811, \"phi\": 0.5365287242552133}, {\"truth_threshold\": 36.87454135719477, \"match_probability\": 0.999999999992063, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1960.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4578.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.299785852432251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.700214147567749, \"precision\": 1.0, \"recall\": 0.299785852432251, \"specificity\": 1.0, \"npv\": 0.9592331051826477, \"accuracy\": 0.9599324464797974, \"f1\": 0.4612850082372323, \"f2\": 0.34860557768924305, \"f0_5\": 0.6815968841285297, \"p4\": 0.6271348304683491, \"phi\": 0.5362504546188103}, {\"truth_threshold\": 36.87960740039029, \"match_probability\": 0.9999999999920908, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1957.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4581.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29932701587677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.70067298412323, \"precision\": 1.0, \"recall\": 0.29932701587677, \"specificity\": 1.0, \"npv\": 0.9592074751853943, \"accuracy\": 0.9599061608314514, \"f1\": 0.4607416127133608, \"f2\": 0.34810914653669645, \"f0_5\": 0.6811220938326604, \"p4\": 0.6266297156441757, \"phi\": 0.5358327164704204}, {\"truth_threshold\": 36.90493383764902, \"match_probability\": 0.9999999999922284, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1956.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4582.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29917407035827637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7008259296417236, \"precision\": 1.0, \"recall\": 0.29917407035827637, \"specificity\": 1.0, \"npv\": 0.9591989517211914, \"accuracy\": 0.9598973989486694, \"f1\": 0.4605603955733459, \"f2\": 0.34794364593709975, \"f0_5\": 0.6809636540871745, \"p4\": 0.6264611828101468, \"phi\": 0.5356934301134185}, {\"truth_threshold\": 36.94433848319274, \"match_probability\": 0.9999999999924378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1954.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4584.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2988681495189667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7011318206787109, \"precision\": 1.0, \"recall\": 0.2988681495189667, \"specificity\": 1.0, \"npv\": 0.9591818451881409, \"accuracy\": 0.9598799347877502, \"f1\": 0.46019783325482805, \"f2\": 0.347612609407244, \"f0_5\": 0.6806465096837119, \"p4\": 0.6261238749470711, \"phi\": 0.5354147154413589}, {\"truth_threshold\": 36.95909395061714, \"match_probability\": 0.9999999999925148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1953.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4585.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.298715204000473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7012848258018494, \"precision\": 1.0, \"recall\": 0.298715204000473, \"specificity\": 1.0, \"npv\": 0.959173321723938, \"accuracy\": 0.9598711729049683, \"f1\": 0.4600164880461665, \"f2\": 0.34744707347447074, \"f0_5\": 0.6804878048780488, \"p4\": 0.6259550997991331, \"phi\": 0.5352752870529771}, {\"truth_threshold\": 36.96382752670259, \"match_probability\": 0.9999999999925393, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1952.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4586.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29856225848197937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.701437771320343, \"precision\": 1.0, \"recall\": 0.29856225848197937, \"specificity\": 1.0, \"npv\": 0.9591647982597351, \"accuracy\": 0.9598624110221863, \"f1\": 0.4598351001177856, \"f2\": 0.34728152576145743, \"f0_5\": 0.6803290115711697, \"p4\": 0.6257862437609036, \"phi\": 0.5351358655412469}, {\"truth_threshold\": 37.00964620482938, \"match_probability\": 0.9999999999927726, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1950.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4588.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2982563376426697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7017436623573303, \"precision\": 1.0, \"recall\": 0.2982563376426697, \"specificity\": 1.0, \"npv\": 0.9591476917266846, \"accuracy\": 0.9598448872566223, \"f1\": 0.4594721960414703, \"f2\": 0.34695039498968044, \"f0_5\": 0.6800111591574836, \"p4\": 0.6254482887751458, \"phi\": 0.5348568802010464}, {\"truth_threshold\": 37.01338012762238, \"match_probability\": 0.9999999999927912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1947.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4591.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2977975010871887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7022024989128113, \"precision\": 1.0, \"recall\": 0.2977975010871887, \"specificity\": 1.0, \"npv\": 0.9591220617294312, \"accuracy\": 0.9598186612129211, \"f1\": 0.4589275191514437, \"f2\": 0.34645361044877043, \"f0_5\": 0.6795337149239146, \"p4\": 0.624940748127631, \"phi\": 0.5344381681612748}, {\"truth_threshold\": 37.02116236363155, \"match_probability\": 0.99999999999283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1946.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4592.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2976445257663727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7023554444313049, \"precision\": 1.0, \"recall\": 0.2976445257663727, \"specificity\": 1.0, \"npv\": 0.9591135382652283, \"accuracy\": 0.9598098993301392, \"f1\": 0.45874587458745875, \"f2\": 0.34628799202790234, \"f0_5\": 0.6793743890518084, \"p4\": 0.6247714054941795, \"phi\": 0.5342985023495062}, {\"truth_threshold\": 37.02475309721959, \"match_probability\": 0.9999999999928478, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1944.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4594.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2973386347293854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7026613354682922, \"precision\": 1.0, \"recall\": 0.2973386347293854, \"specificity\": 1.0, \"npv\": 0.9590964317321777, \"accuracy\": 0.9597923755645752, \"f1\": 0.4583824569676963, \"f2\": 0.34595671981776766, \"f0_5\": 0.6790554701690652, \"p4\": 0.6244324762412821, \"phi\": 0.534019109411359}, {\"truth_threshold\": 37.04802877351797, \"match_probability\": 0.9999999999929623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1943.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4595.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2971856892108917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7028143405914307, \"precision\": 1.0, \"recall\": 0.2971856892108917, \"specificity\": 1.0, \"npv\": 0.9590879082679749, \"accuracy\": 0.959783673286438, \"f1\": 0.4582006838816177, \"f2\": 0.34579106602598325, \"f0_5\": 0.6788958770090846, \"p4\": 0.6242628895017716, \"phi\": 0.5338793822520326}, {\"truth_threshold\": 37.04874853538214, \"match_probability\": 0.9999999999929657, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1941.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4597.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29687976837158203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.703120231628418, \"precision\": 1.0, \"recall\": 0.29687976837158203, \"specificity\": 1.0, \"npv\": 0.9590708613395691, \"accuracy\": 0.959766149520874, \"f1\": 0.45783700908125957, \"f2\": 0.34545972306268463, \"f0_5\": 0.6785764228779192, \"p4\": 0.6239234714960222, \"phi\": 0.5335997848031444}, {\"truth_threshold\": 37.078903406102576, \"match_probability\": 0.9999999999931113, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1939.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4599.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2965738773345947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7034261226654053, \"precision\": 1.0, \"recall\": 0.2965738773345947, \"specificity\": 1.0, \"npv\": 0.9590537548065186, \"accuracy\": 0.9597486257553101, \"f1\": 0.45747316267547483, \"f2\": 0.3451283329180164, \"f0_5\": 0.678256611165524, \"p4\": 0.6235837270531381, \"phi\": 0.5333200507381822}, {\"truth_threshold\": 37.108626547650566, \"match_probability\": 0.9999999999932517, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1937.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4601.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2962679862976074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7037320137023926, \"precision\": 1.0, \"recall\": 0.2962679862976074, \"specificity\": 1.0, \"npv\": 0.9590367078781128, \"accuracy\": 0.9597311615943909, \"f1\": 0.45710914454277285, \"f2\": 0.3447968955819004, \"f0_5\": 0.6779364412711746, \"p4\": 0.6232436556904921, \"phi\": 0.5330401798415294}, {\"truth_threshold\": 37.11491763046028, \"match_probability\": 0.9999999999932812, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1936.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4602.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2961150109767914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7038849592208862, \"precision\": 1.0, \"recall\": 0.2961150109767914, \"specificity\": 1.0, \"npv\": 0.9590281248092651, \"accuracy\": 0.9597223997116089, \"f1\": 0.4569270710408308, \"f2\": 0.3446311592138992, \"f0_5\": 0.6777762218176726, \"p4\": 0.6230734972631772, \"phi\": 0.5329002134564842}, {\"truth_threshold\": 37.13660212031175, \"match_probability\": 0.9999999999933814, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1935.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4603.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29596206545829773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7040379047393799, \"precision\": 1.0, \"recall\": 0.29596206545829773, \"specificity\": 1.0, \"npv\": 0.9590196013450623, \"accuracy\": 0.9597136378288269, \"f1\": 0.45674495456154846, \"f2\": 0.3444654110442554, \"f0_5\": 0.6776159125928001, \"p4\": 0.6229032569245052, \"phi\": 0.5327602127927882}, {\"truth_threshold\": 37.144841779457444, \"match_probability\": 0.999999999993419, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1934.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4604.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2958091199398041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7041909098625183, \"precision\": 1.0, \"recall\": 0.2958091199398041, \"specificity\": 1.0, \"npv\": 0.9590110778808594, \"accuracy\": 0.9597048759460449, \"f1\": 0.45656279508970726, \"f2\": 0.34429965107170835, \"f0_5\": 0.6774555135210872, \"p4\": 0.6227329346138798, \"phi\": 0.5326201369171771}, {\"truth_threshold\": 37.14640115653425, \"match_probability\": 0.9999999999934261, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1933.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4605.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2956561744213104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.704343855381012, \"precision\": 1.0, \"recall\": 0.2956561744213104, \"specificity\": 1.0, \"npv\": 0.9590025544166565, \"accuracy\": 0.9596961140632629, \"f1\": 0.45638059261008146, \"f2\": 0.34413387929499734, \"f0_5\": 0.6772950245269796, \"p4\": 0.6225625302706448, \"phi\": 0.532480067604455}, {\"truth_threshold\": 37.15626063839057, \"match_probability\": 0.9999999999934709, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1931.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4607.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29535025358200073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7046497464179993, \"precision\": 1.0, \"recall\": 0.29535025358200073, \"specificity\": 1.0, \"npv\": 0.958985447883606, \"accuracy\": 0.959678590297699, \"f1\": 0.45601605856653676, \"f2\": 0.34380230032403947, \"f0_5\": 0.6769737764689384, \"p4\": 0.6222214752434219, \"phi\": 0.5321997849342551}, {\"truth_threshold\": 37.15647260464499, \"match_probability\": 0.9999999999934719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1929.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4609.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2950443625450134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7049556374549866, \"precision\": 1.0, \"recall\": 0.2950443625450134, \"specificity\": 1.0, \"npv\": 0.9589684009552002, \"accuracy\": 0.9596611261367798, \"f1\": 0.4556513523089642, \"f2\": 0.34347067412129195, \"f0_5\": 0.6766521678125439, \"p4\": 0.6218800913563888, \"phi\": 0.5319193645643259}, {\"truth_threshold\": 37.16796824348282, \"match_probability\": 0.9999999999935237, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1928.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4610.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2948914170265198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7051085829734802, \"precision\": 1.0, \"recall\": 0.2948914170265198, \"specificity\": 1.0, \"npv\": 0.9589598178863525, \"accuracy\": 0.9596523642539978, \"f1\": 0.4554689345617765, \"f2\": 0.3433048433048433, \"f0_5\": 0.6764912280701755, \"p4\": 0.6217092759381657, \"phi\": 0.5317791231580632}, {\"truth_threshold\": 37.17899274756297, \"match_probability\": 0.999999999993573, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1927.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4611.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29473844170570374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7052615284919739, \"precision\": 1.0, \"recall\": 0.29473844170570374, \"specificity\": 1.0, \"npv\": 0.9589512944221497, \"accuracy\": 0.9596436023712158, \"f1\": 0.4552864737152983, \"f2\": 0.34313900067666225, \"f0_5\": 0.6763301979503018, \"p4\": 0.6215383781221367, \"phi\": 0.531638806276239}, {\"truth_threshold\": 37.187520750053665, \"match_probability\": 0.9999999999936109, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1923.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4615.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29412662982940674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7058733701705933, \"precision\": 1.0, \"recall\": 0.29412662982940674, \"specificity\": 1.0, \"npv\": 0.9589171409606934, \"accuracy\": 0.9596086144447327, \"f1\": 0.45455619903084743, \"f2\": 0.34247551202137133, \"f0_5\": 0.6756851721714687, \"p4\": 0.620853961657522, \"phi\": 0.5310772750690312}, {\"truth_threshold\": 37.1991515752412, \"match_probability\": 0.9999999999936622, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1922.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4616.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2939736843109131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7060263156890869, \"precision\": 1.0, \"recall\": 0.2939736843109131, \"specificity\": 1.0, \"npv\": 0.9589086174964905, \"accuracy\": 0.9595998525619507, \"f1\": 0.45437352245862883, \"f2\": 0.3423096103155945, \"f0_5\": 0.6755236890201041, \"p4\": 0.6206826509351051, \"phi\": 0.5309368262412433}, {\"truth_threshold\": 37.217185498071466, \"match_probability\": 0.9999999999937409, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1919.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4619.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29351484775543213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7064851522445679, \"precision\": 1.0, \"recall\": 0.29351484775543213, \"specificity\": 1.0, \"npv\": 0.9588829874992371, \"accuracy\": 0.9595735669136047, \"f1\": 0.4538252335343502, \"f2\": 0.3418118342773681, \"f0_5\": 0.6750386942451104, \"p4\": 0.6201682219309979, \"phi\": 0.5305152306167796}, {\"truth_threshold\": 37.22686193253639, \"match_probability\": 0.9999999999937828, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1916.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4622.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2930559813976288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7069440484046936, \"precision\": 1.0, \"recall\": 0.2930559813976288, \"specificity\": 1.0, \"npv\": 0.9588574171066284, \"accuracy\": 0.9595473408699036, \"f1\": 0.45327655547669743, \"f2\": 0.34131395183126695, \"f0_5\": 0.6745528798760738, \"p4\": 0.6196530463794502, \"phi\": 0.5300932811367687}, {\"truth_threshold\": 37.26510028828097, \"match_probability\": 0.9999999999939454, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1914.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4624.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2927500903606415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7072499394416809, \"precision\": 1.0, \"recall\": 0.2927500903606415, \"specificity\": 1.0, \"npv\": 0.9588403105735779, \"accuracy\": 0.9595298171043396, \"f1\": 0.45291055371509703, \"f2\": 0.3409819710681964, \"f0_5\": 0.6742285472734958, \"p4\": 0.6193091804409285, \"phi\": 0.5298118210275387}, {\"truth_threshold\": 37.270248245361664, \"match_probability\": 0.9999999999939669, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1911.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4627.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29229122400283813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7077087759971619, \"precision\": 1.0, \"recall\": 0.29229122400283813, \"specificity\": 1.0, \"npv\": 0.9588147401809692, \"accuracy\": 0.9595035910606384, \"f1\": 0.4523612261806131, \"f2\": 0.3404839111998004, \"f0_5\": 0.6737413622902271, \"p4\": 0.6187927569401795, \"phi\": 0.5293893896651976}, {\"truth_threshold\": 37.27143150976336, \"match_probability\": 0.9999999999939719, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1910.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4628.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2921382784843445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7078617215156555, \"precision\": 1.0, \"recall\": 0.2921382784843445, \"specificity\": 1.0, \"npv\": 0.9588062167167664, \"accuracy\": 0.9594948291778564, \"f1\": 0.4521780303030303, \"f2\": 0.34031786757893234, \"f0_5\": 0.6735787840315982, \"p4\": 0.6186204489672404, \"phi\": 0.5292485230198477}, {\"truth_threshold\": 37.276653148565934, \"match_probability\": 0.9999999999939937, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1909.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4629.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29198530316352844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7080146670341492, \"precision\": 1.0, \"recall\": 0.29198530316352844, \"specificity\": 1.0, \"npv\": 0.9587976932525635, \"accuracy\": 0.9594860672950745, \"f1\": 0.45199479105007695, \"f2\": 0.3401518121235879, \"f0_5\": 0.6734161140115705, \"p4\": 0.6184480574878196, \"phi\": 0.5291075802110745}, {\"truth_threshold\": 37.28530821899092, \"match_probability\": 0.9999999999940296, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1908.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4630.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2918323576450348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7081676125526428, \"precision\": 1.0, \"recall\": 0.2918323576450348, \"specificity\": 1.0, \"npv\": 0.9587891101837158, \"accuracy\": 0.9594773054122925, \"f1\": 0.4518115084063462, \"f2\": 0.33998574483250177, \"f0_5\": 0.6732533521524348, \"p4\": 0.6182755824397425, \"phi\": 0.5289666435373728}, {\"truth_threshold\": 37.3041812184826, \"match_probability\": 0.9999999999941072, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1901.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4637.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29076170921325684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7092382907867432, \"precision\": 1.0, \"recall\": 0.29076170921325684, \"specificity\": 1.0, \"npv\": 0.9587293863296509, \"accuracy\": 0.9594160318374634, \"f1\": 0.4505273136627562, \"f2\": 0.33882294228781235, \"f0_5\": 0.6721114410974403, \"p4\": 0.6170659119451765, \"phi\": 0.5279789800569822}, {\"truth_threshold\": 37.3263976060873, \"match_probability\": 0.9999999999941972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1899.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4639.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.29045578837394714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7095441818237305, \"precision\": 1.0, \"recall\": 0.29045578837394714, \"specificity\": 1.0, \"npv\": 0.9587123394012451, \"accuracy\": 0.9593985676765442, \"f1\": 0.4501600094820434, \"f2\": 0.33849060639549394, \"f0_5\": 0.671784349794821, \"p4\": 0.6167195361280885, \"phi\": 0.5276964677001533}, {\"truth_threshold\": 37.32737664025172, \"match_probability\": 0.9999999999942012, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1898.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4640.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2903028428554535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7096971273422241, \"precision\": 1.0, \"recall\": 0.2903028428554535, \"specificity\": 1.0, \"npv\": 0.9587038159370422, \"accuracy\": 0.9593898057937622, \"f1\": 0.44997629208155526, \"f2\": 0.33832442067736185, \"f0_5\": 0.6716206652512385, \"p4\": 0.6165462219602276, \"phi\": 0.5275551379191535}, {\"truth_threshold\": 37.34891774900528, \"match_probability\": 0.9999999999942871, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1895.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4643.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28984397649765015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7101560235023499, \"precision\": 1.0, \"recall\": 0.28984397649765015, \"specificity\": 1.0, \"npv\": 0.9586781859397888, \"accuracy\": 0.9593635201454163, \"f1\": 0.44942487845369383, \"f2\": 0.33782579241986666, \"f0_5\": 0.6711290551069556, \"p4\": 0.616025773664895, \"phi\": 0.5271310189669334}, {\"truth_threshold\": 37.34909268369151, \"match_probability\": 0.9999999999942878, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1894.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4644.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2896910309791565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7103089690208435, \"precision\": 1.0, \"recall\": 0.2896910309791565, \"specificity\": 1.0, \"npv\": 0.9586696624755859, \"accuracy\": 0.9593547582626343, \"f1\": 0.44924098671726753, \"f2\": 0.3376595592954432, \"f0_5\": 0.6709649992914837, \"p4\": 0.6158521220925909, \"phi\": 0.526989588944219}, {\"truth_threshold\": 37.36503422756053, \"match_probability\": 0.9999999999943506, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1893.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4645.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28953808546066284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7104619145393372, \"precision\": 1.0, \"recall\": 0.28953808546066284, \"specificity\": 1.0, \"npv\": 0.9586611390113831, \"accuracy\": 0.9593460559844971, \"f1\": 0.44905705135808327, \"f2\": 0.33749331431627744, \"f0_5\": 0.6708008504606662, \"p4\": 0.6156783860115617, \"phi\": 0.52684808213438}, {\"truth_threshold\": 37.375267320747895, \"match_probability\": 0.9999999999943905, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1890.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4648.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2890792191028595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7109207510948181, \"precision\": 1.0, \"recall\": 0.2890792191028595, \"specificity\": 1.0, \"npv\": 0.9586355686187744, \"accuracy\": 0.9593197703361511, \"f1\": 0.4485049833887043, \"f2\": 0.33699450823764354, \"f0_5\": 0.6703078450844091, \"p4\": 0.6151566700840945, \"phi\": 0.5264234313450452}, {\"truth_threshold\": 37.37886502598143, \"match_probability\": 0.9999999999944045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1889.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4649.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28892627358436584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7110736966133118, \"precision\": 1.0, \"recall\": 0.28892627358436584, \"specificity\": 1.0, \"npv\": 0.9586269855499268, \"accuracy\": 0.9593110084533691, \"f1\": 0.4483208733831731, \"f2\": 0.336828215826825, \"f0_5\": 0.6701433234000284, \"p4\": 0.6149825953358208, \"phi\": 0.526281782392445}, {\"truth_threshold\": 37.425925125842504, \"match_probability\": 0.9999999999945841, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1888.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4650.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2887733280658722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7112267017364502, \"precision\": 1.0, \"recall\": 0.2887733280658722, \"specificity\": 1.0, \"npv\": 0.9586184620857239, \"accuracy\": 0.9593022465705872, \"f1\": 0.44813671967718965, \"f2\": 0.33666191155492153, \"f0_5\": 0.6699787083037615, \"p4\": 0.6148084357623346, \"phi\": 0.5261401392198858}, {\"truth_threshold\": 37.42716852600142, \"match_probability\": 0.9999999999945888, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1886.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4652.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2884674072265625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7115325927734375, \"precision\": 1.0, \"recall\": 0.2884674072265625, \"specificity\": 1.0, \"npv\": 0.9586014151573181, \"accuracy\": 0.959284782409668, \"f1\": 0.44776828110161443, \"f2\": 0.33632926742278335, \"f0_5\": 0.6696491975571651, \"p4\": 0.6144598618857133, \"phi\": 0.5258567045705344}, {\"truth_threshold\": 37.484497365823, \"match_probability\": 0.9999999999947995, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1885.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4653.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28831446170806885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7116855382919312, \"precision\": 1.0, \"recall\": 0.28831446170806885, \"specificity\": 1.0, \"npv\": 0.9585928916931152, \"accuracy\": 0.959276020526886, \"f1\": 0.4475839962008785, \"f2\": 0.33616292756001, \"f0_5\": 0.6694843017474073, \"p4\": 0.6142854474554142, \"phi\": 0.525714954439781}, {\"truth_threshold\": 37.49126882887601, \"match_probability\": 0.9999999999948239, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1884.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4654.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2881615161895752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7118384838104248, \"precision\": 1.0, \"recall\": 0.2881615161895752, \"specificity\": 1.0, \"npv\": 0.9585843682289124, \"accuracy\": 0.959267258644104, \"f1\": 0.44739966753740207, \"f2\": 0.33599657583107434, \"f0_5\": 0.6693193122069063, \"p4\": 0.6141109479455744, \"phi\": 0.5255731271658676}, {\"truth_threshold\": 37.526939178962266, \"match_probability\": 0.9999999999949503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1882.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4656.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2878556251525879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7121443748474121, \"precision\": 1.0, \"recall\": 0.2878556251525879, \"specificity\": 1.0, \"npv\": 0.9585673213005066, \"accuracy\": 0.95924973487854, \"f1\": 0.4470308788598575, \"f2\": 0.33566383676963685, \"f0_5\": 0.6689890516138206, \"p4\": 0.6137616934322448, \"phi\": 0.5252894067741467}, {\"truth_threshold\": 37.54252307418072, \"match_probability\": 0.9999999999950046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1881.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4657.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28770264983177185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7122973203659058, \"precision\": 1.0, \"recall\": 0.28770264983177185, \"specificity\": 1.0, \"npv\": 0.9585587382316589, \"accuracy\": 0.9592410326004028, \"f1\": 0.44684641881458603, \"f2\": 0.3354974494345949, \"f0_5\": 0.6688237804010809, \"p4\": 0.6135869383010825, \"phi\": 0.5251475136198925}, {\"truth_threshold\": 37.54978604169438, \"match_probability\": 0.9999999999950296, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1880.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4658.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2875497043132782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7124502658843994, \"precision\": 1.0, \"recall\": 0.2875497043132782, \"specificity\": 1.0, \"npv\": 0.958550214767456, \"accuracy\": 0.9592322707176208, \"f1\": 0.44666191494416724, \"f2\": 0.3353310502283105, \"f0_5\": 0.6686584151372884, \"p4\": 0.6134120978350334, \"phi\": 0.5250055431630154}, {\"truth_threshold\": 37.55727573573864, \"match_probability\": 0.9999999999950554, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1879.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4659.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28739675879478455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7126032710075378, \"precision\": 1.0, \"recall\": 0.28739675879478455, \"specificity\": 1.0, \"npv\": 0.9585416913032532, \"accuracy\": 0.9592235088348389, \"f1\": 0.44647736723298087, \"f2\": 0.33516463914951306, \"f0_5\": 0.6684929557421375, \"p4\": 0.6132371719701016, \"phi\": 0.524863578322576}, {\"truth_threshold\": 37.55901946351571, \"match_probability\": 0.9999999999950614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1877.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4661.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28709086775779724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7129091620445251, \"precision\": 1.0, \"recall\": 0.28709086775779724, \"specificity\": 1.0, \"npv\": 0.9585246443748474, \"accuracy\": 0.9592059850692749, \"f1\": 0.44610814022578726, \"f2\": 0.3348317813692961, \"f0_5\": 0.6681617542360815, \"p4\": 0.6128870637872861, \"phi\": 0.5245794994561691}, {\"truth_threshold\": 37.55910099675069, \"match_probability\": 0.9999999999950616, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1876.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4662.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2869378924369812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7130621075630188, \"precision\": 1.0, \"recall\": 0.2869378924369812, \"specificity\": 1.0, \"npv\": 0.9585161209106445, \"accuracy\": 0.9591972231864929, \"f1\": 0.4459234608985025, \"f2\": 0.33466533466533466, \"f0_5\": 0.6679960119641076, \"p4\": 0.6127118813410899, \"phi\": 0.5244374268729736}, {\"truth_threshold\": 37.56860350556515, \"match_probability\": 0.999999999995094, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1874.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4664.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2866320013999939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7133679986000061, \"precision\": 1.0, \"recall\": 0.2866320013999939, \"specificity\": 1.0, \"npv\": 0.9584990739822388, \"accuracy\": 0.9591797590255737, \"f1\": 0.4455539705183072, \"f2\": 0.33433240562334976, \"f0_5\": 0.6676642439789083, \"p4\": 0.6123612594178585, \"phi\": 0.5241531322250443}, {\"truth_threshold\": 37.6054324369513, \"match_probability\": 0.9999999999952177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1873.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4665.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28647905588150024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7135209441184998, \"precision\": 1.0, \"recall\": 0.28647905588150024, \"specificity\": 1.0, \"npv\": 0.9584905505180359, \"accuracy\": 0.9591709971427917, \"f1\": 0.4453691594340744, \"f2\": 0.3341659232827832, \"f0_5\": 0.6674982181040627, \"p4\": 0.6121858198121253, \"phi\": 0.5240109100798164}, {\"truth_threshold\": 37.615586536370444, \"match_probability\": 0.9999999999952512, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1872.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4666.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2863260805606842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7136738896369934, \"precision\": 1.0, \"recall\": 0.2863260805606842, \"specificity\": 1.0, \"npv\": 0.958482027053833, \"accuracy\": 0.9591622352600098, \"f1\": 0.4451843043995244, \"f2\": 0.33399942906080504, \"f0_5\": 0.6673320975331527, \"p4\": 0.6120102943577411, \"phi\": 0.5238686934220924}, {\"truth_threshold\": 37.621142484083805, \"match_probability\": 0.9999999999952695, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1871.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4667.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28617313504219055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7138268351554871, \"precision\": 1.0, \"recall\": 0.28617313504219055, \"specificity\": 1.0, \"npv\": 0.9584735035896301, \"accuracy\": 0.9591534733772278, \"f1\": 0.4449994053989773, \"f2\": 0.33383292295614314, \"f0_5\": 0.6671658821851376, \"p4\": 0.6118346829901958, \"phi\": 0.5237264406776699}, {\"truth_threshold\": 37.62799487404508, \"match_probability\": 0.9999999999952919, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1870.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4668.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2860201895236969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7139797806739807, \"precision\": 1.0, \"recall\": 0.2860201895236969, \"specificity\": 1.0, \"npv\": 0.9584649205207825, \"accuracy\": 0.9591447114944458, \"f1\": 0.44481446241674594, \"f2\": 0.33366640496752553, \"f0_5\": 0.6669995719788843, \"p4\": 0.6116589856449145, \"phi\": 0.5235841102286385}, {\"truth_threshold\": 37.64141135023543, \"match_probability\": 0.9999999999953355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1868.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4670.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2857142984867096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7142857313156128, \"precision\": 1.0, \"recall\": 0.2857142984867096, \"specificity\": 1.0, \"npv\": 0.9584478735923767, \"accuracy\": 0.9591272473335266, \"f1\": 0.4444444444444444, \"f2\": 0.3333333333333333, \"f0_5\": 0.6666666666666666, \"p4\": 0.611307332762521, \"phi\": 0.5232993824085721}, {\"truth_threshold\": 37.725843247376346, \"match_probability\": 0.9999999999956006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1867.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4671.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28556132316589355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7144386768341064, \"precision\": 1.0, \"recall\": 0.28556132316589355, \"specificity\": 1.0, \"npv\": 0.9584393501281738, \"accuracy\": 0.9591184854507446, \"f1\": 0.4442593694229625, \"f2\": 0.33316677968521363, \"f0_5\": 0.6665000713979723, \"p4\": 0.6111313770959355, \"phi\": 0.5231569850002387}, {\"truth_threshold\": 37.734715453896264, \"match_probability\": 0.9999999999956276, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1866.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4672.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2854083776473999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7145916223526001, \"precision\": 1.0, \"recall\": 0.2854083776473999, \"specificity\": 1.0, \"npv\": 0.958430826663971, \"accuracy\": 0.9591097235679626, \"f1\": 0.44407425035697284, \"f2\": 0.3330002141480477, \"f0_5\": 0.6663333809455793, \"p4\": 0.6109553351926666, \"phi\": 0.5230145097251487}, {\"truth_threshold\": 37.76395524828413, \"match_probability\": 0.9999999999957153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1865.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4673.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28525543212890625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7147445678710938, \"precision\": 1.0, \"recall\": 0.28525543212890625, \"specificity\": 1.0, \"npv\": 0.9584223031997681, \"accuracy\": 0.9591009616851807, \"f1\": 0.44388908723075093, \"f2\": 0.33283363672056254, \"f0_5\": 0.6661665952278897, \"p4\": 0.6107792069878155, \"phi\": 0.5228720398071289}, {\"truth_threshold\": 37.76671395431831, \"match_probability\": 0.9999999999957235, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1864.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4674.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2851024866104126, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7148975133895874, \"precision\": 1.0, \"recall\": 0.2851024866104126, \"specificity\": 1.0, \"npv\": 0.9584137797355652, \"accuracy\": 0.9590921998023987, \"f1\": 0.44370388002856465, \"f2\": 0.33266704740148484, \"f0_5\": 0.6659997141632128, \"p4\": 0.6106029924164177, \"phi\": 0.5227295335951858}, {\"truth_threshold\": 37.7667757881236, \"match_probability\": 0.9999999999957238, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1862.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4676.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2847965657711029, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7152034044265747, \"precision\": 1.0, \"recall\": 0.2847965657711029, \"specificity\": 1.0, \"npv\": 0.9583967328071594, \"accuracy\": 0.9590747356414795, \"f1\": 0.44333333333333336, \"f2\": 0.33233383308345826, \"f0_5\": 0.6656656656656657, \"p4\": 0.6102503039137989, \"phi\": 0.5224443704942607}, {\"truth_threshold\": 37.76977258567933, \"match_probability\": 0.9999999999957325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1861.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4677.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28464362025260925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7153563499450684, \"precision\": 1.0, \"recall\": 0.28464362025260925, \"specificity\": 1.0, \"npv\": 0.9583882093429565, \"accuracy\": 0.9590659737586975, \"f1\": 0.4431479938087868, \"f2\": 0.33216720808196193, \"f0_5\": 0.6654984980689458, \"p4\": 0.610073829852323, \"phi\": 0.5223017135236198}, {\"truth_threshold\": 37.77314557752886, \"match_probability\": 0.9999999999957425, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1860.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4678.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2844906747341156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7155093550682068, \"precision\": 1.0, \"recall\": 0.2844906747341156, \"specificity\": 1.0, \"npv\": 0.9583796858787537, \"accuracy\": 0.9590572118759155, \"f1\": 0.44296261014527266, \"f2\": 0.3320005711837784, \"f0_5\": 0.665331234797539, \"p4\": 0.6098972691637903, \"phi\": 0.522159061815953}, {\"truth_threshold\": 37.77437385740558, \"match_probability\": 0.9999999999957462, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1859.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4679.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28433772921562195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7156623005867004, \"precision\": 1.0, \"recall\": 0.28433772921562195, \"specificity\": 1.0, \"npv\": 0.9583711624145508, \"accuracy\": 0.9590484499931335, \"f1\": 0.44277718232702157, \"f2\": 0.33183392238763343, \"f0_5\": 0.6651638757692858, \"p4\": 0.6097206217829098, \"phi\": 0.5220163319558981}, {\"truth_threshold\": 37.798157452192235, \"match_probability\": 0.9999999999958157, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1857.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4681.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28403180837631226, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7159681916236877, \"precision\": 1.0, \"recall\": 0.28403180837631226, \"specificity\": 1.0, \"npv\": 0.958354115486145, \"accuracy\": 0.9590309858322144, \"f1\": 0.4424061941631924, \"f2\": 0.3315005890963619, \"f0_5\": 0.6648288701131319, \"p4\": 0.6093670666826128, \"phi\": 0.5217308044515775}, {\"truth_threshold\": 37.79939112423834, \"match_probability\": 0.9999999999958193, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1856.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4682.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2838788628578186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7161211371421814, \"precision\": 1.0, \"recall\": 0.2838788628578186, \"specificity\": 1.0, \"npv\": 0.9583455920219421, \"accuracy\": 0.9590222239494324, \"f1\": 0.44222063378603765, \"f2\": 0.3313339045986861, \"f0_5\": 0.6646612233204412, \"p4\": 0.6091901588322854, \"phi\": 0.5215880067693263}, {\"truth_threshold\": 37.805680149255146, \"match_probability\": 0.9999999999958374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1855.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4683.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28372591733932495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.716274082660675, \"precision\": 1.0, \"recall\": 0.28372591733932495, \"specificity\": 1.0, \"npv\": 0.9583370685577393, \"accuracy\": 0.9590134620666504, \"f1\": 0.44203502919099247, \"f2\": 0.33116720819795054, \"f0_5\": 0.664493480441324, \"p4\": 0.6090131640277888, \"phi\": 0.5214451725238358}, {\"truth_threshold\": 37.84868642049511, \"match_probability\": 0.9999999999959598, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1853.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4685.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28341999650001526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7165799736976624, \"precision\": 1.0, \"recall\": 0.28341999650001526, \"specificity\": 1.0, \"npv\": 0.9583199620246887, \"accuracy\": 0.9589959383010864, \"f1\": 0.44166368728399474, \"f2\": 0.3308337796821996, \"f0_5\": 0.6641577060931899, \"p4\": 0.6086589132937418, \"phi\": 0.5211593524469998}, {\"truth_threshold\": 37.8570877806546, \"match_probability\": 0.9999999999959832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1852.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4686.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2832670509815216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.716732919216156, \"precision\": 1.0, \"recall\": 0.2832670509815216, \"specificity\": 1.0, \"npv\": 0.9583114385604858, \"accuracy\": 0.9589871764183044, \"f1\": 0.44147794994040523, \"f2\": 0.3306670475646336, \"f0_5\": 0.6639896744586261, \"p4\": 0.6084816572327532, \"phi\": 0.5210163665331051}, {\"truth_threshold\": 37.863490921835044, \"match_probability\": 0.999999999996001, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1851.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4687.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28311410546302795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7168859243392944, \"precision\": 1.0, \"recall\": 0.28311410546302795, \"specificity\": 1.0, \"npv\": 0.958302915096283, \"accuracy\": 0.9589784145355225, \"f1\": 0.44129216831565143, \"f2\": 0.3305003035389065, \"f0_5\": 0.6638215464065413, \"p4\": 0.6083043139547186, \"phi\": 0.5208733857108269}, {\"truth_threshold\": 37.86891454871567, \"match_probability\": 0.999999999996016, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1850.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4688.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2829611599445343, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7170388698577881, \"precision\": 1.0, \"recall\": 0.2829611599445343, \"specificity\": 1.0, \"npv\": 0.9582943916320801, \"accuracy\": 0.9589697122573853, \"f1\": 0.44110634239389607, \"f2\": 0.3303335476037426, \"f0_5\": 0.6636533218539246, \"p4\": 0.6081268833937536, \"phi\": 0.5207303263653634}, {\"truth_threshold\": 37.87202427837684, \"match_probability\": 0.9999999999960245, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1849.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4689.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28280818462371826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7171918153762817, \"precision\": 1.0, \"recall\": 0.28280818462371826, \"specificity\": 1.0, \"npv\": 0.9582858681678772, \"accuracy\": 0.9589609503746033, \"f1\": 0.44092047215929414, \"f2\": 0.3301667797578658, \"f0_5\": 0.663485000717669, \"p4\": 0.6079493654839073, \"phi\": 0.5205872720730863}, {\"truth_threshold\": 37.87431817269454, \"match_probability\": 0.9999999999960308, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1848.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4690.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2826552391052246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7173447608947754, \"precision\": 1.0, \"recall\": 0.2826552391052246, \"specificity\": 1.0, \"npv\": 0.9582773447036743, \"accuracy\": 0.9589521884918213, \"f1\": 0.44073455759599334, \"f2\": 0.33, \"f0_5\": 0.6633165829145728, \"p4\": 0.6077717601591621, \"phi\": 0.5204441391746748}, {\"truth_threshold\": 37.88477028940719, \"match_probability\": 0.9999999999960595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1842.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4696.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2817375361919403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7182624936103821, \"precision\": 1.0, \"recall\": 0.2817375361919403, \"specificity\": 1.0, \"npv\": 0.958226203918457, \"accuracy\": 0.9588996767997742, \"f1\": 0.439618138424821, \"f2\": 0.3289990712295492, \"f0_5\": 0.6623040414209693, \"p4\": 0.6067042887924479, \"phi\": 0.5195847349275584}, {\"truth_threshold\": 37.90808860688561, \"match_probability\": 0.9999999999961227, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1841.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4697.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28158459067344666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7184154391288757, \"precision\": 1.0, \"recall\": 0.28158459067344666, \"specificity\": 1.0, \"npv\": 0.9582176804542542, \"accuracy\": 0.9588909149169922, \"f1\": 0.4394319131161236, \"f2\": 0.328832208052013, \"f0_5\": 0.662134944612286, \"p4\": 0.6065260697093248, \"phi\": 0.5194413436387908}, {\"truth_threshold\": 37.91572970665112, \"match_probability\": 0.9999999999961432, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1840.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4698.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.281431645154953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7185683846473694, \"precision\": 1.0, \"recall\": 0.281431645154953, \"specificity\": 1.0, \"npv\": 0.9582091569900513, \"accuracy\": 0.9588821530342102, \"f1\": 0.43924564335163524, \"f2\": 0.32866533295227207, \"f0_5\": 0.6619657504676932, \"p4\": 0.6063477626807614, \"phi\": 0.5192979572286821}, {\"truth_threshold\": 37.91595834172918, \"match_probability\": 0.9999999999961438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1838.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4700.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2811257243156433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7188742756843567, \"precision\": 1.0, \"recall\": 0.2811257243156433, \"specificity\": 1.0, \"npv\": 0.9581921100616455, \"accuracy\": 0.958864688873291, \"f1\": 0.438872970391595, \"f2\": 0.32833154698106465, \"f0_5\": 0.6616270698344132, \"p4\": 0.6059908845207708, \"phi\": 0.5190110312841771}, {\"truth_threshold\": 37.93563956038534, \"match_probability\": 0.999999999996196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1836.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4702.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.280819833278656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.719180166721344, \"precision\": 1.0, \"recall\": 0.280819833278656, \"specificity\": 1.0, \"npv\": 0.9581750631332397, \"accuracy\": 0.958847165107727, \"f1\": 0.43850011941724387, \"f2\": 0.32799771330570243, \"f0_5\": 0.6612879988474283, \"p4\": 0.6056336537787145, \"phi\": 0.5187239568474972}, {\"truth_threshold\": 37.94307057897117, \"match_probability\": 0.9999999999962156, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1835.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4703.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28066685795783997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7193331122398376, \"precision\": 1.0, \"recall\": 0.28066685795783997, \"specificity\": 1.0, \"npv\": 0.9581665396690369, \"accuracy\": 0.9588384032249451, \"f1\": 0.4383136271348382, \"f2\": 0.3278307785757673, \"f0_5\": 0.66111831676034, \"p4\": 0.6054549060223163, \"phi\": 0.5185803848556821}, {\"truth_threshold\": 37.96314430064753, \"match_probability\": 0.9999999999962679, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1834.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4704.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2805139124393463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7194860577583313, \"precision\": 1.0, \"recall\": 0.2805139124393463, \"specificity\": 1.0, \"npv\": 0.958158016204834, \"accuracy\": 0.9588296413421631, \"f1\": 0.43812709030100333, \"f2\": 0.327663831915958, \"f0_5\": 0.6609485368314834, \"p4\": 0.6052760699197521, \"phi\": 0.5184367336714225}, {\"truth_threshold\": 37.965623080239276, \"match_probability\": 0.9999999999962743, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1831.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4707.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.28005507588386536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.719944953918457, \"precision\": 1.0, \"recall\": 0.28005507588386536, \"specificity\": 1.0, \"npv\": 0.9581324458122253, \"accuracy\": 0.9588034152984619, \"f1\": 0.43756721233122237, \"f2\": 0.32716292034449485, \"f0_5\": 0.6604386091473092, \"p4\": 0.6047390308644827, \"phi\": 0.5180056404893475}, {\"truth_threshold\": 37.97675915390476, \"match_probability\": 0.999999999996303, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1830.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4708.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2799021005630493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7200978994369507, \"precision\": 1.0, \"recall\": 0.2799021005630493, \"specificity\": 1.0, \"npv\": 0.9581239223480225, \"accuracy\": 0.9587946534156799, \"f1\": 0.43738049713193117, \"f2\": 0.32699592595239796, \"f0_5\": 0.6602684370038967, \"p4\": 0.6045598407063344, \"phi\": 0.5178618821418394}, {\"truth_threshold\": 38.0088391110426, \"match_probability\": 0.9999999999963842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1827.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4711.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27944326400756836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7205567359924316, \"precision\": 1.0, \"recall\": 0.27944326400756836, \"specificity\": 1.0, \"npv\": 0.9580983519554138, \"accuracy\": 0.958768367767334, \"f1\": 0.43682008368200836, \"f2\": 0.326494871153365, \"f0_5\": 0.659757330637007, \"p4\": 0.6040217378705717, \"phi\": 0.517430298680775}, {\"truth_threshold\": 38.01538195690937, \"match_probability\": 0.9999999999964007, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1825.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4713.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27913734316825867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.720862627029419, \"precision\": 1.0, \"recall\": 0.27913734316825867, \"specificity\": 1.0, \"npv\": 0.9580813050270081, \"accuracy\": 0.9587509036064148, \"f1\": 0.43644625134521103, \"f2\": 0.3261607749222576, \"f0_5\": 0.6594161005925712, \"p4\": 0.603662558337805, \"phi\": 0.5171424031112271}, {\"truth_threshold\": 38.02698965411792, \"match_probability\": 0.9999999999964294, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1824.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4714.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.278984397649765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7210155725479126, \"precision\": 1.0, \"recall\": 0.278984397649765, \"specificity\": 1.0, \"npv\": 0.9580727815628052, \"accuracy\": 0.9587421417236328, \"f1\": 0.4362592681176752, \"f2\": 0.3259937088933371, \"f0_5\": 0.6592453375740928, \"p4\": 0.6034828350760374, \"phi\": 0.5169984201009337}, {\"truth_threshold\": 38.02925866613693, \"match_probability\": 0.9999999999964351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1823.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4715.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27883145213127136, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.721168577671051, \"precision\": 1.0, \"recall\": 0.27883145213127136, \"specificity\": 1.0, \"npv\": 0.9580642580986023, \"accuracy\": 0.9587333798408508, \"f1\": 0.43607224016266, \"f2\": 0.3258266309204647, \"f0_5\": 0.6590744757772957, \"p4\": 0.6033030227270951, \"phi\": 0.5168543995427637}, {\"truth_threshold\": 38.029384835364056, \"match_probability\": 0.9999999999964354, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1821.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4717.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27852553129196167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7214744687080383, \"precision\": 1.0, \"recall\": 0.27852553129196167, \"specificity\": 1.0, \"npv\": 0.9580472707748413, \"accuracy\": 0.9587158560752869, \"f1\": 0.43569805000598155, \"f2\": 0.32549243913773995, \"f0_5\": 0.6587324555057156, \"p4\": 0.6029431304965193, \"phi\": 0.5165662035218223}, {\"truth_threshold\": 38.03715205104059, \"match_probability\": 0.9999999999964545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1820.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4718.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.278372585773468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.721627414226532, \"precision\": 1.0, \"recall\": 0.278372585773468, \"specificity\": 1.0, \"npv\": 0.9580387473106384, \"accuracy\": 0.9587071537971497, \"f1\": 0.4355108877721943, \"f2\": 0.3253253253253253, \"f0_5\": 0.6585612968591692, \"p4\": 0.60276305047913, \"phi\": 0.5164220279732176}, {\"truth_threshold\": 38.05220335500862, \"match_probability\": 0.9999999999964914, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1817.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4721.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27791374921798706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7220862507820129, \"precision\": 1.0, \"recall\": 0.27791374921798706, \"specificity\": 1.0, \"npv\": 0.9580131769180298, \"accuracy\": 0.9586808681488037, \"f1\": 0.4349491322561341, \"f2\": 0.3248239121884944, \"f0_5\": 0.658047225843836, \"p4\": 0.6022222740025764, \"phi\": 0.5159893593812428}, {\"truth_threshold\": 38.06241811822811, \"match_probability\": 0.999999999996516, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1815.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4723.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27760782837867737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7223921418190002, \"precision\": 1.0, \"recall\": 0.27760782837867737, \"specificity\": 1.0, \"npv\": 0.957996129989624, \"accuracy\": 0.9586633443832397, \"f1\": 0.4345744044056028, \"f2\": 0.324489577001466, \"f0_5\": 0.6577040150746485, \"p4\": 0.6018613086498533, \"phi\": 0.5157007107548073}, {\"truth_threshold\": 38.082697925098394, \"match_probability\": 0.9999999999965647, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1814.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4724.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2774548828601837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7225451469421387, \"precision\": 1.0, \"recall\": 0.2774548828601837, \"specificity\": 1.0, \"npv\": 0.9579876065254211, \"accuracy\": 0.9586545825004578, \"f1\": 0.43438697318007663, \"f2\": 0.32432239147536296, \"f0_5\": 0.6575322604030738, \"p4\": 0.6016806914582122, \"phi\": 0.5155563507988331}, {\"truth_threshold\": 38.086434754142346, \"match_probability\": 0.9999999999965736, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1813.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4725.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27730193734169006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7226980924606323, \"precision\": 1.0, \"recall\": 0.27730193734169006, \"specificity\": 1.0, \"npv\": 0.9579790830612183, \"accuracy\": 0.9586458802223206, \"f1\": 0.43419949706621963, \"f2\": 0.3241551939924906, \"f0_5\": 0.6573604060913706, \"p4\": 0.601499984498546, \"phi\": 0.5154119107519094}, {\"truth_threshold\": 38.10121060122517, \"match_probability\": 0.9999999999966085, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1812.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4726.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.277148962020874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.722851037979126, \"precision\": 1.0, \"recall\": 0.277148962020874, \"specificity\": 1.0, \"npv\": 0.9579705595970154, \"accuracy\": 0.9586371183395386, \"f1\": 0.4340119760479042, \"f2\": 0.3239879845515663, \"f0_5\": 0.6571884520528072, \"p4\": 0.6013191877023887, \"phi\": 0.5152674750235233}, {\"truth_threshold\": 38.10800368718301, \"match_probability\": 0.9999999999966245, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1811.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4727.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27699601650238037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7230039834976196, \"precision\": 1.0, \"recall\": 0.27699601650238037, \"specificity\": 1.0, \"npv\": 0.9579620361328125, \"accuracy\": 0.9586283564567566, \"f1\": 0.4338244101089951, \"f2\": 0.3238207631513071, \"f0_5\": 0.6570163982005515, \"p4\": 0.6011383010012045, \"phi\": 0.515122959117396}, {\"truth_threshold\": 38.11503095407698, \"match_probability\": 0.9999999999966408, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1810.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4728.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2768430709838867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7231569290161133, \"precision\": 1.0, \"recall\": 0.2768430709838867, \"specificity\": 1.0, \"npv\": 0.9579535126686096, \"accuracy\": 0.9586195945739746, \"f1\": 0.4336367992333493, \"f2\": 0.3236535297904299, \"f0_5\": 0.6568442444476702, \"p4\": 0.6009573243263879, \"phi\": 0.5149784474887761}, {\"truth_threshold\": 38.115217459219046, \"match_probability\": 0.9999999999966412, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1807.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4731.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2763842046260834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7236157655715942, \"precision\": 1.0, \"recall\": 0.2763842046260834, \"specificity\": 1.0, \"npv\": 0.957927942276001, \"accuracy\": 0.9585933685302734, \"f1\": 0.4330736968244458, \"f2\": 0.3231517579312565, \"f0_5\": 0.6563271829144268, \"p4\": 0.6004138537730436, \"phi\": 0.5145446422247191}, {\"truth_threshold\": 38.13291946095251, \"match_probability\": 0.9999999999966822, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1806.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4732.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2762312591075897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7237687110900879, \"precision\": 1.0, \"recall\": 0.2762312591075897, \"specificity\": 1.0, \"npv\": 0.9579194784164429, \"accuracy\": 0.9585846066474915, \"f1\": 0.43288590604026844, \"f2\": 0.32298447671507263, \"f0_5\": 0.6561546286876907, \"p4\": 0.600232516516247, \"phi\": 0.5143999361154017}, {\"truth_threshold\": 38.133927986013425, \"match_probability\": 0.9999999999966845, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1805.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4733.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27607831358909607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7239217162132263, \"precision\": 1.0, \"recall\": 0.27607831358909607, \"specificity\": 1.0, \"npv\": 0.95791095495224, \"accuracy\": 0.9585758447647095, \"f1\": 0.4326980702385233, \"f2\": 0.3228171835318525, \"f0_5\": 0.6559819741241459, \"p4\": 0.6000510889417423, \"phi\": 0.5142552341804107}, {\"truth_threshold\": 38.15803198172179, \"match_probability\": 0.9999999999967395, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1802.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4736.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2756194472312927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7243805527687073, \"precision\": 1.0, \"recall\": 0.2756194472312927, \"specificity\": 1.0, \"npv\": 0.9578853845596313, \"accuracy\": 0.9585495591163635, \"f1\": 0.43213429256594726, \"f2\": 0.3223152321671317, \"f0_5\": 0.6554634075367379, \"p4\": 0.5995062636213738, \"phi\": 0.5138208146204533}, {\"truth_threshold\": 38.18007030998554, \"match_probability\": 0.9999999999967889, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1801.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4737.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2754665017127991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7245334982872009, \"precision\": 1.0, \"recall\": 0.2754665017127991, \"specificity\": 1.0, \"npv\": 0.9578768610954285, \"accuracy\": 0.9585408568382263, \"f1\": 0.4319462765319583, \"f2\": 0.32214789110292275, \"f0_5\": 0.655290350749527, \"p4\": 0.5993244740850784, \"phi\": 0.5136759598552325}, {\"truth_threshold\": 38.19122169687924, \"match_probability\": 0.9999999999968137, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1799.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4739.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27516061067581177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7248393893241882, \"precision\": 1.0, \"recall\": 0.27516061067581177, \"specificity\": 1.0, \"npv\": 0.9578598141670227, \"accuracy\": 0.9585233330726624, \"f1\": 0.43157010915197314, \"f2\": 0.32181317305284246, \"f0_5\": 0.6549439347604485, \"p4\": 0.5989606229524899, \"phi\": 0.5133860930562152}, {\"truth_threshold\": 38.20422840947886, \"match_probability\": 0.9999999999968422, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1798.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4740.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2750076353549957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7249923348426819, \"precision\": 1.0, \"recall\": 0.2750076353549957, \"specificity\": 1.0, \"npv\": 0.9578512907028198, \"accuracy\": 0.9585145711898804, \"f1\": 0.43138195777351246, \"f2\": 0.3216457960644007, \"f0_5\": 0.6547705753823744, \"p4\": 0.5987785612173698, \"phi\": 0.513241123333585}, {\"truth_threshold\": 38.214255279757296, \"match_probability\": 0.9999999999968641, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1797.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4741.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2748546898365021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7251452803611755, \"precision\": 1.0, \"recall\": 0.2748546898365021, \"specificity\": 1.0, \"npv\": 0.9578427672386169, \"accuracy\": 0.9585058093070984, \"f1\": 0.43119376124775044, \"f2\": 0.32147840709864395, \"f0_5\": 0.6545971149643013, \"p4\": 0.5985964086103632, \"phi\": 0.5130960728196106}, {\"truth_threshold\": 38.23185315700961, \"match_probability\": 0.9999999999969021, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1796.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4742.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2747017443180084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.725298285484314, \"precision\": 1.0, \"recall\": 0.2747017443180084, \"specificity\": 1.0, \"npv\": 0.9578342437744141, \"accuracy\": 0.9584970474243164, \"f1\": 0.4310055195584353, \"f2\": 0.32131100615428654, \"f0_5\": 0.6544235534178691, \"p4\": 0.5984141650618794, \"phi\": 0.5129510262920128}, {\"truth_threshold\": 38.24292087930831, \"match_probability\": 0.9999999999969258, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1795.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4743.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27454879879951477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7254512310028076, \"precision\": 1.0, \"recall\": 0.27454879879951477, \"specificity\": 1.0, \"npv\": 0.957825779914856, \"accuracy\": 0.9584883451461792, \"f1\": 0.43081723268930755, \"f2\": 0.3211435932300426, \"f0_5\": 0.6542498906546144, \"p4\": 0.5982318305022564, \"phi\": 0.5128058988845352}, {\"truth_threshold\": 38.281350205422235, \"match_probability\": 0.9999999999970066, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1794.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4744.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2743958532810211, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7256041765213013, \"precision\": 1.0, \"recall\": 0.2743958532810211, \"specificity\": 1.0, \"npv\": 0.9578172564506531, \"accuracy\": 0.9584795832633972, \"f1\": 0.43062890062409986, \"f2\": 0.32097616832462605, \"f0_5\": 0.6540761265859706, \"p4\": 0.5980494048617613, \"phi\": 0.5126607754212748}, {\"truth_threshold\": 38.2900471879307, \"match_probability\": 0.9999999999970246, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1793.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4745.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2742428779602051, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7257571220397949, \"precision\": 1.0, \"recall\": 0.2742428779602051, \"specificity\": 1.0, \"npv\": 0.9578087329864502, \"accuracy\": 0.9584708213806152, \"f1\": 0.43044052334653704, \"f2\": 0.32080873143675076, \"f0_5\": 0.6539022611232677, \"p4\": 0.5978668880705901, \"phi\": 0.512515570989377}, {\"truth_threshold\": 38.294701289086206, \"match_probability\": 0.9999999999970342, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1792.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4746.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2740899324417114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7259100675582886, \"precision\": 1.0, \"recall\": 0.2740899324417114, \"specificity\": 1.0, \"npv\": 0.9578002095222473, \"accuracy\": 0.9584620594978333, \"f1\": 0.43025210084033616, \"f2\": 0.32064128256513025, \"f0_5\": 0.6537282941777324, \"p4\": 0.5976842800588671, \"phi\": 0.512370370459393}, {\"truth_threshold\": 38.31476678089976, \"match_probability\": 0.9999999999970751, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1786.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4752.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2731722295284271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7268278002738953, \"precision\": 1.0, \"recall\": 0.2731722295284271, \"specificity\": 1.0, \"npv\": 0.9577491283416748, \"accuracy\": 0.9584095478057861, \"f1\": 0.4291206150888996, \"f2\": 0.3196363376046961, \"f0_5\": 0.6526823563806461, \"p4\": 0.5965867124349049, \"phi\": 0.5114982283960947}, {\"truth_threshold\": 38.317232017256934, \"match_probability\": 0.9999999999970801, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1785.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4753.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27301928400993347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7269807457923889, \"precision\": 1.0, \"recall\": 0.27301928400993347, \"specificity\": 1.0, \"npv\": 0.9577406048774719, \"accuracy\": 0.9584007859230042, \"f1\": 0.4289318755256518, \"f2\": 0.31946880481082435, \"f0_5\": 0.6525076765609007, \"p4\": 0.5964034639167952, \"phi\": 0.5113527571010275}, {\"truth_threshold\": 38.35683050440267, \"match_probability\": 0.9999999999971592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1784.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4754.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27286630868911743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7271336913108826, \"precision\": 1.0, \"recall\": 0.27286630868911743, \"specificity\": 1.0, \"npv\": 0.957732081413269, \"accuracy\": 0.9583920240402222, \"f1\": 0.42874309060322036, \"f2\": 0.3193012600229095, \"f0_5\": 0.6523328945443908, \"p4\": 0.5962201236165509, \"phi\": 0.5112072044351552}, {\"truth_threshold\": 38.36378226315792, \"match_probability\": 0.9999999999971728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1783.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4755.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2727133631706238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7272866368293762, \"precision\": 1.0, \"recall\": 0.2727133631706238, \"specificity\": 1.0, \"npv\": 0.9577235579490662, \"accuracy\": 0.958383321762085, \"f1\": 0.4285542603052518, \"f2\": 0.3191337032396635, \"f0_5\": 0.6521580102414045, \"p4\": 0.5960366914636503, \"phi\": 0.5110616554790399}, {\"truth_threshold\": 38.36479741607407, \"match_probability\": 0.9999999999971748, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1781.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4757.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2724074721336365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7275925278663635, \"precision\": 1.0, \"recall\": 0.2724074721336365, \"specificity\": 1.0, \"npv\": 0.9577065110206604, \"accuracy\": 0.958365797996521, \"f1\": 0.4281764635172497, \"f2\": 0.31879855368202487, \"f0_5\": 0.6518079344166301, \"p4\": 0.5956695513174334, \"phi\": 0.5107703983118684}, {\"truth_threshold\": 38.36908193073462, \"match_probability\": 0.9999999999971833, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1780.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4758.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2722545266151428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7277454733848572, \"precision\": 1.0, \"recall\": 0.2722545266151428, \"specificity\": 1.0, \"npv\": 0.9576980471611023, \"accuracy\": 0.958357036113739, \"f1\": 0.4279874969944698, \"f2\": 0.31863096090505516, \"f0_5\": 0.6516327427148924, \"p4\": 0.595485843182712, \"phi\": 0.510624732620395}, {\"truth_threshold\": 38.37096718331427, \"match_probability\": 0.9999999999971869, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1779.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4759.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2721015512943268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7278984189033508, \"precision\": 1.0, \"recall\": 0.2721015512943268, \"specificity\": 1.0, \"npv\": 0.9576895236968994, \"accuracy\": 0.958348274230957, \"f1\": 0.4277984850306601, \"f2\": 0.3184633561276002, \"f0_5\": 0.651457448366779, \"p4\": 0.5953020429125249, \"phi\": 0.510478985332718}, {\"truth_threshold\": 38.37966005944565, \"match_probability\": 0.9999999999972038, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1778.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4760.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27194860577583313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7280513644218445, \"precision\": 1.0, \"recall\": 0.27194860577583313, \"specificity\": 1.0, \"npv\": 0.9576810002326965, \"accuracy\": 0.958339512348175, \"f1\": 0.4276094276094276, \"f2\": 0.3182957393483709, \"f0_5\": 0.6512820512820513, \"p4\": 0.595118150435988, \"phi\": 0.5103332416467617}, {\"truth_threshold\": 38.39377700345576, \"match_probability\": 0.999999999997231, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1777.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4761.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2717956602573395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7282043695449829, \"precision\": 1.0, \"recall\": 0.2717956602573395, \"specificity\": 1.0, \"npv\": 0.9576724767684937, \"accuracy\": 0.9583308100700378, \"f1\": 0.42742032471437164, \"f2\": 0.31812811056607826, \"f0_5\": 0.651106551370365, \"p4\": 0.5949341656821452, \"phi\": 0.5101874162740416}, {\"truth_threshold\": 38.39446288313387, \"match_probability\": 0.9999999999972323, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1774.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4764.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27133679389953613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7286632061004639, \"precision\": 1.0, \"recall\": 0.27133679389953613, \"specificity\": 1.0, \"npv\": 0.957646906375885, \"accuracy\": 0.9583045244216919, \"f1\": 0.42685274302213666, \"f2\": 0.31762515218792525, \"f0_5\": 0.6505794337685199, \"p4\": 0.5943816570461228, \"phi\": 0.5097497907901267}, {\"truth_threshold\": 38.40309810796188, \"match_probability\": 0.9999999999972489, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1773.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4765.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2711838483810425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7288161516189575, \"precision\": 1.0, \"recall\": 0.2711838483810425, \"specificity\": 1.0, \"npv\": 0.9576384425163269, \"accuracy\": 0.9582957625389099, \"f1\": 0.42666345806762124, \"f2\": 0.3174574753804834, \"f0_5\": 0.6504035216434336, \"p4\": 0.5941973024720335, \"phi\": 0.5096038515366473}, {\"truth_threshold\": 38.418346884350804, \"match_probability\": 0.9999999999972777, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1768.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4770.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.27041909098625183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7295809388160706, \"precision\": 1.0, \"recall\": 0.27041909098625183, \"specificity\": 1.0, \"npv\": 0.9575958251953125, \"accuracy\": 0.9582520127296448, \"f1\": 0.42571634962677585, \"f2\": 0.3166189111747851, \"f0_5\": 0.6495224099926524, \"p4\": 0.5932741386748577, \"phi\": 0.5088734809420083}, {\"truth_threshold\": 38.422099392524586, \"match_probability\": 0.9999999999972848, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1765.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4773.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2699602246284485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7300397753715515, \"precision\": 1.0, \"recall\": 0.2699602246284485, \"specificity\": 1.0, \"npv\": 0.9575703144073486, \"accuracy\": 0.9582257270812988, \"f1\": 0.4251475370348067, \"f2\": 0.3161156284701078, \"f0_5\": 0.6489924988968966, \"p4\": 0.5927191250783461, \"phi\": 0.5084347519614051}, {\"truth_threshold\": 38.43755595103004, \"match_probability\": 0.9999999999973138, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1764.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4774.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26980727910995483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7301927208900452, \"precision\": 1.0, \"recall\": 0.26980727910995483, \"specificity\": 1.0, \"npv\": 0.9575617909431458, \"accuracy\": 0.9582170248031616, \"f1\": 0.42495784148397975, \"f2\": 0.3159478435305918, \"f0_5\": 0.6488156539649845, \"p4\": 0.5925339342292325, \"phi\": 0.5082884585516751}, {\"truth_threshold\": 38.438278426934, \"match_probability\": 0.9999999999973151, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1763.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4775.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2696543335914612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7303456664085388, \"precision\": 1.0, \"recall\": 0.2696543335914612, \"specificity\": 1.0, \"npv\": 0.9575532674789429, \"accuracy\": 0.9582082629203796, \"f1\": 0.4247681002288881, \"f2\": 0.31578004656994446, \"f0_5\": 0.6486387049300957, \"p4\": 0.5923486501017352, \"phi\": 0.508142082814804}, {\"truth_threshold\": 38.44139613555052, \"match_probability\": 0.9999999999973209, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1760.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4778.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26919546723365784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7308045029640198, \"precision\": 1.0, \"recall\": 0.26919546723365784, \"specificity\": 1.0, \"npv\": 0.957527756690979, \"accuracy\": 0.9581819772720337, \"f1\": 0.42419860207278864, \"f2\": 0.31527658354829463, \"f0_5\": 0.648107232287524, \"p4\": 0.591792237327986, \"phi\": 0.5077028037191881}, {\"truth_threshold\": 38.443235400636745, \"match_probability\": 0.9999999999973244, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1758.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4780.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26888957619667053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7311104536056519, \"precision\": 1.0, \"recall\": 0.26888957619667053, \"specificity\": 1.0, \"npv\": 0.9575107097625732, \"accuracy\": 0.9581645131111145, \"f1\": 0.42381870781099323, \"f2\": 0.3149408814045145, \"f0_5\": 0.6477523949889462, \"p4\": 0.59142082776385, \"phi\": 0.5074097384514944}, {\"truth_threshold\": 38.4550155943982, \"match_probability\": 0.9999999999973461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1756.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4782.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26858365535736084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7314163446426392, \"precision\": 1.0, \"recall\": 0.26858365535736084, \"specificity\": 1.0, \"npv\": 0.9574937224388123, \"accuracy\": 0.9581469893455505, \"f1\": 0.4234386303351821, \"f2\": 0.31460513114519134, \"f0_5\": 0.6473971390650347, \"p4\": 0.591049043352242, \"phi\": 0.5071165142489269}, {\"truth_threshold\": 38.461609171330444, \"match_probability\": 0.9999999999973582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1753.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4785.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2681248188018799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7318751811981201, \"precision\": 1.0, \"recall\": 0.2681248188018799, \"specificity\": 1.0, \"npv\": 0.9574681520462036, \"accuracy\": 0.9581207036972046, \"f1\": 0.42286817030515017, \"f2\": 0.31410141551693244, \"f0_5\": 0.6468634686346864, \"p4\": 0.5904906626259974, \"phi\": 0.506676400803085}, {\"truth_threshold\": 38.464569901111446, \"match_probability\": 0.9999999999973636, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1751.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4787.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2678188979625702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7321810722351074, \"precision\": 1.0, \"recall\": 0.2678188979625702, \"specificity\": 1.0, \"npv\": 0.9574511647224426, \"accuracy\": 0.9581032395362854, \"f1\": 0.4224876342140186, \"f2\": 0.3137655449234849, \"f0_5\": 0.6465071629006055, \"p4\": 0.5901179385540972, \"phi\": 0.5063827780643593}, {\"truth_threshold\": 38.47841602697827, \"match_probability\": 0.9999999999973888, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1745.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4793.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2669011950492859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7330988049507141, \"precision\": 1.0, \"recall\": 0.2669011950492859, \"specificity\": 1.0, \"npv\": 0.9574000835418701, \"accuracy\": 0.9580507278442383, \"f1\": 0.4213449233369552, \"f2\": 0.31275764419113167, \"f0_5\": 0.6454357153425063, \"p4\": 0.5889975026955138, \"phi\": 0.5055009492960207}, {\"truth_threshold\": 38.49077362630273, \"match_probability\": 0.9999999999974111, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1744.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4794.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26674824953079224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7332517504692078, \"precision\": 1.0, \"recall\": 0.26674824953079224, \"specificity\": 1.0, \"npv\": 0.957391619682312, \"accuracy\": 0.9580419659614563, \"f1\": 0.4211543105530065, \"f2\": 0.3125896185833094, \"f0_5\": 0.6452567707562528, \"p4\": 0.5888104325025538, \"phi\": 0.5053538589069686}, {\"truth_threshold\": 38.49154081326093, \"match_probability\": 0.9999999999974124, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1742.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4796.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26644232869148254, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7335576415061951, \"precision\": 1.0, \"recall\": 0.26644232869148254, \"specificity\": 1.0, \"npv\": 0.9573745727539062, \"accuracy\": 0.9580244421958923, \"f1\": 0.4207729468599034, \"f2\": 0.3122535312253531, \"f0_5\": 0.6448985636013623, \"p4\": 0.5884360078417828, \"phi\": 0.5050595144005466}, {\"truth_threshold\": 38.51972488115568, \"match_probability\": 0.9999999999974625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1740.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4798.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26613643765449524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7338635921478271, \"precision\": 1.0, \"recall\": 0.26613643765449524, \"specificity\": 1.0, \"npv\": 0.9573575258255005, \"accuracy\": 0.9580069780349731, \"f1\": 0.4203913988886204, \"f2\": 0.31191739566900906, \"f0_5\": 0.6445399318417543, \"p4\": 0.5880612036570887, \"phi\": 0.5047650087256786}, {\"truth_threshold\": 38.53446591559715, \"match_probability\": 0.9999999999974883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1737.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4801.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2656775712966919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7343224287033081, \"precision\": 1.0, \"recall\": 0.2656775712966919, \"specificity\": 1.0, \"npv\": 0.9573320150375366, \"accuracy\": 0.9579806923866272, \"f1\": 0.41981873111782475, \"f2\": 0.3114131019398329, \"f0_5\": 0.644001186415542, \"p4\": 0.5874982844817012, \"phi\": 0.504322968966509}, {\"truth_threshold\": 38.5390899421226, \"match_probability\": 0.9999999999974963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1736.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4802.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26552462577819824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7344753742218018, \"precision\": 1.0, \"recall\": 0.26552462577819824, \"specificity\": 1.0, \"npv\": 0.9573235511779785, \"accuracy\": 0.9579719305038452, \"f1\": 0.4196277495769882, \"f2\": 0.3112449799196787, \"f0_5\": 0.6438213914849429, \"p4\": 0.5873104543546509, \"phi\": 0.5041755558764587}, {\"truth_threshold\": 38.54037126050162, \"match_probability\": 0.9999999999974986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1735.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4803.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2653716802597046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7346283197402954, \"precision\": 1.0, \"recall\": 0.2653716802597046, \"specificity\": 1.0, \"npv\": 0.9573150277137756, \"accuracy\": 0.9579631686210632, \"f1\": 0.4194367218663121, \"f2\": 0.3110768458421487, \"f0_5\": 0.6436414898352871, \"p4\": 0.5871225289032103, \"phi\": 0.5040280591436122}, {\"truth_threshold\": 38.56361226125667, \"match_probability\": 0.9999999999975385, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1732.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4806.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26491281390190125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7350871562957764, \"precision\": 1.0, \"recall\": 0.26491281390190125, \"specificity\": 1.0, \"npv\": 0.9572895169258118, \"accuracy\": 0.9579369425773621, \"f1\": 0.418863361547763, \"f2\": 0.31057237125233106, \"f0_5\": 0.6431011436209714, \"p4\": 0.5865581798604284, \"phi\": 0.5035854118599681}, {\"truth_threshold\": 38.56890656092618, \"match_probability\": 0.9999999999975475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1731.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4807.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2647598683834076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7352401614189148, \"precision\": 1.0, \"recall\": 0.2647598683834076, \"specificity\": 1.0, \"npv\": 0.9572809934616089, \"accuracy\": 0.9579281806945801, \"f1\": 0.4186721489902044, \"f2\": 0.31040418893232435, \"f0_5\": 0.6429208141435151, \"p4\": 0.5863698723689237, \"phi\": 0.5034377527264505}, {\"truth_threshold\": 38.57503512877569, \"match_probability\": 0.999999999997558, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1730.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4808.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26460692286491394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7353931069374084, \"precision\": 1.0, \"recall\": 0.26460692286491394, \"specificity\": 1.0, \"npv\": 0.957272469997406, \"accuracy\": 0.9579194188117981, \"f1\": 0.41848089017900336, \"f2\": 0.3102359945484542, \"f0_5\": 0.6427403774706494, \"p4\": 0.586181469181392, \"phi\": 0.5032900961086922}, {\"truth_threshold\": 38.58411236071674, \"match_probability\": 0.9999999999975733, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1728.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4810.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26430100202560425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7356989979743958, \"precision\": 1.0, \"recall\": 0.26430100202560425, \"specificity\": 1.0, \"npv\": 0.957255482673645, \"accuracy\": 0.9579018950462341, \"f1\": 0.4180982337285265, \"f2\": 0.3098995695839311, \"f0_5\": 0.6423791821561339, \"p4\": 0.5858043754199342, \"phi\": 0.5029946174797543}, {\"truth_threshold\": 38.59874235303403, \"match_probability\": 0.9999999999975977, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1727.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4811.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2641480565071106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7358519434928894, \"precision\": 1.0, \"recall\": 0.2641480565071106, \"specificity\": 1.0, \"npv\": 0.9572469592094421, \"accuracy\": 0.9578931927680969, \"f1\": 0.41790683605565637, \"f2\": 0.3097313390006815, \"f0_5\": 0.6421984233229213, \"p4\": 0.5856156846966577, \"phi\": 0.5028468386205156}, {\"truth_threshold\": 38.606489743734336, \"match_probability\": 0.9999999999976106, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1725.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4813.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2638421654701233, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7361578345298767, \"precision\": 1.0, \"recall\": 0.2638421654701233, \"specificity\": 1.0, \"npv\": 0.9572299718856812, \"accuracy\": 0.957875669002533, \"f1\": 0.41752390173060633, \"f2\": 0.30939484162571296, \"f0_5\": 0.6418365828248251, \"p4\": 0.5852380151910512, \"phi\": 0.5025511151475919}, {\"truth_threshold\": 38.611975282818065, \"match_probability\": 0.9999999999976197, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1722.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4816.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26338329911231995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7366167306900024, \"precision\": 1.0, \"recall\": 0.26338329911231995, \"specificity\": 1.0, \"npv\": 0.9572044014930725, \"accuracy\": 0.957849383354187, \"f1\": 0.41694915254237286, \"f2\": 0.3088900050226017, \"f0_5\": 0.6412930135557873, \"p4\": 0.5846707896607984, \"phi\": 0.5021072014450699}, {\"truth_threshold\": 38.612434073578214, \"match_probability\": 0.9999999999976205, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1719.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4819.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2629244327545166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7370755672454834, \"precision\": 1.0, \"recall\": 0.2629244327545166, \"specificity\": 1.0, \"npv\": 0.9571788907051086, \"accuracy\": 0.9578231573104858, \"f1\": 0.41637398570909534, \"f2\": 0.3083850597395142, \"f0_5\": 0.6407484717459371, \"p4\": 0.5841026968013848, \"phi\": 0.5016629619766777}, {\"truth_threshold\": 38.61460221315559, \"match_probability\": 0.999999999997624, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1718.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4820.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26277148723602295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.737228512763977, \"precision\": 1.0, \"recall\": 0.26277148723602295, \"specificity\": 1.0, \"npv\": 0.9571704268455505, \"accuracy\": 0.9578143954277039, \"f1\": 0.4161821705426357, \"f2\": 0.30821672048797993, \"f0_5\": 0.6405667412378822, \"p4\": 0.583913139423705, \"phi\": 0.501514814428698}, {\"truth_threshold\": 38.62361986486034, \"match_probability\": 0.9999999999976388, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1717.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4821.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2626185417175293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7373814582824707, \"precision\": 1.0, \"recall\": 0.2626185417175293, \"specificity\": 1.0, \"npv\": 0.9571619033813477, \"accuracy\": 0.9578056335449219, \"f1\": 0.4159903089036947, \"f2\": 0.3080483691556927, \"f0_5\": 0.6403849022825601, \"p4\": 0.5837234853746613, \"phi\": 0.5013665823666131}, {\"truth_threshold\": 38.632285116559046, \"match_probability\": 0.999999999997653, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1715.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4823.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2623126208782196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.737687349319458, \"precision\": 1.0, \"recall\": 0.2623126208782196, \"specificity\": 1.0, \"npv\": 0.9571449160575867, \"accuracy\": 0.9577881693840027, \"f1\": 0.4156064461407973, \"f2\": 0.3077116302436574, \"f0_5\": 0.6400208986415883, \"p4\": 0.5833438869601082, \"phi\": 0.5010700379933571}, {\"truth_threshold\": 38.636740363093864, \"match_probability\": 0.9999999999976602, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1712.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4826.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26185378432273865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7381462454795837, \"precision\": 1.0, \"recall\": 0.26185378432273865, \"specificity\": 1.0, \"npv\": 0.957119345664978, \"accuracy\": 0.9577618837356567, \"f1\": 0.415030303030303, \"f2\": 0.307206431237439, \"f0_5\": 0.6394740773942925, \"p4\": 0.5827737624111421, \"phi\": 0.5006249335780606}, {\"truth_threshold\": 38.642348931861584, \"match_probability\": 0.9999999999976693, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1711.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4827.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.261700838804245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7382991909980774, \"precision\": 1.0, \"recall\": 0.261700838804245, \"specificity\": 1.0, \"npv\": 0.9571108818054199, \"accuracy\": 0.9577531218528748, \"f1\": 0.41483816220147895, \"f2\": 0.3070380073933173, \"f0_5\": 0.6392915857121506, \"p4\": 0.5825835267441047, \"phi\": 0.5004764972304974}, {\"truth_threshold\": 38.649959163051044, \"match_probability\": 0.9999999999976815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1710.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4828.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26154786348342896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.738452136516571, \"precision\": 1.0, \"recall\": 0.26154786348342896, \"specificity\": 1.0, \"npv\": 0.957102358341217, \"accuracy\": 0.9577443599700928, \"f1\": 0.4146459747817653, \"f2\": 0.3068695714593353, \"f0_5\": 0.6391089849005831, \"p4\": 0.5823931938750291, \"phi\": 0.5003279760244064}, {\"truth_threshold\": 38.65659484088952, \"match_probability\": 0.9999999999976922, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1709.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4829.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2613949179649353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7386050820350647, \"precision\": 1.0, \"recall\": 0.2613949179649353, \"specificity\": 1.0, \"npv\": 0.9570938348770142, \"accuracy\": 0.9577356576919556, \"f1\": 0.41445374075421365, \"f2\": 0.30670112343419115, \"f0_5\": 0.6389262748616719, \"p4\": 0.5822027637277879, \"phi\": 0.5001794568296549}, {\"truth_threshold\": 38.66585654889256, \"match_probability\": 0.999999999997707, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1708.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4830.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26124197244644165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7387580275535583, \"precision\": 1.0, \"recall\": 0.26124197244644165, \"specificity\": 1.0, \"npv\": 0.957085371017456, \"accuracy\": 0.9577268958091736, \"f1\": 0.4142614601018676, \"f2\": 0.3065326633165829, \"f0_5\": 0.6387434554973822, \"p4\": 0.5820122362261742, \"phi\": 0.5000308526773835}, {\"truth_threshold\": 38.67084584389265, \"match_probability\": 0.9999999999977148, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1707.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4831.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.261089026927948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.738910973072052, \"precision\": 1.0, \"recall\": 0.261089026927948, \"specificity\": 1.0, \"npv\": 0.9570768475532532, \"accuracy\": 0.9577181339263916, \"f1\": 0.4140691328077623, \"f2\": 0.30636419110520835, \"f0_5\": 0.6385605267095615, \"p4\": 0.5818216112939016, \"phi\": 0.49988225048743085}, {\"truth_threshold\": 38.67756996945636, \"match_probability\": 0.9999999999977255, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1705.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4833.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2607831060886383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7392168641090393, \"precision\": 1.0, \"recall\": 0.2607831060886383, \"specificity\": 1.0, \"npv\": 0.9570598602294922, \"accuracy\": 0.9577006101608276, \"f1\": 0.4136843382263739, \"f2\": 0.30602721039595077, \"f0_5\": 0.6381943404701302, \"p4\": 0.5814400688318354, \"phi\": 0.4995848779071028}, {\"truth_threshold\": 38.67870729299738, \"match_probability\": 0.9999999999977273, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1704.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4834.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26063016057014465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.739369809627533, \"precision\": 1.0, \"recall\": 0.26063016057014465, \"specificity\": 1.0, \"npv\": 0.9570513367652893, \"accuracy\": 0.9576918482780457, \"f1\": 0.41349187090512013, \"f2\": 0.3058587018954624, \"f0_5\": 0.6380110828216264, \"p4\": 0.5812491511490698, \"phi\": 0.4994361509521597}, {\"truth_threshold\": 38.68528574464051, \"match_probability\": 0.9999999999977376, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1703.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4835.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.260477215051651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7395228147506714, \"precision\": 1.0, \"recall\": 0.260477215051651, \"specificity\": 1.0, \"npv\": 0.9570428133010864, \"accuracy\": 0.9576831459999084, \"f1\": 0.41329935687416575, \"f2\": 0.3056901812959971, \"f0_5\": 0.6378277153558053, \"p4\": 0.5810581357297016, \"phi\": 0.49928733879107545}, {\"truth_threshold\": 38.70101009693353, \"match_probability\": 0.9999999999977621, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1702.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4836.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.26032426953315735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.739675760269165, \"precision\": 1.0, \"recall\": 0.26032426953315735, \"specificity\": 1.0, \"npv\": 0.9570343494415283, \"accuracy\": 0.9576743841171265, \"f1\": 0.41310679611650486, \"f2\": 0.30552164859625186, \"f0_5\": 0.6376442379739248, \"p4\": 0.5808670224970445, \"phi\": 0.4991385284690029}, {\"truth_threshold\": 38.704791623300956, \"match_probability\": 0.999999999997768, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1701.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4837.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2601712942123413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7398287057876587, \"precision\": 1.0, \"recall\": 0.2601712942123413, \"specificity\": 1.0, \"npv\": 0.9570258259773254, \"accuracy\": 0.9576656222343445, \"f1\": 0.4129141886151232, \"f2\": 0.30535310379492336, \"f0_5\": 0.6374606505771249, \"p4\": 0.5806758113743322, \"phi\": 0.49898963284087744}, {\"truth_threshold\": 38.7048345584455, \"match_probability\": 0.999999999997768, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1698.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4840.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25971245765686035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7402875423431396, \"precision\": 1.0, \"recall\": 0.25971245765686035, \"specificity\": 1.0, \"npv\": 0.9570003151893616, \"accuracy\": 0.9576393365859985, \"f1\": 0.41233608547838757, \"f2\": 0.30484739676840217, \"f0_5\": 0.6369092273068268, \"p4\": 0.5801015898969973, \"phi\": 0.4985427822517551}, {\"truth_threshold\": 38.746921646551286, \"match_probability\": 0.9999999999978322, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1697.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4841.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2595595121383667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7404404878616333, \"precision\": 1.0, \"recall\": 0.2595595121383667, \"specificity\": 1.0, \"npv\": 0.9569918513298035, \"accuracy\": 0.9576306343078613, \"f1\": 0.41214329083181545, \"f2\": 0.3046788035477037, \"f0_5\": 0.6367251988593726, \"p4\": 0.5799099864447943, \"phi\": 0.49839371923967984}, {\"truth_threshold\": 38.74907241904272, \"match_probability\": 0.9999999999978354, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1696.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4842.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25940653681755066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.740593433380127, \"precision\": 1.0, \"recall\": 0.25940653681755066, \"specificity\": 1.0, \"npv\": 0.9569833278656006, \"accuracy\": 0.9576218724250793, \"f1\": 0.4119504493563274, \"f2\": 0.30451019821890263, \"f0_5\": 0.6365410599009158, \"p4\": 0.5797182847174979, \"phi\": 0.49824465791719325}, {\"truth_threshold\": 38.76215794063875, \"match_probability\": 0.999999999997855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1694.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4844.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25910064578056335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.740899384021759, \"precision\": 1.0, \"recall\": 0.25910064578056335, \"specificity\": 1.0, \"npv\": 0.9569663405418396, \"accuracy\": 0.9576043486595154, \"f1\": 0.41156462585034015, \"f2\": 0.30417295123177474, \"f0_5\": 0.6361724500525763, \"p4\": 0.5793345861285448, \"phi\": 0.4979463656968797}, {\"truth_threshold\": 38.76395524828413, \"match_probability\": 0.9999999999978577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1691.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4847.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25864177942276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.74135822057724, \"precision\": 1.0, \"recall\": 0.25864177942276, \"specificity\": 1.0, \"npv\": 0.9569408297538757, \"accuracy\": 0.9575780630111694, \"f1\": 0.41098553894762424, \"f2\": 0.30366698990769675, \"f0_5\": 0.6356187039542925, \"p4\": 0.5787582992480359, \"phi\": 0.49749863376847314}, {\"truth_threshold\": 38.77483651413865, \"match_probability\": 0.9999999999978738, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1689.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4849.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2583358883857727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7416641116142273, \"precision\": 1.0, \"recall\": 0.2583358883857727, \"specificity\": 1.0, \"npv\": 0.9569238424301147, \"accuracy\": 0.9575605988502502, \"f1\": 0.41059924638385803, \"f2\": 0.30332962178082684, \"f0_5\": 0.6352489845042877, \"p4\": 0.5783736144246096, \"phi\": 0.49719992052129547}, {\"truth_threshold\": 38.77711099705838, \"match_probability\": 0.9999999999978771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1688.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4850.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25818294286727905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.741817057132721, \"precision\": 1.0, \"recall\": 0.25818294286727905, \"specificity\": 1.0, \"npv\": 0.9569153189659119, \"accuracy\": 0.9575518369674683, \"f1\": 0.41040602966204714, \"f2\": 0.3031609195402299, \"f0_5\": 0.6350639578630549, \"p4\": 0.5781811237087585, \"phi\": 0.4970504786923457}, {\"truth_threshold\": 38.778005437508156, \"match_probability\": 0.9999999999978785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1687.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4851.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.258029967546463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7419700026512146, \"precision\": 1.0, \"recall\": 0.258029967546463, \"specificity\": 1.0, \"npv\": 0.956906795501709, \"accuracy\": 0.9575430750846863, \"f1\": 0.4102127659574468, \"f2\": 0.30299220517978376, \"f0_5\": 0.6348788198103267, \"p4\": 0.5779885340196421, \"phi\": 0.49690103832584975}, {\"truth_threshold\": 38.77840661331115, \"match_probability\": 0.999999999997879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1684.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4854.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25757113099098206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7424288988113403, \"precision\": 1.0, \"recall\": 0.25757113099098206, \"specificity\": 1.0, \"npv\": 0.9568812847137451, \"accuracy\": 0.9575168490409851, \"f1\": 0.4096326927754804, \"f2\": 0.30248598936628823, \"f0_5\": 0.6343227361759831, \"p4\": 0.5774101703324676, \"phi\": 0.4964524194803084}, {\"truth_threshold\": 38.778914873985364, \"match_probability\": 0.9999999999978798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1682.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4856.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25726521015167236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7427347898483276, \"precision\": 1.0, \"recall\": 0.25726521015167236, \"specificity\": 1.0, \"npv\": 0.9568642973899841, \"accuracy\": 0.9574993252754211, \"f1\": 0.4092457420924574, \"f2\": 0.302148451534095, \"f0_5\": 0.6339514548469772, \"p4\": 0.5770240982428283, \"phi\": 0.4961531135879613}, {\"truth_threshold\": 38.79874379442379, \"match_probability\": 0.9999999999979087, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1681.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4857.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2571122646331787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7428877353668213, \"precision\": 1.0, \"recall\": 0.2571122646331787, \"specificity\": 1.0, \"npv\": 0.956855833530426, \"accuracy\": 0.9574905633926392, \"f1\": 0.40905219613091615, \"f2\": 0.3019796644271189, \"f0_5\": 0.6337656462072085, \"p4\": 0.5768309130736196, \"phi\": 0.4960033749892178}, {\"truth_threshold\": 38.81634472204291, \"match_probability\": 0.9999999999979341, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1680.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4858.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25695931911468506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7430406808853149, \"precision\": 1.0, \"recall\": 0.25695931911468506, \"specificity\": 1.0, \"npv\": 0.9568473100662231, \"accuracy\": 0.9574818015098572, \"f1\": 0.4088586030664395, \"f2\": 0.30181086519114686, \"f0_5\": 0.6335797254487856, \"p4\": 0.5766376283835449, \"phi\": 0.4958536376737345}, {\"truth_threshold\": 38.837978957706895, \"match_probability\": 0.9999999999979649, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1679.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4859.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2568063735961914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7431936264038086, \"precision\": 1.0, \"recall\": 0.2568063735961914, \"specificity\": 1.0, \"npv\": 0.9568387866020203, \"accuracy\": 0.9574730396270752, \"f1\": 0.40866496288183035, \"f2\": 0.3016420538248715, \"f0_5\": 0.6333936924701977, \"p4\": 0.5764442440940463, \"phi\": 0.4957038577884455}, {\"truth_threshold\": 38.852622853892655, \"match_probability\": 0.9999999999979854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1673.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4865.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2558886408805847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7441113591194153, \"precision\": 1.0, \"recall\": 0.2558886408805847, \"specificity\": 1.0, \"npv\": 0.9567878246307373, \"accuracy\": 0.9574205279350281, \"f1\": 0.4075021312872975, \"f2\": 0.30062893081761005, \"f0_5\": 0.6322751322751323, \"p4\": 0.575281842359467, \"phi\": 0.4948041505500038}, {\"truth_threshold\": 38.87363071983243, \"match_probability\": 0.9999999999980145, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1672.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4866.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25573569536209106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7442643046379089, \"precision\": 1.0, \"recall\": 0.25573569536209106, \"specificity\": 1.0, \"npv\": 0.9567793011665344, \"accuracy\": 0.9574118256568909, \"f1\": 0.40730816077953713, \"f2\": 0.3004600345025877, \"f0_5\": 0.6320883109027673, \"p4\": 0.5750877586674152, \"phi\": 0.4946540715512289}, {\"truth_threshold\": 38.9117766915257, \"match_probability\": 0.9999999999980663, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1671.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4867.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2555827498435974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7444172501564026, \"precision\": 1.0, \"recall\": 0.2555827498435974, \"specificity\": 1.0, \"npv\": 0.9567708373069763, \"accuracy\": 0.9574030637741089, \"f1\": 0.40711414301376536, \"f2\": 0.3002911260467958, \"f0_5\": 0.6319013764937226, \"p4\": 0.5748935747444892, \"phi\": 0.49450390571534103}, {\"truth_threshold\": 38.919715392501175, \"match_probability\": 0.9999999999980769, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1667.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4871.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2549709379673004, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7450290322303772, \"precision\": 1.0, \"recall\": 0.2549709379673004, \"specificity\": 1.0, \"npv\": 0.9567368030548096, \"accuracy\": 0.957368016242981, \"f1\": 0.4063375990249848, \"f2\": 0.29961537078974804, \"f0_5\": 0.6311525064364683, \"p4\": 0.5741158351566628, \"phi\": 0.4939029005366608}, {\"truth_threshold\": 38.92146142785713, \"match_probability\": 0.9999999999980792, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1665.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4873.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2546650469303131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7453349828720093, \"precision\": 1.0, \"recall\": 0.2546650469303131, \"specificity\": 1.0, \"npv\": 0.9567198157310486, \"accuracy\": 0.9573505520820618, \"f1\": 0.4059490430330367, \"f2\": 0.29927742028256105, \"f0_5\": 0.6307773905137142, \"p4\": 0.5737263619115641, \"phi\": 0.493602139563825}, {\"truth_threshold\": 38.93619518921342, \"match_probability\": 0.9999999999980987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1664.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4874.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25451207160949707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7454879283905029, \"precision\": 1.0, \"recall\": 0.25451207160949707, \"specificity\": 1.0, \"npv\": 0.9567113518714905, \"accuracy\": 0.9573417901992798, \"f1\": 0.40575469397707875, \"f2\": 0.2991084268047167, \"f0_5\": 0.630589661967561, \"p4\": 0.5735314741472523, \"phi\": 0.4934517163671491}, {\"truth_threshold\": 38.95125161948965, \"match_probability\": 0.9999999999981185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1663.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4875.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2543591260910034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7456408739089966, \"precision\": 1.0, \"recall\": 0.2543591260910034, \"specificity\": 1.0, \"npv\": 0.9567028284072876, \"accuracy\": 0.9573330283164978, \"f1\": 0.40556029752469214, \"f2\": 0.29893942117562466, \"f0_5\": 0.630401819560273, \"p4\": 0.5733364855152678, \"phi\": 0.49330124997485236}, {\"truth_threshold\": 38.9628824446772, \"match_probability\": 0.9999999999981336, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1662.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4876.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25420618057250977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7457938194274902, \"precision\": 1.0, \"recall\": 0.25420618057250977, \"specificity\": 1.0, \"npv\": 0.9566943645477295, \"accuracy\": 0.9573242664337158, \"f1\": 0.4053658536585366, \"f2\": 0.29877040339397426, \"f0_5\": 0.6302138631882299, \"p4\": 0.5731413959356324, \"phi\": 0.49315069627395014}, {\"truth_threshold\": 38.96599697582067, \"match_probability\": 0.9999999999981376, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1659.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4879.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2537473142147064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7462526559829712, \"precision\": 1.0, \"recall\": 0.2537473142147064, \"specificity\": 1.0, \"npv\": 0.9566688537597656, \"accuracy\": 0.9572980403900146, \"f1\": 0.40478223740392827, \"f2\": 0.29826327712056383, \"f0_5\": 0.6296493092454836, \"p4\": 0.5725555207097648, \"phi\": 0.49269886343112684}, {\"truth_threshold\": 38.969308713836625, \"match_probability\": 0.9999999999981419, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1658.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4880.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25359436869621277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7464056015014648, \"precision\": 1.0, \"recall\": 0.25359436869621277, \"specificity\": 1.0, \"npv\": 0.9566603899002075, \"accuracy\": 0.9572892785072327, \"f1\": 0.4045876037091264, \"f2\": 0.29809421071556996, \"f0_5\": 0.6294608959757023, \"p4\": 0.5723600265380463, \"phi\": 0.4925481363134487}, {\"truth_threshold\": 38.97571181147935, \"match_probability\": 0.9999999999981501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1655.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4883.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2531355023384094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7468644976615906, \"precision\": 1.0, \"recall\": 0.2531355023384094, \"specificity\": 1.0, \"npv\": 0.9566348791122437, \"accuracy\": 0.9572629928588867, \"f1\": 0.40400341755156843, \"f2\": 0.2975869385406552, \"f0_5\": 0.6288949688402493, \"p4\": 0.5717729356079673, \"phi\": 0.492095782367934}, {\"truth_threshold\": 38.976802666301225, \"match_probability\": 0.9999999999981515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1654.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4884.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25298255681991577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7470174431800842, \"precision\": 1.0, \"recall\": 0.25298255681991577, \"specificity\": 1.0, \"npv\": 0.9566263556480408, \"accuracy\": 0.9572542309761047, \"f1\": 0.40380859375, \"f2\": 0.29741782349133283, \"f0_5\": 0.6287060970047134, \"p4\": 0.5715770355577235, \"phi\": 0.4919449253728022}, {\"truth_threshold\": 38.97777429296482, \"match_probability\": 0.9999999999981528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1653.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4885.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2528296113014221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7471703886985779, \"precision\": 1.0, \"recall\": 0.2528296113014221, \"specificity\": 1.0, \"npv\": 0.9566178917884827, \"accuracy\": 0.9572455286979675, \"f1\": 0.40361372237822, \"f2\": 0.2972486962776479, \"f0_5\": 0.6285171102661598, \"p4\": 0.5713810338362029, \"phi\": 0.4917939805917726}, {\"truth_threshold\": 38.992318512094556, \"match_probability\": 0.9999999999981714, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1650.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4888.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2523707449436188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7476292252540588, \"precision\": 1.0, \"recall\": 0.2523707449436188, \"specificity\": 1.0, \"npv\": 0.9565923810005188, \"accuracy\": 0.9572192430496216, \"f1\": 0.40302882266731804, \"f2\": 0.29674124163729226, \"f0_5\": 0.6279494595828893, \"p4\": 0.5707924178352587, \"phi\": 0.4913409725831503}, {\"truth_threshold\": 38.99693408643103, \"match_probability\": 0.9999999999981771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1649.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4889.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2522177994251251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7477821707725525, \"precision\": 1.0, \"recall\": 0.2522177994251251, \"specificity\": 1.0, \"npv\": 0.9565839171409607, \"accuracy\": 0.9572104811668396, \"f1\": 0.40283376084035666, \"f2\": 0.29657206575303047, \"f0_5\": 0.6277600121821227, \"p4\": 0.5705960086194808, \"phi\": 0.4911898529422943}, {\"truth_threshold\": 39.001290217435304, \"match_probability\": 0.9999999999981827, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1648.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4890.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25206485390663147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7479351758956909, \"precision\": 1.0, \"recall\": 0.25206485390663147, \"specificity\": 1.0, \"npv\": 0.9565753936767578, \"accuracy\": 0.9572017192840576, \"f1\": 0.4026386513559736, \"f2\": 0.29640287769784174, \"f0_5\": 0.6275704493526276, \"p4\": 0.570399497327422, \"phi\": 0.49103873373624995}, {\"truth_threshold\": 39.00217755269315, \"match_probability\": 0.9999999999981838, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1638.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4900.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.25053533911705017, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7494646906852722, \"precision\": 1.0, \"recall\": 0.25053533911705017, \"specificity\": 1.0, \"npv\": 0.9564904570579529, \"accuracy\": 0.9571142196655273, \"f1\": 0.4006849315068493, \"f2\": 0.2947103274559194, \"f0_5\": 0.6256684491978609, \"p4\": 0.5684287522916717, \"phi\": 0.4895249463794727}, {\"truth_threshold\": 39.0055064137397, \"match_probability\": 0.9999999999981879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1637.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4901.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2503823935985565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7496176362037659, \"precision\": 1.0, \"recall\": 0.2503823935985565, \"specificity\": 1.0, \"npv\": 0.9564819931983948, \"accuracy\": 0.9571054577827454, \"f1\": 0.4004892966360856, \"f2\": 0.29454100543380474, \"f0_5\": 0.6254776096591778, \"p4\": 0.5682311127784128, \"phi\": 0.48937329827036363}, {\"truth_threshold\": 39.00619229341781, \"match_probability\": 0.9999999999981888, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1633.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4905.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24977056682109833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7502294182777405, \"precision\": 1.0, \"recall\": 0.24977056682109833, \"specificity\": 1.0, \"npv\": 0.9564480185508728, \"accuracy\": 0.9570704698562622, \"f1\": 0.3997062783013095, \"f2\": 0.29386359546517904, \"f0_5\": 0.6247130833970925, \"p4\": 0.5674395233308863, \"phi\": 0.48876635120204137}, {\"truth_threshold\": 39.03150162227265, \"match_probability\": 0.9999999999982203, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1632.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4906.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24961762130260468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7503823637962341, \"precision\": 1.0, \"recall\": 0.24961762130260468, \"specificity\": 1.0, \"npv\": 0.9564394950866699, \"accuracy\": 0.9570617079734802, \"f1\": 0.3995104039167687, \"f2\": 0.2936942124964008, \"f0_5\": 0.62452165926833, \"p4\": 0.5672413677082174, \"phi\": 0.4886145256102511}, {\"truth_threshold\": 39.04185416827056, \"match_probability\": 0.999999999998233, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1629.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4909.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24915876984596252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7508412599563599, \"precision\": 1.0, \"recall\": 0.24915876984596252, \"specificity\": 1.0, \"npv\": 0.9564140439033508, \"accuracy\": 0.957035481929779, \"f1\": 0.398922492959471, \"f2\": 0.2931859904251107, \"f0_5\": 0.6239466830090393, \"p4\": 0.5666462796922304, \"phi\": 0.48815873719599456}, {\"truth_threshold\": 39.043543979354034, \"match_probability\": 0.9999999999982351, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1626.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4912.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24869990348815918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7513000965118408, \"precision\": 1.0, \"recall\": 0.24869990348815918, \"specificity\": 1.0, \"npv\": 0.956388533115387, \"accuracy\": 0.9570091962814331, \"f1\": 0.3983341499265066, \"f2\": 0.29267765857873135, \"f0_5\": 0.6233706486735163, \"p4\": 0.5660502582139358, \"phi\": 0.4877025025822555}, {\"truth_threshold\": 39.04464162618558, \"match_probability\": 0.9999999999982364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1625.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4913.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24854695796966553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7514530420303345, \"precision\": 1.0, \"recall\": 0.24854695796966553, \"specificity\": 1.0, \"npv\": 0.9563800692558289, \"accuracy\": 0.9570004343986511, \"f1\": 0.3981379394830332, \"f2\": 0.29250819022932645, \"f0_5\": 0.6231784015953367, \"p4\": 0.5658513765642023, \"phi\": 0.4875503646193711}, {\"truth_threshold\": 39.04946399653446, \"match_probability\": 0.9999999999982423, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1623.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4915.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24824105203151703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7517589330673218, \"precision\": 1.0, \"recall\": 0.24824105203151703, \"specificity\": 1.0, \"npv\": 0.9563630819320679, \"accuracy\": 0.9569829702377319, \"f1\": 0.39774537434137974, \"f2\": 0.2921692169216922, \"f0_5\": 0.6227935533384498, \"p4\": 0.5654533010297842, \"phi\": 0.48724590970134135}, {\"truth_threshold\": 39.05258057486362, \"match_probability\": 0.9999999999982461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1622.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4916.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24808810651302338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7519118785858154, \"precision\": 1.0, \"recall\": 0.24808810651302338, \"specificity\": 1.0, \"npv\": 0.9563546180725098, \"accuracy\": 0.95697420835495, \"f1\": 0.3975490196078431, \"f2\": 0.2919997119608267, \"f0_5\": 0.6226009519422693, \"p4\": 0.565254106978289, \"phi\": 0.4870936372405537}, {\"truth_threshold\": 39.054202965474246, \"match_probability\": 0.9999999999982481, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1621.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4917.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24793514609336853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7520648241043091, \"precision\": 1.0, \"recall\": 0.24793514609336853, \"specificity\": 1.0, \"npv\": 0.9563460946083069, \"accuracy\": 0.956965446472168, \"f1\": 0.3973526167422478, \"f2\": 0.29183019479350447, \"f0_5\": 0.6224082322223928, \"p4\": 0.5650548086259144, \"phi\": 0.4869412752482423}, {\"truth_threshold\": 39.061778200257585, \"match_probability\": 0.9999999999982573, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1618.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4920.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24747629463672638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7525237202644348, \"precision\": 1.0, \"recall\": 0.24747629463672638, \"specificity\": 1.0, \"npv\": 0.9563206434249878, \"accuracy\": 0.956939160823822, \"f1\": 0.3967631191760667, \"f2\": 0.29132157003961107, \"f0_5\": 0.6218293620292084, \"p4\": 0.564456286926783, \"phi\": 0.486484008531187}, {\"truth_threshold\": 39.069504173312374, \"match_probability\": 0.9999999999982666, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1617.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4921.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24732333421707153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7526766657829285, \"precision\": 1.0, \"recall\": 0.24732333421707153, \"specificity\": 1.0, \"npv\": 0.9563121199607849, \"accuracy\": 0.9569304585456848, \"f1\": 0.3965665236051502, \"f2\": 0.2911520040332745, \"f0_5\": 0.6216361679224973, \"p4\": 0.5642565705337125, \"phi\": 0.48633146638481545}, {\"truth_threshold\": 39.09076497340938, \"match_probability\": 0.9999999999982919, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1615.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4923.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24701744318008423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7529825568199158, \"precision\": 1.0, \"recall\": 0.24701744318008423, \"specificity\": 1.0, \"npv\": 0.9562951922416687, \"accuracy\": 0.9569129347801208, \"f1\": 0.3961731877836379, \"f2\": 0.2908128353801275, \"f0_5\": 0.621249422988152, \"p4\": 0.5638568235037467, \"phi\": 0.4860263359966197}, {\"truth_threshold\": 39.10127121913103, \"match_probability\": 0.9999999999983044, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1614.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4924.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24686448276042938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7531355023384094, \"precision\": 1.0, \"recall\": 0.24686448276042938, \"specificity\": 1.0, \"npv\": 0.9562866687774658, \"accuracy\": 0.9569041728973389, \"f1\": 0.3959764474975466, \"f2\": 0.2906432327306778, \"f0_5\": 0.6210558719408958, \"p4\": 0.5636567926986084, \"phi\": 0.48587365829530355}, {\"truth_threshold\": 39.1158765309543, \"match_probability\": 0.9999999999983213, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1613.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4925.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24671153724193573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7532884478569031, \"precision\": 1.0, \"recall\": 0.24671153724193573, \"specificity\": 1.0, \"npv\": 0.9562782049179077, \"accuracy\": 0.9568954110145569, \"f1\": 0.3957796589375537, \"f2\": 0.29047361786421755, \"f0_5\": 0.6208622016936105, \"p4\": 0.5634566569210542, \"phi\": 0.4857209800426303}, {\"truth_threshold\": 39.11720944196828, \"match_probability\": 0.9999999999983229, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1612.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4926.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24655857682228088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7534413933753967, \"precision\": 1.0, \"recall\": 0.24655857682228088, \"specificity\": 1.0, \"npv\": 0.9562696814537048, \"accuracy\": 0.9568866491317749, \"f1\": 0.3955828220858896, \"f2\": 0.2903039907794266, \"f0_5\": 0.6206684121361467, \"p4\": 0.5632564160867373, \"phi\": 0.4855682117533373}, {\"truth_threshold\": 39.13846384864657, \"match_probability\": 0.9999999999983474, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1610.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4928.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24625267088413239, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7537473440170288, \"precision\": 1.0, \"recall\": 0.24625267088413239, \"specificity\": 1.0, \"npv\": 0.9562526941299438, \"accuracy\": 0.9568691849708557, \"f1\": 0.3951890034364261, \"f2\": 0.28996469994957136, \"f0_5\": 0.6202804746494067, \"p4\": 0.5628556189099762, \"phi\": 0.48526258380572657}, {\"truth_threshold\": 39.152178125037544, \"match_probability\": 0.9999999999983631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1609.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4929.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24609972536563873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7539002895355225, \"precision\": 1.0, \"recall\": 0.24609972536563873, \"specificity\": 1.0, \"npv\": 0.9562442302703857, \"accuracy\": 0.9568604230880737, \"f1\": 0.3949920216030441, \"f2\": 0.2897950362018659, \"f0_5\": 0.6200863264991522, \"p4\": 0.5626550623983857, \"phi\": 0.4851097240889044}, {\"truth_threshold\": 39.15217812503755, \"match_probability\": 0.9999999999983631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1608.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4930.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24594677984714508, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7540532350540161, \"precision\": 1.0, \"recall\": 0.24594677984714508, \"specificity\": 1.0, \"npv\": 0.9562357664108276, \"accuracy\": 0.9568516612052917, \"f1\": 0.39479499140682545, \"f2\": 0.2896253602305475, \"f0_5\": 0.6198920585967618, \"p4\": 0.5624544004917403, \"phi\": 0.484956818905479}, {\"truth_threshold\": 39.17029865844085, \"match_probability\": 0.9999999999983835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1606.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4932.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24564087390899658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7543591260910034, \"precision\": 1.0, \"recall\": 0.24564087390899658, \"specificity\": 1.0, \"npv\": 0.9562187790870667, \"accuracy\": 0.9568341374397278, \"f1\": 0.3944007858546169, \"f2\": 0.2892859716117876, \"f0_5\": 0.6195031630921154, \"p4\": 0.5620527601539935, \"phi\": 0.4846508271423346}, {\"truth_threshold\": 39.182768010403066, \"match_probability\": 0.9999999999983975, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1605.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4933.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24548791348934174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7545120716094971, \"precision\": 1.0, \"recall\": 0.24548791348934174, \"specificity\": 1.0, \"npv\": 0.9562102556228638, \"accuracy\": 0.9568253755569458, \"f1\": 0.3942036104629743, \"f2\": 0.28911625896170334, \"f0_5\": 0.6193085352677883, \"p4\": 0.5618517815530194, \"phi\": 0.4844977404487039}, {\"truth_threshold\": 39.18530695835168, \"match_probability\": 0.9999999999984003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1604.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4934.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24533496797084808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7546650171279907, \"precision\": 1.0, \"recall\": 0.24533496797084808, \"specificity\": 1.0, \"npv\": 0.9562017917633057, \"accuracy\": 0.9568166732788086, \"f1\": 0.3940063866371899, \"f2\": 0.28894653408272086, \"f0_5\": 0.6191137872471824, \"p4\": 0.561650697217244, \"phi\": 0.48434465293971884}, {\"truth_threshold\": 39.187520750053665, \"match_probability\": 0.9999999999984027, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1603.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4935.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24518200755119324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7548179626464844, \"precision\": 1.0, \"recall\": 0.24518200755119324, \"specificity\": 1.0, \"npv\": 0.9561933279037476, \"accuracy\": 0.9568079113960266, \"f1\": 0.3938091143594153, \"f2\": 0.28877679697351827, \"f0_5\": 0.6189189189189189, \"p4\": 0.561449507061503, \"phi\": 0.48419147488259523}, {\"truth_threshold\": 39.201131925513366, \"match_probability\": 0.9999999999984177, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1601.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4937.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24487610161304474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7551239132881165, \"precision\": 1.0, \"recall\": 0.24487610161304474, \"specificity\": 1.0, \"npv\": 0.9561763405799866, \"accuracy\": 0.9567903876304626, \"f1\": 0.393414424376459, \"f2\": 0.2884372860591648, \"f0_5\": 0.6185288208932159, \"p4\": 0.5610468089490083, \"phi\": 0.48388502635641084}, {\"truth_threshold\": 39.207672929104284, \"match_probability\": 0.9999999999984249, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1600.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4938.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2447231560945511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7552768588066101, \"precision\": 1.0, \"recall\": 0.2447231560945511, \"specificity\": 1.0, \"npv\": 0.9561678171157837, \"accuracy\": 0.9567816257476807, \"f1\": 0.393217006635537, \"f2\": 0.28826751225136926, \"f0_5\": 0.6183335909723295, \"p4\": 0.5608453008214676, \"phi\": 0.4837317558278637}, {\"truth_threshold\": 39.217696343706024, \"match_probability\": 0.9999999999984358, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1597.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4941.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24426430463790894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7557356953620911, \"precision\": 1.0, \"recall\": 0.24426430463790894, \"specificity\": 1.0, \"npv\": 0.9561423659324646, \"accuracy\": 0.9567553997039795, \"f1\": 0.3926244622003688, \"f2\": 0.28775811740963636, \"f0_5\": 0.617747176233947, \"p4\": 0.560240139127022, \"phi\": 0.48327162397745793}, {\"truth_threshold\": 39.22565587894044, \"match_probability\": 0.9999999999984444, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1594.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4944.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2438054382801056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.756194531917572, \"precision\": 1.0, \"recall\": 0.2438054382801056, \"specificity\": 1.0, \"npv\": 0.9561169147491455, \"accuracy\": 0.9567291140556335, \"f1\": 0.39203148057058534, \"f2\": 0.2872486124126, \"f0_5\": 0.6171596716741521, \"p4\": 0.5596340196638525, \"phi\": 0.4828110331591435}, {\"truth_threshold\": 39.22674148330903, \"match_probability\": 0.9999999999984456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1593.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4945.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24365249276161194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7563474774360657, \"precision\": 1.0, \"recall\": 0.24365249276161194, \"specificity\": 1.0, \"npv\": 0.9561084508895874, \"accuracy\": 0.9567203521728516, \"f1\": 0.3918337227893248, \"f2\": 0.2870787529284556, \"f0_5\": 0.6169635941130907, \"p4\": 0.5594317666042203, \"phi\": 0.482657440670257}, {\"truth_threshold\": 39.23094142679977, \"match_probability\": 0.9999999999984501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1592.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4946.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2434995472431183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7565004825592041, \"precision\": 1.0, \"recall\": 0.2434995472431183, \"specificity\": 1.0, \"npv\": 0.9560999274253845, \"accuracy\": 0.9567116498947144, \"f1\": 0.3916359163591636, \"f2\": 0.2869088811995386, \"f0_5\": 0.6167673950100728, \"p4\": 0.5592294067817485, \"phi\": 0.48250375699914116}, {\"truth_threshold\": 39.233463659564336, \"match_probability\": 0.9999999999984528, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1591.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4947.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24334658682346344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7566534280776978, \"precision\": 1.0, \"recall\": 0.24334658682346344, \"specificity\": 1.0, \"npv\": 0.9560914635658264, \"accuracy\": 0.9567028880119324, \"f1\": 0.39143806126214786, \"f2\": 0.2867389972245251, \"f0_5\": 0.6165710742520539, \"p4\": 0.5590269401101666, \"phi\": 0.4823500721234842}, {\"truth_threshold\": 39.237215794425445, \"match_probability\": 0.9999999999984568, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1590.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4948.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2431936413049698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7568063735961914, \"precision\": 1.0, \"recall\": 0.2431936413049698, \"specificity\": 1.0, \"npv\": 0.9560829997062683, \"accuracy\": 0.9566941261291504, \"f1\": 0.391240157480315, \"f2\": 0.2865691010020907, \"f0_5\": 0.6163746317258489, \"p4\": 0.5588243665031115, \"phi\": 0.4821963409950535}, {\"truth_threshold\": 39.24008297340092, \"match_probability\": 0.9999999999984599, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1589.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4949.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24304068088531494, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7569593191146851, \"precision\": 1.0, \"recall\": 0.24304068088531494, \"specificity\": 1.0, \"npv\": 0.9560744762420654, \"accuracy\": 0.9566853642463684, \"f1\": 0.39104220499569337, \"f2\": 0.28639919253091095, \"f0_5\": 0.6161780673181325, \"p4\": 0.5586216858741269, \"phi\": 0.4820425185097379}, {\"truth_threshold\": 39.24061608970513, \"match_probability\": 0.9999999999984605, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1588.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4950.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2428877353668213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7571122646331787, \"precision\": 1.0, \"recall\": 0.2428877353668213, \"specificity\": 1.0, \"npv\": 0.9560660123825073, \"accuracy\": 0.9566766023635864, \"f1\": 0.3908442037903027, \"f2\": 0.2862292718096611, \"f0_5\": 0.6159813809154383, \"p4\": 0.558418898136663, \"phi\": 0.4818886947287297}, {\"truth_threshold\": 39.27756722587802, \"match_probability\": 0.9999999999984994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1587.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4951.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24273477494716644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7572652101516724, \"precision\": 1.0, \"recall\": 0.24273477494716644, \"specificity\": 1.0, \"npv\": 0.9560574889183044, \"accuracy\": 0.9566678404808044, \"f1\": 0.39064615384615387, \"f2\": 0.28605933883701645, \"f0_5\": 0.6157845724041595, \"p4\": 0.5582160032040773, \"phi\": 0.48173477947397975}, {\"truth_threshold\": 39.27792868862532, \"match_probability\": 0.9999999999984998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1585.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4953.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24242888391017914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7575711011886597, \"precision\": 1.0, \"recall\": 0.24242888391017914, \"specificity\": 1.0, \"npv\": 0.9560405611991882, \"accuracy\": 0.9566503763198853, \"f1\": 0.39024990766958023, \"f2\": 0.28571943613224215, \"f0_5\": 0.6153905886007144, \"p4\": 0.557809891406501, \"phi\": 0.4814268546600492}, {\"truth_threshold\": 39.29424132990485, \"match_probability\": 0.9999999999985166, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1584.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4954.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2422759234905243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7577240467071533, \"precision\": 1.0, \"recall\": 0.2422759234905243, \"specificity\": 1.0, \"npv\": 0.9560320377349854, \"accuracy\": 0.9566416144371033, \"f1\": 0.3900517114011327, \"f2\": 0.28554946639746176, \"f0_5\": 0.6151934130806276, \"p4\": 0.557606674367757, \"phi\": 0.4812728450395843}, {\"truth_threshold\": 39.305601192069396, \"match_probability\": 0.9999999999985283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1583.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4955.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24212297797203064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7578770518302917, \"precision\": 1.0, \"recall\": 0.24212297797203064, \"specificity\": 1.0, \"npv\": 0.9560235738754272, \"accuracy\": 0.9566328525543213, \"f1\": 0.38985346632188156, \"f2\": 0.2853794844059852, \"f0_5\": 0.614996114996115, \"p4\": 0.5574033497863838, \"phi\": 0.48111878885455733}, {\"truth_threshold\": 39.307562708402685, \"match_probability\": 0.9999999999985303, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1581.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4957.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24181707203388214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.758182942867279, \"precision\": 1.0, \"recall\": 0.24181707203388214, \"specificity\": 1.0, \"npv\": 0.9560065865516663, \"accuracy\": 0.9566153287887573, \"f1\": 0.389456829658825, \"f2\": 0.28503948364764, \"f0_5\": 0.6146011506764111, \"p4\": 0.5569963776472102, \"phi\": 0.4808104914394336}, {\"truth_threshold\": 39.30823142796631, \"match_probability\": 0.999999999998531, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1579.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4959.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24151116609573364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7584888339042664, \"precision\": 1.0, \"recall\": 0.24151116609573364, \"specificity\": 1.0, \"npv\": 0.95598965883255, \"accuracy\": 0.9565978646278381, \"f1\": 0.3890599975360355, \"f2\": 0.2846994338465977, \"f0_5\": 0.6142056947253773, \"p4\": 0.5565889742909593, \"phi\": 0.4805020071709302}, {\"truth_threshold\": 39.320528021425126, \"match_probability\": 0.9999999999985434, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1578.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4960.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24135822057724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.75864177942276, \"precision\": 1.0, \"recall\": 0.24135822057724, \"specificity\": 1.0, \"npv\": 0.9559811353683472, \"accuracy\": 0.9565891027450562, \"f1\": 0.38886150813208475, \"f2\": 0.28452939055174903, \"f0_5\": 0.6140077821011674, \"p4\": 0.5563851106878857, \"phi\": 0.48034767224680874}, {\"truth_threshold\": 39.33306233846972, \"match_probability\": 0.999999999998556, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1576.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4962.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2410523146390915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7589476704597473, \"precision\": 1.0, \"recall\": 0.2410523146390915, \"specificity\": 1.0, \"npv\": 0.955964207649231, \"accuracy\": 0.9565715789794922, \"f1\": 0.38846438254868126, \"f2\": 0.28418926716676285, \"f0_5\": 0.6136115869802211, \"p4\": 0.5559770591939265, \"phi\": 0.4800389522500691}, {\"truth_threshold\": 39.34894087698427, \"match_probability\": 0.9999999999985718, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1575.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4963.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24089935421943665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.759100615978241, \"precision\": 1.0, \"recall\": 0.24089935421943665, \"specificity\": 1.0, \"npv\": 0.9559556841850281, \"accuracy\": 0.9565628170967102, \"f1\": 0.3882657463330457, \"f2\": 0.2840191870739712, \"f0_5\": 0.6134133042529989, \"p4\": 0.5557728711275904, \"phi\": 0.4798844766298499}, {\"truth_threshold\": 39.37370432296707, \"match_probability\": 0.9999999999985961, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1574.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4964.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.240746408700943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7592536211013794, \"precision\": 1.0, \"recall\": 0.240746408700943, \"specificity\": 1.0, \"npv\": 0.95594722032547, \"accuracy\": 0.9565540552139282, \"f1\": 0.3880670611439842, \"f2\": 0.28384909471254416, \"f0_5\": 0.6132148979273804, \"p4\": 0.5555685747312249, \"phi\": 0.4797299992817237}, {\"truth_threshold\": 39.390749310758196, \"match_probability\": 0.9999999999986126, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1573.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4965.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.24059344828128815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.759406566619873, \"precision\": 1.0, \"recall\": 0.24059344828128815, \"specificity\": 1.0, \"npv\": 0.9559387564659119, \"accuracy\": 0.956545352935791, \"f1\": 0.3878683269633831, \"f2\": 0.2836789900811542, \"f0_5\": 0.613016367887763, \"p4\": 0.555364169916867, \"phi\": 0.4795754296324335}, {\"truth_threshold\": 39.404109467936905, \"match_probability\": 0.9999999999986254, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1570.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4968.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.240134596824646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.759865403175354, \"precision\": 1.0, \"recall\": 0.240134596824646, \"specificity\": 1.0, \"npv\": 0.9559133052825928, \"accuracy\": 0.9565190672874451, \"f1\": 0.38727183029107054, \"f2\": 0.2831686025539283, \"f0_5\": 0.6124200343267281, \"p4\": 0.5547503040847828, \"phi\": 0.479111528617839}, {\"truth_threshold\": 39.41049950857975, \"match_probability\": 0.9999999999986314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1569.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4969.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23998165130615234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7600183486938477, \"precision\": 1.0, \"recall\": 0.23998165130615234, \"specificity\": 1.0, \"npv\": 0.9559047818183899, \"accuracy\": 0.9565103054046631, \"f1\": 0.38707289996299493, \"f2\": 0.28299844882940733, \"f0_5\": 0.6122210082722023, \"p4\": 0.5545454647169216, \"phi\": 0.4789567703630791}, {\"truth_threshold\": 39.41677304485896, \"match_probability\": 0.9999999999986374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1568.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4970.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2398286908864975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7601712942123413, \"precision\": 1.0, \"recall\": 0.2398286908864975, \"specificity\": 1.0, \"npv\": 0.9558963179588318, \"accuracy\": 0.9565015435218811, \"f1\": 0.38687392055267705, \"f2\": 0.2828282828282828, \"f0_5\": 0.6120218579234973, \"p4\": 0.5543405164898231, \"phi\": 0.4788020101916684}, {\"truth_threshold\": 39.41823104906682, \"match_probability\": 0.9999999999986388, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1566.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4972.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.239522784948349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7604771852493286, \"precision\": 1.0, \"recall\": 0.239522784948349, \"specificity\": 1.0, \"npv\": 0.9558793306350708, \"accuracy\": 0.9564840793609619, \"f1\": 0.38647581441263573, \"f2\": 0.28248791399090845, \"f0_5\": 0.6116231838775191, \"p4\": 0.553930293103674, \"phi\": 0.47849230254697855}, {\"truth_threshold\": 39.421261885034696, \"match_probability\": 0.9999999999986416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1564.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4974.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2392168790102005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7607831358909607, \"precision\": 1.0, \"recall\": 0.2392168790102005, \"specificity\": 1.0, \"npv\": 0.9558624029159546, \"accuracy\": 0.956466555595398, \"f1\": 0.38607751172549987, \"f2\": 0.28214749603117334, \"f0_5\": 0.6112240112552759, \"p4\": 0.5535196332168936, \"phi\": 0.478182405315526}, {\"truth_threshold\": 39.44970385391919, \"match_probability\": 0.9999999999986682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1563.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4975.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23906393349170685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7609360814094543, \"precision\": 1.0, \"recall\": 0.23906393349170685, \"specificity\": 1.0, \"npv\": 0.9558538794517517, \"accuracy\": 0.956457793712616, \"f1\": 0.3858782866312801, \"f2\": 0.28197726862709727, \"f0_5\": 0.6110242376856919, \"p4\": 0.553314139363645, \"phi\": 0.4780274082032535}, {\"truth_threshold\": 39.452580948867926, \"match_probability\": 0.9999999999986708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1562.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4976.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2389109879732132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.761089026927948, \"precision\": 1.0, \"recall\": 0.2389109879732132, \"specificity\": 1.0, \"npv\": 0.9558454155921936, \"accuracy\": 0.956449031829834, \"f1\": 0.38567901234567903, \"f2\": 0.28180702893844267, \"f0_5\": 0.6108243391209135, \"p4\": 0.5531085361184996, \"phi\": 0.4778723181278872}, {\"truth_threshold\": 39.472089107757135, \"match_probability\": 0.9999999999986886, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1561.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4977.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23875802755355835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7612419724464417, \"precision\": 1.0, \"recall\": 0.23875802755355835, \"specificity\": 1.0, \"npv\": 0.9558369517326355, \"accuracy\": 0.9564403295516968, \"f1\": 0.38547968885047534, \"f2\": 0.2816367769638798, \"f0_5\": 0.6106243154435925, \"p4\": 0.5529028233923432, \"phi\": 0.4777172259129618}, {\"truth_threshold\": 39.480619526883586, \"match_probability\": 0.9999999999986964, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1560.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4978.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2386050820350647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7613949179649353, \"precision\": 1.0, \"recall\": 0.2386050820350647, \"specificity\": 1.0, \"npv\": 0.9558284878730774, \"accuracy\": 0.9564315676689148, \"f1\": 0.38528031612743885, \"f2\": 0.2814665127020785, \"f0_5\": 0.6104241665362341, \"p4\": 0.552697001095965, \"phi\": 0.47756204061345253}, {\"truth_threshold\": 39.48164341447039, \"match_probability\": 0.9999999999986973, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1556.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4982.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2379932701587677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7620067596435547, \"precision\": 1.0, \"recall\": 0.2379932701587677, \"specificity\": 1.0, \"npv\": 0.9557945132255554, \"accuracy\": 0.9563965201377869, \"f1\": 0.3844823325920435, \"f2\": 0.2807853327558828, \"f0_5\": 0.6096223162513713, \"p4\": 0.5518726144206185, \"phi\": 0.47694095864422736}, {\"truth_threshold\": 39.51792936749406, \"match_probability\": 0.9999999999987297, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1555.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4983.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23784032464027405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7621597051620483, \"precision\": 1.0, \"recall\": 0.23784032464027405, \"specificity\": 1.0, \"npv\": 0.9557860493659973, \"accuracy\": 0.9563878178596497, \"f1\": 0.3842827134560732, \"f2\": 0.28061500703793263, \"f0_5\": 0.6094215394262423, \"p4\": 0.5516662429315692, \"phi\": 0.4767855344761788}, {\"truth_threshold\": 39.52244935250436, \"match_probability\": 0.9999999999987337, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1552.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4986.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2373814582824707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7626185417175293, \"precision\": 1.0, \"recall\": 0.2373814582824707, \"specificity\": 1.0, \"npv\": 0.9557605981826782, \"accuracy\": 0.9563615322113037, \"f1\": 0.38368355995055625, \"f2\": 0.28010395610742134, \"f0_5\": 0.6088184528479523, \"p4\": 0.5510464674595875, \"phi\": 0.4763190654200156}, {\"truth_threshold\": 39.52891459955274, \"match_probability\": 0.9999999999987393, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1551.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4987.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23722851276397705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.762771487236023, \"precision\": 1.0, \"recall\": 0.23722851276397705, \"specificity\": 1.0, \"npv\": 0.9557521343231201, \"accuracy\": 0.9563527703285217, \"f1\": 0.3834837433551737, \"f2\": 0.279933581200592, \"f0_5\": 0.608617171558625, \"p4\": 0.5508396550006819, \"phi\": 0.4761634949084753}, {\"truth_threshold\": 39.552631992646994, \"match_probability\": 0.9999999999987599, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1549.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4989.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23692260682582855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7630773782730103, \"precision\": 1.0, \"recall\": 0.23692260682582855, \"specificity\": 1.0, \"npv\": 0.9557351469993591, \"accuracy\": 0.9563353061676025, \"f1\": 0.38308396191418326, \"f2\": 0.27959279448395363, \"f0_5\": 0.6082142296214857, \"p4\": 0.5504256985895327, \"phi\": 0.47585216396205376}, {\"truth_threshold\": 39.556427341100324, \"match_probability\": 0.9999999999987631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1548.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4990.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2367696613073349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7632303237915039, \"precision\": 1.0, \"recall\": 0.2367696613073349, \"specificity\": 1.0, \"npv\": 0.955726683139801, \"accuracy\": 0.9563265442848206, \"f1\": 0.382883997031907, \"f2\": 0.2794223826714801, \"f0_5\": 0.608012568735271, \"p4\": 0.5502185544566219, \"phi\": 0.475696403403536}, {\"truth_threshold\": 39.562011068288285, \"match_probability\": 0.9999999999987679, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1546.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4992.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2364637553691864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.763536274433136, \"precision\": 1.0, \"recall\": 0.2364637553691864, \"specificity\": 1.0, \"npv\": 0.9557097554206848, \"accuracy\": 0.9563090205192566, \"f1\": 0.38248391885205346, \"f2\": 0.27908152213156184, \"f0_5\": 0.6076088665304198, \"p4\": 0.5498039338837206, \"phi\": 0.4753847831528355}, {\"truth_threshold\": 39.565122936830186, \"match_probability\": 0.9999999999987705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1545.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4993.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23631079494953156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7636892199516296, \"precision\": 1.0, \"recall\": 0.23631079494953156, \"specificity\": 1.0, \"npv\": 0.9557012319564819, \"accuracy\": 0.9563002586364746, \"f1\": 0.3822838055177533, \"f2\": 0.27891107340145144, \"f0_5\": 0.60740682497248, \"p4\": 0.5495964572624713, \"phi\": 0.4752289233946897}, {\"truth_threshold\": 39.56852437524696, \"match_probability\": 0.9999999999987734, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1542.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4996.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2358519434928894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7641480565071106, \"precision\": 1.0, \"recall\": 0.2358519434928894, \"specificity\": 1.0, \"npv\": 0.9556758403778076, \"accuracy\": 0.9562740325927734, \"f1\": 0.3816831683168317, \"f2\": 0.2783996533545172, \"f0_5\": 0.60679993703762, \"p4\": 0.5489733609698978, \"phi\": 0.47476100799685855}, {\"truth_threshold\": 39.579222925739124, \"match_probability\": 0.9999999999987825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1541.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4997.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23569898307323456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7643010020256042, \"precision\": 1.0, \"recall\": 0.23569898307323456, \"specificity\": 1.0, \"npv\": 0.9556673169136047, \"accuracy\": 0.9562652707099915, \"f1\": 0.38148285678920657, \"f2\": 0.27822915538222653, \"f0_5\": 0.6065973862383877, \"p4\": 0.5487654397595113, \"phi\": 0.47460490872396505}, {\"truth_threshold\": 39.579755577456176, \"match_probability\": 0.999999999998783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1540.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 4998.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2355460375547409, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7644539475440979, \"precision\": 1.0, \"recall\": 0.2355460375547409, \"specificity\": 1.0, \"npv\": 0.9556588530540466, \"accuracy\": 0.9562565088272095, \"f1\": 0.38128249566724437, \"f2\": 0.2780586450960566, \"f0_5\": 0.6063947078280044, \"p4\": 0.5485574071741519, \"phi\": 0.4744488066247682}, {\"truth_threshold\": 39.58219143619625, \"match_probability\": 0.999999999998785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1537.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5001.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23508718609809875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7649128437042236, \"precision\": 1.0, \"recall\": 0.23508718609809875, \"specificity\": 1.0, \"npv\": 0.9556334018707275, \"accuracy\": 0.9562302231788635, \"f1\": 0.3806811145510836, \"f2\": 0.2775470403409296, \"f0_5\": 0.6057859057228441, \"p4\": 0.5479326402549932, \"phi\": 0.47398011688773656}, {\"truth_threshold\": 39.59609674430352, \"match_probability\": 0.9999999999987966, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1536.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5002.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2349342256784439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7650657892227173, \"precision\": 1.0, \"recall\": 0.2349342256784439, \"specificity\": 1.0, \"npv\": 0.9556249380111694, \"accuracy\": 0.9562215209007263, \"f1\": 0.38048055486747584, \"f2\": 0.27737648078590005, \"f0_5\": 0.6055827156599906, \"p4\": 0.547724161256, \"phi\": 0.4738238200457326}, {\"truth_threshold\": 39.611975282818065, \"match_probability\": 0.9999999999988098, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1533.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5005.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23447537422180176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7655246257781982, \"precision\": 1.0, \"recall\": 0.23447537422180176, \"specificity\": 1.0, \"npv\": 0.9555995464324951, \"accuracy\": 0.9561952352523804, \"f1\": 0.3798785776235906, \"f2\": 0.27686472819216185, \"f0_5\": 0.6049723756906077, \"p4\": 0.5470980528977587, \"phi\": 0.4733545906678944}, {\"truth_threshold\": 39.61967769015942, \"match_probability\": 0.9999999999988162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1530.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5008.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2340165227651596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7659834623336792, \"precision\": 1.0, \"recall\": 0.2340165227651596, \"specificity\": 1.0, \"npv\": 0.955574095249176, \"accuracy\": 0.9561690092086792, \"f1\": 0.37927615270203274, \"f2\": 0.2763528646774077, \"f0_5\": 0.6043608784958129, \"p4\": 0.5464709355671947, \"phi\": 0.4728848747921882}, {\"truth_threshold\": 39.61970978249746, \"match_probability\": 0.9999999999988162, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1529.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5009.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23386356234550476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7661364078521729, \"precision\": 1.0, \"recall\": 0.23386356234550476, \"specificity\": 1.0, \"npv\": 0.9555656313896179, \"accuracy\": 0.9561602473258972, \"f1\": 0.37907524482459404, \"f2\": 0.27618221885047506, \"f0_5\": 0.6041567883673147, \"p4\": 0.5462616718110106, \"phi\": 0.47272823529324726}, {\"truth_threshold\": 39.62610931336996, \"match_probability\": 0.9999999999988214, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1528.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5010.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2337106168270111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7662894129753113, \"precision\": 1.0, \"recall\": 0.2337106168270111, \"specificity\": 1.0, \"npv\": 0.955557107925415, \"accuracy\": 0.9561514854431152, \"f1\": 0.3788742871311679, \"f2\": 0.27601156069364163, \"f0_5\": 0.6039525691699604, \"p4\": 0.5460522955779473, \"phi\": 0.4725715007167222}, {\"truth_threshold\": 39.626332917834446, \"match_probability\": 0.9999999999988216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1526.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5012.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2334047108888626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7665953040122986, \"precision\": 1.0, \"recall\": 0.2334047108888626, \"specificity\": 1.0, \"npv\": 0.9555401802062988, \"accuracy\": 0.9561339616775513, \"f1\": 0.3784722222222222, \"f2\": 0.27567020738492665, \"f0_5\": 0.6035437430786268, \"p4\": 0.5456332053111609, \"phi\": 0.47225797579516066}, {\"truth_threshold\": 39.6285182219959, \"match_probability\": 0.9999999999988234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1525.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5013.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23325176537036896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7667482495307922, \"precision\": 1.0, \"recall\": 0.23325176537036896, \"specificity\": 1.0, \"npv\": 0.9555317163467407, \"accuracy\": 0.9561251997947693, \"f1\": 0.3782711149696143, \"f2\": 0.2754995122303718, \"f0_5\": 0.6033391359392309, \"p4\": 0.5454234910921725, \"phi\": 0.4721010934462608}, {\"truth_threshold\": 39.63829768119088, \"match_probability\": 0.9999999999988314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1522.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5016.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2327928990125656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7672070860862732, \"precision\": 1.0, \"recall\": 0.2327928990125656, \"specificity\": 1.0, \"npv\": 0.9555062651634216, \"accuracy\": 0.9560989737510681, \"f1\": 0.37766749379652603, \"f2\": 0.2749873527498735, \"f0_5\": 0.6027245366703627, \"p4\": 0.544793670979102, \"phi\": 0.47163024206210924}, {\"truth_threshold\": 39.63916546619541, \"match_probability\": 0.999999999998832, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1520.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5018.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23248699307441711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7675129771232605, \"precision\": 1.0, \"recall\": 0.23248699307441711, \"specificity\": 1.0, \"npv\": 0.9554893374443054, \"accuracy\": 0.9560814499855042, \"f1\": 0.37726482998262595, \"f2\": 0.2746458514021394, \"f0_5\": 0.602314154382628, \"p4\": 0.5443732254268241, \"phi\": 0.471316078398921}, {\"truth_threshold\": 39.651517109620045, \"match_probability\": 0.999999999998842, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1519.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5019.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23233404755592346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7676659822463989, \"precision\": 1.0, \"recall\": 0.23233404755592346, \"specificity\": 1.0, \"npv\": 0.9554808735847473, \"accuracy\": 0.9560726881027222, \"f1\": 0.37706342311033886, \"f2\": 0.27447508221603845, \"f0_5\": 0.602108768035516, \"p4\": 0.5441628327280367, \"phi\": 0.47115894523079266}, {\"truth_threshold\": 39.6537954585127, \"match_probability\": 0.9999999999988438, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1517.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5021.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23202814161777496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7679718732833862, \"precision\": 1.0, \"recall\": 0.23202814161777496, \"specificity\": 1.0, \"npv\": 0.9554638862609863, \"accuracy\": 0.956055223941803, \"f1\": 0.3766604593420236, \"f2\": 0.27413350681267845, \"f0_5\": 0.6016976043154053, \"p4\": 0.543741707018175, \"phi\": 0.47084448384378114}, {\"truth_threshold\": 39.654254249272846, \"match_probability\": 0.9999999999988443, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1514.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5024.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2315692901611328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7684307098388672, \"precision\": 1.0, \"recall\": 0.2315692901611328, \"specificity\": 1.0, \"npv\": 0.955438494682312, \"accuracy\": 0.956028938293457, \"f1\": 0.3760556383507203, \"f2\": 0.2736210511096653, \"f0_5\": 0.6010798793076068, \"p4\": 0.5431091662686147, \"phi\": 0.4703723954572603}, {\"truth_threshold\": 39.662015965317664, \"match_probability\": 0.9999999999988504, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1512.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5026.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23126338422298431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7687366008758545, \"precision\": 1.0, \"recall\": 0.23126338422298431, \"specificity\": 1.0, \"npv\": 0.955421507358551, \"accuracy\": 0.9560114741325378, \"f1\": 0.37565217391304345, \"f2\": 0.2732793522267207, \"f0_5\": 0.6006674082313682, \"p4\": 0.5426869032179523, \"phi\": 0.4700574820050587}, {\"truth_threshold\": 39.66975046499705, \"match_probability\": 0.9999999999988566, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1511.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5027.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23111043870449066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7688895463943481, \"precision\": 1.0, \"recall\": 0.23111043870449066, \"specificity\": 1.0, \"npv\": 0.9554130434989929, \"accuracy\": 0.9560027122497559, \"f1\": 0.3754503665051559, \"f2\": 0.2731084842569497, \"f0_5\": 0.6004609759974567, \"p4\": 0.5424756006452864, \"phi\": 0.4698999041370351}, {\"truth_threshold\": 39.67712796234332, \"match_probability\": 0.9999999999988624, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1508.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5030.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23065157234668732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7693484425544739, \"precision\": 1.0, \"recall\": 0.23065157234668732, \"specificity\": 1.0, \"npv\": 0.9553876519203186, \"accuracy\": 0.9559764266014099, \"f1\": 0.37484464330101913, \"f2\": 0.2725958062183659, \"f0_5\": 0.5998408910103421, \"p4\": 0.541841007606962, \"phi\": 0.469426962423216}, {\"truth_threshold\": 39.680267669873885, \"match_probability\": 0.9999999999988649, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1507.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5031.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.23049862682819366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7695013880729675, \"precision\": 1.0, \"recall\": 0.23049862682819366, \"specificity\": 1.0, \"npv\": 0.9553791284561157, \"accuracy\": 0.9559676647186279, \"f1\": 0.37464263517712865, \"f2\": 0.2724248888246141, \"f0_5\": 0.5996339328346332, \"p4\": 0.5416292478393087, \"phi\": 0.4692691840270467}, {\"truth_threshold\": 39.682234666492704, \"match_probability\": 0.9999999999988665, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1498.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5040.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22912205755710602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7708779573440552, \"precision\": 1.0, \"recall\": 0.22912205755710602, \"specificity\": 1.0, \"npv\": 0.955302894115448, \"accuracy\": 0.9558889269828796, \"f1\": 0.37282229965156793, \"f2\": 0.2708860759493671, \"f0_5\": 0.5977653631284916, \"p4\": 0.5397182444604456, \"phi\": 0.46784714231229374}, {\"truth_threshold\": 39.684001592666895, \"match_probability\": 0.9999999999988678, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1496.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5042.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22881615161895752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7711838483810425, \"precision\": 1.0, \"recall\": 0.22881615161895752, \"specificity\": 1.0, \"npv\": 0.9552859663963318, \"accuracy\": 0.9558714032173157, \"f1\": 0.37241722678615885, \"f2\": 0.27054398148148145, \"f0_5\": 0.5973486663472288, \"p4\": 0.539292310184166, \"phi\": 0.46753057139553006}, {\"truth_threshold\": 39.69116291408034, \"match_probability\": 0.9999999999988733, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1489.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5049.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22774548828601837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7722545266151428, \"precision\": 1.0, \"recall\": 0.22774548828601837, \"specificity\": 1.0, \"npv\": 0.9552266597747803, \"accuracy\": 0.9558101296424866, \"f1\": 0.3709978821477513, \"f2\": 0.26934626098911035, \"f0_5\": 0.5958860252921402, \"p4\": 0.537797894309029, \"phi\": 0.46642099306783197}, {\"truth_threshold\": 39.69361325021778, \"match_probability\": 0.9999999999988753, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1487.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5051.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22743958234786987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7725604176521301, \"precision\": 1.0, \"recall\": 0.22743958234786987, \"specificity\": 1.0, \"npv\": 0.9552097320556641, \"accuracy\": 0.9557926654815674, \"f1\": 0.3705919003115265, \"f2\": 0.2690039437027389, \"f0_5\": 0.5954669229537082, \"p4\": 0.5373698734814, \"phi\": 0.466103550790016}, {\"truth_threshold\": 39.69665123471202, \"match_probability\": 0.9999999999988777, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1482.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5056.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22667482495307922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7733252048492432, \"precision\": 1.0, \"recall\": 0.22667482495307922, \"specificity\": 1.0, \"npv\": 0.9551673531532288, \"accuracy\": 0.9557488560676575, \"f1\": 0.36957605985037406, \"f2\": 0.26814793370485634, \"f0_5\": 0.5944168137333548, \"p4\": 0.5362977818408357, \"phi\": 0.4653089070775448}, {\"truth_threshold\": 39.705375243459464, \"match_probability\": 0.9999999999988844, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1480.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5058.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22636891901493073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7736310958862305, \"precision\": 1.0, \"recall\": 0.22636891901493073, \"specificity\": 1.0, \"npv\": 0.9551504254341125, \"accuracy\": 0.9557313919067383, \"f1\": 0.36916936891993013, \"f2\": 0.2678054429646786, \"f0_5\": 0.5939958259752769, \"p4\": 0.5358681273174103, \"phi\": 0.46499074511195726}, {\"truth_threshold\": 39.72707031455878, \"match_probability\": 0.9999999999989011, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1478.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5060.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22606301307678223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7739369869232178, \"precision\": 1.0, \"recall\": 0.22606301307678223, \"specificity\": 1.0, \"npv\": 0.9551334977149963, \"accuracy\": 0.9557138681411743, \"f1\": 0.3687624750499002, \"f2\": 0.26746290264205574, \"f0_5\": 0.593574297188755, \"p4\": 0.5354380042728246, \"phi\": 0.4646723298982273}, {\"truth_threshold\": 39.734019264816155, \"match_probability\": 0.9999999999989064, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1477.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5061.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22591006755828857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7740899324417114, \"precision\": 1.0, \"recall\": 0.22591006755828857, \"specificity\": 1.0, \"npv\": 0.9551250338554382, \"accuracy\": 0.9557051062583923, \"f1\": 0.3685589519650655, \"f2\": 0.2672916138839625, \"f0_5\": 0.593363329583802, \"p4\": 0.535222766810988, \"phi\": 0.4645130213219435}, {\"truth_threshold\": 39.734715453896264, \"match_probability\": 0.9999999999989069, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1475.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5063.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22560416162014008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7743958234786987, \"precision\": 1.0, \"recall\": 0.22560416162014008, \"specificity\": 1.0, \"npv\": 0.955108106136322, \"accuracy\": 0.9556876420974731, \"f1\": 0.3681517534007238, \"f2\": 0.2669489991674811, \"f0_5\": 0.5929409872969931, \"p4\": 0.5347919395190602, \"phi\": 0.4641942953757909}, {\"truth_threshold\": 39.735803869670924, \"match_probability\": 0.9999999999989078, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1474.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5064.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22545120120048523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7745487689971924, \"precision\": 1.0, \"recall\": 0.22545120120048523, \"specificity\": 1.0, \"npv\": 0.9550996422767639, \"accuracy\": 0.9556788802146912, \"f1\": 0.36794807788317524, \"f2\": 0.2667776732063998, \"f0_5\": 0.5927296123532251, \"p4\": 0.5345763494929757, \"phi\": 0.4640348779302161}, {\"truth_threshold\": 39.74170030687607, \"match_probability\": 0.9999999999989122, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1471.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5067.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22499234974384308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7750076651573181, \"precision\": 1.0, \"recall\": 0.22499234974384308, \"specificity\": 1.0, \"npv\": 0.9550741910934448, \"accuracy\": 0.9556525945663452, \"f1\": 0.3673367461605694, \"f2\": 0.26626362089563044, \"f0_5\": 0.5920946707454516, \"p4\": 0.5339288727159893, \"phi\": 0.4635562668248797}, {\"truth_threshold\": 39.753319390142906, \"match_probability\": 0.9999999999989209, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1468.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5070.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22453349828720093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7754665017127991, \"precision\": 1.0, \"recall\": 0.22453349828720093, \"specificity\": 1.0, \"npv\": 0.9550487995147705, \"accuracy\": 0.955626368522644, \"f1\": 0.3667249562827879, \"f2\": 0.2657494569152788, \"f0_5\": 0.5914585012087027, \"p4\": 0.5332803338237968, \"phi\": 0.4630771396987955}, {\"truth_threshold\": 39.75672599158615, \"match_probability\": 0.9999999999989234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1465.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5073.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22407464683055878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.77592533826828, \"precision\": 1.0, \"recall\": 0.22407464683055878, \"specificity\": 1.0, \"npv\": 0.9550234079360962, \"accuracy\": 0.9556000828742981, \"f1\": 0.36611270773459953, \"f2\": 0.2652351812289532, \"f0_5\": 0.5908211001774479, \"p4\": 0.5326307301512808, \"phi\": 0.46259758875474266}, {\"truth_threshold\": 39.75852394617101, \"match_probability\": 0.9999999999989247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1463.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5075.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22376874089241028, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7762312889099121, \"precision\": 1.0, \"recall\": 0.22376874089241028, \"specificity\": 1.0, \"npv\": 0.95500648021698, \"accuracy\": 0.9555826187133789, \"f1\": 0.3657042869641295, \"f2\": 0.26489226869455007, \"f0_5\": 0.5903954802259888, \"p4\": 0.532197068171501, \"phi\": 0.46227761029782105}, {\"truth_threshold\": 39.759239407323335, \"match_probability\": 0.9999999999989253, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1460.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5078.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22330987453460693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7766901254653931, \"precision\": 1.0, \"recall\": 0.22330987453460693, \"specificity\": 1.0, \"npv\": 0.9549810886383057, \"accuracy\": 0.955556333065033, \"f1\": 0.3650912728182045, \"f2\": 0.2643778067506881, \"f0_5\": 0.589756018742931, \"p4\": 0.5315456839183799, \"phi\": 0.4617972716976509}, {\"truth_threshold\": 39.7624178622755, \"match_probability\": 0.9999999999989277, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1459.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5079.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22315692901611328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7768430709838867, \"precision\": 1.0, \"recall\": 0.22315692901611328, \"specificity\": 1.0, \"npv\": 0.9549726247787476, \"accuracy\": 0.955547571182251, \"f1\": 0.3648868325622108, \"f2\": 0.26420629459273476, \"f0_5\": 0.5895425893001455, \"p4\": 0.5313283177601612, \"phi\": 0.461637022116013}, {\"truth_threshold\": 39.76846721643886, \"match_probability\": 0.9999999999989322, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1458.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5080.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22300398349761963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7769960165023804, \"precision\": 1.0, \"recall\": 0.22300398349761963, \"specificity\": 1.0, \"npv\": 0.9549641609191895, \"accuracy\": 0.955538809299469, \"f1\": 0.3646823411705853, \"f2\": 0.2640347700108656, \"f0_5\": 0.5893290218270008, \"p4\": 0.5311108323987549, \"phi\": 0.4614767667431188}, {\"truth_threshold\": 39.77617367323342, \"match_probability\": 0.9999999999989378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1457.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5081.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22285102307796478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.777148962020874, \"precision\": 1.0, \"recall\": 0.22285102307796478, \"specificity\": 1.0, \"npv\": 0.9549556970596313, \"accuracy\": 0.955530047416687, \"f1\": 0.3644777986241401, \"f2\": 0.26386323300373066, \"f0_5\": 0.589115316189552, \"p4\": 0.5308932277342346, \"phi\": 0.46131641151333197}, {\"truth_threshold\": 39.788472938183865, \"match_probability\": 0.9999999999989468, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1456.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5082.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22269807755947113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7773019075393677, \"precision\": 1.0, \"recall\": 0.22269807755947113, \"specificity\": 1.0, \"npv\": 0.9549472332000732, \"accuracy\": 0.9555213451385498, \"f1\": 0.36427320490367776, \"f2\": 0.26369168356997974, \"f0_5\": 0.5889014722536806, \"p4\": 0.5306755036665624, \"phi\": 0.4611560504138265}, {\"truth_threshold\": 39.80352020306509, \"match_probability\": 0.9999999999989578, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1455.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5083.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22254511713981628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7774548530578613, \"precision\": 1.0, \"recall\": 0.22254511713981628, \"specificity\": 1.0, \"npv\": 0.9549387693405151, \"accuracy\": 0.9555125832557678, \"f1\": 0.36406855998999127, \"f2\": 0.2635201217082624, \"f0_5\": 0.5886874898850947, \"p4\": 0.5304576600955881, \"phi\": 0.4609956363761215}, {\"truth_threshold\": 39.805680149255146, \"match_probability\": 0.9999999999989594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1453.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5085.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22223921120166779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7777608036994934, \"precision\": 1.0, \"recall\": 0.22223921120166779, \"specificity\": 1.0, \"npv\": 0.9549217820167542, \"accuracy\": 0.9554950594902039, \"f1\": 0.3636591165060693, \"f2\": 0.26317696069552615, \"f0_5\": 0.5882591093117409, \"p4\": 0.5300216140425743, \"phi\": 0.46067460217158973}, {\"truth_threshold\": 39.80953247475075, \"match_probability\": 0.9999999999989622, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1452.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5086.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22208626568317413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7779137492179871, \"precision\": 1.0, \"recall\": 0.22208626568317413, \"specificity\": 1.0, \"npv\": 0.954913318157196, \"accuracy\": 0.9554862976074219, \"f1\": 0.3634543178973717, \"f2\": 0.26300536154180554, \"f0_5\": 0.5880447108375182, \"p4\": 0.5298034113596742, \"phi\": 0.46051398186175035}, {\"truth_threshold\": 39.81016218619635, \"match_probability\": 0.9999999999989626, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1449.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5089.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22162741422653198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.778372585773468, \"precision\": 1.0, \"recall\": 0.22162741422653198, \"specificity\": 1.0, \"npv\": 0.9548879265785217, \"accuracy\": 0.9554600715637207, \"f1\": 0.3628396143733567, \"f2\": 0.262490489475019, \"f0_5\": 0.5874006810442679, \"p4\": 0.5291480834778763, \"phi\": 0.46003189586960896}, {\"truth_threshold\": 39.82167426559915, \"match_probability\": 0.9999999999989708, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1445.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5093.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22101560235023499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7789844274520874, \"precision\": 1.0, \"recall\": 0.22101560235023499, \"specificity\": 1.0, \"npv\": 0.9548540711402893, \"accuracy\": 0.9554250240325928, \"f1\": 0.3620192909933609, \"f2\": 0.2618038192557162, \"f0_5\": 0.5865400227309628, \"p4\": 0.5282726295909772, \"phi\": 0.4593883360643883}, {\"truth_threshold\": 39.827746282266325, \"match_probability\": 0.9999999999989752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1444.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5094.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.22086264193058014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.779137372970581, \"precision\": 1.0, \"recall\": 0.22086264193058014, \"specificity\": 1.0, \"npv\": 0.9548456072807312, \"accuracy\": 0.9554163217544556, \"f1\": 0.36181408168378854, \"f2\": 0.261632120597188, \"f0_5\": 0.5863245086892968, \"p4\": 0.5280534648416424, \"phi\": 0.45922733595105436}, {\"truth_threshold\": 39.830188153527175, \"match_probability\": 0.9999999999989769, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1443.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5095.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2207096964120865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7792903184890747, \"precision\": 1.0, \"recall\": 0.2207096964120865, \"specificity\": 1.0, \"npv\": 0.9548371434211731, \"accuracy\": 0.9554075598716736, \"f1\": 0.36160882094975566, \"f2\": 0.26146040949447363, \"f0_5\": 0.5861088545897645, \"p4\": 0.5278341793784251, \"phi\": 0.4590662349749954}, {\"truth_threshold\": 39.831092572121655, \"match_probability\": 0.9999999999989775, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1441.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5097.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.220403790473938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.779596209526062, \"precision\": 1.0, \"recall\": 0.220403790473938, \"specificity\": 1.0, \"npv\": 0.9548202157020569, \"accuracy\": 0.9553900361061096, \"f1\": 0.3611981451309688, \"f2\": 0.26111694995107454, \"f0_5\": 0.5856771256706227, \"p4\": 0.5273952459037565, \"phi\": 0.45874391915899093}, {\"truth_threshold\": 39.83874614466509, \"match_probability\": 0.9999999999989829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1438.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5100.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21994493901729584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.780055046081543, \"precision\": 1.0, \"recall\": 0.21994493901729584, \"specificity\": 1.0, \"npv\": 0.9547948241233826, \"accuracy\": 0.9553638100624084, \"f1\": 0.36058174523570713, \"f2\": 0.2606016672707503, \"f0_5\": 0.5850284784377543, \"p4\": 0.5267359377934677, \"phi\": 0.4582600654974708}, {\"truth_threshold\": 39.84284471287871, \"match_probability\": 0.9999999999989858, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1437.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.219791978597641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7802079916000366, \"precision\": 1.0, \"recall\": 0.219791978597641, \"specificity\": 1.0, \"npv\": 0.9547863602638245, \"accuracy\": 0.9553550481796265, \"f1\": 0.36037617554858936, \"f2\": 0.2604298814745007, \"f0_5\": 0.5848119811167182, \"p4\": 0.5265159259089742, \"phi\": 0.45809868888252886}, {\"truth_threshold\": 39.844969281349215, \"match_probability\": 0.9999999999989874, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1436.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5102.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21963903307914734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7803609371185303, \"precision\": 1.0, \"recall\": 0.21963903307914734, \"specificity\": 1.0, \"npv\": 0.9547778964042664, \"accuracy\": 0.9553462862968445, \"f1\": 0.3601705543014798, \"f2\": 0.2602580832245904, \"f0_5\": 0.5845953427780491, \"p4\": 0.5262957925968691, \"phi\": 0.4579372108935472}, {\"truth_threshold\": 39.8464573201022, \"match_probability\": 0.9999999999989884, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1435.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5103.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2194860875606537, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7805139422416687, \"precision\": 1.0, \"recall\": 0.2194860875606537, \"specificity\": 1.0, \"npv\": 0.9547694325447083, \"accuracy\": 0.9553375244140625, \"f1\": 0.35996488147497807, \"f2\": 0.26008627251966504, \"f0_5\": 0.5843785632839225, \"p4\": 0.5260755377547323, \"phi\": 0.4577757261917423}, {\"truth_threshold\": 39.85260119664264, \"match_probability\": 0.9999999999989927, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1433.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5105.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2191801816225052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.780819833278656, \"precision\": 1.0, \"recall\": 0.2191801816225052, \"specificity\": 1.0, \"npv\": 0.9547525644302368, \"accuracy\": 0.9553200006484985, \"f1\": 0.3595533810061473, \"f2\": 0.2597426137393511, \"f0_5\": 0.5839445802770986, \"p4\": 0.525634663070107, \"phi\": 0.457452546950778}, {\"truth_threshold\": 39.856394010484514, \"match_probability\": 0.9999999999989954, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1432.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5106.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21902722120285034, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7809727787971497, \"precision\": 1.0, \"recall\": 0.21902722120285034, \"specificity\": 1.0, \"npv\": 0.9547441005706787, \"accuracy\": 0.9553112983703613, \"f1\": 0.35934755332496865, \"f2\": 0.2595707656612529, \"f0_5\": 0.5837273764878526, \"p4\": 0.5254140430222015, \"phi\": 0.45729085226401023}, {\"truth_threshold\": 39.85706002344128, \"match_probability\": 0.9999999999989958, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1431.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5107.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2188742756843567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7811257243156433, \"precision\": 1.0, \"recall\": 0.2188742756843567, \"specificity\": 1.0, \"npv\": 0.9547356367111206, \"accuracy\": 0.9553025364875793, \"f1\": 0.35914167398669844, \"f2\": 0.2593989051227205, \"f0_5\": 0.5835100309900506, \"p4\": 0.5251933010334303, \"phi\": 0.4571291506997389}, {\"truth_threshold\": 39.85814221509818, \"match_probability\": 0.9999999999989966, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1425.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5113.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2179565578699112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.78204345703125, \"precision\": 1.0, \"recall\": 0.2179565578699112, \"specificity\": 1.0, \"npv\": 0.954684853553772, \"accuracy\": 0.9552500247955322, \"f1\": 0.35790531206831594, \"f2\": 0.2583674801464989, \"f0_5\": 0.5822029743422128, \"p4\": 0.5238662825666173, \"phi\": 0.4561576552629856}, {\"truth_threshold\": 39.8621044664514, \"match_probability\": 0.9999999999989992, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1422.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5116.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21749770641326904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.782502293586731, \"precision\": 1.0, \"recall\": 0.21749770641326904, \"specificity\": 1.0, \"npv\": 0.9546594619750977, \"accuracy\": 0.9552237391471863, \"f1\": 0.357286432160804, \"f2\": 0.25785159933270474, \"f0_5\": 0.5815475216751186, \"p4\": 0.5232011187625418, \"phi\": 0.4556711934566202}, {\"truth_threshold\": 39.869773040285715, \"match_probability\": 0.9999999999990046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1421.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5117.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2173447608947754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7826552391052246, \"precision\": 1.0, \"recall\": 0.2173447608947754, \"specificity\": 1.0, \"npv\": 0.9546509981155396, \"accuracy\": 0.9552149772644043, \"f1\": 0.357080035180299, \"f2\": 0.2576796141152577, \"f0_5\": 0.5813287514318443, \"p4\": 0.5229791516810416, \"phi\": 0.45550894569733624}, {\"truth_threshold\": 39.87156632210876, \"match_probability\": 0.9999999999990058, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1418.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5120.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21688589453697205, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7831140756607056, \"precision\": 1.0, \"recall\": 0.21688589453697205, \"specificity\": 1.0, \"npv\": 0.9546256065368652, \"accuracy\": 0.9551887512207031, \"f1\": 0.3564605329311212, \"f2\": 0.2571635836053682, \"f0_5\": 0.5806715806715806, \"p4\": 0.5223125115378012, \"phi\": 0.45502177725168647}, {\"truth_threshold\": 39.87523841109648, \"match_probability\": 0.9999999999990083, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1417.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5121.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2167329490184784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.783267080783844, \"precision\": 1.0, \"recall\": 0.2167329490184784, \"specificity\": 1.0, \"npv\": 0.9546171426773071, \"accuracy\": 0.9551799893379211, \"f1\": 0.3562539283469516, \"f2\": 0.25699154847836336, \"f0_5\": 0.5804522366049484, \"p4\": 0.522090051509139, \"phi\": 0.45485930936851554}, {\"truth_threshold\": 39.88161998677269, \"match_probability\": 0.9999999999990127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1415.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5123.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2164270430803299, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7835729718208313, \"precision\": 1.0, \"recall\": 0.2164270430803299, \"specificity\": 1.0, \"npv\": 0.9546002149581909, \"accuracy\": 0.9551624655723572, \"f1\": 0.35584056330944297, \"f2\": 0.2566474407806435, \"f0_5\": 0.5800131169044106, \"p4\": 0.5216447608527975, \"phi\": 0.45453416031883087}, {\"truth_threshold\": 39.88765568045077, \"match_probability\": 0.9999999999990169, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1414.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5124.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21627408266067505, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.783725917339325, \"precision\": 1.0, \"recall\": 0.21627408266067505, \"specificity\": 1.0, \"npv\": 0.9545917510986328, \"accuracy\": 0.9551537036895752, \"f1\": 0.35563380281690143, \"f2\": 0.2564753682072118, \"f0_5\": 0.5797933409873708, \"p4\": 0.5214219300154896, \"phi\": 0.4543715267301555}, {\"truth_threshold\": 39.88780696311598, \"match_probability\": 0.999999999999017, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1412.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5126.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21596819162368774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7840318083763123, \"precision\": 1.0, \"recall\": 0.21596819162368774, \"specificity\": 1.0, \"npv\": 0.9545748829841614, \"accuracy\": 0.955136239528656, \"f1\": 0.3552201257861635, \"f2\": 0.25613118560441156, \"f0_5\": 0.5793533563105203, \"p4\": 0.5209758967976379, \"phi\": 0.45404604568481327}, {\"truth_threshold\": 39.89746090308942, \"match_probability\": 0.9999999999990236, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1409.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5129.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2155093252658844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7844906449317932, \"precision\": 1.0, \"recall\": 0.2155093252658844, \"specificity\": 1.0, \"npv\": 0.9545494914054871, \"accuracy\": 0.9551099538803101, \"f1\": 0.35459921983138293, \"f2\": 0.25561481803998404, \"f0_5\": 0.5786922950550353, \"p4\": 0.5203059165343188, \"phi\": 0.45355738392737105}, {\"truth_threshold\": 39.91159321598034, \"match_probability\": 0.999999999999033, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1407.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5131.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2152034193277359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7847965955734253, \"precision\": 1.0, \"recall\": 0.2152034193277359, \"specificity\": 1.0, \"npv\": 0.9545325636863708, \"accuracy\": 0.9550924897193909, \"f1\": 0.3541850220264317, \"f2\": 0.25527051054102107, \"f0_5\": 0.5782508630609896, \"p4\": 0.5198586415039442, \"phi\": 0.4532313949694029}, {\"truth_threshold\": 39.91455151545384, \"match_probability\": 0.999999999999035, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1406.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5132.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21505047380924225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.784949541091919, \"precision\": 1.0, \"recall\": 0.21505047380924225, \"specificity\": 1.0, \"npv\": 0.9545240998268127, \"accuracy\": 0.9550837278366089, \"f1\": 0.3539778449144008, \"f2\": 0.2550983380506568, \"f0_5\": 0.578029929287946, \"p4\": 0.519634817215185, \"phi\": 0.4530682690052797}, {\"truth_threshold\": 39.93091796743041, \"match_probability\": 0.9999999999990459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1405.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5133.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2148975282907486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7851024866104126, \"precision\": 1.0, \"recall\": 0.2148975282907486, \"specificity\": 1.0, \"npv\": 0.9545156359672546, \"accuracy\": 0.9550749659538269, \"f1\": 0.35377061563640944, \"f2\": 0.2549261530645571, \"f0_5\": 0.5778088501398256, \"p4\": 0.5194108682694878, \"phi\": 0.4529051350599751}, {\"truth_threshold\": 39.94985838418979, \"match_probability\": 0.9999999999990583, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1404.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5134.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21474456787109375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7852554321289062, \"precision\": 1.0, \"recall\": 0.21474456787109375, \"specificity\": 1.0, \"npv\": 0.9545071721076965, \"accuracy\": 0.9550662040710449, \"f1\": 0.35356333417275243, \"f2\": 0.2547539555813616, \"f0_5\": 0.5775876254730953, \"p4\": 0.5191867945607849, \"phi\": 0.4527418973288681}, {\"truth_threshold\": 39.95592968403543, \"match_probability\": 0.9999999999990623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1402.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5136.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21443866193294525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7855613231658936, \"precision\": 1.0, \"recall\": 0.21443866193294525, \"specificity\": 1.0, \"npv\": 0.9544903039932251, \"accuracy\": 0.955048680305481, \"f1\": 0.3531486146095718, \"f2\": 0.25440952311824055, \"f0_5\": 0.5771447390087272, \"p4\": 0.5187382724294892, \"phi\": 0.45241530178885236}, {\"truth_threshold\": 39.956126731796616, \"match_probability\": 0.9999999999990624, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1399.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5139.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2139798104763031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7860202193260193, \"precision\": 1.0, \"recall\": 0.2139798104763031, \"specificity\": 1.0, \"npv\": 0.9544649124145508, \"accuracy\": 0.9550224542617798, \"f1\": 0.3525261433791105, \"f2\": 0.253892780661319, \"f0_5\": 0.5764793143233888, \"p4\": 0.5180645508513809, \"phi\": 0.45192501166233295}, {\"truth_threshold\": 39.95767788864909, \"match_probability\": 0.9999999999990634, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1396.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5142.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21352095901966095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7864790558815002, \"precision\": 1.0, \"recall\": 0.21352095901966095, \"specificity\": 1.0, \"npv\": 0.9544395208358765, \"accuracy\": 0.9549961686134338, \"f1\": 0.3519032014116461, \"f2\": 0.253375925657035, \"f0_5\": 0.5758125721828081, \"p4\": 0.517389700655037, \"phi\": 0.45143421515330734}, {\"truth_threshold\": 39.97042925373054, \"match_probability\": 0.9999999999990716, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1395.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5143.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2133679986000061, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7866320013999939, \"precision\": 1.0, \"recall\": 0.2133679986000061, \"specificity\": 1.0, \"npv\": 0.9544310569763184, \"accuracy\": 0.9549874663352966, \"f1\": 0.3516954493886298, \"f2\": 0.25320361563872656, \"f0_5\": 0.57559003135831, \"p4\": 0.5171644992863219, \"phi\": 0.45127047146852994}, {\"truth_threshold\": 39.98163182865978, \"match_probability\": 0.9999999999990788, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1394.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5144.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21321505308151245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7867849469184875, \"precision\": 1.0, \"recall\": 0.21321505308151245, \"specificity\": 1.0, \"npv\": 0.9544225931167603, \"accuracy\": 0.9549787044525146, \"f1\": 0.35148764498234997, \"f2\": 0.2530312931097074, \"f0_5\": 0.5753673435694238, \"p4\": 0.5169391720872767, \"phi\": 0.45110671931762053}, {\"truth_threshold\": 39.983673097182034, \"match_probability\": 0.9999999999990802, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1393.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5145.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2130620926618576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7869378924369812, \"precision\": 1.0, \"recall\": 0.2130620926618576, \"specificity\": 1.0, \"npv\": 0.9544141888618469, \"accuracy\": 0.9549699425697327, \"f1\": 0.35127978817299205, \"f2\": 0.25285895806861497, \"f0_5\": 0.5751445086705202, \"p4\": 0.5167137189505004, \"phi\": 0.45094286252256055}, {\"truth_threshold\": 39.98637079759956, \"match_probability\": 0.9999999999990818, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1390.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5148.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21260324120521545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7873967289924622, \"precision\": 1.0, \"recall\": 0.21260324120521545, \"specificity\": 1.0, \"npv\": 0.9543887972831726, \"accuracy\": 0.9549436569213867, \"f1\": 0.35065590312815337, \"f2\": 0.2523418778592695, \"f0_5\": 0.5744751198545214, \"p4\": 0.516036602837941, \"phi\": 0.45045104822188925}, {\"truth_threshold\": 39.99010472039257, \"match_probability\": 0.9999999999990843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1389.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5149.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2124502956867218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7875497341156006, \"precision\": 1.0, \"recall\": 0.2124502956867218, \"specificity\": 1.0, \"npv\": 0.9543803334236145, \"accuracy\": 0.9549349546432495, \"f1\": 0.35044783650813677, \"f2\": 0.25216949275625433, \"f0_5\": 0.5742516950553994, \"p4\": 0.5158106448737834, \"phi\": 0.4502870126161328}, {\"truth_threshold\": 40.00173554558012, \"match_probability\": 0.9999999999990916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1388.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5150.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21229733526706696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7877026796340942, \"precision\": 1.0, \"recall\": 0.21229733526706696, \"specificity\": 1.0, \"npv\": 0.9543718695640564, \"accuracy\": 0.9549261927604675, \"f1\": 0.3502397173858188, \"f2\": 0.25199709513435004, \"f0_5\": 0.5740281224152192, \"p4\": 0.5155845604330529, \"phi\": 0.4501228719709247}, {\"truth_threshold\": 40.006664739808265, \"match_probability\": 0.9999999999990947, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1386.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5152.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21199142932891846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7880085706710815, \"precision\": 1.0, \"recall\": 0.21199142932891846, \"specificity\": 1.0, \"npv\": 0.9543549418449402, \"accuracy\": 0.9549086689949036, \"f1\": 0.3498233215547703, \"f2\": 0.2516522623284189, \"f0_5\": 0.5735805330243338, \"p4\": 0.515132011689202, \"phi\": 0.4497944679209659}, {\"truth_threshold\": 40.02302671242542, \"match_probability\": 0.9999999999991049, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1385.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5153.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2118384838104248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7881615161895752, \"precision\": 1.0, \"recall\": 0.2118384838104248, \"specificity\": 1.0, \"npv\": 0.9543465375900269, \"accuracy\": 0.9548999071121216, \"f1\": 0.34961504480626027, \"f2\": 0.25147982714166395, \"f0_5\": 0.5733565159794668, \"p4\": 0.5149055471694374, \"phi\": 0.44963020442554336}, {\"truth_threshold\": 40.025514656270815, \"match_probability\": 0.9999999999991065, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1383.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5155.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2115325778722763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7884674072265625, \"precision\": 1.0, \"recall\": 0.2115325778722763, \"specificity\": 1.0, \"npv\": 0.9543296098709106, \"accuracy\": 0.9548824429512024, \"f1\": 0.34919833354374447, \"f2\": 0.2511349191937534, \"f0_5\": 0.5729080364540182, \"p4\": 0.5144522372916931, \"phi\": 0.4493014577563419}, {\"truth_threshold\": 40.03592933431346, \"match_probability\": 0.9999999999991128, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1382.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5156.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21137963235378265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7886203527450562, \"precision\": 1.0, \"recall\": 0.21137963235378265, \"specificity\": 1.0, \"npv\": 0.9543211460113525, \"accuracy\": 0.9548736810684204, \"f1\": 0.348989898989899, \"f2\": 0.25096244642986854, \"f0_5\": 0.5726835736781037, \"p4\": 0.514225391716327, \"phi\": 0.4491370226948225}, {\"truth_threshold\": 40.04165955806131, \"match_probability\": 0.9999999999991164, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1378.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5160.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21076782047748566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7892321944236755, \"precision\": 1.0, \"recall\": 0.21076782047748566, \"specificity\": 1.0, \"npv\": 0.9542873501777649, \"accuracy\": 0.9548386335372925, \"f1\": 0.348155634158666, \"f2\": 0.2502724300762804, \"f0_5\": 0.5717842323651452, \"p4\": 0.5133167359629313, \"phi\": 0.4484786120465538}, {\"truth_threshold\": 40.04612966493857, \"match_probability\": 0.9999999999991191, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1377.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5161.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2106148600578308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7893851399421692, \"precision\": 1.0, \"recall\": 0.2106148600578308, \"specificity\": 1.0, \"npv\": 0.9542788863182068, \"accuracy\": 0.9548298716545105, \"f1\": 0.3479469361970941, \"f2\": 0.25009989465654403, \"f0_5\": 0.5715590237423211, \"p4\": 0.5130892531156463, \"phi\": 0.4483138414156203}, {\"truth_threshold\": 40.05527468403288, \"match_probability\": 0.9999999999991247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1374.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5164.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.21015600860118866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7898439764976501, \"precision\": 1.0, \"recall\": 0.21015600860118866, \"specificity\": 1.0, \"npv\": 0.9542534947395325, \"accuracy\": 0.9548036456108093, \"f1\": 0.3473205257836198, \"f2\": 0.24958221318026594, \"f0_5\": 0.5708824995845105, \"p4\": 0.5124060374407975, \"phi\": 0.4478192801290385}, {\"truth_threshold\": 40.05546535758634, \"match_probability\": 0.9999999999991248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1373.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5165.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.210003063082695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7899969220161438, \"precision\": 1.0, \"recall\": 0.210003063082695, \"specificity\": 1.0, \"npv\": 0.9542450904846191, \"accuracy\": 0.9547948837280273, \"f1\": 0.3471116167361901, \"f2\": 0.24940962761126248, \"f0_5\": 0.5706566916043225, \"p4\": 0.5121780428056714, \"phi\": 0.44765432693803475}, {\"truth_threshold\": 40.06788348903888, \"match_probability\": 0.9999999999991324, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1370.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5168.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20954419672489166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7904558181762695, \"precision\": 1.0, \"recall\": 0.20954419672489166, \"specificity\": 1.0, \"npv\": 0.9542196989059448, \"accuracy\": 0.9547686576843262, \"f1\": 0.3464845725847243, \"f2\": 0.24889179565438557, \"f0_5\": 0.5699783657846563, \"p4\": 0.511493289129693, \"phi\": 0.44715902286208875}, {\"truth_threshold\": 40.077502552550605, \"match_probability\": 0.999999999999138, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1368.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5170.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20923830568790436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7907617092132568, \"precision\": 1.0, \"recall\": 0.20923830568790436, \"specificity\": 1.0, \"npv\": 0.9542027711868286, \"accuracy\": 0.9547511339187622, \"f1\": 0.34606627877561347, \"f2\": 0.24854651162790697, \"f0_5\": 0.5695253955037469, \"p4\": 0.5110361441006549, \"phi\": 0.44682854593935806}, {\"truth_threshold\": 40.07760316741927, \"match_probability\": 0.9999999999991381, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2090853452682495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7909146547317505, \"precision\": 1.0, \"recall\": 0.2090853452682495, \"specificity\": 1.0, \"npv\": 0.9541943669319153, \"accuracy\": 0.9547423720359802, \"f1\": 0.34585705249841875, \"f2\": 0.24837385079399688, \"f0_5\": 0.5692986839913377, \"p4\": 0.5108073784810905, \"phi\": 0.4466632444466101}, {\"truth_threshold\": 40.098654846587934, \"match_probability\": 0.9999999999991506, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1366.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5172.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20893239974975586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7910676002502441, \"precision\": 1.0, \"recall\": 0.20893239974975586, \"specificity\": 1.0, \"npv\": 0.9541859030723572, \"accuracy\": 0.9547336101531982, \"f1\": 0.3456477732793522, \"f2\": 0.24820117741114905, \"f0_5\": 0.5690718213631062, \"p4\": 0.5105784839771869, \"phi\": 0.4464978846864432}, {\"truth_threshold\": 40.10455219908628, \"match_probability\": 0.9999999999991541, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1365.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5173.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.208779439330101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7912205457687378, \"precision\": 1.0, \"recall\": 0.208779439330101, \"specificity\": 1.0, \"npv\": 0.9541774392127991, \"accuracy\": 0.9547248482704163, \"f1\": 0.3454384410983171, \"f2\": 0.2480284914779954, \"f0_5\": 0.5688448074679113, \"p4\": 0.5103494604780536, \"phi\": 0.4463324180256555}, {\"truth_threshold\": 40.107411853225514, \"match_probability\": 0.9999999999991558, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1364.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5174.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20862649381160736, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7913734912872314, \"precision\": 1.0, \"recall\": 0.20862649381160736, \"specificity\": 1.0, \"npv\": 0.954168975353241, \"accuracy\": 0.954716145992279, \"f1\": 0.34522905593520625, \"f2\": 0.24785579299316762, \"f0_5\": 0.5686176421544106, \"p4\": 0.5101203078726735, \"phi\": 0.4461669415184276}, {\"truth_threshold\": 40.1125494996498, \"match_probability\": 0.9999999999991588, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1363.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5175.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20847353339195251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7915264368057251, \"precision\": 1.0, \"recall\": 0.20847353339195251, \"specificity\": 1.0, \"npv\": 0.9541605114936829, \"accuracy\": 0.9547073841094971, \"f1\": 0.34501961776990253, \"f2\": 0.24768308195529712, \"f0_5\": 0.5683903252710593, \"p4\": 0.5098910260499011, \"phi\": 0.4460013579453331}, {\"truth_threshold\": 40.11721059106849, \"match_probability\": 0.9999999999991614, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1362.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5176.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20832058787345886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7916794419288635, \"precision\": 1.0, \"recall\": 0.20832058787345886, \"specificity\": 1.0, \"npv\": 0.9541521072387695, \"accuracy\": 0.9546986222267151, \"f1\": 0.3448101265822785, \"f2\": 0.2475103583630152, \"f0_5\": 0.5681628566661104, \"p4\": 0.509661614898464, \"phi\": 0.44583576443065437}, {\"truth_threshold\": 40.12556413243297, \"match_probability\": 0.9999999999991663, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1359.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5179.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2078617364168167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7921382784843445, \"precision\": 1.0, \"recall\": 0.2078617364168167, \"specificity\": 1.0, \"npv\": 0.9541267156600952, \"accuracy\": 0.9546723365783691, \"f1\": 0.34418133468405726, \"f2\": 0.2469921122460107, \"f0_5\": 0.5674795390011692, \"p4\": 0.5089726043575206, \"phi\": 0.4453385833934849}, {\"truth_threshold\": 40.13968107644308, \"match_probability\": 0.9999999999991744, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1358.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5180.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20770877599716187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7922912240028381, \"precision\": 1.0, \"recall\": 0.20770877599716187, \"specificity\": 1.0, \"npv\": 0.9541183114051819, \"accuracy\": 0.9546636343002319, \"f1\": 0.34397163120567376, \"f2\": 0.24681933842239187, \"f0_5\": 0.5672514619883041, \"p4\": 0.5087426747761403, \"phi\": 0.4451727064047293}, {\"truth_threshold\": 40.14119523161223, \"match_probability\": 0.9999999999991753, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1357.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5181.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.2075558304786682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7924441695213318, \"precision\": 1.0, \"recall\": 0.2075558304786682, \"specificity\": 1.0, \"npv\": 0.9541098475456238, \"accuracy\": 0.95465487241745, \"f1\": 0.34376187460417984, \"f2\": 0.24664655203751498, \"f0_5\": 0.5670232324920609, \"p4\": 0.508512615307812, \"phi\": 0.4450068192347747}, {\"truth_threshold\": 40.15770249695708, \"match_probability\": 0.9999999999991847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1356.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5182.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20740287005901337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7925971150398254, \"precision\": 1.0, \"recall\": 0.20740287005901337, \"specificity\": 1.0, \"npv\": 0.9541013836860657, \"accuracy\": 0.954646110534668, \"f1\": 0.3435520648593869, \"f2\": 0.24647375309001018, \"f0_5\": 0.5667948503594716, \"p4\": 0.5082824258404938, \"phi\": 0.44484082441620204}, {\"truth_threshold\": 40.15834653860664, \"match_probability\": 0.9999999999991851, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1354.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5184.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20709696412086487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7929030060768127, \"precision\": 1.0, \"recall\": 0.20709696412086487, \"specificity\": 1.0, \"npv\": 0.9540844559669495, \"accuracy\": 0.954628586769104, \"f1\": 0.34313228585909783, \"f2\": 0.24612811750163602, \"f0_5\": 0.5663376275723607, \"p4\": 0.5078216564600746, \"phi\": 0.44450870640714635}, {\"truth_threshold\": 40.15931174981874, \"match_probability\": 0.9999999999991855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1351.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5187.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20663811266422272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7933619022369385, \"precision\": 1.0, \"recall\": 0.20663811266422272, \"specificity\": 1.0, \"npv\": 0.9540591239929199, \"accuracy\": 0.9546023607254028, \"f1\": 0.34250221827861577, \"f2\": 0.24560956986510563, \"f0_5\": 0.5656506447831184, \"p4\": 0.5071295245885505, \"phi\": 0.44401011010320685}, {\"truth_threshold\": 40.164134120167624, \"match_probability\": 0.9999999999991883, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1349.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5189.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20633220672607422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7936677932739258, \"precision\": 1.0, \"recall\": 0.20633220672607422, \"specificity\": 1.0, \"npv\": 0.9540422558784485, \"accuracy\": 0.9545848369598389, \"f1\": 0.3420819069354634, \"f2\": 0.24526380858877858, \"f0_5\": 0.5651918887213004, \"p4\": 0.5066674501589068, \"phi\": 0.4436773997374064}, {\"truth_threshold\": 40.17017250826944, \"match_probability\": 0.9999999999991916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1348.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5190.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20617926120758057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7938207387924194, \"precision\": 1.0, \"recall\": 0.20617926120758057, \"specificity\": 1.0, \"npv\": 0.9540337920188904, \"accuracy\": 0.9545760750770569, \"f1\": 0.3418716713162567, \"f2\": 0.24509090909090908, \"f0_5\": 0.5649622799664711, \"p4\": 0.5064362166506523, \"phi\": 0.44351097981639587}, {\"truth_threshold\": 40.17094257500628, \"match_probability\": 0.9999999999991921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1347.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5191.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20602630078792572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7939736843109131, \"precision\": 1.0, \"recall\": 0.20602630078792572, \"specificity\": 1.0, \"npv\": 0.9540253281593323, \"accuracy\": 0.9545673131942749, \"f1\": 0.3416613823715916, \"f2\": 0.24491799701807337, \"f0_5\": 0.5647325171893343, \"p4\": 0.506204852129208, \"phi\": 0.4433444514873032}, {\"truth_threshold\": 40.17576494535516, \"match_probability\": 0.9999999999991949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1344.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5194.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20556744933128357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.794432520866394, \"precision\": 1.0, \"recall\": 0.20556744933128357, \"specificity\": 1.0, \"npv\": 0.9539999961853027, \"accuracy\": 0.9545410871505737, \"f1\": 0.3410301953818828, \"f2\": 0.24439918533604887, \"f0_5\": 0.564042303172738, \"p4\": 0.5055099713516906, \"phi\": 0.4428446063747838}, {\"truth_threshold\": 40.19395237326421, \"match_probability\": 0.9999999999992049, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1341.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5197.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20510859787464142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7948914170265198, \"precision\": 1.0, \"recall\": 0.20510859787464142, \"specificity\": 1.0, \"npv\": 0.9539746642112732, \"accuracy\": 0.9545148015022278, \"f1\": 0.3403985277319457, \"f2\": 0.2438802604299276, \"f0_5\": 0.5633506973617879, \"p4\": 0.5048139073674006, \"phi\": 0.4423442230472202}, {\"truth_threshold\": 40.195177202375746, \"match_probability\": 0.9999999999992056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20480269193649292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7951973080635071, \"precision\": 1.0, \"recall\": 0.20480269193649292, \"specificity\": 1.0, \"npv\": 0.953957736492157, \"accuracy\": 0.9544973373413086, \"f1\": 0.3399771486606576, \"f2\": 0.24353424757193262, \"f0_5\": 0.5628888515217757, \"p4\": 0.5043492058546175, \"phi\": 0.442010317906201}, {\"truth_threshold\": 40.222639928163574, \"match_probability\": 0.9999999999992205, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1337.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5201.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20449678599834442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7955031991004944, \"precision\": 1.0, \"recall\": 0.20449678599834442, \"specificity\": 1.0, \"npv\": 0.9539408683776855, \"accuracy\": 0.9544798135757446, \"f1\": 0.33955555555555555, \"f2\": 0.24318818436465495, \"f0_5\": 0.5624263839811543, \"p4\": 0.5038839761898424, \"phi\": 0.441676172175951}, {\"truth_threshold\": 40.227143917693425, \"match_probability\": 0.999999999999223, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1336.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5202.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20434384047985077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.795656144618988, \"precision\": 1.0, \"recall\": 0.20434384047985077, \"specificity\": 1.0, \"npv\": 0.9539324045181274, \"accuracy\": 0.9544710516929626, \"f1\": 0.33934467868935736, \"f2\": 0.2430151338766007, \"f0_5\": 0.5621949166806934, \"p4\": 0.5036511630140682, \"phi\": 0.44150898437580177}, {\"truth_threshold\": 40.24286235756659, \"match_probability\": 0.9999999999992314, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1335.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5203.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20419088006019592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7958090901374817, \"precision\": 1.0, \"recall\": 0.20419088006019592, \"specificity\": 1.0, \"npv\": 0.9539239406585693, \"accuracy\": 0.9544622898101807, \"f1\": 0.3391337482535247, \"f2\": 0.2428420707971041, \"f0_5\": 0.5619632934837515, \"p4\": 0.5034182174563635, \"phi\": 0.44134178530938073}, {\"truth_threshold\": 40.24313639974442, \"match_probability\": 0.9999999999992316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1334.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5204.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20403793454170227, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7959620952606201, \"precision\": 1.0, \"recall\": 0.20403793454170227, \"specificity\": 1.0, \"npv\": 0.9539154767990112, \"accuracy\": 0.9544535279273987, \"f1\": 0.3389227642276423, \"f2\": 0.24266899512479082, \"f0_5\": 0.5617315142327775, \"p4\": 0.5031851394018075, \"phi\": 0.4411745258397997}, {\"truth_threshold\": 40.26222114788189, \"match_probability\": 0.9999999999992416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1331.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5207.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20357908308506012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7964209318161011, \"precision\": 1.0, \"recall\": 0.20357908308506012, \"specificity\": 1.0, \"npv\": 0.9538901448249817, \"accuracy\": 0.9544273018836975, \"f1\": 0.33828949040538825, \"f2\": 0.2421496925372048, \"f0_5\": 0.5610352385769685, \"p4\": 0.5024851091058299, \"phi\": 0.4406722859686393}, {\"truth_threshold\": 40.26552486879664, \"match_probability\": 0.9999999999992434, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1330.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5208.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20342612266540527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7965738773345947, \"precision\": 1.0, \"recall\": 0.20342612266540527, \"specificity\": 1.0, \"npv\": 0.9538817405700684, \"accuracy\": 0.9544185400009155, \"f1\": 0.33807829181494664, \"f2\": 0.24197656647987772, \"f0_5\": 0.5608028335301063, \"p4\": 0.5022514999119994, \"phi\": 0.4405047841605355}, {\"truth_threshold\": 40.27528383525897, \"match_probability\": 0.9999999999992485, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1327.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5211.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20296727120876312, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7970327138900757, \"precision\": 1.0, \"recall\": 0.20296727120876312, \"specificity\": 1.0, \"npv\": 0.953856348991394, \"accuracy\": 0.9543923139572144, \"f1\": 0.3374443738080102, \"f2\": 0.24145711270424688, \"f0_5\": 0.5601046766841128, \"p4\": 0.5015498734267652, \"phi\": 0.44000186471654923}, {\"truth_threshold\": 40.275972526343146, \"match_probability\": 0.9999999999992488, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1326.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5212.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20281431078910828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7971856594085693, \"precision\": 1.0, \"recall\": 0.20281431078910828, \"specificity\": 1.0, \"npv\": 0.9538479447364807, \"accuracy\": 0.9543835520744324, \"f1\": 0.33723296032553407, \"f2\": 0.24128393623990102, \"f0_5\": 0.559871643303496, \"p4\": 0.501315731244253, \"phi\": 0.439834070209818}, {\"truth_threshold\": 40.27756722587802, \"match_probability\": 0.9999999999992497, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1322.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5216.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20220251381397247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7977975010871887, \"precision\": 1.0, \"recall\": 0.20220251381397247, \"specificity\": 1.0, \"npv\": 0.9538141489028931, \"accuracy\": 0.9543485045433044, \"f1\": 0.33638676844783716, \"f2\": 0.2405911043168086, \"f0_5\": 0.5589379333671571, \"p4\": 0.5003778259794686, \"phi\": 0.43916237952786075}, {\"truth_threshold\": 40.29303185334988, \"match_probability\": 0.9999999999992577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1319.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5219.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20174364745616913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7982563376426697, \"precision\": 1.0, \"recall\": 0.20174364745616913, \"specificity\": 1.0, \"npv\": 0.9537888169288635, \"accuracy\": 0.9543222784996033, \"f1\": 0.3357515591192567, \"f2\": 0.24007134796694696, \"f0_5\": 0.558235991196885, \"p4\": 0.4996729904065692, \"phi\": 0.4386579925335808}, {\"truth_threshold\": 40.29560381963856, \"match_probability\": 0.999999999999259, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1318.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5220.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20159070193767548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7984092831611633, \"precision\": 1.0, \"recall\": 0.20159070193767548, \"specificity\": 1.0, \"npv\": 0.9537803530693054, \"accuracy\": 0.9543135166168213, \"f1\": 0.33553971486761713, \"f2\": 0.23989807062249727, \"f0_5\": 0.5580016934801016, \"p4\": 0.49943777666404365, \"phi\": 0.4384897570375114}, {\"truth_threshold\": 40.29740769656555, \"match_probability\": 0.9999999999992599, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1317.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5221.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20143774151802063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.798562228679657, \"precision\": 1.0, \"recall\": 0.20143774151802063, \"specificity\": 1.0, \"npv\": 0.9537718892097473, \"accuracy\": 0.9543047547340393, \"f1\": 0.3353278166772756, \"f2\": 0.23972478066183697, \"f0_5\": 0.5577672369981366, \"p4\": 0.4992024284505044, \"phi\": 0.4383214105156123}, {\"truth_threshold\": 40.29861633908959, \"match_probability\": 0.9999999999992606, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1316.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5222.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20128479599952698, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7987151741981506, \"precision\": 1.0, \"recall\": 0.20128479599952698, \"specificity\": 1.0, \"npv\": 0.953763484954834, \"accuracy\": 0.9542959928512573, \"f1\": 0.33511586452762926, \"f2\": 0.23955147808358818, \"f0_5\": 0.5575326215895611, \"p4\": 0.4989669456486065, \"phi\": 0.43815305174828356}, {\"truth_threshold\": 40.302844462394816, \"match_probability\": 0.9999999999992627, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1315.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5223.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20113185048103333, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7988681793212891, \"precision\": 1.0, \"recall\": 0.20113185048103333, \"specificity\": 1.0, \"npv\": 0.9537550210952759, \"accuracy\": 0.9542872905731201, \"f1\": 0.3349038583980644, \"f2\": 0.23937816288637273, \"f0_5\": 0.5572978470927276, \"p4\": 0.49873132814086846, \"phi\": 0.4379845817757251}, {\"truth_threshold\": 40.30657838518783, \"match_probability\": 0.9999999999992646, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1314.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5224.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20097889006137848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7990211248397827, \"precision\": 1.0, \"recall\": 0.20097889006137848, \"specificity\": 1.0, \"npv\": 0.9537465572357178, \"accuracy\": 0.9542785286903381, \"f1\": 0.3346917982679572, \"f2\": 0.23920483506881235, \"f0_5\": 0.5570629133457691, \"p4\": 0.49849557580967213, \"phi\": 0.4378160994523052}, {\"truth_threshold\": 40.322209484367086, \"match_probability\": 0.9999999999992726, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1313.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5225.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20082594454288483, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7991740703582764, \"precision\": 1.0, \"recall\": 0.20082594454288483, \"specificity\": 1.0, \"npv\": 0.9537381529808044, \"accuracy\": 0.9542697668075562, \"f1\": 0.33447968411667306, \"f2\": 0.2390314946295285, \"f0_5\": 0.5568278201865988, \"p4\": 0.4982596885372623, \"phi\": 0.43764750574362743}, {\"truth_threshold\": 40.33188414727245, \"match_probability\": 0.9999999999992774, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1312.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5226.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20067298412322998, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.79932701587677, \"precision\": 1.0, \"recall\": 0.20067298412322998, \"specificity\": 1.0, \"npv\": 0.9537296891212463, \"accuracy\": 0.9542610049247742, \"f1\": 0.3342675159235669, \"f2\": 0.23885814156714244, \"f0_5\": 0.5565925674529102, \"p4\": 0.49802366620574673, \"phi\": 0.4374788995781973}, {\"truth_threshold\": 40.350730567559054, \"match_probability\": 0.9999999999992868, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1311.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5227.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20052003860473633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7994799613952637, \"precision\": 1.0, \"recall\": 0.20052003860473633, \"specificity\": 1.0, \"npv\": 0.9537212252616882, \"accuracy\": 0.9542522430419922, \"f1\": 0.3340552936679832, \"f2\": 0.23868477588027529, \"f0_5\": 0.5563571549821762, \"p4\": 0.4977875086970957, \"phi\": 0.4373102313935345}, {\"truth_threshold\": 40.35122094657156, \"match_probability\": 0.999999999999287, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1310.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5228.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20036707818508148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7996329069137573, \"precision\": 1.0, \"recall\": 0.20036707818508148, \"specificity\": 1.0, \"npv\": 0.9537128210067749, \"accuracy\": 0.9542434811592102, \"f1\": 0.33384301732925586, \"f2\": 0.23851139756754788, \"f0_5\": 0.5561215826116488, \"p4\": 0.49755121589314205, \"phi\": 0.4371414515523985}, {\"truth_threshold\": 40.35833957498652, \"match_probability\": 0.9999999999992906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1309.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5229.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.20021413266658783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.799785852432251, \"precision\": 1.0, \"recall\": 0.20021413266658783, \"specificity\": 1.0, \"npv\": 0.9537043571472168, \"accuracy\": 0.954234778881073, \"f1\": 0.33363068688670827, \"f2\": 0.23833800662758092, \"f0_5\": 0.5558858501783591, \"p4\": 0.4973147876755808, \"phi\": 0.43697265909481775}, {\"truth_threshold\": 40.36201122404563, \"match_probability\": 0.9999999999992923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1306.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5232.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19975528120994568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8002447485923767, \"precision\": 1.0, \"recall\": 0.19975528120994568, \"specificity\": 1.0, \"npv\": 0.9536790251731873, \"accuracy\": 0.954208493232727, \"f1\": 0.3329933707292198, \"f2\": 0.2378177580304465, \"f0_5\": 0.5551776908688999, \"p4\": 0.49660468935613183, \"phi\": 0.4364658087404957}, {\"truth_threshold\": 40.362073497779534, \"match_probability\": 0.9999999999992923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1305.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5233.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19960232079029083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8003976941108704, \"precision\": 1.0, \"recall\": 0.19960232079029083, \"specificity\": 1.0, \"npv\": 0.9536705613136292, \"accuracy\": 0.9541997313499451, \"f1\": 0.33278082366441414, \"f2\": 0.23764431656772408, \"f0_5\": 0.5549413165504338, \"p4\": 0.49636771829832893, \"phi\": 0.4362967668699866}, {\"truth_threshold\": 40.36973152948911, \"match_probability\": 0.9999999999992961, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1302.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5236.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19914346933364868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8008565306663513, \"precision\": 1.0, \"recall\": 0.19914346933364868, \"specificity\": 1.0, \"npv\": 0.9536452293395996, \"accuracy\": 0.9541735053062439, \"f1\": 0.33214285714285713, \"f2\": 0.23712391636919938, \"f0_5\": 0.5542312276519666, \"p4\": 0.4956559886050055, \"phi\": 0.4357892160996513}, {\"truth_threshold\": 40.39377700345576, \"match_probability\": 0.9999999999993078, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1301.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5237.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19899052381515503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.801009476184845, \"precision\": 1.0, \"recall\": 0.19899052381515503, \"specificity\": 1.0, \"npv\": 0.9536368250846863, \"accuracy\": 0.9541647434234619, \"f1\": 0.33193009312412297, \"f2\": 0.23695042436163624, \"f0_5\": 0.5539942088230284, \"p4\": 0.4954184728030099, \"phi\": 0.43561987393702456}, {\"truth_threshold\": 40.39741330665958, \"match_probability\": 0.9999999999993094, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1297.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5241.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19837871193885803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8016213178634644, \"precision\": 1.0, \"recall\": 0.19837871193885803, \"specificity\": 1.0, \"npv\": 0.9536030292510986, \"accuracy\": 0.954129695892334, \"f1\": 0.33107849393746014, \"f2\": 0.2362563299209443, \"f0_5\": 0.5530445164591506, \"p4\": 0.494467043551554, \"phi\": 0.4349419756186704}, {\"truth_threshold\": 40.39815736669161, \"match_probability\": 0.9999999999993099, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1296.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5242.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19822575151920319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.801774263381958, \"precision\": 1.0, \"recall\": 0.19822575151920319, \"specificity\": 1.0, \"npv\": 0.9535946249961853, \"accuracy\": 0.9541209936141968, \"f1\": 0.3308654582588716, \"f2\": 0.23608277470125327, \"f0_5\": 0.5528066882784508, \"p4\": 0.4942288441283034, \"phi\": 0.4347723683106994}, {\"truth_threshold\": 40.40656956720666, \"match_probability\": 0.9999999999993139, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1295.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5243.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19807280600070953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8019272089004517, \"precision\": 1.0, \"recall\": 0.19807280600070953, \"specificity\": 1.0, \"npv\": 0.9535861611366272, \"accuracy\": 0.9541122317314148, \"f1\": 0.33065236818588023, \"f2\": 0.2359092068349911, \"f0_5\": 0.5525686977299881, \"p4\": 0.49399050762059976, \"phi\": 0.4346026978167426}, {\"truth_threshold\": 40.412134703471466, \"match_probability\": 0.9999999999993165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1294.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5244.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19791986048221588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8020801544189453, \"precision\": 1.0, \"recall\": 0.19791986048221588, \"specificity\": 1.0, \"npv\": 0.9535776972770691, \"accuracy\": 0.9541034698486328, \"f1\": 0.33043922369765066, \"f2\": 0.23573562632077535, \"f0_5\": 0.5523305446474305, \"p4\": 0.49375203390804756, \"phi\": 0.4344329141953565}, {\"truth_threshold\": 40.41698884499634, \"match_probability\": 0.9999999999993188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1293.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5245.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19776690006256104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.802233099937439, \"precision\": 1.0, \"recall\": 0.19776690006256104, \"specificity\": 1.0, \"npv\": 0.9535692930221558, \"accuracy\": 0.9540947079658508, \"f1\": 0.33022602477333673, \"f2\": 0.23556203315722354, \"f0_5\": 0.5520922288642186, \"p4\": 0.49351342287011035, \"phi\": 0.434263117087887}, {\"truth_threshold\": 40.42676316938046, \"match_probability\": 0.9999999999993234, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1292.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5246.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19761395454406738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8023860454559326, \"precision\": 1.0, \"recall\": 0.19761395454406738, \"specificity\": 1.0, \"npv\": 0.9535608291625977, \"accuracy\": 0.9540859460830688, \"f1\": 0.33001277139208174, \"f2\": 0.23538842734295293, \"f0_5\": 0.5518537502135656, \"p4\": 0.4932746743861106, \"phi\": 0.43409320666616913}, {\"truth_threshold\": 40.4286884378577, \"match_probability\": 0.9999999999993243, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1289.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5249.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19715508818626404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8028448820114136, \"precision\": 1.0, \"recall\": 0.19715508818626404, \"specificity\": 1.0, \"npv\": 0.9535354971885681, \"accuracy\": 0.9540597200393677, \"f1\": 0.32937268429794303, \"f2\": 0.23486753398199775, \"f0_5\": 0.5511373353856679, \"p4\": 0.49255760304883717, \"phi\": 0.4335831938983683}, {\"truth_threshold\": 40.43528521136003, \"match_probability\": 0.9999999999993274, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1288.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5250.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19700214266777039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.802997887134552, \"precision\": 1.0, \"recall\": 0.19700214266777039, \"specificity\": 1.0, \"npv\": 0.9535270929336548, \"accuracy\": 0.9540509581565857, \"f1\": 0.3291592128801431, \"f2\": 0.23469387755102042, \"f0_5\": 0.5508982035928144, \"p4\": 0.4923183035709795, \"phi\": 0.4334130789617763}, {\"truth_threshold\": 40.43731131243597, \"match_probability\": 0.9999999999993283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1287.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5251.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19684918224811554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8031508326530457, \"precision\": 1.0, \"recall\": 0.19684918224811554, \"specificity\": 1.0, \"npv\": 0.9535186290740967, \"accuracy\": 0.9540421962738037, \"f1\": 0.3289456869009585, \"f2\": 0.2345202084624075, \"f0_5\": 0.5506589080951566, \"p4\": 0.4920788660415457, \"phi\": 0.43324285024097686}, {\"truth_threshold\": 40.468522492736945, \"match_probability\": 0.9999999999993427, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1283.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5255.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19623738527297974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8037626147270203, \"precision\": 1.0, \"recall\": 0.19623738527297974, \"specificity\": 1.0, \"npv\": 0.9534848928451538, \"accuracy\": 0.9540072083473206, \"f1\": 0.3280910369517964, \"f2\": 0.23382540550391837, \"f0_5\": 0.5497000856898029, \"p4\": 0.49111973297532435, \"phi\": 0.43256139579161634}, {\"truth_threshold\": 40.47410621992491, \"match_probability\": 0.9999999999993452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1282.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5256.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1960844248533249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8039155602455139, \"precision\": 1.0, \"recall\": 0.1960844248533249, \"specificity\": 1.0, \"npv\": 0.9534764289855957, \"accuracy\": 0.9539984464645386, \"f1\": 0.3278772378516624, \"f2\": 0.23365167310636437, \"f0_5\": 0.5494599691410937, \"p4\": 0.49087960336221553, \"phi\": 0.4323908969671165}, {\"truth_threshold\": 40.485674333997366, \"match_probability\": 0.9999999999993505, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1281.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5257.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19593147933483124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8040685057640076, \"precision\": 1.0, \"recall\": 0.19593147933483124, \"specificity\": 1.0, \"npv\": 0.9534679651260376, \"accuracy\": 0.9539896845817566, \"f1\": 0.3276633840644584, \"f2\": 0.23347792804286807, \"f0_5\": 0.5492196878751501, \"p4\": 0.49063933496621115, \"phi\": 0.432220283788871}, {\"truth_threshold\": 40.491261417031986, \"match_probability\": 0.999999999999353, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1279.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5259.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19562557339668274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8043743968009949, \"precision\": 1.0, \"recall\": 0.19562557339668274, \"specificity\": 1.0, \"npv\": 0.9534510970115662, \"accuracy\": 0.9539721608161926, \"f1\": 0.32723551234488935, \"f2\": 0.23313039991250775, \"f0_5\": 0.5487386305131285, \"p4\": 0.4901583813358185, \"phi\": 0.43187896461185266}, {\"truth_threshold\": 40.50166194244547, \"match_probability\": 0.9999999999993576, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1278.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5260.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1954726278781891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8045274019241333, \"precision\": 1.0, \"recall\": 0.1954726278781891, \"specificity\": 1.0, \"npv\": 0.9534426927566528, \"accuracy\": 0.9539634585380554, \"f1\": 0.327021494370522, \"f2\": 0.23295661684287278, \"f0_5\": 0.5484978540772533, \"p4\": 0.4899176958562216, \"phi\": 0.4317081581878368}, {\"truth_threshold\": 40.502564066097484, \"match_probability\": 0.9999999999993581, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1277.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5261.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19531966745853424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.804680347442627, \"precision\": 1.0, \"recall\": 0.19531966745853424, \"specificity\": 1.0, \"npv\": 0.9534342288970947, \"accuracy\": 0.9539546966552734, \"f1\": 0.32680742162508, \"f2\": 0.2327828211017536, \"f0_5\": 0.5482569122445475, \"p4\": 0.4896768711033113, \"phi\": 0.4315373373769133}, {\"truth_threshold\": 40.50918867908035, \"match_probability\": 0.999999999999361, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1271.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5267.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19440196454524994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8055980205535889, \"precision\": 1.0, \"recall\": 0.19440196454524994, \"specificity\": 1.0, \"npv\": 0.9533836245536804, \"accuracy\": 0.9539021849632263, \"f1\": 0.32552183378153415, \"f2\": 0.23173978047624258, \"f0_5\": 0.5468077783514025, \"p4\": 0.48822899095006617, \"phi\": 0.430510901876278}, {\"truth_threshold\": 40.50952801384725, \"match_probability\": 0.9999999999993612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1270.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5268.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1942490041255951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8057509660720825, \"precision\": 1.0, \"recall\": 0.1942490041255951, \"specificity\": 1.0, \"npv\": 0.9533751606941223, \"accuracy\": 0.9538934230804443, \"f1\": 0.32530737704918034, \"f2\": 0.23156589599591568, \"f0_5\": 0.546565673954209, \"p4\": 0.48798718783281153, \"phi\": 0.4303396270516255}, {\"truth_threshold\": 40.51030386492316, \"match_probability\": 0.9999999999993615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19409605860710144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.805903971195221, \"precision\": 1.0, \"recall\": 0.19409605860710144, \"specificity\": 1.0, \"npv\": 0.953366756439209, \"accuracy\": 0.9538846611976624, \"f1\": 0.3250928653772256, \"f2\": 0.2313919988330112, \"f0_5\": 0.5463234027897366, \"p4\": 0.4877452444544555, \"phi\": 0.43016823671556076}, {\"truth_threshold\": 40.52382030569065, \"match_probability\": 0.9999999999993674, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1266.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5272.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1936371922492981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8063628077507019, \"precision\": 1.0, \"recall\": 0.1936371922492981, \"specificity\": 1.0, \"npv\": 0.9533414244651794, \"accuracy\": 0.9538584351539612, \"f1\": 0.32444900051255765, \"f2\": 0.23087023123495515, \"f0_5\": 0.5455955869677642, \"p4\": 0.48701857151075084, \"phi\": 0.42965377454503983}, {\"truth_threshold\": 40.54040191717424, \"match_probability\": 0.9999999999993746, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1264.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5274.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1933313012123108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8066686987876892, \"precision\": 1.0, \"recall\": 0.1933313012123108, \"specificity\": 1.0, \"npv\": 0.953324556350708, \"accuracy\": 0.9538409113883972, \"f1\": 0.32401948218405535, \"f2\": 0.2305223227312518, \"f0_5\": 0.5451095394169398, \"p4\": 0.4865334192964892, \"phi\": 0.4293104556447131}, {\"truth_threshold\": 40.54054542474028, \"match_probability\": 0.9999999999993747, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1260.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5278.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1927194893360138, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8072805404663086, \"precision\": 1.0, \"recall\": 0.1927194893360138, \"specificity\": 1.0, \"npv\": 0.9532908201217651, \"accuracy\": 0.9538059234619141, \"f1\": 0.3231597845601436, \"f2\": 0.22982635342185903, \"f0_5\": 0.5441354292623942, \"p4\": 0.48556142176987727, \"phi\": 0.4286230294017304}, {\"truth_threshold\": 40.540601631711816, \"match_probability\": 0.9999999999993747, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19256652891635895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8074334859848022, \"precision\": 1.0, \"recall\": 0.19256652891635895, \"specificity\": 1.0, \"npv\": 0.953282356262207, \"accuracy\": 0.9537971615791321, \"f1\": 0.32294472232910093, \"f2\": 0.22965232935682756, \"f0_5\": 0.5438914809054778, \"p4\": 0.48531806892914225, \"phi\": 0.42845103339448637}, {\"truth_threshold\": 40.540892184756586, \"match_probability\": 0.9999999999993748, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1256.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5282.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1921076774597168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8078923225402832, \"precision\": 1.0, \"recall\": 0.1921076774597168, \"specificity\": 1.0, \"npv\": 0.9532570242881775, \"accuracy\": 0.9537708759307861, \"f1\": 0.32229920451629457, \"f2\": 0.22913018096906013, \"f0_5\": 0.5431586230755925, \"p4\": 0.4845871600960659, \"phi\": 0.42793459828294705}, {\"truth_threshold\": 40.54460190570353, \"match_probability\": 0.9999999999993765, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1255.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5283.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19195473194122314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8080452680587769, \"precision\": 1.0, \"recall\": 0.19195473194122314, \"specificity\": 1.0, \"npv\": 0.9532486200332642, \"accuracy\": 0.9537621140480042, \"f1\": 0.3220839214679841, \"f2\": 0.22895610610427994, \"f0_5\": 0.5429139989617581, \"p4\": 0.484343239961744, \"phi\": 0.4277622870406039}, {\"truth_threshold\": 40.55427656860889, \"match_probability\": 0.9999999999993806, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1252.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5286.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1914958655834198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8085041046142578, \"precision\": 1.0, \"recall\": 0.1914958655834198, \"specificity\": 1.0, \"npv\": 0.9532232880592346, \"accuracy\": 0.953735888004303, \"f1\": 0.3214377406931964, \"f2\": 0.22843380528390017, \"f0_5\": 0.542179109648363, \"p4\": 0.48361062622208545, \"phi\": 0.4272450560453747}, {\"truth_threshold\": 40.55876540878463, \"match_probability\": 0.9999999999993826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1249.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5289.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19103701412677765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8089630007743835, \"precision\": 1.0, \"recall\": 0.19103701412677765, \"specificity\": 1.0, \"npv\": 0.9531980156898499, \"accuracy\": 0.953709602355957, \"f1\": 0.32079106202645435, \"f2\": 0.227911390095252, \"f0_5\": 0.5414426911739206, \"p4\": 0.48287672981932145, \"phi\": 0.42672717488503975}, {\"truth_threshold\": 40.56578723559416, \"match_probability\": 0.9999999999993856, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1248.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5290.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.190884068608284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8091159462928772, \"precision\": 1.0, \"recall\": 0.190884068608284, \"specificity\": 1.0, \"npv\": 0.9531895518302917, \"accuracy\": 0.953700840473175, \"f1\": 0.3205753917287439, \"f2\": 0.22773722627737225, \"f0_5\": 0.5411968777103209, \"p4\": 0.4826318120567378, \"phi\": 0.42655444806841747}, {\"truth_threshold\": 40.565878868228616, \"match_probability\": 0.9999999999993856, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1247.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5291.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19073110818862915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8092688918113708, \"precision\": 1.0, \"recall\": 0.19073110818862915, \"specificity\": 1.0, \"npv\": 0.9531811475753784, \"accuracy\": 0.9536921381950378, \"f1\": 0.3203596660244059, \"f2\": 0.22756304974634112, \"f0_5\": 0.540950893631789, \"p4\": 0.48238675126802916, \"phi\": 0.426381654339026}, {\"truth_threshold\": 40.576641060605574, \"match_probability\": 0.9999999999993902, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1246.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5292.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1905781626701355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8094218373298645, \"precision\": 1.0, \"recall\": 0.1905781626701355, \"specificity\": 1.0, \"npv\": 0.9531726837158203, \"accuracy\": 0.9536833763122559, \"f1\": 0.32014388489208634, \"f2\": 0.22738886050076648, \"f0_5\": 0.5407047387606319, \"p4\": 0.4821415473257929, \"phi\": 0.4262087428074138}, {\"truth_threshold\": 40.579222925739124, \"match_probability\": 0.9999999999993913, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1245.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5293.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.19042520225048065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8095747828483582, \"precision\": 1.0, \"recall\": 0.19042520225048065, \"specificity\": 1.0, \"npv\": 0.953164279460907, \"accuracy\": 0.9536746144294739, \"f1\": 0.31992804831042015, \"f2\": 0.22721465853925613, \"f0_5\": 0.5404584129189095, \"p4\": 0.4818962001024748, \"phi\": 0.4260357895736691}, {\"truth_threshold\": 40.58493746513779, \"match_probability\": 0.9999999999993937, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1244.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5294.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.190272256731987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8097277283668518, \"precision\": 1.0, \"recall\": 0.190272256731987, \"specificity\": 1.0, \"npv\": 0.9531558156013489, \"accuracy\": 0.9536658525466919, \"f1\": 0.31971215625803134, \"f2\": 0.22704044386041758, \"f0_5\": 0.540211915928435, \"p4\": 0.4816507094703692, \"phi\": 0.42586276916204496}, {\"truth_threshold\": 40.59609674430352, \"match_probability\": 0.9999999999993984, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1241.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5297.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18981340527534485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8101866245269775, \"precision\": 1.0, \"recall\": 0.18981340527534485, \"specificity\": 1.0, \"npv\": 0.9531305432319641, \"accuracy\": 0.9536396265029907, \"f1\": 0.31906414706260444, \"f2\": 0.2265177235060052, \"f0_5\": 0.539471396278908, \"p4\": 0.48091337584199284, \"phi\": 0.4253433294936825}, {\"truth_threshold\": 40.59830034592099, \"match_probability\": 0.9999999999993993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1238.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5300.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1893545389175415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8106454610824585, \"precision\": 1.0, \"recall\": 0.1893545389175415, \"specificity\": 1.0, \"npv\": 0.9531052112579346, \"accuracy\": 0.9536133408546448, \"f1\": 0.3184156378600823, \"f2\": 0.22599488864549105, \"f0_5\": 0.5387293298520452, \"p4\": 0.48017474692252815, \"phi\": 0.424823256838603}, {\"truth_threshold\": 40.6020997396484, \"match_probability\": 0.9999999999994008, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1237.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5301.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18920159339904785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8107984066009521, \"precision\": 1.0, \"recall\": 0.18920159339904785, \"specificity\": 1.0, \"npv\": 0.9530968070030212, \"accuracy\": 0.9536045789718628, \"f1\": 0.3181993569131833, \"f2\": 0.22582058490634926, \"f0_5\": 0.5384816298102038, \"p4\": 0.4799282488403732, \"phi\": 0.4246497638868845}, {\"truth_threshold\": 40.61269325483421, \"match_probability\": 0.9999999999994053, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1236.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5302.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.189048632979393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8109513521194458, \"precision\": 1.0, \"recall\": 0.189048632979393, \"specificity\": 1.0, \"npv\": 0.9530883431434631, \"accuracy\": 0.9535958170890808, \"f1\": 0.31798302032415743, \"f2\": 0.22564626843873228, \"f0_5\": 0.5382337571851594, \"p4\": 0.4796816063223022, \"phi\": 0.42447622860211687}, {\"truth_threshold\": 40.6285182219959, \"match_probability\": 0.9999999999994117, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1235.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5303.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18889568746089935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8111042976379395, \"precision\": 1.0, \"recall\": 0.18889568746089935, \"specificity\": 1.0, \"npv\": 0.9530799388885498, \"accuracy\": 0.9535871148109436, \"f1\": 0.31776662807152967, \"f2\": 0.22547193924124584, \"f0_5\": 0.5379857117964802, \"p4\": 0.47943481923923537, \"phi\": 0.42430259990033176}, {\"truth_threshold\": 40.62949080329005, \"match_probability\": 0.9999999999994121, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1234.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5304.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1887427419424057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8112572431564331, \"precision\": 1.0, \"recall\": 0.1887427419424057, \"specificity\": 1.0, \"npv\": 0.9530714750289917, \"accuracy\": 0.9535783529281616, \"f1\": 0.3175501801338137, \"f2\": 0.22529759731249543, \"f0_5\": 0.5377374934634827, \"p4\": 0.47918788746193886, \"phi\": 0.42412890319325697}, {\"truth_threshold\": 40.63558784004002, \"match_probability\": 0.9999999999994146, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1233.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5305.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18858978152275085, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8114101886749268, \"precision\": 1.0, \"recall\": 0.18858978152275085, \"specificity\": 1.0, \"npv\": 0.9530630707740784, \"accuracy\": 0.9535695910453796, \"f1\": 0.3173336764895123, \"f2\": 0.22512324265108635, \"f0_5\": 0.537489102005231, \"p4\": 0.4789408108610249, \"phi\": 0.4239551383972243}, {\"truth_threshold\": 40.64013730526273, \"match_probability\": 0.9999999999994165, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1232.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5306.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1884368360042572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8115631937980652, \"precision\": 1.0, \"recall\": 0.1884368360042572, \"specificity\": 1.0, \"npv\": 0.9530546069145203, \"accuracy\": 0.9535608291625977, \"f1\": 0.3171171171171171, \"f2\": 0.2249488752556237, \"f0_5\": 0.5372405372405372, \"p4\": 0.4786935893069516, \"phi\": 0.42378130542839604}, {\"truth_threshold\": 40.64541910261598, \"match_probability\": 0.9999999999994186, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1231.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5307.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18828387558460236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8117161393165588, \"precision\": 1.0, \"recall\": 0.18828387558460236, \"specificity\": 1.0, \"npv\": 0.9530462026596069, \"accuracy\": 0.9535520672798157, \"f1\": 0.3169005019951088, \"f2\": 0.22477449512471243, \"f0_5\": 0.5369917989879602, \"p4\": 0.47844622267002224, \"phi\": 0.4236074042027633}, {\"truth_threshold\": 40.64738061894926, \"match_probability\": 0.9999999999994194, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1230.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5308.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1881309300661087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8118690848350525, \"precision\": 1.0, \"recall\": 0.1881309300661087, \"specificity\": 1.0, \"npv\": 0.9530377984046936, \"accuracy\": 0.9535433053970337, \"f1\": 0.31668383110195675, \"f2\": 0.22460010225695712, \"f0_5\": 0.5367428870658055, \"p4\": 0.47819871082038556, \"phi\": 0.4234334346361467}, {\"truth_threshold\": 40.647935675823135, \"match_probability\": 0.9999999999994196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1227.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5311.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18767206370830536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8123279213905334, \"precision\": 1.0, \"recall\": 0.18767206370830536, \"specificity\": 1.0, \"npv\": 0.9530124664306641, \"accuracy\": 0.9535170793533325, \"f1\": 0.3160334835801674, \"f2\": 0.22407684721867124, \"f0_5\": 0.5359951074611218, \"p4\": 0.47745530269439224, \"phi\": 0.42291114064379887}, {\"truth_threshold\": 40.64917390077232, \"match_probability\": 0.99999999999942, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1226.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5312.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1875191181898117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8124808669090271, \"precision\": 1.0, \"recall\": 0.1875191181898117, \"specificity\": 1.0, \"npv\": 0.9530040621757507, \"accuracy\": 0.9535083174705505, \"f1\": 0.315816589386914, \"f2\": 0.22390240338958287, \"f0_5\": 0.5357454990386296, \"p4\": 0.47720720869231, \"phi\": 0.4227368968783388}, {\"truth_threshold\": 40.655285131558685, \"match_probability\": 0.9999999999994225, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1225.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5313.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18736617267131805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8126338124275208, \"precision\": 1.0, \"recall\": 0.18736617267131805, \"specificity\": 1.0, \"npv\": 0.9529955983161926, \"accuracy\": 0.9534995555877686, \"f1\": 0.3155996393146979, \"f2\": 0.22372794681667094, \"f0_5\": 0.5354957160342717, \"p4\": 0.4769589688259345, \"phi\": 0.4225625843484278}, {\"truth_threshold\": 40.67516910930526, \"match_probability\": 0.9999999999994305, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1222.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5316.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1869073063135147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8130927085876465, \"precision\": 1.0, \"recall\": 0.1869073063135147, \"specificity\": 1.0, \"npv\": 0.9529703259468079, \"accuracy\": 0.9534733295440674, \"f1\": 0.3149484536082474, \"f2\": 0.22320450062102726, \"f0_5\": 0.5347453176964817, \"p4\": 0.47621337273241987, \"phi\": 0.42203923331896037}, {\"truth_threshold\": 40.686823978355996, \"match_probability\": 0.999999999999435, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1219.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5319.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18644845485687256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8135515451431274, \"precision\": 1.0, \"recall\": 0.18644845485687256, \"specificity\": 1.0, \"npv\": 0.9529450535774231, \"accuracy\": 0.9534470438957214, \"f1\": 0.3142967642129689, \"f2\": 0.22268093968068395, \"f0_5\": 0.5339933415104258, \"p4\": 0.47546645914262303, \"phi\": 0.42151528601190225}, {\"truth_threshold\": 40.69033811818492, \"match_probability\": 0.9999999999994363, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1217.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5321.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18614254891872406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8138574361801147, \"precision\": 1.0, \"recall\": 0.18614254891872406, \"specificity\": 1.0, \"npv\": 0.9529281854629517, \"accuracy\": 0.9534295201301575, \"f1\": 0.31386202450032236, \"f2\": 0.2223318352880997, \"f0_5\": 0.5334911450113975, \"p4\": 0.47496778305331666, \"phi\": 0.4211656240278591}, {\"truth_threshold\": 40.69309232596282, \"match_probability\": 0.9999999999994374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1215.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5323.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18583664298057556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.814163327217102, \"precision\": 1.0, \"recall\": 0.18583664298057556, \"specificity\": 1.0, \"npv\": 0.9529113173484802, \"accuracy\": 0.9534120559692383, \"f1\": 0.3134270604927125, \"f2\": 0.22198267986991632, \"f0_5\": 0.5329882435515003, \"p4\": 0.47446851877583457, \"phi\": 0.4208156838928329}, {\"truth_threshold\": 40.69563241785443, \"match_probability\": 0.9999999999994384, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1214.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5324.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1856836974620819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8143163323402405, \"precision\": 1.0, \"recall\": 0.1856836974620819, \"specificity\": 1.0, \"npv\": 0.9529028534889221, \"accuracy\": 0.9534032940864563, \"f1\": 0.31320949432404543, \"f2\": 0.22180808302272895, \"f0_5\": 0.5327365279971915, \"p4\": 0.4742186657359273, \"phi\": 0.4206406093015797}, {\"truth_threshold\": 40.71074088963214, \"match_probability\": 0.9999999999994443, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1213.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5325.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18553073704242706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8144692778587341, \"precision\": 1.0, \"recall\": 0.18553073704242706, \"specificity\": 1.0, \"npv\": 0.9528944492340088, \"accuracy\": 0.9533945322036743, \"f1\": 0.312991872016514, \"f2\": 0.2216334734149461, \"f0_5\": 0.5324846356453029, \"p4\": 0.4739686652519385, \"phi\": 0.42046546491167663}, {\"truth_threshold\": 40.720085461578975, \"match_probability\": 0.9999999999994479, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1211.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5327.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18522484600543976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8147751688957214, \"precision\": 1.0, \"recall\": 0.18522484600543976, \"specificity\": 1.0, \"npv\": 0.9528775811195374, \"accuracy\": 0.9533770084381104, \"f1\": 0.31255645889792233, \"f2\": 0.22128421591199796, \"f0_5\": 0.531980319803198, \"p4\": 0.47346822142085054, \"phi\": 0.42011499215087017}, {\"truth_threshold\": 40.72090965437123, \"match_probability\": 0.9999999999994482, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1207.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5331.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18461303412914276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.815386950969696, \"precision\": 1.0, \"recall\": 0.18461303412914276, \"specificity\": 1.0, \"npv\": 0.9528438448905945, \"accuracy\": 0.9533420205116272, \"f1\": 0.3116849580374435, \"f2\": 0.22058554771738734, \"f0_5\": 0.530969558331867, \"p4\": 0.47246555858124306, \"phi\": 0.4194131537034739}, {\"truth_threshold\": 40.72271353129822, \"match_probability\": 0.9999999999994489, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1206.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5332.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18446007370948792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8155398964881897, \"precision\": 1.0, \"recall\": 0.18446007370948792, \"specificity\": 1.0, \"npv\": 0.9528354406356812, \"accuracy\": 0.9533332586288452, \"f1\": 0.3114669421487603, \"f2\": 0.22041084874625338, \"f0_5\": 0.5307164231649357, \"p4\": 0.47221452226480487, \"phi\": 0.4192375182778729}, {\"truth_threshold\": 40.730811990733336, \"match_probability\": 0.999999999999452, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1205.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5333.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18430712819099426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8156929016113281, \"precision\": 1.0, \"recall\": 0.18430712819099426, \"specificity\": 1.0, \"npv\": 0.9528270363807678, \"accuracy\": 0.9533244967460632, \"f1\": 0.3112488699470489, \"f2\": 0.2202361370033264, \"f0_5\": 0.5304631097024124, \"p4\": 0.47196333743840063, \"phi\": 0.4190618123498123}, {\"truth_threshold\": 40.73464554934212, \"match_probability\": 0.9999999999994534, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1204.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5334.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1841541826725006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8158458471298218, \"precision\": 1.0, \"recall\": 0.1841541826725006, \"specificity\": 1.0, \"npv\": 0.9528185725212097, \"accuracy\": 0.953315794467926, \"f1\": 0.31103074141048825, \"f2\": 0.22006141248720573, \"f0_5\": 0.530209617755857, \"p4\": 0.4717120039680734, \"phi\": 0.41888606166897757}, {\"truth_threshold\": 40.749478806568, \"match_probability\": 0.999999999999459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1203.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5335.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18400122225284576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8159987926483154, \"precision\": 1.0, \"recall\": 0.18400122225284576, \"specificity\": 1.0, \"npv\": 0.9528101682662964, \"accuracy\": 0.953307032585144, \"f1\": 0.3108125565172458, \"f2\": 0.21988667519649058, \"f0_5\": 0.5299559471365639, \"p4\": 0.47146052171970493, \"phi\": 0.4187102144800308}, {\"truth_threshold\": 40.74992081368104, \"match_probability\": 0.9999999999994592, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1193.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5345.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18247170746326447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8175283074378967, \"precision\": 1.0, \"recall\": 0.18247170746326447, \"specificity\": 1.0, \"npv\": 0.952725887298584, \"accuracy\": 0.953219473361969, \"f1\": 0.3086276031561247, \"f2\": 0.21813859937831415, \"f0_5\": 0.5274093722369585, \"p4\": 0.4689374868220679, \"phi\": 0.41694786142359114}, {\"truth_threshold\": 40.753319390142906, \"match_probability\": 0.9999999999994604, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1190.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5348.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18201284110546112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8179871439933777, \"precision\": 1.0, \"recall\": 0.18201284110546112, \"specificity\": 1.0, \"npv\": 0.9527006149291992, \"accuracy\": 0.9531932473182678, \"f1\": 0.3079710144927536, \"f2\": 0.21761392729134665, \"f0_5\": 0.5266418835192069, \"p4\": 0.46817765237064757, \"phi\": 0.4164177542824591}, {\"truth_threshold\": 40.756089104688826, \"match_probability\": 0.9999999999994615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1187.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5351.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18155398964881897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8184459805488586, \"precision\": 1.0, \"recall\": 0.18155398964881897, \"specificity\": 1.0, \"npv\": 0.9526753425598145, \"accuracy\": 0.9531669616699219, \"f1\": 0.3073139158576052, \"f2\": 0.2170891400563298, \"f0_5\": 0.5258727627148679, \"p4\": 0.4674164618634846, \"phi\": 0.4158870256494556}, {\"truth_threshold\": 40.76699432703998, \"match_probability\": 0.9999999999994655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1186.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5352.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18140104413032532, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8185989856719971, \"precision\": 1.0, \"recall\": 0.18140104413032532, \"specificity\": 1.0, \"npv\": 0.9526668787002563, \"accuracy\": 0.9531582593917847, \"f1\": 0.30709476954945625, \"f2\": 0.2169141853829834, \"f0_5\": 0.5256160255273887, \"p4\": 0.4671624297110234, \"phi\": 0.4157099631216495}, {\"truth_threshold\": 40.77146443391723, \"match_probability\": 0.9999999999994672, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1182.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5356.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18078923225402832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8192107677459717, \"precision\": 1.0, \"recall\": 0.18078923225402832, \"specificity\": 1.0, \"npv\": 0.9526332020759583, \"accuracy\": 0.9531232118606567, \"f1\": 0.3062176165803109, \"f2\": 0.21621423867710543, \"f0_5\": 0.5245872536836499, \"p4\": 0.466144787528092, \"phi\": 0.41500098894162807}, {\"truth_threshold\": 40.77437385740558, \"match_probability\": 0.9999999999994683, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1181.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5357.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18063628673553467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8193637132644653, \"precision\": 1.0, \"recall\": 0.18063628673553467, \"specificity\": 1.0, \"npv\": 0.9526247978210449, \"accuracy\": 0.9531144499778748, \"f1\": 0.30599818629356135, \"f2\": 0.2160392199904877, \"f0_5\": 0.524329603977979, \"p4\": 0.46588999790171015, \"phi\": 0.41482356391494285}, {\"truth_threshold\": 40.77778417578815, \"match_probability\": 0.9999999999994695, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1180.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5358.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18048332631587982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.819516658782959, \"precision\": 1.0, \"recall\": 0.18048332631587982, \"specificity\": 1.0, \"npv\": 0.9526163339614868, \"accuracy\": 0.9531056880950928, \"f1\": 0.30577869914485617, \"f2\": 0.21586418849699984, \"f0_5\": 0.5240717711849352, \"p4\": 0.465635056367535, \"phi\": 0.4146460661091039}, {\"truth_threshold\": 40.78548375833815, \"match_probability\": 0.9999999999994723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1179.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5359.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18033038079738617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8196696043014526, \"precision\": 1.0, \"recall\": 0.18033038079738617, \"specificity\": 1.0, \"npv\": 0.9526079297065735, \"accuracy\": 0.9530969858169556, \"f1\": 0.3055591551120902, \"f2\": 0.2156891441952362, \"f0_5\": 0.5238137551092945, \"p4\": 0.4653799627875075, \"phi\": 0.41446852153863256}, {\"truth_threshold\": 40.78725378349293, \"match_probability\": 0.999999999999473, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1177.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5361.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.18002447485923767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8199755549430847, \"precision\": 1.0, \"recall\": 0.18002447485923767, \"specificity\": 1.0, \"npv\": 0.952591061592102, \"accuracy\": 0.9530794620513916, \"f1\": 0.3051198963058976, \"f2\": 0.21533901716125728, \"f0_5\": 0.5232971723279388, \"p4\": 0.4648693189368228, \"phi\": 0.4141131612098476}, {\"truth_threshold\": 40.78759093348507, \"match_probability\": 0.9999999999994731, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1175.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5363.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17971856892108917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.820281445980072, \"precision\": 1.0, \"recall\": 0.17971856892108917, \"specificity\": 1.0, \"npv\": 0.9525742530822754, \"accuracy\": 0.9530619382858276, \"f1\": 0.3046804096979126, \"f2\": 0.21498883887730083, \"f0_5\": 0.5227798540665599, \"p4\": 0.4643580652418334, \"phi\": 0.41375750826212504}, {\"truth_threshold\": 40.79278865530862, \"match_probability\": 0.999999999999475, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1172.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5366.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17925971746444702, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.820740282535553, \"precision\": 1.0, \"recall\": 0.17925971746444702, \"specificity\": 1.0, \"npv\": 0.9525489807128906, \"accuracy\": 0.9530357122421265, \"f1\": 0.3040207522697795, \"f2\": 0.21446347533304055, \"f0_5\": 0.52200249420987, \"p4\": 0.4635900388112952, \"phi\": 0.41322350471077796}, {\"truth_threshold\": 40.795492864237, \"match_probability\": 0.999999999999476, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1171.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5367.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17910675704479218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8208932280540466, \"precision\": 1.0, \"recall\": 0.17910675704479218, \"specificity\": 1.0, \"npv\": 0.9525405168533325, \"accuracy\": 0.9530269503593445, \"f1\": 0.3038007523673628, \"f2\": 0.21428832851443838, \"f0_5\": 0.5217430048119764, \"p4\": 0.4633337238741943, \"phi\": 0.41304534767926565}, {\"truth_threshold\": 40.796034314812275, \"match_probability\": 0.9999999999994762, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1170.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5368.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17895381152629852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8210461735725403, \"precision\": 1.0, \"recall\": 0.17895381152629852, \"specificity\": 1.0, \"npv\": 0.9525321125984192, \"accuracy\": 0.9530181884765625, \"f1\": 0.3035806953814219, \"f2\": 0.21411316887489934, \"f0_5\": 0.5214833303619183, \"p4\": 0.4630772556411504, \"phi\": 0.41286711692373507}, {\"truth_threshold\": 40.79674167043403, \"match_probability\": 0.9999999999994764, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1169.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5369.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17880085110664368, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8211991190910339, \"precision\": 1.0, \"recall\": 0.17880085110664368, \"specificity\": 1.0, \"npv\": 0.9525237083435059, \"accuracy\": 0.9530094265937805, \"f1\": 0.3033605812897366, \"f2\": 0.21393799641301564, \"f0_5\": 0.521223470661673, \"p4\": 0.4628206339724198, \"phi\": 0.41268881234858346}, {\"truth_threshold\": 40.80135264692655, \"match_probability\": 0.9999999999994781, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1165.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5373.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17818905413150787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8218109607696533, \"precision\": 1.0, \"recall\": 0.17818905413150787, \"specificity\": 1.0, \"npv\": 0.9524900317192078, \"accuracy\": 0.9529744386672974, \"f1\": 0.3024795534207452, \"f2\": 0.21323717831387048, \"f0_5\": 0.5201821753884622, \"p4\": 0.4617926101398063, \"phi\": 0.4119748539325272}, {\"truth_threshold\": 40.80578681003704, \"match_probability\": 0.9999999999994797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1164.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5374.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17803609371185303, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.821963906288147, \"precision\": 1.0, \"recall\": 0.17803609371185303, \"specificity\": 1.0, \"npv\": 0.9524815678596497, \"accuracy\": 0.9529656767845154, \"f1\": 0.30225915346663207, \"f2\": 0.21306194171913898, \"f0_5\": 0.5199213864570306, \"p4\": 0.4615352191905328, \"phi\": 0.41179617881803626}, {\"truth_threshold\": 40.81566312156121, \"match_probability\": 0.9999999999994833, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1163.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5375.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17788314819335938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8221168518066406, \"precision\": 1.0, \"recall\": 0.17788314819335938, \"specificity\": 1.0, \"npv\": 0.9524731636047363, \"accuracy\": 0.9529569149017334, \"f1\": 0.3020386962732113, \"f2\": 0.21288669229361157, \"f0_5\": 0.5196604110813227, \"p4\": 0.4612776739635342, \"phi\": 0.4116174555912104}, {\"truth_threshold\": 40.81741763522458, \"match_probability\": 0.9999999999994839, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1162.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5376.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17773018777370453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8222697973251343, \"precision\": 1.0, \"recall\": 0.17773018777370453, \"specificity\": 1.0, \"npv\": 0.952464759349823, \"accuracy\": 0.9529481530189514, \"f1\": 0.3018181818181818, \"f2\": 0.21271143003587903, \"f0_5\": 0.5193992490613266, \"p4\": 0.4610199743178723, \"phi\": 0.4114386315957373}, {\"truth_threshold\": 40.826092494166446, \"match_probability\": 0.999999999999487, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17757724225521088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8224227428436279, \"precision\": 1.0, \"recall\": 0.17757724225521088, \"specificity\": 1.0, \"npv\": 0.9524562954902649, \"accuracy\": 0.9529394507408142, \"f1\": 0.3015976100792311, \"f2\": 0.2125361549445319, \"f0_5\": 0.5191379001967448, \"p4\": 0.4607621201124372, \"phi\": 0.41125973300840757}, {\"truth_threshold\": 40.832765599558016, \"match_probability\": 0.9999999999994894, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1160.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5378.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17742428183555603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8225756883621216, \"precision\": 1.0, \"recall\": 0.17742428183555603, \"specificity\": 1.0, \"npv\": 0.9524478912353516, \"accuracy\": 0.9529306888580322, \"f1\": 0.3013769810340348, \"f2\": 0.2123608670181605, \"f0_5\": 0.5188763642869924, \"p4\": 0.460504111205947, \"phi\": 0.41108075973175234}, {\"truth_threshold\": 40.83738365493138, \"match_probability\": 0.999999999999491, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1159.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5379.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17727133631706238, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8227286338806152, \"precision\": 1.0, \"recall\": 0.17727133631706238, \"specificity\": 1.0, \"npv\": 0.9524394869804382, \"accuracy\": 0.9529219269752502, \"f1\": 0.30115629466025723, \"f2\": 0.21218556625535498, \"f0_5\": 0.5186146411311974, \"p4\": 0.4602459474569476, \"phi\": 0.41090171166809175}, {\"truth_threshold\": 40.844237948178574, \"match_probability\": 0.9999999999994934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1158.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5380.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17711839079856873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8228816390037537, \"precision\": 1.0, \"recall\": 0.17711839079856873, \"specificity\": 1.0, \"npv\": 0.9524310827255249, \"accuracy\": 0.9529131650924683, \"f1\": 0.3009355509355509, \"f2\": 0.21201025265470524, \"f0_5\": 0.5183527305282005, \"p4\": 0.45998762872381244, \"phi\": 0.4107225887195354}, {\"truth_threshold\": 40.844898371646686, \"match_probability\": 0.9999999999994936, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1157.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5381.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17696543037891388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8230345845222473, \"precision\": 1.0, \"recall\": 0.17696543037891388, \"specificity\": 1.0, \"npv\": 0.9524226188659668, \"accuracy\": 0.9529044032096863, \"f1\": 0.30071474983755686, \"f2\": 0.211834926214801, \"f0_5\": 0.5180906322765538, \"p4\": 0.45972915486474214, \"phi\": 0.41054339078798063}, {\"truth_threshold\": 40.84565127091498, \"match_probability\": 0.9999999999994938, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1156.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5382.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17681248486042023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.823187530040741, \"precision\": 1.0, \"recall\": 0.17681248486042023, \"specificity\": 1.0, \"npv\": 0.9524142146110535, \"accuracy\": 0.9528956413269043, \"f1\": 0.30049389134390436, \"f2\": 0.21165958693423173, \"f0_5\": 0.5178283461745207, \"p4\": 0.4594705257377644, \"phi\": 0.4103641441389868}, {\"truth_threshold\": 40.85188322462649, \"match_probability\": 0.9999999999994961, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1155.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5383.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17665952444076538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8233404755592346, \"precision\": 1.0, \"recall\": 0.17665952444076538, \"specificity\": 1.0, \"npv\": 0.9524058103561401, \"accuracy\": 0.9528869390487671, \"f1\": 0.3002729754322111, \"f2\": 0.21148423481158676, \"f0_5\": 0.5175658720200753, \"p4\": 0.45921174120073366, \"phi\": 0.4101847959575714}, {\"truth_threshold\": 40.85587308622955, \"match_probability\": 0.9999999999994975, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1153.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5385.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17635361850261688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8236463665962219, \"precision\": 1.0, \"recall\": 0.17635361850261688, \"specificity\": 1.0, \"npv\": 0.9523889422416687, \"accuracy\": 0.9528694152832031, \"f1\": 0.29983097126511504, \"f2\": 0.21113349203442594, \"f0_5\": 0.5170403587443946, \"p4\": 0.45869370532706266, \"phi\": 0.4098258736600797}, {\"truth_threshold\": 40.860839915515704, \"match_probability\": 0.9999999999994992, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1151.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5387.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17604772746562958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8239522576332092, \"precision\": 1.0, \"recall\": 0.17604772746562958, \"specificity\": 1.0, \"npv\": 0.952372133731842, \"accuracy\": 0.9528518915176392, \"f1\": 0.2993887371569775, \"f2\": 0.21078269787202872, \"f0_5\": 0.5165140908274996, \"p4\": 0.4581750461030889, \"phi\": 0.4094666494555913}, {\"truth_threshold\": 40.864573838308715, \"match_probability\": 0.9999999999995005, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1148.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5390.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17558886110782623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.824411153793335, \"precision\": 1.0, \"recall\": 0.17558886110782623, \"specificity\": 1.0, \"npv\": 0.9523468613624573, \"accuracy\": 0.952825665473938, \"f1\": 0.2987249544626594, \"f2\": 0.21025641025641026, \"f0_5\": 0.5157232704402516, \"p4\": 0.4573958859832933, \"phi\": 0.4089272453311282}, {\"truth_threshold\": 40.86678918184689, \"match_probability\": 0.9999999999995013, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1147.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5391.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17543591558933258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8245640993118286, \"precision\": 1.0, \"recall\": 0.17543591558933258, \"specificity\": 1.0, \"npv\": 0.952338457107544, \"accuracy\": 0.952816903591156, \"f1\": 0.2985035783994795, \"f2\": 0.21008095534634968, \"f0_5\": 0.5154592845586914, \"p4\": 0.4571358530277164, \"phi\": 0.40874731860436386}, {\"truth_threshold\": 40.879505450193705, \"match_probability\": 0.9999999999995056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1146.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5392.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17528295516967773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8247170448303223, \"precision\": 1.0, \"recall\": 0.17528295516967773, \"specificity\": 1.0, \"npv\": 0.9523299932479858, \"accuracy\": 0.952808141708374, \"f1\": 0.2982821447162936, \"f2\": 0.20990548758150782, \"f0_5\": 0.5151951087933825, \"p4\": 0.4568756633749352, \"phi\": 0.40856728934670167}, {\"truth_threshold\": 40.88069350367199, \"match_probability\": 0.9999999999995061, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1145.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5393.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17513000965118408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8248699903488159, \"precision\": 1.0, \"recall\": 0.17513000965118408, \"specificity\": 1.0, \"npv\": 0.9523215889930725, \"accuracy\": 0.952799379825592, \"f1\": 0.2980606533906026, \"f2\": 0.20973000696047184, \"f0_5\": 0.5149307429393776, \"p4\": 0.45661531688105644, \"phi\": 0.40838718391208634}, {\"truth_threshold\": 40.90504851503324, \"match_probability\": 0.9999999999995143, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1144.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5394.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17497706413269043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8250229358673096, \"precision\": 1.0, \"recall\": 0.17497706413269043, \"specificity\": 1.0, \"npv\": 0.9523131847381592, \"accuracy\": 0.9527906179428101, \"f1\": 0.29783910439989586, \"f2\": 0.20955451348182885, \"f0_5\": 0.5146661867914343, \"p4\": 0.45635481340201123, \"phi\": 0.4082070021996031}, {\"truth_threshold\": 40.91355473231363, \"match_probability\": 0.9999999999995172, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1143.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5395.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17482410371303558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8251758813858032, \"precision\": 1.0, \"recall\": 0.17482410371303558, \"specificity\": 1.0, \"npv\": 0.9523047804832458, \"accuracy\": 0.9527819156646729, \"f1\": 0.2976174977216508, \"f2\": 0.2093790071441656, \"f0_5\": 0.5144014401440145, \"p4\": 0.4560941527935538, \"phi\": 0.40802674410811607}, {\"truth_threshold\": 40.91681812242578, \"match_probability\": 0.9999999999995183, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1137.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5401.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17390640079975128, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8260936141014099, \"precision\": 1.0, \"recall\": 0.17390640079975128, \"specificity\": 1.0, \"npv\": 0.9522542357444763, \"accuracy\": 0.952729344367981, \"f1\": 0.29628664495114004, \"f2\": 0.2083256989995969, \"f0_5\": 0.512808948222984, \"p4\": 0.45452688132509445, \"phi\": 0.40694361248949923}, {\"truth_threshold\": 40.91760156537633, \"match_probability\": 0.9999999999995185, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1136.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5402.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17375344038009644, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8262465596199036, \"precision\": 1.0, \"recall\": 0.17375344038009644, \"specificity\": 1.0, \"npv\": 0.952245831489563, \"accuracy\": 0.9527206420898438, \"f1\": 0.29606463382851184, \"f2\": 0.20815010260920552, \"f0_5\": 0.512542862299224, \"p4\": 0.45426511675699344, \"phi\": 0.4067628169060552}, {\"truth_threshold\": 40.92433283914109, \"match_probability\": 0.9999999999995207, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1133.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5405.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17329458892345428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8267053961753845, \"precision\": 1.0, \"recall\": 0.17329458892345428, \"specificity\": 1.0, \"npv\": 0.9522205591201782, \"accuracy\": 0.9526943564414978, \"f1\": 0.2953982531612567, \"f2\": 0.207623236210372, \"f0_5\": 0.511743450767841, \"p4\": 0.45347887273054954, \"phi\": 0.40621996656619686}, {\"truth_threshold\": 40.93390337770543, \"match_probability\": 0.9999999999995239, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1132.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5406.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17314162850379944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8268583416938782, \"precision\": 1.0, \"recall\": 0.17314162850379944, \"specificity\": 1.0, \"npv\": 0.9522121548652649, \"accuracy\": 0.9526855945587158, \"f1\": 0.2951760104302477, \"f2\": 0.20744758833015686, \"f0_5\": 0.5114765949756009, \"p4\": 0.4532164741276032, \"phi\": 0.4060388615784564}, {\"truth_threshold\": 40.93619518921342, \"match_probability\": 0.9999999999995247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1131.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5407.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1729886829853058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8270113468170166, \"precision\": 1.0, \"recall\": 0.1729886829853058, \"specificity\": 1.0, \"npv\": 0.9522037506103516, \"accuracy\": 0.9526768326759338, \"f1\": 0.29495370974051377, \"f2\": 0.20727192757394713, \"f0_5\": 0.5112095461941782, \"p4\": 0.45295391665043316, \"phi\": 0.40585770563132534}, {\"truth_threshold\": 40.936716563596924, \"match_probability\": 0.9999999999995248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1130.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5408.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17283572256565094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8271642923355103, \"precision\": 1.0, \"recall\": 0.17283572256565094, \"specificity\": 1.0, \"npv\": 0.9521953463554382, \"accuracy\": 0.9526681303977966, \"f1\": 0.29473135106937925, \"f2\": 0.20709625394032696, \"f0_5\": 0.5109423042141437, \"p4\": 0.4526912001524748, \"phi\": 0.4056764453309754}, {\"truth_threshold\": 40.94377362172949, \"match_probability\": 0.9999999999995272, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1723768711090088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8276231288909912, \"precision\": 1.0, \"recall\": 0.1723768711090088, \"specificity\": 1.0, \"npv\": 0.9521700739860535, \"accuracy\": 0.9526418447494507, \"f1\": 0.29406392694063926, \"f2\": 0.20656915576084167, \"f0_5\": 0.5101394169835235, \"p4\": 0.4519020950655178, \"phi\": 0.40513219710078235}, {\"truth_threshold\": 40.94703599850069, \"match_probability\": 0.9999999999995283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1124.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5414.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17191801965236664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8280819654464722, \"precision\": 1.0, \"recall\": 0.17191801965236664, \"specificity\": 1.0, \"npv\": 0.9521448016166687, \"accuracy\": 0.9526156187057495, \"f1\": 0.29339598016183766, \"f2\": 0.20604194163367062, \"f0_5\": 0.5093347833967736, \"p4\": 0.4511115534977994, \"phi\": 0.40458727240708914}, {\"truth_threshold\": 40.9483984882344, \"match_probability\": 0.9999999999995287, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1123.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5415.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1717650592327118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8282349109649658, \"precision\": 1.0, \"recall\": 0.1717650592327118, \"specificity\": 1.0, \"npv\": 0.9521363973617554, \"accuracy\": 0.9526068568229675, \"f1\": 0.2931732149849889, \"f2\": 0.20586617781851513, \"f0_5\": 0.5090661831368993, \"p4\": 0.4508477197353335, \"phi\": 0.4044054651859272}, {\"truth_threshold\": 40.958666823688226, \"match_probability\": 0.999999999999532, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1121.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5417.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1714591681957245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8285408616065979, \"precision\": 1.0, \"recall\": 0.1714591681957245, \"specificity\": 1.0, \"npv\": 0.9521195888519287, \"accuracy\": 0.9525893330574036, \"f1\": 0.2927275101188145, \"f2\": 0.20551461152055145, \"f0_5\": 0.5085283977499546, \"p4\": 0.45031957146274587, \"phi\": 0.4040416149721833}, {\"truth_threshold\": 40.958798428543005, \"match_probability\": 0.999999999999532, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1119.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5419.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.171153262257576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8288467526435852, \"precision\": 1.0, \"recall\": 0.171153262257576, \"specificity\": 1.0, \"npv\": 0.9521027207374573, \"accuracy\": 0.9525718092918396, \"f1\": 0.29228157241739583, \"f2\": 0.2051629936562649, \"f0_5\": 0.507989831124024, \"p4\": 0.44979078120438687, \"phi\": 0.4036774496875342}, {\"truth_threshold\": 40.965739464827436, \"match_probability\": 0.9999999999995344, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1118.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5420.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17100030183792114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8289996981620789, \"precision\": 1.0, \"recall\": 0.17100030183792114, \"specificity\": 1.0, \"npv\": 0.952094316482544, \"accuracy\": 0.9525631070137024, \"f1\": 0.29205851619644724, \"f2\": 0.204987165383205, \"f0_5\": 0.5077202543142597, \"p4\": 0.44952614495902016, \"phi\": 0.403495248626848}, {\"truth_threshold\": 40.96666667187635, \"match_probability\": 0.9999999999995346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1114.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5424.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17038850486278534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8296114802360535, \"precision\": 1.0, \"recall\": 0.17038850486278534, \"specificity\": 1.0, \"npv\": 0.9520606398582458, \"accuracy\": 0.9525280594825745, \"f1\": 0.29116570831155253, \"f2\": 0.20428372331841854, \"f0_5\": 0.5066399854466073, \"p4\": 0.4484659890591145, \"phi\": 0.40276567927718676}, {\"truth_threshold\": 40.969308713836625, \"match_probability\": 0.9999999999995355, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1112.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5426.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.17008259892463684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8299174308776855, \"precision\": 1.0, \"recall\": 0.17008259892463684, \"specificity\": 1.0, \"npv\": 0.9520438313484192, \"accuracy\": 0.9525105953216553, \"f1\": 0.290718954248366, \"f2\": 0.2039319248826291, \"f0_5\": 0.5060986710358638, \"p4\": 0.44793494246597887, \"phi\": 0.40240040451663545}, {\"truth_threshold\": 40.98087604116566, \"match_probability\": 0.9999999999995391, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1111.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5427.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.169929638504982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8300703763961792, \"precision\": 1.0, \"recall\": 0.169929638504982, \"specificity\": 1.0, \"npv\": 0.9520354270935059, \"accuracy\": 0.9525018334388733, \"f1\": 0.2904954896064845, \"f2\": 0.20375600630891685, \"f0_5\": 0.5058277180841377, \"p4\": 0.44766917648429144, \"phi\": 0.4022176475864237}, {\"truth_threshold\": 40.982598943157804, \"match_probability\": 0.9999999999995397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1110.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5428.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16977669298648834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8302233219146729, \"precision\": 1.0, \"recall\": 0.16977669298648834, \"specificity\": 1.0, \"npv\": 0.9520270228385925, \"accuracy\": 0.9524930715560913, \"f1\": 0.29027196652719667, \"f2\": 0.2035800748294329, \"f0_5\": 0.5055565676808161, \"p4\": 0.44740324851228747, \"phi\": 0.40203481081123593}, {\"truth_threshold\": 40.99001857461471, \"match_probability\": 0.9999999999995421, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1108.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5430.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16947078704833984, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8305292129516602, \"precision\": 1.0, \"recall\": 0.16947078704833984, \"specificity\": 1.0, \"npv\": 0.9520101547241211, \"accuracy\": 0.9524755477905273, \"f1\": 0.2898247449646874, \"f2\": 0.20322817314746883, \"f0_5\": 0.5050136736554239, \"p4\": 0.4468709059955038, \"phi\": 0.40166892421257}, {\"truth_threshold\": 40.99010472039257, \"match_probability\": 0.9999999999995421, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1107.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5431.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1693178415298462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8306821584701538, \"precision\": 1.0, \"recall\": 0.1693178415298462, \"specificity\": 1.0, \"npv\": 0.9520017504692078, \"accuracy\": 0.9524667859077454, \"f1\": 0.2896010464355788, \"f2\": 0.20305220294214754, \"f0_5\": 0.5047419296005836, \"p4\": 0.44660449114934514, \"phi\": 0.401485847259083}, {\"truth_threshold\": 40.99722893547509, \"match_probability\": 0.9999999999995444, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1106.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5432.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16916488111019135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8308351039886475, \"precision\": 1.0, \"recall\": 0.16916488111019135, \"specificity\": 1.0, \"npv\": 0.9519933462142944, \"accuracy\": 0.9524580836296082, \"f1\": 0.2893772893772894, \"f2\": 0.20287621982537238, \"f0_5\": 0.5044699872286079, \"p4\": 0.4463379137101115, \"phi\": 0.4013026900228724}, {\"truth_threshold\": 41.000882387214254, \"match_probability\": 0.9999999999995456, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1105.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5433.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1690119355916977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8309880495071411, \"precision\": 1.0, \"recall\": 0.1690119355916977, \"specificity\": 1.0, \"npv\": 0.9519849419593811, \"accuracy\": 0.9524493217468262, \"f1\": 0.28915347376684547, \"f2\": 0.2027002237957222, \"f0_5\": 0.5041978463223216, \"p4\": 0.4460711735266462, \"phi\": 0.40111945239387736}, {\"truth_threshold\": 41.00839710392957, \"match_probability\": 0.9999999999995479, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1104.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5434.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16885897517204285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8311409950256348, \"precision\": 1.0, \"recall\": 0.16885897517204285, \"specificity\": 1.0, \"npv\": 0.9519765377044678, \"accuracy\": 0.9524405598640442, \"f1\": 0.28892959958126146, \"f2\": 0.20252421485177577, \"f0_5\": 0.5039255066642322, \"p4\": 0.44580427044760523, \"phi\": 0.4009361342617877}, {\"truth_threshold\": 41.01113424358236, \"match_probability\": 0.9999999999995487, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1103.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5435.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1687060296535492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8312940001487732, \"precision\": 1.0, \"recall\": 0.1687060296535492, \"specificity\": 1.0, \"npv\": 0.9519681334495544, \"accuracy\": 0.9524317979812622, \"f1\": 0.28870566679753956, \"f2\": 0.20234819299211154, \"f0_5\": 0.5036529680365297, \"p4\": 0.4455372043214568, \"phi\": 0.4007527355160425}, {\"truth_threshold\": 41.0163655378974, \"match_probability\": 0.9999999999995504, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1101.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5437.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1684001237154007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8315998911857605, \"precision\": 1.0, \"recall\": 0.1684001237154007, \"specificity\": 1.0, \"npv\": 0.951951265335083, \"accuracy\": 0.9524142742156982, \"f1\": 0.28825762534363136, \"f2\": 0.20199611051994276, \"f0_5\": 0.5031072929994517, \"p4\": 0.44500258232077056, \"phi\": 0.40038569574008726}, {\"truth_threshold\": 41.023761851910116, \"match_probability\": 0.9999999999995527, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1100.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5438.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16824716329574585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8317528367042542, \"precision\": 1.0, \"recall\": 0.16824716329574585, \"specificity\": 1.0, \"npv\": 0.9519428610801697, \"accuracy\": 0.9524055123329163, \"f1\": 0.28803351662738935, \"f2\": 0.20182004990459415, \"f0_5\": 0.5028341561528615, \"p4\": 0.4447350261422282, \"phi\": 0.4002020544874972}, {\"truth_threshold\": 41.029439997896866, \"match_probability\": 0.9999999999995545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1098.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5440.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16794127225875854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8320587277412415, \"precision\": 1.0, \"recall\": 0.16794127225875854, \"specificity\": 1.0, \"npv\": 0.951926052570343, \"accuracy\": 0.9523880481719971, \"f1\": 0.28758512310110007, \"f2\": 0.20146788990825687, \"f0_5\": 0.5022872827081427, \"p4\": 0.44419942266731766, \"phi\": 0.39983455573953597}, {\"truth_threshold\": 41.037459569532025, \"match_probability\": 0.9999999999995569, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1096.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5442.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16763536632061005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8323646187782288, \"precision\": 1.0, \"recall\": 0.16763536632061005, \"specificity\": 1.0, \"npv\": 0.9519092440605164, \"accuracy\": 0.9523705244064331, \"f1\": 0.28713649462929003, \"f2\": 0.20111567821491486, \"f0_5\": 0.5017396081303791, \"p4\": 0.44366316335119493, \"phi\": 0.3994667048421678}, {\"truth_threshold\": 41.043834532398805, \"match_probability\": 0.9999999999995589, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1095.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5443.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1674824059009552, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8325175642967224, \"precision\": 1.0, \"recall\": 0.1674824059009552, \"specificity\": 1.0, \"npv\": 0.951900839805603, \"accuracy\": 0.9523617625236511, \"f1\": 0.2869120922311018, \"f2\": 0.20093955297830954, \"f0_5\": 0.5014654698662758, \"p4\": 0.4433947873704258, \"phi\": 0.39928265718893335}, {\"truth_threshold\": 41.04780343460175, \"match_probability\": 0.99999999999956, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1093.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5445.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1671764999628067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8328235149383545, \"precision\": 1.0, \"recall\": 0.1671764999628067, \"specificity\": 1.0, \"npv\": 0.9518839716911316, \"accuracy\": 0.9523442983627319, \"f1\": 0.2864631109946272, \"f2\": 0.20058726371811342, \"f0_5\": 0.500916590284143, \"p4\": 0.44285754199730126, \"phi\": 0.3989143169091153}, {\"truth_threshold\": 41.04870820904034, \"match_probability\": 0.9999999999995604, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1090.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5448.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16671764850616455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8332823514938354, \"precision\": 1.0, \"recall\": 0.16671764850616455, \"specificity\": 1.0, \"npv\": 0.9518587589263916, \"accuracy\": 0.952318012714386, \"f1\": 0.28578919769271105, \"f2\": 0.2000587328389986, \"f0_5\": 0.5000917599559552, \"p4\": 0.4420504381044127, \"phi\": 0.39836121949790104}, {\"truth_threshold\": 41.05163587278847, \"match_probability\": 0.9999999999995612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1085.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1659528911113739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8340471386909485, \"precision\": 1.0, \"recall\": 0.1659528911113739, \"specificity\": 1.0, \"npv\": 0.9518166780471802, \"accuracy\": 0.9522742629051208, \"f1\": 0.2846648301193756, \"f2\": 0.199177589308661, \"f0_5\": 0.49871299871299873, \"p4\": 0.4407019591182226, \"phi\": 0.39743770000768847}, {\"truth_threshold\": 41.054335022389424, \"match_probability\": 0.999999999999562, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1081.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5457.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1653410792350769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8346589207649231, \"precision\": 1.0, \"recall\": 0.1653410792350769, \"specificity\": 1.0, \"npv\": 0.9517830610275269, \"accuracy\": 0.9522392749786377, \"f1\": 0.2837642735267095, \"f2\": 0.19847244152315205, \"f0_5\": 0.4976063340084699, \"p4\": 0.4396201895342649, \"phi\": 0.39669742262286384}, {\"truth_threshold\": 41.05582306114241, \"match_probability\": 0.9999999999995625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1080.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5458.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16518813371658325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8348118662834167, \"precision\": 1.0, \"recall\": 0.16518813371658325, \"specificity\": 1.0, \"npv\": 0.9517746567726135, \"accuracy\": 0.9522305130958557, \"f1\": 0.28353898661065896, \"f2\": 0.19829612220916568, \"f0_5\": 0.4973291582243507, \"p4\": 0.43934933106581914, \"phi\": 0.3965121386979808}, {\"truth_threshold\": 41.05721891625111, \"match_probability\": 0.9999999999995629, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1079.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5459.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1650351732969284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8349648118019104, \"precision\": 1.0, \"recall\": 0.1650351732969284, \"specificity\": 1.0, \"npv\": 0.9517662525177002, \"accuracy\": 0.9522217512130737, \"f1\": 0.28331364054089536, \"f2\": 0.19811978994528295, \"f0_5\": 0.4970517781463055, \"p4\": 0.43907830585643326, \"phi\": 0.3963267714288303}, {\"truth_threshold\": 41.05862948013924, \"match_probability\": 0.9999999999995633, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1078.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5460.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16488222777843475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.835117757320404, \"precision\": 1.0, \"recall\": 0.16488222777843475, \"specificity\": 1.0, \"npv\": 0.9517578482627869, \"accuracy\": 0.9522129893302917, \"f1\": 0.28308823529411764, \"f2\": 0.19794344473007713, \"f0_5\": 0.4967741935483871, \"p4\": 0.43880711374978737, \"phi\": 0.39614132069832725}, {\"truth_threshold\": 41.05977607626782, \"match_probability\": 0.9999999999995637, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1077.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5461.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1647292822599411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8352707028388977, \"precision\": 1.0, \"recall\": 0.1647292822599411, \"specificity\": 1.0, \"npv\": 0.9517494440078735, \"accuracy\": 0.9522042274475098, \"f1\": 0.2828627708470125, \"f2\": 0.19776708656212127, \"f0_5\": 0.49649640420431496, \"p4\": 0.4385357545893661, \"phi\": 0.3959557863891141}, {\"truth_threshold\": 41.0718489085684, \"match_probability\": 0.9999999999995673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1074.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5464.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16427041590213776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8357295989990234, \"precision\": 1.0, \"recall\": 0.16427041590213776, \"specificity\": 1.0, \"npv\": 0.9517241716384888, \"accuracy\": 0.9521780014038086, \"f1\": 0.28218602207041515, \"f2\": 0.19723793432748107, \"f0_5\": 0.4956618054273583, \"p4\": 0.4377206732173586, \"phi\": 0.3953987081534374}, {\"truth_threshold\": 41.07470768815281, \"match_probability\": 0.9999999999995682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1070.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16365860402584076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.836341381072998, \"precision\": 1.0, \"recall\": 0.16365860402584076, \"specificity\": 1.0, \"npv\": 0.9516905546188354, \"accuracy\": 0.9521429538726807, \"f1\": 0.2812828601472135, \"f2\": 0.1965322165895232, \"f0_5\": 0.49454612682566096, \"p4\": 0.4366315497722345, \"phi\": 0.3946547234976468}, {\"truth_threshold\": 41.08960830160545, \"match_probability\": 0.9999999999995727, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1069.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5469.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1635056585073471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8364943265914917, \"precision\": 1.0, \"recall\": 0.1635056585073471, \"specificity\": 1.0, \"npv\": 0.9516821503639221, \"accuracy\": 0.9521342515945435, \"f1\": 0.2810569212567372, \"f2\": 0.19635575474817238, \"f0_5\": 0.4942666913260588, \"p4\": 0.4363588485235043, \"phi\": 0.39446851631363333}, {\"truth_threshold\": 41.0993269869128, \"match_probability\": 0.9999999999995756, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1068.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5470.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16335271298885345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8366472721099854, \"precision\": 1.0, \"recall\": 0.16335271298885345, \"specificity\": 1.0, \"npv\": 0.9516737461090088, \"accuracy\": 0.9521254897117615, \"f1\": 0.2808309229555614, \"f2\": 0.1961792799412197, \"f0_5\": 0.4939870490286771, \"p4\": 0.4360859788035155, \"phi\": 0.39428222448232075}, {\"truth_threshold\": 41.10221912628609, \"match_probability\": 0.9999999999995763, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1067.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5471.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1631997525691986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.836800217628479, \"precision\": 1.0, \"recall\": 0.1631997525691986, \"specificity\": 1.0, \"npv\": 0.9516653418540955, \"accuracy\": 0.9521167278289795, \"f1\": 0.28060486522024986, \"f2\": 0.19600279216723612, \"f0_5\": 0.4937071997038682, \"p4\": 0.43581294045378144, \"phi\": 0.39409587531417056}, {\"truth_threshold\": 41.10423829392274, \"match_probability\": 0.999999999999577, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1066.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5472.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16304680705070496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8369532227516174, \"precision\": 1.0, \"recall\": 0.16304680705070496, \"specificity\": 1.0, \"npv\": 0.9516569375991821, \"accuracy\": 0.9521079659461975, \"f1\": 0.280378748027354, \"f2\": 0.1958262914247924, \"f0_5\": 0.49342714312164415, \"p4\": 0.4355397333156167, \"phi\": 0.3939094138403373}, {\"truth_threshold\": 41.10604752490083, \"match_probability\": 0.9999999999995774, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1063.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5475.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1625879406929016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8374120593070984, \"precision\": 1.0, \"recall\": 0.1625879406929016, \"specificity\": 1.0, \"npv\": 0.9516317248344421, \"accuracy\": 0.9520817399024963, \"f1\": 0.279700039468491, \"f2\": 0.19529671137240492, \"f0_5\": 0.49258572752548657, \"p4\": 0.4347190975806953, \"phi\": 0.39334951888358555}, {\"truth_threshold\": 41.11066991713328, \"match_probability\": 0.9999999999995788, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1060.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5478.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16212908923625946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8378708958625793, \"precision\": 1.0, \"recall\": 0.16212908923625946, \"specificity\": 1.0, \"npv\": 0.9516065120697021, \"accuracy\": 0.9520554542541504, \"f1\": 0.27902079494603843, \"f2\": 0.19476701455240336, \"f0_5\": 0.4917424383002412, \"p4\": 0.43389693701807025, \"phi\": 0.39278888309462606}, {\"truth_threshold\": 41.123280741813915, \"match_probability\": 0.9999999999995824, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1059.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5479.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1619761437177658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.838023841381073, \"precision\": 1.0, \"recall\": 0.1619761437177658, \"specificity\": 1.0, \"npv\": 0.9515981078147888, \"accuracy\": 0.9520466923713684, \"f1\": 0.27879426089245757, \"f2\": 0.19459042299070228, \"f0_5\": 0.4914609244477446, \"p4\": 0.43362254390093224, \"phi\": 0.39260182402358734}, {\"truth_threshold\": 41.12458693931454, \"match_probability\": 0.9999999999995829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1053.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5485.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1610584259033203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8389415740966797, \"precision\": 1.0, \"recall\": 0.1610584259033203, \"specificity\": 1.0, \"npv\": 0.9515476226806641, \"accuracy\": 0.9519941806793213, \"f1\": 0.2774338031879858, \"f2\": 0.1935306009924646, \"f0_5\": 0.4897674418604651, \"p4\": 0.4319726082066218, \"phi\": 0.39147766219436253}, {\"truth_threshold\": 41.12828876976951, \"match_probability\": 0.999999999999584, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1052.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5486.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16090548038482666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8390945196151733, \"precision\": 1.0, \"recall\": 0.16090548038482666, \"specificity\": 1.0, \"npv\": 0.9515392184257507, \"accuracy\": 0.9519854187965393, \"f1\": 0.27720685111989457, \"f2\": 0.19335391854139097, \"f0_5\": 0.48948445933370555, \"p4\": 0.4316970212563712, \"phi\": 0.39128999950092763}, {\"truth_threshold\": 41.135122960857814, \"match_probability\": 0.9999999999995859, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1050.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5488.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16059957444667816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8394004106521606, \"precision\": 1.0, \"recall\": 0.16059957444667816, \"specificity\": 1.0, \"npv\": 0.9515224099159241, \"accuracy\": 0.9519679546356201, \"f1\": 0.2767527675276753, \"f2\": 0.1930005146680391, \"f0_5\": 0.48891786179921776, \"p4\": 0.4311453336156075, \"phi\": 0.39091444145341864}, {\"truth_threshold\": 41.13594715365008, \"match_probability\": 0.9999999999995861, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1048.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5490.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.16029366850852966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8397063612937927, \"precision\": 1.0, \"recall\": 0.16029366850852966, \"specificity\": 1.0, \"npv\": 0.9515056014060974, \"accuracy\": 0.9519504308700562, \"f1\": 0.2762984445030319, \"f2\": 0.19264705882352942, \"f0_5\": 0.48835041938490215, \"p4\": 0.43059295990740926, \"phi\": 0.3905385078667721}, {\"truth_threshold\": 41.14138984182148, \"match_probability\": 0.9999999999995877, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1047.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5491.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.160140722990036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8398593068122864, \"precision\": 1.0, \"recall\": 0.160140722990036, \"specificity\": 1.0, \"npv\": 0.9514971971511841, \"accuracy\": 0.9519416689872742, \"f1\": 0.2760711931443639, \"f2\": 0.19247031140850768, \"f0_5\": 0.48806638075703895, \"p4\": 0.43031651537209864, \"phi\": 0.39035041029082407}, {\"truth_threshold\": 41.142239870752796, \"match_probability\": 0.999999999999588, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1045.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5493.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1598348170518875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8401651978492737, \"precision\": 1.0, \"recall\": 0.1598348170518875, \"specificity\": 1.0, \"npv\": 0.9514803886413574, \"accuracy\": 0.9519241452217102, \"f1\": 0.27561651061585124, \"f2\": 0.19211677758576315, \"f0_5\": 0.48749766747527523, \"p4\": 0.42976311012541313, \"phi\": 0.3899739529424292}, {\"truth_threshold\": 41.14857476197783, \"match_probability\": 0.9999999999995898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1043.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.159528911113739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.840471088886261, \"precision\": 1.0, \"recall\": 0.159528911113739, \"specificity\": 1.0, \"npv\": 0.9514635801315308, \"accuracy\": 0.951906681060791, \"f1\": 0.27516158818097874, \"f2\": 0.19176319176319176, \"f0_5\": 0.4869281045751634, \"p4\": 0.4292090155567209, \"phi\": 0.38959717289495394}, {\"truth_threshold\": 41.15131190163063, \"match_probability\": 0.9999999999995905, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1042.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5496.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15937595069408417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8406240344047546, \"precision\": 1.0, \"recall\": 0.15937595069408417, \"specificity\": 1.0, \"npv\": 0.9514551758766174, \"accuracy\": 0.951897919178009, \"f1\": 0.274934036939314, \"f2\": 0.19158637934838568, \"f0_5\": 0.48664300392303383, \"p4\": 0.42893170936812897, \"phi\": 0.3894086372803881}, {\"truth_threshold\": 41.153738639025164, \"match_probability\": 0.9999999999995912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1038.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5500.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15876415371894836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.841235876083374, \"precision\": 1.0, \"recall\": 0.15876415371894836, \"specificity\": 1.0, \"npv\": 0.9514215588569641, \"accuracy\": 0.9518629312515259, \"f1\": 0.2740232312565998, \"f2\": 0.19087899963221772, \"f0_5\": 0.4855004677268475, \"p4\": 0.4278207547619936, \"phi\": 0.3886536136154538}, {\"truth_threshold\": 41.161890293920514, \"match_probability\": 0.9999999999995935, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1036.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5502.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15845824778079987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8415417671203613, \"precision\": 1.0, \"recall\": 0.15845824778079987, \"specificity\": 1.0, \"npv\": 0.9514047503471375, \"accuracy\": 0.9518454074859619, \"f1\": 0.2735674676524954, \"f2\": 0.19052523171987643, \"f0_5\": 0.4849279161205767, \"p4\": 0.42726423724725127, \"phi\": 0.38827557125830126}, {\"truth_threshold\": 41.16680811735483, \"match_probability\": 0.9999999999995949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1034.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5504.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15815234184265137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8418476581573486, \"precision\": 1.0, \"recall\": 0.15815234184265137, \"specificity\": 1.0, \"npv\": 0.9513879418373108, \"accuracy\": 0.951827883720398, \"f1\": 0.2731114632857897, \"f2\": 0.1901714117560509, \"f0_5\": 0.4843545062769346, \"p4\": 0.42670702450021236, \"phi\": 0.38789720169942443}, {\"truth_threshold\": 41.170951665374616, \"match_probability\": 0.9999999999995961, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1031.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5507.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15769349038600922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8423064947128296, \"precision\": 1.0, \"recall\": 0.15769349038600922, \"specificity\": 1.0, \"npv\": 0.9513627886772156, \"accuracy\": 0.9518016576766968, \"f1\": 0.2724270048883604, \"f2\": 0.18964058418864732, \"f0_5\": 0.4834927780904146, \"p4\": 0.4258698989250709, \"phi\": 0.3873289375895831}, {\"truth_threshold\": 41.176589741250574, \"match_probability\": 0.9999999999995977, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1030.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5508.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15754052996635437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8424594402313232, \"precision\": 1.0, \"recall\": 0.15754052996635437, \"specificity\": 1.0, \"npv\": 0.9513543844223022, \"accuracy\": 0.9517928957939148, \"f1\": 0.27219873150105706, \"f2\": 0.1894636156279891, \"f0_5\": 0.48320510414711954, \"p4\": 0.425590508015631, \"phi\": 0.38713933755763297}, {\"truth_threshold\": 41.182768010403066, \"match_probability\": 0.9999999999995993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1029.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5509.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15738758444786072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8426124453544617, \"precision\": 1.0, \"recall\": 0.15738758444786072, \"specificity\": 1.0, \"npv\": 0.9513459801673889, \"accuracy\": 0.9517841339111328, \"f1\": 0.2719703977798335, \"f2\": 0.18928663404584084, \"f0_5\": 0.48291721419185285, \"p4\": 0.4253109423037264, \"phi\": 0.38694964797573006}, {\"truth_threshold\": 41.1866694480854, \"match_probability\": 0.9999999999996004, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1028.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5510.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15723462402820587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8427653908729553, \"precision\": 1.0, \"recall\": 0.15723462402820587, \"specificity\": 1.0, \"npv\": 0.9513375759124756, \"accuracy\": 0.9517753720283508, \"f1\": 0.27174200370076657, \"f2\": 0.18910963944076528, \"f0_5\": 0.48262910798122066, \"p4\": 0.42503120162287994, \"phi\": 0.38675989665328353}, {\"truth_threshold\": 41.19170648922419, \"match_probability\": 0.9999999999996019, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1027.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5511.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15708167850971222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.842918336391449, \"precision\": 1.0, \"recall\": 0.15708167850971222, \"specificity\": 1.0, \"npv\": 0.9513291716575623, \"accuracy\": 0.9517666101455688, \"f1\": 0.2715135492399207, \"f2\": 0.1889326318113249, \"f0_5\": 0.48234078527146346, \"p4\": 0.4247512858064027, \"phi\": 0.3865700275890792}, {\"truth_threshold\": 41.192419107189224, \"match_probability\": 0.999999999999602, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1026.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5512.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15692871809005737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8430712819099426, \"precision\": 1.0, \"recall\": 0.15692871809005737, \"specificity\": 1.0, \"npv\": 0.9513207674026489, \"accuracy\": 0.9517579078674316, \"f1\": 0.27128503437334744, \"f2\": 0.18875561115608214, \"f0_5\": 0.4820522458184552, \"p4\": 0.42447119468739414, \"phi\": 0.38638006857842583}, {\"truth_threshold\": 41.201131925513366, \"match_probability\": 0.9999999999996044, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1025.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5513.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15677577257156372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8432242274284363, \"precision\": 1.0, \"recall\": 0.15677577257156372, \"specificity\": 1.0, \"npv\": 0.9513123631477356, \"accuracy\": 0.9517491459846497, \"f1\": 0.2710564590770858, \"f2\": 0.188578577473599, \"f0_5\": 0.4817634893777026, \"p4\": 0.4241909280987416, \"phi\": 0.3861900194885059}, {\"truth_threshold\": 41.21105889178388, \"match_probability\": 0.9999999999996071, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1021.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5517.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15616396069526672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8438360095024109, \"precision\": 1.0, \"recall\": 0.15616396069526672, \"specificity\": 1.0, \"npv\": 0.9512787461280823, \"accuracy\": 0.9517140984535217, \"f1\": 0.2701415531154915, \"f2\": 0.18787031244249808, \"f0_5\": 0.48060628883449447, \"p4\": 0.42306810369799525, \"phi\": 0.3854289196684284}, {\"truth_threshold\": 41.212762750700904, \"match_probability\": 0.9999999999996076, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1020.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5518.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15601101517677307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8439890146255493, \"precision\": 1.0, \"recall\": 0.15601101517677307, \"specificity\": 1.0, \"npv\": 0.951270341873169, \"accuracy\": 0.9517053365707397, \"f1\": 0.26991267531092883, \"f2\": 0.1876932136022376, \"f0_5\": 0.48031644377472216, \"p4\": 0.4227869572469852, \"phi\": 0.3852384181785152}, {\"truth_threshold\": 41.21821915401828, \"match_probability\": 0.9999999999996091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1019.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5519.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15585805475711823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.844141960144043, \"precision\": 1.0, \"recall\": 0.15585805475711823, \"specificity\": 1.0, \"npv\": 0.9512619376182556, \"accuracy\": 0.9516966342926025, \"f1\": 0.26968373693264525, \"f2\": 0.18751610172610503, \"f0_5\": 0.4800263802524967, \"p4\": 0.42250563431918176, \"phi\": 0.3850478538688398}, {\"truth_threshold\": 41.23399821094063, \"match_probability\": 0.9999999999996133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1016.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5522.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15539920330047607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8446007966995239, \"precision\": 1.0, \"recall\": 0.15539920330047607, \"specificity\": 1.0, \"npv\": 0.9512367248535156, \"accuracy\": 0.9516703486442566, \"f1\": 0.268996558114906, \"f2\": 0.1869846878680801, \"f0_5\": 0.4791548764384079, \"p4\": 0.42166060498786845, \"phi\": 0.38447553014009955}, {\"truth_threshold\": 41.23877474288096, \"match_probability\": 0.9999999999996146, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1014.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5524.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15509329736232758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8449066877365112, \"precision\": 1.0, \"recall\": 0.15509329736232758, \"specificity\": 1.0, \"npv\": 0.951219916343689, \"accuracy\": 0.9516528248786926, \"f1\": 0.2685381355932203, \"f2\": 0.18663034675697562, \"f0_5\": 0.47857277704360957, \"p4\": 0.42109636661949795, \"phi\": 0.384093524086618}, {\"truth_threshold\": 41.24940520343336, \"match_probability\": 0.9999999999996174, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1013.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5525.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15494035184383392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8450596332550049, \"precision\": 1.0, \"recall\": 0.15494035184383392, \"specificity\": 1.0, \"npv\": 0.9512115716934204, \"accuracy\": 0.9516441226005554, \"f1\": 0.26830883326711696, \"f2\": 0.1864531566353764, \"f0_5\": 0.47828139754485366, \"p4\": 0.420813981282659, \"phi\": 0.3839023835802306}, {\"truth_threshold\": 41.25037704250069, \"match_probability\": 0.9999999999996178, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1010.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5528.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15448148548603058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8455185294151306, \"precision\": 1.0, \"recall\": 0.15448148548603058, \"specificity\": 1.0, \"npv\": 0.9511863589286804, \"accuracy\": 0.9516178369522095, \"f1\": 0.2676205617382088, \"f2\": 0.18592150798910242, \"f0_5\": 0.47740593685006616, \"p4\": 0.41996575862206387, \"phi\": 0.3833284386828628}, {\"truth_threshold\": 41.25242115421022, \"match_probability\": 0.9999999999996182, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1007.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5531.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15402263402938843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8459773659706116, \"precision\": 1.0, \"recall\": 0.15402263402938843, \"specificity\": 1.0, \"npv\": 0.9511611461639404, \"accuracy\": 0.9515916109085083, \"f1\": 0.26693174287607685, \"f2\": 0.18538974189034943, \"f0_5\": 0.47652848760174144, \"p4\": 0.41911593240702544, \"phi\": 0.3827536353950125}, {\"truth_threshold\": 41.25297181845355, \"match_probability\": 0.9999999999996184, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1005.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5533.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15371672809123993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8462832570075989, \"precision\": 1.0, \"recall\": 0.15371672809123993, \"specificity\": 1.0, \"npv\": 0.9511443376541138, \"accuracy\": 0.9515740871429443, \"f1\": 0.2664722259048124, \"f2\": 0.18503516588724822, \"f0_5\": 0.47594241333585907, \"p4\": 0.4185484884542926, \"phi\": 0.3823699701059235}, {\"truth_threshold\": 41.25704995894941, \"match_probability\": 0.9999999999996194, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1004.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5534.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15356378257274628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8464362025260925, \"precision\": 1.0, \"recall\": 0.15356378257274628, \"specificity\": 1.0, \"npv\": 0.9511359333992004, \"accuracy\": 0.9515653252601624, \"f1\": 0.2662423760275789, \"f2\": 0.1848578583001915, \"f0_5\": 0.47564904301686567, \"p4\": 0.41826449802083415, \"phi\": 0.38217799811364456}, {\"truth_threshold\": 41.26476995141391, \"match_probability\": 0.9999999999996215, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1003.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5535.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15341082215309143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8465891480445862, \"precision\": 1.0, \"recall\": 0.15341082215309143, \"specificity\": 1.0, \"npv\": 0.9511275291442871, \"accuracy\": 0.9515565633773804, \"f1\": 0.2660124651902931, \"f2\": 0.18468053765420733, \"f0_5\": 0.47535545023696685, \"p4\": 0.4179803283869002, \"phi\": 0.38198596132024426}, {\"truth_threshold\": 41.26523017059504, \"match_probability\": 0.9999999999996216, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1001.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5537.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15310493111610413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8468950986862183, \"precision\": 1.0, \"recall\": 0.15310493111610413, \"specificity\": 1.0, \"npv\": 0.9511107802391052, \"accuracy\": 0.9515390992164612, \"f1\": 0.265552460538533, \"f2\": 0.1843258571796855, \"f0_5\": 0.4747675962815405, \"p4\": 0.41741145082904335, \"phi\": 0.3816015513743556}, {\"truth_threshold\": 41.27447720052859, \"match_probability\": 0.9999999999996241, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 998.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5540.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15264606475830078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8473539352416992, \"precision\": 1.0, \"recall\": 0.15264606475830078, \"specificity\": 1.0, \"npv\": 0.9510855674743652, \"accuracy\": 0.9515128135681152, \"f1\": 0.2648619957537155, \"f2\": 0.1837937384898711, \"f0_5\": 0.47388414055080724, \"p4\": 0.41655678617938435, \"phi\": 0.3810242347899029}, {\"truth_threshold\": 41.27530061890608, \"match_probability\": 0.9999999999996243, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 997.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5541.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15249311923980713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8475068807601929, \"precision\": 1.0, \"recall\": 0.15249311923980713, \"specificity\": 1.0, \"npv\": 0.9510771632194519, \"accuracy\": 0.9515040516853333, \"f1\": 0.2646317186463172, \"f2\": 0.18361633946001693, \"f0_5\": 0.4735892076762303, \"p4\": 0.41627153772107595, \"phi\": 0.38083160824999895}, {\"truth_threshold\": 41.27812329883457, \"match_probability\": 0.999999999999625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 994.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5544.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15203426778316498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8479657173156738, \"precision\": 1.0, \"recall\": 0.15203426778316498, \"specificity\": 1.0, \"npv\": 0.9510519504547119, \"accuracy\": 0.9514778256416321, \"f1\": 0.26394052044609667, \"f2\": 0.18308406395048996, \"f0_5\": 0.47270306258322237, \"p4\": 0.41541470919309903, \"phi\": 0.3802531920080736}, {\"truth_threshold\": 41.281636992101454, \"match_probability\": 0.9999999999996259, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 992.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5546.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15172836184501648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8482716679573059, \"precision\": 1.0, \"recall\": 0.15172836184501648, \"specificity\": 1.0, \"npv\": 0.95103520154953, \"accuracy\": 0.9514603018760681, \"f1\": 0.26347941567065075, \"f2\": 0.18272914824638964, \"f0_5\": 0.47211117456691415, \"p4\": 0.41484258580776057, \"phi\": 0.37986708997196234}, {\"truth_threshold\": 41.281826681125736, \"match_probability\": 0.999999999999626, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 991.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5547.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15157540142536163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8484246134757996, \"precision\": 1.0, \"recall\": 0.15157540142536163, \"specificity\": 1.0, \"npv\": 0.9510267972946167, \"accuracy\": 0.9514515399932861, \"f1\": 0.2632487714171869, \"f2\": 0.1825516707806801, \"f0_5\": 0.47181489240144736, \"p4\": 0.4145562522821689, \"phi\": 0.37967389683271885}, {\"truth_threshold\": 41.29424132990485, \"match_probability\": 0.9999999999996292, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 988.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5550.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15111654996871948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8488834500312805, \"precision\": 1.0, \"recall\": 0.15111654996871948, \"specificity\": 1.0, \"npv\": 0.9510015845298767, \"accuracy\": 0.951425313949585, \"f1\": 0.26255647090087697, \"f2\": 0.18201915991156964, \"f0_5\": 0.47092469018112487, \"p4\": 0.4136961622759875, \"phi\": 0.379093747190676}, {\"truth_threshold\": 41.2977816876101, \"match_probability\": 0.9999999999996301, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 986.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5552.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15081064403057098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8491893410682678, \"precision\": 1.0, \"recall\": 0.15081064403057098, \"specificity\": 1.0, \"npv\": 0.9509848356246948, \"accuracy\": 0.951407790184021, \"f1\": 0.26209463051568316, \"f2\": 0.1816640872577198, \"f0_5\": 0.4703300896775425, \"p4\": 0.4131218593280979, \"phi\": 0.3787065326435965}, {\"truth_threshold\": 41.30196856936816, \"match_probability\": 0.9999999999996312, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 985.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5553.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15065769851207733, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8493422865867615, \"precision\": 1.0, \"recall\": 0.15065769851207733, \"specificity\": 1.0, \"npv\": 0.9509764313697815, \"accuracy\": 0.951399028301239, \"f1\": 0.2618636182374053, \"f2\": 0.1814865313041235, \"f0_5\": 0.4700324489406375, \"p4\": 0.4128344344440592, \"phi\": 0.37851276768976433}, {\"truth_threshold\": 41.303852987455734, \"match_probability\": 0.9999999999996316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 984.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5554.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15050473809242249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8494952321052551, \"precision\": 1.0, \"recall\": 0.15050473809242249, \"specificity\": 1.0, \"npv\": 0.9509680271148682, \"accuracy\": 0.951390266418457, \"f1\": 0.26163254453602763, \"f2\": 0.18130896226415094, \"f0_5\": 0.46973458086690856, \"p4\": 0.41254682705189083, \"phi\": 0.3783189069184839}, {\"truth_threshold\": 41.30721983855413, \"match_probability\": 0.9999999999996325, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 983.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5555.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.15035179257392883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8496482372283936, \"precision\": 1.0, \"recall\": 0.15035179257392883, \"specificity\": 1.0, \"npv\": 0.9509596228599548, \"accuracy\": 0.9513815641403198, \"f1\": 0.2614014093870496, \"f2\": 0.18113138013635527, \"f0_5\": 0.4694364851957975, \"p4\": 0.4122590369752591, \"phi\": 0.37812495018229053}, {\"truth_threshold\": 41.30991898815509, \"match_probability\": 0.9999999999996332, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 982.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5556.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.150198832154274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8498011827468872, \"precision\": 1.0, \"recall\": 0.150198832154274, \"specificity\": 1.0, \"npv\": 0.9509512186050415, \"accuracy\": 0.9513728022575378, \"f1\": 0.2611702127659574, \"f2\": 0.18095378491928946, \"f0_5\": 0.4691381616663482, \"p4\": 0.41197106403760314, \"phi\": 0.3779308973333438}, {\"truth_threshold\": 41.31967795461742, \"match_probability\": 0.9999999999996356, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 979.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5559.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14973998069763184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8502600193023682, \"precision\": 1.0, \"recall\": 0.14973998069763184, \"specificity\": 1.0, \"npv\": 0.9509260654449463, \"accuracy\": 0.9513465166091919, \"f1\": 0.2604762538246641, \"f2\": 0.18042092071799787, \"f0_5\": 0.4682418213124163, \"p4\": 0.4111060462894647, \"phi\": 0.37734818925169056}, {\"truth_threshold\": 41.324253898971286, \"match_probability\": 0.9999999999996367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 977.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5561.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14943407475948334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8505659103393555, \"precision\": 1.0, \"recall\": 0.14943407475948334, \"specificity\": 1.0, \"npv\": 0.9509092569351196, \"accuracy\": 0.9513289928436279, \"f1\": 0.26001330671989353, \"f2\": 0.18006561244424785, \"f0_5\": 0.46764311698257705, \"p4\": 0.4105284502383768, \"phi\": 0.3769592148512342}, {\"truth_threshold\": 41.33188414727245, \"match_probability\": 0.9999999999996387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 976.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5562.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14928112924098969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8507188558578491, \"precision\": 1.0, \"recall\": 0.14928112924098969, \"specificity\": 1.0, \"npv\": 0.9509008526802063, \"accuracy\": 0.9513202905654907, \"f1\": 0.2597817407505989, \"f2\": 0.1798879386611619, \"f0_5\": 0.4673434208006129, \"p4\": 0.4102393764140265, \"phi\": 0.376764582214459}, {\"truth_threshold\": 41.34894087698427, \"match_probability\": 0.999999999999643, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 974.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5564.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1489752233028412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8510248064994812, \"precision\": 1.0, \"recall\": 0.1489752233028412, \"specificity\": 1.0, \"npv\": 0.9508840441703796, \"accuracy\": 0.9513027667999268, \"f1\": 0.25931842385516507, \"f2\": 0.1795325517953255, \"f0_5\": 0.46674333908376464, \"p4\": 0.4096606762769048, \"phi\": 0.3763750253152718}, {\"truth_threshold\": 41.35342971716001, \"match_probability\": 0.9999999999996441, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 971.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5567.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14851637184619904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8514836430549622, \"precision\": 1.0, \"recall\": 0.14851637184619904, \"specificity\": 1.0, \"npv\": 0.9508588910102844, \"accuracy\": 0.9512764811515808, \"f1\": 0.2586229857504328, \"f2\": 0.17899937322567563, \"f0_5\": 0.46584148915755136, \"p4\": 0.40879124217083274, \"phi\": 0.37578998737558444}, {\"truth_threshold\": 41.35569754688232, \"match_probability\": 0.9999999999996446, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 970.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5568.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1483634114265442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8516365885734558, \"precision\": 1.0, \"recall\": 0.1483634114265442, \"specificity\": 1.0, \"npv\": 0.9508504867553711, \"accuracy\": 0.9512677788734436, \"f1\": 0.2583910495471497, \"f2\": 0.178821620824423, \"f0_5\": 0.4655404108274141, \"p4\": 0.4085010610459312, \"phi\": 0.3755947695328035}, {\"truth_threshold\": 41.360029386069996, \"match_probability\": 0.9999999999996457, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 968.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5570.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1480575054883957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8519424796104431, \"precision\": 1.0, \"recall\": 0.1480575054883957, \"specificity\": 1.0, \"npv\": 0.9508337378501892, \"accuracy\": 0.9512502551078796, \"f1\": 0.2579269917399414, \"f2\": 0.17846607669616518, \"f0_5\": 0.46493756003842457, \"p4\": 0.4079201430848708, \"phi\": 0.37520403948566794}, {\"truth_threshold\": 41.3616314906665, \"match_probability\": 0.9999999999996461, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 967.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5571.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14790455996990204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8520954251289368, \"precision\": 1.0, \"recall\": 0.14790455996990204, \"specificity\": 1.0, \"npv\": 0.9508253335952759, \"accuracy\": 0.9512414932250977, \"f1\": 0.2576948700866089, \"f2\": 0.1782882849662598, \"f0_5\": 0.46463578704593506, \"p4\": 0.4076294058889181, \"phi\": 0.37500852697442844}, {\"truth_threshold\": 41.36973152948911, \"match_probability\": 0.9999999999996481, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 965.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5573.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14759865403175354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8524013757705688, \"precision\": 1.0, \"recall\": 0.14759865403175354, \"specificity\": 1.0, \"npv\": 0.9508085250854492, \"accuracy\": 0.9512239694595337, \"f1\": 0.2572304411568706, \"f2\": 0.17793266216764392, \"f0_5\": 0.4640315445277938, \"p4\": 0.4070473741649356, \"phi\": 0.3746172062064109}, {\"truth_threshold\": 41.37541308834547, \"match_probability\": 0.9999999999996494, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 964.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5574.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1474457085132599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8525543212890625, \"precision\": 1.0, \"recall\": 0.1474457085132599, \"specificity\": 1.0, \"npv\": 0.9508001208305359, \"accuracy\": 0.9512152671813965, \"f1\": 0.2569981338309784, \"f2\": 0.17775483109603185, \"f0_5\": 0.4637290744660381, \"p4\": 0.406756079275712, \"phi\": 0.37442142648607146}, {\"truth_threshold\": 41.37545602349001, \"match_probability\": 0.9999999999996495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 961.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5577.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14698684215545654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8530131578445435, \"precision\": 1.0, \"recall\": 0.14698684215545654, \"specificity\": 1.0, \"npv\": 0.9507749676704407, \"accuracy\": 0.9511889815330505, \"f1\": 0.2563008401120149, \"f2\": 0.17722125917456572, \"f0_5\": 0.4628202658447313, \"p4\": 0.4058810763270296, \"phi\": 0.3738334062402177}, {\"truth_threshold\": 41.39405296835888, \"match_probability\": 0.9999999999996539, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 959.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5579.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14668093621730804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8533190488815308, \"precision\": 1.0, \"recall\": 0.14668093621730804, \"specificity\": 1.0, \"npv\": 0.950758159160614, \"accuracy\": 0.9511714577674866, \"f1\": 0.25583566760037346, \"f2\": 0.17686547895688098, \"f0_5\": 0.4622132253711201, \"p4\": 0.40529680731229717, \"phi\": 0.3734408956879945}, {\"truth_threshold\": 41.39815736669161, \"match_probability\": 0.9999999999996549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 958.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5580.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1465279906988144, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8534719944000244, \"precision\": 1.0, \"recall\": 0.1465279906988144, \"specificity\": 1.0, \"npv\": 0.9507498145103455, \"accuracy\": 0.9511627554893494, \"f1\": 0.25560298826040556, \"f2\": 0.1766875691626706, \"f0_5\": 0.46190935390549664, \"p4\": 0.4050043921445803, \"phi\": 0.3732444908247896}, {\"truth_threshold\": 41.40442424765527, \"match_probability\": 0.9999999999996564, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 957.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5581.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14637504518032074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8536249399185181, \"precision\": 1.0, \"recall\": 0.14637504518032074, \"specificity\": 1.0, \"npv\": 0.9507414102554321, \"accuracy\": 0.9511539936065674, \"f1\": 0.25537024683122084, \"f2\": 0.17650964624294516, \"f0_5\": 0.4616052479259116, \"p4\": 0.4047117896268927, \"phi\": 0.373047986026745}, {\"truth_threshold\": 41.4127873590089, \"match_probability\": 0.9999999999996584, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 955.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5583.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14606913924217224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8539308905601501, \"precision\": 1.0, \"recall\": 0.14606913924217224, \"specificity\": 1.0, \"npv\": 0.9507246017456055, \"accuracy\": 0.9511364698410034, \"f1\": 0.2549045776057654, \"f2\": 0.17615376102113844, \"f0_5\": 0.46099633133809614, \"p4\": 0.40412602181097335, \"phi\": 0.3726547049734958}, {\"truth_threshold\": 41.42755071168064, \"match_probability\": 0.9999999999996619, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 954.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5584.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1459161788225174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8540838360786438, \"precision\": 1.0, \"recall\": 0.1459161788225174, \"specificity\": 1.0, \"npv\": 0.9507161974906921, \"accuracy\": 0.9511277079582214, \"f1\": 0.2546716497597437, \"f2\": 0.1759757987161514, \"f0_5\": 0.4606915201854356, \"p4\": 0.4038328561468318, \"phi\": 0.37245789943573865}, {\"truth_threshold\": 41.43141982082336, \"match_probability\": 0.9999999999996628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 948.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5590.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1449984759092331, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8550015091896057, \"precision\": 1.0, \"recall\": 0.1449984759092331, \"specificity\": 1.0, \"npv\": 0.9506658911705017, \"accuracy\": 0.9510751962661743, \"f1\": 0.2532727758482501, \"f2\": 0.17490774907749077, \"f0_5\": 0.45885769603097776, \"p4\": 0.4020699060117371, \"phi\": 0.37127497772502066}, {\"truth_threshold\": 41.436845725347645, \"match_probability\": 0.999999999999664, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 947.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5591.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14484551548957825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8551544547080994, \"precision\": 1.0, \"recall\": 0.14484551548957825, \"specificity\": 1.0, \"npv\": 0.9506574869155884, \"accuracy\": 0.9510664343833923, \"f1\": 0.25303941215764864, \"f2\": 0.1747296948226872, \"f0_5\": 0.45855122990509395, \"p4\": 0.4017754199121253, \"phi\": 0.37107746484475385}, {\"truth_threshold\": 41.44083558695071, \"match_probability\": 0.9999999999996649, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 945.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5593.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14453960955142975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8554604053497314, \"precision\": 1.0, \"recall\": 0.14453960955142975, \"specificity\": 1.0, \"npv\": 0.9506407380104065, \"accuracy\": 0.9510489702224731, \"f1\": 0.25257249766136575, \"f2\": 0.17437354688710927, \"f0_5\": 0.45793758480325647, \"p4\": 0.40118587941264905, \"phi\": 0.3706821338307485}, {\"truth_threshold\": 41.45473554100687, \"match_probability\": 0.9999999999996682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 943.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5595.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14423370361328125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8557662963867188, \"precision\": 1.0, \"recall\": 0.14423370361328125, \"specificity\": 1.0, \"npv\": 0.9506239295005798, \"accuracy\": 0.9510314464569092, \"f1\": 0.2521053335115626, \"f2\": 0.17401734637386973, \"f0_5\": 0.4573229873908826, \"p4\": 0.40059557994342226, \"phi\": 0.37028639472502584}, {\"truth_threshold\": 41.45669705734016, \"match_probability\": 0.9999999999996686, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 941.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5597.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14392781257629395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.856072187423706, \"precision\": 1.0, \"recall\": 0.14392781257629395, \"specificity\": 1.0, \"npv\": 0.950607180595398, \"accuracy\": 0.9510139226913452, \"f1\": 0.2516379195079556, \"f2\": 0.1736610932713247, \"f0_5\": 0.45670743544942727, \"p4\": 0.4000045200177593, \"phi\": 0.3698902462170143}, {\"truth_threshold\": 41.4604582825696, \"match_probability\": 0.9999999999996695, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 940.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5598.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1437748521566391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8562251329421997, \"precision\": 1.0, \"recall\": 0.1437748521566391, \"specificity\": 1.0, \"npv\": 0.9505987763404846, \"accuracy\": 0.9510051608085632, \"f1\": 0.2514041187483284, \"f2\": 0.173482946995423, \"f0_5\": 0.4563993008351136, \"p4\": 0.39970870441811307, \"phi\": 0.36969201802568996}, {\"truth_threshold\": 41.47323999651799, \"match_probability\": 0.9999999999996724, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 939.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5599.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14362190663814545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8563780784606934, \"precision\": 1.0, \"recall\": 0.14362190663814545, \"specificity\": 1.0, \"npv\": 0.9505903720855713, \"accuracy\": 0.950996458530426, \"f1\": 0.2511702554500468, \"f2\": 0.17330478756782694, \"f0_5\": 0.4560909267534486, \"p4\": 0.39941269814508956, \"phi\": 0.3694937162131282}, {\"truth_threshold\": 41.47481357554667, \"match_probability\": 0.9999999999996728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 937.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5601.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14331600069999695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8566840291023254, \"precision\": 1.0, \"recall\": 0.14331600069999695, \"specificity\": 1.0, \"npv\": 0.9505736231803894, \"accuracy\": 0.9509789347648621, \"f1\": 0.25070234113712375, \"f2\": 0.1729484292517258, \"f0_5\": 0.4554734590705814, \"p4\": 0.39882011283094493, \"phi\": 0.36909674497177325}, {\"truth_threshold\": 41.480730749539816, \"match_probability\": 0.9999999999996741, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 935.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5603.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14301009476184845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8569899201393127, \"precision\": 1.0, \"recall\": 0.14301009476184845, \"specificity\": 1.0, \"npv\": 0.9505568146705627, \"accuracy\": 0.9509614109992981, \"f1\": 0.25023417636825906, \"f2\": 0.17259201831136708, \"f0_5\": 0.45485503016151, \"p4\": 0.3982267625769467, \"phi\": 0.36869936035443535}, {\"truth_threshold\": 41.487162372750355, \"match_probability\": 0.9999999999996756, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 932.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5606.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1425512433052063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8574487566947937, \"precision\": 1.0, \"recall\": 0.1425512433052063, \"specificity\": 1.0, \"npv\": 0.9505316615104675, \"accuracy\": 0.9509351849555969, \"f1\": 0.24953145917001338, \"f2\": 0.1720573032048442, \"f0_5\": 0.4539255795830898, \"p4\": 0.39733529964636327, \"phi\": 0.3681025347504729}, {\"truth_threshold\": 41.48827755859316, \"match_probability\": 0.9999999999996758, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 931.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5607.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14239828288555145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8576017022132874, \"precision\": 1.0, \"recall\": 0.14239828288555145, \"specificity\": 1.0, \"npv\": 0.9505232572555542, \"accuracy\": 0.9509264230728149, \"f1\": 0.2492970946579194, \"f2\": 0.17187903851124323, \"f0_5\": 0.4536152796725784, \"p4\": 0.3970377612362471, \"phi\": 0.36790337497764447}, {\"truth_threshold\": 41.49229573064366, \"match_probability\": 0.9999999999996767, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 928.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5610.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1419394314289093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8580605983734131, \"precision\": 1.0, \"recall\": 0.1419394314289093, \"specificity\": 1.0, \"npv\": 0.950498104095459, \"accuracy\": 0.950900137424469, \"f1\": 0.24859362443075275, \"f2\": 0.17134416543574593, \"f0_5\": 0.4526829268292683, \"p4\": 0.3961439910615749, \"phi\": 0.3673052688591846}, {\"truth_threshold\": 41.4941789004136, \"match_probability\": 0.9999999999996771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 927.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5611.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14178648591041565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8582135438919067, \"precision\": 1.0, \"recall\": 0.14178648591041565, \"specificity\": 1.0, \"npv\": 0.9504896998405457, \"accuracy\": 0.9508914351463318, \"f1\": 0.24835900870730074, \"f2\": 0.17116584807415341, \"f0_5\": 0.45237165723209055, \"p4\": 0.39584568205726767, \"phi\": 0.3671056906520553}, {\"truth_threshold\": 41.50025020025924, \"match_probability\": 0.9999999999996785, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 926.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5612.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1416335254907608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8583664894104004, \"precision\": 1.0, \"recall\": 0.1416335254907608, \"specificity\": 1.0, \"npv\": 0.9504813551902771, \"accuracy\": 0.9508826732635498, \"f1\": 0.24812433011789925, \"f2\": 0.17098751754191593, \"f0_5\": 0.45206014450302673, \"p4\": 0.3955471799303099, \"phi\": 0.36690600740946255}, {\"truth_threshold\": 41.50122041373785, \"match_probability\": 0.9999999999996787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 920.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5618.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1407158225774765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8592841625213623, \"precision\": 1.0, \"recall\": 0.1407158225774765, \"specificity\": 1.0, \"npv\": 0.9504309892654419, \"accuracy\": 0.9508301615715027, \"f1\": 0.2467149369804237, \"f2\": 0.16991725768321514, \"f0_5\": 0.4501859463691525, \"p4\": 0.3937521009276218, \"phi\": 0.3657057220842377}, {\"truth_threshold\": 41.50723505323904, \"match_probability\": 0.99999999999968, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 919.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5619.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14056286215782166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.859437108039856, \"precision\": 1.0, \"recall\": 0.14056286215782166, \"specificity\": 1.0, \"npv\": 0.9504226446151733, \"accuracy\": 0.9508213996887207, \"f1\": 0.24647981762102722, \"f2\": 0.16973883491559233, \"f0_5\": 0.4498727237125514, \"p4\": 0.39345224160421, \"phi\": 0.3655052987761657}, {\"truth_threshold\": 41.51313926739963, \"match_probability\": 0.9999999999996814, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 917.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5621.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.14025695621967316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.859743058681488, \"precision\": 1.0, \"recall\": 0.14025695621967316, \"specificity\": 1.0, \"npv\": 0.9504058361053467, \"accuracy\": 0.9508038759231567, \"f1\": 0.2460093896713615, \"f2\": 0.16938194983191104, \"f0_5\": 0.4492455418381344, \"p4\": 0.392851938812912, \"phi\": 0.3651041327186258}, {\"truth_threshold\": 41.53298698667124, \"match_probability\": 0.9999999999996857, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 914.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5624.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.139798104763031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.860201895236969, \"precision\": 1.0, \"recall\": 0.139798104763031, \"specificity\": 1.0, \"npv\": 0.9503806829452515, \"accuracy\": 0.9507776498794556, \"f1\": 0.24530327428878154, \"f2\": 0.1688465233133821, \"f0_5\": 0.44830292328820875, \"p4\": 0.3919500213787665, \"phi\": 0.3645016120075897}, {\"truth_threshold\": 41.53744809930469, \"match_probability\": 0.9999999999996867, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 908.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5630.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1388803869485855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8611196279525757, \"precision\": 1.0, \"recall\": 0.1388803869485855, \"specificity\": 1.0, \"npv\": 0.950330376625061, \"accuracy\": 0.9507251381874084, \"f1\": 0.24388933655654044, \"f2\": 0.16777531411677754, \"f0_5\": 0.4464110127826942, \"p4\": 0.3901408996974526, \"phi\": 0.3632936094140198}, {\"truth_threshold\": 41.53891182062834, \"match_probability\": 0.999999999999687, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 907.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5631.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13872744143009186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8612725734710693, \"precision\": 1.0, \"recall\": 0.13872744143009186, \"specificity\": 1.0, \"npv\": 0.9503220319747925, \"accuracy\": 0.9507163763046265, \"f1\": 0.24365345869711216, \"f2\": 0.16759673306478437, \"f0_5\": 0.4460948258902223, \"p4\": 0.389838691827128, \"phi\": 0.36309192710336646}, {\"truth_threshold\": 41.54158595492667, \"match_probability\": 0.9999999999996876, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 906.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5632.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.138574481010437, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.861425518989563, \"precision\": 1.0, \"recall\": 0.138574481010437, \"specificity\": 1.0, \"npv\": 0.9503136277198792, \"accuracy\": 0.9507076144218445, \"f1\": 0.24341751746372917, \"f2\": 0.1674181388129204, \"f0_5\": 0.44577839008069275, \"p4\": 0.38953628698346826, \"phi\": 0.3628901065188025}, {\"truth_threshold\": 41.554449691659876, \"match_probability\": 0.9999999999996904, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 905.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5633.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13842153549194336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8615784645080566, \"precision\": 1.0, \"recall\": 0.13842153549194336, \"specificity\": 1.0, \"npv\": 0.9503052234649658, \"accuracy\": 0.9506988525390625, \"f1\": 0.24318151283084777, \"f2\": 0.16723953135972205, \"f0_5\": 0.44546170506005117, \"p4\": 0.38923368497126254, \"phi\": 0.36268817719358765}, {\"truth_threshold\": 41.556833728625605, \"match_probability\": 0.9999999999996909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 904.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5634.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1382685899734497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8617314100265503, \"precision\": 1.0, \"recall\": 0.1382685899734497, \"specificity\": 1.0, \"npv\": 0.9502968788146973, \"accuracy\": 0.9506900906562805, \"f1\": 0.2429454447729105, \"f2\": 0.1670609107037256, \"f0_5\": 0.44514477053377977, \"p4\": 0.38893088559504196, \"phi\": 0.3624861389459001}, {\"truth_threshold\": 41.575711738831295, \"match_probability\": 0.9999999999996949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 903.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5635.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13811562955379486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.861884355545044, \"precision\": 1.0, \"recall\": 0.13811562955379486, \"specificity\": 1.0, \"npv\": 0.9502884745597839, \"accuracy\": 0.9506813883781433, \"f1\": 0.2427093132643462, \"f2\": 0.16688227684346701, \"f0_5\": 0.44482758620689655, \"p4\": 0.38862788865907927, \"phi\": 0.3622839915934139}, {\"truth_threshold\": 41.58026642309073, \"match_probability\": 0.9999999999996958, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 902.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5636.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1379626840353012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8620373010635376, \"precision\": 1.0, \"recall\": 0.1379626840353012, \"specificity\": 1.0, \"npv\": 0.9502800703048706, \"accuracy\": 0.9506726264953613, \"f1\": 0.24247311827956988, \"f2\": 0.16670362977748207, \"f0_5\": 0.44451015178395425, \"p4\": 0.3883246939673884, \"phi\": 0.36208173495329754}, {\"truth_threshold\": 41.58123563468282, \"match_probability\": 0.999999999999696, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 899.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5639.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13750381767749786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8624961972236633, \"precision\": 1.0, \"recall\": 0.13750381767749786, \"specificity\": 1.0, \"npv\": 0.9502549171447754, \"accuracy\": 0.9506463408470154, \"f1\": 0.2417641522119134, \"f2\": 0.16616760933052382, \"f0_5\": 0.4435563449773041, \"p4\": 0.38741392139419306, \"phi\": 0.3614743373329888}, {\"truth_threshold\": 41.58205970491378, \"match_probability\": 0.9999999999996962, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 898.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5640.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1373508721590042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.862649142742157, \"precision\": 1.0, \"recall\": 0.1373508721590042, \"specificity\": 1.0, \"npv\": 0.9502465724945068, \"accuracy\": 0.9506375789642334, \"f1\": 0.2415277030661646, \"f2\": 0.16598890942698707, \"f0_5\": 0.4432379072063179, \"p4\": 0.38710993371453567, \"phi\": 0.3612716417203448}, {\"truth_threshold\": 41.59283868039576, \"match_probability\": 0.9999999999996985, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 897.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5641.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13719792664051056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8628020882606506, \"precision\": 1.0, \"recall\": 0.13719792664051056, \"specificity\": 1.0, \"npv\": 0.9502381682395935, \"accuracy\": 0.9506288170814514, \"f1\": 0.24129119031607263, \"f2\": 0.16581019631039964, \"f0_5\": 0.44291921785502664, \"p4\": 0.3868057472953215, \"phi\": 0.3610688358982866}, {\"truth_threshold\": 41.60325806571696, \"match_probability\": 0.9999999999997007, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 896.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5642.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1370449662208557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8629550337791443, \"precision\": 1.0, \"recall\": 0.1370449662208557, \"specificity\": 1.0, \"npv\": 0.950229823589325, \"accuracy\": 0.9506201148033142, \"f1\": 0.24105461393596986, \"f2\": 0.16563146997929606, \"f0_5\": 0.4426002766251729, \"p4\": 0.3865013619390023, \"phi\": 0.3608659196809069}, {\"truth_threshold\": 41.61072673662081, \"match_probability\": 0.9999999999997022, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 895.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5643.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13689202070236206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8631079792976379, \"precision\": 1.0, \"recall\": 0.13689202070236206, \"specificity\": 1.0, \"npv\": 0.9502214193344116, \"accuracy\": 0.9506113529205322, \"f1\": 0.2408179739001749, \"f2\": 0.1654527304322106, \"f0_5\": 0.4422810832180273, \"p4\": 0.38619677744776776, \"phi\": 0.3606628928817793}, {\"truth_threshold\": 41.61317025766246, \"match_probability\": 0.9999999999997027, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 894.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5644.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13673906028270721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8632609248161316, \"precision\": 1.0, \"recall\": 0.13673906028270721, \"specificity\": 1.0, \"npv\": 0.9502130150794983, \"accuracy\": 0.9506025910377502, \"f1\": 0.24058127018299247, \"f2\": 0.1652739776676773, \"f0_5\": 0.441961637334388, \"p4\": 0.3858919936235455, \"phi\": 0.3604597553139551}, {\"truth_threshold\": 41.61426709432606, \"match_probability\": 0.9999999999997029, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 893.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5645.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13658611476421356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8634138703346252, \"precision\": 1.0, \"recall\": 0.13658611476421356, \"specificity\": 1.0, \"npv\": 0.9502046704292297, \"accuracy\": 0.9505938291549683, \"f1\": 0.2403445027587135, \"f2\": 0.16509521168423, \"f0_5\": 0.4416419386745796, \"p4\": 0.3855870102680002, \"phi\": 0.3602565067899624}, {\"truth_threshold\": 41.615727417679174, \"match_probability\": 0.9999999999997032, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 890.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5648.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1361272633075714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.863872766494751, \"precision\": 1.0, \"recall\": 0.1361272633075714, \"specificity\": 1.0, \"npv\": 0.9501795172691345, \"accuracy\": 0.9505676031112671, \"f1\": 0.23963381798599892, \"f2\": 0.1645588344057392, \"f0_5\": 0.4406813230342642, \"p4\": 0.3846708610261237, \"phi\": 0.3596461236095307}, {\"truth_threshold\": 41.61616942479221, \"match_probability\": 0.9999999999997033, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 889.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5649.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13597430288791656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8640257120132446, \"precision\": 1.0, \"recall\": 0.13597430288791656, \"specificity\": 1.0, \"npv\": 0.9501711130142212, \"accuracy\": 0.9505588412284851, \"f1\": 0.23939679547596607, \"f2\": 0.16438001553196996, \"f0_5\": 0.4403606102635229, \"p4\": 0.38436507755666394, \"phi\": 0.3594424293923381}, {\"truth_threshold\": 41.622370763960525, \"match_probability\": 0.9999999999997046, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 887.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5651.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13566839694976807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8643316030502319, \"precision\": 1.0, \"recall\": 0.13566839694976807, \"specificity\": 1.0, \"npv\": 0.9501543641090393, \"accuracy\": 0.9505413174629211, \"f1\": 0.23892255892255893, \"f2\": 0.16402233810421982, \"f0_5\": 0.4397184215744597, \"p4\": 0.38375290883695684, \"phi\": 0.3590347050630089}, {\"truth_threshold\": 41.62466589650029, \"match_probability\": 0.999999999999705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 886.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5652.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13551545143127441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8644845485687256, \"precision\": 1.0, \"recall\": 0.13551545143127441, \"specificity\": 1.0, \"npv\": 0.950145959854126, \"accuracy\": 0.9505325555801392, \"f1\": 0.23868534482758622, \"f2\": 0.1638434795473038, \"f0_5\": 0.4393969450505852, \"p4\": 0.3834465231866019, \"phi\": 0.3588306745690182}, {\"truth_threshold\": 41.64218141697227, \"match_probability\": 0.9999999999997087, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 885.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5653.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13536249101161957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8646374940872192, \"precision\": 1.0, \"recall\": 0.13536249101161957, \"specificity\": 1.0, \"npv\": 0.9501376152038574, \"accuracy\": 0.9505237936973572, \"f1\": 0.23844806681934527, \"f2\": 0.16366460775973665, \"f0_5\": 0.4390752133359794, \"p4\": 0.3831399364087309, \"phi\": 0.35862653160000824}, {\"truth_threshold\": 41.64738061894926, \"match_probability\": 0.9999999999997097, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 884.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5654.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13520954549312592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8647904396057129, \"precision\": 1.0, \"recall\": 0.13520954549312592, \"specificity\": 1.0, \"npv\": 0.9501292109489441, \"accuracy\": 0.95051509141922, \"f1\": 0.23821072487200215, \"f2\": 0.1634857227400503, \"f0_5\": 0.4387532261266627, \"p4\": 0.38283314830262416, \"phi\": 0.35842230607575654}, {\"truth_threshold\": 41.65225329370429, \"match_probability\": 0.9999999999997107, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 883.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5655.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13505658507347107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8649433851242065, \"precision\": 1.0, \"recall\": 0.13505658507347107, \"specificity\": 1.0, \"npv\": 0.9501208662986755, \"accuracy\": 0.950506329536438, \"f1\": 0.23797331895970894, \"f2\": 0.16330682448677641, \"f0_5\": 0.4384309831181728, \"p4\": 0.38252615866729495, \"phi\": 0.35821793759623893}, {\"truth_threshold\": 41.681264453014094, \"match_probability\": 0.9999999999997164, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 882.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5656.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13490363955497742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8650963306427002, \"precision\": 1.0, \"recall\": 0.13490363955497742, \"specificity\": 1.0, \"npv\": 0.9501124620437622, \"accuracy\": 0.950497567653656, \"f1\": 0.23773584905660378, \"f2\": 0.1631279129984464, \"f0_5\": 0.4381084840055633, \"p4\": 0.38221896730148885, \"phi\": 0.358013456063257}, {\"truth_threshold\": 41.68355958555386, \"match_probability\": 0.9999999999997169, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 881.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5657.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13475069403648376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8652493357658386, \"precision\": 1.0, \"recall\": 0.13475069403648376, \"specificity\": 1.0, \"npv\": 0.9501040577888489, \"accuracy\": 0.950488805770874, \"f1\": 0.23749831513681088, \"f2\": 0.16294898827359153, \"f0_5\": 0.4377857284834029, \"p4\": 0.38191157400368353, \"phi\": 0.35780886128289086}, {\"truth_threshold\": 41.684001592666895, \"match_probability\": 0.999999999999717, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 880.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5658.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13459773361682892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8654022812843323, \"precision\": 1.0, \"recall\": 0.13459773361682892, \"specificity\": 1.0, \"npv\": 0.9500957131385803, \"accuracy\": 0.950480043888092, \"f1\": 0.23726071717444056, \"f2\": 0.16277005031074282, \"f0_5\": 0.4374627162457745, \"p4\": 0.3816039785720881, \"phi\": 0.35760415306066956}, {\"truth_threshold\": 41.688146963303474, \"match_probability\": 0.9999999999997178, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 879.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5659.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13444478809833527, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8655552268028259, \"precision\": 1.0, \"recall\": 0.13444478809833527, \"specificity\": 1.0, \"npv\": 0.950087308883667, \"accuracy\": 0.9504712820053101, \"f1\": 0.23702305514358904, \"f2\": 0.16259109910843106, \"f0_5\": 0.4371394469862741, \"p4\": 0.3812961808046428, \"phi\": 0.3573993312015685}, {\"truth_threshold\": 41.70613912165312, \"match_probability\": 0.9999999999997212, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 873.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5665.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13352707028388977, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8664728999137878, \"precision\": 1.0, \"recall\": 0.13352707028388977, \"specificity\": 1.0, \"npv\": 0.9500370621681213, \"accuracy\": 0.9504187703132629, \"f1\": 0.23559573606800702, \"f2\": 0.16151711378353376, \"f0_5\": 0.43519441674975073, \"p4\": 0.37944513379777706, \"phi\": 0.3561680329805276}, {\"truth_threshold\": 41.71526309123009, \"match_probability\": 0.999999999999723, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 872.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5666.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13337412476539612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8666259050369263, \"precision\": 1.0, \"recall\": 0.13337412476539612, \"specificity\": 1.0, \"npv\": 0.950028657913208, \"accuracy\": 0.9504100680351257, \"f1\": 0.23535762483130904, \"f2\": 0.16133806986382473, \"f0_5\": 0.43486933971673647, \"p4\": 0.37913591399902435, \"phi\": 0.3559624101728626}, {\"truth_threshold\": 41.72349268840339, \"match_probability\": 0.9999999999997246, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 870.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5668.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13306821882724762, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8669317960739136, \"precision\": 1.0, \"recall\": 0.13306821882724762, \"specificity\": 1.0, \"npv\": 0.9500119090080261, \"accuracy\": 0.9503925442695618, \"f1\": 0.23488120950323974, \"f2\": 0.16097994226926207, \"f0_5\": 0.43421840686763824, \"p4\": 0.3785168623108281, \"phi\": 0.3555508187057156}, {\"truth_threshold\": 41.72539849454697, \"match_probability\": 0.999999999999725, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 866.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5672.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13245640695095062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8675435781478882, \"precision\": 1.0, \"recall\": 0.13245640695095062, \"specificity\": 1.0, \"npv\": 0.9499784111976624, \"accuracy\": 0.9503575563430786, \"f1\": 0.23392760669908158, \"f2\": 0.16026352801835814, \"f0_5\": 0.4329134173165367, \"p4\": 0.37727630483608177, \"phi\": 0.3547262771619501}, {\"truth_threshold\": 41.72635234254263, \"match_probability\": 0.9999999999997251, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 865.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5673.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13230346143245697, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8676965236663818, \"precision\": 1.0, \"recall\": 0.13230346143245697, \"specificity\": 1.0, \"npv\": 0.949970006942749, \"accuracy\": 0.9503487944602966, \"f1\": 0.23368904498176415, \"f2\": 0.1600843913091757, \"f0_5\": 0.4325865173034607, \"p4\": 0.3769656529987902, \"phi\": 0.35451984362860206}, {\"truth_threshold\": 41.72707031455878, \"match_probability\": 0.9999999999997252, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 863.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5675.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13199755549430847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8680024743080139, \"precision\": 1.0, \"recall\": 0.13199755549430847, \"specificity\": 1.0, \"npv\": 0.9499532580375671, \"accuracy\": 0.9503312706947327, \"f1\": 0.23321172814484528, \"f2\": 0.1597260781047566, \"f0_5\": 0.4319319319319319, \"p4\": 0.3763437329198094, \"phi\": 0.3541066264673374}, {\"truth_threshold\": 41.732541082661925, \"match_probability\": 0.9999999999997263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 861.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5677.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13169164955615997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8683083653450012, \"precision\": 1.0, \"recall\": 0.13169164955615997, \"specificity\": 1.0, \"npv\": 0.9499365091323853, \"accuracy\": 0.9503137469291687, \"f1\": 0.23273415326395458, \"f2\": 0.15936771184244622, \"f0_5\": 0.43127629733520334, \"p4\": 0.37572098959075356, \"phi\": 0.3536929411491009}, {\"truth_threshold\": 41.73784798138046, \"match_probability\": 0.9999999999997273, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 860.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5678.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13153870403766632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8684613108634949, \"precision\": 1.0, \"recall\": 0.13153870403766632, \"specificity\": 1.0, \"npv\": 0.9499281048774719, \"accuracy\": 0.9503049850463867, \"f1\": 0.23249526899161935, \"f2\": 0.15918850881089885, \"f0_5\": 0.4309480857887352, \"p4\": 0.375409308689829, \"phi\": 0.353485922417307}, {\"truth_threshold\": 41.74363033397447, \"match_probability\": 0.9999999999997284, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 856.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5682.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13092689216136932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8690730929374695, \"precision\": 1.0, \"recall\": 0.13092689216136932, \"specificity\": 1.0, \"npv\": 0.9498946070671082, \"accuracy\": 0.9502699971199036, \"f1\": 0.2315390857451988, \"f2\": 0.15847156398104265, \"f0_5\": 0.42963260389480024, \"p4\": 0.37416051866444927, \"phi\": 0.35265669944203604}, {\"truth_threshold\": 41.77862515222752, \"match_probability\": 0.9999999999997349, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 855.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5683.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13077393174171448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8692260384559631, \"precision\": 1.0, \"recall\": 0.13077393174171448, \"specificity\": 1.0, \"npv\": 0.9498862624168396, \"accuracy\": 0.9502612352371216, \"f1\": 0.23129987826322196, \"f2\": 0.1582922945902914, \"f0_5\": 0.42930307290620606, \"p4\": 0.37384780351152885, \"phi\": 0.3524490903651285}, {\"truth_threshold\": 41.79129898226263, \"match_probability\": 0.9999999999997372, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 854.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5684.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13062098622322083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8693790435791016, \"precision\": 1.0, \"recall\": 0.13062098622322083, \"specificity\": 1.0, \"npv\": 0.9498778581619263, \"accuracy\": 0.9502524733543396, \"f1\": 0.23106060606060605, \"f2\": 0.15811301192327631, \"f0_5\": 0.4289732770745429, \"p4\": 0.3735348808825367, \"phi\": 0.3522413625892965}, {\"truth_threshold\": 41.79278865530862, \"match_probability\": 0.9999999999997375, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 851.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5687.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.13016213476657867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8698378801345825, \"precision\": 1.0, \"recall\": 0.13016213476657867, \"specificity\": 1.0, \"npv\": 0.9498527646064758, \"accuracy\": 0.9502262473106384, \"f1\": 0.2303424008661524, \"f2\": 0.15757508424989816, \"f0_5\": 0.427982297324482, \"p4\": 0.3725948660456054, \"phi\": 0.35161749564882083}, {\"truth_threshold\": 41.79418451041732, \"match_probability\": 0.9999999999997378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 848.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5690.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12970326840877533, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8702967166900635, \"precision\": 1.0, \"recall\": 0.12970326840877533, \"specificity\": 1.0, \"npv\": 0.9498276114463806, \"accuracy\": 0.9501999616622925, \"f1\": 0.22962361223937178, \"f2\": 0.15703703703703703, \"f0_5\": 0.4269889224572004, \"p4\": 0.3716529763754989, \"phi\": 0.3509925221807945}, {\"truth_threshold\": 41.79469755872449, \"match_probability\": 0.9999999999997379, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 847.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5691.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12955032289028168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8704496622085571, \"precision\": 1.0, \"recall\": 0.12955032289028168, \"specificity\": 1.0, \"npv\": 0.9498192667961121, \"accuracy\": 0.9501912593841553, \"f1\": 0.22938388625592418, \"f2\": 0.15685766139486648, \"f0_5\": 0.42665726375176305, \"p4\": 0.3713385955402869, \"phi\": 0.3507839576095279}, {\"truth_threshold\": 41.79674167043403, \"match_probability\": 0.9999999999997382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 844.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5694.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12909147143363953, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8709085583686829, \"precision\": 1.0, \"recall\": 0.12909147143363953, \"specificity\": 1.0, \"npv\": 0.9497941136360168, \"accuracy\": 0.9501649737358093, \"f1\": 0.22866431861284206, \"f2\": 0.15631945473403466, \"f0_5\": 0.42566068186403067, \"p4\": 0.3703941972424423, \"phi\": 0.3501575406455865}, {\"truth_threshold\": 41.797725251422065, \"match_probability\": 0.9999999999997384, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 843.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5695.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12893851101398468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8710615038871765, \"precision\": 1.0, \"recall\": 0.12893851101398468, \"specificity\": 1.0, \"npv\": 0.9497857689857483, \"accuracy\": 0.9501562118530273, \"f1\": 0.22842433274624035, \"f2\": 0.1561400259307279, \"f0_5\": 0.4253279515640767, \"p4\": 0.3700789785065541, \"phi\": 0.3499485240180426}, {\"truth_threshold\": 41.79928955786318, \"match_probability\": 0.9999999999997387, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 837.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5701.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12802080810070038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8719791769981384, \"precision\": 1.0, \"recall\": 0.12802080810070038, \"specificity\": 1.0, \"npv\": 0.9497355222702026, \"accuracy\": 0.9501037001609802, \"f1\": 0.22698305084745762, \"f2\": 0.15506317388565713, \"f0_5\": 0.42332591543597003, \"p4\": 0.36818324852847867, \"phi\": 0.3486916852161571}, {\"truth_threshold\": 41.801946226462135, \"match_probability\": 0.9999999999997392, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 835.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5703.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12771490216255188, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8722851276397705, \"precision\": 1.0, \"recall\": 0.12771490216255188, \"specificity\": 1.0, \"npv\": 0.9497187733650208, \"accuracy\": 0.950086236000061, \"f1\": 0.22650210226502102, \"f2\": 0.15470411679697632, \"f0_5\": 0.4226564081797935, \"p4\": 0.3675496505328853, \"phi\": 0.348271791639651}, {\"truth_threshold\": 41.8198681344594, \"match_probability\": 0.9999999999997424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 834.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5704.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12756194174289703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8724380731582642, \"precision\": 1.0, \"recall\": 0.12756194174289703, \"specificity\": 1.0, \"npv\": 0.9497103691101074, \"accuracy\": 0.950077474117279, \"f1\": 0.22626153011394465, \"f2\": 0.15452456829467132, \"f0_5\": 0.4223212477212882, \"p4\": 0.3672325340709483, \"phi\": 0.3480616449575786}, {\"truth_threshold\": 41.82557859042629, \"match_probability\": 0.9999999999997434, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 833.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5705.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12740899622440338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8725910186767578, \"precision\": 1.0, \"recall\": 0.12740899622440338, \"specificity\": 1.0, \"npv\": 0.9497020244598389, \"accuracy\": 0.9500687122344971, \"f1\": 0.22602089268755934, \"f2\": 0.1543450064850843, \"f0_5\": 0.4219858156028369, \"p4\": 0.36691520567977515, \"phi\": 0.34785137502894325}, {\"truth_threshold\": 41.860839915515704, \"match_probability\": 0.9999999999997496, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 831.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5707.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12710309028625488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8728969097137451, \"precision\": 1.0, \"recall\": 0.12710309028625488, \"specificity\": 1.0, \"npv\": 0.949685275554657, \"accuracy\": 0.9500511884689331, \"f1\": 0.2255394219025648, \"f2\": 0.15398584293814624, \"f0_5\": 0.42131413506388155, \"p4\": 0.3662799122485461, \"phi\": 0.34743046453637294}, {\"truth_threshold\": 41.86252972659918, \"match_probability\": 0.9999999999997499, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 830.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5708.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12695014476776123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8730498552322388, \"precision\": 1.0, \"recall\": 0.12695014476776123, \"specificity\": 1.0, \"npv\": 0.9496768712997437, \"accuracy\": 0.9500424265861511, \"f1\": 0.2252985884907709, \"f2\": 0.1538062411978356, \"f0_5\": 0.42097788598092917, \"p4\": 0.36596194677717403, \"phi\": 0.3472198235229459}, {\"truth_threshold\": 41.87186541924695, \"match_probability\": 0.9999999999997515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 829.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5709.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12679718434810638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8732028007507324, \"precision\": 1.0, \"recall\": 0.12679718434810638, \"specificity\": 1.0, \"npv\": 0.9496685266494751, \"accuracy\": 0.9500337243080139, \"f1\": 0.22505768969729875, \"f2\": 0.1536266261443238, \"f0_5\": 0.4206413639131317, \"p4\": 0.36564376851393227, \"phi\": 0.3470090583639664}, {\"truth_threshold\": 41.878450547536275, \"match_probability\": 0.9999999999997526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 826.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5712.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12633833289146423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8736616969108582, \"precision\": 1.0, \"recall\": 0.12633833289146423, \"specificity\": 1.0, \"npv\": 0.9496433734893799, \"accuracy\": 0.950007438659668, \"f1\": 0.22433460076045628, \"f2\": 0.15308770108977685, \"f0_5\": 0.41963015647226176, \"p4\": 0.36468795480762595, \"phi\": 0.3463760468891933}, {\"truth_threshold\": 41.88056632035972, \"match_probability\": 0.999999999999753, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 825.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5713.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1261853724718094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8738146424293518, \"precision\": 1.0, \"recall\": 0.1261853724718094, \"specificity\": 1.0, \"npv\": 0.9496350288391113, \"accuracy\": 0.949998676776886, \"f1\": 0.2240934401738422, \"f2\": 0.15290803276865478, \"f0_5\": 0.4192925391339703, \"p4\": 0.3643689232100731, \"phi\": 0.34616478289541996}, {\"truth_threshold\": 41.89627734398495, \"match_probability\": 0.9999999999997556, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 822.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5716.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12572652101516724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8742734789848328, \"precision\": 1.0, \"recall\": 0.12572652101516724, \"specificity\": 1.0, \"npv\": 0.9496099352836609, \"accuracy\": 0.9499724507331848, \"f1\": 0.2233695652173913, \"f2\": 0.15236894787573219, \"f0_5\": 0.4182780378587421, \"p4\": 0.3634105442851293, \"phi\": 0.345530238286072}, {\"truth_threshold\": 41.910970081656934, \"match_probability\": 0.9999999999997582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 820.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5718.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12542061507701874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8745793700218201, \"precision\": 1.0, \"recall\": 0.12542061507701874, \"specificity\": 1.0, \"npv\": 0.949593186378479, \"accuracy\": 0.9499549269676208, \"f1\": 0.22288665398206034, \"f2\": 0.15200949132433636, \"f0_5\": 0.4176003259319617, \"p4\": 0.3627705527092749, \"phi\": 0.345106610305}, {\"truth_threshold\": 41.915287699538084, \"match_probability\": 0.9999999999997589, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 819.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5719.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12526766955852509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8747323155403137, \"precision\": 1.0, \"recall\": 0.12526766955852509, \"specificity\": 1.0, \"npv\": 0.9495847821235657, \"accuracy\": 0.9499461650848389, \"f1\": 0.2226450999048525, \"f2\": 0.1518297430573579, \"f0_5\": 0.4172610556348074, \"p4\": 0.3624502345773258, \"phi\": 0.34489459115991605}, {\"truth_threshold\": 41.91899742048503, \"match_probability\": 0.9999999999997595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 818.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5720.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12511470913887024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8748852610588074, \"precision\": 1.0, \"recall\": 0.12511470913887024, \"specificity\": 1.0, \"npv\": 0.9495764374732971, \"accuracy\": 0.9499374032020569, \"f1\": 0.22240348015225667, \"f2\": 0.15164998146088246, \"f0_5\": 0.4169215086646279, \"p4\": 0.3621297012569991, \"phi\": 0.3446824453402999}, {\"truth_threshold\": 41.920847224879985, \"match_probability\": 0.9999999999997597, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 816.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5722.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12480881065130234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8751912117004395, \"precision\": 1.0, \"recall\": 0.12480881065130234, \"specificity\": 1.0, \"npv\": 0.9495596885681152, \"accuracy\": 0.9499199390411377, \"f1\": 0.221920043513734, \"f2\": 0.15129041827350934, \"f0_5\": 0.4162415833503367, \"p4\": 0.36148798817233346, \"phi\": 0.3442577727401899}, {\"truth_threshold\": 41.92373055672575, \"match_probability\": 0.9999999999997603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 815.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5723.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12465585768222809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8753441572189331, \"precision\": 1.0, \"recall\": 0.12465585768222809, \"specificity\": 1.0, \"npv\": 0.9495512843132019, \"accuracy\": 0.9499111771583557, \"f1\": 0.2216782265741874, \"f2\": 0.15111061667964548, \"f0_5\": 0.41590120432741373, \"p4\": 0.3611668079678066, \"phi\": 0.3440452454892584}, {\"truth_threshold\": 41.932342863717814, \"match_probability\": 0.9999999999997617, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 813.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5725.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12434995174407959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8756500482559204, \"precision\": 1.0, \"recall\": 0.12434995174407959, \"specificity\": 1.0, \"npv\": 0.9495345950126648, \"accuracy\": 0.9498936533927917, \"f1\": 0.22119439532036458, \"f2\": 0.15075097348414612, \"f0_5\": 0.41521961184882533, \"p4\": 0.36052379913164595, \"phi\": 0.34361980790412394}, {\"truth_threshold\": 41.93624731817373, \"match_probability\": 0.9999999999997623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 812.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5726.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12419699877500534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8758029937744141, \"precision\": 1.0, \"recall\": 0.12419699877500534, \"specificity\": 1.0, \"npv\": 0.9495261907577515, \"accuracy\": 0.9498848915100098, \"f1\": 0.22095238095238096, \"f2\": 0.1505711318795431, \"f0_5\": 0.41487839771101576, \"p4\": 0.3602019700580226, \"phi\": 0.3434068970951308}, {\"truth_threshold\": 41.93720416440288, \"match_probability\": 0.9999999999997625, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 811.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5727.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12404405325651169, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8759559392929077, \"precision\": 1.0, \"recall\": 0.12404405325651169, \"specificity\": 1.0, \"npv\": 0.9495178461074829, \"accuracy\": 0.9498761296272278, \"f1\": 0.22071030072118655, \"f2\": 0.15039127693505916, \"f0_5\": 0.4145369045185034, \"p4\": 0.3598799242522088, \"phi\": 0.3431938893854118}, {\"truth_threshold\": 41.94330207570768, \"match_probability\": 0.9999999999997635, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 809.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5729.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12373814731836319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.876261830329895, \"precision\": 1.0, \"recall\": 0.12373814731836319, \"specificity\": 1.0, \"npv\": 0.949501097202301, \"accuracy\": 0.9498586654663086, \"f1\": 0.22022594256158975, \"f2\": 0.15003152702051112, \"f0_5\": 0.41385307959893597, \"p4\": 0.35923518155671164, \"phi\": 0.3427674252048264}, {\"truth_threshold\": 41.958666823688226, \"match_probability\": 0.999999999999766, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 808.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5730.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12358519434928894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8764148354530334, \"precision\": 1.0, \"recall\": 0.12358519434928894, \"specificity\": 1.0, \"npv\": 0.9494927525520325, \"accuracy\": 0.9498499035835266, \"f1\": 0.21998366457936291, \"f2\": 0.14985163204747776, \"f0_5\": 0.413510747185261, \"p4\": 0.3589124842226223, \"phi\": 0.34255399966203043}, {\"truth_threshold\": 41.96109356108277, \"match_probability\": 0.9999999999997664, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 805.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5733.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12312633544206619, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8768736720085144, \"precision\": 1.0, \"recall\": 0.12312633544206619, \"specificity\": 1.0, \"npv\": 0.9494675993919373, \"accuracy\": 0.9498236179351807, \"f1\": 0.219256434699714, \"f2\": 0.1493118670475201, \"f0_5\": 0.41248206599713055, \"p4\": 0.3579430856021794, \"phi\": 0.34191294632387437}, {\"truth_threshold\": 41.96666667187635, \"match_probability\": 0.9999999999997673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 801.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5737.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12251453101634979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.877485454082489, \"precision\": 1.0, \"recall\": 0.12251453101634979, \"specificity\": 1.0, \"npv\": 0.9494341611862183, \"accuracy\": 0.9497886300086975, \"f1\": 0.21828587000953809, \"f2\": 0.14859199347011465, \"f0_5\": 0.4111065489632519, \"p4\": 0.3566474969886565, \"phi\": 0.3410564187472662}, {\"truth_threshold\": 41.96782602913475, \"match_probability\": 0.9999999999997675, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 800.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5738.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12236157804727554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8776383996009827, \"precision\": 1.0, \"recall\": 0.12236157804727554, \"specificity\": 1.0, \"npv\": 0.9494257569313049, \"accuracy\": 0.9497798681259155, \"f1\": 0.21804306350504224, \"f2\": 0.14841199168892846, \"f0_5\": 0.41076196344218524, \"p4\": 0.3563230524264984, \"phi\": 0.3408419520796627}, {\"truth_threshold\": 41.977653580498455, \"match_probability\": 0.9999999999997691, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 799.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5739.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1222086250782013, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8777913451194763, \"precision\": 1.0, \"recall\": 0.1222086250782013, \"specificity\": 1.0, \"npv\": 0.9494174122810364, \"accuracy\": 0.9497711062431335, \"f1\": 0.21780019081368407, \"f2\": 0.14823197655003525, \"f0_5\": 0.41041709471953974, \"p4\": 0.35599838845107923, \"phi\": 0.34062735416315093}, {\"truth_threshold\": 41.98574793713201, \"match_probability\": 0.9999999999997704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 798.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5740.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12205567210912704, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8779443502426147, \"precision\": 1.0, \"recall\": 0.12205567210912704, \"specificity\": 1.0, \"npv\": 0.949409008026123, \"accuracy\": 0.9497624039649963, \"f1\": 0.21755725190839695, \"f2\": 0.14805194805194805, \"f0_5\": 0.41007194244604317, \"p4\": 0.3556735048369848, \"phi\": 0.34041262474941064}, {\"truth_threshold\": 41.98637079759956, \"match_probability\": 0.9999999999997705, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 796.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5742.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12174977362155914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.878250241279602, \"precision\": 1.0, \"recall\": 0.12174977362155914, \"specificity\": 1.0, \"npv\": 0.9493923187255859, \"accuracy\": 0.9497448801994324, \"f1\": 0.21707117534769566, \"f2\": 0.14769185097224283, \"f0_5\": 0.40938078584653365, \"p4\": 0.35502307778956893, \"phi\": 0.33998277043306485}, {\"truth_threshold\": 42.00101757356397, \"match_probability\": 0.9999999999997727, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 793.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5745.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1212909147143364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.878709077835083, \"precision\": 1.0, \"recall\": 0.1212909147143364, \"specificity\": 1.0, \"npv\": 0.9493672251701355, \"accuracy\": 0.9497185945510864, \"f1\": 0.2163415632246624, \"f2\": 0.14715160512154388, \"f0_5\": 0.4083419155509784, \"p4\": 0.3540457842752411, \"phi\": 0.33933702825647444}, {\"truth_threshold\": 42.00167200543769, \"match_probability\": 0.9999999999997728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 791.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5747.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1209850087761879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8790149688720703, \"precision\": 1.0, \"recall\": 0.1209850087761879, \"specificity\": 1.0, \"npv\": 0.9493504762649536, \"accuracy\": 0.9497011303901672, \"f1\": 0.21585482330468003, \"f2\": 0.1467913743829566, \"f0_5\": 0.40764790764790765, \"p4\": 0.3533931506556403, \"phi\": 0.33890584772744137}, {\"truth_threshold\": 42.00839710392957, \"match_probability\": 0.999999999999774, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 790.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5748.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12083205580711365, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.879167914390564, \"precision\": 1.0, \"recall\": 0.12083205580711365, \"specificity\": 1.0, \"npv\": 0.9493420720100403, \"accuracy\": 0.9496923685073853, \"f1\": 0.21561135371179038, \"f2\": 0.14661123895776113, \"f0_5\": 0.40730047432460303, \"p4\": 0.3530665017800631, \"phi\": 0.3386900573221089}, {\"truth_threshold\": 42.01086535952032, \"match_probability\": 0.9999999999997743, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 789.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5749.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12067911028862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8793209195137024, \"precision\": 1.0, \"recall\": 0.12067911028862, \"specificity\": 1.0, \"npv\": 0.9493337273597717, \"accuracy\": 0.9496836066246033, \"f1\": 0.21536781766070698, \"f2\": 0.1464310901599792, \"f0_5\": 0.40695275428099853, \"p4\": 0.35273963122312196, \"phi\": 0.3384741331492242}, {\"truth_threshold\": 42.0163537959767, \"match_probability\": 0.9999999999997752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 786.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5752.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.12022025138139725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8797797560691833, \"precision\": 1.0, \"recall\": 0.12022025138139725, \"specificity\": 1.0, \"npv\": 0.9493086338043213, \"accuracy\": 0.9496573805809021, \"f1\": 0.2146368104860732, \"f2\": 0.14589056351622243, \"f0_5\": 0.4059078702747366, \"p4\": 0.3517576871772783, \"phi\": 0.3378255873788429}, {\"truth_threshold\": 42.03433153197821, \"match_probability\": 0.999999999999778, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 784.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5754.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11991434544324875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8800856471061707, \"precision\": 1.0, \"recall\": 0.11991434544324875, \"specificity\": 1.0, \"npv\": 0.9492918848991394, \"accuracy\": 0.9496398568153381, \"f1\": 0.21414913957934992, \"f2\": 0.14553014553014554, \"f0_5\": 0.40520984081041966, \"p4\": 0.3511019452085216, \"phi\": 0.337392528734284}, {\"truth_threshold\": 42.041628272703626, \"match_probability\": 0.9999999999997791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 783.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5755.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1197613924741745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8802385926246643, \"precision\": 1.0, \"recall\": 0.1197613924741745, \"specificity\": 1.0, \"npv\": 0.9492835402488708, \"accuracy\": 0.9496310949325562, \"f1\": 0.21390520420707554, \"f2\": 0.14534991646556525, \"f0_5\": 0.4048603929679421, \"p4\": 0.35077373975332493, \"phi\": 0.33717579656607033}, {\"truth_threshold\": 42.04165955806131, \"match_probability\": 0.9999999999997791, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 782.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5756.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11960843950510025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.880391538143158, \"precision\": 1.0, \"recall\": 0.11960843950510025, \"specificity\": 1.0, \"npv\": 0.9492751955986023, \"accuracy\": 0.9496223330497742, \"f1\": 0.21366120218579235, \"f2\": 0.14516967401796985, \"f0_5\": 0.40451065590730395, \"p4\": 0.35044531101046195, \"phi\": 0.33695892881923173}, {\"truth_threshold\": 42.04355572127474, \"match_probability\": 0.9999999999997794, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 779.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5759.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1191495880484581, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8808504343032837, \"precision\": 1.0, \"recall\": 0.1191495880484581, \"specificity\": 1.0, \"npv\": 0.9492501020431519, \"accuracy\": 0.949596107006073, \"f1\": 0.21292879595462622, \"f2\": 0.14462886636218483, \"f0_5\": 0.40345970582142116, \"p4\": 0.3494586827469135, \"phi\": 0.33630754154475645}, {\"truth_threshold\": 42.04587180934823, \"match_probability\": 0.9999999999997797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 778.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5760.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11899663507938385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8810033798217773, \"precision\": 1.0, \"recall\": 0.11899663507938385, \"specificity\": 1.0, \"npv\": 0.9492416977882385, \"accuracy\": 0.949587345123291, \"f1\": 0.21268452706396937, \"f2\": 0.14444857036761977, \"f0_5\": 0.40310880829015544, \"p4\": 0.34912935854283134, \"phi\": 0.3360901288749925}, {\"truth_threshold\": 42.064211400051164, \"match_probability\": 0.9999999999997825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 777.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5761.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1188436821103096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.881156325340271, \"precision\": 1.0, \"recall\": 0.1188436821103096, \"specificity\": 1.0, \"npv\": 0.94923335313797, \"accuracy\": 0.949578583240509, \"f1\": 0.21244019138755982, \"f2\": 0.14426826098258383, \"f0_5\": 0.4027576197387518, \"p4\": 0.34879980989421167, \"phi\": 0.3358725793079722}, {\"truth_threshold\": 42.066888225105366, \"match_probability\": 0.999999999999783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 776.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5762.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11869072914123535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8813092708587646, \"precision\": 1.0, \"recall\": 0.11869072914123535, \"specificity\": 1.0, \"npv\": 0.9492250084877014, \"accuracy\": 0.949569821357727, \"f1\": 0.21219578889800383, \"f2\": 0.14408793820558527, \"f0_5\": 0.4024061398050197, \"p4\": 0.34847003656872194, \"phi\": 0.33565489257741055}, {\"truth_threshold\": 42.07140690145536, \"match_probability\": 0.9999999999997836, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 774.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5764.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11838483065366745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.881615161895752, \"precision\": 1.0, \"recall\": 0.11838483065366745, \"specificity\": 1.0, \"npv\": 0.9492082595825195, \"accuracy\": 0.9495522975921631, \"f1\": 0.21170678336980306, \"f2\": 0.14372725246973186, \"f0_5\": 0.4017023043388001, \"p4\": 0.34780981495619767, \"phi\": 0.3352191065562226}, {\"truth_threshold\": 42.0758957416311, \"match_probability\": 0.9999999999997843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 771.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5767.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1179259717464447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8820740580558777, \"precision\": 1.0, \"recall\": 0.1179259717464447, \"specificity\": 1.0, \"npv\": 0.9491831660270691, \"accuracy\": 0.9495260715484619, \"f1\": 0.21097277329320016, \"f2\": 0.14318612338892397, \"f0_5\": 0.40064435668260234, \"p4\": 0.34681779163409854, \"phi\": 0.3345644243183722}, {\"truth_threshold\": 42.078697527395, \"match_probability\": 0.9999999999997847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 769.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5769.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1176200658082962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.882379949092865, \"precision\": 1.0, \"recall\": 0.1176200658082962, \"specificity\": 1.0, \"npv\": 0.9491664171218872, \"accuracy\": 0.949508547782898, \"f1\": 0.21048309839879567, \"f2\": 0.14282530366628282, \"f0_5\": 0.3999375910131059, \"p4\": 0.3461553127544985, \"phi\": 0.33412725460377646}, {\"truth_threshold\": 42.083208770732945, \"match_probability\": 0.9999999999997854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 768.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5770.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11746711283922195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8825328946113586, \"precision\": 1.0, \"recall\": 0.11746711283922195, \"specificity\": 1.0, \"npv\": 0.9491580724716187, \"accuracy\": 0.949499785900116, \"f1\": 0.21023816041609636, \"f2\": 0.1426448736998514, \"f0_5\": 0.3995837669094693, \"p4\": 0.34582373361146923, \"phi\": 0.3339084608955471}, {\"truth_threshold\": 42.083479733755944, \"match_probability\": 0.9999999999997854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 767.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5771.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1173141598701477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8826858401298523, \"precision\": 1.0, \"recall\": 0.1173141598701477, \"specificity\": 1.0, \"npv\": 0.9491497278213501, \"accuracy\": 0.9494910836219788, \"f1\": 0.20999315537303218, \"f2\": 0.1424644303280211, \"f0_5\": 0.3992296481365813, \"p4\": 0.3454919276860765, \"phi\": 0.33368952758811354}, {\"truth_threshold\": 42.08892242192734, \"match_probability\": 0.9999999999997862, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 764.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5774.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11685530841350555, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8831446766853333, \"precision\": 1.0, \"recall\": 0.11685530841350555, \"specificity\": 1.0, \"npv\": 0.9491246342658997, \"accuracy\": 0.9494647979736328, \"f1\": 0.2092577376061353, \"f2\": 0.14192301976519542, \"f0_5\": 0.3981655201167396, \"p4\": 0.3444951468584347, \"phi\": 0.33303188731553546}, {\"truth_threshold\": 42.08964039394349, \"match_probability\": 0.9999999999997863, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 762.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5776.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11654940247535706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8834505677223206, \"precision\": 1.0, \"recall\": 0.11654940247535706, \"specificity\": 1.0, \"npv\": 0.9491078853607178, \"accuracy\": 0.9494472742080688, \"f1\": 0.20876712328767122, \"f2\": 0.14156201233558743, \"f0_5\": 0.3974546213227624, \"p4\": 0.3438294880674503, \"phi\": 0.3325927898201014}, {\"truth_threshold\": 42.0942578405834, \"match_probability\": 0.9999999999997871, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 761.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5777.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.1163964495062828, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.883603572845459, \"precision\": 1.0, \"recall\": 0.1163964495062828, \"specificity\": 1.0, \"npv\": 0.9490995407104492, \"accuracy\": 0.9494385719299316, \"f1\": 0.20852171530346622, \"f2\": 0.14138148849998142, \"f0_5\": 0.397098726779378, \"p4\": 0.34349631648956913, \"phi\": 0.3323730131308159}, {\"truth_threshold\": 42.128691337647275, \"match_probability\": 0.999999999999792, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 760.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5778.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11624349653720856, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8837565183639526, \"precision\": 1.0, \"recall\": 0.11624349653720856, \"specificity\": 1.0, \"npv\": 0.9490911364555359, \"accuracy\": 0.9494298100471497, \"f1\": 0.20827624006577145, \"f2\": 0.14120095124851367, \"f0_5\": 0.39674253497598666, \"p4\": 0.3431629164734964, \"phi\": 0.3321530948979543}, {\"truth_threshold\": 42.13951376867027, \"match_probability\": 0.9999999999997936, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 756.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5782.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11563169211149216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8843683004379272, \"precision\": 1.0, \"recall\": 0.11563169211149216, \"specificity\": 1.0, \"npv\": 0.9490576982498169, \"accuracy\": 0.9493947625160217, \"f1\": 0.2072936660268714, \"f2\": 0.1404786680541103, \"f0_5\": 0.3953147877013177, \"p4\": 0.34182702726510555, \"phi\": 0.3312720334312903}, {\"truth_threshold\": 42.1422382364598, \"match_probability\": 0.9999999999997939, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 755.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5783.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11547873914241791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8845212459564209, \"precision\": 1.0, \"recall\": 0.11547873914241791, \"specificity\": 1.0, \"npv\": 0.9490493535995483, \"accuracy\": 0.9493860602378845, \"f1\": 0.20704785410667764, \"f2\": 0.14029806370089568, \"f0_5\": 0.394957103996652, \"p4\": 0.3414924814835408, \"phi\": 0.33105140326176674}, {\"truth_threshold\": 42.15084136894977, \"match_probability\": 0.9999999999997952, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 754.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5784.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11532578617334366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8846741914749146, \"precision\": 1.0, \"recall\": 0.11532578617334366, \"specificity\": 1.0, \"npv\": 0.9490410089492798, \"accuracy\": 0.9493772983551025, \"f1\": 0.2068019747668678, \"f2\": 0.14011744592284248, \"f0_5\": 0.39459912078710485, \"p4\": 0.34115770583165056, \"phi\": 0.3308306298460769}, {\"truth_threshold\": 42.156660161978756, \"match_probability\": 0.999999999999796, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 753.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5785.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11517283320426941, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8848271369934082, \"precision\": 1.0, \"recall\": 0.11517283320426941, \"specificity\": 1.0, \"npv\": 0.9490326046943665, \"accuracy\": 0.9493685364723206, \"f1\": 0.206556027979701, \"f2\": 0.13993681471845382, \"f0_5\": 0.39424083769633506, \"p4\": 0.34082270006958315, \"phi\": 0.33060971289714863}, {\"truth_threshold\": 42.16299045161588, \"match_probability\": 0.9999999999997969, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 752.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5786.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11501988023519516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8849801421165466, \"precision\": 1.0, \"recall\": 0.11501988023519516, \"specificity\": 1.0, \"npv\": 0.9490242600440979, \"accuracy\": 0.9493597745895386, \"f1\": 0.20631001371742114, \"f2\": 0.13975617008623253, \"f0_5\": 0.3938822543473706, \"p4\": 0.34048746395715307, \"phi\": 0.330388652126955}, {\"truth_threshold\": 42.1649412139544, \"match_probability\": 0.9999999999997972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 751.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5787.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11486693471670151, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8851330876350403, \"precision\": 1.0, \"recall\": 0.11486693471670151, \"specificity\": 1.0, \"npv\": 0.9490159153938293, \"accuracy\": 0.9493510127067566, \"f1\": 0.20606393195225683, \"f2\": 0.13957551202468127, \"f0_5\": 0.3935233703626074, \"p4\": 0.3401519972538404, \"phi\": 0.3301674472465102}, {\"truth_threshold\": 42.17094257500628, \"match_probability\": 0.999999999999798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 750.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5788.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11471398174762726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8852860331535339, \"precision\": 1.0, \"recall\": 0.11471398174762726, \"specificity\": 1.0, \"npv\": 0.9490075707435608, \"accuracy\": 0.9493422508239746, \"f1\": 0.2058177826564215, \"f2\": 0.13939484053230244, \"f0_5\": 0.3931641853638079, \"p4\": 0.33981629971879024, \"phi\": 0.3299460979658646}, {\"truth_threshold\": 42.178322105371876, \"match_probability\": 0.999999999999799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 749.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5789.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11456102877855301, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8854389786720276, \"precision\": 1.0, \"recall\": 0.11456102877855301, \"specificity\": 1.0, \"npv\": 0.9489991664886475, \"accuracy\": 0.9493335485458374, \"f1\": 0.20557156580211336, \"f2\": 0.13921415560759823, \"f0_5\": 0.39280469897209985, \"p4\": 0.33948037111081236, \"phi\": 0.3297246039941008}, {\"truth_threshold\": 42.18530695835168, \"match_probability\": 0.9999999999998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 748.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5790.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11440807580947876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8855919241905212, \"precision\": 1.0, \"recall\": 0.11440807580947876, \"specificity\": 1.0, \"npv\": 0.9489908218383789, \"accuracy\": 0.9493247866630554, \"f1\": 0.20532528136151523, \"f2\": 0.13903345724907062, \"f0_5\": 0.39244491080797483, \"p4\": 0.33914421118838034, \"phi\": 0.3295029650393287}, {\"truth_threshold\": 42.18968539886226, \"match_probability\": 0.9999999999998006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 745.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5793.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11394921690225601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8860507607460022, \"precision\": 1.0, \"recall\": 0.11394921690225601, \"specificity\": 1.0, \"npv\": 0.9489657282829285, \"accuracy\": 0.9492985010147095, \"f1\": 0.20458602224358094, \"f2\": 0.1384912815555638, \"f0_5\": 0.39136373187644463, \"p4\": 0.3381343411140409, \"phi\": 0.3288372081243881}, {\"truth_threshold\": 42.19583762584385, \"match_probability\": 0.9999999999998015, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 744.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5794.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11379627138376236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8862037062644958, \"precision\": 1.0, \"recall\": 0.11379627138376236, \"specificity\": 1.0, \"npv\": 0.9489573836326599, \"accuracy\": 0.9492897391319275, \"f1\": 0.20433946717934634, \"f2\": 0.1383105294467579, \"f0_5\": 0.39100273281479925, \"p4\": 0.3377972535117852, \"phi\": 0.32861498632094843}, {\"truth_threshold\": 42.19693778353923, \"match_probability\": 0.9999999999998016, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 743.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5795.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11364331841468811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8863567113876343, \"precision\": 1.0, \"recall\": 0.11364331841468811, \"specificity\": 1.0, \"npv\": 0.9489490389823914, \"accuracy\": 0.9492809772491455, \"f1\": 0.20409284438950692, \"f2\": 0.13812976389663506, \"f0_5\": 0.39064143007360674, \"p4\": 0.33745993338238106, \"phi\": 0.32839261806034514}, {\"truth_threshold\": 42.198132758383615, \"match_probability\": 0.9999999999998018, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 742.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5796.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11349036544561386, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8865096569061279, \"precision\": 1.0, \"recall\": 0.11349036544561386, \"specificity\": 1.0, \"npv\": 0.9489406943321228, \"accuracy\": 0.9492722749710083, \"f1\": 0.20384615384615384, \"f2\": 0.137948984903696, \"f0_5\": 0.390279823269514, \"p4\": 0.3371223804822732, \"phi\": 0.3281701030447562}, {\"truth_threshold\": 42.215410749815454, \"match_probability\": 0.9999999999998042, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 740.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5798.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11318445950746536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8868155479431152, \"precision\": 1.0, \"recall\": 0.11318445950746536, \"specificity\": 1.0, \"npv\": 0.9489239454269409, \"accuracy\": 0.9492547512054443, \"f1\": 0.2033525693871943, \"f2\": 0.13758738658337052, \"f0_5\": 0.38955569593598655, \"p4\": 0.3364465753940228, \"phi\": 0.3277246644431503}, {\"truth_threshold\": 42.217696343706024, \"match_probability\": 0.9999999999998045, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 737.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5801.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11272560060024261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8872743844985962, \"precision\": 1.0, \"recall\": 0.11272560060024261, \"specificity\": 1.0, \"npv\": 0.9488988518714905, \"accuracy\": 0.9492284655570984, \"f1\": 0.20261168384879724, \"f2\": 0.13704488824426345, \"f0_5\": 0.3884672148429264, \"p4\": 0.33543111587288943, \"phi\": 0.32705534910492057}, {\"truth_threshold\": 42.223409994900415, \"match_probability\": 0.9999999999998053, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 736.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5802.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11257265508174896, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8874273300170898, \"precision\": 1.0, \"recall\": 0.11257265508174896, \"specificity\": 1.0, \"npv\": 0.9488905072212219, \"accuracy\": 0.9492197632789612, \"f1\": 0.20236458619741546, \"f2\": 0.1368640285629277, \"f0_5\": 0.38810377557477327, \"p4\": 0.3350921612148015, \"phi\": 0.32683194727077464}, {\"truth_threshold\": 42.22608412919874, \"match_probability\": 0.9999999999998056, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 735.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5803.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11241970211267471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8875802755355835, \"precision\": 1.0, \"recall\": 0.11241970211267471, \"specificity\": 1.0, \"npv\": 0.9488821625709534, \"accuracy\": 0.9492110013961792, \"f1\": 0.20211742059672763, \"f2\": 0.1366831554282739, \"f0_5\": 0.38774002954209746, \"p4\": 0.33475297207156246, \"phi\": 0.3266083965685248}, {\"truth_threshold\": 42.227898835076154, \"match_probability\": 0.9999999999998058, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 734.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5804.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11226674914360046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8877332806587219, \"precision\": 1.0, \"recall\": 0.11226674914360046, \"specificity\": 1.0, \"npv\": 0.9488738179206848, \"accuracy\": 0.9492022395133972, \"f1\": 0.20187018701870188, \"f2\": 0.13650226883880087, \"f0_5\": 0.3873759763563437, \"p4\": 0.3344135481968783, \"phi\": 0.3263846966921742}, {\"truth_threshold\": 42.23070062084005, \"match_probability\": 0.9999999999998063, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 733.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5805.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11211379617452621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8878862261772156, \"precision\": 1.0, \"recall\": 0.11211379617452621, \"specificity\": 1.0, \"npv\": 0.9488654136657715, \"accuracy\": 0.9491934776306152, \"f1\": 0.2016228854352909, \"f2\": 0.13632136879300724, \"f0_5\": 0.3870116156282999, \"p4\": 0.33407388934411025, \"phi\": 0.326160847334682}, {\"truth_threshold\": 42.23548282720099, \"match_probability\": 0.9999999999998068, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 732.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5806.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11196084320545197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8880391716957092, \"precision\": 1.0, \"recall\": 0.11196084320545197, \"specificity\": 1.0, \"npv\": 0.9488570690155029, \"accuracy\": 0.9491847157478333, \"f1\": 0.2013755158184319, \"f2\": 0.13614045528939145, \"f0_5\": 0.38664694696809637, \"p4\": 0.33373399526627373, \"phi\": 0.32593684818795854}, {\"truth_threshold\": 42.24420064740525, \"match_probability\": 0.999999999999808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 731.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5807.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11180789023637772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8881921172142029, \"precision\": 1.0, \"recall\": 0.11180789023637772, \"specificity\": 1.0, \"npv\": 0.9488487243652344, \"accuracy\": 0.9491759538650513, \"f1\": 0.20112807814004677, \"f2\": 0.13595952832645167, \"f0_5\": 0.386281969985204, \"p4\": 0.3333938657160379, \"phi\": 0.3257127320342507}, {\"truth_threshold\": 42.248305045737986, \"match_probability\": 0.9999999999998086, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 729.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5809.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11150199174880981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8884980082511902, \"precision\": 1.0, \"recall\": 0.11150199174880981, \"specificity\": 1.0, \"npv\": 0.9488320350646973, \"accuracy\": 0.9491584897041321, \"f1\": 0.20063299848630797, \"f2\": 0.13559763401659164, \"f0_5\": 0.38555108948593186, \"p4\": 0.33271289920731084, \"phi\": 0.3252639820521256}, {\"truth_threshold\": 42.25037704250069, \"match_probability\": 0.9999999999998088, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 728.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5810.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11134903877973557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8886509537696838, \"precision\": 1.0, \"recall\": 0.11134903877973557, \"specificity\": 1.0, \"npv\": 0.9488236308097839, \"accuracy\": 0.9491497278213501, \"f1\": 0.2003853564547206, \"f2\": 0.13541666666666666, \"f0_5\": 0.3851851851851852, \"p4\": 0.3323720617524214, \"phi\": 0.3250393806690315}, {\"truth_threshold\": 42.285972597654684, \"match_probability\": 0.9999999999998135, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 725.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5813.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.11089017987251282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8891097903251648, \"precision\": 1.0, \"recall\": 0.11089017987251282, \"specificity\": 1.0, \"npv\": 0.9487985968589783, \"accuracy\": 0.9491234421730042, \"f1\": 0.1996420212033595, \"f2\": 0.1348736838188786, \"f0_5\": 0.38408561135833863, \"p4\": 0.3313481295999392, \"phi\": 0.3243646671874517}, {\"truth_threshold\": 42.28879864173344, \"match_probability\": 0.9999999999998139, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 719.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5819.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10997246950864792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8900275230407715, \"precision\": 1.0, \"recall\": 0.10997246950864792, \"specificity\": 1.0, \"npv\": 0.9487484097480774, \"accuracy\": 0.949070930480957, \"f1\": 0.1981535069587984, \"f2\": 0.13378735439693348, \"f0_5\": 0.381878053962184, \"p4\": 0.32929385376241366, \"phi\": 0.3230111530685826}, {\"truth_threshold\": 42.29424132990485, \"match_probability\": 0.9999999999998146, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 716.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5822.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10951361060142517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8904863595962524, \"precision\": 1.0, \"recall\": 0.10951361060142517, \"specificity\": 1.0, \"npv\": 0.9487233757972717, \"accuracy\": 0.9490447044372559, \"f1\": 0.1974083264405845, \"f2\": 0.1332440077415513, \"f0_5\": 0.3807700489257605, \"p4\": 0.3282634965231367, \"phi\": 0.32233230182733863}, {\"truth_threshold\": 42.306590127108535, \"match_probability\": 0.9999999999998161, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 714.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5824.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10920771211385727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8907923102378845, \"precision\": 1.0, \"recall\": 0.10920771211385727, \"specificity\": 1.0, \"npv\": 0.9487066864967346, \"accuracy\": 0.9490271806716919, \"f1\": 0.1969111969111969, \"f2\": 0.13288170922355394, \"f0_5\": 0.38002980625931443, \"p4\": 0.3275753947315619, \"phi\": 0.3218789923957002}, {\"truth_threshold\": 42.32676737940374, \"match_probability\": 0.9999999999998187, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 711.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5827.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10874885320663452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8912511467933655, \"precision\": 1.0, \"recall\": 0.10874885320663452, \"specificity\": 1.0, \"npv\": 0.9486815929412842, \"accuracy\": 0.9490009546279907, \"f1\": 0.19616498827424472, \"f2\": 0.1323381602948293, \"f0_5\": 0.37891707525047963, \"p4\": 0.3265414415263236, \"phi\": 0.3211978084018819}, {\"truth_threshold\": 42.329804274561965, \"match_probability\": 0.9999999999998191, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 710.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5828.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10859590023756027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8914040923118591, \"precision\": 1.0, \"recall\": 0.10859590023756027, \"specificity\": 1.0, \"npv\": 0.9486732482910156, \"accuracy\": 0.9489921927452087, \"f1\": 0.19591611479028698, \"f2\": 0.1321569503387685, \"f0_5\": 0.3785455320963958, \"p4\": 0.3261963093026305, \"phi\": 0.32097043382770735}, {\"truth_threshold\": 42.33032519881693, \"match_probability\": 0.9999999999998191, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 709.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5829.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10844294726848602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8915570378303528, \"precision\": 1.0, \"recall\": 0.10844294726848602, \"specificity\": 1.0, \"npv\": 0.9486649036407471, \"accuracy\": 0.9489834308624268, \"f1\": 0.19566717262315442, \"f2\": 0.13197572689028703, \"f0_5\": 0.37817367185833156, \"p4\": 0.3258509360764245, \"phi\": 0.3207429020769521}, {\"truth_threshold\": 42.34644486418021, \"match_probability\": 0.9999999999998211, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 708.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5830.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10828999429941177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8917099833488464, \"precision\": 1.0, \"recall\": 0.10828999429941177, \"specificity\": 1.0, \"npv\": 0.9486564993858337, \"accuracy\": 0.9489746689796448, \"f1\": 0.1954181617444107, \"f2\": 0.13179448994787787, \"f0_5\": 0.37780149413020275, \"p4\": 0.32550532159224155, \"phi\": 0.32051524643596446}, {\"truth_threshold\": 42.36727269975653, \"match_probability\": 0.9999999999998237, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 707.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5831.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10813704133033752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8918629288673401, \"precision\": 1.0, \"recall\": 0.10813704133033752, \"specificity\": 1.0, \"npv\": 0.9486481547355652, \"accuracy\": 0.9489659070968628, \"f1\": 0.19516908212560385, \"f2\": 0.13161323951003387, \"f0_5\": 0.3774289985052317, \"p4\": 0.3251594655942564, \"phi\": 0.32028739934995815}, {\"truth_threshold\": 42.37541308834547, \"match_probability\": 0.9999999999998247, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 706.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5832.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10798409581184387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8920159339904785, \"precision\": 1.0, \"recall\": 0.10798409581184387, \"specificity\": 1.0, \"npv\": 0.9486398100852966, \"accuracy\": 0.9489572048187256, \"f1\": 0.19491993373826616, \"f2\": 0.1314319755752476, \"f0_5\": 0.3770561845759453, \"p4\": 0.32481336782628206, \"phi\": 0.32005939407933687}, {\"truth_threshold\": 42.377751156029774, \"match_probability\": 0.999999999999825, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 705.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5833.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10783114284276962, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8921688795089722, \"precision\": 1.0, \"recall\": 0.10783114284276962, \"specificity\": 1.0, \"npv\": 0.9486314654350281, \"accuracy\": 0.9489484429359436, \"f1\": 0.19467071655391413, \"f2\": 0.1312506981420114, \"f0_5\": 0.37668305193417395, \"p4\": 0.3244670280317691, \"phi\": 0.3198312302856885}, {\"truth_threshold\": 42.37914701113847, \"match_probability\": 0.9999999999998251, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 703.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5835.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10752523690462112, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8924747705459595, \"precision\": 1.0, \"recall\": 0.10752523690462112, \"specificity\": 1.0, \"npv\": 0.948614776134491, \"accuracy\": 0.9489309191703796, \"f1\": 0.19417207568015468, \"f2\": 0.13088810277415752, \"f0_5\": 0.37593582887700533, \"p4\": 0.3237736213351137, \"phi\": 0.31937442576964664}, {\"truth_threshold\": 42.390749310758196, \"match_probability\": 0.9999999999998266, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 702.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5836.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10737228393554688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8926277160644531, \"precision\": 1.0, \"recall\": 0.10737228393554688, \"specificity\": 1.0, \"npv\": 0.9486064314842224, \"accuracy\": 0.9489221572875977, \"f1\": 0.19392265193370165, \"f2\": 0.13070678483652343, \"f0_5\": 0.37556173764177186, \"p4\": 0.3234265539180545, \"phi\": 0.31914578436439556}, {\"truth_threshold\": 42.39333499634273, \"match_probability\": 0.9999999999998269, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 700.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5838.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10706637799739838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8929336071014404, \"precision\": 1.0, \"recall\": 0.10706637799739838, \"specificity\": 1.0, \"npv\": 0.9485896825790405, \"accuracy\": 0.9489046335220337, \"f1\": 0.19342359767891681, \"f2\": 0.13034410844629823, \"f0_5\": 0.3748125937031484, \"p4\": 0.3227316896564447, \"phi\": 0.3186880215431482}, {\"truth_threshold\": 42.396266760060854, \"match_probability\": 0.9999999999998272, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 699.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5839.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10691343247890472, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8930865526199341, \"precision\": 1.0, \"recall\": 0.10691343247890472, \"specificity\": 1.0, \"npv\": 0.948581337928772, \"accuracy\": 0.9488959312438965, \"f1\": 0.1931739671134448, \"f2\": 0.13016274999068936, \"f0_5\": 0.37443754017570174, \"p4\": 0.32238389229478537, \"phi\": 0.31845893327255875}, {\"truth_threshold\": 42.414125648847566, \"match_probability\": 0.9999999999998294, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 698.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5840.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10676047950983047, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8932394981384277, \"precision\": 1.0, \"recall\": 0.10676047950983047, \"specificity\": 1.0, \"npv\": 0.9485729932785034, \"accuracy\": 0.9488871693611145, \"f1\": 0.19292426755113323, \"f2\": 0.12998137802607077, \"f0_5\": 0.3740621650589496, \"p4\": 0.32203585110053945, \"phi\": 0.3182296502645438}, {\"truth_threshold\": 42.420525179720066, \"match_probability\": 0.9999999999998301, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 697.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5841.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10660752654075623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8933925032615662, \"precision\": 1.0, \"recall\": 0.10660752654075623, \"specificity\": 1.0, \"npv\": 0.9485646486282349, \"accuracy\": 0.9488784074783325, \"f1\": 0.1926744989633725, \"f2\": 0.129799992550933, \"f0_5\": 0.373686467939095, \"p4\": 0.32168756581423497, \"phi\": 0.31800020598248113}, {\"truth_threshold\": 42.4278805082396, \"match_probability\": 0.999999999999831, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 695.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5843.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10630162060260773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8936983942985535, \"precision\": 1.0, \"recall\": 0.10630162060260773, \"specificity\": 1.0, \"npv\": 0.9485479593276978, \"accuracy\": 0.9488608837127686, \"f1\": 0.19217475459698605, \"f2\": 0.12943718106306104, \"f0_5\": 0.3729341060313372, \"p4\": 0.32099026192572006, \"phi\": 0.3175408321971649}, {\"truth_threshold\": 42.45474295285089, \"match_probability\": 0.9999999999998341, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 694.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5844.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10614866763353348, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8938513398170471, \"precision\": 1.0, \"recall\": 0.10614866763353348, \"specificity\": 1.0, \"npv\": 0.9485395550727844, \"accuracy\": 0.9488521218299866, \"f1\": 0.19192477876106195, \"f2\": 0.12925575504730685, \"f0_5\": 0.37255744041228256, \"p4\": 0.32064124280272177, \"phi\": 0.31731090199123824}, {\"truth_threshold\": 42.45585608090079, \"match_probability\": 0.9999999999998342, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 693.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5845.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10599571466445923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8940042853355408, \"precision\": 1.0, \"recall\": 0.10599571466445923, \"specificity\": 1.0, \"npv\": 0.9485312104225159, \"accuracy\": 0.9488434195518494, \"f1\": 0.19167473378509198, \"f2\": 0.1290743155149935, \"f0_5\": 0.37218045112781956, \"p4\": 0.3202919785460877, \"phi\": 0.3170808091059052}, {\"truth_threshold\": 42.458923337970305, \"match_probability\": 0.9999999999998346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 692.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5846.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10584276169538498, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8941572308540344, \"precision\": 1.0, \"recall\": 0.10584276169538498, \"specificity\": 1.0, \"npv\": 0.9485228657722473, \"accuracy\": 0.9488346576690674, \"f1\": 0.1914246196403873, \"f2\": 0.12889286246461035, \"f0_5\": 0.37180313776058455, \"p4\": 0.31994246889449807, \"phi\": 0.31685058719190917}, {\"truth_threshold\": 42.461167164217414, \"match_probability\": 0.9999999999998348, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 691.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5847.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10568981617689133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8943101763725281, \"precision\": 1.0, \"recall\": 0.10568981617689133, \"specificity\": 1.0, \"npv\": 0.9485145211219788, \"accuracy\": 0.9488258957862854, \"f1\": 0.19117443629824318, \"f2\": 0.12871139589464664, \"f0_5\": 0.37142549989249624, \"p4\": 0.31959271358626146, \"phi\": 0.3166201679073844}, {\"truth_threshold\": 42.46192208160014, \"match_probability\": 0.9999999999998349, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 687.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5851.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10507800430059433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8949220180511475, \"precision\": 1.0, \"recall\": 0.10507800430059433, \"specificity\": 1.0, \"npv\": 0.9484811425209045, \"accuracy\": 0.9487909078598022, \"f1\": 0.19017301038062284, \"f2\": 0.1279853943887626, \"f0_5\": 0.36991169502476845, \"p4\": 0.31819123053997783, \"phi\": 0.3156968497114365}, {\"truth_threshold\": 42.47481357554667, \"match_probability\": 0.9999999999998364, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 684.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5854.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10461915284395218, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8953808546066284, \"precision\": 1.0, \"recall\": 0.10461915284395218, \"specificity\": 1.0, \"npv\": 0.9484560489654541, \"accuracy\": 0.9487646222114563, \"f1\": 0.1894212129603988, \"f2\": 0.12744075122969145, \"f0_5\": 0.3687729135216735, \"p4\": 0.31713752598208994, \"phi\": 0.3150026278457533}, {\"truth_threshold\": 42.47822389392924, \"match_probability\": 0.9999999999998368, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 683.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5855.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10446619987487793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8955338001251221, \"precision\": 1.0, \"recall\": 0.10446619987487793, \"specificity\": 1.0, \"npv\": 0.9484477043151855, \"accuracy\": 0.9487558603286743, \"f1\": 0.18917047500346212, \"f2\": 0.12725917644866777, \"f0_5\": 0.36839266450916935, \"p4\": 0.31678579595498696, \"phi\": 0.3147709227063407}, {\"truth_threshold\": 42.48338831128468, \"match_probability\": 0.9999999999998374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 677.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5861.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10354848206043243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8964515328407288, \"precision\": 1.0, \"recall\": 0.10354848206043243, \"specificity\": 1.0, \"npv\": 0.9483975768089294, \"accuracy\": 0.9487033486366272, \"f1\": 0.18766458766458766, \"f2\": 0.12616944351261694, \"f0_5\": 0.3661042613021847, \"p4\": 0.3146701978859372, \"phi\": 0.313376974031164}, {\"truth_threshold\": 42.48553998213973, \"match_probability\": 0.9999999999998376, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 675.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5863.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10324258357286453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8967574238777161, \"precision\": 1.0, \"recall\": 0.10324258357286453, \"specificity\": 1.0, \"npv\": 0.9483808875083923, \"accuracy\": 0.948685884475708, \"f1\": 0.1871620684874532, \"f2\": 0.12580609087859246, \"f0_5\": 0.365338817925958, \"p4\": 0.3139630043600052, \"phi\": 0.3129110118123637}, {\"truth_threshold\": 42.48644440073421, \"match_probability\": 0.9999999999998377, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 673.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5865.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10293667763471603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8970633149147034, \"precision\": 1.0, \"recall\": 0.10293667763471603, \"specificity\": 1.0, \"npv\": 0.9483641982078552, \"accuracy\": 0.948668360710144, \"f1\": 0.18665927055886838, \"f2\": 0.12544268406337372, \"f0_5\": 0.3645720476706392, \"p4\": 0.31325481018213197, \"phi\": 0.31244433665120147}, {\"truth_threshold\": 42.498445939510816, \"match_probability\": 0.999999999999839, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 670.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5868.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10247781872749329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8975221514701843, \"precision\": 1.0, \"recall\": 0.10247781872749329, \"specificity\": 1.0, \"npv\": 0.9483391642570496, \"accuracy\": 0.9486420750617981, \"f1\": 0.18590455049944507, \"f2\": 0.1248974722242935, \"f0_5\": 0.36341939683228464, \"p4\": 0.3121906379892519, \"phi\": 0.31174304493129235}, {\"truth_threshold\": 42.51014866132548, \"match_probability\": 0.9999999999998403, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 669.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5869.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10232487320899963, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8976751565933228, \"precision\": 1.0, \"recall\": 0.10232487320899963, \"specificity\": 1.0, \"npv\": 0.948330819606781, \"accuracy\": 0.9486333727836609, \"f1\": 0.18565283751907868, \"f2\": 0.12471570784087097, \"f0_5\": 0.36303451269806813, \"p4\": 0.3118354112664649, \"phi\": 0.31150893842801397}, {\"truth_threshold\": 42.510769575921195, \"match_probability\": 0.9999999999998405, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 668.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5870.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10217192023992538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8978281021118164, \"precision\": 1.0, \"recall\": 0.10217192023992538, \"specificity\": 1.0, \"npv\": 0.9483224749565125, \"accuracy\": 0.9486246109008789, \"f1\": 0.18540105467665835, \"f2\": 0.12453392990305742, \"f0_5\": 0.36264929424538545, \"p4\": 0.3114799327640508, \"phi\": 0.31127465998230996}, {\"truth_threshold\": 42.51930788553962, \"match_probability\": 0.9999999999998413, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 667.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5871.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10201896727085114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8979810476303101, \"precision\": 1.0, \"recall\": 0.10201896727085114, \"specificity\": 1.0, \"npv\": 0.9483141303062439, \"accuracy\": 0.9486158490180969, \"f1\": 0.18514920194309506, \"f2\": 0.12435213840933666, \"f0_5\": 0.36226374103845316, \"p4\": 0.31112420221119996, \"phi\": 0.31104024383840906}, {\"truth_threshold\": 42.52705509987387, \"match_probability\": 0.9999999999998422, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 666.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5872.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10186601430177689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8981339931488037, \"precision\": 1.0, \"recall\": 0.10186601430177689, \"specificity\": 1.0, \"npv\": 0.9483057856559753, \"accuracy\": 0.9486070871353149, \"f1\": 0.18489727928928373, \"f2\": 0.12417033335819226, \"f0_5\": 0.3618778526407303, \"p4\": 0.3107682193367145, \"phi\": 0.31080562036632803}, {\"truth_threshold\": 42.53614386985842, \"match_probability\": 0.9999999999998432, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 665.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5873.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10171306133270264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8982869386672974, \"precision\": 1.0, \"recall\": 0.10171306133270264, \"specificity\": 1.0, \"npv\": 0.9482974410057068, \"accuracy\": 0.948598325252533, \"f1\": 0.184645286686103, \"f2\": 0.12398851474810754, \"f0_5\": 0.3614916286149163, \"p4\": 0.3104119838690073, \"phi\": 0.3105708237815902}, {\"truth_threshold\": 42.5496382272214, \"match_probability\": 0.9999999999998447, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 664.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5874.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10156010836362839, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.898439884185791, \"precision\": 1.0, \"recall\": 0.10156010836362839, \"specificity\": 1.0, \"npv\": 0.9482890963554382, \"accuracy\": 0.948589563369751, \"f1\": 0.18439322410441544, \"f2\": 0.12380668257756564, \"f0_5\": 0.36110506852294977, \"p4\": 0.3100554955361014, \"phi\": 0.31033585369116107}, {\"truth_threshold\": 42.55299166233121, \"match_probability\": 0.999999999999845, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 663.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5875.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10140715539455414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8985928297042847, \"precision\": 1.0, \"recall\": 0.10140715539455414, \"specificity\": 1.0, \"npv\": 0.9482806921005249, \"accuracy\": 0.948580801486969, \"f1\": 0.18414109151506736, \"f2\": 0.12362483684504941, \"f0_5\": 0.3607181719260065, \"p4\": 0.3096987540656292, \"phi\": 0.3101007097005241}, {\"truth_threshold\": 42.556833728625605, \"match_probability\": 0.9999999999998455, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 662.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5876.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10125420987606049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8987457752227783, \"precision\": 1.0, \"recall\": 0.10125420987606049, \"specificity\": 1.0, \"npv\": 0.9482723474502563, \"accuracy\": 0.9485720992088318, \"f1\": 0.18388888888888888, \"f2\": 0.12344297754904154, \"f0_5\": 0.36033093838449815, \"p4\": 0.30934175918483187, \"phi\": 0.30986539141367286}, {\"truth_threshold\": 42.5625441845925, \"match_probability\": 0.999999999999846, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 656.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5882.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10033649206161499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.899663507938385, \"precision\": 1.0, \"recall\": 0.10033649206161499, \"specificity\": 1.0, \"npv\": 0.948222279548645, \"accuracy\": 0.9485195875167847, \"f1\": 0.18237420072282456, \"f2\": 0.12235153685467025, \"f0_5\": 0.35800043658589825, \"p4\": 0.30719445295924874, \"phi\": 0.3084498340263179}, {\"truth_threshold\": 42.56808236813392, \"match_probability\": 0.9999999999998467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 655.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5883.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10018353909254074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8998164534568787, \"precision\": 1.0, \"recall\": 0.10018353909254074, \"specificity\": 1.0, \"npv\": 0.9482139348983765, \"accuracy\": 0.9485108256340027, \"f1\": 0.18212150702071458, \"f2\": 0.12216958257171634, \"f0_5\": 0.35761083205940164, \"p4\": 0.3068356765359138, \"phi\": 0.30821328447746166}, {\"truth_threshold\": 42.56890656092618, \"match_probability\": 0.9999999999998467, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 654.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5884.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.10003059357404709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8999693989753723, \"precision\": 1.0, \"recall\": 0.10003059357404709, \"specificity\": 1.0, \"npv\": 0.9482055902481079, \"accuracy\": 0.9485020637512207, \"f1\": 0.18186874304783093, \"f2\": 0.12198761471312393, \"f0_5\": 0.35722088704391525, \"p4\": 0.30647664450601286, \"phi\": 0.3079765574098079}, {\"truth_threshold\": 42.571333298320724, \"match_probability\": 0.999999999999847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 651.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5887.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09957173466682434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.900428295135498, \"precision\": 1.0, \"recall\": 0.09957173466682434, \"specificity\": 1.0, \"npv\": 0.9481805562973022, \"accuracy\": 0.9484757781028748, \"f1\": 0.18111002921129504, \"f2\": 0.12144162966832071, \"f0_5\": 0.3560490045941807, \"p4\": 0.30539801201180045, \"phi\": 0.3072653420418418}, {\"truth_threshold\": 42.57434924909758, \"match_probability\": 0.9999999999998473, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 650.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5888.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09941878169775009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9005812406539917, \"precision\": 1.0, \"recall\": 0.09941878169775009, \"specificity\": 1.0, \"npv\": 0.9481722116470337, \"accuracy\": 0.9484670758247375, \"f1\": 0.1808569838619922, \"f2\": 0.12125960749197821, \"f0_5\": 0.35565769314948564, \"p4\": 0.30503795478852735, \"phi\": 0.30702790081228026}, {\"truth_threshold\": 42.595107809264384, \"match_probability\": 0.9999999999998495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 649.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5889.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09926582872867584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9007341861724854, \"precision\": 1.0, \"recall\": 0.09926582872867584, \"specificity\": 1.0, \"npv\": 0.9481638669967651, \"accuracy\": 0.9484583139419556, \"f1\": 0.18060386809517184, \"f2\": 0.12107757173239804, \"f0_5\": 0.35526603897525727, \"p4\": 0.3046776405731371, \"phi\": 0.3067902799993052}, {\"truth_threshold\": 42.60153943247492, \"match_probability\": 0.9999999999998501, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 647.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5891.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09895993024110794, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9010400772094727, \"precision\": 1.0, \"recall\": 0.09895993024110794, \"specificity\": 1.0, \"npv\": 0.948147177696228, \"accuracy\": 0.9484407901763916, \"f1\": 0.18009742519137092, \"f2\": 0.12071345945744244, \"f0_5\": 0.3544817006355468, \"p4\": 0.3039562400523586, \"phi\": 0.30631449795063265}, {\"truth_threshold\": 42.60820342837631, \"match_probability\": 0.9999999999998508, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 644.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5894.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09850107133388519, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9014989137649536, \"precision\": 1.0, \"recall\": 0.09850107133388519, \"specificity\": 1.0, \"npv\": 0.9481221437454224, \"accuracy\": 0.9484145641326904, \"f1\": 0.1793372319688109, \"f2\": 0.12016718913270637, \"f0_5\": 0.3533026113671275, \"p4\": 0.30287220485945543, \"phi\": 0.30559950274877473}, {\"truth_threshold\": 42.61616942479221, \"match_probability\": 0.9999999999998517, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 643.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5895.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09834811836481094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9016518592834473, \"precision\": 1.0, \"recall\": 0.09834811836481094, \"specificity\": 1.0, \"npv\": 0.9481137990951538, \"accuracy\": 0.9484058022499084, \"f1\": 0.17908369307895836, \"f2\": 0.11998507184176152, \"f0_5\": 0.35290889132821074, \"p4\": 0.30251034283273465, \"phi\": 0.30536079563370466}, {\"truth_threshold\": 42.622505950310234, \"match_probability\": 0.9999999999998523, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 639.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5899.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09773631393909454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9022637009620667, \"precision\": 1.0, \"recall\": 0.09773631393909454, \"specificity\": 1.0, \"npv\": 0.9480804204940796, \"accuracy\": 0.9483707547187805, \"f1\": 0.17806883098787793, \"f2\": 0.11925646672389982, \"f0_5\": 0.35133054761381133, \"p4\": 0.30106030242479687, \"phi\": 0.3044041374573309}, {\"truth_threshold\": 42.62466589650029, \"match_probability\": 0.9999999999998526, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 635.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5903.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09712450206279755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9028754830360413, \"precision\": 1.0, \"recall\": 0.09712450206279755, \"specificity\": 1.0, \"npv\": 0.9480470418930054, \"accuracy\": 0.9483357667922974, \"f1\": 0.17705283702774294, \"f2\": 0.11852764400642103, \"f0_5\": 0.3497466402291254, \"p4\": 0.2996061007963863, \"phi\": 0.3034445664411927}, {\"truth_threshold\": 42.633080194109404, \"match_probability\": 0.9999999999998533, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 633.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5905.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09681859612464905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9031813740730286, \"precision\": 1.0, \"recall\": 0.09681859612464905, \"specificity\": 1.0, \"npv\": 0.9480303525924683, \"accuracy\": 0.9483182430267334, \"f1\": 0.17654441500488077, \"f2\": 0.11816315101736047, \"f0_5\": 0.34895259095920617, \"p4\": 0.2988774338608233, \"phi\": 0.3029636488666134}, {\"truth_threshold\": 42.635749793761725, \"match_probability\": 0.9999999999998537, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 632.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5906.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0966656506061554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.903334379196167, \"precision\": 1.0, \"recall\": 0.0966656506061554, \"specificity\": 1.0, \"npv\": 0.9480220079421997, \"accuracy\": 0.9483095407485962, \"f1\": 0.17629009762900977, \"f2\": 0.11798088410991636, \"f0_5\": 0.3485550408118244, \"p4\": 0.2985127078676002, \"phi\": 0.302722909936545}, {\"truth_threshold\": 42.63844749417926, \"match_probability\": 0.9999999999998539, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 629.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5909.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09620679169893265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.903793215751648, \"precision\": 1.0, \"recall\": 0.09620679169893265, \"specificity\": 1.0, \"npv\": 0.947996973991394, \"accuracy\": 0.9482832551002502, \"f1\": 0.1755267196874564, \"f2\": 0.11743400171763564, \"f0_5\": 0.3473602827479567, \"p4\": 0.29741695636198523, \"phi\": 0.30199956721326}, {\"truth_threshold\": 42.64610106672269, \"match_probability\": 0.9999999999998547, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 628.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5910.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0960538387298584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9039461612701416, \"precision\": 1.0, \"recall\": 0.0960538387298584, \"specificity\": 1.0, \"npv\": 0.9479886293411255, \"accuracy\": 0.9482744932174683, \"f1\": 0.17527211833658946, \"f2\": 0.11725168035847648, \"f0_5\": 0.3469613259668508, \"p4\": 0.2970511803978835, \"phi\": 0.3017581118472623}, {\"truth_threshold\": 42.648148895371556, \"match_probability\": 0.9999999999998549, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 627.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5911.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09590088576078415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9040991067886353, \"precision\": 1.0, \"recall\": 0.09590088576078415, \"specificity\": 1.0, \"npv\": 0.9479802846908569, \"accuracy\": 0.9482657313346863, \"f1\": 0.17501744591765528, \"f2\": 0.11706934538257589, \"f0_5\": 0.34656201636082246, \"p4\": 0.2966851412248354, \"phi\": 0.3015164316638319}, {\"truth_threshold\": 42.65817389902327, \"match_probability\": 0.9999999999998559, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 624.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5914.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.095442034304142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9045579433441162, \"precision\": 1.0, \"recall\": 0.095442034304142, \"specificity\": 1.0, \"npv\": 0.9479552507400513, \"accuracy\": 0.9482395052909851, \"f1\": 0.17425300195476123, \"f2\": 0.11652225873916941, \"f0_5\": 0.34536196590657514, \"p4\": 0.2955854415766747, \"phi\": 0.30079025159265027}, {\"truth_threshold\": 42.66567380946661, \"match_probability\": 0.9999999999998567, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 623.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5915.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09528908133506775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9047109484672546, \"precision\": 1.0, \"recall\": 0.09528908133506775, \"specificity\": 1.0, \"npv\": 0.9479469060897827, \"accuracy\": 0.9482307434082031, \"f1\": 0.1739980449657869, \"f2\": 0.11633986928104575, \"f0_5\": 0.3449612403100775, \"p4\": 0.29521834669040814, \"phi\": 0.30054781019864113}, {\"truth_threshold\": 42.67756996945636, \"match_probability\": 0.9999999999998579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 622.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5916.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0951361283659935, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9048638939857483, \"precision\": 1.0, \"recall\": 0.0951361283659935, \"specificity\": 1.0, \"npv\": 0.9479385614395142, \"accuracy\": 0.9482219815254211, \"f1\": 0.17374301675977655, \"f2\": 0.11615746619855083, \"f0_5\": 0.34456015953910923, \"p4\": 0.29485098715438135, \"phi\": 0.3003051773498891}, {\"truth_threshold\": 42.681264453014094, \"match_probability\": 0.9999999999998582, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 616.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5922.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0942184180021286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9057815670967102, \"precision\": 1.0, \"recall\": 0.0942184180021286, \"specificity\": 1.0, \"npv\": 0.9478885531425476, \"accuracy\": 0.948169469833374, \"f1\": 0.17221135029354206, \"f2\": 0.11506276150627615, \"f0_5\": 0.3421461897356143, \"p4\": 0.29264125605592806, \"phi\": 0.2988453695913029}, {\"truth_threshold\": 42.68355958555386, \"match_probability\": 0.9999999999998584, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 614.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5924.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0939125120639801, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9060875177383423, \"precision\": 1.0, \"recall\": 0.0939125120639801, \"specificity\": 1.0, \"npv\": 0.9478718638420105, \"accuracy\": 0.9481519460678101, \"f1\": 0.17170022371364654, \"f2\": 0.11469775087797952, \"f0_5\": 0.3413386702245942, \"p4\": 0.2919025486550949, \"phi\": 0.2983572021355759}, {\"truth_threshold\": 42.693648177469925, \"match_probability\": 0.9999999999998594, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 611.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5927.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09345365315675735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9065463542938232, \"precision\": 1.0, \"recall\": 0.09345365315675735, \"specificity\": 1.0, \"npv\": 0.9478468298912048, \"accuracy\": 0.9481257200241089, \"f1\": 0.17093299762204503, \"f2\": 0.11415013264581698, \"f0_5\": 0.34012469383210864, \"p4\": 0.2907924822958717, \"phi\": 0.29762350005124527}, {\"truth_threshold\": 42.7034146538636, \"match_probability\": 0.9999999999998603, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 609.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5929.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09314775466918945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9068522453308105, \"precision\": 1.0, \"recall\": 0.09314775466918945, \"specificity\": 1.0, \"npv\": 0.9478301405906677, \"accuracy\": 0.9481081962585449, \"f1\": 0.17042115572967678, \"f2\": 0.11378498561339262, \"f0_5\": 0.33931357254290173, \"p4\": 0.29005109779146754, \"phi\": 0.2971333864468771}, {\"truth_threshold\": 42.71257074486366, \"match_probability\": 0.9999999999998612, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 608.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5930.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0929948017001152, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9070051908493042, \"precision\": 1.0, \"recall\": 0.0929948017001152, \"specificity\": 1.0, \"npv\": 0.9478217959403992, \"accuracy\": 0.9480994343757629, \"f1\": 0.17016512734396866, \"f2\": 0.11360239162929746, \"f0_5\": 0.33890746934225197, \"p4\": 0.28968000257616583, \"phi\": 0.2968880236465388}, {\"truth_threshold\": 42.719563228663716, \"match_probability\": 0.9999999999998619, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 607.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5931.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09284184873104095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9071581363677979, \"precision\": 1.0, \"recall\": 0.09284184873104095, \"specificity\": 1.0, \"npv\": 0.9478134512901306, \"accuracy\": 0.9480907320976257, \"f1\": 0.16990902729181245, \"f2\": 0.11341978399790725, \"f0_5\": 0.3385010037921035, \"p4\": 0.28930863832506926, \"phi\": 0.29664246222179974}, {\"truth_threshold\": 42.72635234254263, \"match_probability\": 0.9999999999998626, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 606.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5932.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0926888957619667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9073110818862915, \"precision\": 1.0, \"recall\": 0.0926888957619667, \"specificity\": 1.0, \"npv\": 0.9478051066398621, \"accuracy\": 0.9480819702148438, \"f1\": 0.1696528555431131, \"f2\": 0.11323716271769191, \"f0_5\": 0.33809417540727515, \"p4\": 0.28893700474234024, \"phi\": 0.2963967016788714}, {\"truth_threshold\": 42.732541082661925, \"match_probability\": 0.9999999999998631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 605.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5933.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09253594279289246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9074640274047852, \"precision\": 1.0, \"recall\": 0.09253594279289246, \"specificity\": 1.0, \"npv\": 0.9477967619895935, \"accuracy\": 0.9480732083320618, \"f1\": 0.16939661206775863, \"f2\": 0.11305452778712113, \"f0_5\": 0.3376869837017191, \"p4\": 0.2885651015317074, \"phi\": 0.29615075969904814}, {\"truth_threshold\": 42.744960130218004, \"match_probability\": 0.9999999999998643, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 604.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5934.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0923829898238182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9076170325279236, \"precision\": 1.0, \"recall\": 0.0923829898238182, \"specificity\": 1.0, \"npv\": 0.947788417339325, \"accuracy\": 0.9480644464492798, \"f1\": 0.16914029683562026, \"f2\": 0.11287187920466438, \"f0_5\": 0.3372794281885191, \"p4\": 0.2881929283964647, \"phi\": 0.2959045994451642}, {\"truth_threshold\": 42.762763681838074, \"match_probability\": 0.999999999999866, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 602.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5936.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0920770913362503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9079229235649109, \"precision\": 1.0, \"recall\": 0.0920770913362503, \"specificity\": 1.0, \"npv\": 0.9477717876434326, \"accuracy\": 0.9480469226837158, \"f1\": 0.16862745098039217, \"f2\": 0.11250654107796965, \"f0_5\": 0.3364632237871675, \"p4\": 0.28744777116314735, \"phi\": 0.29541169482207774}, {\"truth_threshold\": 42.77399403624191, \"match_probability\": 0.999999999999867, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 601.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5937.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09192413836717606, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9080758690834045, \"precision\": 1.0, \"recall\": 0.09192413836717606, \"specificity\": 1.0, \"npv\": 0.9477634429931641, \"accuracy\": 0.9480382204055786, \"f1\": 0.16837092029696035, \"f2\": 0.11232385153066946, \"f0_5\": 0.3360545739208231, \"p4\": 0.2870747864694801, \"phi\": 0.2951649312397027}, {\"truth_threshold\": 42.77666898994534, \"match_probability\": 0.9999999999998673, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 600.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5938.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0917711853981018, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9082288146018982, \"precision\": 1.0, \"recall\": 0.0917711853981018, \"specificity\": 1.0, \"npv\": 0.9477550983428955, \"accuracy\": 0.9480294585227966, \"f1\": 0.16811431773606053, \"f2\": 0.11214114832535885, \"f0_5\": 0.3356455582904453, \"p4\": 0.2867015306600162, \"phi\": 0.29491796553322447}, {\"truth_threshold\": 42.783095259104776, \"match_probability\": 0.9999999999998679, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 596.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5942.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09115937352180481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9088405966758728, \"precision\": 1.0, \"recall\": 0.09115937352180481, \"specificity\": 1.0, \"npv\": 0.9477217197418213, \"accuracy\": 0.9479944109916687, \"f1\": 0.16708718811326045, \"f2\": 0.11141019889337521, \"f0_5\": 0.33400582828962116, \"p4\": 0.2852057902797698, \"phi\": 0.29392808958106553}, {\"truth_threshold\": 42.78565241912149, \"match_probability\": 0.9999999999998681, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 595.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5943.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09100642055273056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9089936017990112, \"precision\": 1.0, \"recall\": 0.09100642055273056, \"specificity\": 1.0, \"npv\": 0.9477133750915527, \"accuracy\": 0.9479857087135315, \"f1\": 0.16683022571148184, \"f2\": 0.11122742737503272, \"f0_5\": 0.33359497645211933, \"p4\": 0.28483117439915057, \"phi\": 0.2936801056018962}, {\"truth_threshold\": 42.79129898226263, \"match_probability\": 0.9999999999998687, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 594.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5944.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09085347503423691, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9091465473175049, \"precision\": 1.0, \"recall\": 0.09085347503423691, \"specificity\": 1.0, \"npv\": 0.9477050304412842, \"accuracy\": 0.9479769468307495, \"f1\": 0.16657319125070105, \"f2\": 0.11104464218948627, \"f0_5\": 0.33318375588961185, \"p4\": 0.28445628560277825, \"phi\": 0.2934319347603939}, {\"truth_threshold\": 42.79243095175255, \"match_probability\": 0.9999999999998688, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 593.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5945.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09070052206516266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9092994928359985, \"precision\": 1.0, \"recall\": 0.09070052206516266, \"specificity\": 1.0, \"npv\": 0.9476967453956604, \"accuracy\": 0.9479681849479675, \"f1\": 0.166316084700603, \"f2\": 0.11086184333520284, \"f0_5\": 0.3327721661054994, \"p4\": 0.2840811235891125, \"phi\": 0.2931835398631423}, {\"truth_threshold\": 42.81016218619635, \"match_probability\": 0.9999999999998703, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 592.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5946.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09054756909608841, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9094524383544922, \"precision\": 1.0, \"recall\": 0.09054756909608841, \"specificity\": 1.0, \"npv\": 0.9476884007453918, \"accuracy\": 0.9479594230651855, \"f1\": 0.16605890603085555, \"f2\": 0.11067903081064911, \"f0_5\": 0.3323602066022906, \"p4\": 0.28370568805616864, \"phi\": 0.2929349387151141}, {\"truth_threshold\": 42.820445327922144, \"match_probability\": 0.9999999999998712, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 591.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5947.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09039461612701416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9096053838729858, \"precision\": 1.0, \"recall\": 0.09039461612701416, \"specificity\": 1.0, \"npv\": 0.9476800560951233, \"accuracy\": 0.9479506611824036, \"f1\": 0.16580165521110954, \"f2\": 0.11049620461429159, \"f0_5\": 0.33194787688159966, \"p4\": 0.2833299787015167, \"phi\": 0.2926861307906393}, {\"truth_threshold\": 42.82916314812641, \"match_probability\": 0.999999999999872, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 590.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5948.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09024166315793991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9097583293914795, \"precision\": 1.0, \"recall\": 0.09024166315793991, \"specificity\": 1.0, \"npv\": 0.9476717114448547, \"accuracy\": 0.9479418992996216, \"f1\": 0.16554433221099887, \"f2\": 0.11031336474459652, \"f0_5\": 0.33153517644414476, \"p4\": 0.282953995222281, \"phi\": 0.2924371155618206}, {\"truth_threshold\": 42.840940358078, \"match_probability\": 0.9999999999998731, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 589.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5949.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.09008871018886566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9099112749099731, \"precision\": 1.0, \"recall\": 0.09008871018886566, \"specificity\": 1.0, \"npv\": 0.9476633667945862, \"accuracy\": 0.9479331970214844, \"f1\": 0.1652869370001403, \"f2\": 0.11013051120002991, \"f0_5\": 0.3311221047897459, \"p4\": 0.28257773731513874, \"phi\": 0.29218791091958124}, {\"truth_threshold\": 42.84901448011892, \"match_probability\": 0.9999999999998738, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 588.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5950.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08993575721979141, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9100642204284668, \"precision\": 1.0, \"recall\": 0.08993575721979141, \"specificity\": 1.0, \"npv\": 0.9476550221443176, \"accuracy\": 0.9479244351387024, \"f1\": 0.1650294695481336, \"f2\": 0.1099476439790576, \"f0_5\": 0.33070866141732286, \"p4\": 0.28220120467631965, \"phi\": 0.2919384795049867}, {\"truth_threshold\": 42.856887323890206, \"match_probability\": 0.9999999999998744, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 587.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5951.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08978281170129776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9102171659469604, \"precision\": 1.0, \"recall\": 0.08978281170129776, \"specificity\": 1.0, \"npv\": 0.9476466774940491, \"accuracy\": 0.9479156732559204, \"f1\": 0.1647719298245614, \"f2\": 0.1097647630801451, \"f0_5\": 0.3302948458248931, \"p4\": 0.28182439700160505, \"phi\": 0.2916888391889033}, {\"truth_threshold\": 42.85814221509818, \"match_probability\": 0.9999999999998745, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 586.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5952.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08962985873222351, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9103701710700989, \"precision\": 1.0, \"recall\": 0.08962985873222351, \"specificity\": 1.0, \"npv\": 0.9476383328437805, \"accuracy\": 0.9479069113731384, \"f1\": 0.16451431779898934, \"f2\": 0.1095818685017578, \"f0_5\": 0.3298806575095699, \"p4\": 0.28144731398632683, \"phi\": 0.2914390079023026}, {\"truth_threshold\": 42.862330012061605, \"match_probability\": 0.9999999999998749, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 585.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5953.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08947690576314926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9105231165885925, \"precision\": 1.0, \"recall\": 0.08947690576314926, \"specificity\": 1.0, \"npv\": 0.9476300477981567, \"accuracy\": 0.9478981494903564, \"f1\": 0.1642566334409659, \"f2\": 0.10939896024236077, \"f0_5\": 0.32946609596756027, \"p4\": 0.2810699553253668, \"phi\": 0.29118894818583135}, {\"truth_threshold\": 42.86653000059089, \"match_probability\": 0.9999999999998753, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 583.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5955.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08917099982500076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9108290076255798, \"precision\": 1.0, \"recall\": 0.08917099982500076, \"specificity\": 1.0, \"npv\": 0.9476133584976196, \"accuracy\": 0.9478806257247925, \"f1\": 0.16374104760567337, \"f2\": 0.10903310267439686, \"f0_5\": 0.3286358511837655, \"p4\": 0.2803144098436734, \"phi\": 0.29068819665155793}, {\"truth_threshold\": 42.87620466349625, \"match_probability\": 0.9999999999998761, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 582.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5956.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08901804685592651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9109819531440735, \"precision\": 1.0, \"recall\": 0.08901804685592651, \"specificity\": 1.0, \"npv\": 0.9476050138473511, \"accuracy\": 0.9478719234466553, \"f1\": 0.16348314606741574, \"f2\": 0.10885015336275904, \"f0_5\": 0.32822016692984435, \"p4\": 0.2799362224104455, \"phi\": 0.290437503743699}, {\"truth_threshold\": 42.87876182351297, \"match_probability\": 0.9999999999998763, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 580.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5958.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08871214091777802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9112878441810608, \"precision\": 1.0, \"recall\": 0.08871214091777802, \"specificity\": 1.0, \"npv\": 0.947588324546814, \"accuracy\": 0.9478543996810913, \"f1\": 0.16296712559707782, \"f2\": 0.1084842136764926, \"f0_5\": 0.32738767216075865, \"p4\": 0.27917901662459194, \"phi\": 0.28993549946649116}, {\"truth_threshold\": 42.88771533048152, \"match_probability\": 0.9999999999998771, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 579.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5959.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08855919539928436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9114407896995544, \"precision\": 1.0, \"recall\": 0.08855919539928436, \"specificity\": 1.0, \"npv\": 0.9475799798965454, \"accuracy\": 0.9478456377983093, \"f1\": 0.16270900660390614, \"f2\": 0.10830122329879166, \"f0_5\": 0.32697086062796477, \"p4\": 0.2787999976567485, \"phi\": 0.2896841684461896}, {\"truth_threshold\": 42.88829456392193, \"match_probability\": 0.9999999999998772, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 578.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5960.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08840624243021011, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9115937352180481, \"precision\": 1.0, \"recall\": 0.08840624243021011, \"specificity\": 1.0, \"npv\": 0.9475716948509216, \"accuracy\": 0.9478368759155273, \"f1\": 0.16245081506464307, \"f2\": 0.10811821922933033, \"f0_5\": 0.32655367231638416, \"p4\": 0.2784207008947228, \"phi\": 0.28943264220291476}, {\"truth_threshold\": 42.893417689845705, \"match_probability\": 0.9999999999998775, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 576.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5962.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08810033649206161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9118996858596802, \"precision\": 1.0, \"recall\": 0.08810033649206161, \"specificity\": 1.0, \"npv\": 0.9475550055503845, \"accuracy\": 0.9478194117546082, \"f1\": 0.1619342142254709, \"f2\": 0.10775217000897935, \"f0_5\": 0.32571816331146797, \"p4\": 0.27766127275267044, \"phi\": 0.2889289088716619}, {\"truth_threshold\": 42.89627734398495, \"match_probability\": 0.9999999999998779, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 572.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5966.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08748853206634521, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9125114679336548, \"precision\": 1.0, \"recall\": 0.08748853206634521, \"specificity\": 1.0, \"npv\": 0.9475216865539551, \"accuracy\": 0.9477843642234802, \"f1\": 0.16090014064697608, \"f2\": 0.10701990719952104, \"f0_5\": 0.32404260140493996, \"p4\": 0.2761390693227032, \"phi\": 0.2879188703710471}, {\"truth_threshold\": 42.90057748141857, \"match_probability\": 0.9999999999998782, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 571.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5967.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08733557909727097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9126644134521484, \"precision\": 1.0, \"recall\": 0.08733557909727097, \"specificity\": 1.0, \"npv\": 0.9475133419036865, \"accuracy\": 0.9477756023406982, \"f1\": 0.16064144042762696, \"f2\": 0.10683680724469558, \"f0_5\": 0.3236227612786216, \"p4\": 0.27575781933073573, \"phi\": 0.2876658130794794}, {\"truth_threshold\": 42.90148190001305, \"match_probability\": 0.9999999999998783, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 569.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5969.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08702967315912247, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9129703044891357, \"precision\": 1.0, \"recall\": 0.08702967315912247, \"specificity\": 1.0, \"npv\": 0.9474966526031494, \"accuracy\": 0.947758138179779, \"f1\": 0.16012382158435345, \"f2\": 0.10647056622132406, \"f0_5\": 0.32278193782618564, \"p4\": 0.2749944782032522, \"phi\": 0.287159061606318}, {\"truth_threshold\": 42.90557758844803, \"match_probability\": 0.9999999999998787, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 568.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5970.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08687672019004822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9131232500076294, \"precision\": 1.0, \"recall\": 0.08687672019004822, \"specificity\": 1.0, \"npv\": 0.9474883079528809, \"accuracy\": 0.9477493762969971, \"f1\": 0.15986490289895863, \"f2\": 0.1062874251497006, \"f0_5\": 0.322360953461975, \"p4\": 0.27461238644240277, \"phi\": 0.2869053475424742}, {\"truth_threshold\": 42.92022844080835, \"match_probability\": 0.9999999999998799, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 567.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5971.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08672376722097397, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9132762551307678, \"precision\": 1.0, \"recall\": 0.08672376722097397, \"specificity\": 1.0, \"npv\": 0.9474799633026123, \"accuracy\": 0.9477406144142151, \"f1\": 0.15960591133004925, \"f2\": 0.10610427036940005, \"f0_5\": 0.321939586645469, \"p4\": 0.27423001346581777, \"phi\": 0.2866514133865625}, {\"truth_threshold\": 42.92227255251789, \"match_probability\": 0.99999999999988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 566.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5972.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08657081425189972, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9134292006492615, \"precision\": 1.0, \"recall\": 0.08657081425189972, \"specificity\": 1.0, \"npv\": 0.9474716782569885, \"accuracy\": 0.9477318525314331, \"f1\": 0.15934684684684686, \"f2\": 0.10592110187888315, \"f0_5\": 0.32151783685526014, \"p4\": 0.27384735895966655, \"phi\": 0.2863972585530309}, {\"truth_threshold\": 42.937655512566536, \"match_probability\": 0.9999999999998813, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 564.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5974.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08626491576433182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9137350916862488, \"precision\": 1.0, \"recall\": 0.08626491576433182, \"specificity\": 1.0, \"npv\": 0.9474549889564514, \"accuracy\": 0.9477143883705139, \"f1\": 0.15882849901436216, \"f2\": 0.10555472376104207, \"f0_5\": 0.3206731862633614, \"p4\": 0.2730812041010072, \"phi\": 0.2858883033207656}, {\"truth_threshold\": 42.94659399138765, \"match_probability\": 0.999999999999882, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 561.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5977.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08580605685710907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9141939282417297, \"precision\": 1.0, \"recall\": 0.08580605685710907, \"specificity\": 1.0, \"npv\": 0.9474300146102905, \"accuracy\": 0.947688102722168, \"f1\": 0.1580504296379772, \"f2\": 0.10500505371916295, \"f0_5\": 0.3194033249829196, \"p4\": 0.2719298524686042, \"phi\": 0.2851231912902375}, {\"truth_threshold\": 42.95415109223767, \"match_probability\": 0.9999999999998826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 560.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5978.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08565310388803482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9143468737602234, \"precision\": 1.0, \"recall\": 0.08565310388803482, \"specificity\": 1.0, \"npv\": 0.947421669960022, \"accuracy\": 0.947679340839386, \"f1\": 0.15779092702169625, \"f2\": 0.10482180293501048, \"f0_5\": 0.3189792663476874, \"p4\": 0.27154550216839646, \"phi\": 0.2848676999817417}, {\"truth_threshold\": 42.962165279641404, \"match_probability\": 0.9999999999998833, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 558.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5980.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08534719794988632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9146528244018555, \"precision\": 1.0, \"recall\": 0.08534719794988632, \"specificity\": 1.0, \"npv\": 0.9474049806594849, \"accuracy\": 0.9476618766784668, \"f1\": 0.157271702367531, \"f2\": 0.10445526020217147, \"f0_5\": 0.3181299885974915, \"p4\": 0.2707759500318669, \"phi\": 0.284356042208552}, {\"truth_threshold\": 42.96410951185963, \"match_probability\": 0.9999999999998834, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 557.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5981.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08519425243139267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9148057699203491, \"precision\": 1.0, \"recall\": 0.08519425243139267, \"specificity\": 1.0, \"npv\": 0.9473966360092163, \"accuracy\": 0.9476531147956848, \"f1\": 0.15701198026779423, \"f2\": 0.10427196825040248, \"f0_5\": 0.31770476842345424, \"p4\": 0.27039074755988723, \"phi\": 0.2840998934678342}, {\"truth_threshold\": 42.978297497063885, \"match_probability\": 0.9999999999998845, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 556.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5982.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08504129946231842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9149587154388428, \"precision\": 1.0, \"recall\": 0.08504129946231842, \"specificity\": 1.0, \"npv\": 0.9473883509635925, \"accuracy\": 0.9476443529129028, \"f1\": 0.15675218494502396, \"f2\": 0.10408866257301183, \"f0_5\": 0.3172791600091303, \"p4\": 0.27000526039420153, \"phi\": 0.28384349912570905}, {\"truth_threshold\": 42.98558812300352, \"match_probability\": 0.9999999999998852, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 555.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5983.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08488834649324417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9151116609573364, \"precision\": 1.0, \"recall\": 0.08488834649324417, \"specificity\": 1.0, \"npv\": 0.947380006313324, \"accuracy\": 0.9476355910301208, \"f1\": 0.1564923163682504, \"f2\": 0.1039053431684577, \"f0_5\": 0.3168531628225622, \"p4\": 0.2696194882157929, \"phi\": 0.28358687749048994}, {\"truth_threshold\": 42.989386748376425, \"match_probability\": 0.9999999999998854, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 554.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5984.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08473539352416992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9152646064758301, \"precision\": 1.0, \"recall\": 0.08473539352416992, \"specificity\": 1.0, \"npv\": 0.9473716616630554, \"accuracy\": 0.9476268291473389, \"f1\": 0.1562323745064862, \"f2\": 0.10372201003519808, \"f0_5\": 0.31642677633082017, \"p4\": 0.26923343070516786, \"phi\": 0.28333004693557445}, {\"truth_threshold\": 42.995141007227296, \"match_probability\": 0.999999999999886, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 551.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5987.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08427653461694717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.915723443031311, \"precision\": 1.0, \"recall\": 0.08427653461694717, \"specificity\": 1.0, \"npv\": 0.9473466873168945, \"accuracy\": 0.9476006031036377, \"f1\": 0.1554521089011144, \"f2\": 0.10317192824776242, \"f0_5\": 0.3151452756806223, \"p4\": 0.26807354297788777, \"phi\": 0.2825581246647822}, {\"truth_threshold\": 43.003192547901456, \"match_probability\": 0.9999999999998865, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 550.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5988.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08412358164787292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9158763885498047, \"precision\": 1.0, \"recall\": 0.08412358164787292, \"specificity\": 1.0, \"npv\": 0.947338342666626, \"accuracy\": 0.9475918412208557, \"f1\": 0.15519187358916478, \"f2\": 0.10298854018425586, \"f0_5\": 0.3147173266193637, \"p4\": 0.26768634093389443, \"phi\": 0.2823003572594097}, {\"truth_threshold\": 43.01557627235729, \"match_probability\": 0.9999999999998875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 549.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5989.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08397063612937927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9160293936729431, \"precision\": 1.0, \"recall\": 0.08397063612937927, \"specificity\": 1.0, \"npv\": 0.9473299980163574, \"accuracy\": 0.9475830793380737, \"f1\": 0.15493156483702553, \"f2\": 0.10280513838433017, \"f0_5\": 0.31428898557362034, \"p4\": 0.2672988519530338, \"phi\": 0.2820423778894225}, {\"truth_threshold\": 43.03076491695802, \"match_probability\": 0.9999999999998888, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 548.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5990.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08381768316030502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9161823391914368, \"precision\": 1.0, \"recall\": 0.08381768316030502, \"specificity\": 1.0, \"npv\": 0.9473216533660889, \"accuracy\": 0.9475743174552917, \"f1\": 0.1546711826136043, \"f2\": 0.10262172284644194, \"f0_5\": 0.3138602520045819, \"p4\": 0.26691107571293304, \"phi\": 0.2817841477834311}, {\"truth_threshold\": 43.03449883975103, \"match_probability\": 0.999999999999889, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 547.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5991.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08366473019123077, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9163352847099304, \"precision\": 1.0, \"recall\": 0.08366473019123077, \"specificity\": 1.0, \"npv\": 0.9473133683204651, \"accuracy\": 0.9475655555725098, \"f1\": 0.15441072688779112, \"f2\": 0.10243829356904753, \"f0_5\": 0.31343112537245016, \"p4\": 0.266523011890736, \"phi\": 0.28152568536351485}, {\"truth_threshold\": 43.042837749258595, \"match_probability\": 0.9999999999998896, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 546.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5992.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08351177722215652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9164882302284241, \"precision\": 1.0, \"recall\": 0.08351177722215652, \"specificity\": 1.0, \"npv\": 0.9473050236701965, \"accuracy\": 0.9475568532943726, \"f1\": 0.1541501976284585, \"f2\": 0.10225485055060304, \"f0_5\": 0.3130016051364366, \"p4\": 0.26613466016310267, \"phi\": 0.28126700911818686}, {\"truth_threshold\": 43.063186394650394, \"match_probability\": 0.9999999999998912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 542.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 5996.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08289997279644012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9171000123023987, \"precision\": 1.0, \"recall\": 0.08289997279644012, \"specificity\": 1.0, \"npv\": 0.9472717046737671, \"accuracy\": 0.9475218057632446, \"f1\": 0.15310734463276837, \"f2\": 0.10152094103543867, \"f0_5\": 0.3112795773030094, \"p4\": 0.2645783677144166, \"phi\": 0.2802298852316224}, {\"truth_threshold\": 43.06729079298314, \"match_probability\": 0.9999999999998915, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 536.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6002.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08198225498199463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9180177450180054, \"precision\": 1.0, \"recall\": 0.08198225498199463, \"specificity\": 1.0, \"npv\": 0.9472216963768005, \"accuracy\": 0.9474692940711975, \"f1\": 0.15154085383093016, \"f2\": 0.10041966426858513, \"f0_5\": 0.3086846348767565, \"p4\": 0.2622352366051159, \"phi\": 0.27866713861955245}, {\"truth_threshold\": 43.082655540963685, \"match_probability\": 0.9999999999998926, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 535.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6003.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08182930201292038, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.918170690536499, \"precision\": 1.0, \"recall\": 0.08182930201292038, \"specificity\": 1.0, \"npv\": 0.947213351726532, \"accuracy\": 0.9474605321884155, \"f1\": 0.15127951364343278, \"f2\": 0.10023606999662757, \"f0_5\": 0.30825074902051164, \"p4\": 0.2618436964379175, \"phi\": 0.2784058376693777}, {\"truth_threshold\": 43.08521270098039, \"match_probability\": 0.9999999999998929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 532.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6006.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08137045055627823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.91862952709198, \"precision\": 1.0, \"recall\": 0.08137045055627823, \"specificity\": 1.0, \"npv\": 0.9471883773803711, \"accuracy\": 0.9474343061447144, \"f1\": 0.1504950495049505, \"f2\": 0.09968520461699895, \"f0_5\": 0.3069466882067851, \"p4\": 0.2606673236753806, \"phi\": 0.27762050621900647}, {\"truth_threshold\": 43.098597084832704, \"match_probability\": 0.9999999999998939, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 529.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6009.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08091159164905548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9190884232521057, \"precision\": 1.0, \"recall\": 0.08091159164905548, \"specificity\": 1.0, \"npv\": 0.9471634030342102, \"accuracy\": 0.9474080204963684, \"f1\": 0.1497099193434272, \"f2\": 0.09913421535924441, \"f0_5\": 0.3056390108620291, \"p4\": 0.25948831558175, \"phi\": 0.2768329885247428}, {\"truth_threshold\": 43.10178055049889, \"match_probability\": 0.9999999999998941, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 525.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6013.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.08029978722333908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9197002053260803, \"precision\": 1.0, \"recall\": 0.08029978722333908, \"specificity\": 1.0, \"npv\": 0.9471300840377808, \"accuracy\": 0.9473730325698853, \"f1\": 0.14866204162537167, \"f2\": 0.09839937024403043, \"f0_5\": 0.3038897893030794, \"p4\": 0.25791218990073017, \"phi\": 0.27577952522194954}, {\"truth_threshold\": 43.10793277748048, \"match_probability\": 0.9999999999998945, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 522.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6016.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07984092831611633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9201590418815613, \"precision\": 1.0, \"recall\": 0.07984092831611633, \"specificity\": 1.0, \"npv\": 0.9471051096916199, \"accuracy\": 0.9473467469215393, \"f1\": 0.14787535410764874, \"f2\": 0.09784809177476195, \"f0_5\": 0.3025736146533735, \"p4\": 0.2567269978015447, \"phi\": 0.27498683303145655}, {\"truth_threshold\": 43.11322707714999, \"match_probability\": 0.9999999999998949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 516.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6022.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07892321795225143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.921076774597168, \"precision\": 1.0, \"recall\": 0.07892321795225143, \"specificity\": 1.0, \"npv\": 0.9470551609992981, \"accuracy\": 0.9472942352294922, \"f1\": 0.1462999716472923, \"f2\": 0.0967451627418629, \"f0_5\": 0.29993024877935365, \"p4\": 0.2543486084809104, \"phi\": 0.27339466032232407}, {\"truth_threshold\": 43.11471675019598, \"match_probability\": 0.999999999999895, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 515.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6023.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07877026498317719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9212297201156616, \"precision\": 1.0, \"recall\": 0.07877026498317719, \"specificity\": 1.0, \"npv\": 0.9470468163490295, \"accuracy\": 0.947285532951355, \"f1\": 0.14603714731320006, \"f2\": 0.0965612929838377, \"f0_5\": 0.29948825308211213, \"p4\": 0.25395116862497336, \"phi\": 0.27312840895963963}, {\"truth_threshold\": 43.12458693931454, \"match_probability\": 0.9999999999998958, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 513.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6025.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07846435904502869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9215356111526489, \"precision\": 1.0, \"recall\": 0.07846435904502869, \"specificity\": 1.0, \"npv\": 0.9470301866531372, \"accuracy\": 0.947268009185791, \"f1\": 0.14551127499645441, \"f2\": 0.09619351209450591, \"f0_5\": 0.29860302677532014, \"p4\": 0.2531553930331507, \"phi\": 0.2725951598806807}, {\"truth_threshold\": 43.13101856252508, \"match_probability\": 0.9999999999998962, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 512.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6026.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07831141352653503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9216886162757874, \"precision\": 1.0, \"recall\": 0.07831141352653503, \"specificity\": 1.0, \"npv\": 0.9470218420028687, \"accuracy\": 0.947259247303009, \"f1\": 0.1452482269503546, \"f2\": 0.096009600960096, \"f0_5\": 0.29815979501514095, \"p4\": 0.2527570566170849, \"phi\": 0.2723281409513155}, {\"truth_threshold\": 43.15629579904188, \"match_probability\": 0.999999999999898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 511.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6027.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07815846055746078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.921841561794281, \"precision\": 1.0, \"recall\": 0.07815846055746078, \"specificity\": 1.0, \"npv\": 0.9470134973526001, \"accuracy\": 0.947250485420227, \"f1\": 0.14498510427010924, \"f2\": 0.0958256760304542, \"f0_5\": 0.29771615008156604, \"p4\": 0.25235842066660186, \"phi\": 0.27206086465355894}, {\"truth_threshold\": 43.16898105867299, \"match_probability\": 0.9999999999998989, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 507.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6031.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07754664868116379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9224533438682556, \"precision\": 1.0, \"recall\": 0.07754664868116379, \"specificity\": 1.0, \"npv\": 0.9469802379608154, \"accuracy\": 0.9472154974937439, \"f1\": 0.1439318665720369, \"f2\": 0.09508983832851944, \"f0_5\": 0.2959374270371235, \"p4\": 0.2507608746850474, \"phi\": 0.27098919038236946}, {\"truth_threshold\": 43.17225080552624, \"match_probability\": 0.9999999999998991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 506.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6032.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07739369571208954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9226062893867493, \"precision\": 1.0, \"recall\": 0.07739369571208954, \"specificity\": 1.0, \"npv\": 0.9469718933105469, \"accuracy\": 0.9472067356109619, \"f1\": 0.14366837024417944, \"f2\": 0.09490584439942981, \"f0_5\": 0.2954917075449661, \"p4\": 0.25036073593134, \"phi\": 0.2707206356635546}, {\"truth_threshold\": 43.18105924502468, \"match_probability\": 0.9999999999998997, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 504.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6034.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07708779722452164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9229121804237366, \"precision\": 1.0, \"recall\": 0.07708779722452164, \"specificity\": 1.0, \"npv\": 0.9469552636146545, \"accuracy\": 0.947189211845398, \"f1\": 0.14314115308151093, \"f2\": 0.09453781512605042, \"f0_5\": 0.2945990180032733, \"p4\": 0.24955955330785784, \"phi\": 0.27018269980496057}, {\"truth_threshold\": 43.18530695835168, \"match_probability\": 0.9999999999999, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 502.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6036.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07678189128637314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9232181310653687, \"precision\": 1.0, \"recall\": 0.07678189128637314, \"specificity\": 1.0, \"npv\": 0.9469385743141174, \"accuracy\": 0.9471717476844788, \"f1\": 0.14261363636363636, \"f2\": 0.09416973062204548, \"f0_5\": 0.29370465714954364, \"p4\": 0.24875716156358457, \"phi\": 0.26964370974533064}, {\"truth_threshold\": 43.18908992171654, \"match_probability\": 0.9999999999999003, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 501.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6037.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07662893831729889, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9233710765838623, \"precision\": 1.0, \"recall\": 0.07662893831729889, \"specificity\": 1.0, \"npv\": 0.9469302892684937, \"accuracy\": 0.9471629858016968, \"f1\": 0.14234976559170337, \"f2\": 0.09398566765467302, \"f0_5\": 0.29325684851322875, \"p4\": 0.2483555114069163, \"phi\": 0.2693738373785188}, {\"truth_threshold\": 43.19444177073515, \"match_probability\": 0.9999999999999006, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 499.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6039.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07632303237915039, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9236769676208496, \"precision\": 1.0, \"recall\": 0.07632303237915039, \"specificity\": 1.0, \"npv\": 0.9469135999679565, \"accuracy\": 0.9471454620361328, \"f1\": 0.14182179906210032, \"f2\": 0.09361750028141533, \"f0_5\": 0.2923599718771971, \"p4\": 0.2475513007914312, \"phi\": 0.26883325415844}, {\"truth_threshold\": 43.198132758383615, \"match_probability\": 0.9999999999999009, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 498.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6040.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07617007941007614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9238299131393433, \"precision\": 1.0, \"recall\": 0.07617007941007614, \"specificity\": 1.0, \"npv\": 0.9469053149223328, \"accuracy\": 0.9471367001533508, \"f1\": 0.14155770324047753, \"f2\": 0.09343339587242026, \"f0_5\": 0.29191090269636577, \"p4\": 0.24714873963779288, \"phi\": 0.2685625816688999}, {\"truth_threshold\": 43.223409994900415, \"match_probability\": 0.9999999999999026, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 497.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6041.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07601713389158249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9239828586578369, \"precision\": 1.0, \"recall\": 0.07601713389158249, \"specificity\": 1.0, \"npv\": 0.9468969702720642, \"accuracy\": 0.9471279382705688, \"f1\": 0.14129353233830846, \"f2\": 0.09324927764644077, \"f0_5\": 0.2914614121510673, \"p4\": 0.24674587412279225, \"phi\": 0.268291620825324}, {\"truth_threshold\": 43.24790247786022, \"match_probability\": 0.9999999999999043, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 496.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6042.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07586418092250824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9241358041763306, \"precision\": 1.0, \"recall\": 0.07586418092250824, \"specificity\": 1.0, \"npv\": 0.9468886256217957, \"accuracy\": 0.9471192359924316, \"f1\": 0.14102928632357123, \"f2\": 0.09306514560192135, \"f0_5\": 0.29101149964796996, \"p4\": 0.2463427038976908, \"phi\": 0.268020390819242}, {\"truth_threshold\": 43.255831472592796, \"match_probability\": 0.9999999999999047, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 495.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6043.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07571122795343399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9242887496948242, \"precision\": 1.0, \"recall\": 0.07571122795343399, \"specificity\": 1.0, \"npv\": 0.9468803405761719, \"accuracy\": 0.9471104741096497, \"f1\": 0.1407649651642258, \"f2\": 0.09288099973730626, \"f0_5\": 0.2905611645926274, \"p4\": 0.24593922861321704, \"phi\": 0.26774889083254205}, {\"truth_threshold\": 43.26622695373525, \"match_probability\": 0.9999999999999055, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 494.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6044.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07555827498435974, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9244417548179626, \"precision\": 1.0, \"recall\": 0.07555827498435974, \"specificity\": 1.0, \"npv\": 0.9468719959259033, \"accuracy\": 0.9471017122268677, \"f1\": 0.14050056882821388, \"f2\": 0.09269684005103955, \"f0_5\": 0.29011040638947616, \"p4\": 0.24553544791956558, \"phi\": 0.26747712004297464}, {\"truth_threshold\": 43.29379932279181, \"match_probability\": 0.9999999999999073, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 493.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6045.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07540532201528549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9245947003364563, \"precision\": 1.0, \"recall\": 0.07540532201528549, \"specificity\": 1.0, \"npv\": 0.9468637108802795, \"accuracy\": 0.9470929503440857, \"f1\": 0.14023609728345895, \"f2\": 0.09251266654156502, \"f0_5\": 0.2896592244418331, \"p4\": 0.245131361466396, \"phi\": 0.2672050977504951}, {\"truth_threshold\": 43.303852987455734, \"match_probability\": 0.9999999999999079, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 492.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6046.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07525236904621124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.92474764585495, \"precision\": 1.0, \"recall\": 0.07525236904621124, \"specificity\": 1.0, \"npv\": 0.946855366230011, \"accuracy\": 0.9470841884613037, \"f1\": 0.13997155049786628, \"f2\": 0.09232847920732623, \"f0_5\": 0.2892076181518928, \"p4\": 0.2447269689028319, \"phi\": 0.2669327828921019}, {\"truth_threshold\": 43.30504796230013, \"match_probability\": 0.999999999999908, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 491.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6047.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.075099416077137, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9249005913734436, \"precision\": 1.0, \"recall\": 0.075099416077137, \"specificity\": 1.0, \"npv\": 0.9468470215797424, \"accuracy\": 0.9470754265785217, \"f1\": 0.1397069284393228, \"f2\": 0.0921442780467665, \"f0_5\": 0.28875558692072456, \"p4\": 0.2443222698774599, \"phi\": 0.26666019473903513}, {\"truth_threshold\": 43.31131484326379, \"match_probability\": 0.9999999999999084, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 490.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6048.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07494646310806274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9250535368919373, \"precision\": 1.0, \"recall\": 0.07494646310806274, \"specificity\": 1.0, \"npv\": 0.9468387365341187, \"accuracy\": 0.9470667243003845, \"f1\": 0.1394422310756972, \"f2\": 0.09196006305832895, \"f0_5\": 0.2883031301482702, \"p4\": 0.2439172640383284, \"phi\": 0.26638735263982216}, {\"truth_threshold\": 43.32294566845133, \"match_probability\": 0.9999999999999091, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 489.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6049.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07479351758956909, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9252064824104309, \"precision\": 1.0, \"recall\": 0.07479351758956909, \"specificity\": 1.0, \"npv\": 0.9468303918838501, \"accuracy\": 0.9470579624176025, \"f1\": 0.1391774583748399, \"f2\": 0.09177583424045643, \"f0_5\": 0.2878502472333412, \"p4\": 0.24351195103294687, \"phi\": 0.26611421539637736}, {\"truth_threshold\": 43.327627498399394, \"match_probability\": 0.9999999999999094, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 488.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6050.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07464056462049484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9253594279289246, \"precision\": 1.0, \"recall\": 0.07464056462049484, \"specificity\": 1.0, \"npv\": 0.9468220472335815, \"accuracy\": 0.9470492005348206, \"f1\": 0.138912610304583, \"f2\": 0.0915915915915916, \"f0_5\": 0.287396937573616, \"p4\": 0.24310633050828462, \"phi\": 0.2658408023281444}, {\"truth_threshold\": 43.363587652948674, \"match_probability\": 0.9999999999999116, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 487.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6051.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0744876116514206, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9255123734474182, \"precision\": 1.0, \"recall\": 0.0744876116514206, \"specificity\": 1.0, \"npv\": 0.9468137621879578, \"accuracy\": 0.9470404386520386, \"f1\": 0.1386476868327402, \"f2\": 0.0914073351101768, \"f0_5\": 0.28694320056563755, \"p4\": 0.24270040211076976, \"phi\": 0.2655671125830749}, {\"truth_threshold\": 43.3661135276077, \"match_probability\": 0.9999999999999118, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 483.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6055.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0738757997751236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9261242151260376, \"precision\": 1.0, \"recall\": 0.0738757997751236, \"specificity\": 1.0, \"npv\": 0.9467804431915283, \"accuracy\": 0.9470054507255554, \"f1\": 0.13758723828514458, \"f2\": 0.09067017082785808, \"f0_5\": 0.28512396694214875, \"p4\": 0.24107360270174846, \"phi\": 0.26446958997226117}, {\"truth_threshold\": 43.370869858506566, \"match_probability\": 0.9999999999999121, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 482.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6056.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07372285425662994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9262771606445312, \"precision\": 1.0, \"recall\": 0.07372285425662994, \"specificity\": 1.0, \"npv\": 0.9467721581459045, \"accuracy\": 0.9469966888427734, \"f1\": 0.13732193732193732, \"f2\": 0.09048584516032139, \"f0_5\": 0.28466808410111033, \"p4\": 0.24066612961737946, \"phi\": 0.26419452428261714}, {\"truth_threshold\": 43.37914701113847, \"match_probability\": 0.9999999999999126, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 481.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6057.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0735699012875557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9264301061630249, \"precision\": 1.0, \"recall\": 0.0735699012875557, \"specificity\": 1.0, \"npv\": 0.946763813495636, \"accuracy\": 0.9469879269599915, \"f1\": 0.13705656076364153, \"f2\": 0.09030150565088424, \"f0_5\": 0.28421177026707634, \"p4\": 0.24025834652730413, \"phi\": 0.2639191563781256}, {\"truth_threshold\": 43.381362354676654, \"match_probability\": 0.9999999999999127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 480.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6058.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07341694831848145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9265830516815186, \"precision\": 1.0, \"recall\": 0.07341694831848145, \"specificity\": 1.0, \"npv\": 0.9467554688453674, \"accuracy\": 0.9469791650772095, \"f1\": 0.13679110857794244, \"f2\": 0.09011715229798738, \"f0_5\": 0.2837550248285647, \"p4\": 0.23985025307413332, \"phi\": 0.2636435057081641}, {\"truth_threshold\": 43.381704171155185, \"match_probability\": 0.9999999999999127, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 479.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6059.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0732639953494072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9267359972000122, \"precision\": 1.0, \"recall\": 0.0732639953494072, \"specificity\": 1.0, \"npv\": 0.9467471837997437, \"accuracy\": 0.9469704031944275, \"f1\": 0.13652558073250676, \"f2\": 0.08993278510007134, \"f0_5\": 0.2832978471729359, \"p4\": 0.23944184889992842, \"phi\": 0.263367571384745}, {\"truth_threshold\": 43.390749310758196, \"match_probability\": 0.9999999999999133, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 477.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6061.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0729580894112587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9270418882369995, \"precision\": 1.0, \"recall\": 0.0729580894112587, \"specificity\": 1.0, \"npv\": 0.9467305541038513, \"accuracy\": 0.9469529390335083, \"f1\": 0.13599429793300072, \"f2\": 0.08956400916294266, \"f0_5\": 0.28238219275396637, \"p4\": 0.23862410695390773, \"phi\": 0.2628148686620428}, {\"truth_threshold\": 43.403028392546574, \"match_probability\": 0.9999999999999141, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 476.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6062.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07280513644218445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9271948337554932, \"precision\": 1.0, \"recall\": 0.07280513644218445, \"specificity\": 1.0, \"npv\": 0.9467222094535828, \"accuracy\": 0.9469441771507263, \"f1\": 0.13572854291417166, \"f2\": 0.08937960042060988, \"f0_5\": 0.28192371475953565, \"p4\": 0.23821476846345746, \"phi\": 0.2625380780251351}, {\"truth_threshold\": 43.405407828643305, \"match_probability\": 0.9999999999999142, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 470.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6068.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07188742607831955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9281125664710999, \"precision\": 1.0, \"recall\": 0.07188742607831955, \"specificity\": 1.0, \"npv\": 0.9466723203659058, \"accuracy\": 0.9468916654586792, \"f1\": 0.1341324200913242, \"f2\": 0.08827285703553452, \"f0_5\": 0.27916369684010456, \"p4\": 0.23575216955229325, \"phi\": 0.2608712904476456}, {\"truth_threshold\": 43.42517108346473, \"match_probability\": 0.9999999999999153, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 467.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6071.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0714285746216774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9285714030265808, \"precision\": 1.0, \"recall\": 0.0714285746216774, \"specificity\": 1.0, \"npv\": 0.9466473460197449, \"accuracy\": 0.9468653798103333, \"f1\": 0.13333333333333333, \"f2\": 0.08771929824561403, \"f0_5\": 0.2777777777777778, \"p4\": 0.2345166315244049, \"phi\": 0.26003396689794817}, {\"truth_threshold\": 43.435155172037355, \"match_probability\": 0.999999999999916, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 466.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6072.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07127562165260315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9287244081497192, \"precision\": 1.0, \"recall\": 0.07127562165260315, \"specificity\": 1.0, \"npv\": 0.9466390013694763, \"accuracy\": 0.946856677532196, \"f1\": 0.13306681896059394, \"f2\": 0.08753475092042978, \"f0_5\": 0.2773149250178529, \"p4\": 0.2341041551523724, \"phi\": 0.2597542828786934}, {\"truth_threshold\": 43.45473554100687, \"match_probability\": 0.9999999999999171, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 465.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6073.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0711226686835289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9288773536682129, \"precision\": 1.0, \"recall\": 0.0711226686835289, \"specificity\": 1.0, \"npv\": 0.9466307163238525, \"accuracy\": 0.9468479156494141, \"f1\": 0.13280022847351136, \"f2\": 0.08735018972836908, \"f0_5\": 0.27685163134079543, \"p4\": 0.23369136298986862, \"phi\": 0.2594742815945349}, {\"truth_threshold\": 43.45787524853744, \"match_probability\": 0.9999999999999172, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 464.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6074.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07096971571445465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9290302991867065, \"precision\": 1.0, \"recall\": 0.07096971571445465, \"specificity\": 1.0, \"npv\": 0.946622371673584, \"accuracy\": 0.9468391537666321, \"f1\": 0.13253356183947443, \"f2\": 0.08716561466786896, \"f0_5\": 0.2763878961162735, \"p4\": 0.23327825467058386, \"phi\": 0.25919398276083444}, {\"truth_threshold\": 43.46192208160014, \"match_probability\": 0.9999999999999175, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 463.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6075.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0708167627453804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9291832447052002, \"precision\": 1.0, \"recall\": 0.0708167627453804, \"specificity\": 1.0, \"npv\": 0.9466140866279602, \"accuracy\": 0.9468303918838501, \"f1\": 0.13226681902585344, \"f2\": 0.08698102573736614, \"f0_5\": 0.2759237187127533, \"p4\": 0.23286482982764173, \"phi\": 0.2589133854110832}, {\"truth_threshold\": 43.47481357554667, \"match_probability\": 0.9999999999999182, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 460.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6078.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.07035791128873825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9296420812606812, \"precision\": 1.0, \"recall\": 0.07035791128873825, \"specificity\": 1.0, \"npv\": 0.9465891122817993, \"accuracy\": 0.9468041062355042, \"f1\": 0.13146613318090883, \"f2\": 0.08642717571020592, \"f0_5\": 0.27452852709477205, \"p4\": 0.2316226524795836, \"phi\": 0.25806981335458434}, {\"truth_threshold\": 43.48192572438421, \"match_probability\": 0.9999999999999186, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 459.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6079.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.070204958319664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9297950267791748, \"precision\": 1.0, \"recall\": 0.070204958319664, \"specificity\": 1.0, \"npv\": 0.9465807676315308, \"accuracy\": 0.9467954039573669, \"f1\": 0.13119908532228097, \"f2\": 0.08624253128405547, \"f0_5\": 0.27406257463577743, \"p4\": 0.2312079578618754, \"phi\": 0.25778801219302}, {\"truth_threshold\": 43.48644440073421, \"match_probability\": 0.9999999999999188, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 457.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6081.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0698990523815155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9301009774208069, \"precision\": 1.0, \"recall\": 0.0698990523815155, \"specificity\": 1.0, \"npv\": 0.9465641379356384, \"accuracy\": 0.946777880191803, \"f1\": 0.13066476054324516, \"f2\": 0.0858732007967229, \"f0_5\": 0.2731293330145828, \"p4\": 0.2303776131564234, \"phi\": 0.2572235194890727}, {\"truth_threshold\": 43.498517836137935, \"match_probability\": 0.9999999999999195, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 456.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6082.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06974609941244125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9302539229393005, \"precision\": 1.0, \"recall\": 0.06974609941244125, \"specificity\": 1.0, \"npv\": 0.9465558528900146, \"accuracy\": 0.946769118309021, \"f1\": 0.13039748355733485, \"f2\": 0.0856885147324113, \"f0_5\": 0.272662042573547, \"p4\": 0.2299619623275055, \"phi\": 0.25694080506633965}, {\"truth_threshold\": 43.50025020025924, \"match_probability\": 0.9999999999999196, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 455.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6083.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.069593146443367, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9304068684577942, \"precision\": 1.0, \"recall\": 0.069593146443367, \"specificity\": 1.0, \"npv\": 0.9465475082397461, \"accuracy\": 0.946760356426239, \"f1\": 0.13013013013013014, \"f2\": 0.08550381478558274, \"f0_5\": 0.2721943048576214, \"p4\": 0.229545992019385, \"phi\": 0.25665778420413043}, {\"truth_threshold\": 43.51214654535856, \"match_probability\": 0.9999999999999203, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 454.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6084.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06944019347429276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9305598139762878, \"precision\": 1.0, \"recall\": 0.06944019347429276, \"specificity\": 1.0, \"npv\": 0.9465392231941223, \"accuracy\": 0.946751594543457, \"f1\": 0.12986270022883295, \"f2\": 0.08531910095467188, \"f0_5\": 0.27172611922432366, \"p4\": 0.22912970186003542, \"phi\": 0.2563744558874453}, {\"truth_threshold\": 43.51886587842659, \"match_probability\": 0.9999999999999206, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 453.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6085.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0692872405052185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9307127594947815, \"precision\": 1.0, \"recall\": 0.0692872405052185, \"specificity\": 1.0, \"npv\": 0.9465308785438538, \"accuracy\": 0.9467428922653198, \"f1\": 0.1295951938206265, \"f2\": 0.08513437323811314, \"f0_5\": 0.2712574850299401, \"p4\": 0.22871309147685237, \"phi\": 0.25609084008815663}, {\"truth_threshold\": 43.54040191717424, \"match_probability\": 0.9999999999999218, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 452.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6086.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06913429498672485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9308657050132751, \"precision\": 1.0, \"recall\": 0.06913429498672485, \"specificity\": 1.0, \"npv\": 0.9465225338935852, \"accuracy\": 0.9467341303825378, \"f1\": 0.12932761087267525, \"f2\": 0.0849496316343407, \"f0_5\": 0.2707884016295231, \"p4\": 0.2282961604966526, \"phi\": 0.25580689381820754}, {\"truth_threshold\": 43.546056061803924, \"match_probability\": 0.9999999999999222, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 449.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6089.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0686754360795021, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9313245415687561, \"precision\": 1.0, \"recall\": 0.0686754360795021, \"specificity\": 1.0, \"npv\": 0.9464976191520691, \"accuracy\": 0.9467078447341919, \"f1\": 0.12852440246171462, \"f2\": 0.08439532348407955, \"f0_5\": 0.2693784497240221, \"p4\": 0.2270434402334127, \"phi\": 0.25495320873848626}, {\"truth_threshold\": 43.55614465371999, \"match_probability\": 0.9999999999999227, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 448.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6090.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06852248311042786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9314774870872498, \"precision\": 1.0, \"recall\": 0.06852248311042786, \"specificity\": 1.0, \"npv\": 0.9464892745018005, \"accuracy\": 0.9466990828514099, \"f1\": 0.1282565130260521, \"f2\": 0.08421052631578947, \"f0_5\": 0.2689075630252101, \"p4\": 0.22662522312169536, \"phi\": 0.2546680141103376}, {\"truth_threshold\": 43.556833728625605, \"match_probability\": 0.9999999999999227, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 447.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6091.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06836953014135361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9316304922103882, \"precision\": 1.0, \"recall\": 0.06836953014135361, \"specificity\": 1.0, \"npv\": 0.9464809894561768, \"accuracy\": 0.9466903805732727, \"f1\": 0.1279885468861847, \"f2\": 0.0840257152524531, \"f0_5\": 0.26843622387701177, \"p4\": 0.22620668353832163, \"phi\": 0.25438250476371055}, {\"truth_threshold\": 43.561650744923384, \"match_probability\": 0.999999999999923, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 446.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6092.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06821657717227936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9317834377288818, \"precision\": 1.0, \"recall\": 0.06821657717227936, \"specificity\": 1.0, \"npv\": 0.9464726448059082, \"accuracy\": 0.9466816186904907, \"f1\": 0.1277205040091638, \"f2\": 0.08384089029250319, \"f0_5\": 0.2679644316270127, \"p4\": 0.22578782110661091, \"phi\": 0.254096679637596}, {\"truth_threshold\": 43.56808236813392, \"match_probability\": 0.9999999999999233, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 445.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6093.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0680636316537857, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9319363832473755, \"precision\": 1.0, \"recall\": 0.0680636316537857, \"specificity\": 1.0, \"npv\": 0.9464643597602844, \"accuracy\": 0.9466728568077087, \"f1\": 0.12745238436202205, \"f2\": 0.0836560514343723, \"f0_5\": 0.26749218562154364, \"p4\": 0.22536863544929583, \"phi\": 0.25381055884460973}, {\"truth_threshold\": 43.587207377669124, \"match_probability\": 0.9999999999999243, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 443.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6095.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06775772571563721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9322422742843628, \"precision\": 1.0, \"recall\": 0.06775772571563721, \"specificity\": 1.0, \"npv\": 0.9464477300643921, \"accuracy\": 0.9466553330421448, \"f1\": 0.12691591462541182, \"f2\": 0.08328633201729649, \"f0_5\": 0.266546329723225, \"p4\": 0.2245292929458419, \"phi\": 0.2532373201097749}, {\"truth_threshold\": 43.59790062123051, \"match_probability\": 0.9999999999999248, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 440.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6098.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06729886680841446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9327011108398438, \"precision\": 1.0, \"recall\": 0.06729886680841446, \"specificity\": 1.0, \"npv\": 0.9464227557182312, \"accuracy\": 0.9466291069984436, \"f1\": 0.12611063341931786, \"f2\": 0.08273164861612516, \"f0_5\": 0.26512412629549287, \"p4\": 0.22326784553307222, \"phi\": 0.2523750799370684}, {\"truth_threshold\": 43.60153943247492, \"match_probability\": 0.9999999999999251, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 438.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6100.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06699296087026596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9330070614814758, \"precision\": 1.0, \"recall\": 0.06699296087026596, \"specificity\": 1.0, \"npv\": 0.9464061260223389, \"accuracy\": 0.9466115832328796, \"f1\": 0.12557339449541285, \"f2\": 0.08236179014667168, \"f0_5\": 0.26417370325693607, \"p4\": 0.22242525371693833, \"phi\": 0.2517986239538958}, {\"truth_threshold\": 43.615727417679174, \"match_probability\": 0.9999999999999258, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 437.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6101.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06684001535177231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9331600069999695, \"precision\": 1.0, \"recall\": 0.06684001535177231, \"specificity\": 1.0, \"npv\": 0.9463978409767151, \"accuracy\": 0.9466028213500977, \"f1\": 0.12530465949820788, \"f2\": 0.08217684004663582, \"f0_5\": 0.2636978035240164, \"p4\": 0.22200346860236117, \"phi\": 0.2515099294891096}, {\"truth_threshold\": 43.61616942479221, \"match_probability\": 0.9999999999999258, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 436.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6102.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06668706238269806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9333129525184631, \"precision\": 1.0, \"recall\": 0.06668706238269806, \"specificity\": 1.0, \"npv\": 0.9463894963264465, \"accuracy\": 0.9465940594673157, \"f1\": 0.12503584743332377, \"f2\": 0.08199187603430119, \"f0_5\": 0.2632214440956291, \"p4\": 0.22158135684017513, \"phi\": 0.25122088695206146}, {\"truth_threshold\": 43.625781082343096, \"match_probability\": 0.9999999999999263, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 433.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6105.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06622820347547531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9337717890739441, \"precision\": 1.0, \"recall\": 0.06622820347547531, \"specificity\": 1.0, \"npv\": 0.9463645815849304, \"accuracy\": 0.9465678334236145, \"f1\": 0.12422894850093244, \"f2\": 0.08143690050780515, \"f0_5\": 0.2617896009673519, \"p4\": 0.22031305783297198, \"phi\": 0.2503518091379456}, {\"truth_threshold\": 43.6537954585127, \"match_probability\": 0.9999999999999277, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 432.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6106.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06607525050640106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9339247345924377, \"precision\": 1.0, \"recall\": 0.06607525050640106, \"specificity\": 1.0, \"npv\": 0.9463562369346619, \"accuracy\": 0.9465590715408325, \"f1\": 0.12395982783357246, \"f2\": 0.08125188083057479, \"f0_5\": 0.26131139608032905, \"p4\": 0.2198896356423561, \"phi\": 0.25006144836957367}, {\"truth_threshold\": 43.65559933543968, \"match_probability\": 0.9999999999999278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 429.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6109.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06561639904975891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9343836307525635, \"precision\": 1.0, \"recall\": 0.06561639904975891, \"specificity\": 1.0, \"npv\": 0.9463313221931458, \"accuracy\": 0.9465328454971313, \"f1\": 0.12315200229654083, \"f2\": 0.08069673827169783, \"f0_5\": 0.2598740004846135, \"p4\": 0.21861739610739087, \"phi\": 0.24918838836191273}, {\"truth_threshold\": 43.65681140928955, \"match_probability\": 0.9999999999999278, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 428.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6110.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06546344608068466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9345365762710571, \"precision\": 1.0, \"recall\": 0.06546344608068466, \"specificity\": 1.0, \"npv\": 0.9463229775428772, \"accuracy\": 0.9465240836143494, \"f1\": 0.1228825724949756, \"f2\": 0.08051166290443942, \"f0_5\": 0.2593939393939394, \"p4\": 0.21819265731864743, \"phi\": 0.2488966908740664}, {\"truth_threshold\": 43.663660028116155, \"match_probability\": 0.9999999999999283, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 427.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6111.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06531049311161041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9346895217895508, \"precision\": 1.0, \"recall\": 0.06531049311161041, \"specificity\": 1.0, \"npv\": 0.9463146924972534, \"accuracy\": 0.9465153217315674, \"f1\": 0.12261306532663317, \"f2\": 0.08032657361074533, \"f0_5\": 0.25891341256366723, \"p4\": 0.21776758841181798, \"phi\": 0.24860465626063966}, {\"truth_threshold\": 43.670868971871634, \"match_probability\": 0.9999999999999286, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 426.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6112.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06515754014253616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9348424673080444, \"precision\": 1.0, \"recall\": 0.06515754014253616, \"specificity\": 1.0, \"npv\": 0.9463063478469849, \"accuracy\": 0.9465065598487854, \"f1\": 0.12234348075818495, \"f2\": 0.08014147038904357, \"f0_5\": 0.25843241931570005, \"p4\": 0.21734218899826457, \"phi\": 0.24831230497697482}, {\"truth_threshold\": 43.6738849226485, \"match_probability\": 0.9999999999999287, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 425.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6113.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06500458717346191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9349954128265381, \"precision\": 1.0, \"recall\": 0.06500458717346191, \"specificity\": 1.0, \"npv\": 0.9462980628013611, \"accuracy\": 0.9464977979660034, \"f1\": 0.12207381875628322, \"f2\": 0.07995635323776197, \"f0_5\": 0.2579509589706239, \"p4\": 0.21691645868873904, \"phi\": 0.24801959256197093}, {\"truth_threshold\": 43.67712796234332, \"match_probability\": 0.999999999999929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 423.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6115.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06469868123531342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9353013038635254, \"precision\": 1.0, \"recall\": 0.06469868123531342, \"specificity\": 1.0, \"npv\": 0.9462814331054688, \"accuracy\": 0.9464802742004395, \"f1\": 0.12153426231863237, \"f2\": 0.07958607714016933, \"f0_5\": 0.25698663426488455, \"p4\": 0.21606400382172045, \"phi\": 0.2474331443753249}, {\"truth_threshold\": 43.70363226604255, \"match_probability\": 0.9999999999999302, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 422.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6116.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06454573571681976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.935454249382019, \"precision\": 1.0, \"recall\": 0.06454573571681976, \"specificity\": 1.0, \"npv\": 0.9462730884552002, \"accuracy\": 0.9464715719223022, \"f1\": 0.12126436781609196, \"f2\": 0.07940091819071272, \"f0_5\": 0.2565037685387795, \"p4\": 0.21563727848266906, \"phi\": 0.24713940617504176}, {\"truth_threshold\": 43.70439091703946, \"match_probability\": 0.9999999999999303, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 417.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6121.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06378097087144852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9362190365791321, \"precision\": 1.0, \"recall\": 0.06378097087144852, \"specificity\": 1.0, \"npv\": 0.9462315440177917, \"accuracy\": 0.9464277625083923, \"f1\": 0.1199137311286844, \"f2\": 0.0784749143738944, \"f0_5\": 0.2540823787472581, \"p4\": 0.21349865704542617, \"phi\": 0.245665568631589}, {\"truth_threshold\": 43.71526309123009, \"match_probability\": 0.9999999999999307, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 416.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6122.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06362801790237427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9363719820976257, \"precision\": 1.0, \"recall\": 0.06362801790237427, \"specificity\": 1.0, \"npv\": 0.946223258972168, \"accuracy\": 0.9464190602302551, \"f1\": 0.11964337072188669, \"f2\": 0.07828967178560675, \"f0_5\": 0.25359668373567423, \"p4\": 0.21306993105469874, \"phi\": 0.24536974563522784}, {\"truth_threshold\": 43.72225733783298, \"match_probability\": 0.999999999999931, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 413.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6125.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06316916644573212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9368308186531067, \"precision\": 1.0, \"recall\": 0.06316916644573212, \"specificity\": 1.0, \"npv\": 0.9461982846260071, \"accuracy\": 0.9463927745819092, \"f1\": 0.11883182275931521, \"f2\": 0.077733860342556, \"f0_5\": 0.25213675213675213, \"p4\": 0.21178174256403748, \"phi\": 0.2444801822617732}, {\"truth_threshold\": 43.734005915086065, \"match_probability\": 0.9999999999999316, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 406.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6132.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06209849938750267, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.937901496887207, \"precision\": 1.0, \"recall\": 0.06209849938750267, \"specificity\": 1.0, \"npv\": 0.9461401104927063, \"accuracy\": 0.9463315010070801, \"f1\": 0.11693548387096774, \"f2\": 0.0764364786505008, \"f0_5\": 0.24871355060034306, \"p4\": 0.20876419036847468, \"phi\": 0.24239199354439536}, {\"truth_threshold\": 43.734715453896264, \"match_probability\": 0.9999999999999317, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 405.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6133.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06194555014371872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9380544424057007, \"precision\": 1.0, \"recall\": 0.06194555014371872, \"specificity\": 1.0, \"npv\": 0.9461318254470825, \"accuracy\": 0.9463227391242981, \"f1\": 0.1166642661673628, \"f2\": 0.07625108257709831, \"f0_5\": 0.24822260357930864, \"p4\": 0.20833175944691676, \"phi\": 0.24209225062241566}, {\"truth_threshold\": 43.74125829976303, \"match_probability\": 0.9999999999999319, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 404.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6134.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06179259717464447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9382073879241943, \"precision\": 1.0, \"recall\": 0.06179259717464447, \"specificity\": 1.0, \"npv\": 0.946123480796814, \"accuracy\": 0.9463140368461609, \"f1\": 0.1163929703255546, \"f2\": 0.07606567254104533, \"f0_5\": 0.24773117488349278, \"p4\": 0.20789898931206274, \"phi\": 0.24179211916875654}, {\"truth_threshold\": 43.74180487868258, \"match_probability\": 0.999999999999932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 403.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6135.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06163964420557022, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.938360333442688, \"precision\": 1.0, \"recall\": 0.06163964420557022, \"specificity\": 1.0, \"npv\": 0.9461151957511902, \"accuracy\": 0.9463052749633789, \"f1\": 0.11612159631177064, \"f2\": 0.07588024854076444, \"f0_5\": 0.24723926380368097, \"p4\": 0.207465879560931, \"phi\": 0.24149161998701507}, {\"truth_threshold\": 43.74563674027361, \"match_probability\": 0.9999999999999322, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 402.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6136.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06148669496178627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9385132789611816, \"precision\": 1.0, \"recall\": 0.06148669496178627, \"specificity\": 1.0, \"npv\": 0.9461069107055664, \"accuracy\": 0.9462965130805969, \"f1\": 0.11585014409221903, \"f2\": 0.07569481057467801, \"f0_5\": 0.2467468696292659, \"p4\": 0.2070324297899014, \"phi\": 0.2411907739819351}, {\"truth_threshold\": 43.76328460609303, \"match_probability\": 0.999999999999933, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 401.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6137.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06133374199271202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9386662840843201, \"precision\": 1.0, \"recall\": 0.06133374199271202, \"specificity\": 1.0, \"npv\": 0.9460985660552979, \"accuracy\": 0.9462877511978149, \"f1\": 0.11557861363308834, \"f2\": 0.07550935864120815, \"f0_5\": 0.2462539916482437, \"p4\": 0.206598639594714, \"phi\": 0.24088953523934895}, {\"truth_threshold\": 43.775357438393605, \"match_probability\": 0.9999999999999336, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 400.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6138.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06118078902363777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9388192296028137, \"precision\": 1.0, \"recall\": 0.06118078902363777, \"specificity\": 1.0, \"npv\": 0.9460902810096741, \"accuracy\": 0.946278989315033, \"f1\": 0.11530700490054771, \"f2\": 0.07532389273877674, \"f0_5\": 0.2457606291472106, \"p4\": 0.2061645085704678, \"phi\": 0.24058792461924516}, {\"truth_threshold\": 43.77666363589423, \"match_probability\": 0.9999999999999336, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 399.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6139.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06102783605456352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9389721751213074, \"precision\": 1.0, \"recall\": 0.06102783605456352, \"specificity\": 1.0, \"npv\": 0.9460819363594055, \"accuracy\": 0.946270227432251, \"f1\": 0.11503531786074672, \"f2\": 0.07513841286580543, \"f0_5\": 0.2452667814113597, \"p4\": 0.20573003631161949, \"phi\": 0.24028594072112472}, {\"truth_threshold\": 43.78115102688655, \"match_probability\": 0.9999999999999338, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 398.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6140.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06087488681077957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.939125120639801, \"precision\": 1.0, \"recall\": 0.06087488681077957, \"specificity\": 1.0, \"npv\": 0.9460736513137817, \"accuracy\": 0.9462615251541138, \"f1\": 0.11476355247981546, \"f2\": 0.07495291902071563, \"f0_5\": 0.24477244772447723, \"p4\": 0.20529522241198211, \"phi\": 0.23998358213570187}, {\"truth_threshold\": 43.78190028426038, \"match_probability\": 0.9999999999999338, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 395.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6143.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.060416027903556824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.939583957195282, \"precision\": 1.0, \"recall\": 0.060416027903556824, \"specificity\": 1.0, \"npv\": 0.9460487365722656, \"accuracy\": 0.9462352395057678, \"f1\": 0.11394778595124766, \"f2\": 0.0743963536369458, \"f0_5\": 0.24328652377432866, \"p4\": 0.20398872679678545, \"phi\": 0.23907426650452157}, {\"truth_threshold\": 43.78565241912149, \"match_probability\": 0.999999999999934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 394.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6144.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.06026307865977287, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9397369027137756, \"precision\": 1.0, \"recall\": 0.06026307865977287, \"specificity\": 1.0, \"npv\": 0.9460403919219971, \"accuracy\": 0.9462264776229858, \"f1\": 0.11367570686670514, \"f2\": 0.07421080388759135, \"f0_5\": 0.2427902390929258, \"p4\": 0.20355254225920572, \"phi\": 0.2387704174305728}, {\"truth_threshold\": 43.796034314812275, \"match_probability\": 0.9999999999999345, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 393.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6145.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.060110125690698624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9398898482322693, \"precision\": 1.0, \"recall\": 0.060110125690698624, \"specificity\": 1.0, \"npv\": 0.9460321068763733, \"accuracy\": 0.9462177157402039, \"f1\": 0.1134035492713894, \"f2\": 0.07402524015822189, \"f0_5\": 0.24229346485819975, \"p4\": 0.2031160140402034, \"phi\": 0.23846616401337742}, {\"truth_threshold\": 43.79674167043403, \"match_probability\": 0.9999999999999346, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 392.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6146.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.059957172721624374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9400428533554077, \"precision\": 1.0, \"recall\": 0.059957172721624374, \"specificity\": 1.0, \"npv\": 0.9460238218307495, \"accuracy\": 0.9462090134620667, \"f1\": 0.11313131313131314, \"f2\": 0.07383966244725738, \"f0_5\": 0.24179620034542315, \"p4\": 0.20267914172970308, \"phi\": 0.2381615272644678}, {\"truth_threshold\": 43.809090467637716, \"match_probability\": 0.9999999999999352, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 389.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6149.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.059498317539691925, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9405016899108887, \"precision\": 1.0, \"recall\": 0.059498317539691925, \"specificity\": 1.0, \"npv\": 0.9459988474845886, \"accuracy\": 0.9461827278137207, \"f1\": 0.11231413310235311, \"f2\": 0.07328284540898987, \"f0_5\": 0.24030145787002719, \"p4\": 0.20136645613866203, \"phi\": 0.23724532489740516}, {\"truth_threshold\": 43.81566312156121, \"match_probability\": 0.9999999999999354, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 386.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6152.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.059039462357759476, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9409605264663696, \"precision\": 1.0, \"recall\": 0.059039462357759476, \"specificity\": 1.0, \"npv\": 0.9459739327430725, \"accuracy\": 0.9461564421653748, \"f1\": 0.11149624494511842, \"f2\": 0.07272590247946341, \"f0_5\": 0.23880227666419204, \"p4\": 0.20005065889862247, \"phi\": 0.2363256191212782}, {\"truth_threshold\": 43.82916314812641, \"match_probability\": 0.999999999999936, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 384.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6154.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05873355641961098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9412664175033569, \"precision\": 1.0, \"recall\": 0.05873355641961098, \"specificity\": 1.0, \"npv\": 0.945957362651825, \"accuracy\": 0.9461389780044556, \"f1\": 0.11095059231436001, \"f2\": 0.07235453723243895, \"f0_5\": 0.2378003467921724, \"p4\": 0.19917172652675055, \"phi\": 0.23571050015604197}, {\"truth_threshold\": 43.844495803768915, \"match_probability\": 0.9999999999999367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 383.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6155.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.058580607175827026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9414194226264954, \"precision\": 1.0, \"recall\": 0.058580607175827026, \"specificity\": 1.0, \"npv\": 0.9459490180015564, \"accuracy\": 0.9461302161216736, \"f1\": 0.11067764773876608, \"f2\": 0.0721688336159789, \"f0_5\": 0.2372986369268897, \"p4\": 0.1987317388312607, \"phi\": 0.23540234604591723}, {\"truth_threshold\": 43.84565127091498, \"match_probability\": 0.9999999999999367, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 382.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6156.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05842765420675278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.941572368144989, \"precision\": 1.0, \"recall\": 0.05842765420675278, \"specificity\": 1.0, \"npv\": 0.9459407329559326, \"accuracy\": 0.9461214542388916, \"f1\": 0.11040462427745665, \"f2\": 0.0719831160021105, \"f0_5\": 0.23679642945697993, \"p4\": 0.19829140290740915, \"phi\": 0.23509379343947817}, {\"truth_threshold\": 43.85118945445641, \"match_probability\": 0.9999999999999369, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 381.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6157.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05827470123767853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9417253136634827, \"precision\": 1.0, \"recall\": 0.05827470123767853, \"specificity\": 1.0, \"npv\": 0.9459323883056641, \"accuracy\": 0.9461126923561096, \"f1\": 0.11013152189622778, \"f2\": 0.07179738438925112, \"f0_5\": 0.23629372364177623, \"p4\": 0.19785071833786985, \"phi\": 0.23478486364846932}, {\"truth_threshold\": 43.85965300056527, \"match_probability\": 0.9999999999999374, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 379.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6159.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05796879902482033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.94203120470047, \"precision\": 1.0, \"recall\": 0.05796879902482033, \"specificity\": 1.0, \"npv\": 0.9459158182144165, \"accuracy\": 0.9460952281951904, \"f1\": 0.10958508023709701, \"f2\": 0.07142587916022766, \"f0_5\": 0.2352868140054631, \"p4\": 0.19696830158908674, \"phi\": 0.2341657518211852}, {\"truth_threshold\": 43.869773040285715, \"match_probability\": 0.9999999999999378, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 378.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6160.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05781584605574608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9421841502189636, \"precision\": 1.0, \"recall\": 0.05781584605574608, \"specificity\": 1.0, \"npv\": 0.945907473564148, \"accuracy\": 0.9460864663124084, \"f1\": 0.10931174089068826, \"f2\": 0.0712401055408971, \"f0_5\": 0.23478260869565218, \"p4\": 0.19652656857185002, \"phi\": 0.23385561241685257}, {\"truth_threshold\": 43.87396083724915, \"match_probability\": 0.9999999999999379, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 375.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6163.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05735699087381363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9426429867744446, \"precision\": 1.0, \"recall\": 0.05735699087381363, \"specificity\": 1.0, \"npv\": 0.9458825588226318, \"accuracy\": 0.9460601806640625, \"f1\": 0.10849124837263127, \"f2\": 0.07068270064462623, \"f0_5\": 0.23326698183627767, \"p4\": 0.19519926590670908, \"phi\": 0.23292268012947323}, {\"truth_threshold\": 43.87620466349625, \"match_probability\": 0.999999999999938, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 374.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6164.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05720403790473938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9427959322929382, \"precision\": 1.0, \"recall\": 0.05720403790473938, \"specificity\": 1.0, \"npv\": 0.9458742737770081, \"accuracy\": 0.9460514187812805, \"f1\": 0.10821759259259259, \"f2\": 0.07049687099449596, \"f0_5\": 0.23276076674134927, \"p4\": 0.19475612907602188, \"phi\": 0.23261088216974649}, {\"truth_threshold\": 43.879203830626004, \"match_probability\": 0.9999999999999382, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 372.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6166.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05689813569188118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9431018829345703, \"precision\": 1.0, \"recall\": 0.05689813569188118, \"specificity\": 1.0, \"npv\": 0.9458576440811157, \"accuracy\": 0.9460339546203613, \"f1\": 0.10767004341534009, \"f2\": 0.07012516965766853, \"f0_5\": 0.2317468228258161, \"p4\": 0.1938687989659987, \"phi\": 0.2319860686886056}, {\"truth_threshold\": 43.88780696311598, \"match_probability\": 0.9999999999999386, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 371.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6167.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05674518272280693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.943254828453064, \"precision\": 1.0, \"recall\": 0.05674518272280693, \"specificity\": 1.0, \"npv\": 0.9458493590354919, \"accuracy\": 0.9460251927375793, \"f1\": 0.10739614994934144, \"f2\": 0.06993929796780153, \"f0_5\": 0.231239092495637, \"p4\": 0.19342460483922758, \"phi\": 0.2316730266944594}, {\"truth_threshold\": 43.88881548817689, \"match_probability\": 0.9999999999999386, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 368.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6170.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05628632754087448, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9437136650085449, \"precision\": 1.0, \"recall\": 0.05628632754087448, \"specificity\": 1.0, \"npv\": 0.9458244442939758, \"accuracy\": 0.9459989070892334, \"f1\": 0.10657399362872864, \"f2\": 0.0693815987933635, \"f0_5\": 0.22971285892634208, \"p4\": 0.1920899010729735, \"phi\": 0.23073140885350604}, {\"truth_threshold\": 43.893261393208086, \"match_probability\": 0.9999999999999388, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 367.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6171.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05613337457180023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9438666105270386, \"precision\": 1.0, \"recall\": 0.05613337457180023, \"specificity\": 1.0, \"npv\": 0.945816159248352, \"accuracy\": 0.9459902048110962, \"f1\": 0.10629978276611152, \"f2\": 0.06919567102831932, \"f0_5\": 0.22920309767674243, \"p4\": 0.19164429126856414, \"phi\": 0.23041668441957028}, {\"truth_threshold\": 43.894881488876244, \"match_probability\": 0.9999999999999388, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 366.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6172.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05598042160272598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9440195560455322, \"precision\": 1.0, \"recall\": 0.05598042160272598, \"specificity\": 1.0, \"npv\": 0.9458078145980835, \"accuracy\": 0.9459814429283142, \"f1\": 0.10602549246813442, \"f2\": 0.06900972924051588, \"f0_5\": 0.22869282679330166, \"p4\": 0.19119832647777457, \"phi\": 0.2301015350556129}, {\"truth_threshold\": 43.91159321598034, \"match_probability\": 0.9999999999999396, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 365.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6173.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05582746863365173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9441725015640259, \"precision\": 1.0, \"recall\": 0.05582746863365173, \"specificity\": 1.0, \"npv\": 0.9457995295524597, \"accuracy\": 0.9459726810455322, \"f1\": 0.10575112270027524, \"f2\": 0.06882377342836671, \"f0_5\": 0.22818204551137786, \"p4\": 0.19075200627244382, \"phi\": 0.22978598239063916}, {\"truth_threshold\": 43.915287699538084, \"match_probability\": 0.9999999999999397, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 362.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6176.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.055368613451719284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9446313977241516, \"precision\": 1.0, \"recall\": 0.055368613451719284, \"specificity\": 1.0, \"npv\": 0.9457746148109436, \"accuracy\": 0.9459463953971863, \"f1\": 0.10492753623188406, \"f2\": 0.06826582182997662, \"f0_5\": 0.2266466316053093, \"p4\": 0.18941090887725404, \"phi\": 0.22883670009655627}, {\"truth_threshold\": 43.918024839190885, \"match_probability\": 0.9999999999999398, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 359.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6179.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.054909758269786835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9450902342796326, \"precision\": 1.0, \"recall\": 0.054909758269786835, \"specificity\": 1.0, \"npv\": 0.9457497000694275, \"accuracy\": 0.9459201693534851, \"f1\": 0.10410323328983616, \"f2\": 0.0677077439553393, \"f0_5\": 0.22510659643842487, \"p4\": 0.18806659727111508, \"phi\": 0.22788349020975046}, {\"truth_threshold\": 43.920847224879985, \"match_probability\": 0.9999999999999399, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 358.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6180.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.054756805300712585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9452431797981262, \"precision\": 1.0, \"recall\": 0.054756805300712585, \"specificity\": 1.0, \"npv\": 0.9457414150238037, \"accuracy\": 0.9459114074707031, \"f1\": 0.10382830626450117, \"f2\": 0.06752168992832894, \"f0_5\": 0.2245922208281054, \"p4\": 0.18761777711745434, \"phi\": 0.2275648775028197}, {\"truth_threshold\": 43.94267358733316, \"match_probability\": 0.9999999999999408, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 357.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6181.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.054603856056928635, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9453961253166199, \"precision\": 1.0, \"recall\": 0.054603856056928635, \"specificity\": 1.0, \"npv\": 0.9457330703735352, \"accuracy\": 0.9459026455879211, \"f1\": 0.10355329949238579, \"f2\": 0.06733562186427251, \"f0_5\": 0.22407732864674867, \"p4\": 0.18716859809905106, \"phi\": 0.22724584732513328}, {\"truth_threshold\": 43.948744763879084, \"match_probability\": 0.999999999999941, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 356.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6182.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.054450903087854385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9455490708351135, \"precision\": 1.0, \"recall\": 0.054450903087854385, \"specificity\": 1.0, \"npv\": 0.9457247853279114, \"accuracy\": 0.9458938837051392, \"f1\": 0.10327821293878735, \"f2\": 0.0671495397615814, \"f0_5\": 0.22356191911580006, \"p4\": 0.186719059781495, \"phi\": 0.22692635057471575}, {\"truth_threshold\": 43.96109356108277, \"match_probability\": 0.9999999999999416, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 354.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6184.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05414499714970589, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9458550214767456, \"precision\": 1.0, \"recall\": 0.05414499714970589, \"specificity\": 1.0, \"npv\": 0.9457082152366638, \"accuracy\": 0.94587641954422, \"f1\": 0.10272780034822983, \"f2\": 0.06677733343393949, \"f0_5\": 0.2225295448830777, \"p4\": 0.1858189035077751, \"phi\": 0.22628604439678487}, {\"truth_threshold\": 43.98087604116566, \"match_probability\": 0.9999999999999424, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 353.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6185.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.053992047905921936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9460079669952393, \"precision\": 1.0, \"recall\": 0.053992047905921936, \"specificity\": 1.0, \"npv\": 0.9456998705863953, \"accuracy\": 0.945867657661438, \"f1\": 0.10245247424176462, \"f2\": 0.06659120920581023, \"f0_5\": 0.2220125786163522, \"p4\": 0.18536828467927813, \"phi\": 0.22596520747859908}, {\"truth_threshold\": 43.98259763449751, \"match_probability\": 0.9999999999999425, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 352.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6186.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05383909493684769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9461609125137329, \"precision\": 1.0, \"recall\": 0.05383909493684769, \"specificity\": 1.0, \"npv\": 0.9456915855407715, \"accuracy\": 0.945858895778656, \"f1\": 0.10217706821480406, \"f2\": 0.06640507093268941, \"f0_5\": 0.22149509187012334, \"p4\": 0.18491730480695923, \"phi\": 0.22564392001706327}, {\"truth_threshold\": 43.99774985973006, \"match_probability\": 0.999999999999943, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 351.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6187.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05368614196777344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9463138580322266, \"precision\": 1.0, \"recall\": 0.05368614196777344, \"specificity\": 1.0, \"npv\": 0.9456833004951477, \"accuracy\": 0.945850133895874, \"f1\": 0.10190158223254464, \"f2\": 0.0662189186129872, \"f0_5\": 0.2209770838579703, \"p4\": 0.18446596345288704, \"phi\": 0.22532218008473587}, {\"truth_threshold\": 44.003192547901456, \"match_probability\": 0.9999999999999433, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 345.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6193.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05276843160390854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9472315907478333, \"precision\": 1.0, \"recall\": 0.05276843160390854, \"specificity\": 1.0, \"npv\": 0.9456334710121155, \"accuracy\": 0.9457976222038269, \"f1\": 0.10024698532616591, \"f2\": 0.065101709627505, \"f0_5\": 0.2178580449608487, \"p4\": 0.18175029959802594, \"phi\": 0.22338217700479215}, {\"truth_threshold\": 44.00548768044122, \"match_probability\": 0.9999999999999434, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 344.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6194.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05261547863483429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9473845362663269, \"precision\": 1.0, \"recall\": 0.05261547863483429, \"specificity\": 1.0, \"npv\": 0.9456251859664917, \"accuracy\": 0.9457888603210449, \"f1\": 0.0999709386806161, \"f2\": 0.06491545893719806, \"f0_5\": 0.21733636593378822, \"p4\": 0.18129641554990722, \"phi\": 0.22305721470591167}, {\"truth_threshold\": 44.02059457283143, \"match_probability\": 0.9999999999999439, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 342.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6196.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05230957642197609, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9476904273033142, \"precision\": 1.0, \"recall\": 0.05230957642197609, \"specificity\": 1.0, \"npv\": 0.9456085562705994, \"accuracy\": 0.9457713961601257, \"f1\": 0.09941860465116278, \"f2\": 0.06454291537706651, \"f0_5\": 0.21629142423475842, \"p4\": 0.18038755197681677, \"phi\": 0.22240588286183446}, {\"truth_threshold\": 44.02631901192683, \"match_probability\": 0.9999999999999442, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 340.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6198.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05200367048382759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9479963183403015, \"precision\": 1.0, \"recall\": 0.05200367048382759, \"specificity\": 1.0, \"npv\": 0.9455919861793518, \"accuracy\": 0.9457538723945618, \"f1\": 0.09886594940389648, \"f2\": 0.0641703155669636, \"f0_5\": 0.21524436566219296, \"p4\": 0.17947722480191491, \"phi\": 0.22175268512456867}, {\"truth_threshold\": 44.03076491695802, \"match_probability\": 0.9999999999999444, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 339.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6199.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05185071751475334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9481492638587952, \"precision\": 1.0, \"recall\": 0.05185071751475334, \"specificity\": 1.0, \"npv\": 0.9455836415290833, \"accuracy\": 0.9457451105117798, \"f1\": 0.09858950123600407, \"f2\": 0.06398399456419161, \"f0_5\": 0.2147200405371168, \"p4\": 0.17902151124882074, \"phi\": 0.22142536016391592}, {\"truth_threshold\": 44.033439051256344, \"match_probability\": 0.9999999999999445, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 338.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6200.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05169776827096939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9483022093772888, \"precision\": 1.0, \"recall\": 0.05169776827096939, \"specificity\": 1.0, \"npv\": 0.9455753564834595, \"accuracy\": 0.9457363486289978, \"f1\": 0.0983129726585224, \"f2\": 0.06379765949414873, \"f0_5\": 0.21419518377693283, \"p4\": 0.17856543045586679, \"phi\": 0.22109758066375582}, {\"truth_threshold\": 44.04612966493857, \"match_probability\": 0.9999999999999449, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 337.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6201.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05154481530189514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9484552145004272, \"precision\": 1.0, \"recall\": 0.05154481530189514, \"specificity\": 1.0, \"npv\": 0.9455670714378357, \"accuracy\": 0.9457275867462158, \"f1\": 0.09803636363636363, \"f2\": 0.0636113103552418, \"f0_5\": 0.21366979457266042, \"p4\": 0.17810898197507105, \"phi\": 0.22076929594607472}, {\"truth_threshold\": 44.07212487347151, \"match_probability\": 0.9999999999999459, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 335.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6203.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.05123890936374664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9487611055374146, \"precision\": 1.0, \"recall\": 0.05123890936374664, \"specificity\": 1.0, \"npv\": 0.9455504417419434, \"accuracy\": 0.9457101225852966, \"f1\": 0.09748290411756147, \"f2\": 0.06323856986446182, \"f0_5\": 0.2126174155877126, \"p4\": 0.17719498015438015, \"phi\": 0.22011127501041644}, {\"truth_threshold\": 44.07967451743897, \"match_probability\": 0.9999999999999463, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 332.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6206.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.050780054181814194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9492199420928955, \"precision\": 1.0, \"recall\": 0.050780054181814194, \"specificity\": 1.0, \"npv\": 0.945525586605072, \"accuracy\": 0.9456838369369507, \"f1\": 0.09665211062590975, \"f2\": 0.06267935357196798, \"f0_5\": 0.21103483346046276, \"p4\": 0.17582120852298877, \"phi\": 0.2191206066466309}, {\"truth_threshold\": 44.08892242192734, \"match_probability\": 0.9999999999999466, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 328.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6210.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.050168246030807495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9498317241668701, \"precision\": 1.0, \"recall\": 0.050168246030807495, \"specificity\": 1.0, \"npv\": 0.9454923868179321, \"accuracy\": 0.9456488490104675, \"f1\": 0.09554325662685698, \"f2\": 0.061933534743202415, \"f0_5\": 0.2089171974522293, \"p4\": 0.173984325416015, \"phi\": 0.21779277953650888}, {\"truth_threshold\": 44.096353258585594, \"match_probability\": 0.9999999999999468, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 327.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6211.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.050015296787023544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9499847292900085, \"precision\": 1.0, \"recall\": 0.050015296787023544, \"specificity\": 1.0, \"npv\": 0.9454840421676636, \"accuracy\": 0.9456400871276855, \"f1\": 0.09526584122359796, \"f2\": 0.06174704482797689, \"f0_5\": 0.20838643894978334, \"p4\": 0.17352417525669706, \"phi\": 0.21745956437608518}, {\"truth_threshold\": 44.098597084832704, \"match_probability\": 0.9999999999999469, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 326.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6212.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.049862343817949295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9501376748085022, \"precision\": 1.0, \"recall\": 0.049862343817949295, \"specificity\": 1.0, \"npv\": 0.9454757571220398, \"accuracy\": 0.9456313252449036, \"f1\": 0.09498834498834499, \"f2\": 0.0615605408263464, \"f0_5\": 0.2078551389951543, \"p4\": 0.17306365243330032, \"phi\": 0.21712584370592355}, {\"truth_threshold\": 44.09877020788369, \"match_probability\": 0.9999999999999469, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 325.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6213.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.049709390848875046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9502906203269958, \"precision\": 1.0, \"recall\": 0.049709390848875046, \"specificity\": 1.0, \"npv\": 0.945467472076416, \"accuracy\": 0.9456225633621216, \"f1\": 0.09471076788576424, \"f2\": 0.061374022736714884, \"f0_5\": 0.20732329675937738, \"p4\": 0.1726027564889975, \"phi\": 0.21679163996143}, {\"truth_threshold\": 44.106042170849726, \"match_probability\": 0.9999999999999472, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 324.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6214.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.049556437879800797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9504435658454895, \"precision\": 1.0, \"recall\": 0.049556437879800797, \"specificity\": 1.0, \"npv\": 0.9454591870307922, \"accuracy\": 0.9456138610839844, \"f1\": 0.09443310988050131, \"f2\": 0.06118749055748603, \"f0_5\": 0.20679091141179473, \"p4\": 0.17214148696621426, \"phi\": 0.21645690128797251}, {\"truth_threshold\": 44.139993986712774, \"match_probability\": 0.9999999999999484, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 323.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6215.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.049403488636016846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9505965113639832, \"precision\": 1.0, \"recall\": 0.049403488636016846, \"specificity\": 1.0, \"npv\": 0.9454509019851685, \"accuracy\": 0.9456050992012024, \"f1\": 0.09415537093718117, \"f2\": 0.06100094428706327, \"f0_5\": 0.2062579821200511, \"p4\": 0.17167984340662792, \"phi\": 0.21612165004688633}, {\"truth_threshold\": 44.15775380324974, \"match_probability\": 0.999999999999949, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 322.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6216.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.049250535666942596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9507494568824768, \"precision\": 1.0, \"recall\": 0.049250535666942596, \"specificity\": 1.0, \"npv\": 0.9454425573348999, \"accuracy\": 0.9455963373184204, \"f1\": 0.09387755102040816, \"f2\": 0.060814383923849816, \"f0_5\": 0.20572450805008943, \"p4\": 0.1712178253511658, \"phi\": 0.21578590873383663}, {\"truth_threshold\": 44.15931174981874, \"match_probability\": 0.9999999999999492, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 321.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6217.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04909758269786835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9509024024009705, \"precision\": 1.0, \"recall\": 0.04909758269786835, \"specificity\": 1.0, \"npv\": 0.9454342722892761, \"accuracy\": 0.9455875754356384, \"f1\": 0.09359965009476601, \"f2\": 0.06062780946624863, \"f0_5\": 0.20519048836614676, \"p4\": 0.17075543234000368, \"phi\": 0.21544962521001418}, {\"truth_threshold\": 44.17094257500628, \"match_probability\": 0.9999999999999495, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 317.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6221.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04848577454686165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9515142440795898, \"precision\": 1.0, \"recall\": 0.04848577454686165, \"specificity\": 1.0, \"npv\": 0.9454010725021362, \"accuracy\": 0.9455525875091553, \"f1\": 0.0924872355944566, \"f2\": 0.05988137066001738, \"f0_5\": 0.20304893671534716, \"p4\": 0.16890210151548168, \"phi\": 0.21409929373423692}, {\"truth_threshold\": 44.18650193319608, \"match_probability\": 0.99999999999995, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 313.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6225.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04787396639585495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9521260261535645, \"precision\": 1.0, \"recall\": 0.04787396639585495, \"specificity\": 1.0, \"npv\": 0.9453678727149963, \"accuracy\": 0.9455175399780273, \"f1\": 0.09137352211356006, \"f2\": 0.05913470621575666, \"f0_5\": 0.20089858793324775, \"p4\": 0.16704273441737985, \"phi\": 0.21274048715739888}, {\"truth_threshold\": 44.19070582982771, \"match_probability\": 0.9999999999999502, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 311.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6227.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04756806418299675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9524319171905518, \"precision\": 1.0, \"recall\": 0.04756806418299675, \"specificity\": 1.0, \"npv\": 0.9453513026237488, \"accuracy\": 0.9455000758171082, \"f1\": 0.09081617754416703, \"f2\": 0.058761289347390694, \"f0_5\": 0.1998200976612696, \"p4\": 0.16611077796313228, \"phi\": 0.21205784217076581}, {\"truth_threshold\": 44.191701135173076, \"match_probability\": 0.9999999999999503, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 310.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6228.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0474151112139225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9525848627090454, \"precision\": 1.0, \"recall\": 0.0474151112139225, \"specificity\": 1.0, \"npv\": 0.945343017578125, \"accuracy\": 0.9454913139343262, \"f1\": 0.0905373831775701, \"f2\": 0.05857455974605094, \"f0_5\": 0.19928002057084082, \"p4\": 0.16564422987439167, \"phi\": 0.21171571596793762}, {\"truth_threshold\": 44.20068991840033, \"match_probability\": 0.9999999999999505, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 309.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6229.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04726215824484825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9527378678321838, \"precision\": 1.0, \"recall\": 0.04726215824484825, \"specificity\": 1.0, \"npv\": 0.9453347325325012, \"accuracy\": 0.9454825520515442, \"f1\": 0.09025850737549292, \"f2\": 0.05838781603114017, \"f0_5\": 0.1987393877025984, \"p4\": 0.16517730125287866, \"phi\": 0.21137304202346122}, {\"truth_threshold\": 44.201131925513366, \"match_probability\": 0.9999999999999506, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 303.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6235.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04634444788098335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9536555409431458, \"precision\": 1.0, \"recall\": 0.04634444788098335, \"specificity\": 1.0, \"npv\": 0.9452849626541138, \"accuracy\": 0.9454300403594971, \"f1\": 0.08858354041806753, \"f2\": 0.05726705726705727, \"f0_5\": 0.19548387096774195, \"p4\": 0.16236771197617655, \"phi\": 0.20930529351416705}, {\"truth_threshold\": 44.203196774010905, \"match_probability\": 0.9999999999999506, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 302.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6236.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0461914949119091, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9538084864616394, \"precision\": 1.0, \"recall\": 0.0461914949119091, \"specificity\": 1.0, \"npv\": 0.9452766180038452, \"accuracy\": 0.9454212784767151, \"f1\": 0.08830409356725147, \"f2\": 0.05708021471233084, \"f0_5\": 0.19493932352181773, \"p4\": 0.16189810642924657, \"phi\": 0.20895870934465102}, {\"truth_threshold\": 44.223409994900415, \"match_probability\": 0.9999999999999513, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 301.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6237.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04603854566812515, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9539614319801331, \"precision\": 1.0, \"recall\": 0.04603854566812515, \"specificity\": 1.0, \"npv\": 0.9452683329582214, \"accuracy\": 0.9454125165939331, \"f1\": 0.08802456499488229, \"f2\": 0.056893358031225194, \"f0_5\": 0.19439421338155516, \"p4\": 0.16142811656991726, \"phi\": 0.20861155546401933}, {\"truth_threshold\": 44.227143917693425, \"match_probability\": 0.9999999999999515, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 295.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6243.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.045120831578969955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9548791646957397, \"precision\": 1.0, \"recall\": 0.045120831578969955, \"specificity\": 1.0, \"npv\": 0.945218563079834, \"accuracy\": 0.945360004901886, \"f1\": 0.08634567539879995, \"f2\": 0.05577192120089235, \"f0_5\": 0.1911116869655351, \"p4\": 0.15860008014425817, \"phi\": 0.2065164550256723}, {\"truth_threshold\": 44.2317032016999, \"match_probability\": 0.9999999999999516, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 294.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6244.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.044967878609895706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9550321102142334, \"precision\": 1.0, \"recall\": 0.044967878609895706, \"specificity\": 1.0, \"npv\": 0.9452102780342102, \"accuracy\": 0.945351243019104, \"f1\": 0.0860655737704918, \"f2\": 0.0555849655902594, \"f0_5\": 0.19056261343012704, \"p4\": 0.1581273867269053, \"phi\": 0.20616523195303849}, {\"truth_threshold\": 44.237215794425445, \"match_probability\": 0.9999999999999518, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 288.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6250.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04405016824603081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9559498429298401, \"precision\": 1.0, \"recall\": 0.04405016824603081, \"specificity\": 1.0, \"npv\": 0.9451605081558228, \"accuracy\": 0.9452987313270569, \"f1\": 0.08438324055083504, \"f2\": 0.05446293494704992, \"f0_5\": 0.18725617685305593, \"p4\": 0.15528305832704795, \"phi\": 0.20404528956984147}, {\"truth_threshold\": 44.26405197939776, \"match_probability\": 0.9999999999999527, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 287.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6251.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04389721527695656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9561027884483337, \"precision\": 1.0, \"recall\": 0.04389721527695656, \"specificity\": 1.0, \"npv\": 0.945152223110199, \"accuracy\": 0.9452900290489197, \"f1\": 0.0841025641025641, \"f2\": 0.05427588032830288, \"f0_5\": 0.18670309653916212, \"p4\": 0.15480763775758888, \"phi\": 0.20368983602965507}, {\"truth_threshold\": 44.26622695373525, \"match_probability\": 0.9999999999999527, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 285.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6253.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04359131306409836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.956408679485321, \"precision\": 1.0, \"recall\": 0.04359131306409836, \"specificity\": 1.0, \"npv\": 0.9451356530189514, \"accuracy\": 0.9452725052833557, \"f1\": 0.08354096438516781, \"f2\": 0.05390172863789386, \"f0_5\": 0.18559520708517843, \"p4\": 0.15385562152510854, \"phi\": 0.20297710678794995}, {\"truth_threshold\": 44.26627826002791, \"match_probability\": 0.9999999999999527, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 284.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6254.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04343836009502411, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9565616250038147, \"precision\": 1.0, \"recall\": 0.04343836009502411, \"specificity\": 1.0, \"npv\": 0.9451273679733276, \"accuracy\": 0.9452637434005737, \"f1\": 0.0832600410436822, \"f2\": 0.05371463156302012, \"f0_5\": 0.18504039614281992, \"p4\": 0.15337902488540936, \"phi\": 0.2026197981830545}, {\"truth_threshold\": 44.29379932279181, \"match_probability\": 0.9999999999999536, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 283.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6255.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04328540712594986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9567145705223083, \"precision\": 1.0, \"recall\": 0.04328540712594986, \"specificity\": 1.0, \"npv\": 0.9451190829277039, \"accuracy\": 0.9452549815177917, \"f1\": 0.08297903533206274, \"f2\": 0.053527520332892, \"f0_5\": 0.18448500651890481, \"p4\": 0.15290203524426546, \"phi\": 0.20226186465710772}, {\"truth_threshold\": 44.30452572938487, \"match_probability\": 0.9999999999999539, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 282.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6256.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04313245788216591, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.956867516040802, \"precision\": 1.0, \"recall\": 0.04313245788216591, \"specificity\": 1.0, \"npv\": 0.9451107978820801, \"accuracy\": 0.9452462196350098, \"f1\": 0.08269794721407625, \"f2\": 0.053340394945903, \"f0_5\": 0.18392903730759197, \"p4\": 0.15242465211130524, \"phi\": 0.20190331617964583}, {\"truth_threshold\": 44.30767603201937, \"match_probability\": 0.999999999999954, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 281.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6257.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04297950491309166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9570205211639404, \"precision\": 1.0, \"recall\": 0.04297950491309166, \"specificity\": 1.0, \"npv\": 0.9451024532318115, \"accuracy\": 0.9452375173568726, \"f1\": 0.08241677665346825, \"f2\": 0.05315325540044641, \"f0_5\": 0.18337248760114852, \"p4\": 0.15194687499534093, \"phi\": 0.20154413615129402}, {\"truth_threshold\": 44.30829889248693, \"match_probability\": 0.9999999999999541, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 280.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6258.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04282655194401741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9571734666824341, \"precision\": 1.0, \"recall\": 0.04282655194401741, \"specificity\": 1.0, \"npv\": 0.9450941681861877, \"accuracy\": 0.9452287554740906, \"f1\": 0.08213552361396304, \"f2\": 0.05296610169491525, \"f0_5\": 0.18281535648994515, \"p4\": 0.151468703404367, \"phi\": 0.20118430784875863}, {\"truth_threshold\": 44.31743168675596, \"match_probability\": 0.9999999999999544, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 279.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6259.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04267359897494316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9573264122009277, \"precision\": 1.0, \"recall\": 0.04267359897494316, \"specificity\": 1.0, \"npv\": 0.945085883140564, \"accuracy\": 0.9452199935913086, \"f1\": 0.0818541880592636, \"f2\": 0.052778933827702317, \"f0_5\": 0.182257643062451, \"p4\": 0.15099013684555837, \"phi\": 0.2008238411519474}, {\"truth_threshold\": 44.31896841580723, \"match_probability\": 0.9999999999999545, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 278.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6260.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04252064973115921, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9574793577194214, \"precision\": 1.0, \"recall\": 0.04252064973115921, \"specificity\": 1.0, \"npv\": 0.9450775980949402, \"accuracy\": 0.9452112317085266, \"f1\": 0.08157276995305164, \"f2\": 0.05259175179720015, \"f0_5\": 0.18169934640522875, \"p4\": 0.15051117482526882, \"phi\": 0.20046274600519784}, {\"truth_threshold\": 44.32366364046748, \"match_probability\": 0.9999999999999546, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 277.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6261.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04236769676208496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.957632303237915, \"precision\": 1.0, \"recall\": 0.04236769676208496, \"specificity\": 1.0, \"npv\": 0.9450693130493164, \"accuracy\": 0.9452024698257446, \"f1\": 0.08129126925898753, \"f2\": 0.05240455560180105, \"f0_5\": 0.18114046560292962, \"p4\": 0.15003181684902905, \"phi\": 0.2001010055933354}, {\"truth_threshold\": 44.3661135276077, \"match_probability\": 0.9999999999999559, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 276.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6262.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04221474379301071, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9577852487564087, \"precision\": 1.0, \"recall\": 0.04221474379301071, \"specificity\": 1.0, \"npv\": 0.9450610280036926, \"accuracy\": 0.9451937079429626, \"f1\": 0.0810096859407103, \"f2\": 0.05221734523989708, \"f0_5\": 0.1805809997382884, \"p4\": 0.14955206242154528, \"phi\": 0.19973860297369597}, {\"truth_threshold\": 44.37172008258256, \"match_probability\": 0.999999999999956, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 275.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6263.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04206179082393646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9579381942749023, \"precision\": 1.0, \"recall\": 0.04206179082393646, \"specificity\": 1.0, \"npv\": 0.9450527429580688, \"accuracy\": 0.9451850056648254, \"f1\": 0.08072801996183766, \"f2\": 0.05203012070988005, \"f0_5\": 0.18002094789211837, \"p4\": 0.14907191104669726, \"phi\": 0.19937554799639176}, {\"truth_threshold\": 44.381704171155185, \"match_probability\": 0.9999999999999564, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 273.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6265.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.04175588861107826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9582440853118896, \"precision\": 1.0, \"recall\": 0.04175588861107826, \"specificity\": 1.0, \"npv\": 0.9450361728668213, \"accuracy\": 0.9451674818992615, \"f1\": 0.08016443987667009, \"f2\": 0.051655629139072845, \"f0_5\": 0.17889908256880735, \"p4\": 0.14811041546628537, \"phi\": 0.19864749367460358}, {\"truth_threshold\": 44.41409355650953, \"match_probability\": 0.9999999999999574, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 269.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6269.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.041144080460071564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.958855926990509, \"precision\": 1.0, \"recall\": 0.041144080460071564, \"specificity\": 1.0, \"npv\": 0.9450029730796814, \"accuracy\": 0.9451324939727783, \"f1\": 0.0790362861759953, \"f2\": 0.05090647590931456, \"f0_5\": 0.1766482794851589, \"p4\": 0.14618263901566964, \"phi\": 0.19718337080976558}, {\"truth_threshold\": 44.420525179720066, \"match_probability\": 0.9999999999999575, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 266.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6272.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.040685225278139114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.95931476354599, \"precision\": 1.0, \"recall\": 0.040685225278139114, \"specificity\": 1.0, \"npv\": 0.9449781179428101, \"accuracy\": 0.9451062083244324, \"f1\": 0.07818930041152264, \"f2\": 0.050344462109167994, \"f0_5\": 0.17495395948434622, \"p4\": 0.14473260377055877, \"phi\": 0.19607816545328813}, {\"truth_threshold\": 44.43397698084007, \"match_probability\": 0.9999999999999579, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 264.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6274.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.040379319339990616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9596206545829773, \"precision\": 1.0, \"recall\": 0.040379319339990616, \"specificity\": 1.0, \"npv\": 0.9449615478515625, \"accuracy\": 0.9450886845588684, \"f1\": 0.07762422816818583, \"f2\": 0.04996971532404603, \"f0_5\": 0.17382143797735053, \"p4\": 0.1437639046745519, \"phi\": 0.195337925047079}, {\"truth_threshold\": 44.44953633902987, \"match_probability\": 0.9999999999999584, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 261.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6277.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.039920464158058167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.960079550743103, \"precision\": 1.0, \"recall\": 0.039920464158058167, \"specificity\": 1.0, \"npv\": 0.9449366927146912, \"accuracy\": 0.9450624585151672, \"f1\": 0.07677599647006912, \"f2\": 0.049407488736606976, \"f0_5\": 0.17211817462410972, \"p4\": 0.1423078325166474, \"phi\": 0.19422233058806637}, {\"truth_threshold\": 44.456528822829924, \"match_probability\": 0.9999999999999586, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 260.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6278.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03976751118898392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9602324962615967, \"precision\": 1.0, \"recall\": 0.03976751118898392, \"specificity\": 1.0, \"npv\": 0.9449283480644226, \"accuracy\": 0.9450536966323853, \"f1\": 0.07649308620182406, \"f2\": 0.04922005149174618, \"f0_5\": 0.1715492214304566, \"p4\": 0.14182166682966632, \"phi\": 0.19384904294321856}, {\"truth_threshold\": 44.461167164217414, \"match_probability\": 0.9999999999999587, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 259.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6279.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.039614561945199966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9603854417800903, \"precision\": 1.0, \"recall\": 0.039614561945199966, \"specificity\": 1.0, \"npv\": 0.9449200630187988, \"accuracy\": 0.9450449347496033, \"f1\": 0.07621009268795056, \"f2\": 0.04903260005300822, \"f0_5\": 0.1709796672828096, \"p4\": 0.14133509614359133, \"phi\": 0.19347504165248577}, {\"truth_threshold\": 44.46372432423413, \"match_probability\": 0.9999999999999588, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 258.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6280.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03946160897612572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.960538387298584, \"precision\": 1.0, \"recall\": 0.03946160897612572, \"specificity\": 1.0, \"npv\": 0.944911777973175, \"accuracy\": 0.9450361728668213, \"f1\": 0.075927015891701, \"f2\": 0.048845134418780765, \"f0_5\": 0.17040951122853368, \"p4\": 0.14084811994798663, \"phi\": 0.19310033646543434}, {\"truth_threshold\": 44.47822389392924, \"match_probability\": 0.9999999999999591, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 257.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6281.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03930865600705147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9606913328170776, \"precision\": 1.0, \"recall\": 0.03930865600705147, \"specificity\": 1.0, \"npv\": 0.9449034929275513, \"accuracy\": 0.9450274109840393, \"f1\": 0.07564385577630611, \"f2\": 0.04865765458745125, \"f0_5\": 0.16983875231297912, \"p4\": 0.1403607377315583, \"phi\": 0.19272490935257058}, {\"truth_threshold\": 44.48644440073421, \"match_probability\": 0.9999999999999595, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 256.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6282.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03915570676326752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9608442783355713, \"precision\": 1.0, \"recall\": 0.03915570676326752, \"specificity\": 1.0, \"npv\": 0.9448952078819275, \"accuracy\": 0.9450187087059021, \"f1\": 0.07536061230497498, \"f2\": 0.04847016055740685, \"f0_5\": 0.16926738957947632, \"p4\": 0.13987294898215263, \"phi\": 0.19234874213613404}, {\"truth_threshold\": 44.50723505323904, \"match_probability\": 0.99999999999996, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 253.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6285.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03869684785604477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.961303174495697, \"precision\": 1.0, \"recall\": 0.03869684785604477, \"specificity\": 1.0, \"npv\": 0.9448703527450562, \"accuracy\": 0.9449924230575562, \"f1\": 0.07451038138713002, \"f2\": 0.04790759325885249, \"f0_5\": 0.1675496688741722, \"p4\": 0.13840713840159763, \"phi\": 0.1912158684071237}, {\"truth_threshold\": 44.51007676469836, \"match_probability\": 0.99999999999996, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 251.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6287.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03839094564318657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9616090655326843, \"precision\": 1.0, \"recall\": 0.03839094564318657, \"specificity\": 1.0, \"npv\": 0.9448537826538086, \"accuracy\": 0.9449748992919922, \"f1\": 0.0739431433200766, \"f2\": 0.047532477369995836, \"f0_5\": 0.1664014850172368, \"p4\": 0.13742788925466254, \"phi\": 0.1904568902224479}, {\"truth_threshold\": 44.52826457642884, \"match_probability\": 0.9999999999999606, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 250.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6288.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03823799267411232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.961762011051178, \"precision\": 1.0, \"recall\": 0.03823799267411232, \"specificity\": 1.0, \"npv\": 0.9448454976081848, \"accuracy\": 0.944966197013855, \"f1\": 0.07365939893930465, \"f2\": 0.04734489811377926, \"f0_5\": 0.1658264791721942, \"p4\": 0.13693765050378218, \"phi\": 0.19007628879539779}, {\"truth_threshold\": 44.54907201258079, \"match_probability\": 0.9999999999999611, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 249.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6289.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03808503970503807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9619149565696716, \"precision\": 1.0, \"recall\": 0.03808503970503807, \"specificity\": 1.0, \"npv\": 0.944837212562561, \"accuracy\": 0.944957435131073, \"f1\": 0.07337557094445263, \"f2\": 0.04715730464755123, \"f0_5\": 0.16525086275550835, \"p4\": 0.13644700161061912, \"phi\": 0.1896949304330038}, {\"truth_threshold\": 44.56068605412121, \"match_probability\": 0.9999999999999615, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 248.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6290.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03793209046125412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9620679020881653, \"precision\": 1.0, \"recall\": 0.03793209046125412, \"specificity\": 1.0, \"npv\": 0.9448289275169373, \"accuracy\": 0.944948673248291, \"f1\": 0.07309165929855585, \"f2\": 0.04696969696969697, \"f0_5\": 0.1646746347941567, \"p4\": 0.13595594205607509, \"phi\": 0.18931279638756157}, {\"truth_threshold\": 44.56808236813392, \"match_probability\": 0.9999999999999617, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 247.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6291.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03777913749217987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9622208476066589, \"precision\": 1.0, \"recall\": 0.03777913749217987, \"specificity\": 1.0, \"npv\": 0.9448206424713135, \"accuracy\": 0.944939911365509, \"f1\": 0.07280766396462786, \"f2\": 0.046782075078601465, \"f0_5\": 0.1640977943130481, \"p4\": 0.13546447132017553, \"phi\": 0.18892989615426078}, {\"truth_threshold\": 44.59045018116238, \"match_probability\": 0.9999999999999623, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 246.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6292.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03762618452310562, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9623737931251526, \"precision\": 1.0, \"recall\": 0.03762618452310562, \"specificity\": 1.0, \"npv\": 0.9448123574256897, \"accuracy\": 0.944931149482727, \"f1\": 0.07252358490566038, \"f2\": 0.04659443897264944, \"f0_5\": 0.16352034033501728, \"p4\": 0.1349725888820677, \"phi\": 0.18854623929550401}, {\"truth_threshold\": 44.61076058839302, \"match_probability\": 0.9999999999999628, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 244.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6294.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03732028231024742, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9626797437667847, \"precision\": 1.0, \"recall\": 0.03732028231024742, \"specificity\": 1.0, \"npv\": 0.9447957873344421, \"accuracy\": 0.9449136853218079, \"f1\": 0.07195517546446475, \"f2\": 0.04621912410971359, \"f0_5\": 0.1623635879691243, \"p4\": 0.13398758681141426, \"phi\": 0.18777657998508238}, {\"truth_threshold\": 44.615727417679174, \"match_probability\": 0.9999999999999629, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 243.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6295.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03716732934117317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9628326892852783, \"precision\": 1.0, \"recall\": 0.03716732934117317, \"specificity\": 1.0, \"npv\": 0.9447875022888184, \"accuracy\": 0.9449049234390259, \"f1\": 0.0716708450081109, \"f2\": 0.04603144534949801, \"f0_5\": 0.1617842876165113, \"p4\": 0.13349446613275562, \"phi\": 0.18739056789938321}, {\"truth_threshold\": 44.62562975404128, \"match_probability\": 0.9999999999999631, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 242.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6296.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03701437637209892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.962985634803772, \"precision\": 1.0, \"recall\": 0.03701437637209892, \"specificity\": 1.0, \"npv\": 0.9447792172431946, \"accuracy\": 0.9448961615562439, \"f1\": 0.07138643067846608, \"f2\": 0.04584375236796242, \"f0_5\": 0.16120436983746336, \"p4\": 0.1330009316596589, \"phi\": 0.18700378015107952}, {\"truth_threshold\": 44.63844749417926, \"match_probability\": 0.9999999999999635, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 240.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6298.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03670847415924072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9632915258407593, \"precision\": 1.0, \"recall\": 0.03670847415924072, \"specificity\": 1.0, \"npv\": 0.944762647151947, \"accuracy\": 0.9448786377906799, \"f1\": 0.07081735025081144, \"f2\": 0.04546832373446499, \"f0_5\": 0.16004267804747932, \"p4\": 0.13201261922817586, \"phi\": 0.18622780069484915}, {\"truth_threshold\": 44.64473857698898, \"match_probability\": 0.9999999999999637, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 239.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6299.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03655552119016647, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9634444713592529, \"precision\": 1.0, \"recall\": 0.03655552119016647, \"specificity\": 1.0, \"npv\": 0.9447543621063232, \"accuracy\": 0.944869875907898, \"f1\": 0.07053268407850082, \"f2\": 0.04528058807926945, \"f0_5\": 0.15946090205497732, \"p4\": 0.13151784021657661, \"phi\": 0.18583859894894855}, {\"truth_threshold\": 44.644738576988985, \"match_probability\": 0.9999999999999637, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 238.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6300.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.036402568221092224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9635974168777466, \"precision\": 1.0, \"recall\": 0.036402568221092224, \"specificity\": 1.0, \"npv\": 0.9447460770606995, \"accuracy\": 0.9448611736297607, \"f1\": 0.07024793388429752, \"f2\": 0.04509283819628647, \"f0_5\": 0.1588785046728972, \"p4\": 0.13102264530410956, \"phi\": 0.18544860170112057}, {\"truth_threshold\": 44.65636940217652, \"match_probability\": 0.9999999999999639, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 237.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6301.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03624961897730827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9637503623962402, \"precision\": 1.0, \"recall\": 0.03624961897730827, \"specificity\": 1.0, \"npv\": 0.9447377920150757, \"accuracy\": 0.9448524117469788, \"f1\": 0.06996309963099631, \"f2\": 0.04490507408389859, \"f0_5\": 0.1582954849051563, \"p4\": 0.13052703396193446, \"phi\": 0.1850577894237804}, {\"truth_threshold\": 44.659238146684096, \"match_probability\": 0.999999999999964, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 230.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6308.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.035178955644369125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9648210406303406, \"precision\": 1.0, \"recall\": 0.035178955644369125, \"specificity\": 1.0, \"npv\": 0.9446797966957092, \"accuracy\": 0.9447911381721497, \"f1\": 0.06796690307328605, \"f2\": 0.04359032673792738, \"f0_5\": 0.15419683561276482, \"p4\": 0.12704604992346508, \"phi\": 0.18229878208968428}, {\"truth_threshold\": 44.6615311072923, \"match_probability\": 0.999999999999964, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 229.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6309.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.035026002675294876, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9649739861488342, \"precision\": 1.0, \"recall\": 0.035026002675294876, \"specificity\": 1.0, \"npv\": 0.9446715116500854, \"accuracy\": 0.9447823762893677, \"f1\": 0.06768139500517216, \"f2\": 0.043402448732042, \"f0_5\": 0.15360880064394955, \"p4\": 0.12654708799734368, \"phi\": 0.18190125844001426}, {\"truth_threshold\": 44.66325578776176, \"match_probability\": 0.9999999999999641, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 228.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6310.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03487304970622063, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9651269316673279, \"precision\": 1.0, \"recall\": 0.03487304970622063, \"specificity\": 1.0, \"npv\": 0.9446632266044617, \"accuracy\": 0.9447736144065857, \"f1\": 0.06739580254212238, \"f2\": 0.043214556482183475, \"f0_5\": 0.15302013422818792, \"p4\": 0.12604770484136077, \"phi\": 0.18150285635958904}, {\"truth_threshold\": 44.66930845788402, \"match_probability\": 0.9999999999999643, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 227.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6311.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03472009673714638, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9652798771858215, \"precision\": 1.0, \"recall\": 0.03472009673714638, \"specificity\": 1.0, \"npv\": 0.9446549415588379, \"accuracy\": 0.9447648525238037, \"f1\": 0.06711012564671101, \"f2\": 0.04302664998673187, \"f0_5\": 0.15243083534783777, \"p4\": 0.12554789991762055, \"phi\": 0.1811035848642069}, {\"truth_threshold\": 44.685515747836035, \"match_probability\": 0.9999999999999647, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 226.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6312.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03456714749336243, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.96543288230896, \"precision\": 1.0, \"recall\": 0.03456714749336243, \"specificity\": 1.0, \"npv\": 0.9446466565132141, \"accuracy\": 0.9447560906410217, \"f1\": 0.06682436428149024, \"f2\": 0.04283872924406702, \"f0_5\": 0.15184090298306907, \"p4\": 0.12504767268731118, \"phi\": 0.18070345303619095}, {\"truth_threshold\": 44.70363226604255, \"match_probability\": 0.9999999999999651, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 225.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6313.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03441419452428818, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9655858278274536, \"precision\": 1.0, \"recall\": 0.03441419452428818, \"specificity\": 1.0, \"npv\": 0.9446383714675903, \"accuracy\": 0.9447473883628845, \"f1\": 0.0665385184089901, \"f2\": 0.04265079425256853, \"f0_5\": 0.15125033611185804, \"p4\": 0.12454702261070259, \"phi\": 0.180302440268732}, {\"truth_threshold\": 44.71257074486366, \"match_probability\": 0.9999999999999654, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 224.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6314.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03426124155521393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9657387733459473, \"precision\": 1.0, \"recall\": 0.03426124155521393, \"specificity\": 1.0, \"npv\": 0.9446300864219666, \"accuracy\": 0.9447386264801025, \"f1\": 0.06625258799171843, \"f2\": 0.04246284501061571, \"f0_5\": 0.15065913370998116, \"p4\": 0.12404594914714469, \"phi\": 0.1799005257590637}, {\"truth_threshold\": 44.719563228663716, \"match_probability\": 0.9999999999999655, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 222.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6316.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03395533934235573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9660446643829346, \"precision\": 1.0, \"recall\": 0.03395533934235573, \"specificity\": 1.0, \"npv\": 0.944613516330719, \"accuracy\": 0.9447211027145386, \"f1\": 0.06568047337278106, \"f2\": 0.042086903768863274, \"f0_5\": 0.14947481820630218, \"p4\": 0.12304252989196839, \"phi\": 0.17909402713018996}, {\"truth_threshold\": 44.74125829976303, \"match_probability\": 0.999999999999966, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 221.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6317.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03380238637328148, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9661976099014282, \"precision\": 1.0, \"recall\": 0.03380238637328148, \"specificity\": 1.0, \"npv\": 0.9446052312850952, \"accuracy\": 0.9447123408317566, \"f1\": 0.06539428909602012, \"f2\": 0.041898911765821105, \"f0_5\": 0.14888170304500134, \"p4\": 0.1225401830144317, \"phi\": 0.17868943096130596}, {\"truth_threshold\": 44.783095259104776, \"match_probability\": 0.9999999999999669, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 218.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6320.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03334353119134903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9666564464569092, \"precision\": 1.0, \"recall\": 0.03334353119134903, \"specificity\": 1.0, \"npv\": 0.9445803761482239, \"accuracy\": 0.9446861147880554, \"f1\": 0.0645352279455299, \"f2\": 0.04133485020857035, \"f0_5\": 0.14709851551956815, \"p4\": 0.1210305868470308, \"phi\": 0.17747012083904762}, {\"truth_threshold\": 44.79129898226263, \"match_probability\": 0.9999999999999671, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 216.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6322.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03303762525320053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9669623970985413, \"precision\": 1.0, \"recall\": 0.03303762525320053, \"specificity\": 1.0, \"npv\": 0.9445638060569763, \"accuracy\": 0.9446685910224915, \"f1\": 0.06396209653538644, \"f2\": 0.04095873786407767, \"f0_5\": 0.1459065117535801, \"p4\": 0.12002205432531003, \"phi\": 0.176652612890817}, {\"truth_threshold\": 44.80837249562157, \"match_probability\": 0.9999999999999676, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 210.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6328.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03211991488933563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9678800702095032, \"precision\": 1.0, \"recall\": 0.03211991488933563, \"specificity\": 1.0, \"npv\": 0.9445140957832336, \"accuracy\": 0.9446160793304443, \"f1\": 0.06224066390041494, \"f2\": 0.03983005841741901, \"f0_5\": 0.14231499051233396, \"p4\": 0.11698616005691381, \"phi\": 0.174177243389011}, {\"truth_threshold\": 44.8198681344594, \"match_probability\": 0.9999999999999678, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 207.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6331.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.03166105970740318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9683389663696289, \"precision\": 1.0, \"recall\": 0.03166105970740318, \"specificity\": 1.0, \"npv\": 0.9444892406463623, \"accuracy\": 0.9445898532867432, \"f1\": 0.06137879911045219, \"f2\": 0.03926552600629766, \"f0_5\": 0.14051045343469998, \"p4\": 0.11546239367550079, \"phi\": 0.17292636275121973}, {\"truth_threshold\": 44.829131055788366, \"match_probability\": 0.999999999999968, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 206.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6332.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.031508106738328934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9684919118881226, \"precision\": 1.0, \"recall\": 0.031508106738328934, \"specificity\": 1.0, \"npv\": 0.9444809556007385, \"accuracy\": 0.9445810914039612, \"f1\": 0.06109134045077105, \"f2\": 0.03907731997875408, \"f0_5\": 0.13990763379516435, \"p4\": 0.11495360573495671, \"phi\": 0.17250741199467162}, {\"truth_threshold\": 44.83556267899891, \"match_probability\": 0.9999999999999681, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 205.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6333.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.031355153769254684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9686448574066162, \"precision\": 1.0, \"recall\": 0.031355153769254684, \"specificity\": 1.0, \"npv\": 0.9444726705551147, \"accuracy\": 0.9445723295211792, \"f1\": 0.06080379652973454, \"f2\": 0.03888909966991691, \"f0_5\": 0.1393041587387877, \"p4\": 0.11444438395765752, \"phi\": 0.17208744866961592}, {\"truth_threshold\": 44.83923345932633, \"match_probability\": 0.9999999999999682, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 204.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6334.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.031202202662825584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9687978029251099, \"precision\": 1.0, \"recall\": 0.031202202662825584, \"specificity\": 1.0, \"npv\": 0.9444644451141357, \"accuracy\": 0.9445635676383972, \"f1\": 0.060516167309403734, \"f2\": 0.03870086507816057, \"f0_5\": 0.13870002719608376, \"p4\": 0.11393472778413288, \"phi\": 0.17166644972041678}, {\"truth_threshold\": 44.84565127091498, \"match_probability\": 0.9999999999999684, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 203.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6335.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.031049249693751335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9689507484436035, \"precision\": 1.0, \"recall\": 0.031049249693751335, \"specificity\": 1.0, \"npv\": 0.944456160068512, \"accuracy\": 0.9445548057556152, \"f1\": 0.060228452751817235, \"f2\": 0.03851261620185923, \"f0_5\": 0.1380952380952381, \"p4\": 0.11342463665395014, \"phi\": 0.17124442317153862}, {\"truth_threshold\": 44.84901448011892, \"match_probability\": 0.9999999999999685, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 202.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6336.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.030896298587322235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9691036939620972, \"precision\": 1.0, \"recall\": 0.030896298587322235, \"specificity\": 1.0, \"npv\": 0.9444478750228882, \"accuracy\": 0.9445460438728333, \"f1\": 0.0599406528189911, \"f2\": 0.03832435303938681, \"f0_5\": 0.13748979036210182, \"p4\": 0.11291411000571222, \"phi\": 0.17082137710755196}, {\"truth_threshold\": 44.85118945445641, \"match_probability\": 0.9999999999999685, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 201.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6337.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.030743347480893135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9692566394805908, \"precision\": 1.0, \"recall\": 0.030743347480893135, \"specificity\": 1.0, \"npv\": 0.9444395899772644, \"accuracy\": 0.944537341594696, \"f1\": 0.05965276747291883, \"f2\": 0.03813607558911699, \"f0_5\": 0.13688368292018524, \"p4\": 0.11240314727705555, \"phi\": 0.17039728819440267}, {\"truth_threshold\": 44.87620466349625, \"match_probability\": 0.999999999999969, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 200.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6338.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.030590394511818886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9694095849990845, \"precision\": 1.0, \"recall\": 0.030590394511818886, \"specificity\": 1.0, \"npv\": 0.9444313049316406, \"accuracy\": 0.9445285797119141, \"f1\": 0.05936479667557139, \"f2\": 0.03794778384942319, \"f0_5\": 0.1362769146906514, \"p4\": 0.111891747904648, \"phi\": 0.16997213284679835}, {\"truth_threshold\": 44.915287699538084, \"match_probability\": 0.9999999999999699, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 198.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6340.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.030284490436315536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9697155356407166, \"precision\": 1.0, \"recall\": 0.030284490436315536, \"specificity\": 1.0, \"npv\": 0.9444147348403931, \"accuracy\": 0.9445110559463501, \"f1\": 0.058788598574821854, \"f2\": 0.03757115749525617, \"f0_5\": 0.13506139154160982, \"p4\": 0.11086763697039634, \"phi\": 0.1691186540916939}, {\"truth_threshold\": 44.937655512566536, \"match_probability\": 0.9999999999999704, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 197.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6341.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.030131539329886436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9698684811592102, \"precision\": 1.0, \"recall\": 0.030131539329886436, \"specificity\": 1.0, \"npv\": 0.9444064497947693, \"accuracy\": 0.9445022940635681, \"f1\": 0.0585003711952487, \"f2\": 0.03738282287752856, \"f0_5\": 0.13445263445263445, \"p4\": 0.11035492427702631, \"phi\": 0.16869031465490686}, {\"truth_threshold\": 44.97187122790445, \"match_probability\": 0.999999999999971, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 195.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6343.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.029825635254383087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9701743721961975, \"precision\": 1.0, \"recall\": 0.029825635254383087, \"specificity\": 1.0, \"npv\": 0.9443898797035217, \"accuracy\": 0.9444848299026489, \"f1\": 0.057923659587108274, \"f2\": 0.03700611075264736, \"f0_5\": 0.13323312380431812, \"p4\": 0.10932818160165919, \"phi\": 0.16783034688456}, {\"truth_threshold\": 45.02011767275851, \"match_probability\": 0.999999999999972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 194.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6344.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.029672682285308838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9703273177146912, \"precision\": 1.0, \"recall\": 0.029672682285308838, \"specificity\": 1.0, \"npv\": 0.944381594657898, \"accuracy\": 0.9444760680198669, \"f1\": 0.05763517528223411, \"f2\": 0.03681773324223791, \"f0_5\": 0.13262236806125238, \"p4\": 0.10881415048226818, \"phi\": 0.16739873369719552}, {\"truth_threshold\": 45.021808226068806, \"match_probability\": 0.999999999999972, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 191.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6347.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02921382710337639, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9707861542701721, \"precision\": 1.0, \"recall\": 0.02921382710337639, \"specificity\": 1.0, \"npv\": 0.9443567991256714, \"accuracy\": 0.944449782371521, \"f1\": 0.056769207906078166, \"f2\": 0.03625251489959382, \"f0_5\": 0.13078608600383457, \"p4\": 0.10726941115225279, \"phi\": 0.16609717836827134}, {\"truth_threshold\": 45.03449883975103, \"match_probability\": 0.9999999999999722, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 190.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6348.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02906087413430214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9709390997886658, \"precision\": 1.0, \"recall\": 0.02906087413430214, \"specificity\": 1.0, \"npv\": 0.9443485140800476, \"accuracy\": 0.944441020488739, \"f1\": 0.05648038049940547, \"f2\": 0.03606408017614456, \"f0_5\": 0.13017265004110715, \"p4\": 0.10675361414448549, \"phi\": 0.16566108027405027}, {\"truth_threshold\": 45.057731964558286, \"match_probability\": 0.9999999999999727, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 189.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6349.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02890792302787304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9710921049118042, \"precision\": 1.0, \"recall\": 0.02890792302787304, \"specificity\": 1.0, \"npv\": 0.9443402290344238, \"accuracy\": 0.9444323182106018, \"f1\": 0.05619146722164412, \"f2\": 0.03587563114536274, \"f0_5\": 0.1295585412667946, \"p4\": 0.10623737423178785, \"phi\": 0.16522383880647162}, {\"truth_threshold\": 45.06620234542726, \"match_probability\": 0.9999999999999728, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 188.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6350.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02875497005879879, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9712450504302979, \"precision\": 1.0, \"recall\": 0.02875497005879879, \"specificity\": 1.0, \"npv\": 0.9443319439888, \"accuracy\": 0.9444235563278198, \"f1\": 0.05590246803449301, \"f2\": 0.03568716780561883, \"f0_5\": 0.1289437585733882, \"p4\": 0.1057206908390406, \"phi\": 0.16478542858969528}, {\"truth_threshold\": 45.066888225105366, \"match_probability\": 0.9999999999999729, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 187.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6351.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02860201895236969, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9713979959487915, \"precision\": 1.0, \"recall\": 0.02860201895236969, \"specificity\": 1.0, \"npv\": 0.9443236589431763, \"accuracy\": 0.9444147944450378, \"f1\": 0.05561338289962825, \"f2\": 0.03549869015528304, \"f0_5\": 0.128328300850947, \"p4\": 0.10520356339012846, \"phi\": 0.1643458565882037}, {\"truth_threshold\": 45.07140690145537, \"match_probability\": 0.9999999999999729, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 186.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6352.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02844906784594059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9715509414672852, \"precision\": 1.0, \"recall\": 0.02844906784594059, \"specificity\": 1.0, \"npv\": 0.9443153738975525, \"accuracy\": 0.9444060325622559, \"f1\": 0.055324211778703156, \"f2\": 0.03531019819272534, \"f0_5\": 0.12771216698709145, \"p4\": 0.10468599130793778, \"phi\": 0.16390512981581154}, {\"truth_threshold\": 45.08528361068293, \"match_probability\": 0.9999999999999732, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 185.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6353.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02829611487686634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9717038869857788, \"precision\": 1.0, \"recall\": 0.02829611487686634, \"specificity\": 1.0, \"npv\": 0.9443070888519287, \"accuracy\": 0.9443972706794739, \"f1\": 0.055034954633348204, \"f2\": 0.03512169191631545, \"f0_5\": 0.12709535586699644, \"p4\": 0.10416797401435454, \"phi\": 0.16346322252609735}, {\"truth_threshold\": 45.15629579904188, \"match_probability\": 0.9999999999999745, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 184.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6354.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02814316377043724, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9718568325042725, \"precision\": 1.0, \"recall\": 0.02814316377043724, \"specificity\": 1.0, \"npv\": 0.9442988038063049, \"accuracy\": 0.9443885087966919, \"f1\": 0.05474561142517108, \"f2\": 0.03493317132442284, \"f0_5\": 0.12647786637338465, \"p4\": 0.10364951093026209, \"phi\": 0.16302010866876848}, {\"truth_threshold\": 45.15931174981874, \"match_probability\": 0.9999999999999746, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 178.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6360.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.027225451543927193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9727745652198792, \"precision\": 1.0, \"recall\": 0.027225451543927193, \"specificity\": 1.0, \"npv\": 0.944249153137207, \"accuracy\": 0.9443359971046448, \"f1\": 0.053007742703990474, \"f2\": 0.03380174705658944, \"f0_5\": 0.12275862068965518, \"p4\": 0.10052933826760492, \"phi\": 0.16033592689195192}, {\"truth_threshold\": 45.20068991840033, \"match_probability\": 0.9999999999999752, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 175.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6363.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.026766594499349594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9732334017753601, \"precision\": 1.0, \"recall\": 0.026766594499349594, \"specificity\": 1.0, \"npv\": 0.9442243576049805, \"accuracy\": 0.9443097710609436, \"f1\": 0.05213764337851929, \"f2\": 0.033235841531507576, \"f0_5\": 0.12088974854932302, \"p4\": 0.09896318654717305, \"phi\": 0.15897694115260677}, {\"truth_threshold\": 45.212762750700904, \"match_probability\": 0.9999999999999755, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 171.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6367.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.026154788210988045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9738451838493347, \"precision\": 1.0, \"recall\": 0.026154788210988045, \"specificity\": 1.0, \"npv\": 0.9441912174224854, \"accuracy\": 0.9442747235298157, \"f1\": 0.05097630049187658, \"f2\": 0.032481100178551076, \"f0_5\": 0.11838825810024924, \"p4\": 0.09686865856438731, \"phi\": 0.1571468041308966}, {\"truth_threshold\": 45.24420064740525, \"match_probability\": 0.999999999999976, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 170.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6368.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.026001835241913795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9739981889724731, \"precision\": 1.0, \"recall\": 0.026001835241913795, \"specificity\": 1.0, \"npv\": 0.9441829323768616, \"accuracy\": 0.9442660212516785, \"f1\": 0.05068574836016696, \"f2\": 0.03229237899855634, \"f0_5\": 0.11776115267387088, \"p4\": 0.09634389303925063, \"phi\": 0.15668595861264853}, {\"truth_threshold\": 45.28859476676371, \"match_probability\": 0.9999999999999767, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 168.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6370.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.025695931166410446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9743040800094604, \"precision\": 1.0, \"recall\": 0.025695931166410446, \"specificity\": 1.0, \"npv\": 0.9441664218902588, \"accuracy\": 0.9442484974861145, \"f1\": 0.05010438413361169, \"f2\": 0.031914893617021274, \"f0_5\": 0.11650485436893204, \"p4\": 0.09529299759632934, \"phi\": 0.15576018433964442}, {\"truth_threshold\": 45.29379932279181, \"match_probability\": 0.9999999999999768, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 166.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6372.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.025390027090907097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9746099710464478, \"precision\": 1.0, \"recall\": 0.025390027090907097, \"specificity\": 1.0, \"npv\": 0.9441498517990112, \"accuracy\": 0.9442309737205505, \"f1\": 0.049522673031026254, \"f2\": 0.03153735086252755, \"f0_5\": 0.11524576506525964, \"p4\": 0.09424027898828746, \"phi\": 0.15482890739737362}, {\"truth_threshold\": 45.34270892327276, \"match_probability\": 0.9999999999999776, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 165.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6373.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.025237075984477997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9747629165649414, \"precision\": 1.0, \"recall\": 0.025237075984477997, \"specificity\": 1.0, \"npv\": 0.9441415667533875, \"accuracy\": 0.9442222118377686, \"f1\": 0.049231687304192154, \"f2\": 0.03134855796633355, \"f0_5\": 0.11461517088080023, \"p4\": 0.09371323450284023, \"phi\": 0.15436118300926635}, {\"truth_threshold\": 45.35938766441939, \"match_probability\": 0.9999999999999778, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 164.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6374.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.025084123015403748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9749158620834351, \"precision\": 1.0, \"recall\": 0.025084123015403748, \"specificity\": 1.0, \"npv\": 0.9441332817077637, \"accuracy\": 0.9442135095596313, \"f1\": 0.0489406147418681, \"f2\": 0.031159750721994225, \"f0_5\": 0.11398387545176536, \"p4\": 0.09318573243061393, \"phi\": 0.15389202788599787}, {\"truth_threshold\": 45.381704171155185, \"match_probability\": 0.9999999999999782, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 161.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6377.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.024625267833471298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9753747582435608, \"precision\": 1.0, \"recall\": 0.024625267833471298, \"specificity\": 1.0, \"npv\": 0.9441084861755371, \"accuracy\": 0.9441872239112854, \"f1\": 0.04806687565308255, \"f2\": 0.030593242883745677, \"f0_5\": 0.11208576998050682, \"p4\": 0.09160047468117503, \"phi\": 0.15247598650947763}, {\"truth_threshold\": 45.39333499634273, \"match_probability\": 0.9999999999999784, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 159.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6379.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02431936375796795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9756806492805481, \"precision\": 1.0, \"recall\": 0.02431936375796795, \"specificity\": 1.0, \"npv\": 0.9440919160842896, \"accuracy\": 0.9441697001457214, \"f1\": 0.04748394803643422, \"f2\": 0.030215499220858196, \"f0_5\": 0.11081683858377474, \"p4\": 0.09054133720705054, \"phi\": 0.151524625490947}, {\"truth_threshold\": 45.420525179720066, \"match_probability\": 0.9999999999999788, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 157.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6381.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0240134596824646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9759865403175354, \"precision\": 1.0, \"recall\": 0.0240134596824646, \"specificity\": 1.0, \"npv\": 0.944075345993042, \"accuracy\": 0.9441522359848022, \"f1\": 0.04690067214339059, \"f2\": 0.029837698126116537, \"f0_5\": 0.1095450739603684, \"p4\": 0.08948035490507694, \"phi\": 0.1505673226877175}, {\"truth_threshold\": 45.45473554100687, \"match_probability\": 0.9999999999999792, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 155.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6383.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02370755560696125, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9762924313545227, \"precision\": 1.0, \"recall\": 0.02370755560696125, \"specificity\": 1.0, \"npv\": 0.9440588355064392, \"accuracy\": 0.9441347122192383, \"f1\": 0.046317047661736145, \"f2\": 0.029459839586421864, \"f0_5\": 0.10827046661078514, \"p4\": 0.08841752291476483, \"phi\": 0.1496039013117087}, {\"truth_threshold\": 45.48644440073421, \"match_probability\": 0.9999999999999797, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 154.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6384.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02355460450053215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9764453768730164, \"precision\": 1.0, \"recall\": 0.02355460450053215, \"specificity\": 1.0, \"npv\": 0.9440505504608154, \"accuracy\": 0.9441259503364563, \"f1\": 0.04602510460251046, \"f2\": 0.02927088877062267, \"f0_5\": 0.10763209393346379, \"p4\": 0.08788541176290833, \"phi\": 0.1491198737359955}, {\"truth_threshold\": 45.49287066989364, \"match_probability\": 0.9999999999999798, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 151.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6387.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02309574745595455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9769042730331421, \"precision\": 1.0, \"recall\": 0.02309574745595455, \"specificity\": 1.0, \"npv\": 0.9440257549285889, \"accuracy\": 0.9440997242927551, \"f1\": 0.04514875168186575, \"f2\": 0.028703950119758202, \"f0_5\": 0.10571268552226268, \"p4\": 0.08628629034165028, \"phi\": 0.14765832287759817}, {\"truth_threshold\": 45.50723505323904, \"match_probability\": 0.99999999999998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 150.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6388.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.02294279634952545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9770572185516357, \"precision\": 1.0, \"recall\": 0.02294279634952545, \"specificity\": 1.0, \"npv\": 0.9440174698829651, \"accuracy\": 0.9440909624099731, \"f1\": 0.04485645933014354, \"f2\": 0.028514941829518668, \"f0_5\": 0.10507144858503782, \"p4\": 0.08575231850114212, \"phi\": 0.1471679309749162}, {\"truth_threshold\": 45.51886587842659, \"match_probability\": 0.9999999999999801, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 149.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6389.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.022789843380451202, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9772101640701294, \"precision\": 1.0, \"recall\": 0.022789843380451202, \"specificity\": 1.0, \"npv\": 0.9440091848373413, \"accuracy\": 0.9440822005271912, \"f1\": 0.04456407955735008, \"f2\": 0.028325919166571612, \"f0_5\": 0.10442949257078778, \"p4\": 0.08521787995212589, \"phi\": 0.14667590815791123}, {\"truth_threshold\": 45.53155649210881, \"match_probability\": 0.9999999999999803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 148.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6390.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.022636892274022102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.977363109588623, \"precision\": 1.0, \"recall\": 0.022636892274022102, \"specificity\": 1.0, \"npv\": 0.9440008997917175, \"accuracy\": 0.9440734386444092, \"f1\": 0.04427161232425965, \"f2\": 0.028136882129277566, \"f0_5\": 0.10378681626928471, \"p4\": 0.08468297407789792, \"phi\": 0.14618223795827373}, {\"truth_threshold\": 45.53370726460024, \"match_probability\": 0.9999999999999803, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 147.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6391.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.022483939304947853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9775160551071167, \"precision\": 1.0, \"recall\": 0.022483939304947853, \"specificity\": 1.0, \"npv\": 0.9439926147460938, \"accuracy\": 0.9440646767616272, \"f1\": 0.04397905759162304, \"f2\": 0.027947830715996807, \"f0_5\": 0.1031434184675835, \"p4\": 0.08414760026066759, \"phi\": 0.14568690362896425}, {\"truth_threshold\": 45.537724905677905, \"match_probability\": 0.9999999999999805, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 144.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6394.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.022025084123015404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9779748916625977, \"precision\": 1.0, \"recall\": 0.022025084123015404, \"specificity\": 1.0, \"npv\": 0.9439678192138672, \"accuracy\": 0.944038450717926, \"f1\": 0.04310086800359174, \"f2\": 0.027380590203833283, \"f0_5\": 0.10120888389091931, \"p4\": 0.08253866495670156, \"phi\": 0.144190744070598}, {\"truth_threshold\": 45.558758605550096, \"match_probability\": 0.9999999999999807, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 143.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6395.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.021872133016586304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9781278967857361, \"precision\": 1.0, \"recall\": 0.021872133016586304, \"specificity\": 1.0, \"npv\": 0.9439595341682434, \"accuracy\": 0.944029688835144, \"f1\": 0.04280796287980841, \"f2\": 0.02719148127020346, \"f0_5\": 0.10056258790436005, \"p4\": 0.08200141316773245, \"phi\": 0.14368857994054343}, {\"truth_threshold\": 45.562616081219616, \"match_probability\": 0.9999999999999808, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 142.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6396.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.021719180047512054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9782808423042297, \"precision\": 1.0, \"recall\": 0.021719180047512054, \"specificity\": 1.0, \"npv\": 0.9439512491226196, \"accuracy\": 0.9440209269523621, \"f1\": 0.04251497005988024, \"f2\": 0.027002357952384575, \"f0_5\": 0.09991556431184914, \"p4\": 0.08146369033041938, \"phi\": 0.14318466352461956}, {\"truth_threshold\": 45.57434924909758, \"match_probability\": 0.9999999999999809, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 139.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6399.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.021260324865579605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9787396788597107, \"precision\": 1.0, \"recall\": 0.021260324865579605, \"specificity\": 1.0, \"npv\": 0.9439264535903931, \"accuracy\": 0.9439947009086609, \"f1\": 0.04163546502920473, \"f2\": 0.026434901677380093, \"f0_5\": 0.09797011559063998, \"p4\": 0.07984768927926532, \"phi\": 0.1416622132389801}, {\"truth_threshold\": 45.59045018116238, \"match_probability\": 0.9999999999999811, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 138.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6400.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.021107371896505356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9788926243782043, \"precision\": 1.0, \"recall\": 0.021107371896505356, \"specificity\": 1.0, \"npv\": 0.9439181685447693, \"accuracy\": 0.9439859390258789, \"f1\": 0.04134212103055722, \"f2\": 0.026245720806390264, \"f0_5\": 0.09732016925246827, \"p4\": 0.07930807599389621, \"phi\": 0.1411510986742724}, {\"truth_threshold\": 45.60574332910655, \"match_probability\": 0.9999999999999813, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 136.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6402.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.020801467821002007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9791985154151917, \"precision\": 1.0, \"recall\": 0.020801467821002007, \"specificity\": 1.0, \"npv\": 0.9439016580581665, \"accuracy\": 0.9439684152603149, \"f1\": 0.04075516931375487, \"f2\": 0.025867315885575167, \"f0_5\": 0.09601807399039819, \"p4\": 0.07822742624958602, \"phi\": 0.14012330374052132}, {\"truth_threshold\": 45.61317025766246, \"match_probability\": 0.9999999999999815, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 135.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6403.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.020648516714572906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9793514609336853, \"precision\": 1.0, \"recall\": 0.020648516714572906, \"specificity\": 1.0, \"npv\": 0.9438933730125427, \"accuracy\": 0.943959653377533, \"f1\": 0.04046156151655927, \"f2\": 0.025678091832464715, \"f0_5\": 0.09536592257699915, \"p4\": 0.07768638852971531, \"phi\": 0.13960658239510598}, {\"truth_threshold\": 45.624772557282185, \"match_probability\": 0.9999999999999816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 134.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6404.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.020495563745498657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.979504406452179, \"precision\": 1.0, \"recall\": 0.020495563745498657, \"specificity\": 1.0, \"npv\": 0.943885087966919, \"accuracy\": 0.943950891494751, \"f1\": 0.04016786570743405, \"f2\": 0.025488853382028456, \"f0_5\": 0.09471303364433135, \"p4\": 0.07714487473555172, \"phi\": 0.13908795051341863}, {\"truth_threshold\": 45.62780024997975, \"match_probability\": 0.9999999999999816, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 133.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6405.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.020342612639069557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9796574115753174, \"precision\": 1.0, \"recall\": 0.020342612639069557, \"specificity\": 1.0, \"npv\": 0.9438768625259399, \"accuracy\": 0.9439421892166138, \"f1\": 0.03987408184679958, \"f2\": 0.02529960053262317, \"f0_5\": 0.09405940594059406, \"p4\": 0.07660288423383267, \"phi\": 0.13856738664287796}, {\"truth_threshold\": 45.63184708304245, \"match_probability\": 0.9999999999999817, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 132.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6406.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.020189659669995308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.979810357093811, \"precision\": 1.0, \"recall\": 0.020189659669995308, \"specificity\": 1.0, \"npv\": 0.9438685774803162, \"accuracy\": 0.9439334273338318, \"f1\": 0.039580209895052475, \"f2\": 0.025110333282605386, \"f0_5\": 0.093405038211152, \"p4\": 0.07606041639017201, \"phi\": 0.13804486892679443}, {\"truth_threshold\": 45.64610106672269, \"match_probability\": 0.9999999999999818, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 131.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6407.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.020036708563566208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9799633026123047, \"precision\": 1.0, \"recall\": 0.020036708563566208, \"specificity\": 1.0, \"npv\": 0.9438602924346924, \"accuracy\": 0.9439246654510498, \"f1\": 0.0392862498125656, \"f2\": 0.024921051630331394, \"f0_5\": 0.09274992919852733, \"p4\": 0.07551747056905751, \"phi\": 0.13752037509363357}, {\"truth_threshold\": 45.65636940217652, \"match_probability\": 0.999999999999982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 130.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6408.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01988375559449196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9801162481307983, \"precision\": 1.0, \"recall\": 0.01988375559449196, \"specificity\": 1.0, \"npv\": 0.9438520073890686, \"accuracy\": 0.9439159035682678, \"f1\": 0.038992201559688064, \"f2\": 0.02473175557415722, \"f0_5\": 0.09209407764239161, \"p4\": 0.07497404613384837, \"phi\": 0.13699388244590963}, {\"truth_threshold\": 45.66463701816012, \"match_probability\": 0.9999999999999821, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 128.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6410.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01957785338163376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9804221391677856, \"precision\": 1.0, \"recall\": 0.01957785338163376, \"specificity\": 1.0, \"npv\": 0.9438354969024658, \"accuracy\": 0.9438983798027039, \"f1\": 0.03840384038403841, \"f2\": 0.0243531202435312, \"f0_5\": 0.09078014184397164, \"p4\": 0.07388575886892505, \"phi\": 0.13593480771772218}, {\"truth_threshold\": 45.70363226604255, \"match_probability\": 0.9999999999999826, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 127.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6411.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01942490041255951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9805750846862793, \"precision\": 1.0, \"recall\": 0.01942490041255951, \"specificity\": 1.0, \"npv\": 0.943827211856842, \"accuracy\": 0.9438896775245667, \"f1\": 0.03810952738184546, \"f2\": 0.024163780965790176, \"f0_5\": 0.09012205506670451, \"p4\": 0.07334089476026384, \"phi\": 0.13540217800708124}, {\"truth_threshold\": 45.72420157005121, \"match_probability\": 0.9999999999999828, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 125.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6413.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01911899633705616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9808809757232666, \"precision\": 1.0, \"recall\": 0.01911899633705616, \"specificity\": 1.0, \"npv\": 0.9438107013702393, \"accuracy\": 0.9438721537590027, \"f1\": 0.037520636349992496, \"f2\": 0.023785059177227234, \"f0_5\": 0.08880363739698778, \"p4\": 0.0722497223846388, \"phi\": 0.13433061127794704}, {\"truth_threshold\": 45.732541082661925, \"match_probability\": 0.9999999999999829, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 124.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6414.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01896604523062706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.981033980846405, \"precision\": 1.0, \"recall\": 0.01896604523062706, \"specificity\": 1.0, \"npv\": 0.9438024163246155, \"accuracy\": 0.9438633918762207, \"f1\": 0.037226058240768536, \"f2\": 0.02359567666311463, \"f0_5\": 0.08814330395223202, \"p4\": 0.0717034128318885, \"phi\": 0.13379162374234108}, {\"truth_threshold\": 45.74125829976303, \"match_probability\": 0.999999999999983, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 123.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6415.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01881309226155281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9811869263648987, \"precision\": 1.0, \"recall\": 0.01881309226155281, \"specificity\": 1.0, \"npv\": 0.9437941312789917, \"accuracy\": 0.9438546299934387, \"f1\": 0.03693139168293049, \"f2\": 0.02340627973358706, \"f0_5\": 0.08748221906116643, \"p4\": 0.07115662017674665, \"phi\": 0.13325046556497894}, {\"truth_threshold\": 45.78115102688655, \"match_probability\": 0.9999999999999835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 122.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6416.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01866014115512371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9813398718833923, \"precision\": 1.0, \"recall\": 0.01866014115512371, \"specificity\": 1.0, \"npv\": 0.9437858462333679, \"accuracy\": 0.9438458681106567, \"f1\": 0.03663663663663664, \"f2\": 0.023216868386998553, \"f0_5\": 0.08682038144036436, \"p4\": 0.07060934377345311, \"phi\": 0.13270711019103218}, {\"truth_threshold\": 45.78190028426038, \"match_probability\": 0.9999999999999835, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 121.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6417.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01850718818604946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.981492817401886, \"precision\": 1.0, \"recall\": 0.01850718818604946, \"specificity\": 1.0, \"npv\": 0.9437776207923889, \"accuracy\": 0.9438371658325195, \"f1\": 0.03634179306202132, \"f2\": 0.02302744262170289, \"f0_5\": 0.0861577898034748, \"p4\": 0.07006158297509639, \"phi\": 0.13216153052026508}, {\"truth_threshold\": 45.81786067726545, \"match_probability\": 0.9999999999999839, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 118.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6420.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.018048333004117012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9819516539573669, \"precision\": 1.0, \"recall\": 0.018048333004117012, \"specificity\": 1.0, \"npv\": 0.9437527656555176, \"accuracy\": 0.9438108801841736, \"f1\": 0.03545673076923077, \"f2\": 0.022459078797106968, \"f0_5\": 0.08416547788873038, \"p4\": 0.06841538772320743, \"phi\": 0.13051116620735775}, {\"truth_threshold\": 45.85965300056527, \"match_probability\": 0.9999999999999843, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 117.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6421.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.017895380035042763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9821045994758606, \"precision\": 1.0, \"recall\": 0.017895380035042763, \"specificity\": 1.0, \"npv\": 0.9437445402145386, \"accuracy\": 0.9438021183013916, \"f1\": 0.03516153268219384, \"f2\": 0.022269595340515435, \"f0_5\": 0.08349985726520126, \"p4\": 0.06786568285236547, \"phi\": 0.12995640687274937}, {\"truth_threshold\": 45.87156632210876, \"match_probability\": 0.9999999999999845, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 116.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6422.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.017742428928613663, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9822575449943542, \"precision\": 1.0, \"recall\": 0.017742428928613663, \"specificity\": 1.0, \"npv\": 0.9437362551689148, \"accuracy\": 0.9437933564186096, \"f1\": 0.03486624586714758, \"f2\": 0.02208009745698188, \"f0_5\": 0.08283347614967153, \"p4\": 0.06731549033454214, \"phi\": 0.1293992789842622}, {\"truth_threshold\": 45.890010463021284, \"match_probability\": 0.9999999999999847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 113.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6425.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.017283573746681213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.98271644115448, \"precision\": 1.0, \"recall\": 0.017283573746681213, \"specificity\": 1.0, \"npv\": 0.9437114596366882, \"accuracy\": 0.9437671303749084, \"f1\": 0.03397985265373628, \"f2\": 0.021511517228250523, \"f0_5\": 0.08082975679542204, \"p4\": 0.06566198035459522, \"phi\": 0.12771337336198374}, {\"truth_threshold\": 45.89627734398495, \"match_probability\": 0.9999999999999847, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 112.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6426.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.017130620777606964, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9828693866729736, \"precision\": 1.0, \"recall\": 0.017130620777606964, \"specificity\": 1.0, \"npv\": 0.9437031745910645, \"accuracy\": 0.9437583684921265, \"f1\": 0.03368421052631579, \"f2\": 0.021321961620469083, \"f0_5\": 0.08016032064128256, \"p4\": 0.06510983069839982, \"phi\": 0.12714645719328818}, {\"truth_threshold\": 45.94659399138765, \"match_probability\": 0.9999999999999852, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 111.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6427.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.016977669671177864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9830223321914673, \"precision\": 1.0, \"recall\": 0.016977669671177864, \"specificity\": 1.0, \"npv\": 0.9436948895454407, \"accuracy\": 0.9437496066093445, \"f1\": 0.03338847947059708, \"f2\": 0.021132391577504475, \"f0_5\": 0.0794901174448582, \"p4\": 0.06455719011413266, \"phi\": 0.126577011932181}, {\"truth_threshold\": 45.952762404956744, \"match_probability\": 0.9999999999999853, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 108.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6430.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.016518812626600266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9834811687469482, \"precision\": 1.0, \"recall\": 0.016518812626600266, \"specificity\": 1.0, \"npv\": 0.9436700940132141, \"accuracy\": 0.9437233805656433, \"f1\": 0.03250075233222991, \"f2\": 0.020563594821020565, \"f0_5\": 0.07747489239598278, \"p4\": 0.06289631618950976, \"phi\": 0.12485315477409589}, {\"truth_threshold\": 45.96666667187635, \"match_probability\": 0.9999999999999855, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 107.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6431.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.016365861520171165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836341142654419, \"precision\": 1.0, \"recall\": 0.016365861520171165, \"specificity\": 1.0, \"npv\": 0.9436618685722351, \"accuracy\": 0.9437146186828613, \"f1\": 0.032204665161775774, \"f2\": 0.020373967020830955, \"f0_5\": 0.07680160780935975, \"p4\": 0.06234170528364087, \"phi\": 0.12427324231516745}, {\"truth_threshold\": 45.99905605723068, \"match_probability\": 0.9999999999999858, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 105.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6433.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.016059957444667816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983940064907074, \"precision\": 1.0, \"recall\": 0.016059957444667816, \"specificity\": 1.0, \"npv\": 0.9436452984809875, \"accuracy\": 0.9436970949172974, \"f1\": 0.03161222339304531, \"f2\": 0.01999466808850973, \"f0_5\": 0.07545271629778671, \"p4\": 0.061231000090229214, \"phi\": 0.1231052531215572}, {\"truth_threshold\": 46.004292705596825, \"match_probability\": 0.9999999999999858, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 104.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6434.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.015907004475593567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9840930104255676, \"precision\": 1.0, \"recall\": 0.015907004475593567, \"specificity\": 1.0, \"npv\": 0.9436370730400085, \"accuracy\": 0.9436883330345154, \"f1\": 0.031315868714242696, \"f2\": 0.019804996953077393, \"f0_5\": 0.07477710670117918, \"p4\": 0.06067490447011596, \"phi\": 0.12251709855407121}, {\"truth_threshold\": 46.03076491695802, \"match_probability\": 0.9999999999999861, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 103.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6435.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.015754053369164467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9842459559440613, \"precision\": 1.0, \"recall\": 0.015754053369164467, \"specificity\": 1.0, \"npv\": 0.9436287879943848, \"accuracy\": 0.9436795711517334, \"f1\": 0.031019424785423882, \"f2\": 0.019615311369263, \"f0_5\": 0.07410071942446043, \"p4\": 0.060118312610688146, \"phi\": 0.1219261172232132}, {\"truth_threshold\": 46.06620234542726, \"match_probability\": 0.9999999999999865, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 100.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6438.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.015295197255909443, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9847047924995422, \"precision\": 1.0, \"recall\": 0.015295197255909443, \"specificity\": 1.0, \"npv\": 0.9436039924621582, \"accuracy\": 0.9436533451080322, \"f1\": 0.030129557095510694, \"f2\": 0.019046167911016303, \"f0_5\": 0.07206687806284232, \"p4\": 0.058445552897662276, \"phi\": 0.1201357944816541}, {\"truth_threshold\": 46.077833170614795, \"match_probability\": 0.9999999999999866, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 99.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6439.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.015142245218157768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9848577380180359, \"precision\": 1.0, \"recall\": 0.015142245218157768, \"specificity\": 1.0, \"npv\": 0.9435957074165344, \"accuracy\": 0.9436445832252502, \"f1\": 0.029832755763146, \"f2\": 0.01885642451716125, \"f0_5\": 0.07138736659936544, \"p4\": 0.05788696937609011, \"phi\": 0.11953308271033362}, {\"truth_threshold\": 46.08521270098039, \"match_probability\": 0.9999999999999866, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 98.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6440.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.014989293180406094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9850106835365295, \"precision\": 1.0, \"recall\": 0.014989293180406094, \"specificity\": 1.0, \"npv\": 0.9435874819755554, \"accuracy\": 0.9436358213424683, \"f1\": 0.029535864978902954, \"f2\": 0.018666666666666668, \"f0_5\": 0.0707070707070707, \"p4\": 0.057327886256719765, \"phi\": 0.11892732713483284}, {\"truth_threshold\": 46.11322707714999, \"match_probability\": 0.9999999999999869, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 97.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6441.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.014836341142654419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9851636290550232, \"precision\": 1.0, \"recall\": 0.014836341142654419, \"specificity\": 1.0, \"npv\": 0.9435791969299316, \"accuracy\": 0.9436270594596863, \"f1\": 0.029238884702336095, \"f2\": 0.0184768943578803, \"f0_5\": 0.07002598902685533, \"p4\": 0.05676830286422066, \"phi\": 0.11831848100475251}, {\"truth_threshold\": 46.175412681883536, \"match_probability\": 0.9999999999999875, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 95.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6443.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.01453043706715107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9854695796966553, \"precision\": 1.0, \"recall\": 0.01453043706715107, \"specificity\": 1.0, \"npv\": 0.9435626268386841, \"accuracy\": 0.9436095952987671, \"f1\": 0.028644655510327154, \"f2\": 0.018097306358821962, \"f0_5\": 0.06866146285053484, \"p4\": 0.05564763255242278, \"phi\": 0.11709132399365842}, {\"truth_threshold\": 46.22970107771014, \"match_probability\": 0.9999999999999879, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 94.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6444.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.014377485029399395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9856225252151489, \"precision\": 1.0, \"recall\": 0.014377485029399395, \"specificity\": 1.0, \"npv\": 0.9435544013977051, \"accuracy\": 0.9436008334159851, \"f1\": 0.028347406513872134, \"f2\": 0.01790749066524423, \"f0_5\": 0.06797801562048018, \"p4\": 0.05508654427636353, \"phi\": 0.11647291339163096}, {\"truth_threshold\": 46.26852208627501, \"match_probability\": 0.9999999999999882, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 90.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6448.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.013765677809715271, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9862343072891235, \"precision\": 1.0, \"recall\": 0.013765677809715271, \"specificity\": 1.0, \"npv\": 0.9435213208198547, \"accuracy\": 0.943565845489502, \"f1\": 0.02715751357875679, \"f2\": 0.01714808322536392, \"f0_5\": 0.06523630037692085, \"p4\": 0.052837154484950195, \"phi\": 0.11396583020519321}, {\"truth_threshold\": 46.300225591951246, \"match_probability\": 0.9999999999999885, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 86.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6452.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.013153869658708572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9868461489677429, \"precision\": 1.0, \"recall\": 0.013153869658708572, \"specificity\": 1.0, \"npv\": 0.9434882998466492, \"accuracy\": 0.943530797958374, \"f1\": 0.025966183574879228, \"f2\": 0.016388444241176917, \"f0_5\": 0.06248183667538506, \"p4\": 0.05057967315128733, \"phi\": 0.11140252167906227}, {\"truth_threshold\": 46.326220800484194, \"match_probability\": 0.9999999999999887, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 85.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6453.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.013000917620956898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9869990944862366, \"precision\": 1.0, \"recall\": 0.013000917620956898, \"specificity\": 1.0, \"npv\": 0.9434800148010254, \"accuracy\": 0.943522036075592, \"f1\": 0.025668126226785444, \"f2\": 0.016198498303921942, \"f0_5\": 0.0617912183774353, \"p4\": 0.050014033359465644, \"phi\": 0.1107524537278524}, {\"truth_threshold\": 46.35269301184538, \"match_probability\": 0.9999999999999889, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 84.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6454.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.012847965583205223, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9871520400047302, \"precision\": 1.0, \"recall\": 0.012847965583205223, \"specificity\": 1.0, \"npv\": 0.9434717297554016, \"accuracy\": 0.9435133337974548, \"f1\": 0.02536997885835095, \"f2\": 0.016008537886873, \"f0_5\": 0.06109979633401222, \"p4\": 0.0494478844034036, \"phi\": 0.11009855905868271}, {\"truth_threshold\": 46.35642693463839, \"match_probability\": 0.9999999999999889, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 83.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6455.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.012695013545453548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9873049855232239, \"precision\": 1.0, \"recall\": 0.012695013545453548, \"specificity\": 1.0, \"npv\": 0.9434635043144226, \"accuracy\": 0.9435045719146729, \"f1\": 0.02507174142878719, \"f2\": 0.01581856298837431, \"f0_5\": 0.06040756914119359, \"p4\": 0.04888122559047077, \"phi\": 0.1094407690788124}, {\"truth_threshold\": 46.3830666608889, \"match_probability\": 0.9999999999999891, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 82.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6456.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.012542061507701874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9874579310417175, \"precision\": 1.0, \"recall\": 0.012542061507701874, \"specificity\": 1.0, \"npv\": 0.9434552192687988, \"accuracy\": 0.9434958100318909, \"f1\": 0.024773413897280966, \"f2\": 0.01562857360676984, \"f0_5\": 0.05971453539178561, \"p4\": 0.048314056226779964, \"phi\": 0.10877901312277428}, {\"truth_threshold\": 46.39333499634273, \"match_probability\": 0.9999999999999892, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 81.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6457.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.012389109469950199, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9876108765602112, \"precision\": 1.0, \"recall\": 0.012389109469950199, \"specificity\": 1.0, \"npv\": 0.943446934223175, \"accuracy\": 0.9434870481491089, \"f1\": 0.02447499622299441, \"f2\": 0.015438569740403309, \"f0_5\": 0.05902069367531332, \"p4\": 0.047746375617184346, \"phi\": 0.1081132183636213}, {\"truth_threshold\": 46.439877582279756, \"match_probability\": 0.9999999999999896, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 70.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6468.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.010706637986004353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9892933368682861, \"precision\": 1.0, \"recall\": 0.010706637986004353, \"specificity\": 1.0, \"npv\": 0.9433560967445374, \"accuracy\": 0.9433907866477966, \"f1\": 0.0211864406779661, \"f2\": 0.013347570742124934, \"f0_5\": 0.0513347022587269, \"p4\": 0.041467946600399465, \"phi\": 0.10049961241941906}, {\"truth_threshold\": 46.461167164217414, \"match_probability\": 0.9999999999999897, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 69.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6469.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.010553685948252678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9894463419914246, \"precision\": 1.0, \"recall\": 0.010553685948252678, \"specificity\": 1.0, \"npv\": 0.9433478116989136, \"accuracy\": 0.9433820247650146, \"f1\": 0.020886938095958832, \"f2\": 0.013157392929331452, \"f0_5\": 0.05063105371294394, \"p4\": 0.040894076356058955, \"phi\": 0.09977873889319532}, {\"truth_threshold\": 46.4812398447061, \"match_probability\": 0.9999999999999898, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 67.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6471.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.010247781872749329, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9897522330284119, \"precision\": 1.0, \"recall\": 0.010247781872749329, \"specificity\": 1.0, \"npv\": 0.9433313012123108, \"accuracy\": 0.9433645009994507, \"f1\": 0.02028766086298259, \"f2\": 0.012776993783134368, \"f0_5\": 0.049221275345283574, \"p4\": 0.03974477395803542, \"phi\": 0.09832117573799774}, {\"truth_threshold\": 46.52826457642884, \"match_probability\": 0.9999999999999901, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 66.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6472.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.010094829834997654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9899051785469055, \"precision\": 1.0, \"recall\": 0.010094829834997654, \"specificity\": 1.0, \"npv\": 0.943323016166687, \"accuracy\": 0.9433557391166687, \"f1\": 0.019987886129618413, \"f2\": 0.012586772446410863, \"f0_5\": 0.04851514260511614, \"p4\": 0.03916934037687788, \"phi\": 0.09758424987205754}, {\"truth_threshold\": 46.56325999778504, \"match_probability\": 0.9999999999999903, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 65.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6473.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00994187779724598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9900581240653992, \"precision\": 1.0, \"recall\": 0.00994187779724598, \"specificity\": 1.0, \"npv\": 0.943314790725708, \"accuracy\": 0.9433470368385315, \"f1\": 0.01968802059669847, \"f2\": 0.012396536598390358, \"f0_5\": 0.04780817887614004, \"p4\": 0.03859338425379825, \"phi\": 0.09684172951879544}, {\"truth_threshold\": 46.59045018116238, \"match_probability\": 0.9999999999999906, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 62.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6476.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00948302261531353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905169606208801, \"precision\": 1.0, \"recall\": 0.00948302261531353, \"specificity\": 1.0, \"npv\": 0.9432899951934814, \"accuracy\": 0.9433207511901855, \"f1\": 0.018787878787878787, \"f2\": 0.011825741969939726, \"f0_5\": 0.04568228706159741, \"p4\": 0.036862373456416145, \"phi\": 0.09457927894566588}, {\"truth_threshold\": 46.64473857698898, \"match_probability\": 0.9999999999999909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 61.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6477.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.009330070577561855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906699061393738, \"precision\": 1.0, \"recall\": 0.009330070577561855, \"specificity\": 1.0, \"npv\": 0.9432817101478577, \"accuracy\": 0.9433119893074036, \"f1\": 0.018487649643885436, \"f2\": 0.01163544806012284, \"f0_5\": 0.044971984665290475, \"p4\": 0.036284319982463877, \"phi\": 0.09381303146341126}, {\"truth_threshold\": 46.64541910261598, \"match_probability\": 0.9999999999999909, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 60.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6478.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00917711853981018, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908229112625122, \"precision\": 1.0, \"recall\": 0.00917711853981018, \"specificity\": 1.0, \"npv\": 0.9432734847068787, \"accuracy\": 0.9433032274246216, \"f1\": 0.018187329493785997, \"f2\": 0.011445139630703495, \"f0_5\": 0.04426084390675716, \"p4\": 0.035705740368413216, \"phi\": 0.09304048724617277}, {\"truth_threshold\": 46.670175201701554, \"match_probability\": 0.9999999999999911, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 59.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6479.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.009024166502058506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9909758567810059, \"precision\": 1.0, \"recall\": 0.009024166502058506, \"specificity\": 1.0, \"npv\": 0.9432651996612549, \"accuracy\": 0.9432945251464844, \"f1\": 0.01788691829619524, \"f2\": 0.011254816680019838, \"f0_5\": 0.043548863300856215, \"p4\": 0.035126633890667835, \"phi\": 0.09226148811810053}, {\"truth_threshold\": 46.68131575930675, \"match_probability\": 0.9999999999999911, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 58.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6480.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.008871214464306831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9911288022994995, \"precision\": 1.0, \"recall\": 0.008871214464306831, \"specificity\": 1.0, \"npv\": 0.9432569742202759, \"accuracy\": 0.9432857632637024, \"f1\": 0.01758641600970285, \"f2\": 0.011064479206409768, \"f0_5\": 0.04283604135893648, \"p4\": 0.03454699982430398, \"phi\": 0.09147586917090254}, {\"truth_threshold\": 46.692543014730006, \"match_probability\": 0.9999999999999912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 57.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6481.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.008718262426555157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912817478179932, \"precision\": 1.0, \"recall\": 0.008718262426555157, \"specificity\": 1.0, \"npv\": 0.9432486891746521, \"accuracy\": 0.9432770013809204, \"f1\": 0.01728582259287339, \"f2\": 0.01087412720821092, \"f0_5\": 0.042122376588826484, \"p4\": 0.03396683744306742, \"phi\": 0.09068345835573235}, {\"truth_threshold\": 46.69818957787115, \"match_probability\": 0.9999999999999912, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 56.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6482.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.008565310388803482, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9914346933364868, \"precision\": 1.0, \"recall\": 0.008565310388803482, \"specificity\": 1.0, \"npv\": 0.9432404041290283, \"accuracy\": 0.9432682394981384, \"f1\": 0.016985138004246284, \"f2\": 0.010683760683760684, \"f0_5\": 0.041407867494824016, \"p4\": 0.03338614601937043, \"phi\": 0.08988407604270791}, {\"truth_threshold\": 46.84079397331395, \"match_probability\": 0.9999999999999921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 52.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6486.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.007953502237796783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9920464754104614, \"precision\": 1.0, \"recall\": 0.007953502237796783, \"specificity\": 1.0, \"npv\": 0.9432073831558228, \"accuracy\": 0.9432332515716553, \"f1\": 0.015781487101669194, \"f2\": 0.009922149290184704, \"f0_5\": 0.038541357841683964, \"p4\": 0.0310580753013781, \"phi\": 0.0866129460913429}, {\"truth_threshold\": 46.853484586996174, \"match_probability\": 0.9999999999999921, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 51.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6487.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.007800550665706396, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921994209289551, \"precision\": 1.0, \"recall\": 0.007800550665706396, \"specificity\": 1.0, \"npv\": 0.9431991577148438, \"accuracy\": 0.9432244896888733, \"f1\": 0.015480346031264228, \"f2\": 0.009731710109529444, \"f0_5\": 0.037822604568377334, \"p4\": 0.030474727704674597, \"phi\": 0.0857757108736483}, {\"truth_threshold\": 46.91775595512883, \"match_probability\": 0.9999999999999925, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 50.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6488.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0076475986279547215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923524260520935, \"precision\": 1.0, \"recall\": 0.0076475986279547215, \"specificity\": 1.0, \"npv\": 0.94319087266922, \"accuracy\": 0.9432157278060913, \"f1\": 0.015179113539769277, \"f2\": 0.009541256392641783, \"f0_5\": 0.037102997922232116, \"p4\": 0.029890846671808132, \"phi\": 0.08493023754029434}, {\"truth_threshold\": 46.937655512566536, \"match_probability\": 0.9999999999999926, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 49.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6489.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.007494646590203047, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925053715705872, \"precision\": 1.0, \"recall\": 0.007494646590203047, \"specificity\": 1.0, \"npv\": 0.9431825876235962, \"accuracy\": 0.9432069659233093, \"f1\": 0.01487778958554729, \"f2\": 0.009350788137857334, \"f0_5\": 0.036382536382536385, \"p4\": 0.02930643146577009, \"phi\": 0.0840762775631083}, {\"truth_threshold\": 46.94659399138765, \"match_probability\": 0.9999999999999927, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 47.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6491.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0071887425146996975, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928112626075745, \"precision\": 1.0, \"recall\": 0.0071887425146996975, \"specificity\": 1.0, \"npv\": 0.9431660771369934, \"accuracy\": 0.9431895017623901, \"f1\": 0.014274867122247532, \"f2\": 0.008969808007939234, \"f0_5\": 0.034939042521558134, \"p4\": 0.02813599557935038, \"phi\": 0.08234183888753004}, {\"truth_threshold\": 46.95445075510951, \"match_probability\": 0.9999999999999927, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 45.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6493.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0068828389048576355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931171536445618, \"precision\": 1.0, \"recall\": 0.0068828389048576355, \"specificity\": 1.0, \"npv\": 0.9431495666503906, \"accuracy\": 0.9431719779968262, \"f1\": 0.013671578307762418, \"f2\": 0.008588769706454938, \"f0_5\": 0.0334921107472462, \"p4\": 0.026963414122124964, \"phi\": 0.08057013418681883}, {\"truth_threshold\": 46.99905605723068, \"match_probability\": 0.9999999999999929, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 44.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6494.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.006729886867105961, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932700991630554, \"precision\": 1.0, \"recall\": 0.006729886867105961, \"specificity\": 1.0, \"npv\": 0.9431413412094116, \"accuracy\": 0.9431632161140442, \"f1\": 0.013369796414463689, \"f2\": 0.008398228737211789, \"f0_5\": 0.03276735180220435, \"p4\": 0.026376316947451, \"phi\": 0.0796695321897816}, {\"truth_threshold\": 47.063186394650394, \"match_probability\": 0.9999999999999932, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 43.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6495.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.006576934829354286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9934230446815491, \"precision\": 1.0, \"recall\": 0.006576934829354286, \"specificity\": 1.0, \"npv\": 0.9431330561637878, \"accuracy\": 0.9431544542312622, \"f1\": 0.013067922808083879, \"f2\": 0.008207673220080168, \"f0_5\": 0.03204172876304024, \"p4\": 0.025788681148920474, \"phi\": 0.0787586485590242}, {\"truth_threshold\": 47.10758051400885, \"match_probability\": 0.9999999999999934, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 42.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6496.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0064239827916026115, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935759902000427, \"precision\": 1.0, \"recall\": 0.0064239827916026115, \"specificity\": 1.0, \"npv\": 0.9431248307228088, \"accuracy\": 0.9431456923484802, \"f1\": 0.01276595744680851, \"f2\": 0.008017103153393906, \"f0_5\": 0.031315240083507306, \"p4\": 0.025200505979950924, \"phi\": 0.07783712233459901}, {\"truth_threshold\": 47.28859476676371, \"match_probability\": 0.9999999999999942, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 41.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6497.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.006271030753850937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9937289953231812, \"precision\": 1.0, \"recall\": 0.006271030753850937, \"specificity\": 1.0, \"npv\": 0.9431165456771851, \"accuracy\": 0.943136990070343, \"f1\": 0.012463900288797689, \"f2\": 0.00782651853548658, \"f0_5\": 0.030587884213667562, \"p4\": 0.02461179069257953, \"phi\": 0.07690457093524816}, {\"truth_threshold\": 47.35269301184538, \"match_probability\": 0.9999999999999944, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 40.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6498.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.006118078716099262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938819408416748, \"precision\": 1.0, \"recall\": 0.006118078716099262, \"specificity\": 1.0, \"npv\": 0.943108320236206, \"accuracy\": 0.943128228187561, \"f1\": 0.012161751292186074, \"f2\": 0.0076359193646915085, \"f0_5\": 0.029859659599880562, \"p4\": 0.024022534537459932, \"phi\": 0.0759605883006929}, {\"truth_threshold\": 47.39333499634273, \"match_probability\": 0.9999999999999946, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 38.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6500.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0058121751062572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9941878318786621, \"precision\": 1.0, \"recall\": 0.0058121751062572, \"specificity\": 1.0, \"npv\": 0.9430917501449585, \"accuracy\": 0.9431107044219971, \"f1\": 0.011557177615571776, \"f2\": 0.007254677357770141, \"f0_5\": 0.028400597907324365, \"p4\": 0.02284239661965374, \"phi\": 0.0740365750408254}, {\"truth_threshold\": 47.44461550128642, \"match_probability\": 0.9999999999999948, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 37.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6501.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.005659223068505526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943407773971558, \"precision\": 1.0, \"recall\": 0.005659223068505526, \"specificity\": 1.0, \"npv\": 0.9430835247039795, \"accuracy\": 0.9431019425392151, \"f1\": 0.011254752851711026, \"f2\": 0.0070640345183092135, \"f0_5\": 0.02766975770266228, \"p4\": 0.02225151335132785, \"phi\": 0.07305559505047307}, {\"truth_threshold\": 47.51886587842659, \"match_probability\": 0.999999999999995, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 36.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6502.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.005506271030753851, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9944937229156494, \"precision\": 1.0, \"recall\": 0.005506271030753851, \"specificity\": 1.0, \"npv\": 0.9430752396583557, \"accuracy\": 0.9430931806564331, \"f1\": 0.010952236081533314, \"f2\": 0.006873377119291278, \"f0_5\": 0.02693804250224484, \"p4\": 0.021660086203968715, \"phi\": 0.07206127961093696}, {\"truth_threshold\": 47.5226180132877, \"match_probability\": 0.999999999999995, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 35.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6503.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.005353318993002176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946466684341431, \"precision\": 1.0, \"recall\": 0.005353318993002176, \"specificity\": 1.0, \"npv\": 0.9430670142173767, \"accuracy\": 0.9430844783782959, \"f1\": 0.010649627263045794, \"f2\": 0.006682705159048383, \"f0_5\": 0.02620545073375262, \"p4\": 0.021068114421264068, \"phi\": 0.07105306887580727}, {\"truth_threshold\": 47.5516291725975, \"match_probability\": 0.9999999999999951, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 33.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6505.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.005047414917498827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949525594711304, \"precision\": 1.0, \"recall\": 0.005047414917498827, \"specificity\": 1.0, \"npv\": 0.9430505037307739, \"accuracy\": 0.9430669546127319, \"f1\": 0.010044133313042155, \"f2\": 0.006301317548214626, \"f0_5\": 0.024737631184407798, \"p4\": 0.019882533917551466, \"phi\": 0.0689925164852454}, {\"truth_threshold\": 47.584018557951836, \"match_probability\": 0.9999999999999952, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 32.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6506.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00489446334540844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951055645942688, \"precision\": 1.0, \"recall\": 0.00489446334540844, \"specificity\": 1.0, \"npv\": 0.9430422186851501, \"accuracy\": 0.94305819272995, \"f1\": 0.009741248097412482, \"f2\": 0.006110601894286587, \"f0_5\": 0.024002400240024, \"p4\": 0.019288923676891535, \"phi\": 0.06793883637232995}, {\"truth_threshold\": 47.63184708304245, \"match_probability\": 0.9999999999999954, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 31.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6507.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.004741511307656765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952585101127625, \"precision\": 1.0, \"recall\": 0.004741511307656765, \"specificity\": 1.0, \"npv\": 0.9430339932441711, \"accuracy\": 0.943049430847168, \"f1\": 0.009438270665245852, \"f2\": 0.005919871672459229, \"f0_5\": 0.023266286400480337, \"p4\": 0.018694765761575596, \"phi\": 0.06686857386349593}, {\"truth_threshold\": 47.66463701816012, \"match_probability\": 0.9999999999999956, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 30.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6508.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00458855926990509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9954114556312561, \"precision\": 1.0, \"recall\": 0.00458855926990509, \"specificity\": 1.0, \"npv\": 0.9430257081985474, \"accuracy\": 0.943040668964386, \"f1\": 0.009135200974421437, \"f2\": 0.005729126881063326, \"f0_5\": 0.022529288074496844, \"p4\": 0.01810005940824433, \"phi\": 0.06578091957121972}, {\"truth_threshold\": 47.70363226604255, \"match_probability\": 0.9999999999999957, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 29.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6509.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.004435607232153416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955644011497498, \"precision\": 1.0, \"recall\": 0.004435607232153416, \"specificity\": 1.0, \"npv\": 0.9430174827575684, \"accuracy\": 0.943031907081604, \"f1\": 0.008832038982792752, \"f2\": 0.0055383675184293955, \"f0_5\": 0.02179140366696724, \"p4\": 0.017504803852119177, \"phi\": 0.06467499605606693}, {\"truth_threshold\": 47.96666667187635, \"match_probability\": 0.9999999999999963, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 27.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6511.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.004129703156650066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958702921867371, \"precision\": 1.0, \"recall\": 0.004129703156650066, \"specificity\": 1.0, \"npv\": 0.9430009722709656, \"accuracy\": 0.9430144429206848, \"f1\": 0.008225437928408226, \"f2\": 0.005156805072768249, \"f0_5\": 0.020312970207643697, \"p4\": 0.01631264206525696, \"phi\": 0.06240444025371502}, {\"truth_threshold\": 48.02011767275851, \"match_probability\": 0.9999999999999964, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 26.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6512.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.003976751118898392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960232377052307, \"precision\": 1.0, \"recall\": 0.003976751118898392, \"specificity\": 1.0, \"npv\": 0.9429926872253418, \"accuracy\": 0.9430056810379028, \"f1\": 0.007921998781230956, \"f2\": 0.004966001986400795, \"f0_5\": 0.019572417946401688, \"p4\": 0.015715734297836802, \"phi\": 0.06123763121281737}, {\"truth_threshold\": 48.063186394650394, \"match_probability\": 0.9999999999999966, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 25.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6513.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0038237993139773607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961761832237244, \"precision\": 1.0, \"recall\": 0.0038237993139773607, \"specificity\": 1.0, \"npv\": 0.9429844617843628, \"accuracy\": 0.9429969191551208, \"f1\": 0.007618467164406522, \"f2\": 0.004775184322114834, \"f0_5\": 0.018830973184694184, \"p4\": 0.015118274254249954, \"phi\": 0.06004817495635262}, {\"truth_threshold\": 48.10758051400885, \"match_probability\": 0.9999999999999967, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 24.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6514.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.003670847276225686, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996329128742218, \"precision\": 1.0, \"recall\": 0.003670847276225686, \"specificity\": 1.0, \"npv\": 0.942976176738739, \"accuracy\": 0.9429881572723389, \"f1\": 0.00731484303565986, \"f2\": 0.004584352078239609, \"f0_5\": 0.01808863430810974, \"p4\": 0.014520261162571947, \"phi\": 0.0588346979290986}, {\"truth_threshold\": 48.28859476676371, \"match_probability\": 0.9999999999999971, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 23.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6515.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.003517895471304655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964821338653564, \"precision\": 1.0, \"recall\": 0.003517895471304655, \"specificity\": 1.0, \"npv\": 0.94296795129776, \"accuracy\": 0.9429793953895569, \"f1\": 0.007011126352690139, \"f2\": 0.004393505253104107, \"f0_5\": 0.017345399698340876, \"p4\": 0.013921694249439134, \"phi\": 0.0575956818776315}, {\"truth_threshold\": 48.46372432423413, \"match_probability\": 0.9999999999999974, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 22.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6516.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0033649434335529804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966350793838501, \"precision\": 1.0, \"recall\": 0.0033649434335529804, \"specificity\": 1.0, \"npv\": 0.9429596662521362, \"accuracy\": 0.9429706931114197, \"f1\": 0.006707317073170732, \"f2\": 0.004202643845037059, \"f0_5\": 0.016601267733172352, \"p4\": 0.013322572740045339, \"phi\": 0.0563294415660723}, {\"truth_threshold\": 48.590450181162375, \"match_probability\": 0.9999999999999977, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 21.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6517.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0032119913958013058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967880249023438, \"precision\": 1.0, \"recall\": 0.0032119913958013058, \"specificity\": 1.0, \"npv\": 0.9429514408111572, \"accuracy\": 0.9429619312286377, \"f1\": 0.0064034151547491995, \"f2\": 0.004011767852366943, \"f0_5\": 0.015856236786469344, \"p4\": 0.012722895858138473, \"phi\": 0.055034097875141255}, {\"truth_threshold\": 48.76773051112423, \"match_probability\": 0.9999999999999979, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 20.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6518.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.003059039358049631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969409704208374, \"precision\": 1.0, \"recall\": 0.003059039358049631, \"specificity\": 1.0, \"npv\": 0.9429431557655334, \"accuracy\": 0.9429531693458557, \"f1\": 0.006099420555047271, \"f2\": 0.0038208772734219776, \"f0_5\": 0.015110305228165609, \"p4\": 0.012122662826017176, \"phi\": 0.05370754505875522}, {\"truth_threshold\": 48.78565241912149, \"match_probability\": 0.9999999999999979, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 19.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6519.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0029060875531286, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997093915939331, \"precision\": 1.0, \"recall\": 0.0029060875531286, \"specificity\": 1.0, \"npv\": 0.9429349303245544, \"accuracy\": 0.9429444074630737, \"f1\": 0.0057953332316608205, \"f2\": 0.003629972106530129, \"f0_5\": 0.014363471424251588, \"p4\": 0.011521872864527426, \"phi\": 0.05234741052814377}, {\"truth_threshold\": 48.853484586996174, \"match_probability\": 0.999999999999998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 18.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6520.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0027531355153769255, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972468614578247, \"precision\": 1.0, \"recall\": 0.0027531355153769255, \"specificity\": 1.0, \"npv\": 0.9429266452789307, \"accuracy\": 0.9429356455802917, \"f1\": 0.005491153142159854, \"f2\": 0.003439052350019106, \"f0_5\": 0.01361573373676248, \"p4\": 0.010920525193059145, \"phi\": 0.05095100496708276}, {\"truth_threshold\": 48.87876182351297, \"match_probability\": 0.9999999999999981, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 17.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6521.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.002600183477625251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973998069763184, \"precision\": 1.0, \"recall\": 0.002600183477625251, \"specificity\": 1.0, \"npv\": 0.9429184198379517, \"accuracy\": 0.9429268836975098, \"f1\": 0.005186880244088482, \"f2\": 0.003248118002216363, \"f0_5\": 0.012867090523766273, \"p4\": 0.010318619029542802, \"phi\": 0.049515259775476585}, {\"truth_threshold\": 48.937655512566536, \"match_probability\": 0.9999999999999981, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 16.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6522.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00244723167270422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997552752494812, \"precision\": 1.0, \"recall\": 0.00244723167270422, \"specificity\": 1.0, \"npv\": 0.9429101347923279, \"accuracy\": 0.9429181814193726, \"f1\": 0.004882514494964907, \"f2\": 0.003057169061449098, \"f0_5\": 0.012117540139351712, \"p4\": 0.009716153590445989, \"phi\": 0.048036647669955204}, {\"truth_threshold\": 48.96666667187635, \"match_probability\": 0.9999999999999982, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 15.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6523.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.002294279634952545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977056980133057, \"precision\": 1.0, \"recall\": 0.002294279634952545, \"specificity\": 1.0, \"npv\": 0.9429019093513489, \"accuracy\": 0.9429094195365906, \"f1\": 0.0045780558522813975, \"f2\": 0.0028662055260442543, \"f0_5\": 0.011367080933616247, \"p4\": 0.009113128090770013, \"phi\": 0.0465110805431655}, {\"truth_threshold\": 49.300225591951246, \"match_probability\": 0.9999999999999986, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 14.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6524.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0021413275972008705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978586435317993, \"precision\": 1.0, \"recall\": 0.0021413275972008705, \"specificity\": 1.0, \"npv\": 0.9428936839103699, \"accuracy\": 0.9429006576538086, \"f1\": 0.004273504273504274, \"f2\": 0.002675227394328518, \"f0_5\": 0.010615711252653927, \"p4\": 0.008509541744046455, \"phi\": 0.044933776074828895}, {\"truth_threshold\": 49.370614919842644, \"match_probability\": 0.9999999999999987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 12.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6526.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.001835423638112843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981645941734314, \"precision\": 1.0, \"recall\": 0.001835423638112843, \"specificity\": 1.0, \"npv\": 0.9428771734237671, \"accuracy\": 0.9428831338882446, \"f1\": 0.00366412213740458, \"f2\": 0.0022932273352698363, \"f0_5\": 0.009110233829334954, \"p4\": 0.007300683356213649, \"phi\": 0.04160022891224967}, {\"truth_threshold\": 49.40714079586776, \"match_probability\": 0.9999999999999987, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 11.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6527.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0016824717167764902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998317539691925, \"precision\": 1.0, \"recall\": 0.0016824717167764902, \"specificity\": 1.0, \"npv\": 0.9428688883781433, \"accuracy\": 0.9428743720054626, \"f1\": 0.003359291494884715, \"f2\": 0.0021022054045789856, \"f0_5\": 0.008356122759039806, \"p4\": 0.0066954097347879295, \"phi\": 0.039829012535809026}, {\"truth_threshold\": 49.56325999778504, \"match_probability\": 0.9999999999999988, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 10.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6528.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0015295196790248156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984704852104187, \"precision\": 1.0, \"recall\": 0.0015295196790248156, \"specificity\": 1.0, \"npv\": 0.9428606629371643, \"accuracy\": 0.9428656697273254, \"f1\": 0.0030543677458766036, \"f2\": 0.0019111688708814312, \"f0_5\": 0.007601094557616297, \"p4\": 0.0060895721056747525, \"phi\": 0.03797530722012782}, {\"truth_threshold\": 49.78565241912149, \"match_probability\": 0.999999999999999, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 9.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6529.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0013765677576884627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986234307289124, \"precision\": 1.0, \"recall\": 0.0013765677576884627, \"specificity\": 1.0, \"npv\": 0.9428523778915405, \"accuracy\": 0.9428569078445435, \"f1\": 0.0027493508477165114, \"f2\": 0.0017201177325025802, \"f0_5\": 0.006845147550958321, \"p4\": 0.005483169675005273, \"phi\": 0.03602638202958567}, {\"truth_threshold\": 49.937655512566536, \"match_probability\": 0.9999999999999991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 7.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6531.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0010706637986004353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989293217658997, \"precision\": 1.0, \"recall\": 0.0010706637986004353, \"specificity\": 1.0, \"npv\": 0.9428358674049377, \"accuracy\": 0.9428393840789795, \"f1\": 0.0021390374331550803, \"f2\": 0.001337971635001338, \"f0_5\": 0.005330490405117271, \"p4\": 0.004268667226065932, \"phi\": 0.03177200440030331}, {\"truth_threshold\": 49.978297497063885, \"match_probability\": 0.9999999999999991, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 6.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6532.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0009177118190564215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990822672843933, \"precision\": 1.0, \"recall\": 0.0009177118190564215, \"specificity\": 1.0, \"npv\": 0.9428276419639587, \"accuracy\": 0.9428306221961975, \"f1\": 0.0018337408312958435, \"f2\": 0.0011468766725284808, \"f0_5\": 0.004571776897287412, \"p4\": 0.0036605656125917874, \"phi\": 0.029415031553152962}, {\"truth_threshold\": 50.40714079586776, \"match_probability\": 0.9999999999999993, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 5.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6533.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0007647598395124078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999235212802887, \"precision\": 1.0, \"recall\": 0.0007647598395124078, \"specificity\": 1.0, \"npv\": 0.942819356918335, \"accuracy\": 0.9428218603134155, \"f1\": 0.0015283509093687911, \"f2\": 0.0009557670986733952, \"f0_5\": 0.003812137846904544, \"p4\": 0.0030518960071457416, \"phi\": 0.026852009672667005}, {\"truth_threshold\": 50.615727417679174, \"match_probability\": 0.9999999999999994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 4.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6534.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.000611807918176055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993882179260254, \"precision\": 1.0, \"recall\": 0.000611807918176055, \"specificity\": 1.0, \"npv\": 0.942811131477356, \"accuracy\": 0.9428131580352783, \"f1\": 0.0012228676245796392, \"f2\": 0.000764642911760208, \"f0_5\": 0.003051571559353067, \"p4\": 0.0024426576083712687, \"phi\": 0.02401706247880159}, {\"truth_threshold\": 50.78565241912149, \"match_probability\": 0.9999999999999994, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 3.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6535.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00045885590952821076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999541163444519, \"precision\": 1.0, \"recall\": 0.00045885590952821076, \"specificity\": 1.0, \"npv\": 0.942802906036377, \"accuracy\": 0.9428043961524963, \"f1\": 0.0009172909341079345, \"f2\": 0.0005735041101127892, \"f0_5\": 0.0022900763358778627, \"p4\": 0.0018328496134037294, \"phi\": 0.020799295208147547}, {\"truth_threshold\": 51.300225591951246, \"match_probability\": 0.9999999999999997, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 2.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6536.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.0003059039590880275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996941089630127, \"precision\": 1.0, \"recall\": 0.0003059039590880275, \"specificity\": 1.0, \"npv\": 0.9427946209907532, \"accuracy\": 0.9427956342697144, \"f1\": 0.0006116207951070336, \"f2\": 0.00038235069205475264, \"f0_5\": 0.0015276504735716467, \"p4\": 0.001222471217866821, \"phi\": 0.01698247910435193}, {\"truth_threshold\": 51.78565241912149, \"match_probability\": 0.9999999999999998, \"row_count\": 114257.0, \"p\": 6538.0, \"n\": 107719.0, \"tp\": 1.0, \"tn\": 107719.0, \"fp\": 0.0, \"fn\": 6537.0, \"P_rate\": 0.057221876996595394, \"N_rate\": 0.9427781105041504, \"tp_rate\": 0.00015295197954401374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998470544815063, \"precision\": 1.0, \"recall\": 0.00015295197954401374, \"specificity\": 1.0, \"npv\": 0.9427863955497742, \"accuracy\": 0.9427868723869324, \"f1\": 0.0003058571647040832, \"f2\": 0.0001911826559094559, \"f0_5\": 0.0007642922653622745, \"p4\": 0.0006115216158690174, \"phi\": 0.01200837358540363}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.roc_chart_from_labels_column(\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clerical_match_score</th>\n",
       "      <th>found_by_blocking_rules</th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>rec_id_l</th>\n",
       "      <th>rec_id_r</th>\n",
       "      <th>given_name_l</th>\n",
       "      <th>given_name_r</th>\n",
       "      <th>gamma_given_name</th>\n",
       "      <th>tf_given_name_l</th>\n",
       "      <th>...</th>\n",
       "      <th>postcode_l</th>\n",
       "      <th>postcode_r</th>\n",
       "      <th>gamma_postcode</th>\n",
       "      <th>tf_postcode_l</th>\n",
       "      <th>tf_postcode_r</th>\n",
       "      <th>bf_postcode</th>\n",
       "      <th>bf_tf_adj_postcode</th>\n",
       "      <th>cluster_l</th>\n",
       "      <th>cluster_r</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-8.712500</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>rec-1320-dup-1</td>\n",
       "      <td>rec-1320-dup-4</td>\n",
       "      <td>amber</td>\n",
       "      <td>kexel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>...</td>\n",
       "      <td>461</td>\n",
       "      <td>4061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.215951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-1320</td>\n",
       "      <td>rec-1320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.635846</td>\n",
       "      <td>0.074456</td>\n",
       "      <td>rec-941-dup-0</td>\n",
       "      <td>rec-941-dup-3</td>\n",
       "      <td>coby</td>\n",
       "      <td>cobuy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>...</td>\n",
       "      <td>3078</td>\n",
       "      <td>3088</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.215951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-941</td>\n",
       "      <td>rec-941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.437169</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>rec-1727-dup-1</td>\n",
       "      <td>rec-1727-org</td>\n",
       "      <td>campblel</td>\n",
       "      <td>joshua</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3189</td>\n",
       "      <td>3198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.215951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-1727</td>\n",
       "      <td>rec-1727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.178625</td>\n",
       "      <td>0.469086</td>\n",
       "      <td>rec-1899-dup-0</td>\n",
       "      <td>rec-1899-org</td>\n",
       "      <td>thomas</td>\n",
       "      <td>matthew</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>...</td>\n",
       "      <td>6117</td>\n",
       "      <td>6171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.215951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-1899</td>\n",
       "      <td>rec-1899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-6.592447</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>rec-75-dup-0</td>\n",
       "      <td>rec-75-dup-4</td>\n",
       "      <td>samara</td>\n",
       "      <td>willing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>...</td>\n",
       "      <td>3765</td>\n",
       "      <td>3756</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.215951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-75</td>\n",
       "      <td>rec-75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-6.576899</td>\n",
       "      <td>0.010366</td>\n",
       "      <td>rec-75-dup-0</td>\n",
       "      <td>rec-75-dup-4</td>\n",
       "      <td>samara</td>\n",
       "      <td>willing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>...</td>\n",
       "      <td>3765</td>\n",
       "      <td>3756</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.216593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-75</td>\n",
       "      <td>rec-75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clerical_match_score  found_by_blocking_rules  match_weight  \\\n",
       "0                   1.0                     True     -8.712500   \n",
       "1                   1.0                     True     -3.635846   \n",
       "2                   1.0                     True     -5.437169   \n",
       "3                   1.0                     True     -0.178625   \n",
       "4                   1.0                     True     -6.592447   \n",
       "\n",
       "   match_probability        rec_id_l        rec_id_r given_name_l  \\\n",
       "0           0.002378  rec-1320-dup-1  rec-1320-dup-4        amber   \n",
       "1           0.074456   rec-941-dup-0   rec-941-dup-3         coby   \n",
       "2           0.022560  rec-1727-dup-1    rec-1727-org     campblel   \n",
       "3           0.469086  rec-1899-dup-0    rec-1899-org       thomas   \n",
       "4           0.010256    rec-75-dup-0    rec-75-dup-4       samara   \n",
       "\n",
       "  given_name_r  gamma_given_name  tf_given_name_l  ...  postcode_l  \\\n",
       "0        kexel                 0           0.0044  ...         461   \n",
       "1        cobuy                 3           0.0010  ...        3078   \n",
       "2       joshua                 0           0.0002  ...        3189   \n",
       "3      matthew                 0           0.0094  ...        6117   \n",
       "4      willing                 0           0.0014  ...        3765   \n",
       "\n",
       "   postcode_r  gamma_postcode tf_postcode_l tf_postcode_r  bf_postcode  \\\n",
       "0        4061               0        0.0002        0.0006     0.215951   \n",
       "1        3088               0        0.0010        0.0008     0.215951   \n",
       "2        3198               0        0.0008        0.0008     0.215951   \n",
       "3        6171               0        0.0002        0.0004     0.215951   \n",
       "4        3756               0        0.0012        0.0004     0.215951   \n",
       "\n",
       "   bf_tf_adj_postcode  cluster_l  cluster_r  match_key  \n",
       "0                 1.0   rec-1320   rec-1320          0  \n",
       "1                 1.0    rec-941    rec-941          0  \n",
       "2                 1.0   rec-1727   rec-1727          0  \n",
       "3                 1.0   rec-1899   rec-1899          0  \n",
       "4                 1.0     rec-75     rec-75          0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_errors_df = linker.prediction_errors_from_labels_column(\"cluster\").as_pandas_dataframe()\n",
    "len(pred_errors_df)\n",
    "pred_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-af5cca7a1f5d42a1bafccd8d1374e8fc.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-af5cca7a1f5d42a1bafccd8d1374e8fc.vega-embed details,\n",
       "  #altair-viz-af5cca7a1f5d42a1bafccd8d1374e8fc.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-af5cca7a1f5d42a1bafccd8d1374e8fc\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-af5cca7a1f5d42a1bafccd8d1374e8fc\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-af5cca7a1f5d42a1bafccd8d1374e8fc\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Adjusted match score\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"log2(Bayes factor)\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-38cc51efaf31aa94c2b0b87d08361a57\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 9, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-38cc51efaf31aa94c2b0b87d08361a57\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" amber\", \"value_r\": \" kexel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" kexel\", \"value_r\": \" amber\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n     IS NULL OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     IS NULL OR\\n                      \\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n    =='' OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     ==''\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \" \", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"9952722\", \"value_r\": \"9952722\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"column_name\": \"street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.107916319963705, \"bayes_factor\": 0.23198182427220554, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \" 9\", \"value_r\": \" 49\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"461\", \"value_r\": \"4061\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -8.7124999787346, \"bayes_factor\": 0.0023838348753139386, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"column_name\": \"given_name\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"given_name_l\\\", \\\"given_name_r\\\") <= 1\", \"log2_bayes_factor\": 6.988165071998784, \"bayes_factor\": 126.95426670793958, \"comparison_vector_value\": 3, \"m_probability\": 0.1669513410033733, \"u_probability\": 0.0013150510442271914, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 126.95 times more likely to be a match\", \"value_l\": \" coby\", \"value_r\": \" cobuy\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"Damerau_levenshtein <= 1\", \"sql_condition\": \"damerau_levenshtein(\\\"given_name_l\\\", \\\"given_name_r\\\") <= 1\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 3, \"m_probability\": 0.1669513410033733, \"u_probability\": 0.0013150510442271914, \"bayes_factor_description\": \"If comparison level is `damerau_levenshtein <= 1` then comparison is 126.95 times more likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" fleet\", \"value_r\": \" berry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.965006036701192, \"bayes_factor\": 0.06403453349785591, \"comparison_vector_value\": 0, \"m_probability\": 0.051254494250040666, \"u_probability\": 0.8004195775355626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.62 times less likely to be a match\", \"value_l\": \" 19260518\", \"value_r\": \" 19570701\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"1390881\", \"value_r\": \"1390881\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"column_name\": \"street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.107916319963705, \"bayes_factor\": 0.23198182427220554, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \" 27\", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"3078\", \"value_r\": \"3088\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -3.635845861697161, \"bayes_factor\": 0.08044542232876761, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" campblel\", \"value_r\": \" joshua\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" joshua\", \"value_r\": \" campbell\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.965006036701192, \"bayes_factor\": 0.06403453349785591, \"comparison_vector_value\": 0, \"m_probability\": 0.051254494250040666, \"u_probability\": 0.8004195775355626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.62 times less likely to be a match\", \"value_l\": \" 19801008\", \"value_r\": \" 19670227\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"6114246\", \"value_r\": \"6114246\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"column_name\": \"street_number\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": 5.612670275323986, \"bayes_factor\": 48.930776596328805, \"comparison_vector_value\": 1, \"m_probability\": 0.7716767109813564, \"u_probability\": 0.015770784047585584, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 48.93 times more likely to be a match\", \"value_l\": \" 12\", \"value_r\": \" 12\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"Term freq adjustment on street_number with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": -0.48024913797499197, \"bayes_factor\": 0.7168538203447993, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on street_number makes comparison  1.39 times less likely to be a match\", \"value_l\": \" 12\", \"value_r\": \" 12\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"3189\", \"value_r\": \"3198\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.437168558123093, \"bayes_factor\": 0.02308071043756871, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" thomas\", \"value_r\": \" matthew\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 7.661751222071448, \"bayes_factor\": 202.49622769988594, \"comparison_vector_value\": 4, \"m_probability\": 0.5656235819937037, \"u_probability\": 0.0027932549085901925, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 202.50 times more likely to be a match\", \"value_l\": \" mason\", \"value_r\": \" mason\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.5180527620147841, \"bayes_factor\": 0.34915686357377407, \"comparison_vector_value\": 4, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.86 times less likely to be a match\", \"value_l\": \" mason\", \"value_r\": \" mason\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n     IS NULL OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     IS NULL OR\\n                      \\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n    =='' OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     ==''\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \" \", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"2444851\", \"value_r\": \"2444851\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"column_name\": \"street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.107916319963705, \"bayes_factor\": 0.23198182427220554, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \" 70\", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"6117\", \"value_r\": \"6171\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.17862481631361937, \"bayes_factor\": 0.88354479407004, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" samara\", \"value_r\": \" willing\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" willing\", \"value_r\": \" samara\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.965006036701192, \"bayes_factor\": 0.06403453349785591, \"comparison_vector_value\": 0, \"m_probability\": 0.051254494250040666, \"u_probability\": 0.8004195775355626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.62 times less likely to be a match\", \"value_l\": \" 19600828\", \"value_r\": \" 19270204\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"1045315\", \"value_r\": \"1045315\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"column_name\": \"street_number\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": 5.612670275323986, \"bayes_factor\": 48.930776596328805, \"comparison_vector_value\": 1, \"m_probability\": 0.7716767109813564, \"u_probability\": 0.015770784047585584, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 48.93 times more likely to be a match\", \"value_l\": \" \", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"Term freq adjustment on street_number with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": -1.6355273634529028, \"bayes_factor\": 0.32185273566501194, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on street_number makes comparison  3.11 times less likely to be a match\", \"value_l\": \" \", \"value_r\": \" \", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"3765\", \"value_r\": \"3756\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -6.5924467836010034, \"bayes_factor\": 0.010362767951561469, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"column_name\": \"given_name\", \"label_for_charts\": \"Exact match given_name\", \"sql_condition\": \"\\\"given_name_l\\\" = \\\"given_name_r\\\"\", \"log2_bayes_factor\": 7.130058379414156, \"bayes_factor\": 140.07526186588902, \"comparison_vector_value\": 4, \"m_probability\": 0.5813919597697081, \"u_probability\": 0.004150568430322443, \"bayes_factor_description\": \"If comparison level is `exact match given_name` then comparison is 140.08 times more likely to be a match\", \"value_l\": \" dylan\", \"value_r\": \" dylan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"Term freq adjustment on given_name with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"given_name_l\\\" = \\\"given_name_r\\\"\", \"log2_bayes_factor\": 0.9158054067938026, \"bayes_factor\": 1.8866220137829286, \"comparison_vector_value\": 4, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on given_name makes comparison 1.89 times more likely to be a match\", \"value_l\": \" dylan\", \"value_r\": \" dylan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" campbell\", \"value_r\": \" nguyen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.965006036701192, \"bayes_factor\": 0.06403453349785591, \"comparison_vector_value\": 0, \"m_probability\": 0.051254494250040666, \"u_probability\": 0.8004195775355626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.62 times less likely to be a match\", \"value_l\": \" 19900718\", \"value_r\": \" 19580111\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"4147733\", \"value_r\": \"4147733\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"column_name\": \"street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.107916319963705, \"bayes_factor\": 0.23198182427220554, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \" \", \"value_r\": \" 10\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"2604\", \"value_r\": \"2640\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.5781471474879862, \"bayes_factor\": 0.16745586979336125, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" bkows\", \"value_r\": \" lucy\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" luc y\", \"value_r\": \" cla rke\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n     IS NULL OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     IS NULL OR\\n                      \\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n    =='' OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     ==''\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \" \", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"4309304\", \"value_r\": \"4309304\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"column_name\": \"street_number\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": 5.612670275323986, \"bayes_factor\": 48.930776596328805, \"comparison_vector_value\": 1, \"m_probability\": 0.7716767109813564, \"u_probability\": 0.015770784047585584, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 48.93 times more likely to be a match\", \"value_l\": \" 1\", \"value_r\": \" 1\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"Term freq adjustment on street_number with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": -1.073928855797257, \"bayes_factor\": 0.47502361589113207, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on street_number makes comparison  2.11 times less likely to be a match\", \"value_l\": \" 1\", \"value_r\": \" 1\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"3084\", \"value_r\": \"3085\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.0658422392441658, \"bayes_factor\": 0.23884685091068017, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" benjamin\", \"value_r\": \" noah\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 7.661751222071448, \"bayes_factor\": 202.49622769988594, \"comparison_vector_value\": 4, \"m_probability\": 0.5656235819937037, \"u_probability\": 0.0027932549085901925, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 202.50 times more likely to be a match\", \"value_l\": \" weller\", \"value_r\": \" weller\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -0.4440521805710073, \"bayes_factor\": 0.7350670812079454, \"comparison_vector_value\": 4, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.36 times less likely to be a match\", \"value_l\": \" weller\", \"value_r\": \" weller\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"Within 10 years\", \"sql_condition\": \"\\n            abs(date_diff('year',\\n                strptime(\\\"date_of_birth_l\\\", '%Y%m%d'),\\n                strptime(\\\"date_of_birth_r\\\", '%Y%m%d'))\\n                ) <= 10\\n        \", \"log2_bayes_factor\": -3.838281626142129, \"bayes_factor\": 0.06991366974930942, \"comparison_vector_value\": 1, \"m_probability\": 0.011854554810374894, \"u_probability\": 0.1695598994142628, \"bayes_factor_description\": \"If comparison level is `within 10 years` then comparison is  14.30 times less likely to be a match\", \"value_l\": \" 19540118\", \"value_r\": \" 19440703\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"7771880\", \"value_r\": \"7771880\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"column_name\": \"street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.107916319963705, \"bayes_factor\": 0.23198182427220554, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \" 33\", \"value_r\": \" 67\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"7305\", \"value_r\": \"7307\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -2.9429058610119716, \"bayes_factor\": 0.13004601882386183, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" josha\", \"value_r\": \" campblel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"column_name\": \"surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.390176702364317, \"bayes_factor\": 0.1907590353802845, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \" campbell\", \"value_r\": \" joshua\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.18815108847951015, \"u_probability\": 0.9863285799512704, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.24 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -3.965006036701192, \"bayes_factor\": 0.06403453349785591, \"comparison_vector_value\": 0, \"m_probability\": 0.051254494250040666, \"u_probability\": 0.8004195775355626, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.62 times less likely to be a match\", \"value_l\": \" 19670227\", \"value_r\": \" 19801008\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"6114246\", \"value_r\": \"6114246\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"column_name\": \"street_number\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": 5.612670275323986, \"bayes_factor\": 48.930776596328805, \"comparison_vector_value\": 1, \"m_probability\": 0.7716767109813564, \"u_probability\": 0.015770784047585584, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 48.93 times more likely to be a match\", \"value_l\": \" 12\", \"value_r\": \" 12\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"Term freq adjustment on street_number with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"log2_bayes_factor\": -0.48024913797499197, \"bayes_factor\": 0.7168538203447993, \"comparison_vector_value\": 1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on street_number makes comparison  1.39 times less likely to be a match\", \"value_l\": \" 12\", \"value_r\": \" 12\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"3198\", \"value_r\": \"3189\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -5.437168558123093, \"bayes_factor\": 0.02308071043756871, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"column_name\": \"given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.053495081739847, \"bayes_factor\": 0.24089976949726316, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \" thomas\", \"value_r\": \" matthew\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"column_name\": \"tf_given_name\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.2354886751722387, \"u_probability\": 0.977537984630218, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.15 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"column_name\": \"surname\", \"label_for_charts\": \"Exact match surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": 7.661751222071448, \"bayes_factor\": 202.49622769988594, \"comparison_vector_value\": 4, \"m_probability\": 0.5656235819937037, \"u_probability\": 0.0027932549085901925, \"bayes_factor_description\": \"If comparison level is `exact match surname` then comparison is 202.50 times more likely to be a match\", \"value_l\": \" mason\", \"value_r\": \" mason\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"column_name\": \"tf_surname\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"log2_bayes_factor\": -1.5180527620147841, \"bayes_factor\": 0.34915686357377407, \"comparison_vector_value\": 4, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  2.86 times less likely to be a match\", \"value_l\": \" mason\", \"value_r\": \" mason\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"column_name\": \"date_of_birth\", \"label_for_charts\": \"Null\", \"sql_condition\": \"\\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n     IS NULL OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     IS NULL OR\\n                      \\n        try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d')\\n    =='' OR \\n        try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d')\\n     ==''\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": -1, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": \"If comparison level is `null` then comparison is 1.00 times more likely to be a match\", \"value_l\": \" \", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"column_name\": \"soc_sec_id\", \"label_for_charts\": \"Exact match\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"log2_bayes_factor\": 10.936437996343079, \"bayes_factor\": 1959.7283830283181, \"comparison_vector_value\": 2, \"m_probability\": 0.8609737345716484, \"u_probability\": 0.0004393331963898016, \"bayes_factor_description\": \"If comparison level is `exact match` then comparison is 1,959.73 times more likely to be a match\", \"value_l\": \"2444851\", \"value_r\": \"2444851\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"column_name\": \"street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.107916319963705, \"bayes_factor\": 0.23198182427220554, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \" 70\", \"value_r\": \" \", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"column_name\": \"tf_street_number\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.22832328901864363, \"u_probability\": 0.9842292159524144, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.31 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"column_name\": \"postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": -2.2112260855221457, \"bayes_factor\": 0.21595070244657347, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"6117\", \"value_r\": \"6171\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"column_name\": \"tf_postcode\", \"label_for_charts\": \"All other comparisons\", \"sql_condition\": \"ELSE\", \"log2_bayes_factor\": 0.0, \"bayes_factor\": 1.0, \"comparison_vector_value\": 0, \"m_probability\": 0.21566162232700778, \"u_probability\": 0.9986613605962351, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.63 times less likely to be a match\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -0.17862481631361937, \"bayes_factor\": 0.88354479407004, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.prediction_errors_from_labels_column(\"cluster\").as_record_dict(limit=10)\n",
    "linker.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
