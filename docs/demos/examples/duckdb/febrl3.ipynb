{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicating the febrl3 dataset\n",
    "\n",
    "See A.2 [here](https://arxiv.org/pdf/2008.04443.pdf) and [here](https://recordlinkage.readthedocs.io/en/latest/ref-datasets.html) for the source of this data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/moj-analytical-services/splink/blob/splink4_dev/docs/demos/examples/duckdb/febrl3.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:24.420657Z",
     "iopub.status.busy": "2024-06-07T09:11:24.420336Z",
     "iopub.status.idle": "2024-06-07T09:11:24.443364Z",
     "shell.execute_reply": "2024-06-07T09:11:24.442120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're running in Google Colab.\n",
    "# !pip install git+https://github.com/moj-analytical-services/splink.git@splink4_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:24.447798Z",
     "iopub.status.busy": "2024-06-07T09:11:24.447495Z",
     "iopub.status.idle": "2024-06-07T09:11:26.149918Z",
     "shell.execute_reply": "2024-06-07T09:11:26.149230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: https://raw.githubusercontent.com/moj-analytical-services/splink_datasets/master/data/febrl/dataset3.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  download progress: 0 %\t(..........)\r",
      "  download progress: 2 %\t(..........)\r",
      "  download progress: 3 %\t(..........)\r",
      "  download progress: 5 %\t(..........)\r",
      "  download progress: 6 %\t(..........)\r",
      "  download progress: 8 %\t(..........)\r",
      "  download progress: 10 %\t(..........)\r",
      "  download progress: 11 %\t(=.........)\r",
      "  download progress: 13 %\t(=.........)\r",
      "  download progress: 14 %\t(=.........)\r",
      "  download progress: 16 %\t(=.........)\r",
      "  download progress: 18 %\t(=.........)\r",
      "  download progress: 19 %\t(=.........)\r",
      "  download progress: 21 %\t(==........)\r",
      "  download progress: 22 %\t(==........)\r",
      "  download progress: 24 %\t(==........)\r",
      "  download progress: 25 %\t(==........)\r",
      "  download progress: 27 %\t(==........)\r",
      "  download progress: 29 %\t(==........)\r",
      "  download progress: 30 %\t(===.......)\r",
      "  download progress: 32 %\t(===.......)\r",
      "  download progress: 33 %\t(===.......)\r",
      "  download progress: 35 %\t(===.......)\r",
      "  download progress: 37 %\t(===.......)\r",
      "  download progress: 38 %\t(===.......)\r",
      "  download progress: 40 %\t(===.......)\r",
      "  download progress: 41 %\t(====......)\r",
      "  download progress: 43 %\t(====......)\r",
      "  download progress: 45 %\t(====......)\r",
      "  download progress: 46 %\t(====......)\r",
      "  download progress: 48 %\t(====......)\r",
      "  download progress: 49 %\t(====......)\r",
      "  download progress: 51 %\t(=====.....)\r",
      "  download progress: 53 %\t(=====.....)\r",
      "  download progress: 54 %\t(=====.....)\r",
      "  download progress: 56 %\t(=====.....)\r",
      "  download progress: 57 %\t(=====.....)\r",
      "  download progress: 59 %\t(=====.....)\r",
      "  download progress: 61 %\t(======....)\r",
      "  download progress: 62 %\t(======....)\r",
      "  download progress: 64 %\t(======....)\r",
      "  download progress: 65 %\t(======....)\r",
      "  download progress: 67 %\t(======....)\r",
      "  download progress: 69 %\t(======....)\r",
      "  download progress: 70 %\t(=======...)\r",
      "  download progress: 72 %\t(=======...)\r",
      "  download progress: 73 %\t(=======...)\r",
      "  download progress: 75 %\t(=======...)\r",
      "  download progress: 76 %\t(=======...)\r",
      "  download progress: 78 %\t(=======...)\r",
      "  download progress: 80 %\t(=======...)\r",
      "  download progress: 81 %\t(========..)\r",
      "  download progress: 83 %\t(========..)\r",
      "  download progress: 84 %\t(========..)\r",
      "  download progress: 86 %\t(========..)\r",
      "  download progress: 88 %\t(========..)\r",
      "  download progress: 89 %\t(========..)\r",
      "  download progress: 91 %\t(=========.)\r",
      "  download progress: 92 %\t(=========.)\r",
      "  download progress: 94 %\t(=========.)\r",
      "  download progress: 96 %\t(=========.)\r",
      "  download progress: 97 %\t(=========.)\r",
      "  download progress: 99 %\t(=========.)\r",
      "  download progress: 100 %\t(==========)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec-1496-org</td>\n",
       "      <td>mitchell</td>\n",
       "      <td>green</td>\n",
       "      <td>7</td>\n",
       "      <td>wallaby place</td>\n",
       "      <td>delmar</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>2119</td>\n",
       "      <td>sa</td>\n",
       "      <td>19560409</td>\n",
       "      <td>1804974</td>\n",
       "      <td>rec-1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec-552-dup-3</td>\n",
       "      <td>harley</td>\n",
       "      <td>mccarthy</td>\n",
       "      <td>177</td>\n",
       "      <td>pridhamstreet</td>\n",
       "      <td>milton</td>\n",
       "      <td>marsden</td>\n",
       "      <td>3165</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19080419</td>\n",
       "      <td>6089216</td>\n",
       "      <td>rec-552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rec_id given_name    surname street_number       address_1  \\\n",
       "0   rec-1496-org   mitchell      green             7   wallaby place   \n",
       "1  rec-552-dup-3     harley   mccarthy           177   pridhamstreet   \n",
       "\n",
       "  address_2      suburb  postcode state date_of_birth soc_sec_id   cluster  \n",
       "0    delmar   cleveland      2119    sa      19560409    1804974  rec-1496  \n",
       "1    milton     marsden      3165   nsw      19080419    6089216   rec-552  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "\n",
    "df = splink_datasets.febrl3\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "\n",
    "df[\"cluster\"] = df[\"rec_id\"].apply(lambda x: \"-\".join(x.split(\"-\")[:2]))\n",
    "\n",
    "df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\n",
    "df[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:26.153666Z",
     "iopub.status.busy": "2024-06-07T09:11:26.153378Z",
     "iopub.status.idle": "2024-06-07T09:11:26.160666Z",
     "shell.execute_reply": "2024-06-07T09:11:26.159911Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\n",
    "df[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:26.164000Z",
     "iopub.status.busy": "2024-06-07T09:11:26.163726Z",
     "iopub.status.idle": "2024-06-07T09:11:26.170794Z",
     "shell.execute_reply": "2024-06-07T09:11:26.170146Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"date_of_birth\"] = df[\"date_of_birth\"].astype(str).str.strip()\n",
    "df[\"soc_sec_id\"] = df[\"soc_sec_id\"].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:26.174301Z",
     "iopub.status.busy": "2024-06-07T09:11:26.174024Z",
     "iopub.status.idle": "2024-06-07T09:11:26.331196Z",
     "shell.execute_reply": "2024-06-07T09:11:26.330465Z"
    }
   },
   "outputs": [],
   "source": [
    "from splink import DuckDBAPI, Linker, SettingsCreator\n",
    "\n",
    "# TODO:  Allow missingness to be analysed without a linker\n",
    "settings = SettingsCreator(\n",
    "    unique_id_column_name=\"rec_id\",\n",
    "    link_type=\"dedupe_only\",\n",
    ")\n",
    "\n",
    "linker = Linker(df, settings, database_api=DuckDBAPI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually a good idea to perform exploratory analysis on your data so you understand what's in each column and how often it's missing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:26.334644Z",
     "iopub.status.busy": "2024-06-07T09:11:26.334398Z",
     "iopub.status.idle": "2024-06-07T09:11:26.630134Z",
     "shell.execute_reply": "2024-06-07T09:11:26.629629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-20f1041d514c4b2595dc3e87d49f0cb9.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-20f1041d514c4b2595dc3e87d49f0cb9.vega-embed details,\n",
       "  #altair-viz-20f1041d514c4b2595dc3e87d49f0cb9.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-20f1041d514c4b2595dc3e87d49f0cb9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-20f1041d514c4b2595dc3e87d49f0cb9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-20f1041d514c4b2595dc3e87d49f0cb9\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"completeness\", \"legend\": null, \"scale\": {\"scheme\": \"darkred\", \"zero\": true}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"source_dataset\", \"title\": \"Source dataset\", \"type\": \"nominal\"}, {\"field\": \"total_rows_inc_nulls\", \"format\": \",\", \"title\": \"# of records\", \"type\": \"quantitative\"}, {\"field\": \"column_name\", \"title\": \"Column name\", \"type\": \"nominal\"}, {\"field\": \"total_null_rows\", \"format\": \",\", \"title\": \"# of nulls\", \"type\": \"quantitative\"}, {\"field\": \"completeness\", \"format\": \".1%\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": 20}, \"field\": \"column_name\", \"sort\": {\"field\": \"mean_comp\", \"order\": \"descending\"}, \"title\": \"Column name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"source_dataset\", \"title\": \"Source dataset\", \"type\": \"nominal\"}}, \"title\": \"Column completeness by source dataset\", \"transform\": [{\"joinaggregate\": [{\"op\": \"mean\", \"field\": \"completeness\", \"as\": \"mean_comp\"}], \"groupby\": [\"column_name\"]}]}, {\"mark\": {\"type\": \"text\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"datum['completeness'] < 0.5\", \"value\": \"white\"}, \"value\": \"black\"}, \"text\": {\"field\": \"completeness\", \"format\": \".0%\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"column_name\", \"sort\": {\"field\": \"mean_comp\", \"order\": \"descending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"source_dataset\", \"type\": \"nominal\"}}, \"transform\": [{\"joinaggregate\": [{\"op\": \"mean\", \"field\": \"completeness\", \"as\": \"mean_comp\"}], \"groupby\": [\"column_name\"]}]}], \"data\": {\"name\": \"data-f284bee0b7d37d94cca34fa76f5ff473\"}, \"height\": {\"step\": 40}, \"width\": {\"step\": 40}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-f284bee0b7d37d94cca34fa76f5ff473\": [{\"source_dataset\": \"input_data_1\", \"column_name\": \"rec_id\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"given_name\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"surname\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"street_number\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"address_1\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"address_2\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"suburb\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"postcode\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"state\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"date_of_birth\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"soc_sec_id\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}, {\"source_dataset\": \"input_data_1\", \"column_name\": \"cluster\", \"total_null_rows\": 0, \"total_rows_inc_nulls\": 5000, \"completeness\": 1.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.exploratory import completeness_chart\n",
    "\n",
    "completeness_chart(df, db_api=DuckDBAPI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:26.633200Z",
     "iopub.status.busy": "2024-06-07T09:11:26.632979Z",
     "iopub.status.idle": "2024-06-07T09:11:27.047469Z",
     "shell.execute_reply": "2024-06-07T09:11:27.046951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9223ba00ba0e49cdbd4dd81daf2b9b48.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9223ba00ba0e49cdbd4dd81daf2b9b48.vega-embed details,\n",
       "  #altair-viz-9223ba00ba0e49cdbd4dd81daf2b9b48.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9223ba00ba0e49cdbd4dd81daf2b9b48\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9223ba00ba0e49cdbd4dd81daf2b9b48\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9223ba00ba0e49cdbd4dd81daf2b9b48\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.6094000339508057, \"percentile_inc_nulls\": 0.6094000339508057, \"value_count\": 19, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5914000272750854, \"percentile_inc_nulls\": 0.5914000272750854, \"value_count\": 18, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5845999717712402, \"percentile_inc_nulls\": 0.5845999717712402, \"value_count\": 17, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5717999935150146, \"percentile_inc_nulls\": 0.5717999935150146, \"value_count\": 16, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5478000044822693, \"percentile_inc_nulls\": 0.5478000044822693, \"value_count\": 15, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.522599995136261, \"percentile_inc_nulls\": 0.522599995136261, \"value_count\": 14, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.509600043296814, \"percentile_inc_nulls\": 0.509600043296814, \"value_count\": 13, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.5024000406265259, \"percentile_inc_nulls\": 0.5024000406265259, \"value_count\": 12, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.48919999599456787, \"percentile_inc_nulls\": 0.48919999599456787, \"value_count\": 11, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 66.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.4631999731063843, \"percentile_inc_nulls\": 0.4631999731063843, \"value_count\": 10, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 130.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.4326000213623047, \"percentile_inc_nulls\": 0.4326000213623047, \"value_count\": 9, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 153.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.40380001068115234, \"percentile_inc_nulls\": 0.40380001068115234, \"value_count\": 8, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.3659999966621399, \"percentile_inc_nulls\": 0.3659999966621399, \"value_count\": 7, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.33240002393722534, \"percentile_inc_nulls\": 0.33240002393722534, \"value_count\": 6, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.2784000039100647, \"percentile_inc_nulls\": 0.2784000039100647, \"value_count\": 5, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 270.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.23680001497268677, \"percentile_inc_nulls\": 0.23680001497268677, \"value_count\": 4, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.1905999779701233, \"percentile_inc_nulls\": 0.1905999779701233, \"value_count\": 3, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 231.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.14020001888275146, \"percentile_inc_nulls\": 0.14020001888275146, \"value_count\": 2, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 252.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 701.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9688000082969666, \"percentile_inc_nulls\": 0.9688000082969666, \"value_count\": 156, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9526000022888184, \"percentile_inc_nulls\": 0.9526000022888184, \"value_count\": 81, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9387999773025513, \"percentile_inc_nulls\": 0.9387999773025513, \"value_count\": 69, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9265999794006348, \"percentile_inc_nulls\": 0.9265999794006348, \"value_count\": 61, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 61.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9157999753952026, \"percentile_inc_nulls\": 0.9157999753952026, \"value_count\": 54, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.9056000113487244, \"percentile_inc_nulls\": 0.9056000113487244, \"value_count\": 51, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 51.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.895799994468689, \"percentile_inc_nulls\": 0.895799994468689, \"value_count\": 49, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 49.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8863999843597412, \"percentile_inc_nulls\": 0.8863999843597412, \"value_count\": 47, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8772000074386597, \"percentile_inc_nulls\": 0.8772000074386597, \"value_count\": 46, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8682000041007996, \"percentile_inc_nulls\": 0.8682000041007996, \"value_count\": 45, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8597999811172485, \"percentile_inc_nulls\": 0.8597999811172485, \"value_count\": 42, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.836400032043457, \"percentile_inc_nulls\": 0.836400032043457, \"value_count\": 39, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 117.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8141999840736389, \"percentile_inc_nulls\": 0.8141999840736389, \"value_count\": 37, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.8073999881744385, \"percentile_inc_nulls\": 0.8073999881744385, \"value_count\": 34, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7946000099182129, \"percentile_inc_nulls\": 0.7946000099182129, \"value_count\": 32, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7821999788284302, \"percentile_inc_nulls\": 0.7821999788284302, \"value_count\": 31, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7702000141143799, \"percentile_inc_nulls\": 0.7702000141143799, \"value_count\": 30, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7644000053405762, \"percentile_inc_nulls\": 0.7644000053405762, \"value_count\": 29, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7588000297546387, \"percentile_inc_nulls\": 0.7588000297546387, \"value_count\": 28, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7425999641418457, \"percentile_inc_nulls\": 0.7425999641418457, \"value_count\": 27, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7373999953269958, \"percentile_inc_nulls\": 0.7373999953269958, \"value_count\": 26, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 26.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.727400004863739, \"percentile_inc_nulls\": 0.727400004863739, \"value_count\": 25, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.7081999778747559, \"percentile_inc_nulls\": 0.7081999778747559, \"value_count\": 24, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6759999990463257, \"percentile_inc_nulls\": 0.6759999990463257, \"value_count\": 23, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6540000438690186, \"percentile_inc_nulls\": 0.6540000438690186, \"value_count\": 22, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 110.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6288000345230103, \"percentile_inc_nulls\": 0.6288000345230103, \"value_count\": 21, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 0.6208000183105469, \"percentile_inc_nulls\": 0.6208000183105469, \"value_count\": 20, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 1214}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 19, \"group_name\": \"given_name\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column given_name\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1214 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 156, \"group_name\": \"given_name\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 81, \"group_name\": \"given_name\", \"value\": \" joshua\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 69, \"group_name\": \"given_name\", \"value\": \" emiily\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 61, \"group_name\": \"given_name\", \"value\": \" jack\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 54, \"group_name\": \"given_name\", \"value\": \" benjamin\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 51, \"group_name\": \"given_name\", \"value\": \" isabella\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 49, \"group_name\": \"given_name\", \"value\": \" samuel\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 47, \"group_name\": \"given_name\", \"value\": \" thomas\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 46, \"group_name\": \"given_name\", \"value\": \" sophie\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 45, \"group_name\": \"given_name\", \"value\": \" james\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" katel byn\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" braecon\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" sienna\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" byron\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" hollv\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" brinaa\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" pia\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" any\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" crea\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}, {\"value_count\": 1, \"group_name\": \"given_name\", \"value\": \" colquhoun\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1214}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 156]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9753999710083008, \"percentile_inc_nulls\": 0.9753999710083008, \"value_count\": 123, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9581999778747559, \"percentile_inc_nulls\": 0.9581999778747559, \"value_count\": 86, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9423999786376953, \"percentile_inc_nulls\": 0.9423999786376953, \"value_count\": 79, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 79.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9277999997138977, \"percentile_inc_nulls\": 0.9277999997138977, \"value_count\": 73, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 73.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9139999747276306, \"percentile_inc_nulls\": 0.9139999747276306, \"value_count\": 69, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.9025999903678894, \"percentile_inc_nulls\": 0.9025999903678894, \"value_count\": 57, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8925999999046326, \"percentile_inc_nulls\": 0.8925999999046326, \"value_count\": 50, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8831999897956848, \"percentile_inc_nulls\": 0.8831999897956848, \"value_count\": 47, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8740000128746033, \"percentile_inc_nulls\": 0.8740000128746033, \"value_count\": 46, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.847599983215332, \"percentile_inc_nulls\": 0.847599983215332, \"value_count\": 44, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 132.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8395999670028687, \"percentile_inc_nulls\": 0.8395999670028687, \"value_count\": 40, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8317999839782715, \"percentile_inc_nulls\": 0.8317999839782715, \"value_count\": 39, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 39.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8242000341415405, \"percentile_inc_nulls\": 0.8242000341415405, \"value_count\": 38, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8181999921798706, \"percentile_inc_nulls\": 0.8181999921798706, \"value_count\": 30, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 30.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8123999834060669, \"percentile_inc_nulls\": 0.8123999834060669, \"value_count\": 29, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 29.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.8068000078201294, \"percentile_inc_nulls\": 0.8068000078201294, \"value_count\": 28, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7906000018119812, \"percentile_inc_nulls\": 0.7906000018119812, \"value_count\": 27, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7802000045776367, \"percentile_inc_nulls\": 0.7802000045776367, \"value_count\": 26, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7752000093460083, \"percentile_inc_nulls\": 0.7752000093460083, \"value_count\": 25, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 25.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7703999876976013, \"percentile_inc_nulls\": 0.7703999876976013, \"value_count\": 24, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 24.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7660000324249268, \"percentile_inc_nulls\": 0.7660000324249268, \"value_count\": 22, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 22.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7576000094413757, \"percentile_inc_nulls\": 0.7576000094413757, \"value_count\": 21, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 42.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.75, \"percentile_inc_nulls\": 0.75, \"value_count\": 19, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7427999973297119, \"percentile_inc_nulls\": 0.7427999973297119, \"value_count\": 18, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7394000291824341, \"percentile_inc_nulls\": 0.7394000291824341, \"value_count\": 17, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 17.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7265999913215637, \"percentile_inc_nulls\": 0.7265999913215637, \"value_count\": 16, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7175999879837036, \"percentile_inc_nulls\": 0.7175999879837036, \"value_count\": 15, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7120000123977661, \"percentile_inc_nulls\": 0.7120000123977661, \"value_count\": 14, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.7015999555587769, \"percentile_inc_nulls\": 0.7015999555587769, \"value_count\": 13, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6872000098228455, \"percentile_inc_nulls\": 0.6872000098228455, \"value_count\": 12, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6762000322341919, \"percentile_inc_nulls\": 0.6762000322341919, \"value_count\": 11, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 55.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6582000255584717, \"percentile_inc_nulls\": 0.6582000255584717, \"value_count\": 10, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6402000188827515, \"percentile_inc_nulls\": 0.6402000188827515, \"value_count\": 9, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.6161999702453613, \"percentile_inc_nulls\": 0.6161999702453613, \"value_count\": 8, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.5839999914169312, \"percentile_inc_nulls\": 0.5839999914169312, \"value_count\": 7, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.5371999740600586, \"percentile_inc_nulls\": 0.5371999740600586, \"value_count\": 6, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 234.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.46219998598098755, \"percentile_inc_nulls\": 0.46219998598098755, \"value_count\": 5, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 375.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.3845999836921692, \"percentile_inc_nulls\": 0.3845999836921692, \"value_count\": 4, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 388.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.3011999726295471, \"percentile_inc_nulls\": 0.3011999726295471, \"value_count\": 3, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 417.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.20959997177124023, \"percentile_inc_nulls\": 0.20959997177124023, \"value_count\": 2, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 458.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0, \"value_count\": 1, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 1048.0, \"distinct_value_count\": 1741}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 123, \"group_name\": \"surname\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column surname\", \"subtitle\": \"In this col, 0 values (0.0%) are null and there are 1741 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 123, \"group_name\": \"surname\", \"value\": \" white\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 86, \"group_name\": \"surname\", \"value\": \" clarke\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 79, \"group_name\": \"surname\", \"value\": \" \", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 73, \"group_name\": \"surname\", \"value\": \" campbell\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 69, \"group_name\": \"surname\", \"value\": \" ryan\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 57, \"group_name\": \"surname\", \"value\": \" green\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 50, \"group_name\": \"surname\", \"value\": \" reid\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 47, \"group_name\": \"surname\", \"value\": \" dixon\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 46, \"group_name\": \"surname\", \"value\": \" nguyen\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 44, \"group_name\": \"surname\", \"value\": \" webb\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" tuttleby\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" matthiessen\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" fittock\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" sabieray\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" flockhdart\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" kothe\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" georfe\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" woodmansee\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" vincdnt\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}, {\"value_count\": 1, \"group_name\": \"surname\", \"value\": \" rocheq\", \"total_non_null_rows\": 5000, \"total_rows_inc_nulls\": 5000, \"distinct_value_count\": 1741}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 123]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink.exploratory import profile_columns\n",
    "\n",
    "profile_columns(df, db_api=DuckDBAPI(), column_expressions=[\"given_name\", \"surname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:27.050491Z",
     "iopub.status.busy": "2024-06-07T09:11:27.050266Z",
     "iopub.status.idle": "2024-06-07T09:11:27.428593Z",
     "shell.execute_reply": "2024-06-07T09:11:27.428055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9b8e638ece9642d5bfa73787633a74da.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9b8e638ece9642d5bfa73787633a74da.vega-embed details,\n",
       "  #altair-viz-9b8e638ece9642d5bfa73787633a74da.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9b8e638ece9642d5bfa73787633a74da\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9b8e638ece9642d5bfa73787633a74da\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9b8e638ece9642d5bfa73787633a74da\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4ab5b177c099ba5baa7c18ee8b59ed20\"}, \"mark\": \"bar\", \"encoding\": {\"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"blocking_rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Total comparisons in Cartesian product\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"blocking_rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-4ab5b177c099ba5baa7c18ee8b59ed20\": [{\"blocking_rule\": \"l.\\\"soc_sec_id\\\" = r.\\\"soc_sec_id\\\"\", \"row_count\": 5601, \"cumulative_rows\": 5601, \"cartesian\": 12497500, \"match_key\": \"0\", \"start\": 0}, {\"blocking_rule\": \"l.\\\"given_name\\\" = r.\\\"given_name\\\"\", \"row_count\": 48681, \"cumulative_rows\": 54282, \"cartesian\": 12497500, \"match_key\": \"1\", \"start\": 5601}, {\"blocking_rule\": \"l.\\\"surname\\\" = r.\\\"surname\\\"\", \"row_count\": 36675, \"cumulative_rows\": 90957, \"cartesian\": 12497500, \"match_key\": \"2\", \"start\": 54282}, {\"blocking_rule\": \"l.\\\"date_of_birth\\\" = r.\\\"date_of_birth\\\"\", \"row_count\": 12256, \"cumulative_rows\": 103213, \"cartesian\": 12497500, \"match_key\": \"3\", \"start\": 90957}, {\"blocking_rule\": \"l.\\\"postcode\\\" = r.\\\"postcode\\\"\", \"row_count\": 11037, \"cumulative_rows\": 114250, \"cartesian\": 12497500, \"match_key\": \"4\", \"start\": 103213}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import DuckDBAPI, block_on\n",
    "from splink.blocking_analysis import (\n",
    "    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n",
    ")\n",
    "\n",
    "blocking_rules = [\n",
    "    block_on(\"soc_sec_id\"),\n",
    "    block_on(\"given_name\"),\n",
    "    block_on(\"surname\"),\n",
    "    block_on(\"date_of_birth\"),\n",
    "    block_on(\"postcode\"),\n",
    "]\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "cumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n",
    "    table_or_tables=df,\n",
    "    blocking_rules=blocking_rules,\n",
    "    db_api=db_api,\n",
    "    link_type=\"dedupe_only\",\n",
    "    unique_id_column_name=\"rec_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:27.431702Z",
     "iopub.status.busy": "2024-06-07T09:11:27.431466Z",
     "iopub.status.idle": "2024-06-07T09:11:27.591229Z",
     "shell.execute_reply": "2024-06-07T09:11:27.590491Z"
    }
   },
   "outputs": [],
   "source": [
    "import splink.comparison_library as cl\n",
    "import splink.comparison_template_library as ctl\n",
    "from splink import Linker\n",
    "\n",
    "settings = SettingsCreator(\n",
    "    unique_id_column_name=\"rec_id\",\n",
    "    link_type=\"dedupe_only\",\n",
    "    blocking_rules_to_generate_predictions=blocking_rules,\n",
    "    comparisons=[\n",
    "        ctl.NameComparison(\"given_name\").configure(term_frequency_adjustments=True),\n",
    "        ctl.NameComparison(\"surname\").configure(term_frequency_adjustments=True),\n",
    "        ctl.DateComparison(\n",
    "            \"date_of_birth\",\n",
    "            input_is_string=True,\n",
    "            datetime_format=\"%Y%m%d\",\n",
    "            invalid_dates_as_null=True,\n",
    "            datetime_metrics=[\"month\", \"year\", \"year\"],\n",
    "            datetime_thresholds=[1, 1, 10],\n",
    "        ),\n",
    "        cl.LevenshteinAtThresholds(\"soc_sec_id\", [2]),\n",
    "        cl.ExactMatch(\"street_number\").configure(term_frequency_adjustments=True),\n",
    "        cl.ExactMatch(\"postcode\").configure(term_frequency_adjustments=True),\n",
    "    ],\n",
    "    retain_intermediate_calculation_columns=True,\n",
    ")\n",
    "\n",
    "linker = Linker(df, settings, database_api=DuckDBAPI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:27.594493Z",
     "iopub.status.busy": "2024-06-07T09:11:27.594264Z",
     "iopub.status.idle": "2024-06-07T09:11:27.787352Z",
     "shell.execute_reply": "2024-06-07T09:11:27.786769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000528.\n",
      "This means that amongst all possible pairwise record comparisons, one in 1,893.56 are expected to match.  With 12,497,500 total possible comparisons, we expect a total of around 6,600.00 matching pairs\n"
     ]
    }
   ],
   "source": [
    "from splink import block_on\n",
    "\n",
    "deterministic_rules = [\n",
    "    block_on(\"soc_sec_id\"),\n",
    "    block_on(\"given_name\", \"surname\", \"date_of_birth\"),\n",
    "    \"l.given_name = r.surname and l.surname = r.given_name and l.date_of_birth = r.date_of_birth\",\n",
    "]\n",
    "\n",
    "linker.training.estimate_probability_two_random_records_match(deterministic_rules, recall=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:27.790368Z",
     "iopub.status.busy": "2024-06-07T09:11:27.790145Z",
     "iopub.status.idle": "2024-06-07T09:11:35.433199Z",
     "shell.execute_reply": "2024-06-07T09:11:35.431006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default value for `max_pairs`, which may be too small and thus lead to inaccurate estimates for your model's u-parameters. Consider increasing to 1e8 or 1e9, which will result in more accurate estimates, but with a longer run time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - given_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - date_of_birth (some u values are not trained, no m values are trained).\n",
      "    - soc_sec_id (no m values are trained).\n",
      "    - street_number (no m values are trained).\n",
      "    - postcode (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.training.estimate_u_using_random_sampling(max_pairs=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:35.446472Z",
     "iopub.status.busy": "2024-06-07T09:11:35.440198Z",
     "iopub.status.idle": "2024-06-07T09:11:36.895235Z",
     "shell.execute_reply": "2024-06-07T09:11:36.894603Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"date_of_birth\" = r.\"date_of_birth\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - given_name\n",
      "    - surname\n",
      "    - soc_sec_id\n",
      "    - street_number\n",
      "    - postcode\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - date_of_birth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.376 in the m_probability of surname, level `Exact match on surname`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was 0.0158 in the m_probability of given_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was -0.000688 in the m_probability of postcode, level `Exact match on postcode`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 3.65e-05 in the m_probability of postcode, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 4 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - date_of_birth (some u values are not trained, no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "em_blocking_rule_1 = block_on(\"date_of_birth\")\n",
    "session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n",
    "    em_blocking_rule_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:36.898638Z",
     "iopub.status.busy": "2024-06-07T09:11:36.898156Z",
     "iopub.status.idle": "2024-06-07T09:11:37.517318Z",
     "shell.execute_reply": "2024-06-07T09:11:37.516459Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"postcode\" = r.\"postcode\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - given_name\n",
      "    - surname\n",
      "    - date_of_birth\n",
      "    - soc_sec_id\n",
      "    - street_number\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - postcode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "Level Abs difference of 'transformed date_of_birth <= 1 month' on comparison date_of_birth not observed in dataset, unable to train m value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "Level Abs difference of 'transformed date_of_birth <= 1 year' on comparison date_of_birth not observed in dataset, unable to train m value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:\n",
      "Level Abs difference of 'transformed date_of_birth <= 10 year' on comparison date_of_birth not observed in dataset, unable to train m value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was 0.0627 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was -0.00188 in the m_probability of date_of_birth, level `Exact match on date_of_birth`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 5.26e-05 in the m_probability of soc_sec_id, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 3 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 month' (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 1 year' (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m probability not trained for date_of_birth - Abs difference of 'transformed date_of_birth <= 10 year' (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - date_of_birth (some u values are not trained, some m values are not trained).\n"
     ]
    }
   ],
   "source": [
    "em_blocking_rule_2 = block_on(\"postcode\")\n",
    "session_postcode = linker.training.estimate_parameters_using_expectation_maximisation(\n",
    "    em_blocking_rule_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:37.523135Z",
     "iopub.status.busy": "2024-06-07T09:11:37.522810Z",
     "iopub.status.idle": "2024-06-07T09:11:37.957335Z",
     "shell.execute_reply": "2024-06-07T09:11:37.956712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d6fe4e6aaebc4d1a83bc74499c396f44.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d6fe4e6aaebc4d1a83bc74499c396f44.vega-embed details,\n",
       "  #altair-viz-d6fe4e6aaebc4d1a83bc74499c396f44.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d6fe4e6aaebc4d1a83bc74499c396f44\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d6fe4e6aaebc4d1a83bc74499c396f44\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d6fe4e6aaebc4d1a83bc74499c396f44\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-11, 11]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-11, 11]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-16de5bae4a33b1949fd852105d5c9b4c\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-16de5bae4a33b1949fd852105d5c9b4c\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.0005283846640354178, \"log2_bayes_factor\": -10.886123785487664, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.001 or one in  1,893.6 records.This is equivalent to a starting match weight of -10.886.\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": -1}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"\\\"given_name_l\\\" = \\\"given_name_r\\\"\", \"label_for_charts\": \"Exact match on given_name\", \"m_probability\": 0.5748837504857739, \"u_probability\": 0.003752195898401483, \"m_probability_description\": \"Amongst matching record comparisons, 57.49% of records are in the exact match on given_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.38% of records are in the exact match on given_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"given_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 153.2126163057443, \"log2_bayes_factor\": 7.259391290773299, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on given_name` then comparison is 153.21 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"given_name_l\\\", \\\"given_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of given_name >= 0.9\", \"m_probability\": 0.17034186104733745, \"u_probability\": 0.002942746498694593, \"m_probability_description\": \"Amongst matching record comparisons, 17.03% of records are in the jaro-winkler distance of given_name >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.29% of records are in the jaro-winkler distance of given_name >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 57.88533301217124, \"log2_bayes_factor\": 5.855125939282556, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of given_name >= 0.9` then comparison is 57.89 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"given_name_l\\\", \\\"given_name_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of given_name >= 0.8\", \"m_probability\": 0.009082151318189718, \"u_probability\": 0.01484961128958683, \"m_probability_description\": \"Amongst matching record comparisons, 0.91% of records are in the jaro-winkler distance of given_name >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.48% of records are in the jaro-winkler distance of given_name >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.6116086906974125, \"log2_bayes_factor\": -0.7093191879646772, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of given_name >= 0.8` then comparison is  1.64 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"given_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"m_probability_description\": \"Amongst matching record comparisons, 24.57% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 97.85% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.5619154013925083, \"u_probability\": 0.00307668416914969, \"m_probability_description\": \"Amongst matching record comparisons, 56.19% of records are in the exact match on surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.31% of records are in the exact match on surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 182.63668628288423, \"log2_bayes_factor\": 7.512832778767654, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 182.64 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.9\", \"m_probability\": 0.23310539675110697, \"u_probability\": 0.0015645472809682334, \"m_probability_description\": \"Amongst matching record comparisons, 23.31% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.16% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 148.9922353812457, \"log2_bayes_factor\": 7.219093337449696, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.9` then comparison is 148.99 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.8\", \"m_probability\": 0.005574431415680779, \"u_probability\": 0.008758358972368076, \"m_probability_description\": \"Amongst matching record comparisons, 0.56% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.88% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.6364698493482245, \"log2_bayes_factor\": -0.6518359220428522, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.8` then comparison is  1.57 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"m_probability_description\": \"Amongst matching record comparisons, 19.94% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.66% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 1}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9293969479707318, \"u_probability\": 0.0005337128624799857, \"m_probability_description\": \"Amongst matching record comparisons, 92.94% of records are in the exact match on date_of_birth comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the exact match on date_of_birth comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1741.3800815144946, \"log2_bayes_factor\": 10.766015411183535, \"comparison_vector_value\": 5, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,741.38 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"damerau_levenshtein(\\\"date_of_birth_l\\\", \\\"date_of_birth_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of date_of_birth <= 1\", \"m_probability\": 0.012218867919722957, \"u_probability\": 0.0010122857995965421, \"m_probability_description\": \"Amongst matching record comparisons, 1.22% of records are in the damerau-levenshtein distance of date_of_birth <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.10% of records are in the damerau-levenshtein distance of date_of_birth <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 12.07057129971884, \"log2_bayes_factor\": 3.5934220553022502, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of date_of_birth <= 1` then comparison is 12.07 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"date_of_birth_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"date_of_birth_r\\\", '%Y-%m-%d'))) <= 2629800.0\", \"label_for_charts\": \"Abs difference of 'transformed date_of_birth <= 1 month'\", \"m_probability\": 0.010000000000000009, \"u_probability\": 0.0050000000000000044, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the abs difference of 'transformed date_of_birth <= 1 month' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.50% of records are in the abs difference of 'transformed date_of_birth <= 1 month' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 2.0, \"log2_bayes_factor\": 1.0, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed date_of_birth <= 1 month'` then comparison is 2.00 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"date_of_birth_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"date_of_birth_r\\\", '%Y-%m-%d'))) <= 31557600.0\", \"label_for_charts\": \"Abs difference of 'transformed date_of_birth <= 1 year'\", \"m_probability\": 0.010000000000000009, \"u_probability\": 0.020000000000000018, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the abs difference of 'transformed date_of_birth <= 1 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.00% of records are in the abs difference of 'transformed date_of_birth <= 1 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.5, \"log2_bayes_factor\": -1.0, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed date_of_birth <= 1 year'` then comparison is  2.00 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"date_of_birth_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"date_of_birth_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed date_of_birth <= 10 year'\", \"m_probability\": 0.010000000000000009, \"u_probability\": 0.08000000000000007, \"m_probability_description\": \"Amongst matching record comparisons, 1.00% of records are in the abs difference of 'transformed date_of_birth <= 10 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 8.00% of records are in the abs difference of 'transformed date_of_birth <= 10 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.125, \"log2_bayes_factor\": -3.0, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed date_of_birth <= 10 year'` then comparison is  8.00 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"date_of_birth\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05838418410954519, \"u_probability\": 0.9984540013379235, \"m_probability_description\": \"Amongst matching record comparisons, 5.84% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.85% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.058474585740866045, \"log2_bayes_factor\": -4.096046453833451, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 2}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match on soc_sec_id\", \"m_probability\": 0.8589485966871453, \"u_probability\": 0.00045325284132268303, \"m_probability_description\": \"Amongst matching record comparisons, 85.89% of records are in the exact match on soc_sec_id comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the exact match on soc_sec_id comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1895.0760334575298, \"log2_bayes_factor\": 10.888040017433948, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match on soc_sec_id` then comparison is 1,895.08 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"levenshtein(\\\"soc_sec_id_l\\\", \\\"soc_sec_id_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein distance of soc_sec_id <= 2\", \"m_probability\": 0.07683393545412412, \"u_probability\": 0.00026981646656896335, \"m_probability_description\": \"Amongst matching record comparisons, 7.68% of records are in the levenshtein distance of soc_sec_id <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.03% of records are in the levenshtein distance of soc_sec_id <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 284.7637004188766, \"log2_bayes_factor\": 8.153621443651533, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of soc_sec_id <= 2` then comparison is 284.76 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"soc_sec_id\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"m_probability_description\": \"Amongst matching record comparisons, 6.42% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.93% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 3}, {\"comparison_name\": \"street_number\", \"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Exact match on street_number\", \"m_probability\": 0.7681604748522775, \"u_probability\": 0.015875496200246524, \"m_probability_description\": \"Amongst matching record comparisons, 76.82% of records are in the exact match on street_number comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.59% of records are in the exact match on street_number comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"street_number\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 48.38654900376273, \"log2_bayes_factor\": 5.596534142746451, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on street_number` then comparison is 48.39 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 4}, {\"comparison_name\": \"street_number\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"m_probability_description\": \"Amongst matching record comparisons, 23.18% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 98.41% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 4}, {\"comparison_name\": \"postcode\", \"sql_condition\": \"\\\"postcode_l\\\" = \\\"postcode_r\\\"\", \"label_for_charts\": \"Exact match on postcode\", \"m_probability\": 0.7702508166921226, \"u_probability\": 0.001250084924247571, \"m_probability_description\": \"Amongst matching record comparisons, 77.03% of records are in the exact match on postcode comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.13% of records are in the exact match on postcode comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"postcode\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 616.1587918962692, \"log2_bayes_factor\": 9.267158389330087, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on postcode` then comparison is 616.16 times more likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 5}, {\"comparison_name\": \"postcode\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"m_probability_description\": \"Amongst matching record comparisons, 22.97% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.87% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"probability_two_random_records_match\": 0.0005281056211242248, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.visualisations.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:37.960629Z",
     "iopub.status.busy": "2024-06-07T09:11:37.960358Z",
     "iopub.status.idle": "2024-06-07T09:11:44.496784Z",
     "shell.execute_reply": "2024-06-07T09:11:44.496254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    }
   ],
   "source": [
    "results = linker.inference.predict(threshold_match_probability=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:44.499943Z",
     "iopub.status.busy": "2024-06-07T09:11:44.499693Z",
     "iopub.status.idle": "2024-06-07T09:11:47.310831Z",
     "shell.execute_reply": "2024-06-07T09:11:47.310208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-39962d2d39cc4922babc9cd251a1a02e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-39962d2d39cc4922babc9cd251a1a02e.vega-embed details,\n",
       "  #altair-viz-39962d2d39cc4922babc9cd251a1a02e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-39962d2d39cc4922babc9cd251a1a02e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-39962d2d39cc4922babc9cd251a1a02e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-39962d2d39cc4922babc9cd251a1a02e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-62913e885c8a8cea998badad3d591523\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-62913e885c8a8cea998badad3d591523\": [{\"truth_threshold\": -23.400000348687172, \"match_probability\": 9.034371752972305e-08, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12383243.0, \"fp\": 107719.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9913762446799534, \"fp_rate\": 0.008623755320046606, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.05716411378555799, \"recall\": 0.9989293361884368, \"specificity\": 0.9913762446799534, \"npv\": 0.9999994347202875, \"accuracy\": 0.9913801960392078, \"f1\": 0.10813988144517667, \"f2\": 0.2325821569493312, \"f0_5\": 0.0704472988190828, \"p4\": 0.19509089158934365, \"phi\": 0.23792726011867513}, {\"truth_threshold\": -22.100000329315662, \"match_probability\": 2.2245229983413064e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12394452.0, \"fp\": 96510.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9922736135135148, \"fp_rate\": 0.007726386486485188, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.06338253704835939, \"recall\": 0.9989293361884368, \"specificity\": 0.9922736135135148, \"npv\": 0.9999994352315015, \"accuracy\": 0.9922770954190838, \"f1\": 0.11920167185318355, \"f2\": 0.252761372520183, \"f0_5\": 0.07799102941949167, \"p4\": 0.21292366505302607, \"phi\": 0.2506479560693152}, {\"truth_threshold\": -21.700000323355198, \"match_probability\": 2.9352754975091214e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12394606.0, \"fp\": 96356.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.992285942427813, \"fp_rate\": 0.007714057572186994, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.06347740725261695, \"recall\": 0.9989293361884368, \"specificity\": 0.992285942427813, \"npv\": 0.9999994352385185, \"accuracy\": 0.9922894178835767, \"f1\": 0.11936943111720356, \"f2\": 0.25306302745681536, \"f0_5\": 0.07810593992623527, \"p4\": 0.21319140009766618, \"phi\": 0.2508370309893072}, {\"truth_threshold\": -21.300000317394733, \"match_probability\": 3.873118892024803e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12394730.0, \"fp\": 96232.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9922958696055596, \"fp_rate\": 0.007704130394440396, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.06355400289987641, \"recall\": 0.9989293361884368, \"specificity\": 0.9922958696055596, \"npv\": 0.9999994352441686, \"accuracy\": 0.9922993398679736, \"f1\": 0.11950485356950073, \"f2\": 0.2533064422293759, \"f0_5\": 0.07819871165497258, \"p4\": 0.21340746879908556, \"phi\": 0.2509895810651251}, {\"truth_threshold\": -20.60000030696392, \"match_probability\": 6.29189872645777e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12405730.0, \"fp\": 85232.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9931765063411448, \"fp_rate\": 0.006823493658855099, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.07117247692425052, \"recall\": 0.9989293361884368, \"specificity\": 0.9931765063411448, \"npv\": 0.99999943574493, \"accuracy\": 0.9931795159031807, \"f1\": 0.13287759025849177, \"f2\": 0.2769367764915405, \"f0_5\": 0.08740865654862282, \"p4\": 0.23448970920742496, \"phi\": 0.26572555462939407}, {\"truth_threshold\": -20.300000302493572, \"match_probability\": 7.746234863849234e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12412635.0, \"fp\": 78327.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9937293060374373, \"fp_rate\": 0.006270693962562691, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.07696386905182775, \"recall\": 0.9989293361884368, \"specificity\": 0.9937293060374373, \"npv\": 0.9999994360588181, \"accuracy\": 0.993732026405281, \"f1\": 0.1429165390170248, \"f2\": 0.29416268804612195, \"f0_5\": 0.09438679654305286, \"p4\": 0.24999230612578563, \"phi\": 0.27640240583676073}, {\"truth_threshold\": -20.10000029951334, \"match_probability\": 8.898086238977229e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12415479.0, \"fp\": 75483.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9939569906625286, \"fp_rate\": 0.006043009337471365, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.07963274562879509, \"recall\": 0.9989293361884368, \"specificity\": 0.9939569906625286, \"npv\": 0.9999994361879994, \"accuracy\": 0.9939595919183837, \"f1\": 0.14750654982383232, \"f2\": 0.3018970841114583, \"f0_5\": 0.09759589233518831, \"p4\": 0.25699012721782577, \"phi\": 0.28118624522406016}, {\"truth_threshold\": -20.000000298023224, \"match_probability\": 9.53673209908534e-07, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12420875.0, \"fp\": 70087.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9943889830102758, \"fp_rate\": 0.00561101698972425, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.08524106606802578, \"recall\": 0.9989293361884368, \"specificity\": 0.9943889830102758, \"npv\": 0.9999994364329361, \"accuracy\": 0.9943913582716544, \"f1\": 0.15707826254269083, \"f2\": 0.31774837014693, \"f0_5\": 0.10432574039168077, \"p4\": 0.2714044889000889, \"phi\": 0.2909827360375682}, {\"truth_threshold\": -19.900000296533108, \"match_probability\": 1.0221215694048732e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12423674.0, \"fp\": 67288.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9946130650305397, \"fp_rate\": 0.005386934969460319, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.08847315731722186, \"recall\": 0.9989293361884368, \"specificity\": 0.9946130650305397, \"npv\": 0.9999994365599052, \"accuracy\": 0.994615323064613, \"f1\": 0.16254962231043965, \"f2\": 0.32664472697082153, \"f0_5\": 0.10819577620653781, \"p4\": 0.2795374709424317, \"phi\": 0.29648148907267746}, {\"truth_threshold\": -19.80000029504299, \"match_probability\": 1.095482694339651e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12427835.0, \"fp\": 63127.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9949461858902461, \"fp_rate\": 0.005053814109753916, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.09375807516724569, \"recall\": 0.9989293361884368, \"specificity\": 0.9949461858902461, \"npv\": 0.9999994367485522, \"accuracy\": 0.9949482696539308, \"f1\": 0.1714263215916846, \"f2\": 0.34083081098006474, \"f0_5\": 0.11451064277448539, \"p4\": 0.29257089720737667, \"phi\": 0.3052593915084545}, {\"truth_threshold\": -19.700000293552876, \"match_probability\": 1.174109189357499e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12429684.0, \"fp\": 61278.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9950942129197095, \"fp_rate\": 0.004905787080290533, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.09631464849798699, \"recall\": 0.9989293361884368, \"specificity\": 0.9950942129197095, \"npv\": 0.9999994368323396, \"accuracy\": 0.9950962192438487, \"f1\": 0.17568967140570568, \"f2\": 0.34753780823958874, \"f0_5\": 0.11755959881054383, \"p4\": 0.2987607626972144, \"phi\": 0.30941633591191675}, {\"truth_threshold\": -19.60000029206276, \"match_probability\": 1.2583789665296601e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12430885.0, \"fp\": 60077.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9951903624396584, \"fp_rate\": 0.004809637560341629, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.09805128513091521, \"recall\": 0.9989293361884368, \"specificity\": 0.9951903624396584, \"npv\": 0.9999994368867495, \"accuracy\": 0.9951923184636927, \"f1\": 0.17857435813304898, \"f2\": 0.3520375161707633, \"f0_5\": 0.11962853060775909, \"p4\": 0.3029235980553316, \"phi\": 0.31220851081043266}, {\"truth_threshold\": -19.500000290572643, \"match_probability\": 1.3486970617214505e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12432902.0, \"fp\": 58060.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9953518391938107, \"fp_rate\": 0.004648160806189307, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.10111315817993219, \"recall\": 0.9989293361884368, \"specificity\": 0.9953518391938107, \"npv\": 0.9999994369781038, \"accuracy\": 0.9953537107421484, \"f1\": 0.18363817852071587, \"f2\": 0.35986246873037037, \"f0_5\": 0.12327200247638749, \"p4\": 0.31018206989903857, \"phi\": 0.31707152183644843}, {\"truth_threshold\": -19.400000289082527, \"match_probability\": 1.4454975813216156e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12436868.0, \"fp\": 54094.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9956693487659317, \"fp_rate\": 0.004330651234068281, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.10772783505154639, \"recall\": 0.9989293361884368, \"specificity\": 0.9956693487659317, \"npv\": 0.9999994371576462, \"accuracy\": 0.9956710542108421, \"f1\": 0.1944820809076426, \"f2\": 0.3763093907371769, \"f0_5\": 0.1311245673351055, \"p4\": 0.32551887754211073, \"phi\": 0.32733072460889484}, {\"truth_threshold\": -19.30000028759241, \"match_probability\": 1.549245788689352e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12437644.0, \"fp\": 53318.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.995731473684733, \"fp_rate\": 0.00426852631526699, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.10912463031963776, \"recall\": 0.9989293361884368, \"specificity\": 0.995731473684733, \"npv\": 0.9999994371927625, \"accuracy\": 0.9957331466293259, \"f1\": 0.196755388856252, \"f2\": 0.37970488715247497, \"f0_5\": 0.13277952621435019, \"p4\": 0.32869886501685464, \"phi\": 0.3294562692809753}, {\"truth_threshold\": -19.200000286102295, \"match_probability\": 1.66044034034615e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12440686.0, \"fp\": 50276.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9959750097710649, \"fp_rate\": 0.0040249902289351295, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.11496822574682698, \"recall\": 0.9989293361884368, \"specificity\": 0.9959750097710649, \"npv\": 0.9999994373303802, \"accuracy\": 0.9959765553110622, \"f1\": 0.2062041202936301, \"f2\": 0.3936281777745633, \"f0_5\": 0.13969097302430636, \"p4\": 0.3417877653561756, \"phi\": 0.3382038255849883}, {\"truth_threshold\": -19.10000028461218, \"match_probability\": 1.7796156826591604e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12444256.0, \"fp\": 46706.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9962608164207049, \"fp_rate\": 0.0037391835792951736, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.1226778368427973, \"recall\": 0.9989293361884368, \"specificity\": 0.9962608164207049, \"npv\": 0.9999994374917984, \"accuracy\": 0.9962622124424885, \"f1\": 0.21851944792973652, \"f2\": 0.4113290254317349, \"f0_5\": 0.1487794210109073, \"p4\": 0.3585431851622418, \"phi\": 0.3494098100607936}, {\"truth_threshold\": -19.000000283122063, \"match_probability\": 1.907344620533969e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12447111.0, \"fp\": 43851.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9964893816825318, \"fp_rate\": 0.0035106183174682623, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.12962962962962962, \"recall\": 0.9989293361884368, \"specificity\": 0.9964893816825318, \"npv\": 0.9999994376208211, \"accuracy\": 0.9964906581316263, \"f1\": 0.22947997189037245, \"f2\": 0.42667311260354873, \"f0_5\": 0.15694539232743457, \"p4\": 0.37317327921722127, \"phi\": 0.3592146989214852}, {\"truth_threshold\": -18.900000281631947, \"match_probability\": 2.0442410704611823e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12449081.0, \"fp\": 41881.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9966470957160866, \"fp_rate\": 0.003352904283913441, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.13490456911509544, \"recall\": 0.9989293361884368, \"specificity\": 0.9966470957160866, \"npv\": 0.9999994377098146, \"accuracy\": 0.9966482896579316, \"f1\": 0.23770700636942677, \"f2\": 0.4379459256477657, \"f0_5\": 0.16312329533533815, \"p4\": 0.3839846185548206, \"phi\": 0.3664795352599752}, {\"truth_threshold\": -18.80000028014183, \"match_probability\": 2.1909630111470102e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12451068.0, \"fp\": 39894.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9968061707336873, \"fp_rate\": 0.003193829266312715, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.14067851373182552, \"recall\": 0.9989293361884368, \"specificity\": 0.9968061707336873, \"npv\": 0.9999994377995475, \"accuracy\": 0.9968072814562913, \"f1\": 0.2466250023601382, \"f2\": 0.44993593011560135, \"f0_5\": 0.16986756000374537, \"p4\": 0.3955429234744392, \"phi\": 0.3742699979705262}, {\"truth_threshold\": -18.700000278651714, \"match_probability\": 2.348215645907411e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12451815.0, \"fp\": 39147.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.996865973973822, \"fp_rate\": 0.0031340260261779676, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.14297911467227112, \"recall\": 0.9989293361884368, \"specificity\": 0.996865973973822, \"npv\": 0.9999994378332745, \"accuracy\": 0.9968670534106822, \"f1\": 0.25015320974413974, \"f2\": 0.4546150633440067, \"f0_5\": 0.17254953764861294, \"p4\": 0.40007022304153966, \"phi\": 0.3773292621024914}, {\"truth_threshold\": -18.600000277161598, \"match_probability\": 2.516754792022793e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12452901.0, \"fp\": 38061.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9969529168369898, \"fp_rate\": 0.003047083163010183, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.14646124865446716, \"recall\": 0.9989293361884368, \"specificity\": 0.9969529168369898, \"npv\": 0.9999994378823003, \"accuracy\": 0.996953950790158, \"f1\": 0.25546645804811263, \"f2\": 0.46159391609182404, \"f0_5\": 0.1766032470552605, \"p4\": 0.40684006480685353, \"phi\": 0.3819130771365216}, {\"truth_threshold\": -18.500000275671482, \"match_probability\": 2.6973905133407355e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12454763.0, \"fp\": 36199.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9971019846189589, \"fp_rate\": 0.002898015381041108, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.152843435525392, \"recall\": 0.9989293361884368, \"specificity\": 0.9971019846189589, \"npv\": 0.9999994379663374, \"accuracy\": 0.9971029405881177, \"f1\": 0.265121376958675, \"f2\": 0.47407160070845794, \"f0_5\": 0.18401537265155699, \"p4\": 0.4189963916912101, \"phi\": 0.39017469056816706}, {\"truth_threshold\": -18.400000274181366, \"match_probability\": 2.8909910135828424e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12456946.0, \"fp\": 34016.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9972767509820301, \"fp_rate\": 0.002723249017969953, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.16107233580782795, \"recall\": 0.9989293361884368, \"specificity\": 0.9972767509820301, \"npv\": 0.9999994380648302, \"accuracy\": 0.9972776155231046, \"f1\": 0.2774131889136668, \"f2\": 0.48958755003823146, \"f0_5\": 0.19353863660609508, \"p4\": 0.4342071044426514, \"phi\": 0.4005754380928603}, {\"truth_threshold\": -18.30000027269125, \"match_probability\": 3.098486809064348e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12460316.0, \"fp\": 30646.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9975465460546593, \"fp_rate\": 0.002453453945340639, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.17567313123705516, \"recall\": 0.9989293361884368, \"specificity\": 0.9975465460546593, \"npv\": 0.9999994382168103, \"accuracy\": 0.9975472694538908, \"f1\": 0.2987990392313851, \"f2\": 0.5156405438266829, \"f0_5\": 0.21034358373162593, \"p4\": 0.4599857266076457, \"phi\": 0.4183939275759773}, {\"truth_threshold\": -18.200000271201134, \"match_probability\": 3.3208752008774106e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12461777.0, \"fp\": 29185.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9976635106247221, \"fp_rate\": 0.002336489375277901, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.18285922275730765, \"recall\": 0.9989293361884368, \"specificity\": 0.9976635106247221, \"npv\": 0.9999994382826729, \"accuracy\": 0.9976641728345669, \"f1\": 0.3091304965210394, \"f2\": 0.5278172884205081, \"f0_5\": 0.21857137119985007, \"p4\": 0.47213783994931696, \"phi\": 0.42689065762824635}, {\"truth_threshold\": -18.100000269711018, \"match_probability\": 3.5592250680276667e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12462284.0, \"fp\": 28678.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.997704099972444, \"fp_rate\": 0.002295900027555924, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.18549234570706352, \"recall\": 0.9989293361884368, \"specificity\": 0.997704099972444, \"npv\": 0.9999994383055251, \"accuracy\": 0.9977047409481896, \"f1\": 0.31288475818621697, \"f2\": 0.532178419517283, \"f0_5\": 0.2215791116479162, \"p4\": 0.4765063552428884, \"phi\": 0.4299619914365433}, {\"truth_threshold\": -18.0000002682209, \"match_probability\": 3.8146820045553597e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12463767.0, \"fp\": 27195.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.997822825815978, \"fp_rate\": 0.002177174184022015, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.19364881693648817, \"recall\": 0.9989293361884368, \"specificity\": 0.997822825815978, \"npv\": 0.9999994383723582, \"accuracy\": 0.9978234046809362, \"f1\": 0.32440890125173855, \"f2\": 0.5453588964227262, \"f0_5\": 0.23087201821241216, \"p4\": 0.48976144900453544, \"phi\": 0.4393396375783495}, {\"truth_threshold\": -17.900000266730785, \"match_probability\": 4.088473825324779e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12464191.0, \"fp\": 26771.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9978567703592406, \"fp_rate\": 0.0021432296407594546, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.19611434748663745, \"recall\": 0.9989293361884368, \"specificity\": 0.9978567703592406, \"npv\": 0.9999994383914633, \"accuracy\": 0.9978573314662933, \"f1\": 0.32786144578313253, \"f2\": 0.5492481582399839, \"f0_5\": 0.23367395131166546, \"p4\": 0.49368781869980055, \"phi\": 0.44213515701169576}, {\"truth_threshold\": -17.80000026524067, \"match_probability\": 4.381916466936514e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12465858.0, \"fp\": 25104.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9979902268536243, \"fp_rate\": 0.0020097731463757556, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.20644855381697486, \"recall\": 0.9989293361884368, \"specificity\": 0.9979902268536243, \"npv\": 0.9999994384665645, \"accuracy\": 0.9979907181436287, \"f1\": 0.3421790270610117, \"f2\": 0.5650924948517833, \"f0_5\": 0.24538240730999863, \"p4\": 0.50975492730441, \"phi\": 0.4536651212714251}, {\"truth_threshold\": -17.700000263750553, \"match_probability\": 4.696420312114957e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12466872.0, \"fp\": 24090.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9980714055490681, \"fp_rate\": 0.0019285944509318017, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2132850004898599, \"recall\": 0.9989293361884368, \"specificity\": 0.9980714055490681, \"npv\": 0.9999994385122372, \"accuracy\": 0.9980718543708742, \"f1\": 0.3515164563093732, \"f2\": 0.5751853874200764, \"f0_5\": 0.25309637116150735, \"p4\": 0.520050079977352, \"phi\": 0.4611341929266993}, {\"truth_threshold\": -17.600000262260437, \"match_probability\": 5.03349696795731e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12467798.0, \"fp\": 23164.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9981455391506274, \"fp_rate\": 0.0018544608493725303, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.21993601616433742, \"recall\": 0.9989293361884368, \"specificity\": 0.9981455391506274, \"npv\": 0.9999994385539396, \"accuracy\": 0.998145949189838, \"f1\": 0.3605000965970248, \"f2\": 0.5847225455261698, \"f0_5\": 0.2605770918782617, \"p4\": 0.5298218725258823, \"phi\": 0.46828636121060196}, {\"truth_threshold\": -17.50000026077032, \"match_probability\": 5.394766530610173e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12468611.0, \"fp\": 22351.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9982106262111757, \"fp_rate\": 0.0017893737888242714, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.22612699951526902, \"recall\": 0.9989293361884368, \"specificity\": 0.9982106262111757, \"npv\": 0.9999994385905479, \"accuracy\": 0.9982110022004401, \"f1\": 0.36877470355731223, \"f2\": 0.5933604680742813, \"f0_5\": 0.26751921091868336, \"p4\": 0.5387090295397927, \"phi\": 0.4748470364131934}, {\"truth_threshold\": -17.400000259280205, \"match_probability\": 5.781965371275756e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12469200.0, \"fp\": 21762.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9982577803054721, \"fp_rate\": 0.0017422196945279314, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2308344820273566, \"recall\": 0.9989293361884368, \"specificity\": 0.9982577803054721, \"npv\": 0.9999994386170669, \"accuracy\": 0.9982581316263253, \"f1\": 0.3750107662714249, \"f2\": 0.5997795940857746, \"f0_5\": 0.2727842285523348, \"p4\": 0.5453361054578323, \"phi\": 0.47977558474394716}, {\"truth_threshold\": -17.30000025779009, \"match_probability\": 6.196954480953251e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12470221.0, \"fp\": 20741.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9983395194061114, \"fp_rate\": 0.0016604805938886052, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.23947638603696098, \"recall\": 0.9989293361884368, \"specificity\": 0.9983395194061114, \"npv\": 0.9999994386630301, \"accuracy\": 0.9983398279655932, \"f1\": 0.38633540372670805, \"f2\": 0.6112421383647799, \"f0_5\": 0.28241917907737013, \"p4\": 0.5572184906889626, \"phi\": 0.4886939549872913}, {\"truth_threshold\": -17.200000256299973, \"match_probability\": 6.6417284140038195e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12471206.0, \"fp\": 19756.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9984183764228888, \"fp_rate\": 0.0015816235771111944, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.24844980408566972, \"recall\": 0.9989293361884368, \"specificity\": 0.9984183764228888, \"npv\": 0.9999994387073655, \"accuracy\": 0.9984186437287458, \"f1\": 0.3979284082254379, \"f2\": 0.6227235454528118, \"f0_5\": 0.29238221442257756, \"p4\": 0.5691831929381347, \"phi\": 0.4977853794554934}, {\"truth_threshold\": -17.100000254809856, \"match_probability\": 7.118424873502875e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12472519.0, \"fp\": 18443.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9985234924259637, \"fp_rate\": 0.0014765075740363312, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2615119724513494, \"recall\": 0.9989293361884368, \"specificity\": 0.9985234924259637, \"npv\": 0.9999994387664536, \"accuracy\": 0.9985237047409482, \"f1\": 0.4145087585681645, \"f2\": 0.6387161131322615, \"f0_5\": 0.30680985399402444, \"p4\": 0.5859545720714509, \"phi\": 0.5107301604900001}, {\"truth_threshold\": -17.00000025331974, \"match_probability\": 7.629334984424643e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12473504.0, \"fp\": 17458.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9986023494427411, \"fp_rate\": 0.0013976505572589205, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.2722497811496936, \"recall\": 0.9989293361884368, \"specificity\": 0.9986023494427411, \"npv\": 0.9999994388107727, \"accuracy\": 0.9986025205041008, \"f1\": 0.4278835129557441, \"f2\": 0.6512634371073572, \"f0_5\": 0.31860401584482995, \"p4\": 0.599199812323053, \"phi\": 0.5211307161345772}, {\"truth_threshold\": -16.900000251829624, \"match_probability\": 8.176914304005986e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12474680.0, \"fp\": 16282.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9986964975155637, \"fp_rate\": 0.001303502484436347, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.28628413623810983, \"recall\": 0.9989293361884368, \"specificity\": 0.9986964975155637, \"npv\": 0.9999994388636765, \"accuracy\": 0.9986966193238648, \"f1\": 0.44502742666348677, \"f2\": 0.6669049320943531, \"f0_5\": 0.3339298496778812, \"p4\": 0.615819402597042, \"phi\": 0.5344192083810998}, {\"truth_threshold\": -16.800000250339508, \"match_probability\": 8.76379462217525e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12475856.0, \"fp\": 15106.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9987906455883863, \"fp_rate\": 0.0012093544116137732, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3018440634098997, \"recall\": 0.9989293361884368, \"specificity\": 0.9987906455883863, \"npv\": 0.9999994389165704, \"accuracy\": 0.9987907181436287, \"f1\": 0.4636024844720497, \"f2\": 0.6833162443240076, \"f0_5\": 0.35080463227553016, \"p4\": 0.6333872236913614, \"phi\": 0.5487761780914129}, {\"truth_threshold\": -16.700000248849392, \"match_probability\": 9.392796608724036e-06, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12476236.0, \"fp\": 14726.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9988210675847065, \"fp_rate\": 0.0011789324152935538, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3072399680105377, \"recall\": 0.9989293361884368, \"specificity\": 0.9988210675847065, \"npv\": 0.9999994389336597, \"accuracy\": 0.9988211242248449, \"f1\": 0.4699406368051808, \"f2\": 0.6887932671011833, \"f0_5\": 0.3566280060284385, \"p4\": 0.6392801635279745, \"phi\": 0.5536679892621517}, {\"truth_threshold\": -16.600000247359276, \"match_probability\": 1.0066943367963594e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12477133.0, \"fp\": 13829.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9988928795075992, \"fp_rate\": 0.0011071204924008255, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.32077603143418465, \"recall\": 0.9989293361884368, \"specificity\": 0.9988928795075992, \"npv\": 0.9999994389739957, \"accuracy\": 0.998892898579716, \"f1\": 0.4856123131831363, \"f2\": 0.7020768833849329, \"f0_5\": 0.37117233853918025, \"p4\": 0.6536352900122829, \"phi\": 0.5657533832188976}, {\"truth_threshold\": -16.50000024586916, \"match_probability\": 1.0789474965962542e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12478144.0, \"fp\": 12818.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.998973818029388, \"fp_rate\": 0.0010261819706120314, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3375368236084552, \"recall\": 0.9989293361884368, \"specificity\": 0.998973818029388, \"npv\": 0.9999994390194509, \"accuracy\": 0.9989737947589518, \"f1\": 0.5045775872059335, \"f2\": 0.7176765345816576, \"f0_5\": 0.38905568661090856, \"p4\": 0.670607679716645, \"phi\": 0.5803692799755028}, {\"truth_threshold\": -16.400000244379044, \"match_probability\": 1.1563864000129272e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12478675.0, \"fp\": 12287.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9990163287663513, \"fp_rate\": 0.0009836712336487774, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.34706132426400255, \"recall\": 0.9989293361884368, \"specificity\": 0.9990163287663513, \"npv\": 0.999999439043322, \"accuracy\": 0.9990162832566514, \"f1\": 0.5151443445338382, \"f2\": 0.7261507671781188, \"f0_5\": 0.39915658232489915, \"p4\": 0.6798798848848036, \"phi\": 0.5885131979985193}, {\"truth_threshold\": -16.300000242888927, \"match_probability\": 1.239383228590334e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12479366.0, \"fp\": 11596.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9990716487649229, \"fp_rate\": 0.00092835123507701, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.3602912782037844, \"recall\": 0.9989293361884368, \"specificity\": 0.9990716487649229, \"npv\": 0.9999994390743829, \"accuracy\": 0.9990715743148629, \"f1\": 0.5295763227245084, \"f2\": 0.7374827796472369, \"f0_5\": 0.41311388305543606, \"p4\": 0.6923369438700686, \"phi\": 0.5996419687723363}, {\"truth_threshold\": -16.20000024139881, \"match_probability\": 1.328336874067903e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12479875.0, \"fp\": 11087.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.999112398228415, \"fp_rate\": 0.0008876017715849267, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.37070042002497444, \"recall\": 0.9989293361884368, \"specificity\": 0.999112398228415, \"npv\": 0.9999994390972607, \"accuracy\": 0.9991123024604921, \"f1\": 0.5407352210630899, \"f2\": 0.7460589444825223, \"f0_5\": 0.4240358395013635, \"p4\": 0.7018089494184524, \"phi\": 0.6082548235291179}, {\"truth_threshold\": -16.100000239908695, \"match_probability\": 1.4236748550826774e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12480637.0, \"fp\": 10325.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9991734023368256, \"fp_rate\": 0.0008265976631743816, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.38745847176079734, \"recall\": 0.9989293361884368, \"specificity\": 0.9991734023368256, \"npv\": 0.9999994391315064, \"accuracy\": 0.999173274654931, \"f1\": 0.5583482944344704, \"f2\": 0.75927734375, \"f0_5\": 0.44151050539466213, \"p4\": 0.7164836030336961, \"phi\": 0.6218704060532914}, {\"truth_threshold\": -16.00000023841858, \"match_probability\": 1.5258553713831415e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12480664.0, \"fp\": 10298.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9991755638997221, \"fp_rate\": 0.0008244361002779449, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.38808009982767844, \"recall\": 0.9989293361884368, \"specificity\": 0.9991755638997221, \"npv\": 0.9999994391327197, \"accuracy\": 0.9991754350870174, \"f1\": 0.558993452304532, \"f2\": 0.7597543100439729, \"f0_5\": 0.4421561459094971, \"p4\": 0.7170148370518836, \"phi\": 0.622369736941255}, {\"truth_threshold\": -15.900000236928463, \"match_probability\": 1.6353695054159956e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12481825.0, \"fp\": 9137.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9992685111042688, \"fp_rate\": 0.0007314888957311694, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.41683686494766403, \"recall\": 0.9989293361884368, \"specificity\": 0.9992685111042688, \"npv\": 0.9999994391848889, \"accuracy\": 0.9992683336667334, \"f1\": 0.5882194001621184, \"f2\": 0.7808464849354376, \"f0_5\": 0.4718248807975726, \"p4\": 0.740627664078436, \"phi\": 0.645046588595399}, {\"truth_threshold\": -15.800000235438347, \"match_probability\": 1.7527435818536736e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12482001.0, \"fp\": 8961.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9992826012920382, \"fp_rate\": 0.0007173987079618047, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4215724244771495, \"recall\": 0.9989293361884368, \"specificity\": 0.9992826012920382, \"npv\": 0.9999994391927965, \"accuracy\": 0.9992824164832966, \"f1\": 0.5929187471629596, \"f2\": 0.784146575737201, \"f0_5\": 0.47667357603713545, \"p4\": 0.7443436473749858, \"phi\": 0.6487049150586356}, {\"truth_threshold\": -15.70000023394823, \"match_probability\": 1.8785416963874395e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12482009.0, \"fp\": 8953.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9992832417551186, \"fp_rate\": 0.000716758244881379, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4217902350813743, \"recall\": 0.9989293361884368, \"specificity\": 0.9992832417551186, \"npv\": 0.9999994391931559, \"accuracy\": 0.9992830566113222, \"f1\": 0.593134138588684, \"f2\": 0.7842972427706792, \"f0_5\": 0.4768963402167246, \"p4\": 0.7445134418999542, \"phi\": 0.6488726825098676}, {\"truth_threshold\": -15.600000232458115, \"match_probability\": 2.0133684259220603e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12482912.0, \"fp\": 8050.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9993555340253216, \"fp_rate\": 0.0006444659746783314, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.44791166586653863, \"recall\": 0.9989293361884368, \"specificity\": 0.9993555340253216, \"npv\": 0.9999994392337241, \"accuracy\": 0.9993553110622124, \"f1\": 0.6184951939012264, \"f2\": 0.8016841381680702, \"f0_5\": 0.5034534858622922, \"p4\": 0.7641900074808001, \"phi\": 0.6686874302858675}, {\"truth_threshold\": -15.500000230967999, \"match_probability\": 2.1578717331772276e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12483150.0, \"fp\": 7812.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9993745878019643, \"fp_rate\": 0.0006254121980356677, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.45534407027818447, \"recall\": 0.9989293361884368, \"specificity\": 0.9993745878019643, \"npv\": 0.9999994392444155, \"accuracy\": 0.9993743548709741, \"f1\": 0.6255447536037546, \"f2\": 0.8063958513396715, \"f0_5\": 0.5109529025191676, \"p4\": 0.7695504797471294, \"phi\": 0.6742189646694701}, {\"truth_threshold\": -15.400000229477882, \"match_probability\": 2.312746079632102e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12483548.0, \"fp\": 7414.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9994064508402155, \"fp_rate\": 0.0005935491597844906, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.46833990677662246, \"recall\": 0.9989293361884368, \"specificity\": 0.9994064508402155, \"npv\": 0.9999994392622935, \"accuracy\": 0.999406201240248, \"f1\": 0.6376995557291413, \"f2\": 0.8144000798064693, \"f0_5\": 0.5240059051959306, \"p4\": 0.7786846566768775, \"phi\": 0.6837835400360596}, {\"truth_threshold\": -15.300000227987766, \"match_probability\": 2.478735761747151e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12484326.0, \"fp\": 6636.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9994687358747869, \"fp_rate\": 0.0005312641252130941, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.4960127591706539, \"recall\": 0.9989293361884368, \"specificity\": 0.9994687358747869, \"npv\": 0.9999994392972376, \"accuracy\": 0.9994684536907381, \"f1\": 0.6628774422735346, \"f2\": 0.8305145095246573, \"f0_5\": 0.5515488295105225, \"p4\": 0.7971809943780036, \"phi\": 0.7037170046760161}, {\"truth_threshold\": -15.20000022649765, \"match_probability\": 2.6566384864664307e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6531.0, \"tn\": 12484474.0, \"fp\": 6488.0, \"fn\": 7.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9989293361884368, \"tn_rate\": 0.9994805844417748, \"fp_rate\": 0.0005194155582252192, \"fn_rate\": 0.0010706638115631692, \"precision\": 0.5016514325216991, \"recall\": 0.9989293361884368, \"specificity\": 0.9994805844417748, \"npv\": 0.9999994393038846, \"accuracy\": 0.9994802960592118, \"f1\": 0.6678938487498083, \"f2\": 0.8336524469633146, \"f0_5\": 0.5571194595147917, \"p4\": 0.8007995064598789, \"phi\": 0.7077098325750868}, {\"truth_threshold\": -15.100000225007534, \"match_probability\": 2.8473092031487608e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12484737.0, \"fp\": 6225.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995016396655437, \"fp_rate\": 0.0004983603344562252, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5119560956487652, \"recall\": 0.9987763842153564, \"specificity\": 0.9995016396655437, \"npv\": 0.9999993592179897, \"accuracy\": 0.9995012602520504, \"f1\": 0.6769294562794796, \"f2\": 0.8391806101729766, \"f0_5\": 0.567253900413496, \"p4\": 0.8072626415829411, \"phi\": 0.7148943137271629}, {\"truth_threshold\": -15.000000223517418, \"match_probability\": 3.0516642103032495e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12484997.0, \"fp\": 5965.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995224547156576, \"fp_rate\": 0.0004775452843423909, \"fn_rate\": 0.001223615784643622, \"precision\": 0.522609043617447, \"recall\": 0.9987763842153564, \"specificity\": 0.9995224547156576, \"npv\": 0.9999993592313339, \"accuracy\": 0.9995220644128826, \"f1\": 0.6861766405716387, \"f2\": 0.8448262478329496, \"f0_5\": 0.5776920627056867, \"p4\": 0.8138054290773129, \"phi\": 0.7223014341530339}, {\"truth_threshold\": -14.900000222027302, \"match_probability\": 3.270685556819147e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12485449.0, \"fp\": 5513.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995586408797017, \"fp_rate\": 0.0004413591202983405, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5422236984140164, \"recall\": 0.9987763842153564, \"specificity\": 0.9995586408797017, \"npv\": 0.9999993592545311, \"accuracy\": 0.9995582316463293, \"f1\": 0.7028685216080943, \"f2\": 0.8548239298337479, \"f0_5\": 0.5967830378358618, \"p4\": 0.825435875216624, \"phi\": 0.7357447042858334}, {\"truth_threshold\": -14.800000220537186, \"match_probability\": 3.505425758788192e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12485742.0, \"fp\": 5220.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9995820978400223, \"fp_rate\": 0.00041790215997775034, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5557446808510639, \"recall\": 0.9987763842153564, \"specificity\": 0.9995820978400223, \"npv\": 0.9999993592695673, \"accuracy\": 0.9995816763352671, \"f1\": 0.7141294838145232, \"f2\": 0.8614321144002955, \"f0_5\": 0.6098472113265344, \"p4\": 0.8331543309874082, \"phi\": 0.7448703083800272}, {\"truth_threshold\": -14.70000021904707, \"match_probability\": 3.757012854526189e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12485974.0, \"fp\": 4988.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996006712693546, \"fp_rate\": 0.00039932873064540584, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5669387046362215, \"recall\": 0.9987763842153564, \"specificity\": 0.9996006712693546, \"npv\": 0.9999993592814727, \"accuracy\": 0.9996002400480096, \"f1\": 0.7233052724856004, \"f2\": 0.8667374568622246, \"f0_5\": 0.6206044478236077, \"p4\": 0.8393690339745324, \"phi\": 0.7523416477215324}, {\"truth_threshold\": -14.600000217556953, \"match_probability\": 4.026655822016454e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486065.0, \"fp\": 4897.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996079565368944, \"fp_rate\": 0.00039204346310556384, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5714535748665441, \"recall\": 0.9987763842153564, \"specificity\": 0.9996079565368944, \"npv\": 0.9999993592861423, \"accuracy\": 0.9996075215043009, \"f1\": 0.7269691065961592, \"f2\": 0.8688363181564172, \"f0_5\": 0.6249282241702714, \"p4\": 0.841832087207952, \"phi\": 0.7553341386002418}, {\"truth_threshold\": -14.500000216066837, \"match_probability\": 4.315650384728788e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486308.0, \"fp\": 4654.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996274106029623, \"fp_rate\": 0.0003725893970376341, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5838698140200286, \"recall\": 0.9987763842153564, \"specificity\": 0.9996274106029623, \"npv\": 0.9999993592986114, \"accuracy\": 0.9996269653930786, \"f1\": 0.736937140277621, \"f2\": 0.8744911077780159, \"f0_5\": 0.6367749736708663, \"p4\": 0.8484806484258035, \"phi\": 0.7635032405424124}, {\"truth_threshold\": -14.400000214576721, \"match_probability\": 4.625385233621647e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486466.0, \"fp\": 4496.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996400597488008, \"fp_rate\": 0.0003599402511992271, \"fn_rate\": 0.001223615784643622, \"precision\": 0.5922365318338473, \"recall\": 0.9987763842153564, \"specificity\": 0.9996400597488008, \"npv\": 0.9999993593067186, \"accuracy\": 0.9996396079215843, \"f1\": 0.743566385789114, \"f2\": 0.8782075420947872, \"f0_5\": 0.6447217724418467, \"p4\": 0.8528602122205615, \"phi\": 0.7689590707056568}, {\"truth_threshold\": -14.300000213086605, \"match_probability\": 4.957348695121048e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486689.0, \"fp\": 4273.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996579126571676, \"fp_rate\": 0.0003420873428323615, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6044617235952976, \"recall\": 0.9987763842153564, \"specificity\": 0.9996579126571676, \"npv\": 0.9999993593181608, \"accuracy\": 0.999657451490298, \"f1\": 0.7531284239663226, \"f2\": 0.8835069679339738, \"f0_5\": 0.6562814070351759, \"p4\": 0.8591189968396024, \"phi\": 0.7768620703223341}, {\"truth_threshold\": -14.200000211596489, \"match_probability\": 5.313135876996633e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12486978.0, \"fp\": 3984.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.999681049385948, \"fp_rate\": 0.00031895061405198415, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6210766596918394, \"recall\": 0.9987763842153564, \"specificity\": 0.999681049385948, \"npv\": 0.9999993593329888, \"accuracy\": 0.9996805761152231, \"f1\": 0.7658925639221206, \"f2\": 0.8904707358315606, \"f0_5\": 0.6718936494217393, \"p4\": 0.8673681351660593, \"phi\": 0.7874756936101868}, {\"truth_threshold\": -14.100000210106373, \"match_probability\": 5.694456326333118e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487062.0, \"fp\": 3900.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996877742482925, \"fp_rate\": 0.0003122257517075146, \"fn_rate\": 0.001223615784643622, \"precision\": 0.62607861936721, \"recall\": 0.9987763842153564, \"specificity\": 0.9996877742482925, \"npv\": 0.9999993593372986, \"accuracy\": 0.9996872974594919, \"f1\": 0.7696841112682696, \"f2\": 0.8925154447542507, \"f0_5\": 0.676571760122674, \"p4\": 0.8697956053792526, \"phi\": 0.7906430434398442}, {\"truth_threshold\": -14.000000208616257, \"match_probability\": 6.103142236234761e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487102.0, \"fp\": 3860.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9996909765636947, \"fp_rate\": 0.00030902343630538626, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6284889316650626, \"recall\": 0.9987763842153564, \"specificity\": 0.9996909765636947, \"npv\": 0.9999993593393507, \"accuracy\": 0.99969049809962, \"f1\": 0.7715028355387523, \"f2\": 0.8934924196814624, \"f0_5\": 0.6788224042579734, \"p4\": 0.8709563255375713, \"phi\": 0.7921647841198904}, {\"truth_threshold\": -13.90000020712614, \"match_probability\": 6.541157240512605e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487340.0, \"fp\": 3622.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997100303403372, \"fp_rate\": 0.00028996965966272256, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6432230102442869, \"recall\": 0.9987763842153564, \"specificity\": 0.9997100303403372, \"npv\": 0.9999993593515613, \"accuracy\": 0.9997095419083817, \"f1\": 0.7825044937088077, \"f2\": 0.8993499338915822, \"f0_5\": 0.6925295889364952, \"p4\": 0.8779271760779108, \"phi\": 0.8014042660104671}, {\"truth_threshold\": -13.800000205636024, \"match_probability\": 7.010605838401368e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487372.0, \"fp\": 3590.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.999712592192659, \"fp_rate\": 0.0002874078073410199, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6452569169960475, \"recall\": 0.9987763842153564, \"specificity\": 0.999712592192659, \"npv\": 0.9999993593532029, \"accuracy\": 0.9997121024204841, \"f1\": 0.7840076839956778, \"f2\": 0.9001433612704014, \"f0_5\": 0.6944149049300268, \"p4\": 0.8788729525569766, \"phi\": 0.8026713392745567}, {\"truth_threshold\": -13.700000204145908, \"match_probability\": 7.51374349434771e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487524.0, \"fp\": 3438.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997247609911871, \"fp_rate\": 0.0002752390088129321, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6550963081861958, \"recall\": 0.9987763842153564, \"specificity\": 0.9997247609911871, \"npv\": 0.999999359361001, \"accuracy\": 0.9997242648529706, \"f1\": 0.7912274324488064, \"f2\": 0.9039313399778516, \"f0_5\": 0.7035121741004094, \"p4\": 0.8833933617987549, \"phi\": 0.8087730054012197}, {\"truth_threshold\": -13.600000202655792, \"match_probability\": 8.052987461117984e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487674.0, \"fp\": 3288.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997367696739451, \"fp_rate\": 0.00026323032605495077, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6651049093501732, \"recall\": 0.9987763842153564, \"specificity\": 0.9997367696739451, \"npv\": 0.9999993593686963, \"accuracy\": 0.9997362672534507, \"f1\": 0.7984837368549768, \"f2\": 0.9077008618293022, \"f0_5\": 0.7127264789347304, \"p4\": 0.8879001114215276, \"phi\": 0.8149327340484709}, {\"truth_threshold\": -13.500000201165676, \"match_probability\": 8.630928377906233e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487785.0, \"fp\": 3177.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.999745656099186, \"fp_rate\": 0.0002543439008140446, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6727104151643144, \"recall\": 0.9987763842153564, \"specificity\": 0.999745656099186, \"npv\": 0.9999993593743907, \"accuracy\": 0.9997451490298059, \"f1\": 0.8039396737457679, \"f2\": 0.9105106110042109, \"f0_5\": 0.7197019794559802, \"p4\": 0.8912648225163031, \"phi\": 0.8195825380106165}, {\"truth_threshold\": -13.40000019967556, \"match_probability\": 9.25034269879762e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487821.0, \"fp\": 3141.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997485381830479, \"fp_rate\": 0.00025146181695212907, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6752145589907972, \"recall\": 0.9987763842153564, \"specificity\": 0.9997485381830479, \"npv\": 0.9999993593762374, \"accuracy\": 0.9997480296059211, \"f1\": 0.8057252143870689, \"f2\": 0.9114256204114675, \"f0_5\": 0.7219937198708594, \"p4\": 0.8923615634292106, \"phi\": 0.8211077428935656}, {\"truth_threshold\": -13.300000198185444, \"match_probability\": 9.914206010875549e-05, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12487920.0, \"fp\": 3042.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997564639136681, \"fp_rate\": 0.0002435360863318614, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6821980777267029, \"recall\": 0.9987763842153564, \"specificity\": 0.9997564639136681, \"npv\": 0.9999993593813161, \"accuracy\": 0.9997559511902381, \"f1\": 0.8106765983860956, \"f2\": 0.9139514052177807, \"f0_5\": 0.7283719270066479, \"p4\": 0.8953915658096223, \"phi\": 0.8253463211657222}, {\"truth_threshold\": -13.200000196695328, \"match_probability\": 0.00010625707305470121, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488022.0, \"fp\": 2940.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997646298179436, \"fp_rate\": 0.00023537018205643407, \"fn_rate\": 0.001223615784643622, \"precision\": 0.689545934530095, \"recall\": 0.9987763842153564, \"specificity\": 0.9997646298179436, \"npv\": 0.9999993593865486, \"accuracy\": 0.9997641128225645, \"f1\": 0.8158420789605197, \"f2\": 0.91656841277862, \"f0_5\": 0.7350623621054527, \"p4\": 0.8985349833919181, \"phi\": 0.8297826564886827}, {\"truth_threshold\": -13.100000195205212, \"match_probability\": 0.00011388264270550263, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488126.0, \"fp\": 2836.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997729558379891, \"fp_rate\": 0.00022704416201090036, \"fn_rate\": 0.001223615784643622, \"precision\": 0.6972026478752936, \"recall\": 0.9987763842153564, \"specificity\": 0.9997729558379891, \"npv\": 0.9999993593918836, \"accuracy\": 0.9997724344868973, \"f1\": 0.8211770623742455, \"f2\": 0.9192522101469678, \"f0_5\": 0.7420117267396936, \"p4\": 0.901762842564067, \"phi\": 0.834380371437696}, {\"truth_threshold\": -13.000000193715096, \"match_probability\": 0.00012205539677081966, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488209.0, \"fp\": 2753.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997796006424485, \"fp_rate\": 0.00022039935755148403, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7034363890983518, \"recall\": 0.9987763842153564, \"specificity\": 0.9997796006424485, \"npv\": 0.9999993593961412, \"accuracy\": 0.999779075815163, \"f1\": 0.8254851147209405, \"f2\": 0.9214053901509807, \"f0_5\": 0.7476528509274101, \"p4\": 0.9043556100678978, \"phi\": 0.8381049914074641}, {\"truth_threshold\": -12.90000019222498, \"match_probability\": 0.00013081458937332365, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488281.0, \"fp\": 2681.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997853648101723, \"fp_rate\": 0.000214635189827653, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7089349690587341, \"recall\": 0.9987763842153564, \"specificity\": 0.9997853648101723, \"npv\": 0.9999993593998345, \"accuracy\": 0.9997848369673935, \"f1\": 0.8292590005714648, \"f2\": 0.9232813958091791, \"f0_5\": 0.752616292471532, \"p4\": 0.9066168645119308, \"phi\": 0.8413766712773935}, {\"truth_threshold\": -12.800000190734863, \"match_probability\": 0.00014020228918616167, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488443.0, \"fp\": 2519.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9997983341875509, \"fp_rate\": 0.00020166581244903314, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7216266990827715, \"recall\": 0.9987763842153564, \"specificity\": 0.9997983341875509, \"npv\": 0.9999993594081443, \"accuracy\": 0.999797799559912, \"f1\": 0.8378777186116636, \"f2\": 0.927530467884435, \"f0_5\": 0.7640286422988721, \"p4\": 0.911746266120254, \"phi\": 0.8488801671318317}, {\"truth_threshold\": -12.700000189244747, \"match_probability\": 0.00015026358101882152, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488532.0, \"fp\": 2430.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9998054593393207, \"fp_rate\": 0.00019454066067929756, \"fn_rate\": 0.001223615784643622, \"precision\": 0.7287946428571429, \"recall\": 0.9987763842153564, \"specificity\": 0.9998054593393207, \"npv\": 0.9999993594127096, \"accuracy\": 0.9998049209841968, \"f1\": 0.8426893792747451, \"f2\": 0.9298815219867852, \"f0_5\": 0.7704469300108547, \"p4\": 0.9145890503360998, \"phi\": 0.8530887751917855}, {\"truth_threshold\": -12.600000187754631, \"match_probability\": 0.0001610467818084837, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6530.0, \"tn\": 12488608.0, \"fp\": 2354.0, \"fn\": 8.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9987763842153564, \"tn_rate\": 0.9998115437385847, \"fp_rate\": 0.0001884562614152537, \"fn_rate\": 0.001223615784643622, \"precision\": 0.735029266096353, \"recall\": 0.9987763842153564, \"specificity\": 0.9998115437385847, \"npv\": 0.9999993594166079, \"accuracy\": 0.9998110022004401, \"f1\": 0.8468421735183504, \"f2\": 0.931898618563763, \"f0_5\": 0.7760136901649475, \"p4\": 0.9170306662319075, \"phi\": 0.8567325791271283}, {\"truth_threshold\": -12.500000186264515, \"match_probability\": 0.00017260367204143044, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12488960.0, \"fp\": 2002.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998397241141235, \"fp_rate\": 0.00016027588587652416, \"fn_rate\": 0.002906087488528602, \"precision\": 0.7650510503462035, \"recall\": 0.9970939125114714, \"specificity\": 0.9998397241141235, \"npv\": 0.9999984786586638, \"accuracy\": 0.9998382876575315, \"f1\": 0.8657945414702172, \"f2\": 0.9400686413059153, \"f0_5\": 0.802397715523608, \"p4\": 0.9280357686991302, \"phi\": 0.8733290383065944}, {\"truth_threshold\": -12.400000184774399, \"match_probability\": 0.00018498974370122882, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489080.0, \"fp\": 1882.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998493310603299, \"fp_rate\": 0.0001506689396701391, \"fn_rate\": 0.002906087488528602, \"precision\": 0.7759790501130818, \"recall\": 0.9970939125114714, \"specificity\": 0.9998493310603299, \"npv\": 0.9999984786732814, \"accuracy\": 0.9998478895779156, \"f1\": 0.8727491799986612, \"f2\": 0.9433334298034903, \"f0_5\": 0.8119924268845599, \"p4\": 0.932018271447631, \"phi\": 0.8795484946761649}, {\"truth_threshold\": -12.300000183284283, \"match_probability\": 0.00019826446591752426, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489164.0, \"fp\": 1798.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998560559226743, \"fp_rate\": 0.00014394407732566957, \"fn_rate\": 0.002906087488528602, \"precision\": 0.7838162799086209, \"recall\": 0.9970939125114714, \"specificity\": 0.9998560559226743, \"npv\": 0.9999984786835135, \"accuracy\": 0.9998546109221844, \"f1\": 0.8776842813867385, \"f2\": 0.945632307290609, \"f0_5\": 0.8188464050645631, \"p4\": 0.9348264219759939, \"phi\": 0.8839819561714175}, {\"truth_threshold\": -12.200000181794167, \"match_probability\": 0.00021249156957169895, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489338.0, \"fp\": 1624.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998699859946736, \"fp_rate\": 0.0001300140053264112, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8005649023701339, \"recall\": 0.9970939125114714, \"specificity\": 0.9998699859946736, \"npv\": 0.9999984787047084, \"accuracy\": 0.9998685337067413, \"f1\": 0.8880866425992779, \"f2\": 0.950430091850124, \"f0_5\": 0.8334185630273587, \"p4\": 0.9406974735140679, \"phi\": 0.8933827787671057}, {\"truth_threshold\": -12.10000018030405, \"match_probability\": 0.0002277393522037113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489390.0, \"fp\": 1572.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998741490046964, \"fp_rate\": 0.00012585099530364435, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8057100482017056, \"recall\": 0.9970939125114714, \"specificity\": 0.9998741490046964, \"npv\": 0.9999984787110423, \"accuracy\": 0.9998726945389078, \"f1\": 0.8912434206029121, \"f2\": 0.9518733755804106, \"f0_5\": 0.837874659400545, \"p4\": 0.9424663799907229, \"phi\": 0.8962508958005283}, {\"truth_threshold\": -12.000000178813934, \"match_probability\": 0.00024408100465850272, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489462.0, \"fp\": 1500.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998799131724202, \"fp_rate\": 0.00012008682757981331, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8129442573887018, \"recall\": 0.9970939125114714, \"specificity\": 0.9998799131724202, \"npv\": 0.9999984787198123, \"accuracy\": 0.9998784556911382, \"f1\": 0.8956515765611046, \"f2\": 0.9538790202218256, \"f0_5\": 0.8441238928885896, \"p4\": 0.9449266464221592, \"phi\": 0.9002680876716866}, {\"truth_threshold\": -11.900000177323818, \"match_probability\": 0.0002615949610108224, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6519.0, \"tn\": 12489502.0, \"fp\": 1460.0, \"fn\": 19.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9970939125114714, \"tn_rate\": 0.9998831154878223, \"fp_rate\": 0.00011688451217768495, \"fn_rate\": 0.002906087488528602, \"precision\": 0.8170196766512094, \"recall\": 0.9970939125114714, \"specificity\": 0.9998831154878223, \"npv\": 0.9999984787246845, \"accuracy\": 0.9998816563312662, \"f1\": 0.8981194461665634, \"f2\": 0.9549969236178254, \"f0_5\": 0.8476361366827898, \"p4\": 0.9462990193966214, \"phi\": 0.9025233140302381}, {\"truth_threshold\": -11.800000175833702, \"match_probability\": 0.0002803652734145845, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489597.0, \"fp\": 1365.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9998907209869023, \"fp_rate\": 0.00010927901309763011, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8268425726246353, \"recall\": 0.996940960538391, \"specificity\": 0.9998907209869023, \"npv\": 0.9999983986698712, \"accuracy\": 0.9998891778355671, \"f1\": 0.9039595035018376, \"f2\": 0.957543705009549, \"f0_5\": 0.8560546361964801, \"p4\": 0.949532493781873, \"phi\": 0.9078663314439575}, {\"truth_threshold\": -11.700000174343586, \"match_probability\": 0.0003004820136373637, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489634.0, \"fp\": 1328.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9998936831286493, \"fp_rate\": 0.00010631687135066139, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8307417792505736, \"recall\": 0.996940960538391, \"specificity\": 0.9998936831286493, \"npv\": 0.999998398674615, \"accuracy\": 0.9998921384276855, \"f1\": 0.9062847608453838, \"f2\": 0.9585857991646567, \"f0_5\": 0.8593956014978112, \"p4\": 0.9508144098028801, \"phi\": 0.9100058182462071}, {\"truth_threshold\": -11.60000017285347, \"match_probability\": 0.0003220417031628006, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489672.0, \"fp\": 1290.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9998967253282813, \"fp_rate\": 0.00010327467171863944, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8347848360655737, \"recall\": 0.996940960538391, \"specificity\": 0.9998967253282813, \"npv\": 0.999998398679487, \"accuracy\": 0.9998951790358072, \"f1\": 0.9086853478321484, \"f2\": 0.959658421672556, \"f0_5\": 0.8628541170240932, \"p4\": 0.952134580088913, \"phi\": 0.9122189363982538}, {\"truth_threshold\": -11.500000171363354, \"match_probability\": 0.00034514777387400505, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489725.0, \"fp\": 1237.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999009683961891, \"fp_rate\": 9.903160381081937e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8404900064474533, \"recall\": 0.996940960538391, \"specificity\": 0.9999009683961891, \"npv\": 0.9999983986862823, \"accuracy\": 0.9998994198839768, \"f1\": 0.912054852025467, \"f2\": 0.9611584628542779, \"f0_5\": 0.8677245859736941, \"p4\": 0.9539820043912938, \"phi\": 0.9153327717396891}, {\"truth_threshold\": -11.400000169873238, \"match_probability\": 0.0003699110614699968, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489776.0, \"fp\": 1186.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999050513483269, \"fp_rate\": 9.494865167310572e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8460539979231568, \"recall\": 0.996940960538391, \"specificity\": 0.9999050513483269, \"npv\": 0.9999983986928209, \"accuracy\": 0.99990350070014, \"f1\": 0.9153208818986097, \"f2\": 0.9626063327032136, \"f0_5\": 0.8724634577287573, \"p4\": 0.9557664956333963, \"phi\": 0.9183593835823952}, {\"truth_threshold\": -11.300000168383121, \"match_probability\": 0.00039645033391533577, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489830.0, \"fp\": 1132.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999093744741198, \"fp_rate\": 9.062552588023245e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8520261437908496, \"recall\": 0.996940960538391, \"specificity\": 0.9999093744741198, \"npv\": 0.9999983986997442, \"accuracy\": 0.9999078215643129, \"f1\": 0.9188046236255991, \"f2\": 0.9641441334832258, \"f0_5\": 0.8775378318703215, \"p4\": 0.9576632480289803, \"phi\": 0.9215969567118968}, {\"truth_threshold\": -11.200000166893005, \"match_probability\": 0.00042489285738089063, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489917.0, \"fp\": 1045.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999163395101194, \"fp_rate\": 8.366048988060327e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8618273172021684, \"recall\": 0.996940960538391, \"specificity\": 0.9999163395101194, \"npv\": 0.9999983987108982, \"accuracy\": 0.9999147829565913, \"f1\": 0.9244734415998865, \"f2\": 0.9666320628800237, \"f0_5\": 0.8858385430823593, \"p4\": 0.9607350127447367, \"phi\": 0.9268857838361068}, {\"truth_threshold\": -11.10000016540289, \"match_probability\": 0.00045537500230174836, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12489983.0, \"fp\": 979.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999216233305329, \"fp_rate\": 7.837666946709149e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8694144324396426, \"recall\": 0.996940960538391, \"specificity\": 0.9999216233305329, \"npv\": 0.9999983987193598, \"accuracy\": 0.9999200640128025, \"f1\": 0.9288208051300321, \"f2\": 0.9685280394662545, \"f0_5\": 0.892241143295187, \"p4\": 0.9630784940410264, \"phi\": 0.9309592479362132}, {\"truth_threshold\": -11.000000163912773, \"match_probability\": 0.00048804289235713973, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490026.0, \"fp\": 936.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999250658195902, \"fp_rate\": 7.493418040980351e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8744298363294876, \"recall\": 0.996940960538391, \"specificity\": 0.9999250658195902, \"npv\": 0.9999983987248726, \"accuracy\": 0.9999235047009402, \"f1\": 0.9316752429959977, \"f2\": 0.9697673034577159, \"f0_5\": 0.8964625625790834, \"p4\": 0.9646114681231893, \"phi\": 0.9336422227030345}, {\"truth_threshold\": -10.900000162422657, \"match_probability\": 0.0005230530993675534, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490051.0, \"fp\": 911.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999270672667165, \"fp_rate\": 7.293273328347329e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8773724592811953, \"recall\": 0.996940960538391, \"specificity\": 0.9999270672667165, \"npv\": 0.9999983987280777, \"accuracy\": 0.9999255051010202, \"f1\": 0.9333428796448772, \"f2\": 0.9704892647628123, \"f0_5\": 0.8989352898990456, \"p4\": 0.9655049776683732, \"phi\": 0.9352127869513862}, {\"truth_threshold\": -10.800000160932541, \"match_probability\": 0.0005605733873065377, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490087.0, \"fp\": 875.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999299493505784, \"fp_rate\": 7.005064942155776e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8816447991343163, \"recall\": 0.996940960538391, \"specificity\": 0.9999299493505784, \"npv\": 0.999998398732693, \"accuracy\": 0.9999283856771354, \"f1\": 0.9357547914722562, \"f2\": 0.9715307795498584, \"f0_5\": 0.9025200775408474, \"p4\": 0.9667945433202542, \"phi\": 0.9374883769173387}, {\"truth_threshold\": -10.700000159442425, \"match_probability\": 0.0006007835088396779, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490141.0, \"fp\": 821.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999342724763713, \"fp_rate\": 6.572752362868448e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8881318980787574, \"recall\": 0.996940960538391, \"specificity\": 0.9999342724763713, \"npv\": 0.9999983987396159, \"accuracy\": 0.9999327065413083, \"f1\": 0.9393961230813577, \"f2\": 0.9730972500074647, \"f0_5\": 0.907951189613863, \"p4\": 0.9687353637329369, \"phi\": 0.9409330988908223}, {\"truth_threshold\": -10.600000157952309, \"match_probability\": 0.0006438760580315065, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490168.0, \"fp\": 794.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999364340392678, \"fp_rate\": 6.356596073224784e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8914113785557987, \"recall\": 0.996940960538391, \"specificity\": 0.9999364340392678, \"npv\": 0.9999983987430774, \"accuracy\": 0.9999348669733947, \"f1\": 0.9412274368231047, \"f2\": 0.9738823810662204, \"f0_5\": 0.9106913318057341, \"p4\": 0.96970869899015, \"phi\": 0.9426697493262179}, {\"truth_threshold\": -10.500000156462193, \"match_probability\": 0.0006900573831033208, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490218.0, \"fp\": 744.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999404369335204, \"fp_rate\": 5.95630664795874e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.8975488846047921, \"recall\": 0.996940960538391, \"specificity\": 0.9999404369335204, \"npv\": 0.9999983987494874, \"accuracy\": 0.9999388677735547, \"f1\": 0.9446376811594203, \"f2\": 0.9753396779792901, \"f0_5\": 0.9158095880402406, \"p4\": 0.9715163461040757, \"phi\": 0.9459113014058622}, {\"truth_threshold\": -10.400000154972076, \"match_probability\": 0.0007395485633816526, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490248.0, \"fp\": 714.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.999942838670072, \"fp_rate\": 5.7161329927991134e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9012721238938053, \"recall\": 0.996940960538391, \"specificity\": 0.999942838670072, \"npv\": 0.9999983987533334, \"accuracy\": 0.9999412682536507, \"f1\": 0.9466957153231663, \"f2\": 0.9762161514497963, \"f0_5\": 0.9189082501550782, \"p4\": 0.9726041728640255, \"phi\": 0.9478723451663081}, {\"truth_threshold\": -10.30000015348196, \"match_probability\": 0.0007925864548491303, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490297.0, \"fp\": 665.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999467615064396, \"fp_rate\": 5.32384935603839e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9074202979256578, \"recall\": 0.996940960538391, \"specificity\": 0.9999467615064396, \"npv\": 0.9999983987596152, \"accuracy\": 0.9999451890378076, \"f1\": 0.9500765250346185, \"f2\": 0.9776511174441278, \"f0_5\": 0.9240147434079955, \"p4\": 0.9743862051847613, \"phi\": 0.9511017597920165}, {\"truth_threshold\": -10.200000151991844, \"match_probability\": 0.0008494248089972806, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490322.0, \"fp\": 640.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999487629535659, \"fp_rate\": 5.1237046434053675e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9105895501536743, \"recall\": 0.996940960538391, \"specificity\": 0.9999487629535659, \"npv\": 0.9999983987628202, \"accuracy\": 0.9999471894378876, \"f1\": 0.9518107476635514, \"f2\": 0.978384869408586, \"f0_5\": 0.9266420244526585, \"p4\": 0.9752979234907653, \"phi\": 0.952762178410999}, {\"truth_threshold\": -10.100000150501728, \"match_probability\": 0.0009103354699850551, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490356.0, \"fp\": 606.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999514849216578, \"fp_rate\": 4.8515078342244576e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9149354295339697, \"recall\": 0.996940960538391, \"specificity\": 0.9999514849216578, \"npv\": 0.9999983987671788, \"accuracy\": 0.9999499099819964, \"f1\": 0.9541794759186063, \"f2\": 0.9793845414112273, \"f0_5\": 0.9302391962093965, \"p4\": 0.9765406019210419, \"phi\": 0.9550343562036164}, {\"truth_threshold\": -10.000000149011612, \"match_probability\": 0.0009756096554280922, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490375.0, \"fp\": 587.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999530060214737, \"fp_rate\": 4.699397852623361e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9173821252638986, \"recall\": 0.996940960538391, \"specificity\": 0.9999530060214737, \"npv\": 0.9999983987696146, \"accuracy\": 0.9999514302860573, \"f1\": 0.9555083192846148, \"f2\": 0.9799440719247076, \"f0_5\": 0.9322615710280908, \"p4\": 0.9772364201267669, \"phi\": 0.9563111990605025}, {\"truth_threshold\": -9.900000147521496, \"match_probability\": 0.0010455593264824352, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490415.0, \"fp\": 547.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999562083368759, \"fp_rate\": 4.379166312410525e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9225760792639773, \"recall\": 0.996940960538391, \"specificity\": 0.9999562083368759, \"npv\": 0.9999983987747424, \"accuracy\": 0.9999546309261852, \"f1\": 0.9583180180842461, \"f2\": 0.9811241231899329, \"f0_5\": 0.936548077475717, \"p4\": 0.9787045466273886, \"phi\": 0.9590161026976435}, {\"truth_threshold\": -9.80000014603138, \"match_probability\": 0.0011205186532430977, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490453.0, \"fp\": 509.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999592505365079, \"fp_rate\": 4.0749463492083315e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9275651060196385, \"recall\": 0.996940960538391, \"specificity\": 0.9999592505365079, \"npv\": 0.9999983987796138, \"accuracy\": 0.9999576715343068, \"f1\": 0.961002580169554, \"f2\": 0.9822478073480213, \"f0_5\": 0.94065693009294, \"p4\": 0.9801033585174106, \"phi\": 0.9616071202522097}, {\"truth_threshold\": -9.700000144541264, \"match_probability\": 0.001200845581852835, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490492.0, \"fp\": 470.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.999962372794025, \"fp_rate\": 3.762720597500817e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9327418431597023, \"recall\": 0.996940960538391, \"specificity\": 0.999962372794025, \"npv\": 0.9999983987846135, \"accuracy\": 0.9999607921584317, \"f1\": 0.963773473310661, \"f2\": 0.9834037417018708, \"f0_5\": 0.9449115685706002, \"p4\": 0.9815431450690404, \"phi\": 0.9642882641241531}, {\"truth_threshold\": -9.600000143051147, \"match_probability\": 0.001286923510110021, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490543.0, \"fp\": 419.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999664557461627, \"fp_rate\": 3.3544253837294516e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.939599250396425, \"recall\": 0.996940960538391, \"specificity\": 0.9999664557461627, \"npv\": 0.9999983987911514, \"accuracy\": 0.9999648729745949, \"f1\": 0.9674211502782931, \"f2\": 0.9849194596391551, \"f0_5\": 0.9505337455521204, \"p4\": 0.983432337894982, \"phi\": 0.9678284273561235}, {\"truth_threshold\": -9.500000141561031, \"match_probability\": 0.0013791630787767571, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490556.0, \"fp\": 406.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999674964986685, \"fp_rate\": 3.25035013316028e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9413633737723859, \"recall\": 0.996940960538391, \"specificity\": 0.9999674964986685, \"npv\": 0.9999983987928179, \"accuracy\": 0.9999659131826365, \"f1\": 0.9683553706730055, \"f2\": 0.9853065666948845, \"f0_5\": 0.9519775661622948, \"p4\": 0.9839150605446185, \"phi\": 0.9687370707274748}, {\"truth_threshold\": -9.400000140070915, \"match_probability\": 0.001478004086219237, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490574.0, \"fp\": 388.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999689375405993, \"fp_rate\": 3.106245940064504e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9438169707500724, \"recall\": 0.996940960538391, \"specificity\": 0.9999689375405993, \"npv\": 0.9999983987951253, \"accuracy\": 0.9999673534706941, \"f1\": 0.9696518893186552, \"f2\": 0.9858430637062133, \"f0_5\": 0.9539839587846145, \"p4\": 0.9845842286281121, \"phi\": 0.969999424669256}, {\"truth_threshold\": -9.300000138580799, \"match_probability\": 0.0015839175344616876, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490615.0, \"fp\": 347.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999722199138865, \"fp_rate\": 2.778008611346348e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9494537509104152, \"recall\": 0.996940960538391, \"specificity\": 0.9999722199138865, \"npv\": 0.9999983988003812, \"accuracy\": 0.9999706341268254, \"f1\": 0.9726180705812132, \"f2\": 0.9870672683768967, \"f0_5\": 0.9585857991646567, \"p4\": 0.9861118479323757, \"phi\": 0.9728932943830182}, {\"truth_threshold\": -9.200000137090683, \"match_probability\": 0.0016974078152024628, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6518.0, \"tn\": 12490626.0, \"fp\": 336.0, \"fn\": 20.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.996940960538391, \"tn_rate\": 0.9999731005506222, \"fp_rate\": 2.6899449377878182e-05, \"fn_rate\": 0.0030590394616090547, \"precision\": 0.9509775313685439, \"recall\": 0.996940960538391, \"specificity\": 0.9999731005506222, \"npv\": 0.9999983988017913, \"accuracy\": 0.9999715143028606, \"f1\": 0.9734169653524493, \"f2\": 0.9873962309883052, \"f0_5\": 0.9598280025917417, \"p4\": 0.9865225038514717, \"phi\": 0.9736741120847419}, {\"truth_threshold\": -9.100000135600567, \"match_probability\": 0.0018190150448253225, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490652.0, \"fp\": 310.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999751820556335, \"fp_rate\": 2.481794436649475e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9545920609345246, \"recall\": 0.9967880085653105, \"specificity\": 0.9999751820556335, \"npv\": 0.9999983187455151, \"accuracy\": 0.9999735147029406, \"f1\": 0.9752338196782642, \"f2\": 0.9880530034264229, \"f0_5\": 0.9627430124682385, \"p4\": 0.987455186452866, \"phi\": 0.9754488979879647}, {\"truth_threshold\": -9.00000013411045, \"match_probability\": 0.0019493175579394322, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490659.0, \"fp\": 303.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999757424608289, \"fp_rate\": 2.4257539171122288e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9555718475073314, \"recall\": 0.9967880085653105, \"specificity\": 0.9999757424608289, \"npv\": 0.9999983187464574, \"accuracy\": 0.999974074814963, \"f1\": 0.9757448719868244, \"f2\": 0.9882627684095596, \"f0_5\": 0.9635401265598202, \"p4\": 0.9877172260306248, \"phi\": 0.9759496417765611}, {\"truth_threshold\": -8.900000132620335, \"match_probability\": 0.002088934569496736, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490666.0, \"fp\": 296.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999763028660242, \"fp_rate\": 2.3697133975749826e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9565536474387201, \"recall\": 0.9967880085653105, \"specificity\": 0.9999763028660242, \"npv\": 0.9999983187473995, \"accuracy\": 0.9999746349269854, \"f1\": 0.9762564601902479, \"f2\": 0.9884726224783862, \"f0_5\": 0.9643385617046464, \"p4\": 0.9879794047192858, \"phi\": 0.9764511569575802}, {\"truth_threshold\": -8.800000131130219, \"match_probability\": 0.0022385290160630528, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490676.0, \"fp\": 286.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999771034448748, \"fp_rate\": 2.289655512521774e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9579597236513303, \"recall\": 0.9967880085653105, \"specificity\": 0.9999771034448748, \"npv\": 0.9999983187487456, \"accuracy\": 0.9999754350870174, \"f1\": 0.9769882317667341, \"f2\": 0.9887725686542255, \"f0_5\": 0.9654814814814815, \"p4\": 0.9883541872376157, \"phi\": 0.9771689492784599}, {\"truth_threshold\": -8.700000129640102, \"match_probability\": 0.002398810587356977, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490682.0, \"fp\": 280.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999775837921852, \"fp_rate\": 2.2416207814898486e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9588053553038105, \"recall\": 0.9967880085653105, \"specificity\": 0.9999775837921852, \"npv\": 0.9999983187495531, \"accuracy\": 0.9999759151830366, \"f1\": 0.9774278215223097, \"f2\": 0.9889526237518589, \"f0_5\": 0.9661685346616854, \"p4\": 0.9885791932636133, \"phi\": 0.9776003846778827}, {\"truth_threshold\": -8.600000128149986, \"match_probability\": 0.0025705389597152823, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490687.0, \"fp\": 275.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999779840816103, \"fp_rate\": 2.201591838963244e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9595111896348646, \"recall\": 0.9967880085653105, \"specificity\": 0.9999779840816103, \"npv\": 0.9999983187502262, \"accuracy\": 0.9999763152630526, \"f1\": 0.977794448612153, \"f2\": 0.9891027197668771, \"f0_5\": 0.9667418263810598, \"p4\": 0.9887667765593275, \"phi\": 0.9779603507196106}, {\"truth_threshold\": -8.50000012665987, \"match_probability\": 0.0027545272436909716, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6517.0, \"tn\": 12490704.0, \"fp\": 258.0, \"fn\": 21.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9967880085653105, \"tn_rate\": 0.9999793450656562, \"fp_rate\": 2.065493434372789e-05, \"fn_rate\": 0.0032119914346895075, \"precision\": 0.9619188191881919, \"recall\": 0.9967880085653105, \"specificity\": 0.9999793450656562, \"npv\": 0.9999983187525143, \"accuracy\": 0.999977675535107, \"f1\": 0.9790430406369713, \"f2\": 0.9896133871898442, \"f0_5\": 0.9686961174861763, \"p4\": 0.9894050925942413, \"phi\": 0.9791872139674983}, {\"truth_threshold\": -8.400000125169754, \"match_probability\": 0.0029516456585356845, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490713.0, \"fp\": 249.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999800655866218, \"fp_rate\": 1.993441337824901e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9631765749778172, \"recall\": 0.9961762006729887, \"specificity\": 0.9999800655866218, \"npv\": 0.9999979985169811, \"accuracy\": 0.999978075615123, \"f1\": 0.9793984962406015, \"f2\": 0.9893966093455673, \"f0_5\": 0.9696004287500745, \"p4\": 0.9895866678058491, \"phi\": 0.9795266136704868}, {\"truth_threshold\": -8.300000123679638, \"match_probability\": 0.0031628254468557835, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490719.0, \"fp\": 243.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999980545933932, \"fp_rate\": 1.9454066067929756e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9640319715808171, \"recall\": 0.9961762006729887, \"specificity\": 0.999980545933932, \"npv\": 0.9999979985179426, \"accuracy\": 0.9999785557111422, \"f1\": 0.9798405295622085, \"f2\": 0.9895770025525708, \"f0_5\": 0.9702937846373875, \"p4\": 0.9898123739045631, \"phi\": 0.9799617128465516}, {\"truth_threshold\": -8.200000122189522, \"match_probability\": 0.0033890630432542824, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490731.0, \"fp\": 231.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999815066285527, \"fp_rate\": 1.849337144729125e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9657473309608541, \"recall\": 0.9961762006729887, \"specificity\": 0.9999815066285527, \"npv\": 0.9999979985198654, \"accuracy\": 0.9999795159031807, \"f1\": 0.9807257943080862, \"f2\": 0.9899379863813229, \"f0_5\": 0.9716834755624515, \"p4\": 0.9902640951184987, \"phi\": 0.9808336521820024}, {\"truth_threshold\": -8.100000120699406, \"match_probability\": 0.003631424511270156, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490738.0, \"fp\": 224.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999982067033748, \"fp_rate\": 1.7932966251918786e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9667507792786106, \"recall\": 0.9961762006729887, \"specificity\": 0.999982067033748, \"npv\": 0.999997998520987, \"accuracy\": 0.999980076015203, \"f1\": 0.9812429378531073, \"f2\": 0.9901486819301286, \"f0_5\": 0.9724959684644329, \"p4\": 0.9905277896149696, \"phi\": 0.9813433587692191}, {\"truth_threshold\": -8.00000011920929, \"match_probability\": 0.0038910502633927486, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490756.0, \"fp\": 206.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999983508075679, \"fp_rate\": 1.6491924320961027e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9693406756957881, \"recall\": 0.9961762006729887, \"specificity\": 0.999983508075679, \"npv\": 0.9999979985238713, \"accuracy\": 0.9999815163032606, \"f1\": 0.9825752432677076, \"f2\": 0.9906908825408415, \"f0_5\": 0.9745914885975938, \"p4\": 0.9912065064815885, \"phi\": 0.9826576877984904}, {\"truth_threshold\": -7.900000117719173, \"match_probability\": 0.004169160079349993, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490762.0, \"fp\": 200.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999839884229894, \"fp_rate\": 1.6011577010641774e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9702070609265604, \"recall\": 0.9961762006729887, \"specificity\": 0.9999839884229894, \"npv\": 0.9999979985248327, \"accuracy\": 0.9999819963992799, \"f1\": 0.9830201494226851, \"f2\": 0.9908717480602465, \"f0_5\": 0.9752920035938903, \"p4\": 0.9914329521782317, \"phi\": 0.9830969715572184}, {\"truth_threshold\": -7.800000116229057, \"match_probability\": 0.004467058438231288, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490770.0, \"fp\": 192.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999846288860698, \"fp_rate\": 1.5371113930216104e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9713646532438479, \"recall\": 0.9961762006729887, \"specificity\": 0.9999846288860698, \"npv\": 0.9999979985261146, \"accuracy\": 0.9999826365273055, \"f1\": 0.9836139847466586, \"f2\": 0.9911130048391514, \"f0_5\": 0.9762275915822292, \"p4\": 0.9917350407683725, \"phi\": 0.9836836000411173}, {\"truth_threshold\": -7.700000114738941, \"match_probability\": 0.004786140180292905, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490777.0, \"fp\": 185.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999851892912651, \"fp_rate\": 1.481070873484364e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9723798148701105, \"recall\": 0.9961762006729887, \"specificity\": 0.9999851892912651, \"npv\": 0.9999979985272363, \"accuracy\": 0.9999831966393279, \"f1\": 0.9841341795104261, \"f2\": 0.991324200913242, \"f0_5\": 0.9770477047704771, \"p4\": 0.9919995193379518, \"phi\": 0.9841977617147393}, {\"truth_threshold\": -7.600000113248825, \"match_probability\": 0.0051278965144870335, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490794.0, \"fp\": 168.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.999986550275311, \"fp_rate\": 1.3449724688939091e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9748540637629097, \"recall\": 0.9961762006729887, \"specificity\": 0.999986550275311, \"npv\": 0.9999979985299603, \"accuracy\": 0.9999845569113823, \"f1\": 0.9853998033134125, \"f2\": 0.9918374805835593, \"f0_5\": 0.9790451566351993, \"p4\": 0.992642412101128, \"phi\": 0.9854498019388348}, {\"truth_threshold\": -7.500000111758709, \"match_probability\": 0.005493921387833209, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490797.0, \"fp\": 165.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999867904489662, \"fp_rate\": 1.3209551033779465e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9752920035938903, \"recall\": 0.9961762006729887, \"specificity\": 0.9999867904489662, \"npv\": 0.999997998530441, \"accuracy\": 0.9999847969593919, \"f1\": 0.9856234866828087, \"f2\": 0.9919281145293939, \"f0_5\": 0.9793984962406015, \"p4\": 0.9927559502755972, \"phi\": 0.9856712462720578}, {\"truth_threshold\": -7.400000110268593, \"match_probability\": 0.005885918232687788, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490804.0, \"fp\": 158.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999873508541616, \"fp_rate\": 1.2649145838407001e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9763153949932544, \"recall\": 0.9961762006729887, \"specificity\": 0.9999873508541616, \"npv\": 0.9999979985315627, \"accuracy\": 0.9999853570714143, \"f1\": 0.9861458096752215, \"f2\": 0.9921396581665296, \"f0_5\": 0.9802239479862741, \"p4\": 0.9930209737153933, \"phi\": 0.98618853040238}, {\"truth_threshold\": -7.300000108778477, \"match_probability\": 0.006305707107734554, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490806.0, \"fp\": 156.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999875109699317, \"fp_rate\": 1.2489030068300584e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9766081871345029, \"recall\": 0.9961762006729887, \"specificity\": 0.9999875109699317, \"npv\": 0.9999979985318831, \"accuracy\": 0.9999855171034207, \"f1\": 0.9862951465132127, \"f2\": 0.9922001157795314, \"f0_5\": 0.9804600469681459, \"p4\": 0.9930967206899199, \"phi\": 0.9863364754113385}, {\"truth_threshold\": -7.200000107288361, \"match_probability\": 0.006755232248084272, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490815.0, \"fp\": 147.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999882314908972, \"fp_rate\": 1.1768509102821704e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9779279279279279, \"recall\": 0.9961762006729887, \"specificity\": 0.9999882314908972, \"npv\": 0.9999979985333253, \"accuracy\": 0.9999862372474495, \"f1\": 0.9869677223821791, \"f2\": 0.992472266244057, \"f0_5\": 0.9815239013804328, \"p4\": 0.9934377251279669, \"phi\": 0.987003052290932}, {\"truth_threshold\": -7.1000001057982445, \"match_probability\": 0.007236570039195372, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490816.0, \"fp\": 146.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999883115487822, \"fp_rate\": 1.1688451217768496e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9780747860039045, \"recall\": 0.9961762006729887, \"specificity\": 0.9999883115487822, \"npv\": 0.9999979985334855, \"accuracy\": 0.9999863172634527, \"f1\": 0.9870425096612867, \"f2\": 0.9925025144006583, \"f0_5\": 0.9816422499547839, \"p4\": 0.9934756289663533, \"phi\": 0.9870771997802797}, {\"truth_threshold\": -7.000000104308128, \"match_probability\": 0.00775193742836891, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490823.0, \"fp\": 139.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999888719539776, \"fp_rate\": 1.1128046022396034e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9791040288634997, \"recall\": 0.9961762006729887, \"specificity\": 0.9999888719539776, \"npv\": 0.9999979985346071, \"accuracy\": 0.9999868773754751, \"f1\": 0.9875663381349508, \"f2\": 0.9927143031337642, \"f0_5\": 0.9824714897725215, \"p4\": 0.993741036843316, \"phi\": 0.9875967001930721}, {\"truth_threshold\": -6.900000102818012, \"match_probability\": 0.008303700786279804, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490825.0, \"fp\": 137.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999890320697478, \"fp_rate\": 1.0967930252289615e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9793984962406015, \"recall\": 0.9961762006729887, \"specificity\": 0.9999890320697478, \"npv\": 0.9999979985349275, \"accuracy\": 0.9999870374074815, \"f1\": 0.9877161055505005, \"f2\": 0.9927748308029998, \"f0_5\": 0.9827086728227412, \"p4\": 0.9938168937136123, \"phi\": 0.9877452794954199}, {\"truth_threshold\": -6.800000101327896, \"match_probability\": 0.00889438522932807, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490828.0, \"fp\": 134.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999892722434028, \"fp_rate\": 1.0727756597129988e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9798405295622085, \"recall\": 0.9961762006729887, \"specificity\": 0.9999892722434028, \"npv\": 0.9999979985354083, \"accuracy\": 0.9999872774554911, \"f1\": 0.9879408418657566, \"f2\": 0.9928656361474435, \"f0_5\": 0.983064662198877, \"p4\": 0.9939307007359219, \"phi\": 0.9879682741485495}, {\"truth_threshold\": -6.70000009983778, \"match_probability\": 0.009526684411466419, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490832.0, \"fp\": 130.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999895924749431, \"fp_rate\": 1.0407525056917153e-05, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9804305283757339, \"recall\": 0.9961762006729887, \"specificity\": 0.9999895924749431, \"npv\": 0.9999979985360492, \"accuracy\": 0.999987597519504, \"f1\": 0.9882406494196192, \"f2\": 0.9929867357828938, \"f0_5\": 0.9835397160978556, \"p4\": 0.9940824839844125, \"phi\": 0.9882658352568576}, {\"truth_threshold\": -6.600000098347664, \"match_probability\": 0.010203470791514735, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490841.0, \"fp\": 121.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999903129959086, \"fp_rate\": 9.687004091438274e-06, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.981760627072656, \"recall\": 0.9961762006729887, \"specificity\": 0.9999903129959086, \"npv\": 0.9999979985374913, \"accuracy\": 0.9999883176635327, \"f1\": 0.9889158821743091, \"f2\": 0.9932593180015861, \"f0_5\": 0.9846102678841386, \"p4\": 0.994424165846811, \"phi\": 0.9889363312865134}, {\"truth_threshold\": -6.500000096857548, \"match_probability\": 0.010927806378730125, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6513.0, \"tn\": 12490845.0, \"fp\": 117.0, \"fn\": 25.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9961762006729887, \"tn_rate\": 0.9999906332274487, \"fp_rate\": 9.366772551225439e-06, \"fn_rate\": 0.0038237993270113183, \"precision\": 0.9823529411764705, \"recall\": 0.9961762006729887, \"specificity\": 0.9999906332274487, \"npv\": 0.9999979985381322, \"accuracy\": 0.9999886377275455, \"f1\": 0.9892162818955043, \"f2\": 0.9933805136965408, \"f0_5\": 0.985086817109323, \"p4\": 0.9945760998582738, \"phi\": 0.9892347675828096}, {\"truth_threshold\": -6.400000095367432, \"match_probability\": 0.011702953955477532, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6512.0, \"tn\": 12490861.0, \"fp\": 101.0, \"fn\": 26.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9960232486999082, \"tn_rate\": 0.9999919141536097, \"fp_rate\": 8.085846390374096e-06, \"fn_rate\": 0.0039767513000917715, \"precision\": 0.9847270527748374, \"recall\": 0.9960232486999082, \"specificity\": 0.9999919141536097, \"npv\": 0.9999979184824904, \"accuracy\": 0.9999898379675936, \"f1\": 0.990342939700403, \"f2\": 0.9937433236685488, \"f0_5\": 0.9869657471961201, \"p4\": 0.9951455247789379, \"phi\": 0.9903539784404328}, {\"truth_threshold\": -6.3000000938773155, \"match_probability\": 0.012532388771145032, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6511.0, \"tn\": 12490865.0, \"fp\": 97.0, \"fn\": 27.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9958702967268278, \"tn_rate\": 0.9999922343851498, \"fp_rate\": 7.76561485016126e-06, \"fn_rate\": 0.004129703273172224, \"precision\": 0.9853208232445521, \"recall\": 0.9958702967268278, \"specificity\": 0.9999922343851498, \"npv\": 0.99999783842499, \"accuracy\": 0.9999900780156031, \"f1\": 0.990567472995588, \"f2\": 0.9937423687423688, \"f0_5\": 0.9874127995147104, \"p4\": 0.9952589296120936, \"phi\": 0.9905765676423486}, {\"truth_threshold\": -6.200000092387199, \"match_probability\": 0.013419810695865477, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490869.0, \"fp\": 93.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.99999255461669, \"fp_rate\": 7.445383309948425e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9859154929577465, \"recall\": 0.9957173447537473, \"specificity\": 0.99999255461669, \"npv\": 0.9999977583675536, \"accuracy\": 0.9999903180636127, \"f1\": 0.9907921771554676, \"f2\": 0.9937414135246527, \"f0_5\": 0.9878603945371776, \"p4\": 0.9953723951287743, \"phi\": 0.9907994672309304}, {\"truth_threshold\": -6.100000090897083, \"match_probability\": 0.014369156816028038, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490871.0, \"fp\": 91.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.9999927147324602, \"fp_rate\": 7.285267539842007e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9862142099681867, \"recall\": 0.9957173447537473, \"specificity\": 0.9999927147324602, \"npv\": 0.9999977583679125, \"accuracy\": 0.9999904780956191, \"f1\": 0.9909429941395844, \"f2\": 0.9938020944646292, \"f0_5\": 0.9881002974925627, \"p4\": 0.9954485363274292, \"phi\": 0.9909496342690415}, {\"truth_threshold\": -6.000000089406967, \"match_probability\": 0.015384614445865122, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490874.0, \"fp\": 88.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.9999929549061153, \"fp_rate\": 7.045093884682381e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9866626250378903, \"recall\": 0.9957173447537473, \"specificity\": 0.9999929549061153, \"npv\": 0.9999977583684508, \"accuracy\": 0.9999907181436287, \"f1\": 0.991169305724726, \"f2\": 0.9938931297709923, \"f0_5\": 0.9884603704828424, \"p4\": 0.9955627699695268, \"phi\": 0.9911750128125926}, {\"truth_threshold\": -5.900000087916851, \"match_probability\": 0.016470634520449206, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6510.0, \"tn\": 12490881.0, \"fp\": 81.0, \"fn\": 28.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9957173447537473, \"tn_rate\": 0.9999935153113106, \"fp_rate\": 6.484688689309918e-06, \"fn_rate\": 0.004282655246252677, \"precision\": 0.9877105143377333, \"recall\": 0.9957173447537473, \"specificity\": 0.9999935153113106, \"npv\": 0.9999977583697072, \"accuracy\": 0.9999912782556512, \"f1\": 0.991697768299185, \"f2\": 0.9941056103594661, \"f0_5\": 0.9893015622150629, \"p4\": 0.9958294171204296, \"phi\": 0.9917014942566631}, {\"truth_threshold\": -5.800000086426735, \"match_probability\": 0.017631945325087592, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6506.0, \"tn\": 12490886.0, \"fp\": 76.0, \"fn\": 32.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9951055368614256, \"tn_rate\": 0.9999939156007359, \"fp_rate\": 6.084399264043874e-06, \"fn_rate\": 0.004894463138574488, \"precision\": 0.9884533576420541, \"recall\": 0.9951055368614256, \"specificity\": 0.9999939156007359, \"npv\": 0.999997438138654, \"accuracy\": 0.9999913582716543, \"f1\": 0.9917682926829269, \"f2\": 0.9937679476996395, \"f0_5\": 0.9897766688979492, \"p4\": 0.9958649923370161, \"phi\": 0.9917695527022244}, {\"truth_threshold\": -5.700000084936619, \"match_probability\": 0.01887356650421064, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6506.0, \"tn\": 12490887.0, \"fp\": 75.0, \"fn\": 32.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9951055368614256, \"tn_rate\": 0.999993995658621, \"fp_rate\": 6.004341378990665e-06, \"fn_rate\": 0.004894463138574488, \"precision\": 0.9886035556906245, \"recall\": 0.9951055368614256, \"specificity\": 0.999993995658621, \"npv\": 0.9999974381388591, \"accuracy\": 0.9999914382876576, \"f1\": 0.9918438905404375, \"f2\": 0.9937983075184065, \"f0_5\": 0.9898971456393403, \"p4\": 0.9959031225875888, \"phi\": 0.9918449409099048}, {\"truth_threshold\": -5.600000083446503, \"match_probability\": 0.02020082327925431, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6504.0, \"tn\": 12490887.0, \"fp\": 75.0, \"fn\": 34.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9947996329152646, \"tn_rate\": 0.999993995658621, \"fp_rate\": 6.004341378990665e-06, \"fn_rate\": 0.005200367084735393, \"precision\": 0.9886000911992704, \"recall\": 0.9947996329152646, \"specificity\": 0.999993995658621, \"npv\": 0.9999972780229737, \"accuracy\": 0.9999912782556512, \"f1\": 0.9916901730578639, \"f2\": 0.9935535119611377, \"f0_5\": 0.98983381019054, \"p4\": 0.9958255877767056, \"phi\": 0.9916906594937726}, {\"truth_threshold\": -5.500000081956387, \"match_probability\": 0.02161936078957948, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6504.0, \"tn\": 12490908.0, \"fp\": 54.0, \"fn\": 34.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9947996329152646, \"tn_rate\": 0.9999956768742071, \"fp_rate\": 4.323125792873279e-06, \"fn_rate\": 0.005200367084735393, \"precision\": 0.9917657822506862, \"recall\": 0.9947996329152646, \"specificity\": 0.9999956768742071, \"npv\": 0.9999972780275499, \"accuracy\": 0.9999929585917183, \"f1\": 0.9932803909590715, \"f2\": 0.9941913787832467, \"f0_5\": 0.9923710711016174, \"p4\": 0.9966271197158166, \"phi\": 0.9932780279394297}, {\"truth_threshold\": -5.4000000804662704, \"match_probability\": 0.023135158452986655, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6504.0, \"tn\": 12490925.0, \"fp\": 37.0, \"fn\": 34.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9947996329152646, \"tn_rate\": 0.999997037858253, \"fp_rate\": 2.9621417469687283e-06, \"fn_rate\": 0.005200367084735393, \"precision\": 0.9943433725730011, \"recall\": 0.9947996329152646, \"specificity\": 0.999997037858253, \"npv\": 0.9999972780312545, \"accuracy\": 0.9999943188637728, \"f1\": 0.9945714504166985, \"f2\": 0.9947083473526444, \"f0_5\": 0.9944345911565042, \"p4\": 0.9972769245643808, \"phi\": 0.994568634552632}, {\"truth_threshold\": -5.300000078976154, \"match_probability\": 0.024754544222716376, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6501.0, \"tn\": 12490935.0, \"fp\": 27.0, \"fn\": 37.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9943407769960233, \"tn_rate\": 0.9999978384371035, \"fp_rate\": 2.1615628964366394e-06, \"fn_rate\": 0.005659223003976751, \"precision\": 0.9958639705882353, \"recall\": 0.9943407769960233, \"specificity\": 0.9999978384371035, \"npv\": 0.9999970378606244, \"accuracy\": 0.9999948789757952, \"f1\": 0.9951017909076993, \"f2\": 0.9946450428396573, \"f0_5\": 0.9955589586523736, \"p4\": 0.9975436079693399, \"phi\": 0.9950995208042643}, {\"truth_threshold\": -5.200000077486038, \"match_probability\": 0.02648420859582165, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6496.0, \"tn\": 12490935.0, \"fp\": 27.0, \"fn\": 42.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9935760171306209, \"tn_rate\": 0.9999978384371035, \"fp_rate\": 2.1615628964366394e-06, \"fn_rate\": 0.006423982869379015, \"precision\": 0.9958608002452859, \"recall\": 0.9935760171306209, \"specificity\": 0.9999978384371035, \"npv\": 0.9999966375728656, \"accuracy\": 0.9999944788957792, \"f1\": 0.9947170967000996, \"f2\": 0.9940321346595257, \"f0_5\": 0.9954030033711309, \"p4\": 0.9973501789100293, \"phi\": 0.9947149913863651}, {\"truth_threshold\": -5.100000075995922, \"match_probability\": 0.02833121820332325, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6496.0, \"tn\": 12490938.0, \"fp\": 24.0, \"fn\": 42.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9935760171306209, \"tn_rate\": 0.9999980786107587, \"fp_rate\": 1.921389241277013e-06, \"fn_rate\": 0.006423982869379015, \"precision\": 0.996319018404908, \"recall\": 0.9935760171306209, \"specificity\": 0.9999980786107587, \"npv\": 0.9999966375736732, \"accuracy\": 0.9999947189437888, \"f1\": 0.9949456272017154, \"f2\": 0.9941234084231146, \"f0_5\": 0.9957692071862162, \"p4\": 0.9974650964776995, \"phi\": 0.9949439315669494}, {\"truth_threshold\": -4.90000007301569, \"match_probability\": 0.032407497325934585, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6496.0, \"tn\": 12490940.0, \"fp\": 22.0, \"fn\": 42.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9935760171306209, \"tn_rate\": 0.9999982387265288, \"fp_rate\": 1.7612734711705952e-06, \"fn_rate\": 0.006423982869379015, \"precision\": 0.996624731512734, \"recall\": 0.9935760171306209, \"specificity\": 0.9999982387265288, \"npv\": 0.9999966375742115, \"accuracy\": 0.9999948789757952, \"f1\": 0.9950980392156863, \"f2\": 0.9941842669115396, \"f0_5\": 0.9960134927936216, \"p4\": 0.9975417229029651, \"phi\": 0.9950966461414167}, {\"truth_threshold\": -4.800000071525574, \"match_probability\": 0.03465289308554322, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6495.0, \"tn\": 12490944.0, \"fp\": 18.0, \"fn\": 43.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9934230651575405, \"tn_rate\": 0.999998558958069, \"fp_rate\": 1.4410419309577597e-06, \"fn_rate\": 0.006576934842459468, \"precision\": 0.9972362966374942, \"recall\": 0.9934230651575405, \"specificity\": 0.999998558958069, \"npv\": 0.9999965575178327, \"accuracy\": 0.9999951190238048, \"f1\": 0.9953260286568079, \"f2\": 0.994183376702893, \"f0_5\": 0.9964713102178583, \"p4\": 0.9976563248630456, \"phi\": 0.9953254149254049}, {\"truth_threshold\": -4.700000070035458, \"match_probability\": 0.037047907242669466, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6494.0, \"tn\": 12490945.0, \"fp\": 17.0, \"fn\": 44.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9932701131844601, \"tn_rate\": 0.9999986390159541, \"fp_rate\": 1.3609840459045507e-06, \"fn_rate\": 0.00672988681553992, \"precision\": 0.9973890339425587, \"recall\": 0.9932701131844601, \"specificity\": 0.9999986390159541, \"npv\": 0.9999964774606719, \"accuracy\": 0.9999951190238048, \"f1\": 0.9953253122844662, \"f2\": 0.9940911734990662, \"f0_5\": 0.9965625191823706, \"p4\": 0.9976559649976805, \"phi\": 0.9953250033904799}, {\"truth_threshold\": -4.6000000685453415, \"match_probability\": 0.039601660807737325, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6491.0, \"tn\": 12490947.0, \"fp\": 15.0, \"fn\": 47.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9928112572652187, \"tn_rate\": 0.9999987991317242, \"fp_rate\": 1.2008682757981331e-06, \"fn_rate\": 0.007188742734781279, \"precision\": 0.9976944359053181, \"recall\": 0.9928112572652187, \"specificity\": 0.9999987991317242, \"npv\": 0.999996237289042, \"accuracy\": 0.9999950390078015, \"f1\": 0.995246856792395, \"f2\": 0.9937840651601445, \"f0_5\": 0.996713961058903, \"p4\": 0.9976165318565344, \"phi\": 0.9952473730288349}, {\"truth_threshold\": -4.500000067055225, \"match_probability\": 0.04232371044088178, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6490.0, \"tn\": 12490947.0, \"fp\": 15.0, \"fn\": 48.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9926583052921383, \"tn_rate\": 0.9999987991317242, \"fp_rate\": 1.2008682757981331e-06, \"fn_rate\": 0.007341694707861731, \"precision\": 0.9976940814757879, \"recall\": 0.9926583052921383, \"specificity\": 0.9999987991317242, \"npv\": 0.9999961572316697, \"accuracy\": 0.9999949589917984, \"f1\": 0.9951698228935061, \"f2\": 0.9936613895948802, \"f0_5\": 0.9966828429264697, \"p4\": 0.9975778098597211, \"phi\": 0.9951704896485309}, {\"truth_threshold\": -4.200000062584877, \"match_probability\": 0.05160178526561565, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490948.0, \"fp\": 14.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999988791896093, \"fp_rate\": 1.120810390744924e-06, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9978468163641956, \"recall\": 0.9923524013459774, \"specificity\": 0.9999988791896093, \"npv\": 0.9999959971172839, \"accuracy\": 0.9999948789757952, \"f1\": 0.9950920245398773, \"f2\": 0.9934464384148955, \"f0_5\": 0.996743071345173, \"p4\": 0.9975387007682611, \"phi\": 0.9950932588112428}, {\"truth_threshold\": -3.9000000581145287, \"match_probability\": 0.06278043839004852, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490949.0, \"fp\": 13.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999989592474943, \"fp_rate\": 1.0407525056917153e-06, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9980003076449777, \"recall\": 0.9923524013459774, \"specificity\": 0.9999989592474943, \"npv\": 0.9999959971176045, \"accuracy\": 0.9999949589917984, \"f1\": 0.9951683411304548, \"f2\": 0.9934768627691177, \"f0_5\": 0.9968655890848749, \"p4\": 0.9975770653881216, \"phi\": 0.9951698301789526}, {\"truth_threshold\": -3.7000000551342964, \"match_probability\": 0.07144878715678568, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6488.0, \"tn\": 12490954.0, \"fp\": 8.0, \"fn\": 50.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9923524013459774, \"tn_rate\": 0.9999993595369195, \"fp_rate\": 6.40463080425671e-07, \"fn_rate\": 0.007647598654022637, \"precision\": 0.9987684729064039, \"recall\": 0.9923524013459774, \"specificity\": 0.9999993595369195, \"npv\": 0.9999959971192067, \"accuracy\": 0.9999953590718144, \"f1\": 0.9955500997391438, \"f2\": 0.993629012496937, \"f0_5\": 0.9974786298505627, \"p4\": 0.9977689327601589, \"phi\": 0.9955529521513098}, {\"truth_threshold\": -3.400000050663948, \"match_probability\": 0.08653465658300358, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6487.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 51.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.992199449372897, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.00780055062710309, \"precision\": 0.9989220819217739, \"recall\": 0.992199449372897, \"specificity\": 0.9999994395948046, \"npv\": 0.9999959170622447, \"accuracy\": 0.9999953590718144, \"f1\": 0.9955494168201351, \"f2\": 0.9935367273172824, \"f0_5\": 0.997570277418958, \"p4\": 0.9977685897768772, \"phi\": 0.9955527754779164}, {\"truth_threshold\": -3.200000047683716, \"match_probability\": 0.09813940308831819, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6486.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 52.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9920464973998164, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.007953502600183543, \"precision\": 0.9989219159094409, \"recall\": 0.9920464973998164, \"specificity\": 0.9999994395948046, \"npv\": 0.9999958370049749, \"accuracy\": 0.9999952790558112, \"f1\": 0.9954723352006754, \"f2\": 0.9934139990810231, \"f0_5\": 0.9975392187019378, \"p4\": 0.9977298555343642, \"phi\": 0.9954759154146037}, {\"truth_threshold\": -3.1000000461935997, \"match_probability\": 0.10444750015659417, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6485.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 53.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.991893545426736, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.008106454573263994, \"precision\": 0.9989217498459643, \"recall\": 0.991893545426736, \"specificity\": 0.9999994395948046, \"npv\": 0.9999957569477179, \"accuracy\": 0.9999951990398079, \"f1\": 0.9953952417498081, \"f2\": 0.9932912633255728, \"f0_5\": 0.9975081523411062, \"p4\": 0.9976911123608679, \"phi\": 0.9953990494288513}, {\"truth_threshold\": -3.0000000447034836, \"match_probability\": 0.11111110805075623, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6477.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 61.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9906699296420923, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009330070357907618, \"precision\": 0.9989204194941395, \"recall\": 0.9906699296420923, \"specificity\": 0.9999994395948046, \"npv\": 0.9999951164901237, \"accuracy\": 0.9999945589117823, \"f1\": 0.9947780678851175, \"f2\": 0.9923091065081505, \"f0_5\": 0.9972593459382891, \"p4\": 0.997380845086157, \"phi\": 0.9947839081702453}, {\"truth_threshold\": -2.7000000402331352, \"match_probability\": 0.13336855415354743, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6476.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 62.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9905169776690119, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.00948302233098807, \"precision\": 0.9989202529693043, \"recall\": 0.9905169776690119, \"specificity\": 0.9999994395948046, \"npv\": 0.9999950364329822, \"accuracy\": 0.9999944788957792, \"f1\": 0.9947008678288918, \"f2\": 0.9921863030488739, \"f0_5\": 0.9972282106559901, \"p4\": 0.9973420213944986, \"phi\": 0.9947069888207287}, {\"truth_threshold\": -2.600000038743019, \"match_probability\": 0.1415855743659812, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6475.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 63.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9903640256959315, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009635974304068522, \"precision\": 0.9989200863930886, \"recall\": 0.9903640256959315, \"specificity\": 0.9999994395948046, \"npv\": 0.9999949563758534, \"accuracy\": 0.9999943988797759, \"f1\": 0.9946236559139785, \"f2\": 0.9920634920634921, \"f0_5\": 0.9971970677015956, \"p4\": 0.9973031887408722, \"phi\": 0.9946300635350278}, {\"truth_threshold\": -2.500000037252903, \"match_probability\": 0.15022110152606716, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6474.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 64.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.990211073722851, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009788926277148976, \"precision\": 0.9989199197654683, \"recall\": 0.990211073722851, \"specificity\": 0.9999994395948046, \"npv\": 0.9999948763187375, \"accuracy\": 0.9999943188637728, \"f1\": 0.9945464321376449, \"f2\": 0.9919406735513131, \"f0_5\": 0.9971659170722691, \"p4\": 0.9972643471221716, \"phi\": 0.9945531323117648}, {\"truth_threshold\": -2.400000035762787, \"match_probability\": 0.1592855907727143, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6473.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 65.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9900581217497706, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.009941878250229429, \"precision\": 0.9989197530864198, \"recall\": 0.9900581217497706, \"specificity\": 0.9999994395948046, \"npv\": 0.9999947962616343, \"accuracy\": 0.9999942388477695, \"f1\": 0.9944691964971578, \"f2\": 0.991817847511645, \"f0_5\": 0.9971347587651734, \"p4\": 0.9972254965352889, \"phi\": 0.994476195149562}, {\"truth_threshold\": -2.0000000298023224, \"match_probability\": 0.19999999669481672, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6471.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 67.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9897522178036097, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.010247782196390333, \"precision\": 0.9989194195739426, \"recall\": 0.9897522178036097, \"specificity\": 0.9999994395948046, \"npv\": 0.9999946361474665, \"accuracy\": 0.9999940788157632, \"f1\": 0.9943146896127842, \"f2\": 0.9915721728470732, \"f0_5\": 0.9970724191063174, \"p4\": 0.9971477684445391, \"phi\": 0.9943223030028223}, {\"truth_threshold\": -1.9000000283122063, \"match_probability\": 0.2113212378007128, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6467.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 71.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9891404099112878, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.010859590088712144, \"precision\": 0.9989187519308002, \"recall\": 0.9891404099112878, \"specificity\": 0.9999994395948046, \"npv\": 0.9999943159192848, \"accuracy\": 0.9999937587517503, \"f1\": 0.9940055333538272, \"f2\": 0.9910807331576044, \"f0_5\": 0.9969476475303694, \"p4\": 0.9969922045079532, \"phi\": 0.9940144473813759}, {\"truth_threshold\": -1.600000023841858, \"match_probability\": 0.24805074388621665, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6465.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 73.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9888345059651269, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.01116549403487305, \"precision\": 0.9989184177997528, \"recall\": 0.9888345059651269, \"specificity\": 0.9999994395948046, \"npv\": 0.9999941558052708, \"accuracy\": 0.9999935987197439, \"f1\": 0.9938508839354343, \"f2\": 0.9908349681216283, \"f0_5\": 0.9968852155677542, \"p4\": 0.996914368612266, \"phi\": 0.9938604838845746}, {\"truth_threshold\": -1.4000000208616257, \"match_probability\": 0.2747995717943022, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6464.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 74.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9886815539920465, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.011318446007953502, \"precision\": 0.9989182506567764, \"recall\": 0.9886815539920465, \"specificity\": 0.9999994395948046, \"npv\": 0.999994075748283, \"accuracy\": 0.9999935187037408, \"f1\": 0.9937735413944192, \"f2\": 0.9907120743034056, \"f0_5\": 0.9968539880328172, \"p4\": 0.9968754371716575, \"phi\": 0.9937834932098174}, {\"truth_threshold\": -1.2000000178813934, \"match_probability\": 0.3032695424040186, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6463.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 75.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9885286020189661, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.011471397981033955, \"precision\": 0.998918083462133, \"recall\": 0.9885286020189661, \"specificity\": 0.9999994395948046, \"npv\": 0.9999939956913081, \"accuracy\": 0.9999934386877376, \"f1\": 0.9936961869618696, \"f2\": 0.9905891729507694, \"f0_5\": 0.996822752791659, \"p4\": 0.99683649673171, \"phi\": 0.9937064965823112}, {\"truth_threshold\": -1.1000000163912773, \"match_probability\": 0.318111997717226, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6458.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 80.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9877638421535638, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.012236157846436219, \"precision\": 0.9989172467130704, \"recall\": 0.9877638421535638, \"specificity\": 0.9999994395948046, \"npv\": 0.9999935954066256, \"accuracy\": 0.9999930386077216, \"f1\": 0.9933092363300777, \"f2\": 0.9899745531471319, \"f0_5\": 0.9966664608926477, \"p4\": 0.9966416594325102, \"phi\": 0.9933214241050966}, {\"truth_threshold\": -0.9000000134110451, \"match_probability\": 0.34891031813411577, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6457.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 81.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9876108901804833, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.012389109819516672, \"precision\": 0.9989170792079208, \"recall\": 0.9876108901804833, \"specificity\": 0.9999994395948046, \"npv\": 0.9999935153497276, \"accuracy\": 0.9999929585917183, \"f1\": 0.9932318104906938, \"f2\": 0.9898516065734608, \"f0_5\": 0.9966351793542014, \"p4\": 0.9966026649308819, \"phi\": 0.9932443917320187}, {\"truth_threshold\": -0.7000000104308128, \"match_probability\": 0.38102425962470177, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6455.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 83.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9873049862343224, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.012695013765677577, \"precision\": 0.9989167440420922, \"recall\": 0.9873049862343224, \"specificity\": 0.9999994395948046, \"npv\": 0.99999335523597, \"accuracy\": 0.9999927985597119, \"f1\": 0.9930769230769231, \"f2\": 0.9896056908076286, \"f0_5\": 0.9965725930957822, \"p4\": 0.9965246488607872, \"phi\": 0.9930903090971351}, {\"truth_threshold\": -0.5000000074505806, \"match_probability\": 0.41421356112001384, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6454.0, \"tn\": 12490955.0, \"fp\": 7.0, \"fn\": 84.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.987152034261242, \"tn_rate\": 0.9999994395948046, \"fp_rate\": 5.60405195372462e-07, \"fn_rate\": 0.01284796573875803, \"precision\": 0.9989165763813651, \"recall\": 0.987152034261242, \"specificity\": 0.9999994395948046, \"npv\": 0.9999932751791104, \"accuracy\": 0.9999927185437087, \"f1\": 0.9929994614970382, \"f2\": 0.9894827216140802, \"f0_5\": 0.9965412883700822, \"p4\": 0.9964856272860517, \"phi\": 0.9930132588325536}, {\"truth_threshold\": -0.10000000149011612, \"match_probability\": 0.48267825490990723, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6451.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 87.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9866931783420007, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.013306821657999388, \"precision\": 0.9992255266418835, \"recall\": 0.9866931783420007, \"specificity\": 0.9999995997105747, \"npv\": 0.9999930350097238, \"accuracy\": 0.9999926385277056, \"f1\": 0.9929198091426812, \"f2\": 0.9891744357212954, \"f0_5\": 0.9966936530498733, \"p4\": 0.9964454995039487, \"phi\": 0.9929359186159613}, {\"truth_threshold\": 0.10000000149011612, \"match_probability\": 0.5173217450900928, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6447.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 91.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9860813704496788, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.013918629550321198, \"precision\": 0.9992250464972101, \"recall\": 0.9860813704496788, \"specificity\": 0.9999995997105747, \"npv\": 0.9999927147826188, \"accuracy\": 0.9999923184636927, \"f1\": 0.9926096997690531, \"f2\": 0.9886823702613177, \"f0_5\": 0.9965683546651827, \"p4\": 0.9962892379484716, \"phi\": 0.9926276338306173}, {\"truth_threshold\": 0.20000000298023224, \"match_probability\": 0.5346019618947252, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6446.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 92.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9859284184765984, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.014071581523401652, \"precision\": 0.999224926368005, \"recall\": 0.9859284184765984, \"specificity\": 0.9999995997105747, \"npv\": 0.9999926347258745, \"accuracy\": 0.9999922384476896, \"f1\": 0.9925321425821849, \"f2\": 0.9885593350305186, \"f0_5\": 0.9965370106981634, \"p4\": 0.9962501499375424, \"phi\": 0.9925505477037979}, {\"truth_threshold\": 0.4000000059604645, \"match_probability\": 0.5688740732440556, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6445.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 93.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9857754665035179, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.014224533496482105, \"precision\": 0.9992248062015504, \"recall\": 0.9857754665035179, \"specificity\": 0.9999995997105747, \"npv\": 0.999992554669143, \"accuracy\": 0.9999921584316863, \"f1\": 0.9924545734524176, \"f2\": 0.9884362922520091, \"f0_5\": 0.9965056589770549, \"p4\": 0.9962110528714946, \"phi\": 0.992473455602002}, {\"truth_threshold\": 1.0000000149011612, \"match_probability\": 0.6666666689619328, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6443.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 95.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.985469562557357, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.01453043744264301, \"precision\": 0.9992245657568238, \"recall\": 0.985469562557357, \"specificity\": 0.9999995997105747, \"npv\": 0.9999923945557188, \"accuracy\": 0.9999919983996799, \"f1\": 0.9922993993531496, \"f2\": 0.9881901840490798, \"f0_5\": 0.9964429322610578, \"p4\": 0.9961328315614428, \"phi\": 0.9923192534679103}, {\"truth_threshold\": 1.1000000163912773, \"match_probability\": 0.681888002282774, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6442.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 96.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9853166105842766, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.014683389415723462, \"precision\": 0.9992244454785172, \"recall\": 0.9853166105842766, \"specificity\": 0.9999995997105747, \"npv\": 0.9999923144990258, \"accuracy\": 0.9999919183836767, \"f1\": 0.9922217943781286, \"f2\": 0.9880671186232707, \"f0_5\": 0.9964115572604095, \"p4\": 0.996093707311135, \"phi\": 0.9922421434328279}, {\"truth_threshold\": 1.2000000178813934, \"match_probability\": 0.6967304575959814, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6441.0, \"tn\": 12490957.0, \"fp\": 5.0, \"fn\": 97.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.985163658611196, \"tn_rate\": 0.9999995997105747, \"fp_rate\": 4.0028942526604434e-07, \"fn_rate\": 0.014836341388803916, \"precision\": 0.9992243251628917, \"recall\": 0.985163658611196, \"specificity\": 0.9999995997105747, \"npv\": 0.9999922344423458, \"accuracy\": 0.9999918383676736, \"f1\": 0.9921441774491682, \"f2\": 0.9879440456469722, \"f0_5\": 0.9963801744941526, \"p4\": 0.9960545739931007, \"phi\": 0.9921650274171961}, {\"truth_threshold\": 1.600000023841858, \"match_probability\": 0.7519492561137834, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6433.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 105.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9839400428265525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016059957173447537, \"precision\": 1.0, \"recall\": 0.9839400428265525, \"specificity\": 1.0, \"npv\": 0.999991593992731, \"accuracy\": 0.9999915983196639, \"f1\": 0.9919050188882893, \"f2\": 0.9871106337271751, \"f0_5\": 0.9967462039045553, \"p4\": 0.995933976219228, \"phi\": 0.991933350492562}, {\"truth_threshold\": 1.9000000283122063, \"match_probability\": 0.7886787621992872, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6430.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 108.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9834811869073111, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.016518813092688895, \"precision\": 1.0, \"recall\": 0.9834811869073111, \"specificity\": 1.0, \"npv\": 0.9999913538231713, \"accuracy\": 0.9999913582716543, \"f1\": 0.9916718075262184, \"f2\": 0.9867411454177153, \"f0_5\": 0.9966519933039866, \"p4\": 0.9958163480406573, \"phi\": 0.9917019126507023}, {\"truth_threshold\": 2.2000000327825546, \"match_probability\": 0.8212623941099038, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6429.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 109.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9833282349342306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.01667176506576935, \"precision\": 1.0, \"recall\": 0.9833282349342306, \"specificity\": 1.0, \"npv\": 0.999991273766677, \"accuracy\": 0.9999912782556512, \"f1\": 0.9915940464255417, \"f2\": 0.9866179675270863, \"f0_5\": 0.9966205741923483, \"p4\": 0.9957771204439904, \"phi\": 0.9916247547245981}, {\"truth_threshold\": 2.3000000342726707, \"match_probability\": 0.8312116004280432, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6428.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 110.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9831752829611502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0168247170388498, \"precision\": 1.0, \"recall\": 0.9831752829611502, \"specificity\": 1.0, \"npv\": 0.9999911937101956, \"accuracy\": 0.9999911982396479, \"f1\": 0.9915162733302484, \"f2\": 0.9864947820748926, \"f0_5\": 0.9965891472868217, \"p4\": 0.9957378837401307, \"phi\": 0.9915475908067548}, {\"truth_threshold\": 2.400000035762787, \"match_probability\": 0.8407144092272857, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6387.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 151.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9769042520648517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.023095747935148365, \"precision\": 1.0, \"recall\": 0.9769042520648517, \"specificity\": 1.0, \"npv\": 0.9999879114054928, \"accuracy\": 0.9999879175835167, \"f1\": 0.9883172147001934, \"f2\": 0.9814376594240757, \"f0_5\": 0.9952938976500655, \"p4\": 0.9941212982261061, \"phi\": 0.9883786939556498}, {\"truth_threshold\": 2.500000037252903, \"match_probability\": 0.8497788984739328, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6386.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 152.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9767513000917711, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.023248699908228816, \"precision\": 1.0, \"recall\": 0.9767513000917711, \"specificity\": 1.0, \"npv\": 0.9999878313495497, \"accuracy\": 0.9999878375675135, \"f1\": 0.9882389353141442, \"f2\": 0.9813141557563464, \"f0_5\": 0.9952621407642915, \"p4\": 0.9940816761350107, \"phi\": 0.9883012771147387}, {\"truth_threshold\": 2.9000000432133675, \"match_probability\": 0.8818562391739494, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6384.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 154.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9764453961456103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.023554603854389723, \"precision\": 1.0, \"recall\": 0.9764453961456103, \"specificity\": 1.0, \"npv\": 0.999987671237702, \"accuracy\": 0.9999876775355071, \"f1\": 0.9880823401950163, \"f2\": 0.9810671256454389, \"f0_5\": 0.9951986032300305, \"p4\": 0.9940024042144268, \"phi\": 0.9881464252743235}, {\"truth_threshold\": 3.0000000447034836, \"match_probability\": 0.8888888919492438, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6381.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 157.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9759865402263689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02401345977363108, \"precision\": 1.0, \"recall\": 0.9759865402263689, \"specificity\": 1.0, \"npv\": 0.9999874310700266, \"accuracy\": 0.9999874374874975, \"f1\": 0.9878473566065485, \"f2\": 0.9806965235299542, \"f0_5\": 0.9951032374773876, \"p4\": 0.9938834269389596, \"phi\": 0.9879141020958705}, {\"truth_threshold\": 3.1000000461935997, \"match_probability\": 0.8955524998434058, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6380.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 158.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9758335882532885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02416641174671153, \"precision\": 1.0, \"recall\": 0.9758335882532885, \"specificity\": 1.0, \"npv\": 0.9999873510141605, \"accuracy\": 0.9999873574714943, \"f1\": 0.9877690044898592, \"f2\": 0.9805729743022255, \"f0_5\": 0.9950714330276375, \"p4\": 0.9938437493289402, \"phi\": 0.9878366489192678}, {\"truth_threshold\": 3.200000047683716, \"match_probability\": 0.9018605969116819, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6378.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 160.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9755276843071276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024472315692872438, \"precision\": 1.0, \"recall\": 0.9755276843071276, \"specificity\": 1.0, \"npv\": 0.9999871909024666, \"accuracy\": 0.9999871974394879, \"f1\": 0.9876122638587798, \"f2\": 0.980325853058715, \"f0_5\": 0.9950078003120125, \"p4\": 0.9937643663121284, \"phi\": 0.9876817243818339}, {\"truth_threshold\": 3.300000049173832, \"match_probability\": 0.9078269283845571, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6377.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 161.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9753747323340471, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02462526766595289, \"precision\": 1.0, \"recall\": 0.9753747323340471, \"specificity\": 1.0, \"npv\": 0.9999871108466388, \"accuracy\": 0.9999871174234847, \"f1\": 0.9875338753387534, \"f2\": 0.9802022810415322, \"f0_5\": 0.9949759720401922, \"p4\": 0.9937246608988384, \"phi\": 0.9876042530181497}, {\"truth_threshold\": 3.400000050663948, \"match_probability\": 0.9134653434169965, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6375.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 163.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9750688283878862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.024931171612113796, \"precision\": 1.0, \"recall\": 0.9750688283878862, \"specificity\": 1.0, \"npv\": 0.9999869507350219, \"accuracy\": 0.9999869573914782, \"f1\": 0.9873770618756292, \"f2\": 0.9799551142128078, \"f0_5\": 0.9949122916536612, \"p4\": 0.9936452222462342, \"phi\": 0.9874492920937119}, {\"truth_threshold\": 3.500000052154064, \"match_probability\": 0.9187896995557598, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6374.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 164.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9749158764148057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02508412358519425, \"precision\": 1.0, \"recall\": 0.9749158764148057, \"specificity\": 1.0, \"npv\": 0.9999868706792326, \"accuracy\": 0.9999868773754751, \"f1\": 0.9872986369268897, \"f2\": 0.9798315193998647, \"f0_5\": 0.9948804395329962, \"p4\": 0.9936054890004131, \"phi\": 0.9873718025301021}, {\"truth_threshold\": 3.6000000536441803, \"match_probability\": 0.9238137785296746, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6370.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 168.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.974304068522484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02569593147751606, \"precision\": 1.0, \"recall\": 0.974304068522484, \"specificity\": 1.0, \"npv\": 0.9999865504562038, \"accuracy\": 0.9999865573114622, \"f1\": 0.9869848156182213, \"f2\": 0.9793370641411967, \"f0_5\": 0.994752951464801, \"p4\": 0.9934464631443519, \"phi\": 0.9870617835663803}, {\"truth_threshold\": 3.7000000551342964, \"match_probability\": 0.9285512128432143, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6369.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 169.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9741511165494035, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02584888345059651, \"precision\": 1.0, \"recall\": 0.9741511165494035, \"specificity\": 1.0, \"npv\": 0.9999864704004785, \"accuracy\": 0.9999864772954591, \"f1\": 0.9869063298985047, \"f2\": 0.9792134313213001, \"f0_5\": 0.9947210595364528, \"p4\": 0.9934066834458447, \"phi\": 0.9869842636409779}, {\"truth_threshold\": 3.9000000581145287, \"match_probability\": 0.9372195616099515, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6367.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 171.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9738452126032425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.026154787396757417, \"precision\": 1.0, \"recall\": 0.9738452126032425, \"specificity\": 1.0, \"npv\": 0.9999863102890667, \"accuracy\": 0.9999863172634527, \"f1\": 0.9867493219682294, \"f2\": 0.978966142870322, \"f0_5\": 0.994657251765294, \"p4\": 0.993327096144602, \"phi\": 0.9868292055587877}, {\"truth_threshold\": 4.100000061094761, \"match_probability\": 0.9448986513716398, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6363.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 175.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9732334047109208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02676659528907923, \"precision\": 1.0, \"recall\": 0.9732334047109208, \"specificity\": 1.0, \"npv\": 0.9999859900663967, \"accuracy\": 0.9999859971994399, \"f1\": 0.9864351600651112, \"f2\": 0.9784714747039828, \"f0_5\": 0.9945295404814004, \"p4\": 0.9931678098337335, \"phi\": 0.986519016428746}, {\"truth_threshold\": 4.200000062584877, \"match_probability\": 0.9483982147343843, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6358.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 180.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9724686448455185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.027531355154481494, \"precision\": 1.0, \"recall\": 0.9724686448455185, \"specificity\": 1.0, \"npv\": 0.9999855897883476, \"accuracy\": 0.9999855971194239, \"f1\": 0.9860421836228288, \"f2\": 0.9778529683174408, \"f0_5\": 0.9943697216140132, \"p4\": 0.992968492222042, \"phi\": 0.986131143087227}, {\"truth_threshold\": 4.300000064074993, \"match_probability\": 0.9516868803254299, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6355.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 183.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9720097889262771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02799021107372285, \"precision\": 1.0, \"recall\": 0.9720097889262771, \"specificity\": 1.0, \"npv\": 0.999985349621672, \"accuracy\": 0.9999853570714143, \"f1\": 0.9858062514542775, \"f2\": 0.9774817731565509, \"f0_5\": 0.9942737342762376, \"p4\": 0.9928487896454207, \"phi\": 0.98589834598458}, {\"truth_threshold\": 4.400000065565109, \"match_probability\": 0.9547759482410569, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6354.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 184.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9718568369531967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.028143163046803303, \"precision\": 1.0, \"recall\": 0.9718568369531967, \"specificity\": 1.0, \"npv\": 0.9999852695661391, \"accuracy\": 0.9999852770554111, \"f1\": 0.9857275829972075, \"f2\": 0.9773580262105458, \"f0_5\": 0.9942417224760594, \"p4\": 0.9928088700985888, \"phi\": 0.9858207347587784}, {\"truth_threshold\": 4.6000000685453415, \"match_probability\": 0.9603983391922627, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6351.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 187.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9713979810339554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02860201896604466, \"precision\": 1.0, \"recall\": 0.9713979810339554, \"specificity\": 1.0, \"npv\": 0.9999850293996173, \"accuracy\": 0.9999850370074015, \"f1\": 0.9854915043835829, \"f2\": 0.9769867396855675, \"f0_5\": 0.9941456389706342, \"p4\": 0.99268905534821, \"phi\": 0.985587864486454}, {\"truth_threshold\": 4.700000070035458, \"match_probability\": 0.9629520927573305, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6346.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 192.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9706332211685531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029366778831446925, \"precision\": 1.0, \"recall\": 0.9706332211685531, \"specificity\": 1.0, \"npv\": 0.9999846291223373, \"accuracy\": 0.9999846369273855, \"f1\": 0.9850977957156163, \"f2\": 0.9763677764785526, \"f0_5\": 0.9939853392644571, \"p4\": 0.9924891768671766, \"phi\": 0.9851996252963432}, {\"truth_threshold\": 4.800000071525574, \"match_probability\": 0.9653471069144568, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6344.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 194.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9703273172223922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.02967268277760783, \"precision\": 1.0, \"recall\": 0.9703273172223922, \"specificity\": 1.0, \"npv\": 0.999984469011515, \"accuracy\": 0.9999844768953791, \"f1\": 0.9849402266728768, \"f2\": 0.9761201378631216, \"f0_5\": 0.9939211631259008, \"p4\": 0.9924091598672342, \"phi\": 0.985044286862272}, {\"truth_threshold\": 4.90000007301569, \"match_probability\": 0.9675925026740654, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6342.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 196.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9700214132762313, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.029978586723768737, \"precision\": 1.0, \"recall\": 0.9700214132762313, \"specificity\": 1.0, \"npv\": 0.9999843089007441, \"accuracy\": 0.9999843168633726, \"f1\": 0.9847826086956522, \"f2\": 0.975872468763464, \"f0_5\": 0.9938569548047389, \"p4\": 0.9923291053376769, \"phi\": 0.9848889239777018}, {\"truth_threshold\": 5.000000074505806, \"match_probability\": 0.969696971214501, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6341.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 197.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9698684613031509, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03013153869684919, \"precision\": 1.0, \"recall\": 0.9698684613031509, \"specificity\": 1.0, \"npv\": 0.9999842288453777, \"accuracy\": 0.9999842368473695, \"f1\": 0.9847037813494837, \"f2\": 0.9757486227802912, \"f0_5\": 0.9938248385681149, \"p4\": 0.9922890639910333, \"phi\": 0.9848112333628636}, {\"truth_threshold\": 5.100000075995922, \"match_probability\": 0.9716687817966767, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6338.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 200.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9694096053839094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030590394616090547, \"precision\": 1.0, \"recall\": 0.9694096053839094, \"specificity\": 1.0, \"npv\": 0.9999839886793559, \"accuracy\": 0.9999839967993599, \"f1\": 0.9844672258465362, \"f2\": 0.9753770390889505, \"f0_5\": 0.9937284415177171, \"p4\": 0.9921688835839609, \"phi\": 0.984578124810765}, {\"truth_threshold\": 5.200000077486038, \"match_probability\": 0.9735157914041783, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6336.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 202.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9691037014377486, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.030896298562251453, \"precision\": 1.0, \"recall\": 0.9691037014377486, \"specificity\": 1.0, \"npv\": 0.9999838285687387, \"accuracy\": 0.9999838367673535, \"f1\": 0.9843094609290042, \"f2\": 0.9751292785028318, \"f0_5\": 0.9936641365033562, \"p4\": 0.9920887163068618, \"phi\": 0.9844226885052252}, {\"truth_threshold\": 5.600000083446503, \"match_probability\": 0.9797991767207457, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6334.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 204.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9687977974915877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03120220250841236, \"precision\": 1.0, \"recall\": 0.9687977974915877, \"specificity\": 1.0, \"npv\": 0.9999836684581728, \"accuracy\": 0.999983676735347, \"f1\": 0.9841516469857055, \"f2\": 0.9748814874099612, \"f0_5\": 0.993599799209387, \"p4\": 0.9920085113942668, \"phi\": 0.9842672277028406}, {\"truth_threshold\": 5.700000084936619, \"match_probability\": 0.9811264334957893, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6331.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 207.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9683389415723462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03166105842765372, \"precision\": 1.0, \"recall\": 0.9683389415723462, \"specificity\": 1.0, \"npv\": 0.99998342829242, \"accuracy\": 0.9999834366873375, \"f1\": 0.9839148340974435, \"f2\": 0.9745097435581689, \"f0_5\": 0.9935032326909798, \"p4\": 0.9918881334007732, \"phi\": 0.9840339905422821}, {\"truth_threshold\": 5.800000086426735, \"match_probability\": 0.9823680546749124, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6327.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 211.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9677271336800245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03227286631997553, \"precision\": 1.0, \"recall\": 0.9677271336800245, \"specificity\": 1.0, \"npv\": 0.9999831080715958, \"accuracy\": 0.9999831166233246, \"f1\": 0.9835989117761368, \"f2\": 0.9740139782628775, \"f0_5\": 0.9933743641273629, \"p4\": 0.9917274974373677, \"phi\": 0.9837229218141498}, {\"truth_threshold\": 5.900000087916851, \"match_probability\": 0.9835293654795508, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6326.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 212.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.967574181706944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03242581829305598, \"precision\": 1.0, \"recall\": 0.967574181706944, \"specificity\": 1.0, \"npv\": 0.9999830280164218, \"accuracy\": 0.9999830366073215, \"f1\": 0.9835199004975125, \"f2\": 0.9738900178582425, \"f0_5\": 0.9933421267508322, \"p4\": 0.9916873148579056, \"phi\": 0.9836451392925304}, {\"truth_threshold\": 6.000000089406967, \"match_probability\": 0.9846153855541349, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6317.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 221.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.96619761394922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03380238605078006, \"precision\": 1.0, \"recall\": 0.96619761394922, \"specificity\": 1.0, \"npv\": 0.9999823075204326, \"accuracy\": 0.9999823164632926, \"f1\": 0.9828082458187476, \"f2\": 0.9727740306138163, \"f0_5\": 0.9930516254794692, \"p4\": 0.9913252463480805, \"phi\": 0.9829448201794835}, {\"truth_threshold\": 6.100000090897083, \"match_probability\": 0.985630843183972, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6310.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 228.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9651269501376568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03487304986234322, \"precision\": 1.0, \"recall\": 0.9651269501376568, \"specificity\": 1.0, \"npv\": 0.999981747135381, \"accuracy\": 0.9999817563512703, \"f1\": 0.9822540473225405, \"f2\": 0.9719056127164069, \"f0_5\": 0.9928252249984266, \"p4\": 0.9910431071916149, \"phi\": 0.9823997830853262}, {\"truth_threshold\": 6.200000092387199, \"match_probability\": 0.9865801893041345, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6300.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 238.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9635974304068522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03640256959314775, \"precision\": 1.0, \"recall\": 0.9635974304068522, \"specificity\": 1.0, \"npv\": 0.9999809465863968, \"accuracy\": 0.9999809561912383, \"f1\": 0.9814612868047983, \"f2\": 0.9706643658326143, \"f0_5\": 0.992501102779003, \"p4\": 0.9906392438423233, \"phi\": 0.9816206347599178}, {\"truth_threshold\": 6.3000000938773155, \"match_probability\": 0.987467611228855, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6296.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 242.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9629856225145305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03701437748546956, \"precision\": 1.0, \"recall\": 0.9629856225145305, \"specificity\": 1.0, \"npv\": 0.999980626367162, \"accuracy\": 0.9999806361272254, \"f1\": 0.9811438366838087, \"f2\": 0.9701676528599605, \"f0_5\": 0.9923712250173381, \"p4\": 0.9904774318727086, \"phi\": 0.981308802561483}, {\"truth_threshold\": 6.400000095367432, \"match_probability\": 0.9882970460445225, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6294.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 244.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9626797185683695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03732028143163047, \"precision\": 1.0, \"recall\": 0.9626797185683695, \"specificity\": 1.0, \"npv\": 0.9999804662576216, \"accuracy\": 0.999980476095219, \"f1\": 0.9809850374064838, \"f2\": 0.9699192504468964, \"f0_5\": 0.992306236993126, \"p4\": 0.9903964686450301, \"phi\": 0.9811528493719793}, {\"truth_threshold\": 6.500000096857548, \"match_probability\": 0.9890721936212699, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6292.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 246.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9623738146222086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.037626185377791374, \"precision\": 1.0, \"recall\": 0.9623738146222086, \"specificity\": 1.0, \"npv\": 0.9999803061481324, \"accuracy\": 0.9999803160632127, \"f1\": 0.9808261886204209, \"f2\": 0.9696708174084576, \"f0_5\": 0.992241216173595, \"p4\": 0.9903154672193965, \"phi\": 0.9809968714398952}, {\"truth_threshold\": 6.600000098347664, \"match_probability\": 0.9897965292084853, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6289.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 249.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9619149587029673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03808504129703273, \"precision\": 1.0, \"recall\": 0.9619149587029673, \"specificity\": 1.0, \"npv\": 0.9999800659839947, \"accuracy\": 0.999980076015203, \"f1\": 0.9805878225617838, \"f2\": 0.9692981104158318, \"f0_5\": 0.9921436233987505, \"p4\": 0.9901938934005742, \"phi\": 0.9807628581236061}, {\"truth_threshold\": 6.70000009983778, \"match_probability\": 0.9904733155885336, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6288.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 250.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9617620067298868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03823799327011319, \"precision\": 1.0, \"recall\": 0.9617620067298868, \"specificity\": 1.0, \"npv\": 0.9999799859293077, \"accuracy\": 0.9999799959991998, \"f1\": 0.9805083424294402, \"f2\": 0.969173859432799, \"f0_5\": 0.9921110760492269, \"p4\": 0.9901533496659886, \"phi\": 0.9806848413007591}, {\"truth_threshold\": 6.800000101327896, \"match_probability\": 0.9911056147706719, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6285.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 253.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9613031508106454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.038696849189354544, \"precision\": 1.0, \"recall\": 0.9613031508106454, \"specificity\": 1.0, \"npv\": 0.9999797457653239, \"accuracy\": 0.9999797559511903, \"f1\": 0.9802698276534353, \"f2\": 0.9688010605173105, \"f0_5\": 0.9920133846833765, \"p4\": 0.9900316610298373, \"phi\": 0.9804507536592717}, {\"truth_threshold\": 7.000000104308128, \"match_probability\": 0.9922480625716311, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6284.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 254.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.961150198837565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03884980116243499, \"precision\": 1.0, \"recall\": 0.961150198837565, \"specificity\": 1.0, \"npv\": 0.9999796657106882, \"accuracy\": 0.999979675935187, \"f1\": 0.9801902979254407, \"f2\": 0.9686767788876557, \"f0_5\": 0.9919808044452864, \"p4\": 0.989991078995678, \"phi\": 0.9803727120495296}, {\"truth_threshold\": 7.1000001057982445, \"match_probability\": 0.9927634299608046, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6279.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 259.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9603854389721628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.03961456102783726, \"precision\": 1.0, \"recall\": 0.9603854389721628, \"specificity\": 1.0, \"npv\": 0.9999792654377022, \"accuracy\": 0.999979275855171, \"f1\": 0.979792463134899, \"f2\": 0.9680552557737967, \"f0_5\": 0.9918177797434763, \"p4\": 0.989788025006189, \"phi\": 0.9799824109648337}, {\"truth_threshold\": 7.200000107288361, \"match_probability\": 0.9932447677519157, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6276.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 262.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9599265830529213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04007341694707862, \"precision\": 1.0, \"recall\": 0.9599265830529213, \"specificity\": 1.0, \"npv\": 0.9999790252740645, \"accuracy\": 0.9999790358071614, \"f1\": 0.9795536132355237, \"f2\": 0.9676822499074873, \"f0_5\": 0.9917198660008849, \"p4\": 0.9896660774350681, \"phi\": 0.9797481558318564}, {\"truth_threshold\": 7.300000108778477, \"match_probability\": 0.9936942928922654, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6274.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 264.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9596206791067605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04037932089323952, \"precision\": 1.0, \"recall\": 0.9596206791067605, \"specificity\": 1.0, \"npv\": 0.9999788651650366, \"accuracy\": 0.999978875775155, \"f1\": 0.9793943178270371, \"f2\": 0.9674335409856288, \"f0_5\": 0.9916545489030789, \"p4\": 0.9895847310069513, \"phi\": 0.9795919546842348}, {\"truth_threshold\": 7.400000110268593, \"match_probability\": 0.9941140817673122, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6270.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 268.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9590088712144387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04099112878556133, \"precision\": 1.0, \"recall\": 0.9590088712144387, \"specificity\": 1.0, \"npv\": 0.9999785449471349, \"accuracy\": 0.9999785557111422, \"f1\": 0.9790755777638975, \"f2\": 0.9669360310900006, \"f0_5\": 0.9915238155481055, \"p4\": 0.9894219227141949, \"phi\": 0.9792794777939589}, {\"truth_threshold\": 7.500000111758709, \"match_probability\": 0.9945060786121668, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6267.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 271.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9585500152951973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04144998470480269, \"precision\": 1.0, \"recall\": 0.9585500152951973, \"specificity\": 1.0, \"npv\": 0.9999783047838432, \"accuracy\": 0.9999783156631327, \"f1\": 0.9788363920343616, \"f2\": 0.9665628181004966, \"f0_5\": 0.9914256786686072, \"p4\": 0.9892997153800354, \"phi\": 0.9790450548087244}, {\"truth_threshold\": 7.600000113248825, \"match_probability\": 0.9948721034855129, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6263.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 275.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9579382074028755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0420617925971245, \"precision\": 1.0, \"recall\": 0.9579382074028755, \"specificity\": 1.0, \"npv\": 0.9999779845663004, \"accuracy\": 0.9999779955991198, \"f1\": 0.9785173033356769, \"f2\": 0.9660650933209933, \"f0_5\": 0.9912947135169358, \"p4\": 0.9891366372726919, \"phi\": 0.9787324036618906}, {\"truth_threshold\": 7.700000114738941, \"match_probability\": 0.9952138598197071, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6261.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 277.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9576323034567146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.042367696543285406, \"precision\": 1.0, \"recall\": 0.9576323034567146, \"specificity\": 1.0, \"npv\": 0.9999778244576059, \"accuracy\": 0.9999778355671134, \"f1\": 0.9783576841940776, \"f2\": 0.9658161848640977, \"f0_5\": 0.9912291811791527, \"p4\": 0.9890550403022689, \"phi\": 0.9785760407045389}, {\"truth_threshold\": 7.800000116229057, \"match_probability\": 0.9955329415617687, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6260.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 278.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9574793514836342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04252064851636586, \"precision\": 1.0, \"recall\": 0.9574793514836342, \"specificity\": 1.0, \"npv\": 0.9999777444032778, \"accuracy\": 0.9999777555511102, \"f1\": 0.9782778559149867, \"f2\": 0.9656917191163766, \"f0_5\": 0.9911964025587434, \"p4\": 0.9890142273258592, \"phi\": 0.9784978498746523}, {\"truth_threshold\": 7.900000117719173, \"match_probability\": 0.99583083992065, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6255.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 283.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9567145916182319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04328540838176812, \"precision\": 1.0, \"recall\": 0.9567145916182319, \"specificity\": 1.0, \"npv\": 0.9999773441318299, \"accuracy\": 0.9999773554710942, \"f1\": 0.9778785273196279, \"f2\": 0.965069275156602, \"f0_5\": 0.9910323848152608, \"p4\": 0.98881001739437, \"phi\": 0.9781068021533068}, {\"truth_threshold\": 8.00000011920929, \"match_probability\": 0.9961089497366072, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6250.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 288.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9559498317528297, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04405016824717039, \"precision\": 1.0, \"recall\": 0.9559498317528297, \"specificity\": 1.0, \"npv\": 0.9999769438607025, \"accuracy\": 0.9999769553910782, \"f1\": 0.9774788864560525, \"f2\": 0.9644466390963521, \"f0_5\": 0.9908681590462299, \"p4\": 0.9886055653983197, \"phi\": 0.9777155983415358}, {\"truth_threshold\": 8.200000122189522, \"match_probability\": 0.9966109369567457, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6244.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 294.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9550321199143469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.044967880085653104, \"precision\": 1.0, \"recall\": 0.9550321199143469, \"specificity\": 1.0, \"npv\": 0.9999764635357725, \"accuracy\": 0.9999764752950591, \"f1\": 0.976998904709748, \"f2\": 0.9636992221261884, \"f0_5\": 0.9906708129720124, \"p4\": 0.9883599028708685, \"phi\": 0.9772459474641072}, {\"truth_threshold\": 8.300000123679638, \"match_probability\": 0.9968371745531442, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6239.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 299.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9542673600489446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04573263995105537, \"precision\": 1.0, \"recall\": 0.9542673600489446, \"specificity\": 1.0, \"npv\": 0.99997606326535, \"accuracy\": 0.9999760752150431, \"f1\": 0.9765985755654693, \"f2\": 0.9630761631317342, \"f0_5\": 0.9905061281513939, \"p4\": 0.9881549168140965, \"phi\": 0.9768543995930827}, {\"truth_threshold\": 8.400000125169754, \"match_probability\": 0.9970483543414643, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6226.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 312.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9522789843988988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04772101560110126, \"precision\": 1.0, \"recall\": 0.9522789843988988, \"specificity\": 1.0, \"npv\": 0.9999750225637513, \"accuracy\": 0.9999750350070014, \"f1\": 0.9755562519586336, \"f2\": 0.9614553091605411, \"f0_5\": 0.9900769671140512, \"p4\": 0.9876208126478083, \"phi\": 0.9758356413409355}, {\"truth_threshold\": 8.600000128149986, \"match_probability\": 0.9974294610402847, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6223.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 315.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9518201284796574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.048179871520342615, \"precision\": 1.0, \"recall\": 0.9518201284796574, \"specificity\": 1.0, \"npv\": 0.9999747824021515, \"accuracy\": 0.9999747949589918, \"f1\": 0.9753154141524959, \"f2\": 0.961081081081081, \"f0_5\": 0.9899777282850779, \"p4\": 0.9874973233234631, \"phi\": 0.9756003925083432}, {\"truth_threshold\": 8.700000129640102, \"match_probability\": 0.997601189412643, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6220.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 318.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.951361272560416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04863872743958397, \"precision\": 1.0, \"recall\": 0.951361272560416, \"specificity\": 1.0, \"npv\": 0.9999745422406671, \"accuracy\": 0.9999745549109822, \"f1\": 0.9750744630819878, \"f2\": 0.9607067836401829, \"f0_5\": 0.9898784136482272, \"p4\": 0.987373745856392, \"phi\": 0.9753650870489985}, {\"truth_threshold\": 8.800000131130219, \"match_probability\": 0.997761470983937, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6219.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 319.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9512083205873356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.04879167941266442, \"precision\": 1.0, \"recall\": 0.9512083205873356, \"specificity\": 1.0, \"npv\": 0.9999744621868646, \"accuracy\": 0.999974474894979, \"f1\": 0.9749941208748139, \"f2\": 0.9605820024095642, \"f0_5\": 0.9898452919080665, \"p4\": 0.987332533763769, \"phi\": 0.9752866393050771}, {\"truth_threshold\": 8.900000132620335, \"match_probability\": 0.9979110654305032, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6218.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 320.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9510553686142551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.048944631385744876, \"precision\": 1.0, \"recall\": 0.9510553686142551, \"specificity\": 1.0, \"npv\": 0.9999743821330749, \"accuracy\": 0.9999743948789758, \"f1\": 0.9749137660708687, \"f2\": 0.9604572134692617, \"f0_5\": 0.9898121617319325, \"p4\": 0.9872913118635096, \"phi\": 0.9752081852632205}, {\"truth_threshold\": 9.00000013411045, \"match_probability\": 0.9980506824420605, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6202.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 336.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9486081370449678, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05139186295503212, \"precision\": 1.0, \"recall\": 0.9486081370449678, \"specificity\": 1.0, \"npv\": 0.999973101274183, \"accuracy\": 0.9999731146229246, \"f1\": 0.9736263736263736, \"f2\": 0.9584595413241022, \"f0_5\": 0.9892809289861545, \"p4\": 0.9866304247560589, \"phi\": 0.9739520628320378}, {\"truth_threshold\": 9.100000135600567, \"match_probability\": 0.9981809849551747, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6191.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 347.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9469256653410829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0530743346589171, \"precision\": 1.0, \"recall\": 0.9469256653410829, \"specificity\": 1.0, \"npv\": 0.9999722206855983, \"accuracy\": 0.9999722344468894, \"f1\": 0.9727394139366801, \"f2\": 0.9570849952076184, \"f0_5\": 0.9889144463612549, \"p4\": 0.986174600424879, \"phi\": 0.9730875399445367}, {\"truth_threshold\": 9.200000137090683, \"match_probability\": 0.9983025921847976, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6186.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 352.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9461609054756807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05383909452431936, \"precision\": 1.0, \"recall\": 0.9461609054756807, \"specificity\": 1.0, \"npv\": 0.9999718204185725, \"accuracy\": 0.9999718343668734, \"f1\": 0.9723357434768941, \"f2\": 0.9564598923866658, \"f0_5\": 0.9887475225369222, \"p4\": 0.985967011574786, \"phi\": 0.972694321489234}, {\"truth_threshold\": 9.300000138580799, \"match_probability\": 0.9984160824655384, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6183.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 355.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9457020495564393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05429795044356072, \"precision\": 1.0, \"recall\": 0.9457020495564393, \"specificity\": 1.0, \"npv\": 0.9999715802585107, \"accuracy\": 0.9999715943188637, \"f1\": 0.9720933888845217, \"f2\": 0.9560847379001083, \"f0_5\": 0.98864726574992, \"p4\": 0.9858423392031227, \"phi\": 0.9724583142472819}, {\"truth_threshold\": 9.400000140070915, \"match_probability\": 0.9985219959137808, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6180.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 358.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9452431936371979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05475680636280208, \"precision\": 1.0, \"recall\": 0.9452431936371979, \"specificity\": 1.0, \"npv\": 0.9999713400985645, \"accuracy\": 0.9999713542708542, \"f1\": 0.971850919955968, \"f2\": 0.9557095137943833, \"f0_5\": 0.9885469319854118, \"p4\": 0.9857175774177425, \"phi\": 0.9722222498279062}, {\"truth_threshold\": 9.500000141561031, \"match_probability\": 0.9986208369212233, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6165.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 373.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9429489140409911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.057051085959008874, \"precision\": 1.0, \"recall\": 0.9429489140409911, \"specificity\": 1.0, \"npv\": 0.9999701393005631, \"accuracy\": 0.9999701540308061, \"f1\": 0.9706368574352515, \"f2\": 0.9538323482996566, \"f0_5\": 0.9880441053913712, \"p4\": 0.9850924239094961, \"phi\": 0.9710410686098115}, {\"truth_threshold\": 9.600000143051147, \"match_probability\": 0.9987130764898899, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6158.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 380.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.941878250229428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05812174977057204, \"precision\": 1.0, \"recall\": 0.941878250229428, \"specificity\": 1.0, \"npv\": 0.9999695789291495, \"accuracy\": 0.9999695939187837, \"f1\": 0.9700693131695022, \"f2\": 0.9529557412565769, \"f0_5\": 0.9878087905036894, \"p4\": 0.9847999163965238, \"phi\": 0.9704893596966662}, {\"truth_threshold\": 9.700000144541264, \"match_probability\": 0.9987991544181472, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6151.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 387.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9408075864178648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.05919241358213521, \"precision\": 1.0, \"recall\": 0.9408075864178648, \"specificity\": 1.0, \"npv\": 0.9999690185583638, \"accuracy\": 0.9999690338067614, \"f1\": 0.9695011427220427, \"f2\": 0.9520787542952667, \"f0_5\": 0.987573052469334, \"p4\": 0.9845069176826701, \"phi\": 0.9699373375855448}, {\"truth_threshold\": 9.80000014603138, \"match_probability\": 0.9988794813467569, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6143.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 395.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9395839706332212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06041602936677883, \"precision\": 1.0, \"recall\": 0.9395839706332212, \"specificity\": 1.0, \"npv\": 0.999968378135378, \"accuracy\": 0.9999683936787358, \"f1\": 0.968851036984465, \"f2\": 0.9510760179594364, \"f0_5\": 0.9873031179684989, \"p4\": 0.9841714589491495, \"phi\": 0.9693060709786671}, {\"truth_threshold\": 9.900000147521496, \"match_probability\": 0.9989544406735176, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6139.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 399.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9389721627408993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.061027837259100645, \"precision\": 1.0, \"recall\": 0.9389721627408993, \"specificity\": 1.0, \"npv\": 0.9999680579241925, \"accuracy\": 0.999968073614723, \"f1\": 0.9685256764218664, \"f2\": 0.9505744634727943, \"f0_5\": 0.9871679423683025, \"p4\": 0.9840034878071545, \"phi\": 0.9689902837597992}, {\"truth_threshold\": 10.100000150501728, \"match_probability\": 0.9990896645300149, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6137.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 401.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9386662587947384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06133374120526155, \"precision\": 1.0, \"recall\": 0.9386662587947384, \"specificity\": 1.0, \"npv\": 0.9999678978186768, \"accuracy\": 0.9999679135827165, \"f1\": 0.9683629191321499, \"f2\": 0.9503236396295952, \"f0_5\": 0.9871003023869266, \"p4\": 0.983919441690589, \"phi\": 0.9688323516276159}, {\"truth_threshold\": 10.200000151991844, \"match_probability\": 0.9991505751910027, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6120.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 418.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9360660752523707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06393392474762924, \"precision\": 1.0, \"recall\": 0.9360660752523707, \"specificity\": 1.0, \"npv\": 0.9999665369238627, \"accuracy\": 0.9999665533106621, \"f1\": 0.9669774055933007, \"f2\": 0.9481903817550819, \"f0_5\": 0.9865239538332581, \"p4\": 0.9832034154982748, \"phi\": 0.9674888896530156}, {\"truth_threshold\": 10.30000015348196, \"match_probability\": 0.9992074135451509, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6113.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 425.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9349954114408076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06500458855919242, \"precision\": 1.0, \"recall\": 0.9349954114408076, \"specificity\": 1.0, \"npv\": 0.9999659765564864, \"accuracy\": 0.9999659931986398, \"f1\": 0.9664058177219192, \"f2\": 0.9473113280644662, \"f0_5\": 0.9862858986769926, \"p4\": 0.9829077285313954, \"phi\": 0.9669351579486812}, {\"truth_threshold\": 10.400000154972076, \"match_probability\": 0.9992604514366183, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6105.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 433.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.933771795656164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06622820434383604, \"precision\": 1.0, \"recall\": 0.933771795656164, \"specificity\": 1.0, \"npv\": 0.999965336137397, \"accuracy\": 0.9999653530706141, \"f1\": 0.9657517994146959, \"f2\": 0.9463062281055274, \"f0_5\": 0.9860133083532528, \"p4\": 0.98256918917914, \"phi\": 0.9663019339310756}, {\"truth_threshold\": 10.500000156462193, \"match_probability\": 0.9993099426168967, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6100.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 438.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9330070357907617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0669929642092383, \"precision\": 1.0, \"recall\": 0.9330070357907617, \"specificity\": 1.0, \"npv\": 0.9999649358758826, \"accuracy\": 0.9999649529905981, \"f1\": 0.9653426175027694, \"f2\": 0.9456777874240357, \"f0_5\": 0.9858426530480315, \"p4\": 0.9823572701142986, \"phi\": 0.9659059585261166}, {\"truth_threshold\": 10.600000157952309, \"match_probability\": 0.9993561239419685, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6094.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 444.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.932089323952279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06791067604772101, \"precision\": 1.0, \"recall\": 0.932089323952279, \"specificity\": 1.0, \"npv\": 0.9999644555624884, \"accuracy\": 0.9999644728945789, \"f1\": 0.9648511716276124, \"f2\": 0.9449234013521057, \"f0_5\": 0.9856375752086434, \"p4\": 0.9821026293854247, \"phi\": 0.9654305740764317}, {\"truth_threshold\": 10.700000159442425, \"match_probability\": 0.9993992164911604, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6089.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 449.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9313245640868767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06867543591312328, \"precision\": 1.0, \"recall\": 0.9313245640868767, \"specificity\": 1.0, \"npv\": 0.9999640553016789, \"accuracy\": 0.9999640728145629, \"f1\": 0.9644412766294448, \"f2\": 0.944294531807326, \"f0_5\": 0.9854664336117045, \"p4\": 0.9818901466906317, \"phi\": 0.9650342418310252}, {\"truth_threshold\": 10.800000160932541, \"match_probability\": 0.9994394266126935, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6084.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 454.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9305598042214744, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.06944019577852555, \"precision\": 1.0, \"recall\": 0.9305598042214744, \"specificity\": 1.0, \"npv\": 0.9999636550411899, \"accuracy\": 0.9999636727345469, \"f1\": 0.9640310568848043, \"f2\": 0.9436654671795508, \"f0_5\": 0.9852950702856773, \"p4\": 0.9816774070561771, \"phi\": 0.9646377470655602}, {\"truth_threshold\": 10.900000162422657, \"match_probability\": 0.9994769469006325, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6078.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 460.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9296420923829918, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07035790761700826, \"precision\": 1.0, \"recall\": 0.9296420923829918, \"specificity\": 1.0, \"npv\": 0.9999631747290261, \"accuracy\": 0.9999631926385277, \"f1\": 0.9635383639822448, \"f2\": 0.9429103319888302, \"f0_5\": 0.9850891410048622, \"p4\": 0.9814217796772566, \"phi\": 0.9641617385382139}, {\"truth_threshold\": 11.000000163912773, \"match_probability\": 0.9995119571076428, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6073.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 465.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9288773325175895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07112266748241053, \"precision\": 1.0, \"recall\": 0.9288773325175895, \"specificity\": 1.0, \"npv\": 0.999962774469242, \"accuracy\": 0.9999627925585117, \"f1\": 0.9631274284354928, \"f2\": 0.9422808378588052, \"f0_5\": 0.9849172883554979, \"p4\": 0.9812084731310984, \"phi\": 0.9637648855223339}, {\"truth_threshold\": 11.10000016540289, \"match_probability\": 0.9995446249976983, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6070.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 468.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9284184765983481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07158152340165189, \"precision\": 1.0, \"recall\": 0.9284184765983481, \"specificity\": 1.0, \"npv\": 0.9999625343135253, \"accuracy\": 0.9999625525105021, \"f1\": 0.9628807106598984, \"f2\": 0.9419030476072249, \"f0_5\": 0.9848140696995262, \"p4\": 0.981080365183647, \"phi\": 0.9635266954074426}, {\"truth_threshold\": 11.200000166893005, \"match_probability\": 0.9995751071426191, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6067.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 471.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9279596206791068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07204037932089324, \"precision\": 1.0, \"recall\": 0.9279596206791068, \"specificity\": 1.0, \"npv\": 0.999962294157924, \"accuracy\": 0.9999623124624925, \"f1\": 0.9626338754462515, \"f2\": 0.9415251870014588, \"f0_5\": 0.9847107706290982, \"p4\": 0.980952164097296, \"phi\": 0.9632884465102841}, {\"truth_threshold\": 11.300000168383121, \"match_probability\": 0.9996035496660847, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6058.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 480.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9265830529213827, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07341694707861732, \"precision\": 1.0, \"recall\": 0.9265830529213827, \"specificity\": 1.0, \"npv\": 0.9999615736918124, \"accuracy\": 0.9999615923184637, \"f1\": 0.961892664337885, \"f2\": 0.940391182862465, \"f0_5\": 0.9844003899902503, \"p4\": 0.9805670009871579, \"phi\": 0.9625733466886717}, {\"truth_threshold\": 11.400000169873238, \"match_probability\": 0.99963008893853, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6051.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 487.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9255123891098195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07448761089018048, \"precision\": 1.0, \"recall\": 0.9255123891098195, \"specificity\": 1.0, \"npv\": 0.9999610133299988, \"accuracy\": 0.9999610322064413, \"f1\": 0.9613154341091429, \"f2\": 0.9395087414216067, \"f0_5\": 0.9841584802550257, \"p4\": 0.9802668477525769, \"phi\": 0.9620167911547713}, {\"truth_threshold\": 11.500000171363354, \"match_probability\": 0.999654852226126, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6043.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 495.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9242887733251759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0757112266748241, \"precision\": 1.0, \"recall\": 0.9242887733251759, \"specificity\": 1.0, \"npv\": 0.9999603729172666, \"accuracy\": 0.9999603920784157, \"f1\": 0.9606549558858596, \"f2\": 0.9384997670445722, \"f0_5\": 0.983881471833279, \"p4\": 0.9799231901715827, \"phi\": 0.9613803339248654}, {\"truth_threshold\": 11.60000017285347, \"match_probability\": 0.9996779582968373, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6041.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 497.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.923982869379015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07601713062098502, \"precision\": 1.0, \"recall\": 0.923982869379015, \"specificity\": 1.0, \"npv\": 0.9999602128142117, \"accuracy\": 0.9999602320464093, \"f1\": 0.9604897050639956, \"f2\": 0.9382474450967602, \"f0_5\": 0.9838121295029639, \"p4\": 0.9798371713419749, \"phi\": 0.9612211538979599}, {\"truth_threshold\": 11.700000174343586, \"match_probability\": 0.9996995179863626, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6037.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 501.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9233710614866931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07662893851330682, \"precision\": 1.0, \"recall\": 0.9233710614866931, \"specificity\": 1.0, \"npv\": 0.9999598926082557, \"accuracy\": 0.9999599119823965, \"f1\": 0.9601590457256461, \"f2\": 0.9377427071359782, \"f0_5\": 0.9836733363748941, \"p4\": 0.9796650081479773, \"phi\": 0.9609027148893924}, {\"truth_threshold\": 11.800000175833702, \"match_probability\": 0.9997196347265854, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6034.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 504.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9229122055674518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.07708779443254818, \"precision\": 1.0, \"recall\": 0.9229122055674518, \"specificity\": 1.0, \"npv\": 0.9999596524539234, \"accuracy\": 0.9999596719343868, \"f1\": 0.9599109131403119, \"f2\": 0.9373640713353631, \"f0_5\": 0.9835691465084436, \"p4\": 0.9795357757891738, \"phi\": 0.9606638164960274}, {\"truth_threshold\": 11.900000177323818, \"match_probability\": 0.9997384050389891, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6009.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 529.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9190884062404405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0809115937595595, \"precision\": 1.0, \"recall\": 0.9190884062404405, \"specificity\": 1.0, \"npv\": 0.9999576511723061, \"accuracy\": 0.9999576715343068, \"f1\": 0.9578385271379612, \"f2\": 0.9342060259320295, \"f0_5\": 0.9826977170144567, \"p4\": 0.9784551596968617, \"phi\": 0.9586706858582299}, {\"truth_threshold\": 12.000000178813934, \"match_probability\": 0.9997559189953416, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 6002.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 536.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9180177424288773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08198225757112267, \"precision\": 1.0, \"recall\": 0.9180177424288773, \"specificity\": 1.0, \"npv\": 0.9999570908148887, \"accuracy\": 0.9999571114222845, \"f1\": 0.9572567783094099, \"f2\": 0.9333208932014679, \"f0_5\": 0.9824526942971257, \"p4\": 0.978151404627144, \"phi\": 0.9581118677042009}, {\"truth_threshold\": 12.10000018030405, \"match_probability\": 0.9997722606477963, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5994.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 544.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9167941266442338, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08320587335576629, \"precision\": 1.0, \"recall\": 0.9167941266442338, \"specificity\": 1.0, \"npv\": 0.9999564504071807, \"accuracy\": 0.9999564712942588, \"f1\": 0.9565911267156081, \"f2\": 0.9323088409133329, \"f0_5\": 0.9821721177164581, \"p4\": 0.9778036193590798, \"phi\": 0.9574728197882796}, {\"truth_threshold\": 12.200000181794167, \"match_probability\": 0.9997875084304283, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5990.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 548.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9161823187519119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0838176812480881, \"precision\": 1.0, \"recall\": 0.9161823187519119, \"specificity\": 1.0, \"npv\": 0.9999561302036343, \"accuracy\": 0.9999561512302461, \"f1\": 0.9562579821200511, \"f2\": 0.9318026258478004, \"f0_5\": 0.9820316086300741, \"p4\": 0.9776294714859775, \"phi\": 0.957153136138703}, {\"truth_threshold\": 12.300000183284283, \"match_probability\": 0.9998017355340825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5977.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 561.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.914193943101866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08580605689813399, \"precision\": 1.0, \"recall\": 0.914193943101866, \"specificity\": 1.0, \"npv\": 0.9999550895435249, \"accuracy\": 0.9999551110222045, \"f1\": 0.9551737914502597, \"f2\": 0.9301565563820847, \"f0_5\": 0.9815739341785457, \"p4\": 0.9770623121329545, \"phi\": 0.9561134274941309}, {\"truth_threshold\": 12.400000184774399, \"match_probability\": 0.9998150102562988, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5971.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 567.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9132762312633833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0867237687366167, \"precision\": 1.0, \"recall\": 0.9132762312633833, \"specificity\": 1.0, \"npv\": 0.9999546092395895, \"accuracy\": 0.9999546309261852, \"f1\": 0.9546726357022943, \"f2\": 0.929396382654173, \"f0_5\": 0.9813621721122872, \"p4\": 0.9767999365107534, \"phi\": 0.9556331811740222}, {\"truth_threshold\": 12.500000186264515, \"match_probability\": 0.9998273963279586, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5960.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 578.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9115937595594983, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08840624044050169, \"precision\": 1.0, \"recall\": 0.9115937595594983, \"specificity\": 1.0, \"npv\": 0.999953728683573, \"accuracy\": 0.99995375075015, \"f1\": 0.9537526004160666, \"f2\": 0.9280019930244146, \"f0_5\": 0.9809730726183422, \"p4\": 0.9763179106180604, \"phi\": 0.9547521033840131}, {\"truth_threshold\": 12.600000187754631, \"match_probability\": 0.9998389532181915, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5955.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 583.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.910828999694096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.08917100030590394, \"precision\": 1.0, \"recall\": 0.910828999694096, \"specificity\": 1.0, \"npv\": 0.999953328431351, \"accuracy\": 0.999953350670134, \"f1\": 0.9533338669655007, \"f2\": 0.927367863705734, \"f0_5\": 0.9807958363528559, \"p4\": 0.9760983772939974, \"phi\": 0.954351345090428}, {\"truth_threshold\": 12.700000189244747, \"match_probability\": 0.9998497364189812, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5949.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 589.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9099112878556134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09008871214438666, \"precision\": 1.0, \"recall\": 0.9099112878556134, \"specificity\": 1.0, \"npv\": 0.9999528481291075, \"accuracy\": 0.9999528705741149, \"f1\": 0.9528309441819492, \"f2\": 0.9266066477679823, \"f0_5\": 0.9805828443330916, \"p4\": 0.9758345810608682, \"phi\": 0.9538702133078926}, {\"truth_threshold\": 12.800000190734863, \"match_probability\": 0.9998597977108138, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5943.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 595.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9089935760171306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09100642398286937, \"precision\": 1.0, \"recall\": 0.9089935760171306, \"specificity\": 1.0, \"npv\": 0.9999523678273253, \"accuracy\": 0.9999523904780956, \"f1\": 0.9523275378575434, \"f2\": 0.925845147219193, \"f0_5\": 0.9803695150115473, \"p4\": 0.9755703953841924, \"phi\": 0.9533888391827111}, {\"truth_threshold\": 13.000000193715096, \"match_probability\": 0.9998779446032292, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5925.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 613.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9062404405016825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09375955949831753, \"precision\": 1.0, \"recall\": 0.9062404405016825, \"specificity\": 1.0, \"npv\": 0.9999509269247473, \"accuracy\": 0.999950950190038, \"f1\": 0.9508144106555404, \"f2\": 0.9235589363095053, \"f0_5\": 0.9797274952047093, \"p4\": 0.9747754930426697, \"phi\": 0.9519432590739579}, {\"truth_threshold\": 13.100000195205212, \"match_probability\": 0.9998861173572945, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5918.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 620.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9051697766901193, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0948302233098807, \"precision\": 1.0, \"recall\": 0.9051697766901193, \"specificity\": 1.0, \"npv\": 0.9999503665748661, \"accuracy\": 0.9999503900780156, \"f1\": 0.9502247912652537, \"f2\": 0.9226691612098534, \"f0_5\": 0.9794769943727243, \"p4\": 0.9744654106484961, \"phi\": 0.951380496969417}, {\"truth_threshold\": 13.200000196695328, \"match_probability\": 0.9998937429269453, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5909.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 629.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9037932089323952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09620679106760477, \"precision\": 1.0, \"recall\": 0.9037932089323952, \"specificity\": 1.0, \"npv\": 0.9999496461259418, \"accuracy\": 0.9999496699339868, \"f1\": 0.9494657347151925, \"f2\": 0.9215245937431771, \"f0_5\": 0.9791542387485915, \"p4\": 0.9740659452218975, \"phi\": 0.9506564571089694}, {\"truth_threshold\": 13.300000198185444, \"match_probability\": 0.9999008579398913, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5897.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 641.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9019577852554298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.0980422147445702, \"precision\": 1.0, \"recall\": 0.9019577852554298, \"specificity\": 1.0, \"npv\": 0.999948685528991, \"accuracy\": 0.9999487097419484, \"f1\": 0.9484519501407318, \"f2\": 0.9199975038222722, \"f0_5\": 0.9787226980017261, \"p4\": 0.9735319407618789, \"phi\": 0.9496902135795686}, {\"truth_threshold\": 13.40000019967556, \"match_probability\": 0.999907496573012, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5887.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 651.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.9004282655246253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.09957173447537473, \"precision\": 1.0, \"recall\": 0.9004282655246253, \"specificity\": 1.0, \"npv\": 0.9999478850329417, \"accuracy\": 0.9999479095819164, \"f1\": 0.9476056338028169, \"f2\": 0.9187240550578982, \"f0_5\": 0.9783620288506282, \"p4\": 0.9730857242427854, \"phi\": 0.9488842604528905}, {\"truth_threshold\": 13.500000201165676, \"match_probability\": 0.9999136907162209, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5884.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 654.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.899969409605384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10003059039461609, \"precision\": 1.0, \"recall\": 0.899969409605384, \"specificity\": 1.0, \"npv\": 0.9999476448843768, \"accuracy\": 0.9999476695339068, \"f1\": 0.9473514731927226, \"f2\": 0.9183418654014234, \"f0_5\": 0.9782536410188203, \"p4\": 0.9729516436236364, \"phi\": 0.9486423412450483}, {\"truth_threshold\": 13.600000202655792, \"match_probability\": 0.9999194701253888, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5880.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 658.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8993576017130621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1006423982869379, \"precision\": 1.0, \"recall\": 0.8993576017130621, \"specificity\": 1.0, \"npv\": 0.9999473246864699, \"accuracy\": 0.9999473494698939, \"f1\": 0.9470124013528749, \"f2\": 0.9178321678321678, \"f0_5\": 0.9781089892873778, \"p4\": 0.9727727143028713, \"phi\": 0.9483196864820513}, {\"truth_threshold\": 13.700000204145908, \"match_probability\": 0.9999248625650565, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5878.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 660.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8990516977669012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10094830223309881, \"precision\": 1.0, \"recall\": 0.8990516977669012, \"specificity\": 1.0, \"npv\": 0.9999471645875931, \"accuracy\": 0.9999471894378876, \"f1\": 0.9468427835051546, \"f2\": 0.9175772713081486, \"f0_5\": 0.9780366056572379, \"p4\": 0.972683183070249, \"phi\": 0.9481583180037364}, {\"truth_threshold\": 13.800000205636024, \"match_probability\": 0.999929893941616, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5862.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 676.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8966044661976139, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10339553380238604, \"precision\": 1.0, \"recall\": 0.8966044661976139, \"specificity\": 1.0, \"npv\": 0.9999458837984257, \"accuracy\": 0.9999459091818363, \"f1\": 0.9454838709677419, \"f2\": 0.9155369525832449, \"f0_5\": 0.9774561462015607, \"p4\": 0.9719653311040605, \"phi\": 0.9468663820041289}, {\"truth_threshold\": 13.90000020712614, \"match_probability\": 0.9999345884275949, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5859.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 679.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8961456102783726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10385438972162742, \"precision\": 1.0, \"recall\": 0.8961456102783726, \"specificity\": 1.0, \"npv\": 0.9999456436508222, \"accuracy\": 0.9999456691338268, \"f1\": 0.9452286843591191, \"f2\": 0.9151541657555216, \"f0_5\": 0.9773470340962167, \"p4\": 0.9718304159486504, \"phi\": 0.9466239480779398}, {\"truth_threshold\": 14.000000208616257, \"match_probability\": 0.9999389685776376, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5853.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 685.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8952278984398899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10477210156011013, \"precision\": 1.0, \"recall\": 0.8952278984398899, \"specificity\": 1.0, \"npv\": 0.999945163355961, \"accuracy\": 0.9999451890378076, \"f1\": 0.9447179404406424, \"f2\": 0.9143883768161225, \"f0_5\": 0.9771285475792988, \"p4\": 0.9715602835208209, \"phi\": 0.9461388942149505}, {\"truth_threshold\": 14.100000210106373, \"match_probability\": 0.9999430554367367, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5822.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 716.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8904863872743959, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10951361272560416, \"precision\": 1.0, \"recall\": 0.8904863872743959, \"specificity\": 1.0, \"npv\": 0.9999426818398617, \"accuracy\": 0.9999427085417083, \"f1\": 0.9420711974110032, \"f2\": 0.9104272221179709, \"f0_5\": 0.9759940991081607, \"p4\": 0.9701581500386668, \"phi\": 0.9436288180386656}, {\"truth_threshold\": 14.200000211596489, \"match_probability\": 0.9999468686412301, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5820.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 718.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.890180483328235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.10981951667176507, \"precision\": 1.0, \"recall\": 0.890180483328235, \"specificity\": 1.0, \"npv\": 0.9999425217424718, \"accuracy\": 0.999942548509702, \"f1\": 0.9418999838161515, \"f2\": 0.9101713999749781, \"f0_5\": 0.9759205848816151, \"p4\": 0.9700673169044299, \"phi\": 0.9434666487508542}, {\"truth_threshold\": 14.300000213086605, \"match_probability\": 0.9999504265130488, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5815.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 723.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8894157234628327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11058427653716733, \"precision\": 1.0, \"recall\": 0.8894157234628327, \"specificity\": 1.0, \"npv\": 0.9999421214992212, \"accuracy\": 0.999942148429686, \"f1\": 0.9414717072775844, \"f2\": 0.9095317045703382, \"f0_5\": 0.9757366266192362, \"p4\": 0.9698400353736943, \"phi\": 0.9430611037542528}, {\"truth_threshold\": 14.400000214576721, \"match_probability\": 0.9999537461476637, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5804.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 734.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8877332517589477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1122667482410523, \"precision\": 1.0, \"recall\": 0.8877332517589477, \"specificity\": 1.0, \"npv\": 0.999941240965198, \"accuracy\": 0.9999412682536507, \"f1\": 0.9405282774266731, \"f2\": 0.9081236700463137, \"f0_5\": 0.9753310479263292, \"p4\": 0.9693390146004243, \"phi\": 0.9421682914479306}, {\"truth_threshold\": 14.500000216066837, \"match_probability\": 0.9999568434961527, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5802.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 736.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8874273478127868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11257265218721321, \"precision\": 1.0, \"recall\": 0.8874273478127868, \"specificity\": 1.0, \"npv\": 0.9999410808682695, \"accuracy\": 0.9999411082216443, \"f1\": 0.9403565640194489, \"f2\": 0.9078675596169493, \"f0_5\": 0.9752571774356216, \"p4\": 0.969247771645796, \"phi\": 0.9420058711940068}, {\"truth_threshold\": 14.600000217556953, \"match_probability\": 0.9999597334417798, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5794.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 744.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8862037320281432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11379626797185684, \"precision\": 1.0, \"recall\": 0.8862037320281432, \"specificity\": 1.0, \"npv\": 0.999940440481068, \"accuracy\": 0.9999404680936187, \"f1\": 0.9396691534219915, \"f2\": 0.9068427972203092, \"f0_5\": 0.9749612977047856, \"p4\": 0.9688823424146347, \"phi\": 0.9413559104611751}, {\"truth_threshold\": 14.70000021904707, \"match_probability\": 0.9999624298714548, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5785.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 753.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8848271642704191, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11517283572958091, \"precision\": 1.0, \"recall\": 0.8848271642704191, \"specificity\": 1.0, \"npv\": 0.9999397200464468, \"accuracy\": 0.99993974794959, \"f1\": 0.9388947496551164, \"f2\": 0.9056893258602874, \"f0_5\": 0.9746276703281892, \"p4\": 0.9684703576407967, \"phi\": 0.9406241687996617}, {\"truth_threshold\": 14.800000220537186, \"match_probability\": 0.9999649457424121, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5773.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 765.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8829917405934536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11700825940654634, \"precision\": 1.0, \"recall\": 0.8829917405934536, \"specificity\": 1.0, \"npv\": 0.9999387594685667, \"accuracy\": 0.9999387877575515, \"f1\": 0.9378604500040614, \"f2\": 0.9041503523884103, \"f0_5\": 0.9741815727303409, \"p4\": 0.9679195950543471, \"phi\": 0.9396476284810218}, {\"truth_threshold\": 14.900000222027302, \"match_probability\": 0.9999672931444318, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5770.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 768.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8825328846742123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1174671153257877, \"precision\": 1.0, \"recall\": 0.8825328846742123, \"specificity\": 1.0, \"npv\": 0.999938519324385, \"accuracy\": 0.9999385477095419, \"f1\": 0.937601559961001, \"f2\": 0.9037654282313138, \"f0_5\": 0.974069822405294, \"p4\": 0.9677816447771408, \"phi\": 0.9394033350782879}, {\"truth_threshold\": 15.000000223517418, \"match_probability\": 0.9999694833578969, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5766.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 772.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8819210767818905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11807892321810952, \"precision\": 1.0, \"recall\": 0.8819210767818905, \"specificity\": 1.0, \"npv\": 0.9999381991323222, \"accuracy\": 0.9999382276455291, \"f1\": 0.937256176853056, \"f2\": 0.9032520834638762, \"f0_5\": 0.9739206810350652, \"p4\": 0.967597549139933, \"phi\": 0.9390775118668969}, {\"truth_threshold\": 15.100000225007534, \"match_probability\": 0.9999715269079685, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5758.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 780.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8806974609972469, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.11930253900275313, \"precision\": 1.0, \"recall\": 0.8806974609972469, \"specificity\": 1.0, \"npv\": 0.9999375587488118, \"accuracy\": 0.9999375875175035, \"f1\": 0.9365647364996746, \"f2\": 0.9022250078345346, \"f0_5\": 0.9736219141021305, \"p4\": 0.9672288016130275, \"phi\": 0.9384255266913109}, {\"truth_threshold\": 15.20000022649765, \"match_probability\": 0.9999734336151354, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5747.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 791.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8790149892933619, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12098501070663811, \"precision\": 1.0, \"recall\": 0.8790149892933619, \"specificity\": 1.0, \"npv\": 0.9999366782228243, \"accuracy\": 0.9999367073414683, \"f1\": 0.9356125356125357, \"f2\": 0.9008119376782971, \"f0_5\": 0.9732100521574206, \"p4\": 0.9667205592412763, \"phi\": 0.9375283081070543}, {\"truth_threshold\": 15.300000227987766, \"match_probability\": 0.9999752126423825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5746.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 792.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8788620373202815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12113796267971857, \"precision\": 1.0, \"recall\": 0.8788620373202815, \"specificity\": 1.0, \"npv\": 0.9999365981750842, \"accuracy\": 0.9999366273254651, \"f1\": 0.9355258873331163, \"f2\": 0.9006834284281147, \"f0_5\": 0.9731725492852787, \"p4\": 0.9666742854799766, \"phi\": 0.9374467002786164}, {\"truth_threshold\": 15.400000229477882, \"match_probability\": 0.9999768725392036, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5741.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 797.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8780972774548792, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12190272254512083, \"precision\": 1.0, \"recall\": 0.8780972774548792, \"specificity\": 1.0, \"npv\": 0.9999361979365756, \"accuracy\": 0.9999362272454491, \"f1\": 0.9350924342373157, \"f2\": 0.9000407612955821, \"f0_5\": 0.9729848823808556, \"p4\": 0.9664427415250191, \"phi\": 0.9370385547226381}, {\"truth_threshold\": 15.600000232458115, \"match_probability\": 0.9999798663157408, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5740.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 798.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8779443254817987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12205567451820129, \"precision\": 1.0, \"recall\": 0.8779443254817987, \"specificity\": 1.0, \"npv\": 0.9999361178889123, \"accuracy\": 0.9999361472294459, \"f1\": 0.935005701254276, \"f2\": 0.8999122036874452, \"f0_5\": 0.9729473184622687, \"p4\": 0.9663963976733706, \"phi\": 0.9369569043157052}, {\"truth_threshold\": 15.70000023394823, \"match_probability\": 0.9999812145830361, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5736.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 802.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.877332517589477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1226674824105231, \"precision\": 1.0, \"recall\": 0.877332517589477, \"specificity\": 1.0, \"npv\": 0.9999357976983875, \"accuracy\": 0.999935827165433, \"f1\": 0.9346586279941339, \"f2\": 0.8993978926241847, \"f0_5\": 0.9727969608574724, \"p4\": 0.9662109052502622, \"phi\": 0.9366302316403032}, {\"truth_threshold\": 15.800000235438347, \"match_probability\": 0.9999824725641815, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5733.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 805.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8768736616702355, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12312633832976445, \"precision\": 1.0, \"recall\": 0.8768736616702355, \"specificity\": 1.0, \"npv\": 0.9999355575556285, \"accuracy\": 0.9999355871174235, \"f1\": 0.9343981745579008, \"f2\": 0.8990120746432492, \"f0_5\": 0.9726840855106889, \"p4\": 0.9660716629413537, \"phi\": 0.9363851524816444}, {\"truth_threshold\": 15.900000236928463, \"match_probability\": 0.9999836463049459, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5727.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 811.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8759559498317528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12404405016824717, \"precision\": 1.0, \"recall\": 0.8759559498317528, \"specificity\": 1.0, \"npv\": 0.9999350772704563, \"accuracy\": 0.9999351070214043, \"f1\": 0.9338768854463921, \"f2\": 0.8982402208350325, \"f0_5\": 0.9724580588195341, \"p4\": 0.9657928615394306, \"phi\": 0.9358948019839248}, {\"truth_threshold\": 16.00000023841858, \"match_probability\": 0.9999847414462861, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5723.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 815.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.875344141939431, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12465585806056897, \"precision\": 1.0, \"recall\": 0.875344141939431, \"specificity\": 1.0, \"npv\": 0.9999347570805979, \"accuracy\": 0.9999347869573915, \"f1\": 0.9335290759318163, \"f2\": 0.8977254901960784, \"f0_5\": 0.972307169554876, \"p4\": 0.965606758897203, \"phi\": 0.935567759134596}, {\"truth_threshold\": 16.100000239908695, \"match_probability\": 0.9999857632514492, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5719.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 819.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8747323340471093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1252676659528908, \"precision\": 1.0, \"recall\": 0.8747323340471093, \"specificity\": 1.0, \"npv\": 0.9999344368909445, \"accuracy\": 0.9999344668933787, \"f1\": 0.9331810394060537, \"f2\": 0.897210630353613, \"f0_5\": 0.9721561161351737, \"p4\": 0.9654204678889048, \"phi\": 0.9352406021317177}, {\"truth_threshold\": 16.20000024139881, \"match_probability\": 0.9999867166312594, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5713.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 825.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8738146222086265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1261853777913735, \"precision\": 1.0, \"recall\": 0.8738146222086265, \"specificity\": 1.0, \"npv\": 0.9999339566068489, \"accuracy\": 0.9999339867973595, \"f1\": 0.9326585584850217, \"f2\": 0.8964380982268947, \"f0_5\": 0.971929227628445, \"p4\": 0.9651406775635268, \"phi\": 0.9347496523272908}, {\"truth_threshold\": 16.300000242888927, \"match_probability\": 0.9999876061677141, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5707.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 831.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8728969103701438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12710308962985623, \"precision\": 1.0, \"recall\": 0.8728969103701438, \"specificity\": 1.0, \"npv\": 0.9999334763232147, \"accuracy\": 0.9999335067013403, \"f1\": 0.9321355655369539, \"f2\": 0.8956652751184908, \"f0_5\": 0.9717019682626167, \"p4\": 0.9648604618011865, \"phi\": 0.9342584450023514}, {\"truth_threshold\": 16.400000244379044, \"match_probability\": 0.9999884361359999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5697.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 841.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8713673906393392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12863260936066076, \"precision\": 1.0, \"recall\": 0.8713673906393392, \"specificity\": 1.0, \"npv\": 0.9999326758515164, \"accuracy\": 0.9999327065413083, \"f1\": 0.9312627707396812, \"f2\": 0.8943765895318534, \"f0_5\": 0.9713223760485576, \"p4\": 0.9643924874742633, \"phi\": 0.9334391927553439}, {\"truth_threshold\": 16.50000024586916, \"match_probability\": 0.9999892105250341, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5695.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 843.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8710614866931783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.12893851330682166, \"precision\": 1.0, \"recall\": 0.8710614866931783, \"specificity\": 1.0, \"npv\": 0.9999325157573306, \"accuracy\": 0.9999325465093019, \"f1\": 0.931088040546064, \"f2\": 0.8941187552987723, \"f0_5\": 0.9712463333105942, \"p4\": 0.964298750075329, \"phi\": 0.9332752561642415}, {\"truth_threshold\": 16.600000247359276, \"match_probability\": 0.9999899330566321, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5685.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 853.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8695319669623738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1304680330376262, \"precision\": 1.0, \"recall\": 0.8695319669623738, \"specificity\": 1.0, \"npv\": 0.9999317152871701, \"accuracy\": 0.9999317463492698, \"f1\": 0.930213531866154, \"f2\": 0.8928290982190533, \"f0_5\": 0.9708654962770681, \"p4\": 0.9638293484191341, \"phi\": 0.9324551416672618}, {\"truth_threshold\": 16.700000248849392, \"match_probability\": 0.9999906072033913, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5683.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 855.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8692260630162129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1307739369837871, \"precision\": 1.0, \"recall\": 0.8692260630162129, \"specificity\": 1.0, \"npv\": 0.9999315551932917, \"accuracy\": 0.9999315863172634, \"f1\": 0.9300384583912936, \"f2\": 0.892571069577509, \"f0_5\": 0.9707892039631022, \"p4\": 0.963735324901063, \"phi\": 0.9322910323532797}, {\"truth_threshold\": 16.800000250339508, \"match_probability\": 0.9999912362053778, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5675.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 863.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8680024472315693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13199755276843073, \"precision\": 1.0, \"recall\": 0.8680024472315693, \"specificity\": 1.0, \"npv\": 0.9999309148182912, \"accuracy\": 0.9999309461892378, \"f1\": 0.92933759109146, \"f2\": 0.8915386307223426, \"f0_5\": 0.9704836172104795, \"p4\": 0.9633587523239053, \"phi\": 0.931634306541348}, {\"truth_threshold\": 16.900000251829624, \"match_probability\": 0.999991823085696, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5669.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 869.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8670847353930866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13291526460691344, \"precision\": 1.0, \"recall\": 0.8670847353930866, \"specificity\": 1.0, \"npv\": 0.999930434537579, \"accuracy\": 0.9999304660932187, \"f1\": 0.9288113377570246, \"f2\": 0.8907639609063197, \"f0_5\": 0.9702539878140618, \"p4\": 0.9630758194365757, \"phi\": 0.9311414587711745}, {\"truth_threshold\": 17.00000025331974, \"match_probability\": 0.9999923706650156, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5657.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 881.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8652493117161212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13475068828387887, \"precision\": 1.0, \"recall\": 0.8652493117161212, \"specificity\": 1.0, \"npv\": 0.9999294739775387, \"accuracy\": 0.9999295059011802, \"f1\": 0.9277572775727757, \"f2\": 0.8892137445377094, \"f0_5\": 0.9697935952821779, \"p4\": 0.9625086547691355, \"phi\": 0.9301549812390021}, {\"truth_threshold\": 17.100000254809856, \"match_probability\": 0.9999928815751264, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5643.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 895.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8631079840929948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1368920159070052, \"precision\": 1.0, \"recall\": 0.8631079840929948, \"specificity\": 1.0, \"npv\": 0.999928353326491, \"accuracy\": 0.9999283856771354, \"f1\": 0.9265249158525573, \"f2\": 0.8874036798238717, \"f0_5\": 0.9692545517004466, \"p4\": 0.9618447648273077, \"phi\": 0.9290027692515537}, {\"truth_threshold\": 17.200000256299973, \"match_probability\": 0.999993358271586, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5639.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 899.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.862496176200673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.13750382379932702, \"precision\": 1.0, \"recall\": 0.862496176200673, \"specificity\": 1.0, \"npv\": 0.9999280331409387, \"accuracy\": 0.9999280656131226, \"f1\": 0.9261722920259505, \"f2\": 0.8868862256613507, \"f0_5\": 0.969100158108201, \"p4\": 0.9616546455829704, \"phi\": 0.9286733037295297}, {\"truth_threshold\": 17.30000025779009, \"match_probability\": 0.999993803045519, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5630.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 908.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8611196084429489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1388803915570511, \"precision\": 1.0, \"recall\": 0.8611196084429489, \"specificity\": 1.0, \"npv\": 0.9999273127241958, \"accuracy\": 0.9999273454690938, \"f1\": 0.9253780407626562, \"f2\": 0.8857214775659178, \"f0_5\": 0.9687521508706725, \"p4\": 0.9612261656750148, \"phi\": 0.9279315793766637}, {\"truth_threshold\": 17.400000259280205, \"match_probability\": 0.9999942180346287, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5613.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 925.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8585194249005812, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14148057509941878, \"precision\": 1.0, \"recall\": 0.8585194249005812, \"specificity\": 1.0, \"npv\": 0.999925951939847, \"accuracy\": 0.9999259851970395, \"f1\": 0.9238745782240145, \"f2\": 0.8835195970407681, \"f0_5\": 0.968092445670921, \"p4\": 0.9604141160896794, \"phi\": 0.9265289273425649}, {\"truth_threshold\": 17.50000026077032, \"match_probability\": 0.9999946052334694, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5607.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 931.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8576017130620985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1423982869379015, \"precision\": 1.0, \"recall\": 0.8576017130620985, \"specificity\": 1.0, \"npv\": 0.9999254716639023, \"accuracy\": 0.9999255051010202, \"f1\": 0.923342939481268, \"f2\": 0.882741899933877, \"f0_5\": 0.9678588690188497, \"p4\": 0.9601266643263768, \"phi\": 0.9260333673434179}, {\"truth_threshold\": 17.600000262260437, \"match_probability\": 0.999994966503032, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5604.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 934.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8571428571428571, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14285714285714285, \"precision\": 1.0, \"recall\": 0.8571428571428571, \"specificity\": 1.0, \"npv\": 0.999925231526103, \"accuracy\": 0.9999252650530106, \"f1\": 0.9230769230769231, \"f2\": 0.8823529411764706, \"f0_5\": 0.967741935483871, \"p4\": 0.9599827723646703, \"phi\": 0.9257854880475912}, {\"truth_threshold\": 17.700000263750553, \"match_probability\": 0.9999953035796879, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5597.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 941.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.856072193331294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14392780666870603, \"precision\": 1.0, \"recall\": 0.856072193331294, \"specificity\": 1.0, \"npv\": 0.9999246712050197, \"accuracy\": 0.9999247049409882, \"f1\": 0.9224557066337041, \"f2\": 0.8814450848845633, \"f0_5\": 0.9674687132683399, \"p4\": 0.9596465929901177, \"phi\": 0.9252068452214101}, {\"truth_threshold\": 17.80000026524067, \"match_probability\": 0.9999956180835331, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5590.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 948.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8550015295197309, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1449984704802692, \"precision\": 1.0, \"recall\": 0.8550015295197309, \"specificity\": 1.0, \"npv\": 0.9999241108845645, \"accuracy\": 0.9999241448289657, \"f1\": 0.9218337730870713, \"f2\": 0.8805368281771785, \"f0_5\": 0.9671949615890373, \"p4\": 0.9593098082442986, \"phi\": 0.9246278409230169}, {\"truth_threshold\": 17.900000266730785, \"match_probability\": 0.9999959115261747, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5586.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 952.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.854389721627409, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.145610278372591, \"precision\": 1.0, \"recall\": 0.854389721627409, \"specificity\": 1.0, \"npv\": 0.9999237907017291, \"accuracy\": 0.999923824764953, \"f1\": 0.9214780600461894, \"f2\": 0.8800176444640494, \"f0_5\": 0.9670382937469705, \"p4\": 0.9591170873887016, \"phi\": 0.9242968187688811}, {\"truth_threshold\": 18.0000002682209, \"match_probability\": 0.9999961853179954, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5573.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 965.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8524013459773631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1475986540226369, \"precision\": 1.0, \"recall\": 0.8524013459773631, \"specificity\": 1.0, \"npv\": 0.9999227501089304, \"accuracy\": 0.9999227845569114, \"f1\": 0.9203203699116506, \"f2\": 0.8783293932230103, \"f0_5\": 0.9665279223031564, \"p4\": 0.958489372032922, \"phi\": 0.9232201785415214}, {\"truth_threshold\": 18.100000269711018, \"match_probability\": 0.999996440774932, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5568.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 970.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8516365861119608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.14836341388803917, \"precision\": 1.0, \"recall\": 0.8516365861119608, \"specificity\": 1.0, \"npv\": 0.9999223498815075, \"accuracy\": 0.9999223844768954, \"f1\": 0.9198744424252436, \"f2\": 0.8776796973518285, \"f0_5\": 0.9663311350225616, \"p4\": 0.9582473824953028, \"phi\": 0.9228057522740832}, {\"truth_threshold\": 18.200000271201134, \"match_probability\": 0.9999966791247992, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5554.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 984.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8494952584888346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1505047415111655, \"precision\": 1.0, \"recall\": 0.8494952584888346, \"specificity\": 1.0, \"npv\": 0.999921229246428, \"accuracy\": 0.9999212642528506, \"f1\": 0.9186238835593781, \"f2\": 0.8758594587775185, \"f0_5\": 0.9657786742714057, \"p4\": 0.957568148183659, \"phi\": 0.9216443691072861}, {\"truth_threshold\": 18.30000027269125, \"match_probability\": 0.999996901513191, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5543.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 995.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8478127867849495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15218721321505047, \"precision\": 1.0, \"recall\": 0.8478127867849495, \"specificity\": 1.0, \"npv\": 0.9999203487491992, \"accuracy\": 0.9999203840768154, \"f1\": 0.917639268272494, \"f2\": 0.8744281432402587, \"f0_5\": 0.9653430860327412, \"p4\": 0.9570327375059657, \"phi\": 0.9207308278949051}, {\"truth_threshold\": 18.400000274181366, \"match_probability\": 0.9999971090089864, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5535.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1003.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.846589171000306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1534108289996941, \"precision\": 1.0, \"recall\": 0.846589171000306, \"specificity\": 1.0, \"npv\": 0.9999197083885522, \"accuracy\": 0.9999197439487898, \"f1\": 0.9169220574836412, \"f2\": 0.8733865623126204, \"f0_5\": 0.9650254550526536, \"p4\": 0.9566423895140822, \"phi\": 0.920065865572423}, {\"truth_threshold\": 18.500000275671482, \"match_probability\": 0.9999973026094866, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5513.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1025.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8432242275925359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15677577240746404, \"precision\": 1.0, \"recall\": 0.8432242275925359, \"specificity\": 1.0, \"npv\": 0.9999179474010019, \"accuracy\": 0.9999179835967194, \"f1\": 0.9149448178574392, \"f2\": 0.8705195010263698, \"f0_5\": 0.9641483036026582, \"p4\": 0.9555647488452849, \"phi\": 0.9182347406045601}, {\"truth_threshold\": 18.600000277161598, \"match_probability\": 0.999997483245208, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5502.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1036.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.841541755888651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.15845824411134904, \"precision\": 1.0, \"recall\": 0.841541755888651, \"specificity\": 1.0, \"npv\": 0.9999170669095528, \"accuracy\": 0.9999171034206842, \"f1\": 0.913953488372093, \"f2\": 0.8690844758956214, \"f0_5\": 0.9637076998528691, \"p4\": 0.9550236151979463, \"phi\": 0.9173178098293387}, {\"truth_threshold\": 18.700000278651714, \"match_probability\": 0.9999976517843541, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5487.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1051.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8392474762924442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16075252370755583, \"precision\": 1.0, \"recall\": 0.8392474762924442, \"specificity\": 1.0, \"npv\": 0.9999158662418939, \"accuracy\": 0.9999159031806362, \"f1\": 0.9125987525987526, \"f2\": 0.8671260153607889, \"f0_5\": 0.9631046830021766, \"p4\": 0.9542832047389773, \"phi\": 0.9160659731964083}, {\"truth_threshold\": 18.80000028014183, \"match_probability\": 0.9999978090369889, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5467.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1071.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8361884368308351, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16381156316916487, \"precision\": 1.0, \"recall\": 0.8361884368308351, \"specificity\": 1.0, \"npv\": 0.9999142653561675, \"accuracy\": 0.9999143028605721, \"f1\": 0.9107871720116618, \"f2\": 0.8645118441443436, \"f0_5\": 0.9622966978807295, \"p4\": 0.9532914749206359, \"phi\": 0.9143941964563349}, {\"truth_threshold\": 18.900000281631947, \"match_probability\": 0.9999979557589296, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5460.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1078.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8351177730192719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16488222698072805, \"precision\": 1.0, \"recall\": 0.8351177730192719, \"specificity\": 1.0, \"npv\": 0.9999137050473742, \"accuracy\": 0.9999137427485497, \"f1\": 0.9101516919486581, \"f2\": 0.8635961027457927, \"f0_5\": 0.9620128268376912, \"p4\": 0.9529431434945829, \"phi\": 0.9138083533053374}, {\"truth_threshold\": 19.000000283122063, \"match_probability\": 0.9999980926553794, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5456.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1082.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8345059651269502, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16549403487304987, \"precision\": 1.0, \"recall\": 0.8345059651269502, \"specificity\": 1.0, \"npv\": 0.9999133848712028, \"accuracy\": 0.9999134226845369, \"f1\": 0.9097882274470569, \"f2\": 0.8630726398380157, \"f0_5\": 0.9618503631619773, \"p4\": 0.9527438103909488, \"phi\": 0.9134734173939046}, {\"truth_threshold\": 19.10000028461218, \"match_probability\": 0.9999982203843173, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5443.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1095.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8325175894769042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16748241052309576, \"precision\": 1.0, \"recall\": 0.8325175894769042, \"specificity\": 1.0, \"npv\": 0.999912344300062, \"accuracy\": 0.9999123824764953, \"f1\": 0.9086052917118771, \"f2\": 0.8613704700110777, \"f0_5\": 0.9613210879547863, \"p4\": 0.9520945338863664, \"phi\": 0.9123840280084302}, {\"truth_threshold\": 19.200000286102295, \"match_probability\": 0.9999983395596597, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5433.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1105.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8309880697460997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.16901193025390027, \"precision\": 1.0, \"recall\": 0.8309880697460997, \"specificity\": 1.0, \"npv\": 0.9999115438621967, \"accuracy\": 0.9999115823164633, \"f1\": 0.907693592849386, \"f2\": 0.8600601551369321, \"f0_5\": 0.9609126282278033, \"p4\": 0.951593582371134, \"phi\": 0.9115451517894707}, {\"truth_threshold\": 19.30000028759241, \"match_probability\": 0.9999984507542113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5416.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1122.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.828387886203732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17161211379626798, \"precision\": 1.0, \"recall\": 0.828387886203732, \"specificity\": 1.0, \"npv\": 0.9999101831207667, \"accuracy\": 0.9999102220444089, \"f1\": 0.9061402041157771, \"f2\": 0.8578307146477445, \"f0_5\": 0.9602155875469824, \"p4\": 0.9507389394011454, \"phi\": 0.9101172907867418}, {\"truth_threshold\": 19.400000289082527, \"match_probability\": 0.9999985545024187, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5412.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1126.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8277760783114102, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17222392168858977, \"precision\": 1.0, \"recall\": 0.8277760783114102, \"specificity\": 1.0, \"npv\": 0.9999098629468508, \"accuracy\": 0.9999099019803961, \"f1\": 0.9057740585774059, \"f2\": 0.8573057914079331, \"f0_5\": 0.9600510891932165, \"p4\": 0.9505372910096181, \"phi\": 0.9097809983809532}, {\"truth_threshold\": 19.500000290572643, \"match_probability\": 0.9999986513029383, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5408.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1130.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8271642704190884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1728357295809116, \"precision\": 1.0, \"recall\": 0.8271642704190884, \"specificity\": 1.0, \"npv\": 0.99990954277314, \"accuracy\": 0.9999095819163832, \"f1\": 0.905407667838607, \"f2\": 0.8567807351077313, \"f0_5\": 0.9598864039758609, \"p4\": 0.9503354301381339, \"phi\": 0.9094445818371939}, {\"truth_threshold\": 19.60000029206276, \"match_probability\": 0.9999987416210334, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5401.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1137.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8260936066075253, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17390639339247477, \"precision\": 1.0, \"recall\": 0.8260936066075253, \"specificity\": 1.0, \"npv\": 0.9999089824696394, \"accuracy\": 0.9999090218043609, \"f1\": 0.9047658932908954, \"f2\": 0.8558615662536051, \"f0_5\": 0.9595977542463222, \"p4\": 0.9499816613213495, \"phi\": 0.908855553763966}, {\"truth_threshold\": 19.700000293552876, \"match_probability\": 0.9999988258908107, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5378.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1160.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8225757112266748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.17742428877332517, \"precision\": 1.0, \"recall\": 0.8225757112266748, \"specificity\": 1.0, \"npv\": 0.9999071414768443, \"accuracy\": 0.9999071814362872, \"f1\": 0.9026518966096005, \"f2\": 0.8528385664446558, \"f0_5\": 0.9586452762923351, \"p4\": 0.9488146667459093, \"phi\": 0.9069174869087853}, {\"truth_threshold\": 19.80000029504299, \"match_probability\": 0.9999989045173057, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5359.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1179.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8196696237381462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18033037626185378, \"precision\": 1.0, \"recall\": 0.8196696237381462, \"specificity\": 1.0, \"npv\": 0.9999056206618225, \"accuracy\": 0.9999056611322265, \"f1\": 0.9008993863999327, \"f2\": 0.8503379772143062, \"f0_5\": 0.9578537213126475, \"p4\": 0.9478452599886187, \"phi\": 0.9053133512003088}, {\"truth_threshold\": 19.900000296533108, \"match_probability\": 0.9999989778784306, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5339.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1199.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8166105842765372, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18338941572346285, \"precision\": 1.0, \"recall\": 0.8166105842765372, \"specificity\": 1.0, \"npv\": 0.9999040198089025, \"accuracy\": 0.9999040608121624, \"f1\": 0.899048581291572, \"f2\": 0.8477025181797974, \"f0_5\": 0.9570158457015846, \"p4\": 0.9468195418704209, \"phi\": 0.9036217161161002}, {\"truth_threshold\": 20.000000298023224, \"match_probability\": 0.99999904632679, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5322.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1216.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8140104007341695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.18598959926583053, \"precision\": 1.0, \"recall\": 0.8140104007341695, \"specificity\": 1.0, \"npv\": 0.9999026590879508, \"accuracy\": 0.999902700540108, \"f1\": 0.8974704890387858, \"f2\": 0.845459744551058, \"f0_5\": 0.9562998634370733, \"p4\": 0.9459433837495578, \"phi\": 0.9021813366609535}, {\"truth_threshold\": 20.10000029951334, \"match_probability\": 0.9999991101913761, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5311.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1227.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8123279290302845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1876720709697155, \"precision\": 1.0, \"recall\": 0.8123279290302845, \"specificity\": 1.0, \"npv\": 0.9999017786234262, \"accuracy\": 0.9999018203640728, \"f1\": 0.8964469575491603, \"f2\": 0.8440072466071258, \"f0_5\": 0.9558347131236052, \"p4\": 0.9453743399717395, \"phi\": 0.9012481018359294}, {\"truth_threshold\": 20.200000301003456, \"match_probability\": 0.9999991697791492, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5293.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1245.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8095747935148363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19042520648516365, \"precision\": 1.0, \"recall\": 0.8095747935148363, \"specificity\": 1.0, \"npv\": 0.9999003378666396, \"accuracy\": 0.9999003800760152, \"f1\": 0.8947679824190685, \"f2\": 0.8416282397837495, \"f0_5\": 0.955070371706965, \"p4\": 0.9444395658405997, \"phi\": 0.8997189058610471}, {\"truth_threshold\": 20.300000302493572, \"match_probability\": 0.9999992253765136, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5271.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1267.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8062098501070664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.1937901498929336, \"precision\": 1.0, \"recall\": 0.8062098501070664, \"specificity\": 1.0, \"npv\": 0.9998985769473167, \"accuracy\": 0.9998986197239448, \"f1\": 0.8927089508002372, \"f2\": 0.8387168634439741, \"f0_5\": 0.9541307653319817, \"p4\": 0.9432909339473148, \"phi\": 0.897846357592971}, {\"truth_threshold\": 20.40000030398369, \"match_probability\": 0.9999992772506945, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5246.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1292.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8023860507800551, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19761394921994493, \"precision\": 1.0, \"recall\": 0.8023860507800551, \"specificity\": 1.0, \"npv\": 0.99989657591016, \"accuracy\": 0.9998966193238648, \"f1\": 0.8903598099117448, \"f2\": 0.8354035288871903, \"f0_5\": 0.9530557372283991, \"p4\": 0.9419774135956439, \"phi\": 0.8957137180668011}, {\"truth_threshold\": 20.500000305473804, \"match_probability\": 0.9999993256510213, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5234.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1304.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.8005506271030897, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.19944937289691037, \"precision\": 1.0, \"recall\": 0.8005506271030897, \"specificity\": 1.0, \"npv\": 0.9998956154151697, \"accuracy\": 0.9998956591318263, \"f1\": 0.8892286782195039, \"f2\": 0.833811253425094, \"f0_5\": 0.9525369440198005, \"p4\": 0.9413437789638046, \"phi\": 0.8946882484744303}, {\"truth_threshold\": 20.60000030696392, \"match_probability\": 0.9999993708101274, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5210.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1328.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7968797797491588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20312022025084123, \"precision\": 1.0, \"recall\": 0.7968797797491588, \"specificity\": 1.0, \"npv\": 0.9998936944307248, \"accuracy\": 0.9998937387477496, \"f1\": 0.8869594824651005, \"f2\": 0.8306230469995536, \"f0_5\": 0.9514939002118489, \"p4\": 0.940070339443904, \"phi\": 0.8926337810045779}, {\"truth_threshold\": 20.700000308454037, \"match_probability\": 0.9999994129450668, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5194.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1344.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7944325481798715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.20556745182012848, \"precision\": 1.0, \"recall\": 0.7944325481798715, \"specificity\": 1.0, \"npv\": 0.999892413778529, \"accuracy\": 0.9998924584916984, \"f1\": 0.8854415274463007, \"f2\": 0.8284948637784725, \"f0_5\": 0.9507944643772425, \"p4\": 0.9392167769679785, \"phi\": 0.8912615094257124}, {\"truth_threshold\": 20.800000309944153, \"match_probability\": 0.9999994522583585, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5167.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1371.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7903028449066993, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2096971550933007, \"precision\": 1.0, \"recall\": 0.7903028449066993, \"specificity\": 1.0, \"npv\": 0.9998902526853871, \"accuracy\": 0.9998902980596119, \"f1\": 0.8828705681332764, \"f2\": 0.8248986238385645, \"f0_5\": 0.9496067044034404, \"p4\": 0.9377679643735422, \"phi\": 0.8889410055182176}, {\"truth_threshold\": 20.90000031143427, \"match_probability\": 0.9999994889389594, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5144.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1394.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7867849495258489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21321505047415112, \"precision\": 1.0, \"recall\": 0.7867849495258489, \"specificity\": 1.0, \"npv\": 0.9998884117615604, \"accuracy\": 0.9998884576915383, \"f1\": 0.8806711179592536, \"f2\": 0.8218302658486708, \"f0_5\": 0.948587445600059, \"p4\": 0.9365253693752402, \"phi\": 0.8869594994019178}, {\"truth_threshold\": 21.000000312924385, \"match_probability\": 0.9999995231631726, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5135.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1403.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7854083817681248, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2145916182318752, \"precision\": 1.0, \"recall\": 0.7854083817681248, \"specificity\": 1.0, \"npv\": 0.9998876914019083, \"accuracy\": 0.9998877375475095, \"f1\": 0.8798081041720209, \"f2\": 0.8206283760028127, \"f0_5\": 0.9481867198463697, \"p4\": 0.9360370105486685, \"phi\": 0.8861829233594151}, {\"truth_threshold\": 21.1000003144145, \"match_probability\": 0.9999995550954947, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5115.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1423.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7823493423065158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.21765065769348424, \"precision\": 1.0, \"recall\": 0.7823493423065158, \"specificity\": 1.0, \"npv\": 0.9998860906063974, \"accuracy\": 0.9998861372274455, \"f1\": 0.8778855230412769, \"f2\": 0.8179550324623405, \"f0_5\": 0.9472923920290391, \"p4\": 0.9349474566573615, \"phi\": 0.8844547616285121}, {\"truth_threshold\": 21.200000315904617, \"match_probability\": 0.9999995848894065, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5091.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1447.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7786784949525849, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2213215050474151, \"precision\": 1.0, \"recall\": 0.7786784949525849, \"specificity\": 1.0, \"npv\": 0.9998841696585502, \"accuracy\": 0.9998842168433687, \"f1\": 0.8755696964485339, \"f2\": 0.8147425023205198, \"f0_5\": 0.9462121775332689, \"p4\": 0.9336320838384425, \"phi\": 0.8823765071422941}, {\"truth_threshold\": 21.300000317394733, \"match_probability\": 0.9999996126881108, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5069.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1469.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.775313551544815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.22468644845518507, \"precision\": 1.0, \"recall\": 0.775313551544815, \"specificity\": 1.0, \"npv\": 0.9998824087961743, \"accuracy\": 0.9998824564912983, \"f1\": 0.8734384423192901, \"f2\": 0.8117933442234394, \"f0_5\": 0.9452151860968151, \"p4\": 0.9324186777654888, \"phi\": 0.8804671382231971}, {\"truth_threshold\": 21.40000031888485, \"match_probability\": 0.9999996386252203, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5038.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1500.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7705720403793209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2294279596206791, \"precision\": 1.0, \"recall\": 0.7705720403793209, \"specificity\": 1.0, \"npv\": 0.9998799275915348, \"accuracy\": 0.9998799759951991, \"f1\": 0.8704215618521078, \"f2\": 0.8076306508496313, \"f0_5\": 0.9437991757212439, \"p4\": 0.9306963297203755, \"phi\": 0.8777696257780492}, {\"truth_threshold\": 21.500000320374966, \"match_probability\": 0.9999996628254004, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5023.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1515.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.768277760783114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2317222392168859, \"precision\": 1.0, \"recall\": 0.768277760783114, \"specificity\": 1.0, \"npv\": 0.9998787270130656, \"accuracy\": 0.999878775755151, \"f1\": 0.8689559726667243, \"f2\": 0.8056134723336006, \"f0_5\": 0.9431092752534735, \"p4\": 0.9298576158011251, \"phi\": 0.8764614021417421}, {\"truth_threshold\": 21.600000321865082, \"match_probability\": 0.999999685404968, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4996.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1542.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7641480575099419, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.23585194249005811, \"precision\": 1.0, \"recall\": 0.7641480575099419, \"specificity\": 1.0, \"npv\": 0.9998765659790864, \"accuracy\": 0.9998766153230646, \"f1\": 0.8663083058782729, \"f2\": 0.8019776550661358, \"f0_5\": 0.941859588266345, \"p4\": 0.9283390989753275, \"phi\": 0.8741016735155185}, {\"truth_threshold\": 21.700000323355198, \"match_probability\": 0.9999997064724503, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4968.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1570.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7598654022636891, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2401345977363108, \"precision\": 1.0, \"recall\": 0.7598654022636891, \"specificity\": 1.0, \"npv\": 0.9998743249166783, \"accuracy\": 0.999874374874975, \"f1\": 0.8635494524595863, \"f2\": 0.7982005141388174, \"f0_5\": 0.9405528209011738, \"p4\": 0.926752229548712, \"phi\": 0.8716478108249607}, {\"truth_threshold\": 21.800000324845314, \"match_probability\": 0.999999726129107, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4954.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1584.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7577240746405629, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24227592535943715, \"precision\": 1.0, \"recall\": 0.7577240746405629, \"specificity\": 1.0, \"npv\": 0.9998732043892414, \"accuracy\": 0.9998732546509301, \"f1\": 0.86216498433693, \"f2\": 0.7963093936861055, \"f0_5\": 0.9398952720649617, \"p4\": 0.9259541258114818, \"phi\": 0.8704182894182155}, {\"truth_threshold\": 21.90000032633543, \"match_probability\": 0.9999997444694171, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4919.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1619.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.752370755582747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.24762924441725298, \"precision\": 1.0, \"recall\": 0.752370755582747, \"specificity\": 1.0, \"npv\": 0.999870403081637, \"accuracy\": 0.9998704540908182, \"f1\": 0.8586890110849262, \"f2\": 0.7915741366547585, \"f0_5\": 0.9382391088731212, \"p4\": 0.9239451007487015, \"phi\": 0.8673368726460077}, {\"truth_threshold\": 22.000000327825546, \"match_probability\": 0.9999997615815319, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4889.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1649.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7477821963903334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25221780360966656, \"precision\": 1.0, \"recall\": 0.7477821963903334, \"specificity\": 1.0, \"npv\": 0.9998680019733265, \"accuracy\": 0.9998680536107222, \"f1\": 0.8556926577404393, \"f2\": 0.7875068457846075, \"f0_5\": 0.9368053958764467, \"p4\": 0.9222072523331333, \"phi\": 0.8646869321413552}, {\"truth_threshold\": 22.100000329315662, \"match_probability\": 0.9999997775477002, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4865.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1673.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7441113490364025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2558886509635974, \"precision\": 1.0, \"recall\": 0.7441113490364025, \"specificity\": 1.0, \"npv\": 0.9998660810949812, \"accuracy\": 0.9998661332266453, \"f1\": 0.8532842234499693, \"f2\": 0.7842473482283909, \"f0_5\": 0.9356488960689284, \"p4\": 0.9208063218701751, \"phi\": 0.8625611273755196}, {\"truth_threshold\": 22.20000033080578, \"match_probability\": 0.9999997924446623, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4847.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1691.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7413582135209544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.25864178647904557, \"precision\": 1.0, \"recall\": 0.7413582135209544, \"specificity\": 1.0, \"npv\": 0.9998646404410656, \"accuracy\": 0.9998646929385877, \"f1\": 0.8514712340799298, \"f2\": 0.7817994128842866, \"f0_5\": 0.9347759006402839, \"p4\": 0.9197493468380361, \"phi\": 0.8609633346433283}, {\"truth_threshold\": 22.300000332295895, \"match_probability\": 0.9999998063440199, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4827.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1711.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7382991740593454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26170082594065464, \"precision\": 1.0, \"recall\": 0.7382991740593454, \"specificity\": 1.0, \"npv\": 0.9998630397193619, \"accuracy\": 0.9998630926185237, \"f1\": 0.849450065992081, \"f2\": 0.7790761483585655, \"f0_5\": 0.9338002011916737, \"p4\": 0.9185685638925053, \"phi\": 0.8591845298870733}, {\"truth_threshold\": 22.40000033378601, \"match_probability\": 0.9999998193125794, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4808.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1730.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7353930865708168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.26460691342918324, \"precision\": 1.0, \"recall\": 0.7353930865708168, \"specificity\": 1.0, \"npv\": 0.9998615190384906, \"accuracy\": 0.9998615723144629, \"f1\": 0.8475233562488983, \"f2\": 0.7764857881136951, \"f0_5\": 0.9328676755917734, \"p4\": 0.9174405623684481, \"phi\": 0.8574912528003427}, {\"truth_threshold\": 22.500000335276127, \"match_probability\": 0.9999998314126736, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4786.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1752.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7320281431630468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2679718568369532, \"precision\": 1.0, \"recall\": 0.7320281431630468, \"specificity\": 1.0, \"npv\": 0.9998597582558922, \"accuracy\": 0.9998598119623925, \"f1\": 0.8452843518191452, \"f2\": 0.7734824487685048, \"f0_5\": 0.9317810139397243, \"p4\": 0.9161267712588145, \"phi\": 0.855526435745567}, {\"truth_threshold\": 22.600000336766243, \"match_probability\": 0.9999998427024609, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4768.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1770.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7292750076475987, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27072499235240133, \"precision\": 1.0, \"recall\": 0.7292750076475987, \"specificity\": 1.0, \"npv\": 0.9998583176201971, \"accuracy\": 0.9998583716743349, \"f1\": 0.843445957898461, \"f2\": 0.7710219922380336, \"f0_5\": 0.930886372510738, \"p4\": 0.9150456655314004, \"phi\": 0.8539155006374954}, {\"truth_threshold\": 22.70000033825636, \"match_probability\": 0.9999998532362051, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4747.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1791.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7260630162129091, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27393698378709086, \"precision\": 1.0, \"recall\": 0.7260630162129091, \"specificity\": 1.0, \"npv\": 0.9998566368837998, \"accuracy\": 0.9998566913382676, \"f1\": 0.8412937527691626, \"f2\": 0.7681478364995631, \"f0_5\": 0.9298362453968503, \"p4\": 0.9137772772770576, \"phi\": 0.8520322326980049}, {\"truth_threshold\": 22.800000339746475, \"match_probability\": 0.9999998630645361, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4741.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1797.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7251453043744265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2748546956255736, \"precision\": 1.0, \"recall\": 0.7251453043744265, \"specificity\": 1.0, \"npv\": 0.9998561566744384, \"accuracy\": 0.9998562112422484, \"f1\": 0.840677365014629, \"f2\": 0.7673259314407794, \"f0_5\": 0.929534938436201, \"p4\": 0.9134134674550844, \"phi\": 0.8514933922599339}, {\"truth_threshold\": 22.90000034123659, \"match_probability\": 0.9999998722346936, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4725.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1813.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7226980728051392, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2773019271948608, \"precision\": 1.0, \"recall\": 0.7226980728051392, \"specificity\": 1.0, \"npv\": 0.9998548761183964, \"accuracy\": 0.9998549309861973, \"f1\": 0.839030453697949, \"f2\": 0.7651326229879846, \"f0_5\": 0.9287286736378646, \"p4\": 0.9124402181960329, \"phi\": 0.8500548170886312}, {\"truth_threshold\": 23.000000342726707, \"match_probability\": 0.999999880790753, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4715.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1823.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7211685530743347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.27883144692566536, \"precision\": 1.0, \"recall\": 0.7211685530743347, \"specificity\": 1.0, \"npv\": 0.9998540757725359, \"accuracy\": 0.9998541308261653, \"f1\": 0.837998755887319, \"f2\": 0.7637606505329316, \"f0_5\": 0.9282226947003701, \"p4\": 0.911829644625847, \"phi\": 0.849154471877971}, {\"truth_threshold\": 23.100000344216824, \"match_probability\": 0.9999998887738388, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4700.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1838.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7188742734781278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2811257265218721, \"precision\": 1.0, \"recall\": 0.7188742734781278, \"specificity\": 1.0, \"npv\": 0.9998528752561475, \"accuracy\": 0.9998529305861172, \"f1\": 0.8364477665064958, \"f2\": 0.7617010242447816, \"f0_5\": 0.9274607309179888, \"p4\": 0.9109104576614336, \"phi\": 0.847802164001001}, {\"truth_threshold\": 23.20000034570694, \"match_probability\": 0.9999998962223214, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4689.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1849.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7171918017742429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.2828081982257571, \"precision\": 1.0, \"recall\": 0.7171918017742429, \"specificity\": 1.0, \"npv\": 0.999851994879295, \"accuracy\": 0.9998520504100821, \"f1\": 0.8353077402689943, \"f2\": 0.7601893583217146, \"f0_5\": 0.9268996599984186, \"p4\": 0.9102338368279399, \"phi\": 0.8468091011054691}, {\"truth_threshold\": 23.300000347197056, \"match_probability\": 0.9999999031720016, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4658.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1880.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7124502906087489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28754970939125113, \"precision\": 1.0, \"recall\": 0.7124502906087489, \"specificity\": 1.0, \"npv\": 0.9998495138255971, \"accuracy\": 0.9998495699139828, \"f1\": 0.8320828867452662, \"f2\": 0.7559234014930217, \"f0_5\": 0.9253079062375844, \"p4\": 0.908315288967822, \"phi\": 0.8440041923415208}, {\"truth_threshold\": 23.400000348687172, \"match_probability\": 0.9999999096562825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4643.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1895.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7101560110125421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.28984398898745795, \"precision\": 1.0, \"recall\": 0.7101560110125421, \"specificity\": 1.0, \"npv\": 0.9998483133201637, \"accuracy\": 0.9998483696739348, \"f1\": 0.8305160540202129, \"f2\": 0.753856145478162, \"f0_5\": 0.924532058940661, \"p4\": 0.9073807031724148, \"phi\": 0.842643631557888}, {\"truth_threshold\": 23.500000350177288, \"match_probability\": 0.9999999157063305, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4626.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1912.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7075558274701743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29244417252982563, \"precision\": 1.0, \"recall\": 0.7075558274701743, \"specificity\": 1.0, \"npv\": 0.9998469527508241, \"accuracy\": 0.9998470094018804, \"f1\": 0.8287352203511287, \"f2\": 0.7515108194164664, \"f0_5\": 0.9236482709048798, \"p4\": 0.9063165278596192, \"phi\": 0.8410990060612019}, {\"truth_threshold\": 23.600000351667404, \"match_probability\": 0.9999999213512251, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4601.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1937.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.703732028143163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29626797185683695, \"precision\": 1.0, \"recall\": 0.703732028143163, \"specificity\": 1.0, \"npv\": 0.9998449519202869, \"accuracy\": 0.9998450090018004, \"f1\": 0.826106472753389, \"f2\": 0.7480571001203135, \"f0_5\": 0.9223398284018924, \"p4\": 0.9047418749608697, \"phi\": 0.8388223386650875}, {\"truth_threshold\": 23.70000035315752, \"match_probability\": 0.9999999266180979, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4586.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1952.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7014377485469563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29856225145304377, \"precision\": 1.0, \"recall\": 0.7014377485469563, \"specificity\": 1.0, \"npv\": 0.9998437514258083, \"accuracy\": 0.9998438087617524, \"f1\": 0.8245235526788924, \"f2\": 0.745982171904483, \"f0_5\": 0.9215497146531629, \"p4\": 0.9037914998821425, \"phi\": 0.8374533717759226}, {\"truth_threshold\": 23.800000354647636, \"match_probability\": 0.9999999315322641, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4582.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1956.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.7008259406546344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.29917405934536556, \"precision\": 1.0, \"recall\": 0.7008259406546344, \"specificity\": 1.0, \"npv\": 0.9998434312944342, \"accuracy\": 0.9998434886977395, \"f1\": 0.8241007194244604, \"f2\": 0.7454285156504197, \"f0_5\": 0.9213383736829406, \"p4\": 0.9035373547021504, \"phi\": 0.8370879363867809}, {\"truth_threshold\": 23.900000356137753, \"match_probability\": 0.9999999361173434, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4556.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1982.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6968491893545427, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30315081064545735, \"precision\": 1.0, \"recall\": 0.6968491893545427, \"specificity\": 1.0, \"npv\": 0.9998413504454995, \"accuracy\": 0.9998414082816564, \"f1\": 0.8213448711014963, \"f2\": 0.7418262342060701, \"f0_5\": 0.9199580001615378, \"p4\": 0.9018780566394147, \"phi\": 0.8347087123907942}, {\"truth_threshold\": 24.00000035762787, \"match_probability\": 0.9999999403953735, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4542.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 1996.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6947078617314163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30529213826858365, \"precision\": 1.0, \"recall\": 0.6947078617314163, \"specificity\": 1.0, \"npv\": 0.9998402299919683, \"accuracy\": 0.9998402880576115, \"f1\": 0.81985559566787, \"f2\": 0.7398840164201472, \"f0_5\": 0.9192099085242451, \"p4\": 0.9009792738072309, \"phi\": 0.8334247825993464}, {\"truth_threshold\": 24.100000359117985, \"match_probability\": 0.9999999443869169, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4523.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2015.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6918017742428877, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.30819822575711225, \"precision\": 1.0, \"recall\": 0.6918017742428877, \"specificity\": 1.0, \"npv\": 0.9998387093804784, \"accuracy\": 0.9998387677535507, \"f1\": 0.8178284061115632, \"f2\": 0.7372453137734312, \"f0_5\": 0.9181892001624036, \"p4\": 0.8997534942169106, \"phi\": 0.8316791407184226}, {\"truth_threshold\": 24.2000003606081, \"match_probability\": 0.9999999481111586, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4508.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2030.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6895074946466809, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31049250535331907, \"precision\": 1.0, \"recall\": 0.6895074946466809, \"specificity\": 1.0, \"npv\": 0.9998375089009902, \"accuracy\": 0.9998375675135027, \"f1\": 0.8162230671736375, \"f2\": 0.7351598173515982, \"f0_5\": 0.9173789173789174, \"p4\": 0.8987808557049325, \"phi\": 0.8302984137140696}, {\"truth_threshold\": 24.300000362098217, \"match_probability\": 0.999999951585999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4478.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2060.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6849189354542674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31508106454573265, \"precision\": 1.0, \"recall\": 0.6849189354542674, \"specificity\": 1.0, \"npv\": 0.9998351079506623, \"accuracy\": 0.9998351670334067, \"f1\": 0.8129992737835875, \"f2\": 0.7309826967025792, \"f0_5\": 0.9157464212678936, \"p4\": 0.8968224358663994, \"phi\": 0.8275300585280091}, {\"truth_threshold\": 24.400000363588333, \"match_probability\": 0.9999999548281396, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4465.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2073.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6829305598042215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31706944019577854, \"precision\": 1.0, \"recall\": 0.6829305598042215, \"specificity\": 1.0, \"npv\": 0.9998340675424346, \"accuracy\": 0.9998341268253651, \"f1\": 0.811596837226211, \"f2\": 0.7291700689159617, \"f0_5\": 0.9150340191819002, \"p4\": 0.8959682976618941, \"phi\": 0.826327561840997}, {\"truth_threshold\": 24.50000036507845, \"match_probability\": 0.999999957853164, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4446.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2092.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6800244723156929, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.31997552768430715, \"precision\": 1.0, \"recall\": 0.6800244723156929, \"specificity\": 1.0, \"npv\": 0.999832546949689, \"accuracy\": 0.9998326065213042, \"f1\": 0.8095411507647488, \"f2\": 0.7265180730766717, \"f0_5\": 0.9139873365677165, \"p4\": 0.8947139151375466, \"phi\": 0.8245669167165982}, {\"truth_threshold\": 24.600000366568565, \"match_probability\": 0.9999999606756114, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4436.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2102.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6784949525848883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32150504741511166, \"precision\": 1.0, \"recall\": 0.6784949525848883, \"specificity\": 1.0, \"npv\": 0.9998317466395754, \"accuracy\": 0.9998318063612722, \"f1\": 0.8084563513759796, \"f2\": 0.7251209624689421, \"f0_5\": 0.9134338192900091, \"p4\": 0.8940508209861183, \"phi\": 0.8236387518378946}, {\"truth_threshold\": 24.70000036805868, \"match_probability\": 0.999999963309048, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4425.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2113.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6768124808810033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3231875191189966, \"precision\": 1.0, \"recall\": 0.6768124808810033, \"specificity\": 1.0, \"npv\": 0.9998308662999301, \"accuracy\": 0.9998309261852371, \"f1\": 0.8072607862811274, \"f2\": 0.7235830853255715, \"f0_5\": 0.9128228401683307, \"p4\": 0.8933190991792779, \"phi\": 0.8226165626109522}, {\"truth_threshold\": 24.800000369548798, \"match_probability\": 0.9999999657661313, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4414.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2124.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6751300091771184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3248699908228816, \"precision\": 1.0, \"recall\": 0.6751300091771184, \"specificity\": 1.0, \"npv\": 0.9998299859618353, \"accuracy\": 0.9998300460092019, \"f1\": 0.8060628195763331, \"f2\": 0.722044101289014, \"f0_5\": 0.91220963875341, \"p4\": 0.8925849369517723, \"phi\": 0.8215931034264905}, {\"truth_threshold\": 24.900000371038914, \"match_probability\": 0.999999968058671, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4405.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2133.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6737534414193943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3262465585806057, \"precision\": 1.0, \"recall\": 0.6737534414193943, \"specificity\": 1.0, \"npv\": 0.9998292656863651, \"accuracy\": 0.999829325865173, \"f1\": 0.8050808736178379, \"f2\": 0.7207841083876035, \"f0_5\": 0.911706267075089, \"p4\": 0.8919824350298745, \"phi\": 0.8207547798142966}, {\"truth_threshold\": 25.00000037252903, \"match_probability\": 0.9999999701976862, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4384.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2154.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6705414499847048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.32945855001529517, \"precision\": 1.0, \"recall\": 0.6705414499847048, \"specificity\": 1.0, \"npv\": 0.9998275850476375, \"accuracy\": 0.9998276455291059, \"f1\": 0.8027833730086065, \"f2\": 0.7178412365732251, \"f0_5\": 0.9105258785411647, \"p4\": 0.890570174259922, \"phi\": 0.818795358201638}, {\"truth_threshold\": 25.100000374019146, \"match_probability\": 0.9999999721934579, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4366.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2172.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6677883144692567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3322116855307434, \"precision\": 1.0, \"recall\": 0.6677883144692567, \"specificity\": 1.0, \"npv\": 0.9998261445046536, \"accuracy\": 0.9998262052410483, \"f1\": 0.8008070432868672, \"f2\": 0.7153155514778163, \"f0_5\": 0.9095075410382468, \"p4\": 0.889352455534928, \"phi\": 0.8171121194799756}, {\"truth_threshold\": 25.200000375509262, \"match_probability\": 0.9999999740555788, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4347.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2191.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6648822269807281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3351177730192719, \"precision\": 1.0, \"recall\": 0.6648822269807281, \"specificity\": 1.0, \"npv\": 0.9998246239360072, \"accuracy\": 0.9998246849369874, \"f1\": 0.7987138263665595, \"f2\": 0.7126463162726647, \"f0_5\": 0.9084259801053247, \"p4\": 0.8880598018385625, \"phi\": 0.8153316028173698}, {\"truth_threshold\": 25.300000376999378, \"match_probability\": 0.9999999757929992, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4339.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2199.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6636586111960844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.33634138880391556, \"precision\": 1.0, \"recall\": 0.6636586111960844, \"specificity\": 1.0, \"npv\": 0.9998239836979609, \"accuracy\": 0.9998240448089618, \"f1\": 0.7978302840856853, \"f2\": 0.7115214325538683, \"f0_5\": 0.9079685276638486, \"p4\": 0.8875132731248652, \"phi\": 0.81458074888959}, {\"truth_threshold\": 25.400000378489494, \"match_probability\": 0.9999999774140695, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4327.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2211.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.661823187519119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.338176812480881, \"precision\": 1.0, \"recall\": 0.661823187519119, \"specificity\": 1.0, \"npv\": 0.9998230233424287, \"accuracy\": 0.9998230846169234, \"f1\": 0.7965025310630465, \"f2\": 0.7098329997703337, \"f0_5\": 0.907280046968045, \"p4\": 0.8866909611855933, \"phi\": 0.8134531702953088}, {\"truth_threshold\": 25.50000037997961, \"match_probability\": 0.9999999789265818, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4310.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2228.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6592230039767513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3407769960232487, \"precision\": 1.0, \"recall\": 0.6592230039767513, \"specificity\": 1.0, \"npv\": 0.9998216628419163, \"accuracy\": 0.9998217243448689, \"f1\": 0.7946165191740413, \"f2\": 0.7074387761801589, \"f0_5\": 0.9062999411220456, \"p4\": 0.8855208155917281, \"phi\": 0.8118530901706777}, {\"truth_threshold\": 25.600000381469727, \"match_probability\": 0.9999999803378055, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4297.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2241.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6572346283267054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34276537167329457, \"precision\": 1.0, \"recall\": 0.6572346283267054, \"specificity\": 1.0, \"npv\": 0.9998206224616698, \"accuracy\": 0.9998206841368273, \"f1\": 0.7931702814951546, \"f2\": 0.7056060954382738, \"f0_5\": 0.9055466576751243, \"p4\": 0.8846218551733269, \"phi\": 0.8106273713593508}, {\"truth_threshold\": 25.700000382959843, \"match_probability\": 0.9999999816545239, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4287.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2251.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6557051085959009, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34429489140409913, \"precision\": 1.0, \"recall\": 0.6557051085959009, \"specificity\": 1.0, \"npv\": 0.9998198221706458, \"accuracy\": 0.9998198839767953, \"f1\": 0.7920554272517321, \"f2\": 0.7041952757974966, \"f0_5\": 0.904964958203158, \"p4\": 0.8839278886178521, \"phi\": 0.8096832498407865}, {\"truth_threshold\": 25.80000038444996, \"match_probability\": 0.9999999828830655, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4274.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2264.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.653716732945855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.34628326705414497, \"precision\": 1.0, \"recall\": 0.653716732945855, \"specificity\": 1.0, \"npv\": 0.9998187817942299, \"accuracy\": 0.9998188437687537, \"f1\": 0.7906030336662967, \"f2\": 0.702359823834878, \"f0_5\": 0.9042058051959042, \"p4\": 0.8830225181611127, \"phi\": 0.8084542458126054}, {\"truth_threshold\": 25.900000385940075, \"match_probability\": 0.9999999840293354, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4268.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2270.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6527990211073723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3472009788926277, \"precision\": 1.0, \"recall\": 0.6527990211073723, \"specificity\": 1.0, \"npv\": 0.9998183016212298, \"accuracy\": 0.9998183636727346, \"f1\": 0.7899315195261891, \"f2\": 0.7015121630506246, \"f0_5\": 0.9038542990258365, \"p4\": 0.8826034239814592, \"phi\": 0.8078863834621638}, {\"truth_threshold\": 26.00000038743019, \"match_probability\": 0.999999985098843, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4257.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2281.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6511165494034873, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3488834505965127, \"precision\": 1.0, \"recall\": 0.6511165494034873, \"specificity\": 1.0, \"npv\": 0.9998174213052607, \"accuracy\": 0.9998174834966993, \"f1\": 0.78869847151459, \"f2\": 0.6999572494985037, \"f0_5\": 0.9032080115420521, \"p4\": 0.8818330561456207, \"phi\": 0.8068442658864065}, {\"truth_threshold\": 26.100000388920307, \"match_probability\": 0.9999999860967289, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4248.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2290.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6497399816457632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35026001835423676, \"precision\": 1.0, \"recall\": 0.6497399816457632, \"specificity\": 1.0, \"npv\": 0.9998167010478937, \"accuracy\": 0.9998167633526706, \"f1\": 0.7876877433710365, \"f2\": 0.6986842105263158, \"f0_5\": 0.9026774330641734, \"p4\": 0.8812007947167311, \"phi\": 0.8059906233871372}, {\"truth_threshold\": 26.200000390410423, \"match_probability\": 0.9999999870277894, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4227.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2311.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6465279902110738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3534720097889263, \"precision\": 1.0, \"recall\": 0.6465279902110738, \"specificity\": 1.0, \"npv\": 0.9998150204514061, \"accuracy\": 0.9998150830166033, \"f1\": 0.785322805387831, \"f2\": 0.6957108528918002, \"f0_5\": 0.9014330802695556, \"p4\": 0.8797186124788048, \"phi\": 0.8039952709781888}, {\"truth_threshold\": 26.30000039190054, \"match_probability\": 0.9999999878964996, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4216.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2322.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6448455185071887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.35515448149281126, \"precision\": 1.0, \"recall\": 0.6448455185071887, \"specificity\": 1.0, \"npv\": 0.9998141401412151, \"accuracy\": 0.9998142028405681, \"f1\": 0.7840803421982518, \"f2\": 0.6941517386722866, \"f0_5\": 0.9007777113067259, \"p4\": 0.8789383482184896, \"phi\": 0.8029481101604145}, {\"truth_threshold\": 26.400000393390656, \"match_probability\": 0.9999999887070348, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4205.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2333.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6431630468033037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3568369531966962, \"precision\": 1.0, \"recall\": 0.6431630468033037, \"specificity\": 1.0, \"npv\": 0.9998132598325742, \"accuracy\": 0.9998133226645329, \"f1\": 0.7828353346365075, \"f2\": 0.6925914945482097, \"f0_5\": 0.9001198732768216, \"p4\": 0.8781553963531536, \"phi\": 0.8018995837561343}, {\"truth_threshold\": 26.50000039488077, \"match_probability\": 0.9999999894632908, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4187.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2351.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6404099112878556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3595900887121444, \"precision\": 1.0, \"recall\": 0.6404099112878556, \"specificity\": 1.0, \"npv\": 0.9998118193308693, \"accuracy\": 0.9998118823764753, \"f1\": 0.7807925407925408, \"f2\": 0.6900359273542306, \"f0_5\": 0.8990380486129005, \"p4\": 0.8768683687338288, \"phi\": 0.8001808536338716}, {\"truth_threshold\": 26.600000396370888, \"match_probability\": 0.9999999901689027, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4173.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2365.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6382685836647293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.36173141633527073, \"precision\": 1.0, \"recall\": 0.6382685836647293, \"specificity\": 1.0, \"npv\": 0.999810698943524, \"accuracy\": 0.9998107621524305, \"f1\": 0.7791989543459994, \"f2\": 0.6880461665292663, \"f0_5\": 0.8981919931123548, \"p4\": 0.8758623066942601, \"phi\": 0.7988415104058666}, {\"truth_threshold\": 26.700000397861004, \"match_probability\": 0.999999990827262, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4155.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2383.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6355154481492811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3644845518507189, \"precision\": 1.0, \"recall\": 0.6355154481492811, \"specificity\": 1.0, \"npv\": 0.9998092584491983, \"accuracy\": 0.9998093218643729, \"f1\": 0.7771439259328533, \"f2\": 0.6854852014386116, \"f0_5\": 0.8970981950082045, \"p4\": 0.8745622664808305, \"phi\": 0.797116195386308}, {\"truth_threshold\": 26.80000039935112, \"match_probability\": 0.9999999914415327, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4140.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2398.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6332211685530743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3667788314469257, \"precision\": 1.0, \"recall\": 0.6332211685530743, \"specificity\": 1.0, \"npv\": 0.999808058040431, \"accuracy\": 0.9998081216243249, \"f1\": 0.7754261097583817, \"f2\": 0.6833487389409745, \"f0_5\": 0.8961814875746817, \"p4\": 0.8734732445521758, \"phi\": 0.7956755788895005}, {\"truth_threshold\": 26.900000400841236, \"match_probability\": 0.9999999920146677, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4112.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2426.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6289385133068217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37106148669317834, \"precision\": 1.0, \"recall\": 0.6289385133068217, \"specificity\": 1.0, \"npv\": 0.9998058172851111, \"accuracy\": 0.9998058811762353, \"f1\": 0.7722065727699531, \"f2\": 0.6793550092519165, \"f0_5\": 0.8944574958670495, \"p4\": 0.8714265152486926, \"phi\": 0.7929794349911033}, {\"truth_threshold\": 27.000000402331352, \"match_probability\": 0.9999999925494215, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4096.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2442.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6264912817375344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.37350871826246557, \"precision\": 1.0, \"recall\": 0.6264912817375344, \"specificity\": 1.0, \"npv\": 0.9998045368580092, \"accuracy\": 0.9998046009201841, \"f1\": 0.7703592251269513, \"f2\": 0.6770695583179053, \"f0_5\": 0.8934647936480238, \"p4\": 0.8702487585154107, \"phi\": 0.7914346629906831}, {\"truth_threshold\": 27.10000040382147, \"match_probability\": 0.9999999930483645, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4082.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2456.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6243499541144081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3756500458855919, \"precision\": 1.0, \"recall\": 0.6243499541144081, \"specificity\": 1.0, \"npv\": 0.9998034164869853, \"accuracy\": 0.9998034806961392, \"f1\": 0.7687382297551789, \"f2\": 0.6750678044585566, \"f0_5\": 0.8925916207469605, \"p4\": 0.8692132857359537, \"phi\": 0.7900805131169087}, {\"truth_threshold\": 27.200000405311584, \"match_probability\": 0.9999999935138947, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4071.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2467.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.622667482410523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3773325175894769, \"precision\": 1.0, \"recall\": 0.622667482410523, \"specificity\": 1.0, \"npv\": 0.9998025361972281, \"accuracy\": 0.9998026005201041, \"f1\": 0.7674615892167028, \"f2\": 0.6734936968533898, \"f0_5\": 0.8919025501708877, \"p4\": 0.8683964471127058, \"phi\": 0.789014909948845}, {\"truth_threshold\": 27.3000004068017, \"match_probability\": 0.9999999939482498, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4062.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2476.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6212909146527991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.378709085347201, \"precision\": 1.0, \"recall\": 0.6212909146527991, \"specificity\": 1.0, \"npv\": 0.999801815961307, \"accuracy\": 0.9998018803760752, \"f1\": 0.7664150943396226, \"f2\": 0.6722049381081617, \"f0_5\": 0.8913367857456332, \"p4\": 0.8677259838532362, \"phi\": 0.78814198258317}, {\"truth_threshold\": 27.400000408291817, \"match_probability\": 0.9999999943535174, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4056.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2482.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6203732028143163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3796267971856837, \"precision\": 1.0, \"recall\": 0.6203732028143163, \"specificity\": 1.0, \"npv\": 0.9998013358046028, \"accuracy\": 0.999801400280056, \"f1\": 0.7657164432697754, \"f2\": 0.6713453389830508, \"f0_5\": 0.8909586152359195, \"p4\": 0.8672779335085573, \"phi\": 0.7875594941787784}, {\"truth_threshold\": 27.500000409781933, \"match_probability\": 0.9999999947316455, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4036.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2502.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6173141633527073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3826858366472928, \"precision\": 1.0, \"recall\": 0.6173141633527073, \"specificity\": 1.0, \"npv\": 0.9997997352855861, \"accuracy\": 0.999799799959992, \"f1\": 0.763381880083223, \"f2\": 0.6684775407446668, \"f0_5\": 0.8896922669958558, \"p4\": 0.8657781872085841, \"phi\": 0.78561475107592}, {\"truth_threshold\": 27.60000041127205, \"match_probability\": 0.9999999950844514, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4027.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2511.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6159375955949832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3840624044050168, \"precision\": 1.0, \"recall\": 0.6159375955949832, \"specificity\": 1.0, \"npv\": 0.9997990150537004, \"accuracy\": 0.9997990798159632, \"f1\": 0.7623284429720776, \"f2\": 0.6671857914443818, \"f0_5\": 0.889119491300892, \"p4\": 0.8651001491095405, \"phi\": 0.7847380463635037}, {\"truth_threshold\": 27.700000412762165, \"match_probability\": 0.999999995413631, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4012.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2526.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6136433159987764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.38635668400122364, \"precision\": 1.0, \"recall\": 0.6136433159987764, \"specificity\": 1.0, \"npv\": 0.9997978146695302, \"accuracy\": 0.9997978795759151, \"f1\": 0.7605687203791469, \"f2\": 0.6650311629757326, \"f0_5\": 0.8881608075799168, \"p4\": 0.863965706758565, \"phi\": 0.7832746940391605}, {\"truth_threshold\": 27.80000041425228, \"match_probability\": 0.9999999957207664, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3991.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2547.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6104313245640869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3895686754359131, \"precision\": 1.0, \"recall\": 0.6104313245640869, \"specificity\": 1.0, \"npv\": 0.9997961341365345, \"accuracy\": 0.999796199239848, \"f1\": 0.758096685345237, \"f2\": 0.662011080516206, \"f0_5\": 0.886810061327882, \"p4\": 0.8623682248082081, \"phi\": 0.7812214016877791}, {\"truth_threshold\": 27.900000415742397, \"match_probability\": 0.9999999960073339, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3983.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2555.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6092077087794433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39079229122055675, \"precision\": 1.0, \"recall\": 0.6092077087794433, \"specificity\": 1.0, \"npv\": 0.9997954939349745, \"accuracy\": 0.9997955591118224, \"f1\": 0.7571523619427811, \"f2\": 0.6608594657375145, \"f0_5\": 0.8862928348909658, \"p4\": 0.8617567974489632, \"phi\": 0.7804377759361328}, {\"truth_threshold\": 28.000000417232513, \"match_probability\": 0.9999999962747108, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3959.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2579.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6055368614255124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.3944631385744876, \"precision\": 1.0, \"recall\": 0.6055368614255124, \"specificity\": 1.0, \"npv\": 0.9997935733352138, \"accuracy\": 0.9997936387277455, \"f1\": 0.7543107554539392, \"f2\": 0.657400949819003, \"f0_5\": 0.8847322785375883, \"p4\": 0.8599129566611442, \"phi\": 0.7780821694852049}, {\"truth_threshold\": 28.10000041872263, \"match_probability\": 0.9999999965241823, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3937.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2601.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.6021719180177424, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.39782808198225755, \"precision\": 1.0, \"recall\": 0.6021719180177424, \"specificity\": 1.0, \"npv\": 0.9997918127919153, \"accuracy\": 0.9997918783756752, \"f1\": 0.7516945107398568, \"f2\": 0.6542257968028183, \"f0_5\": 0.8832899578210536, \"p4\": 0.8582100624669508, \"phi\": 0.7759165892847912}, {\"truth_threshold\": 28.200000420212746, \"match_probability\": 0.9999999967569474, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3906.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2632.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5974304068522484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4025695931477516, \"precision\": 1.0, \"recall\": 0.5974304068522484, \"specificity\": 1.0, \"npv\": 0.9997893320368823, \"accuracy\": 0.9997893978795759, \"f1\": 0.7479892761394102, \"f2\": 0.6497438285980438, \"f0_5\": 0.881238155401137, \"p4\": 0.8557896389568707, \"phi\": 0.7728548035726583}, {\"truth_threshold\": 28.300000421702862, \"match_probability\": 0.9999999969741249, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3892.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2646.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5952890792291221, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.40471092077087795, \"precision\": 1.0, \"recall\": 0.5952890792291221, \"specificity\": 1.0, \"npv\": 0.9997882116999349, \"accuracy\": 0.9997882776555311, \"f1\": 0.7463087248322148, \"f2\": 0.6477166821994408, \"f0_5\": 0.8803039898670044, \"p4\": 0.8546884455976975, \"phi\": 0.771468083569881}, {\"truth_threshold\": 28.400000423192978, \"match_probability\": 0.9999999971767587, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3861.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2677.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5905475680636281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.409452431936372, \"precision\": 1.0, \"recall\": 0.5905475680636281, \"specificity\": 1.0, \"npv\": 0.9997857309627723, \"accuracy\": 0.9997857971594318, \"f1\": 0.7425714010962593, \"f2\": 0.6432212707826609, \"f0_5\": 0.8782185424438177, \"p4\": 0.8522319300038024, \"phi\": 0.7683885944005038}, {\"truth_threshold\": 28.500000424683094, \"match_probability\": 0.9999999973658228, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3836.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2702.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5867237687366167, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4132762312633833, \"precision\": 1.0, \"recall\": 0.5867237687366167, \"specificity\": 1.0, \"npv\": 0.9997837303772537, \"accuracy\": 0.9997837967593519, \"f1\": 0.7395411605937922, \"f2\": 0.6395891690009337, \"f0_5\": 0.8765195137555982, \"p4\": 0.8502324329966748, \"phi\": 0.7658961275581015}, {\"truth_threshold\": 28.60000042617321, \"match_probability\": 0.9999999975422257, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3819.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2719.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.584123585194249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.415876414805751, \"precision\": 1.0, \"recall\": 0.584123585194249, \"specificity\": 1.0, \"npv\": 0.9997823699836742, \"accuracy\": 0.9997824364872975, \"f1\": 0.7374722409964275, \"f2\": 0.6371158786827267, \"f0_5\": 0.875355276427982, \"p4\": 0.8488632582121125, \"phi\": 0.7641966123772512}, {\"truth_threshold\": 28.700000427663326, \"match_probability\": 0.9999999977068155, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3793.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2745.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5801468338941572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4198531661058428, \"precision\": 1.0, \"recall\": 0.5801468338941572, \"specificity\": 1.0, \"npv\": 0.99978028938889, \"accuracy\": 0.9997803560712143, \"f1\": 0.7342948407704966, \"f2\": 0.6333277675738854, \"f0_5\": 0.8735605711653616, \"p4\": 0.8467541548192153, \"phi\": 0.7615900271660263}, {\"truth_threshold\": 28.800000429153442, \"match_probability\": 0.9999999978603832, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3776.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2762.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5775466503517895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42245334964821046, \"precision\": 1.0, \"recall\": 0.5775466503517895, \"specificity\": 1.0, \"npv\": 0.9997789290046747, \"accuracy\": 0.9997789957991599, \"f1\": 0.7322086484390149, \"f2\": 0.6308473670141673, \"f0_5\": 0.8723777839386379, \"p4\": 0.8453651720296272, \"phi\": 0.7598808929950466}, {\"truth_threshold\": 28.90000043064356, \"match_probability\": 0.999999998003667, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3754.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2784.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5741817069440196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4258182930559804, \"precision\": 1.0, \"recall\": 0.5741817069440196, \"specificity\": 1.0, \"npv\": 0.9997771685129504, \"accuracy\": 0.9997772354470894, \"f1\": 0.729498639720171, \"f2\": 0.6276332508526717, \"f0_5\": 0.8708360397142062, \"p4\": 0.8435558539506934, \"phi\": 0.7576633561024477}, {\"truth_threshold\": 29.000000432133675, \"match_probability\": 0.9999999981373554, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3736.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2802.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5714285714285714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.42857142857142855, \"precision\": 1.0, \"recall\": 0.5714285714285714, \"specificity\": 1.0, \"npv\": 0.9997757281152422, \"accuracy\": 0.9997757951590318, \"f1\": 0.7272727272727273, \"f2\": 0.625, \"f0_5\": 0.8695652173913043, \"p4\": 0.8420654960043185, \"phi\": 0.7558441744604854}, {\"truth_threshold\": 29.10000043362379, \"match_probability\": 0.9999999982620912, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3705.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2833.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5666870602630774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4333129397369226, \"precision\": 1.0, \"recall\": 0.5666870602630774, \"specificity\": 1.0, \"npv\": 0.9997732474400293, \"accuracy\": 0.9997733146629326, \"f1\": 0.7234208727911745, \"f2\": 0.6204575141507854, \"f0_5\": 0.8673564940537504, \"p4\": 0.8394774021283078, \"phi\": 0.7527008453040692}, {\"truth_threshold\": 29.200000435113907, \"match_probability\": 0.9999999983784738, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3683.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2855.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5633221168553074, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4366778831446926, \"precision\": 1.0, \"recall\": 0.5633221168553074, \"specificity\": 1.0, \"npv\": 0.999771486968314, \"accuracy\": 0.9997715543108622, \"f1\": 0.7206731239604736, \"f2\": 0.6172280878163231, \"f0_5\": 0.8657733897508227, \"p4\": 0.8376240906995253, \"phi\": 0.7504621179050739}, {\"truth_threshold\": 29.300000436604023, \"match_probability\": 0.9999999984870624, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3657.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2881.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5593453655552156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4406546344447843, \"precision\": 1.0, \"recall\": 0.5593453655552156, \"specificity\": 1.0, \"npv\": 0.9997694064188256, \"accuracy\": 0.999769473894779, \"f1\": 0.7174104953408533, \"f2\": 0.6134053473783085, \"f0_5\": 0.8638854767079278, \"p4\": 0.8354158060119907, \"phi\": 0.747807718671223}, {\"truth_threshold\": 29.40000043809414, \"match_probability\": 0.9999999985883794, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3642.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2896.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5570510859590089, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4429489140409911, \"precision\": 1.0, \"recall\": 0.5570510859590089, \"specificity\": 1.0, \"npv\": 0.9997682061057521, \"accuracy\": 0.999768273654731, \"f1\": 0.7155206286836935, \"f2\": 0.6111968852789152, \"f0_5\": 0.8627878328437412, \"p4\": 0.8341328256610646, \"phi\": 0.7462720448459124}, {\"truth_threshold\": 29.500000439584255, \"match_probability\": 0.9999999986829113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3600.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2938.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5506271030896298, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.44937289691037013, \"precision\": 1.0, \"recall\": 0.5506271030896298, \"specificity\": 1.0, \"npv\": 0.9997648452444793, \"accuracy\": 0.9997649129825965, \"f1\": 0.7101992503452358, \"f2\": 0.6050013444474321, \"f0_5\": 0.8596809628426784, \"p4\": 0.8305050619827865, \"phi\": 0.7419552685356576}, {\"truth_threshold\": 29.60000044107437, \"match_probability\": 0.9999999987711129, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3574.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2964.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5466503517895381, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4533496482104619, \"precision\": 1.0, \"recall\": 0.5466503517895381, \"specificity\": 1.0, \"npv\": 0.999762764722634, \"accuracy\": 0.9997628325665133, \"f1\": 0.7068829113924051, \"f2\": 0.6011572360896185, \"f0_5\": 0.8577325525583182, \"p4\": 0.8282327689623699, \"phi\": 0.739270361262853}, {\"truth_threshold\": 29.700000442564487, \"match_probability\": 0.9999999988534077, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3544.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 2994.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5420617925971245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4579382074028755, \"precision\": 1.0, \"recall\": 0.5420617925971245, \"specificity\": 1.0, \"npv\": 0.9997603641312648, \"accuracy\": 0.9997604320864173, \"f1\": 0.7030351120809363, \"f2\": 0.5967133620689655, \"f0_5\": 0.8554600753113836, \"p4\": 0.8255852467999479, \"phi\": 0.7361602374133958}, {\"truth_threshold\": 29.800000444054604, \"match_probability\": 0.9999999989301916, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3515.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3023.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5376261853777914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4623738146222086, \"precision\": 1.0, \"recall\": 0.5376261853777914, \"specificity\": 1.0, \"npv\": 0.9997580435705662, \"accuracy\": 0.9997581116223244, \"f1\": 0.6992937431612454, \"f2\": 0.5924090740553477, \"f0_5\": 0.8532381784639286, \"p4\": 0.8229994666399375, \"phi\": 0.733141257375144}, {\"truth_threshold\": 29.90000044554472, \"match_probability\": 0.9999999990018335, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3486.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3052.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5331905781584583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4668094218415418, \"precision\": 1.0, \"recall\": 0.5331905781584583, \"specificity\": 1.0, \"npv\": 0.9997557230206401, \"accuracy\": 0.9997557911582317, \"f1\": 0.6955307262569832, \"f2\": 0.5880963627775153, \"f0_5\": 0.8509911141490089, \"p4\": 0.8203872222250156, \"phi\": 0.7301098081621713}, {\"truth_threshold\": 30.000000447034836, \"match_probability\": 0.9999999990686778, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3449.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3089.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5275313551544815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4724686448455185, \"precision\": 1.0, \"recall\": 0.5275313551544815, \"specificity\": 1.0, \"npv\": 0.9997527623346503, \"accuracy\": 0.9997528305661132, \"f1\": 0.6906979072794633, \"f2\": 0.5825816695381912, \"f0_5\": 0.848086947968919, \"p4\": 0.817015288138656, \"phi\": 0.7262237461924764}, {\"truth_threshold\": 30.100000448524952, \"match_probability\": 0.9999999991310455, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3421.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3117.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5232486999082289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4767513000917712, \"precision\": 1.0, \"recall\": 0.5232486999082289, \"specificity\": 1.0, \"npv\": 0.999750521827179, \"accuracy\": 0.9997505901180236, \"f1\": 0.6870167687518827, \"f2\": 0.5783992155006256, \"f0_5\": 0.8458609435268519, \"p4\": 0.814433946539948, \"phi\": 0.7232690790975685}, {\"truth_threshold\": 30.200000450015068, \"match_probability\": 0.9999999991892369, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3368.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3170.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5151422453349648, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48485775466503517, \"precision\": 1.0, \"recall\": 0.5151422453349648, \"specificity\": 1.0, \"npv\": 0.9997462808941029, \"accuracy\": 0.999746349269854, \"f1\": 0.6799919240864123, \"f2\": 0.5704607046070461, \"f0_5\": 0.8415792103948025, \"p4\": 0.8094765115832974, \"phi\": 0.7176430476950701}, {\"truth_threshold\": 30.300000451505184, \"match_probability\": 0.9999999992435312, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3338.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3200.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5105536861425513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.48944631385744874, \"precision\": 1.0, \"recall\": 0.5105536861425513, \"specificity\": 1.0, \"npv\": 0.9997438803818935, \"accuracy\": 0.9997439487897579, \"f1\": 0.6759821790198461, \"f2\": 0.5659545608680909, \"f0_5\": 0.8391151332327803, \"p4\": 0.8066282150110221, \"phi\": 0.7144388870487338}, {\"truth_threshold\": 30.4000004529953, \"match_probability\": 0.9999999992941897, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3307.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3231.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5058121749770572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4941878250229428, \"precision\": 1.0, \"recall\": 0.5058121749770572, \"specificity\": 1.0, \"npv\": 0.9997413998647211, \"accuracy\": 0.9997414682936587, \"f1\": 0.6718131030980193, \"f2\": 0.5612885705556876, \"f0_5\": 0.8365374886168168, \"p4\": 0.803652259938511, \"phi\": 0.7111127701568736}, {\"truth_threshold\": 30.500000454485416, \"match_probability\": 0.9999999993414557, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3276.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3262.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.5010706638115632, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.4989293361884368, \"precision\": 1.0, \"recall\": 0.5010706638115632, \"specificity\": 1.0, \"npv\": 0.9997389193598578, \"accuracy\": 0.9997389877975595, \"f1\": 0.6676176890156919, \"f2\": 0.5566127497621313, \"f0_5\": 0.8339272986457591, \"p4\": 0.8006424924540139, \"phi\": 0.7077710392223595}, {\"truth_threshold\": 30.600000455975533, \"match_probability\": 0.9999999993855564, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3244.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3294.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4961762006729887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5038237993270113, \"precision\": 1.0, \"recall\": 0.4961762006729887, \"specificity\": 1.0, \"npv\": 0.9997363588516195, \"accuracy\": 0.9997364272854571, \"f1\": 0.6632590472296054, \"f2\": 0.5517757518029663, \"f0_5\": 0.8311981141744389, \"p4\": 0.7974995548331207, \"phi\": 0.7043048971927174}, {\"truth_threshold\": 30.70000045746565, \"match_probability\": 0.9999999994267039, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3201.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3337.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4895992658305292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5104007341694707, \"precision\": 1.0, \"recall\": 0.4895992658305292, \"specificity\": 1.0, \"npv\": 0.9997329181893277, \"accuracy\": 0.9997329865973195, \"f1\": 0.6573570181743505, \"f2\": 0.5452594283378189, \"f0_5\": 0.8274738910143729, \"p4\": 0.793217376518894, \"phi\": 0.699620256119066}, {\"truth_threshold\": 30.800000458955765, \"match_probability\": 0.9999999994650958, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3175.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3363.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4856225145304374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5143774854695625, \"precision\": 1.0, \"recall\": 0.4856225145304374, \"specificity\": 1.0, \"npv\": 0.9997308378003613, \"accuracy\": 0.9997309061812363, \"f1\": 0.6537629980438587, \"f2\": 0.5413100555801821, \"f0_5\": 0.8251897286620231, \"p4\": 0.7905947944781891, \"phi\": 0.6967724185889052}, {\"truth_threshold\": 30.90000046044588, \"match_probability\": 0.9999999995009168, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3146.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3392.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4811869073111043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5188130926888956, \"precision\": 1.0, \"recall\": 0.4811869073111043, \"specificity\": 1.0, \"npv\": 0.9997285173767287, \"accuracy\": 0.9997285857171434, \"f1\": 0.6497315159025197, \"f2\": 0.5368967164994197, \"f0_5\": 0.8226126974165883, \"p4\": 0.7876394032828589, \"phi\": 0.6935822037993937}, {\"truth_threshold\": 31.000000461935997, \"match_probability\": 0.9999999995343388, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3115.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3423.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.47644539614561027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5235546038543897, \"precision\": 1.0, \"recall\": 0.47644539614561027, \"specificity\": 1.0, \"npv\": 0.9997260369357915, \"accuracy\": 0.9997261052210442, \"f1\": 0.6453952139231327, \"f2\": 0.532169337479072, \"f0_5\": 0.8198231392778187, \"p4\": 0.7844443981403797, \"phi\": 0.6901556836721366}, {\"truth_threshold\": 31.100000463426113, \"match_probability\": 0.9999999995655228, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3093.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3445.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.47308045273784033, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5269195472621597, \"precision\": 1.0, \"recall\": 0.47308045273784033, \"specificity\": 1.0, \"npv\": 0.9997242766303355, \"accuracy\": 0.9997243448689738, \"f1\": 0.6423009033329873, \"f2\": 0.5288083433065481, \"f0_5\": 0.8178212585933369, \"p4\": 0.7821541875992409, \"phi\": 0.6877136129242237}, {\"truth_threshold\": 31.20000046491623, \"match_probability\": 0.9999999995946184, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3051.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3487.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4666564698684613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5333435301315387, \"precision\": 1.0, \"recall\": 0.4666564698684613, \"specificity\": 1.0, \"npv\": 0.9997209160644058, \"accuracy\": 0.9997209841968394, \"f1\": 0.6363541558035248, \"f2\": 0.5223778378933671, \"f0_5\": 0.8139472841745812, \"p4\": 0.7777284807168962, \"phi\": 0.6830272568091846}, {\"truth_threshold\": 31.300000466406345, \"match_probability\": 0.9999999996217657, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3033.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3505.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4639033343530132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5360966656469869, \"precision\": 1.0, \"recall\": 0.4639033343530132, \"specificity\": 1.0, \"npv\": 0.9997194758287808, \"accuracy\": 0.9997195439087817, \"f1\": 0.6337895726674329, \"f2\": 0.5196162412198047, \"f0_5\": 0.8122656668452062, \"p4\": 0.775809920865284, \"phi\": 0.6810089560751885}, {\"truth_threshold\": 31.40000046789646, \"match_probability\": 0.9999999996470949, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2991.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3547.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4574793514836341, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5425206485163658, \"precision\": 1.0, \"recall\": 0.4574793514836341, \"specificity\": 1.0, \"npv\": 0.9997161152951268, \"accuracy\": 0.9997161832366473, \"f1\": 0.6277678665127505, \"f2\": 0.5131592492193666, \"f0_5\": 0.8082909955680467, \"p4\": 0.771281343543147, \"phi\": 0.6762761862530371}, {\"truth_threshold\": 31.500000469386578, \"match_probability\": 0.9999999996707278, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2961.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3577.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.45289079229122053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5471092077087795, \"precision\": 1.0, \"recall\": 0.45289079229122053, \"specificity\": 1.0, \"npv\": 0.9997137149277776, \"accuracy\": 0.9997137827565513, \"f1\": 0.6234340456890199, \"f2\": 0.5085357056984852, \"f0_5\": 0.8054074638233054, \"p4\": 0.7680013479300131, \"phi\": 0.6728752755288611}, {\"truth_threshold\": 31.600000470876694, \"match_probability\": 0.9999999996927782, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2934.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3604.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.44876108901804834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5512389109819517, \"precision\": 1.0, \"recall\": 0.44876108901804834, \"specificity\": 1.0, \"npv\": 0.9997115546070188, \"accuracy\": 0.9997116223244649, \"f1\": 0.6195101351351351, \"f2\": 0.5043663618235578, \"f0_5\": 0.8027799058772026, \"p4\": 0.7650164524579206, \"phi\": 0.6697997058444949}, {\"truth_threshold\": 31.70000047236681, \"match_probability\": 0.999999999713352, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2895.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3643.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.44279596206791066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5572040379320893, \"precision\": 1.0, \"recall\": 0.44279596206791066, \"specificity\": 1.0, \"npv\": 0.9997084341601835, \"accuracy\": 0.9997085017003401, \"f1\": 0.6138026078660024, \"f2\": 0.49833029228491754, \"f0_5\": 0.7989292416381499, \"p4\": 0.7606488709113556, \"phi\": 0.6653321410328551}, {\"truth_threshold\": 31.800000473856926, \"match_probability\": 0.9999999997325479, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2875.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3663.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4397369226063016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5602630773936984, \"precision\": 1.0, \"recall\": 0.4397369226063016, \"specificity\": 1.0, \"npv\": 0.9997068339385936, \"accuracy\": 0.9997069013802761, \"f1\": 0.6108573249760969, \"f2\": 0.4952285802873187, \"f0_5\": 0.7969287060649739, \"p4\": 0.758382945831677, \"phi\": 0.6630294161382632}, {\"truth_threshold\": 31.900000475347042, \"match_probability\": 0.9999999997504584, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2841.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3697.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4345365555215662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5654634444784338, \"precision\": 1.0, \"recall\": 0.4345365555215662, \"specificity\": 1.0, \"npv\": 0.9997041135736477, \"accuracy\": 0.9997041808361672, \"f1\": 0.605821516153108, \"f2\": 0.489945848998034, \"f0_5\": 0.7934867612557256, \"p4\": 0.7544894481369315, \"phi\": 0.6590963374598842}, {\"truth_threshold\": 32.00000047683716, \"match_probability\": 0.9999999997671695, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2800.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3738.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4282655246252677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5717344753747323, \"precision\": 1.0, \"recall\": 0.4282655246252677, \"specificity\": 1.0, \"npv\": 0.999700833153257, \"accuracy\": 0.999700900180036, \"f1\": 0.5997001499250375, \"f2\": 0.4835589941972921, \"f0_5\": 0.7892659826361483, \"p4\": 0.7497236439401248, \"phi\": 0.6543220932986267}, {\"truth_threshold\": 32.100000478327274, \"match_probability\": 0.9999999997827614, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2765.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3773.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4229122055674518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5770877944325482, \"precision\": 1.0, \"recall\": 0.4229122055674518, \"specificity\": 1.0, \"npv\": 0.9996980328114202, \"accuracy\": 0.999698099619924, \"f1\": 0.5944319036869827, \"f2\": 0.47809247155652385, \"f0_5\": 0.7856006364359587, \"p4\": 0.7455927517891531, \"phi\": 0.6502188092924723}, {\"truth_threshold\": 32.20000047981739, \"match_probability\": 0.9999999997973092, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2720.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3818.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.41602936677883146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5839706332211686, \"precision\": 1.0, \"recall\": 0.41602936677883146, \"specificity\": 1.0, \"npv\": 0.9996944323949681, \"accuracy\": 0.9996944988997799, \"f1\": 0.587599913588248, \"f2\": 0.47104461069548353, \"f0_5\": 0.780801469743943, \"p4\": 0.7401948975024825, \"phi\": 0.6449048314919046}, {\"truth_threshold\": 32.30000048130751, \"match_probability\": 0.9999999998108828, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2698.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3840.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.41266442337106146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5873355766289385, \"precision\": 1.0, \"recall\": 0.41266442337106146, \"specificity\": 1.0, \"npv\": 0.9996926722008079, \"accuracy\": 0.9996927385477096, \"f1\": 0.5842355998267649, \"f2\": 0.46759098786828424, \"f0_5\": 0.7784189267166762, \"p4\": 0.737519702193418, \"phi\": 0.6422908999215402}, {\"truth_threshold\": 32.40000048279762, \"match_probability\": 0.9999999998235475, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2678.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3860.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.40960538390945245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5903946160905476, \"precision\": 1.0, \"recall\": 0.40960538390945245, \"specificity\": 1.0, \"npv\": 0.9996910720296776, \"accuracy\": 0.9996911382276455, \"f1\": 0.5811631944444444, \"f2\": 0.46444675685050296, \"f0_5\": 0.776231884057971, \"p4\": 0.7350666816302669, \"phi\": 0.6399053409290848}, {\"truth_threshold\": 32.50000048428774, \"match_probability\": 0.9999999998353639, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2656.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3882.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.40624044050168245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5937595594983175, \"precision\": 1.0, \"recall\": 0.40624044050168245, \"specificity\": 1.0, \"npv\": 0.9996893118473508, \"accuracy\": 0.9996893778755751, \"f1\": 0.5777681096367197, \"f2\": 0.4609830602610386, \"f0_5\": 0.7738025871110593, \"p4\": 0.732344925557475, \"phi\": 0.6372709207312787}, {\"truth_threshold\": 32.600000485777855, \"match_probability\": 0.9999999998463891, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2632.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3906.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.4025695931477516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.5974304068522484, \"precision\": 1.0, \"recall\": 0.4025695931477516, \"specificity\": 1.0, \"npv\": 0.9996873916555181, \"accuracy\": 0.9996874574914983, \"f1\": 0.5740458015267176, \"f2\": 0.4571984435797665, \"f0_5\": 0.771123872026251, \"p4\": 0.7293473545908598, \"phi\": 0.6343845415311591}, {\"truth_threshold\": 32.70000048726797, \"match_probability\": 0.999999999856676, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2608.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3930.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.39889874579382073, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6011012542061792, \"precision\": 1.0, \"recall\": 0.39889874579382073, \"specificity\": 1.0, \"npv\": 0.9996854714710619, \"accuracy\": 0.9996855371074215, \"f1\": 0.5703039580144326, \"f2\": 0.4534075104311544, \"f0_5\": 0.7684148497348262, \"p4\": 0.7263197339813031, \"phi\": 0.6314849806274976}, {\"truth_threshold\": 32.80000048875809, \"match_probability\": 0.999999999866274, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2572.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3966.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.39339247476292444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6066075252370755, \"precision\": 1.0, \"recall\": 0.39339247476292444, \"specificity\": 1.0, \"npv\": 0.9996825912082087, \"accuracy\": 0.9996826565313063, \"f1\": 0.5646542261251372, \"f2\": 0.44770923269739593, \"f0_5\": 0.7642933555212171, \"p4\": 0.7217209637768601, \"phi\": 0.6271105233791011}, {\"truth_threshold\": 32.9000004902482, \"match_probability\": 0.9999999998752291, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2547.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 3991.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3895686754359131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6104313245640869, \"precision\": 1.0, \"recall\": 0.3895686754359131, \"specificity\": 1.0, \"npv\": 0.9996805910354365, \"accuracy\": 0.9996806561312263, \"f1\": 0.5607044578976335, \"f2\": 0.4437436844489355, \"f0_5\": 0.7613894535453785, \"p4\": 0.718486162625368, \"phi\": 0.6240546800631062}, {\"truth_threshold\": 33.00000049173832, \"match_probability\": 0.9999999998835847, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2519.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4019.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.38528602018966046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6147139798103396, \"precision\": 1.0, \"recall\": 0.38528602018966046, \"specificity\": 1.0, \"npv\": 0.9996783508514339, \"accuracy\": 0.9996784156831366, \"f1\": 0.5562548305178315, \"f2\": 0.4392940602002023, \"f0_5\": 0.758095582039244, \"p4\": 0.7148223228203463, \"phi\": 0.6206142870328656}, {\"truth_threshold\": 33.100000493228436, \"match_probability\": 0.9999999998913807, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2499.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4039.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3822269807280514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6177730192719486, \"precision\": 1.0, \"recall\": 0.3822269807280514, \"specificity\": 1.0, \"npv\": 0.9996767507261504, \"accuracy\": 0.9996768153630726, \"f1\": 0.5530596436870643, \"f2\": 0.4361104324456389, \"f0_5\": 0.7557154953429297, \"p4\": 0.7121784478996175, \"phi\": 0.6181451497294833}, {\"truth_threshold\": 33.20000049471855, \"match_probability\": 0.9999999998986546, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2477.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4061.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.37886203732028145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6211379626797185, \"precision\": 1.0, \"recall\": 0.37886203732028145, \"specificity\": 1.0, \"npv\": 0.999674990594255, \"accuracy\": 0.9996750550110022, \"f1\": 0.549528563505269, \"f2\": 0.43260330434175137, \"f0_5\": 0.7530706554785358, \"p4\": 0.7092439572429342, \"phi\": 0.6154176659754517}, {\"truth_threshold\": 33.30000049620867, \"match_probability\": 0.9999999999054414, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2465.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4073.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.377026613643316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.622973386356684, \"precision\": 1.0, \"recall\": 0.377026613643316, \"specificity\": 1.0, \"npv\": 0.9996740305249245, \"accuracy\": 0.9996740948189637, \"f1\": 0.5475952460291014, \"f2\": 0.43068805255617293, \"f0_5\": 0.7516160507378948, \"p4\": 0.7076316100018153, \"phi\": 0.6139248443221509}, {\"truth_threshold\": 33.400000497698784, \"match_probability\": 0.9999999999117737, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2442.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4096.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.37350871826246557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6264912817375344, \"precision\": 1.0, \"recall\": 0.37350871826246557, \"specificity\": 1.0, \"npv\": 0.9996721903971955, \"accuracy\": 0.9996722544508901, \"f1\": 0.5438752783964366, \"f2\": 0.4270126599986011, \"f0_5\": 0.7488041211823868, \"p4\": 0.7045178765665048, \"phi\": 0.6110534170740624}, {\"truth_threshold\": 33.5000004991889, \"match_probability\": 0.999999999917682, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2421.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4117.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3702967268277761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.629703273172224, \"precision\": 1.0, \"recall\": 0.3702967268277761, \"specificity\": 1.0, \"npv\": 0.9996705102864896, \"accuracy\": 0.999670574114823, \"f1\": 0.5404621051456636, \"f2\": 0.4236516991565464, \"f0_5\": 0.7462088521760573, \"p4\": 0.7016477150157799, \"phi\": 0.6084198532800682}, {\"truth_threshold\": 33.600000500679016, \"match_probability\": 0.9999999999231945, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2389.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4149.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3654022636892016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6345977363107984, \"precision\": 1.0, \"recall\": 0.3654022636892016, \"specificity\": 1.0, \"npv\": 0.9996679501286543, \"accuracy\": 0.9996680136027205, \"f1\": 0.5352302005152907, \"f2\": 0.41852072457166883, \"f0_5\": 0.7422020628805767, \"p4\": 0.6972234025444047, \"phi\": 0.6043847548660987}, {\"truth_threshold\": 33.70000050216913, \"match_probability\": 0.999999999928338, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2376.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4162.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3634138880391557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6365861119608442, \"precision\": 1.0, \"recall\": 0.3634138880391557, \"specificity\": 1.0, \"npv\": 0.9996669100682795, \"accuracy\": 0.9996669733946789, \"f1\": 0.5330940094233789, \"f2\": 0.4164329781267527, \"f0_5\": 0.7405560403939658, \"p4\": 0.6954082727526119, \"phi\": 0.6027377858837145}, {\"truth_threshold\": 33.80000050365925, \"match_probability\": 0.9999999999331369, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2352.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4186.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.35974304068522484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6402569593147751, \"precision\": 1.0, \"recall\": 0.35974304068522484, \"specificity\": 1.0, \"npv\": 0.9996649899625039, \"accuracy\": 0.9996650530106022, \"f1\": 0.5291338582677165, \"f2\": 0.412573673870334, \"f0_5\": 0.7374890254609306, \"p4\": 0.692029905599789, \"phi\": 0.5996853534610261}, {\"truth_threshold\": 33.900000505149364, \"match_probability\": 0.9999999999376146, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2323.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4215.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3553074334658917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6446925665341083, \"precision\": 1.0, \"recall\": 0.3553074334658917, \"specificity\": 1.0, \"npv\": 0.9996626698445328, \"accuracy\": 0.9996627325465093, \"f1\": 0.5243200541699582, \"f2\": 0.40790166812993855, \"f0_5\": 0.7337334175615919, \"p4\": 0.6878996644388093, \"phi\": 0.5959761551892173}, {\"truth_threshold\": 34.00000050663948, \"match_probability\": 0.9999999999417923, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2306.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4232.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.35270724992352404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.647292750076476, \"precision\": 1.0, \"recall\": 0.35270724992352404, \"specificity\": 1.0, \"npv\": 0.9996613097803844, \"accuracy\": 0.9996613722744548, \"f1\": 0.5214834916327453, \"f2\": 0.4051584791622742, \"f0_5\": 0.7315061540413653, \"p4\": 0.685453661254731, \"phi\": 0.5937910334684984}, {\"truth_threshold\": 34.1000005081296, \"match_probability\": 0.9999999999456903, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2282.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4256.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3490364025695932, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6509635974304069, \"precision\": 1.0, \"recall\": 0.3490364025695932, \"specificity\": 1.0, \"npv\": 0.9996593896961221, \"accuracy\": 0.9996594518903781, \"f1\": 0.5174603174603175, \"f2\": 0.4012801575578533, \"f0_5\": 0.7283288650580876, \"p4\": 0.6819687495284521, \"phi\": 0.5906924048728318}, {\"truth_threshold\": 34.20000050961971, \"match_probability\": 0.9999999999493273, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2270.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4268.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3472009788926277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6527990211073723, \"precision\": 1.0, \"recall\": 0.3472009788926277, \"specificity\": 1.0, \"npv\": 0.999658429656757, \"accuracy\": 0.9996584916983396, \"f1\": 0.5154405086285195, \"f2\": 0.3993385405671663, \"f0_5\": 0.7267255730567295, \"p4\": 0.6802121971290069, \"phi\": 0.5891369835064618}, {\"truth_threshold\": 34.30000051110983, \"match_probability\": 0.9999999999527207, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2265.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4273.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.34643621902722543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6535637809727746, \"precision\": 1.0, \"recall\": 0.34643621902722543, \"specificity\": 1.0, \"npv\": 0.9996580296408991, \"accuracy\": 0.9996580916183236, \"f1\": 0.5145972963762354, \"f2\": 0.3985290495126157, \"f0_5\": 0.7260546223874855, \"p4\": 0.6794775010816225, \"phi\": 0.5884876788081457}, {\"truth_threshold\": 34.400000512599945, \"match_probability\": 0.9999999999558868, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2247.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4291.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3436830835117773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6563169164882227, \"precision\": 1.0, \"recall\": 0.3436830835117773, \"specificity\": 1.0, \"npv\": 0.9996565895864613, \"accuracy\": 0.999656651330266, \"f1\": 0.5115537848605578, \"f2\": 0.39561252156766086, \"f0_5\": 0.7236248872858431, \"p4\": 0.6768188536728977, \"phi\": 0.5861442306821267}, {\"truth_threshold\": 34.50000051409006, \"match_probability\": 0.999999999958841, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2226.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4312.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3404710920770878, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6595289079229122, \"precision\": 1.0, \"recall\": 0.3404710920770878, \"specificity\": 1.0, \"npv\": 0.9996549095281945, \"accuracy\": 0.9996549709941989, \"f1\": 0.5079872204472844, \"f2\": 0.3922052294030587, \"f0_5\": 0.7207615593834995, \"p4\": 0.6736896422701116, \"phi\": 0.5833983191159251}, {\"truth_threshold\": 34.60000051558018, \"match_probability\": 0.9999999999615973, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2206.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4332.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.33741205261547874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6625879473845213, \"precision\": 1.0, \"recall\": 0.33741205261547874, \"specificity\": 1.0, \"npv\": 0.9996533094779523, \"accuracy\": 0.9996533706741348, \"f1\": 0.5045745654162854, \"f2\": 0.3889554975668242, \"f0_5\": 0.7180054680380159, \"p4\": 0.6706815814312562, \"phi\": 0.5807711038393804}, {\"truth_threshold\": 34.70000051707029, \"match_probability\": 0.999999999964169, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2192.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4346.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3352707249923524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6647292750076476, \"precision\": 1.0, \"recall\": 0.3352707249923524, \"specificity\": 1.0, \"npv\": 0.9996521894458303, \"accuracy\": 0.99965225045009, \"f1\": 0.502176403207331, \"f2\": 0.3866779565340107, \"f0_5\": 0.7160590618058278, \"p4\": 0.6685595632418379, \"phi\": 0.57892496430513}, {\"truth_threshold\": 34.80000051856041, \"match_probability\": 0.9999999999665685, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2175.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4363.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3326705414499847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6673294585500152, \"precision\": 1.0, \"recall\": 0.3326705414499847, \"specificity\": 1.0, \"npv\": 0.9996508294101994, \"accuracy\": 0.9996508901780357, \"f1\": 0.49925398829335477, \"f2\": 0.3839093444416987, \"f0_5\": 0.7136763354770967, \"p4\": 0.6659644843645965, \"phi\": 0.5766752835702406}, {\"truth_threshold\": 34.900000520050526, \"match_probability\": 0.9999999999688073, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2167.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4371.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.33144692566534106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6685530743346589, \"precision\": 1.0, \"recall\": 0.33144692566534106, \"specificity\": 1.0, \"npv\": 0.9996501893947124, \"accuracy\": 0.99965025005001, \"f1\": 0.49787478460654794, \"f2\": 0.3826053179843921, \"f0_5\": 0.7125476785479417, \"p4\": 0.6647362472032575, \"phi\": 0.5756135700412677}, {\"truth_threshold\": 35.00000052154064, \"match_probability\": 0.9999999999708962, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2150.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4388.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3288467421229734, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6711532578770266, \"precision\": 1.0, \"recall\": 0.3288467421229734, \"specificity\": 1.0, \"npv\": 0.9996488293645236, \"accuracy\": 0.9996488897779556, \"f1\": 0.4949355432780847, \"f2\": 0.3798318140060773, \"f0_5\": 0.7101334390276126, \"p4\": 0.6621111733356267, \"phi\": 0.5733509054702606}, {\"truth_threshold\": 35.10000052303076, \"match_probability\": 0.9999999999728452, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2133.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4405.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3262465585806057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6737534414193943, \"precision\": 1.0, \"recall\": 0.3262465585806057, \"specificity\": 1.0, \"npv\": 0.9996474693380355, \"accuracy\": 0.9996475295059012, \"f1\": 0.49198477684234804, \"f2\": 0.377054976135761, \"f0_5\": 0.7076974120769741, \"p4\": 0.659465404769006, \"phi\": 0.5710792822939259}, {\"truth_threshold\": 35.200000524520874, \"match_probability\": 0.9999999999746636, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2121.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4417.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32441113490364026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6755888650963597, \"precision\": 1.0, \"recall\": 0.32441113490364026, \"specificity\": 1.0, \"npv\": 0.999646509321566, \"accuracy\": 0.9996465693138628, \"f1\": 0.4898949070331447, \"f2\": 0.3750928447635553, \"f0_5\": 0.7059645852749301, \"p4\": 0.6575852103475986, \"phi\": 0.5694703316165571}, {\"truth_threshold\": 35.30000052601099, \"match_probability\": 0.9999999999763604, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2106.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4432.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32211685530743345, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6778831446925665, \"precision\": 1.0, \"recall\": 0.32211685530743345, \"specificity\": 1.0, \"npv\": 0.9996453093035722, \"accuracy\": 0.9996453690738147, \"f1\": 0.4872744099953725, \"f2\": 0.3726378370726874, \"f0_5\": 0.7037829167223634, \"p4\": 0.6552201610841019, \"phi\": 0.5674527323537119}, {\"truth_threshold\": 35.400000527501106, \"match_probability\": 0.9999999999779434, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2102.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4436.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32150504741511166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6784949525848883, \"precision\": 1.0, \"recall\": 0.32150504741511166, \"specificity\": 1.0, \"npv\": 0.9996449892992604, \"accuracy\": 0.999645049009802, \"f1\": 0.48657407407407405, \"f2\": 0.3719827281092943, \"f0_5\": 0.703198180115081, \"p4\": 0.6545866827057676, \"phi\": 0.5669134940032187}, {\"truth_threshold\": 35.50000052899122, \"match_probability\": 0.9999999999794205, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2099.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4439.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.32104619149587027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6789538085041297, \"precision\": 1.0, \"recall\": 0.32104619149587027, \"specificity\": 1.0, \"npv\": 0.9996447492961611, \"accuracy\": 0.9996448089617923, \"f1\": 0.486048396433947, \"f2\": 0.3714912746451453, \"f0_5\": 0.7027588054104728, \"p4\": 0.6541107966547529, \"phi\": 0.5665087286268206}, {\"truth_threshold\": 35.60000053048134, \"match_probability\": 0.9999999999807987, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2082.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4456.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3184460079535026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6815539920464974, \"precision\": 1.0, \"recall\": 0.3184460079535026, \"specificity\": 1.0, \"npv\": 0.9996433892807748, \"accuracy\": 0.999643448689738, \"f1\": 0.48306264501160096, \"f2\": 0.3687043989516186, \"f0_5\": 0.7002556168438047, \"p4\": 0.6514014538213357, \"phi\": 0.5642095769247203}, {\"truth_threshold\": 35.700000531971455, \"match_probability\": 0.9999999999820844, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2064.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4474.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31569287243805444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6843071275619456, \"precision\": 1.0, \"recall\": 0.31569287243805444, \"specificity\": 1.0, \"npv\": 0.9996419492685169, \"accuracy\": 0.9996420084016804, \"f1\": 0.4798883980469658, \"f2\": 0.3657499291182308, \"f0_5\": 0.6975801000405569, \"p4\": 0.6485090784991382, \"phi\": 0.5617649315987551}, {\"truth_threshold\": 35.80000053346157, \"match_probability\": 0.9999999999832843, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2050.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4488.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3135515448149281, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6864484551850719, \"precision\": 1.0, \"recall\": 0.3135515448149281, \"specificity\": 1.0, \"npv\": 0.9996408292618513, \"accuracy\": 0.9996408881776355, \"f1\": 0.4774103400093153, \"f2\": 0.3634494007517197, \"f0_5\": 0.6954810693445515, \"p4\": 0.6462424338526489, \"phi\": 0.5598561657025216}, {\"truth_threshold\": 35.90000053495169, \"match_probability\": 0.9999999999844037, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2041.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4497.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31217497705720404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.687825022942796, \"precision\": 1.0, \"recall\": 0.31217497705720404, \"specificity\": 1.0, \"npv\": 0.9996401092588916, \"accuracy\": 0.9996401680336067, \"f1\": 0.47581303182189066, \"f2\": 0.3619692831553932, \"f0_5\": 0.694123248537614, \"p4\": 0.6447773648729818, \"phi\": 0.5586256601458219}, {\"truth_threshold\": 36.0000005364418, \"match_probability\": 0.9999999999854481, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2034.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4504.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.31110431324564086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6888956867543591, \"precision\": 1.0, \"recall\": 0.31110431324564086, \"specificity\": 1.0, \"npv\": 0.9996395492573066, \"accuracy\": 0.9996396079215843, \"f1\": 0.47456836210919273, \"f2\": 0.36081742709146386, \"f0_5\": 0.6930625596292763, \"p4\": 0.6436335399947954, \"phi\": 0.5576667243657957}, {\"truth_threshold\": 36.10000053793192, \"match_probability\": 0.9999999999864226, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2017.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4521.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3085041297032732, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6914958702967269, \"precision\": 1.0, \"recall\": 0.3085041297032732, \"specificity\": 1.0, \"npv\": 0.9996381892560696, \"accuracy\": 0.9996382476495299, \"f1\": 0.4715371127995324, \"f2\": 0.3580176790088395, \"f0_5\": 0.6904696699986307, \"p4\": 0.6408397937580784, \"phi\": 0.5553309910266127}, {\"truth_threshold\": 36.200000539422035, \"match_probability\": 0.9999999999873318, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2008.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4530.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3071275619455491, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6928724380544509, \"precision\": 1.0, \"recall\": 0.3071275619455491, \"specificity\": 1.0, \"npv\": 0.9996374692569128, \"accuracy\": 0.9996375275055011, \"f1\": 0.46992745143926984, \"f2\": 0.3565340909090909, \"f0_5\": 0.6890871654083733, \"p4\": 0.6393515688372079, \"phi\": 0.5540904427638997}, {\"truth_threshold\": 36.30000054091215, \"match_probability\": 0.9999999999881801, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1997.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4541.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3054450902416641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6945549097583359, \"precision\": 1.0, \"recall\": 0.3054450902416641, \"specificity\": 1.0, \"npv\": 0.999636589259352, \"accuracy\": 0.9996366473294659, \"f1\": 0.46795547744581134, \"f2\": 0.35471952822480374, \"f0_5\": 0.6873881316260498, \"p4\": 0.6375239173733245, \"phi\": 0.5525704373337322}, {\"truth_threshold\": 36.40000054240227, \"match_probability\": 0.9999999999889717, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1987.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4551.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.3039155705108596, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6960844294891404, \"precision\": 1.0, \"recall\": 0.3039155705108596, \"specificity\": 1.0, \"npv\": 0.9996357892629139, \"accuracy\": 0.9996358471694339, \"f1\": 0.466158357771261, \"f2\": 0.35306869469419666, \"f0_5\": 0.6858345989230982, \"p4\": 0.6358540421800607, \"phi\": 0.5511849791103817}, {\"truth_threshold\": 36.500000543892384, \"match_probability\": 0.9999999999897102, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1976.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4562.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.30223309880697463, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6977669011930254, \"precision\": 1.0, \"recall\": 0.30223309880697463, \"specificity\": 1.0, \"npv\": 0.9996349092683108, \"accuracy\": 0.9996349669933987, \"f1\": 0.46417665022316185, \"f2\": 0.3512514220705347, \"f0_5\": 0.6841157734385819, \"p4\": 0.6340078972747747, \"phi\": 0.549656944196824}, {\"truth_threshold\": 36.6000005453825, \"match_probability\": 0.9999999999903993, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1967.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4571.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.30085653104925053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.6991434689507494, \"precision\": 1.0, \"recall\": 0.30085653104925053, \"specificity\": 1.0, \"npv\": 0.9996341892738789, \"accuracy\": 0.9996342468493699, \"f1\": 0.46255144032921813, \"f2\": 0.34976350510331095, \"f0_5\": 0.6827016520894071, \"p4\": 0.6324901298636184, \"phi\": 0.54840356901024}, {\"truth_threshold\": 36.700000546872616, \"match_probability\": 0.9999999999910423, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1951.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4587.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2984092994799633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7015907005200367, \"precision\": 1.0, \"recall\": 0.2984092994799633, \"specificity\": 1.0, \"npv\": 0.9996329092863386, \"accuracy\": 0.9996329665933187, \"f1\": 0.4596536694545883, \"f2\": 0.3471159662669466, \"f0_5\": 0.6801701296890252, \"p4\": 0.6297755461955975, \"phi\": 0.5461682489830895}, {\"truth_threshold\": 36.80000054836273, \"match_probability\": 0.9999999999916421, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1935.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4603.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.29596206791067603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.704037932089324, \"precision\": 1.0, \"recall\": 0.29596206791067603, \"specificity\": 1.0, \"npv\": 0.9996316293020764, \"accuracy\": 0.9996316863372674, \"f1\": 0.45674495456154846, \"f2\": 0.3444654110442554, \"f0_5\": 0.6776159125928001, \"p4\": 0.6270398511692444, \"phi\": 0.543923748476899}, {\"truth_threshold\": 36.90000054985285, \"match_probability\": 0.9999999999922018, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1920.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4618.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.29366778831446927, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7063322116855307, \"precision\": 1.0, \"recall\": 0.29366778831446927, \"specificity\": 1.0, \"npv\": 0.9996304293198075, \"accuracy\": 0.9996304860972195, \"f1\": 0.45400803972570347, \"f2\": 0.3419777714448561, \"f0_5\": 0.6752004501336334, \"p4\": 0.6244557438248436, \"phi\": 0.5418110900583258}, {\"truth_threshold\": 37.000000551342964, \"match_probability\": 0.999999999992724, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1912.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4626.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.29244417252982563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7075558274701743, \"precision\": 1.0, \"recall\": 0.29244417252982563, \"specificity\": 1.0, \"npv\": 0.9996297893304421, \"accuracy\": 0.9996298459691938, \"f1\": 0.45254437869822484, \"f2\": 0.34064994298745727, \"f0_5\": 0.6739038488650783, \"p4\": 0.6230698061909045, \"phi\": 0.5406809656136463}, {\"truth_threshold\": 37.10000055283308, \"match_probability\": 0.9999999999932113, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1896.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4642.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2899969409605384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7100030590394616, \"precision\": 1.0, \"recall\": 0.2899969409605384, \"specificity\": 1.0, \"npv\": 0.9996285093541697, \"accuracy\": 0.9996285657131426, \"f1\": 0.4496087265828788, \"f2\": 0.3379920136908157, \"f0_5\": 0.671293017986121, \"p4\": 0.6202816084250107, \"phi\": 0.5384136047776394}, {\"truth_threshold\": 37.200000554323196, \"match_probability\": 0.999999999993666, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1872.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4666.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.28632609360660755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7136739063933925, \"precision\": 1.0, \"recall\": 0.28632609360660755, \"specificity\": 1.0, \"npv\": 0.9996265893959071, \"accuracy\": 0.9996266453290659, \"f1\": 0.4451843043995244, \"f2\": 0.33399942906080504, \"f0_5\": 0.6673320975331527, \"p4\": 0.6160580220002259, \"phi\": 0.5349945573620598}, {\"truth_threshold\": 37.30000055581331, \"match_probability\": 0.9999999999940901, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1854.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4684.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2835729580911594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7164270419088407, \"precision\": 1.0, \"recall\": 0.2835729580911594, \"specificity\": 1.0, \"npv\": 0.9996251494320502, \"accuracy\": 0.9996252050410082, \"f1\": 0.44184938036224974, \"f2\": 0.3310004998928801, \"f0_5\": 0.6643256413931489, \"p4\": 0.6128573488431872, \"phi\": 0.532415871858422}, {\"truth_threshold\": 37.40000055730343, \"match_probability\": 0.9999999999944859, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1841.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4697.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2815845824411135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7184154175588865, \"precision\": 1.0, \"recall\": 0.2815845824411135, \"specificity\": 1.0, \"npv\": 0.9996241094607335, \"accuracy\": 0.9996241648329666, \"f1\": 0.4394319131161236, \"f2\": 0.328832208052013, \"f0_5\": 0.662134944612286, \"p4\": 0.610527928609566, \"phi\": 0.5305456978061084}, {\"truth_threshold\": 37.500000558793545, \"match_probability\": 0.9999999999948551, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1826.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4712.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2792903028449067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7207096971550933, \"precision\": 1.0, \"recall\": 0.2792903028449067, \"specificity\": 1.0, \"npv\": 0.9996229094965186, \"accuracy\": 0.9996229645929186, \"f1\": 0.4366331898613104, \"f2\": 0.3263278290085067, \"f0_5\": 0.6595867649183644, \"p4\": 0.607821347889367, \"phi\": 0.5283795843179309}, {\"truth_threshold\": 37.60000056028366, \"match_probability\": 0.9999999999951996, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1817.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4721.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27791373508718265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7220862649128174, \"precision\": 1.0, \"recall\": 0.27791373508718265, \"specificity\": 1.0, \"npv\": 0.9996221895193724, \"accuracy\": 0.9996222444488898, \"f1\": 0.4349491322561341, \"f2\": 0.3248239121884944, \"f0_5\": 0.658047225843836, \"p4\": 0.6061876475124999, \"phi\": 0.5270756457714171}, {\"truth_threshold\": 37.70000056177378, \"match_probability\": 0.9999999999955211, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1804.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4734.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27592535943713675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7240746405628633, \"precision\": 1.0, \"recall\": 0.27592535943713675, \"specificity\": 1.0, \"npv\": 0.9996211495542145, \"accuracy\": 0.9996212042408482, \"f1\": 0.4325101894030209, \"f2\": 0.3226498783803119, \"f0_5\": 0.6558092191362512, \"p4\": 0.6038148258282768, \"phi\": 0.5251864668779179}, {\"truth_threshold\": 37.80000056326389, \"match_probability\": 0.999999999995821, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1788.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4750.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2734781278678495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7265218721321505, \"precision\": 1.0, \"recall\": 0.2734781278678495, \"specificity\": 1.0, \"npv\": 0.9996198696000677, \"accuracy\": 0.9996199239847969, \"f1\": 0.42949795820321884, \"f2\": 0.3199713672154617, \"f0_5\": 0.6530314097881665, \"p4\": 0.6008730841364339, \"phi\": 0.5228519585099881}, {\"truth_threshold\": 37.90000056475401, \"match_probability\": 0.9999999999961009, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1769.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4769.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.27057204037932087, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7294279596206791, \"precision\": 1.0, \"recall\": 0.27057204037932087, \"specificity\": 1.0, \"npv\": 0.9996183496587755, \"accuracy\": 0.9996184036807362, \"f1\": 0.4259058625255808, \"f2\": 0.31678664804269185, \"f0_5\": 0.6496988394299985, \"p4\": 0.597348801374475, \"phi\": 0.5200661270144252}, {\"truth_threshold\": 38.000000566244125, \"match_probability\": 0.999999999996362, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1750.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4788.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2676659528907923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7323340471092077, \"precision\": 1.0, \"recall\": 0.2676659528907923, \"specificity\": 1.0, \"npv\": 0.9996168297221055, \"accuracy\": 0.9996168833766753, \"f1\": 0.4222972972972973, \"f2\": 0.3135975915704967, \"f0_5\": 0.6463288521199586, \"p4\": 0.5937904379363829, \"phi\": 0.5172653006468153}, {\"truth_threshold\": 38.10000056773424, \"match_probability\": 0.9999999999966056, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1721.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4817.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.26323034567145914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7367696543285408, \"precision\": 1.0, \"recall\": 0.26323034567145914, \"specificity\": 1.0, \"npv\": 0.9996145098276786, \"accuracy\": 0.9996145629125825, \"f1\": 0.41675747669209345, \"f2\": 0.30872170200552507, \"f0_5\": 0.6411116078080763, \"p4\": 0.5882924159886327, \"phi\": 0.5129608883337463}, {\"truth_threshold\": 38.20000056922436, \"match_probability\": 0.999999999996833, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1696.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4842.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2594065463444478, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7405934536555522, \"precision\": 1.0, \"recall\": 0.2594065463444478, \"specificity\": 1.0, \"npv\": 0.9996125099273324, \"accuracy\": 0.9996125625125025, \"f1\": 0.4119504493563274, \"f2\": 0.30451019821890263, \"f0_5\": 0.6365410599009158, \"p4\": 0.5834867016790001, \"phi\": 0.5092210020049786}, {\"truth_threshold\": 38.300000570714474, \"match_probability\": 0.999999999997045, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1684.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4854.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2575711226674824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7424288773325176, \"precision\": 1.0, \"recall\": 0.2575711226674824, \"specificity\": 1.0, \"npv\": 0.9996115499780086, \"accuracy\": 0.9996116023204641, \"f1\": 0.4096326927754804, \"f2\": 0.30248598936628823, \"f0_5\": 0.6343227361759831, \"p4\": 0.5811578678121875, \"phi\": 0.507416071049408}, {\"truth_threshold\": 38.40000057220459, \"match_probability\": 0.999999999997243, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1662.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4876.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.25420617925971245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7457938207402875, \"precision\": 1.0, \"recall\": 0.25420617925971245, \"specificity\": 1.0, \"npv\": 0.9996097900757036, \"accuracy\": 0.9996098419683936, \"f1\": 0.4053658536585366, \"f2\": 0.29877040339397426, \"f0_5\": 0.6302138631882299, \"p4\": 0.5768505509991216, \"phi\": 0.5040902552973503}, {\"truth_threshold\": 38.500000573694706, \"match_probability\": 0.9999999999974276, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1631.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4907.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2494646680942184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7505353319057816, \"precision\": 1.0, \"recall\": 0.2494646680942184, \"specificity\": 1.0, \"npv\": 0.9996073102238828, \"accuracy\": 0.9996073614722945, \"f1\": 0.39931448157669236, \"f2\": 0.29352481733434116, \"f0_5\": 0.6243301178992497, \"p4\": 0.570696731542618, \"phi\": 0.4993663042993142}, {\"truth_threshold\": 38.60000057518482, \"match_probability\": 0.9999999999975998, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1602.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4936.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2450290608748853, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7549709391251147, \"precision\": 1.0, \"recall\": 0.2450290608748853, \"specificity\": 1.0, \"npv\": 0.999604990373641, \"accuracy\": 0.9996050410082017, \"f1\": 0.3936117936117936, \"f2\": 0.28860704763277367, \"f0_5\": 0.6187239301714815, \"p4\": 0.5648485912818594, \"phi\": 0.4949063265276592}, {\"truth_threshold\": 38.70000057667494, \"match_probability\": 0.9999999999977606, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1586.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4952.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.24258182930559805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.757418170694402, \"precision\": 1.0, \"recall\": 0.24258182930559805, \"specificity\": 1.0, \"npv\": 0.9996037104608755, \"accuracy\": 0.9996037607521504, \"f1\": 0.39044805514524866, \"f2\": 0.2858893936116519, \"f0_5\": 0.615587641670548, \"p4\": 0.5615834716993262, \"phi\": 0.49242836703855986}, {\"truth_threshold\": 38.800000578165054, \"match_probability\": 0.9999999999979106, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1567.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 4971.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.23967574181706944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7603242581829306, \"precision\": 1.0, \"recall\": 0.23967574181706944, \"specificity\": 1.0, \"npv\": 0.9996021905687235, \"accuracy\": 0.9996022404480897, \"f1\": 0.38667489204194944, \"f2\": 0.2826581045492262, \"f0_5\": 0.6118225831641418, \"p4\": 0.5576699197808568, \"phi\": 0.48946950522634847}, {\"truth_threshold\": 38.90000057965517, \"match_probability\": 0.9999999999980504, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1536.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5002.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2349342306515754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7650657693484246, \"precision\": 1.0, \"recall\": 0.2349342306515754, \"specificity\": 1.0, \"npv\": 0.9995997107546084, \"accuracy\": 0.9995997599519904, \"f1\": 0.38048055486747584, \"f2\": 0.27737648078590005, \"f0_5\": 0.6055827156599906, \"p4\": 0.5511987226722421, \"phi\": 0.48460312525371857}, {\"truth_threshold\": 39.00000058114529, \"match_probability\": 0.999999999998181, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1516.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5022.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.23187519118996636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7681248088100336, \"precision\": 1.0, \"recall\": 0.23187519118996636, \"specificity\": 1.0, \"npv\": 0.9995981108810639, \"accuracy\": 0.9995981596319263, \"f1\": 0.376458902408741, \"f2\": 0.2739627005927425, \"f0_5\": 0.6014918266941756, \"p4\": 0.5469661392109346, \"phi\": 0.48143743422554486}, {\"truth_threshold\": 39.1000005826354, \"match_probability\": 0.9999999999983028, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1503.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5035.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.22988681553992046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7701131844600795, \"precision\": 1.0, \"recall\": 0.22988681553992046, \"specificity\": 1.0, \"npv\": 0.9995970709660061, \"accuracy\": 0.9995971194238847, \"f1\": 0.37383410023628905, \"f2\": 0.2717410956427409, \"f0_5\": 0.598804780876494, \"p4\": 0.5441903054435285, \"phi\": 0.4793685299093037}, {\"truth_threshold\": 39.20000058412552, \"match_probability\": 0.9999999999984165, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1485.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5053.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.22713368002447232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7728663199755277, \"precision\": 1.0, \"recall\": 0.22713368002447232, \"specificity\": 1.0, \"npv\": 0.9995956310871906, \"accuracy\": 0.9995956791358271, \"f1\": 0.37018571606630934, \"f2\": 0.2686615768715852, \"f0_5\": 0.5950472832184645, \"p4\": 0.540314328806217, \"phi\": 0.47648907041528077}, {\"truth_threshold\": 39.300000585615635, \"match_probability\": 0.9999999999985225, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1461.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5077.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.22346283267054146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7765371673294585, \"precision\": 1.0, \"recall\": 0.22346283267054146, \"specificity\": 1.0, \"npv\": 0.9995937112552226, \"accuracy\": 0.9995937587517504, \"f1\": 0.3652956619577447, \"f2\": 0.2645493064860754, \"f0_5\": 0.5899693102891294, \"p4\": 0.5350867365546128, \"phi\": 0.47262251558379154}, {\"truth_threshold\": 39.40000058710575, \"match_probability\": 0.9999999999986214, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1438.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5100.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.21994493728969103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.780055062710309, \"precision\": 1.0, \"recall\": 0.21994493728969103, \"specificity\": 1.0, \"npv\": 0.9995918714231732, \"accuracy\": 0.9995919183836768, \"f1\": 0.36058174523570713, \"f2\": 0.2606016672707503, \"f0_5\": 0.5850284784377543, \"p4\": 0.5300118701544849, \"phi\": 0.46888716283926424}, {\"truth_threshold\": 39.50000058859587, \"match_probability\": 0.9999999999987138, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1404.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5134.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.21474457020495563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7852554297950444, \"precision\": 1.0, \"recall\": 0.21474457020495563, \"specificity\": 1.0, \"npv\": 0.9995891516838539, \"accuracy\": 0.9995891978395679, \"f1\": 0.35356333417275243, \"f2\": 0.2547539555813616, \"f0_5\": 0.5775876254730953, \"p4\": 0.5223905623310277, \"phi\": 0.46331020144163176}, {\"truth_threshold\": 39.60000059008598, \"match_probability\": 0.9999999999988, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1373.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5165.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.21000305903946162, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7899969409605384, \"precision\": 1.0, \"recall\": 0.21000305903946162, \"specificity\": 1.0, \"npv\": 0.9995866719344322, \"accuracy\": 0.9995867173434687, \"f1\": 0.3471116167361901, \"f2\": 0.24940962761126248, \"f0_5\": 0.5706566916043225, \"p4\": 0.515314576179575, \"phi\": 0.4581661913337839}, {\"truth_threshold\": 39.7000005915761, \"match_probability\": 0.9999999999988802, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1352.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5186.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.2067910676047721, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7932089323952279, \"precision\": 1.0, \"recall\": 0.2067910676047721, \"specificity\": 1.0, \"npv\": 0.999584992111169, \"accuracy\": 0.9995850370074015, \"f1\": 0.3427122940430925, \"f2\": 0.245782431646306, \"f0_5\": 0.5658797923991294, \"p4\": 0.5104505825968885, \"phi\": 0.4546484880436493}, {\"truth_threshold\": 39.800000593066216, \"match_probability\": 0.9999999999989553, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1318.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5220.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.20159070052003672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.7984092994799633, \"precision\": 1.0, \"recall\": 0.20159070052003672, \"specificity\": 1.0, \"npv\": 0.9995822724092847, \"accuracy\": 0.9995823164632927, \"f1\": 0.33553971486761713, \"f2\": 0.23989807062249727, \"f0_5\": 0.5580016934801016, \"p4\": 0.5024517014955714, \"phi\": 0.44889474325547396}, {\"truth_threshold\": 39.90000059455633, \"match_probability\": 0.9999999999990252, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1287.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5251.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.19684918935454268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8031508106454573, \"precision\": 1.0, \"recall\": 0.19684918935454268, \"specificity\": 1.0, \"npv\": 0.9995797926939946, \"accuracy\": 0.9995798359671935, \"f1\": 0.3289456869009585, \"f2\": 0.2345202084624075, \"f0_5\": 0.5506589080951566, \"p4\": 0.49502184597333043, \"phi\": 0.44358366954498524}, {\"truth_threshold\": 40.00000059604645, \"match_probability\": 0.9999999999990905, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1260.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5278.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.19271948608137046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8072805139186295, \"precision\": 1.0, \"recall\": 0.19271948608137046, \"specificity\": 1.0, \"npv\": 0.999577632951992, \"accuracy\": 0.999577675535107, \"f1\": 0.3231597845601436, \"f2\": 0.22982635342185903, \"f0_5\": 0.5441354292623942, \"p4\": 0.48844155360786284, \"phi\": 0.4389055567214212}, {\"truth_threshold\": 40.100000597536564, \"match_probability\": 0.9999999999991515, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1225.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5313.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1873661670235546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8126338329764454, \"precision\": 1.0, \"recall\": 0.1873661670235546, \"specificity\": 1.0, \"npv\": 0.9995748333003235, \"accuracy\": 0.999574874974995, \"f1\": 0.3155996393146979, \"f2\": 0.22372794681667094, \"f0_5\": 0.5354957160342717, \"p4\": 0.47975619530785885, \"phi\": 0.4327661090805172}, {\"truth_threshold\": 40.20000059902668, \"match_probability\": 0.9999999999992082, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1200.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5338.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.18354236769654328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8164576323034567, \"precision\": 1.0, \"recall\": 0.18354236769654328, \"specificity\": 1.0, \"npv\": 0.9995728335587334, \"accuracy\": 0.999572874574915, \"f1\": 0.31015766347893514, \"f2\": 0.2193623866627669, \"f0_5\": 0.5291938613512083, \"p4\": 0.4734422183798725, \"phi\": 0.42832693652922726}, {\"truth_threshold\": 40.300000600516796, \"match_probability\": 0.9999999999992613, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1167.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5371.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.17849495258488834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8215050474151117, \"precision\": 1.0, \"recall\": 0.17849495258488834, \"specificity\": 1.0, \"npv\": 0.999570193912086, \"accuracy\": 0.9995702340468093, \"f1\": 0.3029201817001947, \"f2\": 0.21358761301658186, \"f0_5\": 0.5207031947171158, \"p4\": 0.46496331125592316, \"phi\": 0.4223958266455831}, {\"truth_threshold\": 40.40000060200691, \"match_probability\": 0.9999999999993108, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1139.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5399.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.17421229733863566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8257877026613644, \"precision\": 1.0, \"recall\": 0.17421229733863566, \"specificity\": 1.0, \"npv\": 0.9995679542228334, \"accuracy\": 0.9995679935987197, \"f1\": 0.29673049368242804, \"f2\": 0.2086768531750394, \"f0_5\": 0.5133405444384352, \"p4\": 0.4576368357115885, \"phi\": 0.41729729168931834}, {\"truth_threshold\": 40.50000060349703, \"match_probability\": 0.9999999999993568, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1129.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5409.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.17268277760783113, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8273172223921689, \"precision\": 1.0, \"recall\": 0.17268277760783113, \"specificity\": 1.0, \"npv\": 0.9995671543362469, \"accuracy\": 0.9995671934386877, \"f1\": 0.29450893439415676, \"f2\": 0.2069205674278802, \"f0_5\": 0.5106748688257644, \"p4\": 0.45499018215228776, \"phi\": 0.4154612287763309}, {\"truth_threshold\": 40.600000604987144, \"match_probability\": 0.9999999999993999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1095.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5443.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.16748241052309576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8325175894769042, \"precision\": 1.0, \"recall\": 0.16748241052309576, \"specificity\": 1.0, \"npv\": 0.9995644347314288, \"accuracy\": 0.999564472894579, \"f1\": 0.2869120922311018, \"f2\": 0.20093955297830954, \"f0_5\": 0.5014654698662758, \"p4\": 0.44587063544984223, \"phi\": 0.4091570126515924}, {\"truth_threshold\": 40.70000060647726, \"match_probability\": 0.9999999999994401, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1059.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5479.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.16197613949219944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8380238605078005, \"precision\": 1.0, \"recall\": 0.16197613949219944, \"specificity\": 1.0, \"npv\": 0.9995615551659869, \"accuracy\": 0.9995615923184636, \"f1\": 0.27879426089245757, \"f2\": 0.19459042299070228, \"f0_5\": 0.4914609244477446, \"p4\": 0.4360059153836068, \"phi\": 0.40237435540874833}, {\"truth_threshold\": 40.80000060796738, \"match_probability\": 0.9999999999994776, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1034.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5504.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.15815234016518814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8418476598348119, \"precision\": 1.0, \"recall\": 0.15815234016518814, \"specificity\": 1.0, \"npv\": 0.9995595554775246, \"accuracy\": 0.9995595919183837, \"f1\": 0.2731114632857897, \"f2\": 0.1901714117560509, \"f0_5\": 0.4843545062769346, \"p4\": 0.4290253659055036, \"phi\": 0.39759613030466695}, {\"truth_threshold\": 40.90000060945749, \"match_probability\": 0.9999999999995126, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 989.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5549.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.15126950137656775, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8487304986234322, \"precision\": 1.0, \"recall\": 0.15126950137656775, \"specificity\": 1.0, \"npv\": 0.999555956058455, \"accuracy\": 0.9995559911982397, \"f1\": 0.2627872990567291, \"f2\": 0.18219667661471575, \"f0_5\": 0.4712216504669335, \"p4\": 0.4161827615160143, \"phi\": 0.388847439326712}, {\"truth_threshold\": 41.00000061094761, \"match_probability\": 0.9999999999995453, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 962.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5576.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.14713979810339553, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8528602018966045, \"precision\": 1.0, \"recall\": 0.14713979810339553, \"specificity\": 1.0, \"npv\": 0.9995537964194563, \"accuracy\": 0.9995538307661532, \"f1\": 0.25653333333333334, \"f2\": 0.17739912960094417, \"f0_5\": 0.46312343539379935, \"p4\": 0.4083005793313789, \"phi\": 0.3835024690906713}, {\"truth_threshold\": 41.100000612437725, \"match_probability\": 0.9999999999995757, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 936.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5602.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.14316304680330377, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8568369531966963, \"precision\": 1.0, \"recall\": 0.14316304680330377, \"specificity\": 1.0, \"npv\": 0.9995517167759074, \"accuracy\": 0.99955175035007, \"f1\": 0.25046829007225047, \"f2\": 0.17277023036030714, \"f0_5\": 0.45516436490955064, \"p4\": 0.4005811944697175, \"phi\": 0.37828411176140064}, {\"truth_threshold\": 41.20000061392784, \"match_probability\": 0.9999999999996041, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 894.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5644.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.13673906393392474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8632609360660752, \"precision\": 1.0, \"recall\": 0.13673906393392474, \"specificity\": 1.0, \"npv\": 0.9995483573699931, \"accuracy\": 0.9995483896779356, \"f1\": 0.24058127018299247, \"f2\": 0.1652739776676773, \"f0_5\": 0.441961637334388, \"p4\": 0.38783550254655713, \"phi\": 0.3696989406848023}, {\"truth_threshold\": 41.30000061541796, \"match_probability\": 0.9999999999996306, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 875.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5663.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.13383297644539616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8661670235546038, \"precision\": 1.0, \"recall\": 0.13383297644539616, \"specificity\": 1.0, \"npv\": 0.9995468376461645, \"accuracy\": 0.9995468693738748, \"f1\": 0.2360717658168083, \"f2\": 0.16187516187516188, \"f0_5\": 0.43584379358437936, \"p4\": 0.3819544341250318, \"phi\": 0.36574899641525926}, {\"truth_threshold\": 41.40000061690807, \"match_probability\": 0.9999999999996554, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 840.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5698.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1284796573875803, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8715203426124197, \"precision\": 1.0, \"recall\": 0.1284796573875803, \"specificity\": 1.0, \"npv\": 0.9995440381669982, \"accuracy\": 0.9995440688137628, \"f1\": 0.22770398481973433, \"f2\": 0.15560165975103735, \"f0_5\": 0.4243281471004243, \"p4\": 0.3709271215677005, \"phi\": 0.3583588642234128}, {\"truth_threshold\": 41.50000061839819, \"match_probability\": 0.9999999999996785, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 813.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5725.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.12434995411440808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8756500458855919, \"precision\": 1.0, \"recall\": 0.12434995411440808, \"specificity\": 1.0, \"npv\": 0.9995418785794987, \"accuracy\": 0.9995419083816763, \"f1\": 0.22119439532036458, \"f2\": 0.15075097348414612, \"f0_5\": 0.41521961184882533, \"p4\": 0.3622440703325214, \"phi\": 0.3525521049955452}, {\"truth_threshold\": 41.600000619888306, \"match_probability\": 0.9999999999997, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 788.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5750.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.12052615478739676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8794738452126032, \"precision\": 1.0, \"recall\": 0.12052615478739676, \"specificity\": 1.0, \"npv\": 0.9995398789697643, \"accuracy\": 0.9995399079815963, \"f1\": 0.21512421512421512, \"f2\": 0.14625092798812175, \"f0_5\": 0.4066047471620227, \"p4\": 0.3540633078262699, \"phi\": 0.3470888908750691}, {\"truth_threshold\": 41.70000062137842, \"match_probability\": 0.9999999999997201, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 761.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5777.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.11639645151422454, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8836035484857755, \"precision\": 1.0, \"recall\": 0.11639645151422454, \"specificity\": 1.0, \"npv\": 0.9995377194002372, \"accuracy\": 0.9995377475495099, \"f1\": 0.20852171530346622, \"f2\": 0.14138148849998142, \"f0_5\": 0.397098726779378, \"p4\": 0.3450718228237847, \"phi\": 0.34109037467042114}, {\"truth_threshold\": 41.80000062286854, \"match_probability\": 0.9999999999997388, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 744.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5794.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.11379626797185684, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8862037320281432, \"precision\": 1.0, \"recall\": 0.11379626797185684, \"specificity\": 1.0, \"npv\": 0.9995363596760631, \"accuracy\": 0.9995363872774555, \"f1\": 0.20433946717934634, \"f2\": 0.1383105294467579, \"f0_5\": 0.39100273281479925, \"p4\": 0.33932530170873554, \"phi\": 0.3372588137222089}, {\"truth_threshold\": 41.900000624358654, \"match_probability\": 0.9999999999997563, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 711.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5827.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.1087488528602019, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8912511471397981, \"precision\": 1.0, \"recall\": 0.1087488528602019, \"specificity\": 1.0, \"npv\": 0.9995337202220507, \"accuracy\": 0.9995337467493499, \"f1\": 0.19616498827424472, \"f2\": 0.1323381602948293, \"f0_5\": 0.37891707525047963, \"p4\": 0.32797730557327004, \"phi\": 0.3296940179457887}, {\"truth_threshold\": 42.00000062584877, \"match_probability\": 0.9999999999997726, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 685.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5853.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.10477210156011013, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8952278984398899, \"precision\": 1.0, \"recall\": 0.10477210156011013, \"specificity\": 1.0, \"npv\": 0.9995316406620407, \"accuracy\": 0.9995316663332666, \"f1\": 0.18967188148968572, \"f2\": 0.12762231247904013, \"f0_5\": 0.3691528346626428, \"p4\": 0.31885228161496326, \"phi\": 0.3236093796044651}, {\"truth_threshold\": 42.100000627338886, \"match_probability\": 0.9999999999997878, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 664.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5874.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.10156011012542061, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8984398898745793, \"precision\": 1.0, \"recall\": 0.10156011012542061, \"specificity\": 1.0, \"npv\": 0.9995299610237344, \"accuracy\": 0.9995299859971994, \"f1\": 0.18439322410441544, \"f2\": 0.12380668257756564, \"f0_5\": 0.36110506852294977, \"p4\": 0.3113602317634428, \"phi\": 0.31861006405201303}, {\"truth_threshold\": 42.200000628829, \"match_probability\": 0.999999999999802, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 631.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5907.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.09651269501376568, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9034873049862343, \"precision\": 1.0, \"recall\": 0.09651269501376568, \"specificity\": 1.0, \"npv\": 0.9995273216035152, \"accuracy\": 0.9995273454690938, \"f1\": 0.17603570930394755, \"f2\": 0.11779860359183064, \"f0_5\": 0.34815713970425954, \"p4\": 0.29936077219920604, \"phi\": 0.31059149303843814}, {\"truth_threshold\": 42.30000063031912, \"match_probability\": 0.9999999999998154, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 622.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5916.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0951361272560416, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9048638727439584, \"precision\": 1.0, \"recall\": 0.0951361272560416, \"specificity\": 1.0, \"npv\": 0.9995266017640566, \"accuracy\": 0.999526625325065, \"f1\": 0.17374301675977655, \"f2\": 0.11615746619855083, \"f0_5\": 0.34456015953910923, \"p4\": 0.2960391229055828, \"phi\": 0.30836843220606114}, {\"truth_threshold\": 42.400000631809235, \"match_probability\": 0.9999999999998277, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 584.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5954.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0893239522789844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9106760477210156, \"precision\": 1.0, \"recall\": 0.0893239522789844, \"specificity\": 1.0, \"npv\": 0.9995235624533285, \"accuracy\": 0.9995235847169434, \"f1\": 0.16399887672002247, \"f2\": 0.10921603830041891, \"f0_5\": 0.32905116069416274, \"p4\": 0.28177582164746995, \"phi\": 0.2987999246892502}, {\"truth_threshold\": 42.50000063329935, \"match_probability\": 0.9999999999998392, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 564.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5974.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.08626491281737535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9137350871826246, \"precision\": 1.0, \"recall\": 0.08626491281737535, \"specificity\": 1.0, \"npv\": 0.9995219628235273, \"accuracy\": 0.9995219843968793, \"f1\": 0.15882849901436216, \"f2\": 0.10555472376104207, \"f0_5\": 0.3206731862633614, \"p4\": 0.2741100924688891, \"phi\": 0.2936386810044335}, {\"truth_threshold\": 42.60000063478947, \"match_probability\": 0.99999999999985, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 539.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 5999.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.08244111349036402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.917558886509636, \"precision\": 1.0, \"recall\": 0.08244111349036402, \"specificity\": 1.0, \"npv\": 0.9995199632934759, \"accuracy\": 0.9995199839967993, \"f1\": 0.152324431256182, \"f2\": 0.1009703645423551, \"f0_5\": 0.30998389694041867, \"p4\": 0.26436929053280256, \"phi\": 0.28705668208519713}, {\"truth_threshold\": 42.70000063627958, \"match_probability\": 0.99999999999986, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 526.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6012.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.08045273784031814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9195472621596819, \"precision\": 1.0, \"recall\": 0.08045273784031814, \"specificity\": 1.0, \"npv\": 0.9995189235410108, \"accuracy\": 0.9995189437887577, \"f1\": 0.14892412231030577, \"f2\": 0.09858310218157283, \"f0_5\": 0.3043277019208517, \"p4\": 0.2592329189893566, \"phi\": 0.2835736834088839}, {\"truth_threshold\": 42.8000006377697, \"match_probability\": 0.9999999999998694, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 509.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6029.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.07785255429795045, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9221474457020495, \"precision\": 1.0, \"recall\": 0.07785255429795045, \"specificity\": 1.0, \"npv\": 0.9995175638679743, \"accuracy\": 0.9995175835167034, \"f1\": 0.1444586348800908, \"f2\": 0.0954577847792656, \"f0_5\": 0.29682761838115235, \"p4\": 0.2524411631283098, \"phi\": 0.2789533929042388}, {\"truth_threshold\": 42.900000639259815, \"match_probability\": 0.9999999999998782, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 494.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6044.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.07555827470174366, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9244417252982563, \"precision\": 1.0, \"recall\": 0.07555827470174366, \"specificity\": 1.0, \"npv\": 0.9995163641595435, \"accuracy\": 0.9995163832766554, \"f1\": 0.14050056882821388, \"f2\": 0.09269684005103955, \"f0_5\": 0.29011040638947616, \"p4\": 0.24637669677767973, \"phi\": 0.2748121758802816}, {\"truth_threshold\": 43.00000064074993, \"match_probability\": 0.9999999999998863, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 466.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6072.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.07127561945549098, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.928724380544509, \"precision\": 1.0, \"recall\": 0.07127561945549098, \"specificity\": 1.0, \"npv\": 0.9995141247115116, \"accuracy\": 0.9995141428285658, \"f1\": 0.13306681896059394, \"f2\": 0.08753475092042978, \"f0_5\": 0.2773149250178529, \"p4\": 0.2348723279805091, \"phi\": 0.26691007548109874}, {\"truth_threshold\": 43.10000064224005, \"match_probability\": 0.999999999999894, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 444.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6094.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.06791067604772101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.932089323952279, \"precision\": 1.0, \"recall\": 0.06791067604772101, \"specificity\": 1.0, \"npv\": 0.9995123651522406, \"accuracy\": 0.9995123824764953, \"f1\": 0.12718418791177313, \"f2\": 0.0834711986764927, \"f0_5\": 0.2670194852056772, \"p4\": 0.22566087907947527, \"phi\": 0.26053322328552503}, {\"truth_threshold\": 43.200000643730164, \"match_probability\": 0.9999999999999011, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 429.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6109.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.06561639645151422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9343836035484858, \"precision\": 1.0, \"recall\": 0.06561639645151422, \"specificity\": 1.0, \"npv\": 0.9995111654562897, \"accuracy\": 0.9995111822364473, \"f1\": 0.12315200229654083, \"f2\": 0.08069673827169783, \"f0_5\": 0.2598740004846135, \"p4\": 0.21929124472045242, \"phi\": 0.25609435934884417}, {\"truth_threshold\": 43.30000064522028, \"match_probability\": 0.9999999999999076, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 406.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6132.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.06209850107066381, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9379014989293362, \"precision\": 1.0, \"recall\": 0.06209850107066381, \"specificity\": 1.0, \"npv\": 0.9995093259280917, \"accuracy\": 0.9995093418683737, \"f1\": 0.11693548387096774, \"f2\": 0.0764364786505008, \"f0_5\": 0.24871355060034306, \"p4\": 0.20938090097792697, \"phi\": 0.24913456393339736}, {\"truth_threshold\": 43.400000646710396, \"match_probability\": 0.9999999999999138, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 388.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6150.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.05934536555521566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9406546344447844, \"precision\": 1.0, \"recall\": 0.05934536555521566, \"specificity\": 1.0, \"npv\": 0.9995078863020512, \"accuracy\": 0.9995079015803161, \"f1\": 0.11204158244296852, \"f2\": 0.07309721175584025, \"f0_5\": 0.23980222496909764, \"p4\": 0.2015011044420622, \"phi\": 0.24354909338348227}, {\"truth_threshold\": 43.50000064820051, \"match_probability\": 0.9999999999999196, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 377.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6161.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.05766289385133068, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9423371061486693, \"precision\": 1.0, \"recall\": 0.05766289385133068, \"specificity\": 1.0, \"npv\": 0.9995070065326236, \"accuracy\": 0.9995070214042808, \"f1\": 0.10903832248734635, \"f2\": 0.0710543179162426, \"f0_5\": 0.23427790206313695, \"p4\": 0.196631038781739, \"phi\": 0.24007179430610326}, {\"truth_threshold\": 43.60000064969063, \"match_probability\": 0.999999999999925, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 365.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6173.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.05582747017436525, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9441725298256347, \"precision\": 1.0, \"recall\": 0.05582747017436525, \"specificity\": 1.0, \"npv\": 0.9995060467859234, \"accuracy\": 0.9995060612122425, \"f1\": 0.10575112270027524, \"f2\": 0.06882377342836671, \"f0_5\": 0.22818204551137786, \"p4\": 0.19127020808238523, \"phi\": 0.2362200118873057}, {\"truth_threshold\": 43.700000651180744, \"match_probability\": 0.9999999999999301, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 335.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6203.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.051238910981951664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9487610890180483, \"precision\": 1.0, \"recall\": 0.051238910981951664, \"specificity\": 1.0, \"npv\": 0.9995036474272365, \"accuracy\": 0.9995036607321465, \"f1\": 0.09748290411756147, \"f2\": 0.06323856986446182, \"f0_5\": 0.2126174155877126, \"p4\": 0.1776442326638859, \"phi\": 0.22630395139427015}, {\"truth_threshold\": 43.80000065267086, \"match_probability\": 0.9999999999999347, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 322.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6216.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.04925053533190578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9507494646680942, \"precision\": 1.0, \"recall\": 0.04925053533190578, \"specificity\": 1.0, \"npv\": 0.9995026077087164, \"accuracy\": 0.9995026205241048, \"f1\": 0.09387755102040816, \"f2\": 0.060814383923849816, \"f0_5\": 0.20572450805008943, \"p4\": 0.17163812589329475, \"phi\": 0.22186941766563975}, {\"truth_threshold\": 43.900000654160976, \"match_probability\": 0.999999999999939, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 298.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6240.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.04557968797797492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.954420312022025, \"precision\": 1.0, \"recall\": 0.04557968797797492, \"specificity\": 1.0, \"npv\": 0.9995006882340544, \"accuracy\": 0.999500700140028, \"f1\": 0.0871854885898186, \"f2\": 0.056332703213610585, \"f0_5\": 0.1927554980595084, \"p4\": 0.16038430082229319, \"phi\": 0.21344069317606562}, {\"truth_threshold\": 44.00000065565109, \"match_probability\": 0.9999999999999432, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 285.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6253.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.04359131232792903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.956408687672071, \"precision\": 1.0, \"recall\": 0.04359131232792903, \"specificity\": 1.0, \"npv\": 0.9994996485216906, \"accuracy\": 0.9994996599319864, \"f1\": 0.08354096438516781, \"f2\": 0.05390172863789386, \"f0_5\": 0.18559520708517843, \"p4\": 0.1541969431194377, \"phi\": 0.2087330863815421}, {\"truth_threshold\": 44.10000065714121, \"match_probability\": 0.9999999999999469, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 268.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6270.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.04099112878556133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9590088712144387, \"precision\": 1.0, \"recall\": 0.04099112878556133, \"specificity\": 1.0, \"npv\": 0.9994982889010943, \"accuracy\": 0.999498299659932, \"f1\": 0.07875404055245372, \"f2\": 0.050719152157456475, \"f0_5\": 0.17608409986859397, \"p4\": 0.14600658653065263, \"phi\": 0.2024118649716289}, {\"truth_threshold\": 44.200000658631325, \"match_probability\": 0.9999999999999505, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 242.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6296.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03701437748546956, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9629856225145305, \"precision\": 1.0, \"recall\": 0.03701437748546956, \"specificity\": 1.0, \"npv\": 0.9994962094885134, \"accuracy\": 0.9994962192438488, \"f1\": 0.07138643067846608, \"f2\": 0.04584375236796242, \"f0_5\": 0.16120436983746336, \"p4\": 0.1332576742008174, \"phi\": 0.19234274094257833}, {\"truth_threshold\": 44.30000066012144, \"match_probability\": 0.9999999999999538, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 241.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6297.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03686142551238911, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9631385744876109, \"precision\": 1.0, \"recall\": 0.03686142551238911, \"specificity\": 1.0, \"npv\": 0.9994961295112792, \"accuracy\": 0.9994961392278455, \"f1\": 0.07110193243841274, \"f2\": 0.04565604516349032, \"f0_5\": 0.1606238336443615, \"p4\": 0.13276186065691148, \"phi\": 0.19194491951573306}, {\"truth_threshold\": 44.40000066161156, \"match_probability\": 0.9999999999999569, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 223.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6315.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03410828999694096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9658917100030591, \"precision\": 1.0, \"recall\": 0.03410828999694096, \"specificity\": 1.0, \"npv\": 0.9994946899232529, \"accuracy\": 0.9994946989397879, \"f1\": 0.06596657299216092, \"f2\": 0.042274881516587676, \"f0_5\": 0.1500672947510094, \"p4\": 0.12376662223017129, \"phi\": 0.18463763087275817}, {\"truth_threshold\": 44.50000066310167, \"match_probability\": 0.9999999999999598, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 219.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6319.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03349648210461915, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9665035178953808, \"precision\": 1.0, \"recall\": 0.03349648210461915, \"specificity\": 1.0, \"npv\": 0.9994943700153658, \"accuracy\": 0.9994943788757752, \"f1\": 0.06482166642000887, \"f2\": 0.04152288498729665, \"f0_5\": 0.14769355273806312, \"p4\": 0.1217493414196047, \"phi\": 0.18297416560511293}, {\"truth_threshold\": 44.60000066459179, \"match_probability\": 0.9999999999999625, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 204.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6334.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.03120220250841236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9687977974915877, \"precision\": 1.0, \"recall\": 0.03120220250841236, \"specificity\": 1.0, \"npv\": 0.9994931703626129, \"accuracy\": 0.9994931786357272, \"f1\": 0.060516167309403734, \"f2\": 0.03870086507816057, \"f0_5\": 0.13870002719608376, \"p4\": 0.11412422298498996, \"phi\": 0.17659668260595765}, {\"truth_threshold\": 44.700000666081905, \"match_probability\": 0.999999999999965, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 187.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6351.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02860201896604466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9713979810339554, \"precision\": 1.0, \"recall\": 0.02860201896604466, \"specificity\": 1.0, \"npv\": 0.9994918107596409, \"accuracy\": 0.9994918183636727, \"f1\": 0.05561338289962825, \"f2\": 0.03549869015528304, \"f0_5\": 0.128328300850947, \"p4\": 0.10536554188973224, \"phi\": 0.16907833606868022}, {\"truth_threshold\": 44.80000066757202, \"match_probability\": 0.9999999999999674, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 175.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6363.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02676659528907923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9732334047109208, \"precision\": 1.0, \"recall\": 0.02676659528907923, \"specificity\": 1.0, \"npv\": 0.999490851042123, \"accuracy\": 0.9994908581716343, \"f1\": 0.05213764337851929, \"f2\": 0.033235841531507576, \"f0_5\": 0.12088974854932302, \"p4\": 0.09910677686281072, \"phi\": 0.16356334279104803}, {\"truth_threshold\": 44.90000066906214, \"match_probability\": 0.9999999999999696, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 169.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6369.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02584888345059651, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9741511165494035, \"precision\": 1.0, \"recall\": 0.02584888345059651, \"specificity\": 1.0, \"npv\": 0.9994903711840553, \"accuracy\": 0.9994903780756151, \"f1\": 0.05039510958699866, \"f2\": 0.03210364347859124, \"f0_5\": 0.1171333518159135, \"p4\": 0.09595340405698327, \"phi\": 0.1607349063356497}, {\"truth_threshold\": 45.000000670552254, \"match_probability\": 0.9999999999999716, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 161.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6377.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02462526766595289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9753747323340471, \"precision\": 1.0, \"recall\": 0.02462526766595289, \"specificity\": 1.0, \"npv\": 0.9994897313740149, \"accuracy\": 0.9994897379475896, \"f1\": 0.04806687565308255, \"f2\": 0.030593242883745677, \"f0_5\": 0.11208576998050682, \"p4\": 0.09172375170898207, \"phi\": 0.15688435920912086}, {\"truth_threshold\": 45.10000067204237, \"match_probability\": 0.9999999999999735, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 143.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6395.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.021872132150504743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9781278678494952, \"precision\": 1.0, \"recall\": 0.021872132150504743, \"specificity\": 1.0, \"npv\": 0.9994882918044191, \"accuracy\": 0.999488297659532, \"f1\": 0.04280796287980841, \"f2\": 0.02719148127020346, \"f0_5\": 0.10056258790436005, \"p4\": 0.08210047212315064, \"phi\": 0.14785445546627435}, {\"truth_threshold\": 45.200000673532486, \"match_probability\": 0.9999999999999752, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 139.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6399.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02126032425818293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9787396757418171, \"precision\": 1.0, \"recall\": 0.02126032425818293, \"specificity\": 1.0, \"npv\": 0.9994879719006277, \"accuracy\": 0.9994879775955191, \"f1\": 0.04163546502920473, \"f2\": 0.026434901677380093, \"f0_5\": 0.09797011559063998, \"p4\": 0.07994166894095465, \"phi\": 0.14577187099972674}, {\"truth_threshold\": 45.3000006750226, \"match_probability\": 0.9999999999999769, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 131.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6407.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.02003670847353931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9799632915264607, \"precision\": 1.0, \"recall\": 0.02003670847353931, \"specificity\": 1.0, \"npv\": 0.999487332093659, \"accuracy\": 0.9994873374674935, \"f1\": 0.0392862498125656, \"f2\": 0.024921051630331394, \"f0_5\": 0.09274992919852733, \"p4\": 0.07560163324601013, \"phi\": 0.14151479179278828}, {\"truth_threshold\": 45.40000067651272, \"match_probability\": 0.9999999999999785, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 124.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6414.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.01896604466197614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810339553380238, \"precision\": 1.0, \"recall\": 0.01896604466197614, \"specificity\": 1.0, \"npv\": 0.9994867722632335, \"accuracy\": 0.9994867773554711, \"f1\": 0.037226058240768536, \"f2\": 0.02359567666311463, \"f0_5\": 0.08814330395223202, \"p4\": 0.07177936752506696, \"phi\": 0.13768191879037298}, {\"truth_threshold\": 45.500000678002834, \"match_probability\": 0.9999999999999799, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 115.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6423.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.017589476904252065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.982410523095748, \"precision\": 1.0, \"recall\": 0.017589476904252065, \"specificity\": 1.0, \"npv\": 0.9994860524821793, \"accuracy\": 0.9994860572114422, \"f1\": 0.03457087028408237, \"f2\": 0.021890585144858567, \"f0_5\": 0.08216633323806802, \"p4\": 0.06683074938350145, \"phi\": 0.13259123966634206}, {\"truth_threshold\": 45.60000067949295, \"match_probability\": 0.9999999999999812, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 107.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6431.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.016365861119608444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836341388803915, \"precision\": 1.0, \"recall\": 0.016365861119608444, \"specificity\": 1.0, \"npv\": 0.9994854126776681, \"accuracy\": 0.9994854170834166, \"f1\": 0.032204665161775774, \"f2\": 0.020373967020830955, \"f0_5\": 0.07680160780935975, \"p4\": 0.06239926555983355, \"phi\": 0.12789620578796404}, {\"truth_threshold\": 45.70000068098307, \"match_probability\": 0.9999999999999825, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 100.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6438.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.015295197308045273, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9847048026919547, \"precision\": 1.0, \"recall\": 0.015295197308045273, \"specificity\": 1.0, \"npv\": 0.9994848528493927, \"accuracy\": 0.9994848569713943, \"f1\": 0.030129557095510694, \"f2\": 0.019046167911016303, \"f0_5\": 0.07206687806284232, \"p4\": 0.058496195529687475, \"phi\": 0.12364189431877069}, {\"truth_threshold\": 45.80000068247318, \"match_probability\": 0.9999999999999837, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 89.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6449.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.013612725604160294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9863872743958397, \"precision\": 1.0, \"recall\": 0.013612725604160294, \"specificity\": 1.0, \"npv\": 0.9994839731205127, \"accuracy\": 0.999483976795359, \"f1\": 0.026859815904632565, \"f2\": 0.01695819519073206, \"f0_5\": 0.0645488830867421, \"p4\": 0.05231412140495124, \"phi\": 0.11664347847970524}, {\"truth_threshold\": 45.9000006839633, \"match_probability\": 0.9999999999999848, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 86.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6452.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.013153869684918936, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9868461303150811, \"precision\": 1.0, \"recall\": 0.013153869684918936, \"specificity\": 1.0, \"npv\": 0.9994837331947233, \"accuracy\": 0.9994837367473495, \"f1\": 0.025966183574879228, \"f2\": 0.016388444241176917, \"f0_5\": 0.06248183667538506, \"p4\": 0.05061767973330871, \"phi\": 0.11466071157392874}, {\"truth_threshold\": 46.000000685453415, \"match_probability\": 0.9999999999999858, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 80.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6458.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.012236157846436219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9877638421535638, \"precision\": 1.0, \"recall\": 0.012236157846436219, \"specificity\": 1.0, \"npv\": 0.9994832533434901, \"accuracy\": 0.9994832566513303, \"f1\": 0.024176488365064974, \"f2\": 0.015248551387618176, \"f0_5\": 0.058326042578011085, \"p4\": 0.04721127873846389, \"phi\": 0.11058858373620915}, {\"truth_threshold\": 46.10000068694353, \"match_probability\": 0.9999999999999868, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 78.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6460.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.011930253900275314, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9880697460997246, \"precision\": 1.0, \"recall\": 0.011930253900275314, \"specificity\": 1.0, \"npv\": 0.9994830933931814, \"accuracy\": 0.9994830966193239, \"f1\": 0.02357920193470375, \"f2\": 0.014868471216164697, \"f0_5\": 0.05693430656934306, \"p4\": 0.04607178698819498, \"phi\": 0.1091974682545948}, {\"truth_threshold\": 46.20000068843365, \"match_probability\": 0.9999999999999877, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 76.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6462.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.011624349954114408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9883756500458856, \"precision\": 1.0, \"recall\": 0.011624349954114408, \"specificity\": 1.0, \"npv\": 0.9994829334429239, \"accuracy\": 0.9994829365873175, \"f1\": 0.02298155427880254, \"f2\": 0.014488333079152052, \"f0_5\": 0.05553931598947676, \"p4\": 0.044930273937183664, \"phi\": 0.10778840100634848}, {\"truth_threshold\": 46.30000068992376, \"match_probability\": 0.9999999999999885, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 62.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6476.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.00948302233098807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905169776690119, \"precision\": 1.0, \"recall\": 0.00948302233098807, \"specificity\": 1.0, \"npv\": 0.999481813792555, \"accuracy\": 0.9994818163632726, \"f1\": 0.018787878787878787, \"f2\": 0.011825741969939726, \"f0_5\": 0.04568228706159741, \"p4\": 0.036882631534392994, \"phi\": 0.09735557693122288}, {\"truth_threshold\": 46.40000069141388, \"match_probability\": 0.9999999999999892, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 61.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6477.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.009330070357907618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906699296420923, \"precision\": 1.0, \"recall\": 0.009330070357907618, \"specificity\": 1.0, \"npv\": 0.9994817338176245, \"accuracy\": 0.9994817363472694, \"f1\": 0.018487649643885436, \"f2\": 0.01163544806012284, \"f0_5\": 0.044971984665290475, \"p4\": 0.03630395055544782, \"phi\": 0.09656725582702415}, {\"truth_threshold\": 46.500000692903996, \"match_probability\": 0.9999999999999899, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 57.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6481.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.008718262465585805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912817375344142, \"precision\": 1.0, \"recall\": 0.008718262465585805, \"specificity\": 1.0, \"npv\": 0.999481413918031, \"accuracy\": 0.9994814162832566, \"f1\": 0.01728582259287339, \"f2\": 0.01087412720821092, \"f0_5\": 0.042122376588826484, \"p4\": 0.03398405051876811, \"phi\": 0.09334742254616461}, {\"truth_threshold\": 46.70000069588423, \"match_probability\": 0.9999999999999912, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 49.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6489.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.007494646680942184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925053533190579, \"precision\": 1.0, \"recall\": 0.007494646680942184, \"specificity\": 1.0, \"npv\": 0.9994807741194585, \"accuracy\": 0.999480776155231, \"f1\": 0.01487778958554729, \"f2\": 0.009350788137857334, \"f0_5\": 0.036382536382536385, \"p4\": 0.02931926008524652, \"phi\": 0.08654914942632264}, {\"truth_threshold\": 46.800000697374344, \"match_probability\": 0.9999999999999918, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 47.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6491.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.007188742734781279, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928112572652187, \"precision\": 1.0, \"recall\": 0.007188742734781279, \"specificity\": 1.0, \"npv\": 0.9994806141699433, \"accuracy\": 0.9994806161232247, \"f1\": 0.014274867122247532, \"f2\": 0.008969808007939234, \"f0_5\": 0.034939042521558134, \"p4\": 0.028147823405097274, \"phi\": 0.08476443242108632}, {\"truth_threshold\": 46.90000069886446, \"match_probability\": 0.9999999999999923, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 42.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6496.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.006423982869379015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935760171306209, \"precision\": 1.0, \"recall\": 0.006423982869379015, \"specificity\": 1.0, \"npv\": 0.9994802142963793, \"accuracy\": 0.9994802160432087, \"f1\": 0.01276595744680851, \"f2\": 0.008017103153393906, \"f0_5\": 0.031315240083507306, \"p4\": 0.02521000140369941, \"phi\": 0.08012891971643701}, {\"truth_threshold\": 47.000000700354576, \"match_probability\": 0.9999999999999929, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 40.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6498.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0061180789232181095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938819210767819, \"precision\": 1.0, \"recall\": 0.0061180789232181095, \"specificity\": 1.0, \"npv\": 0.9994800543470433, \"accuracy\": 0.9994800560112023, \"f1\": 0.012161751292186074, \"f2\": 0.0076359193646915085, \"f0_5\": 0.029859659599880562, \"p4\": 0.02403116550675825, \"phi\": 0.07819781233946085}, {\"truth_threshold\": 47.10000070184469, \"match_probability\": 0.9999999999999933, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 39.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6499.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.005965126950137657, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940348730498624, \"precision\": 1.0, \"recall\": 0.005965126950137657, \"specificity\": 1.0, \"npv\": 0.9994799743723946, \"accuracy\": 0.999479975995199, \"f1\": 0.011859510415082864, \"f2\": 0.0074453056393417585, \"f0_5\": 0.029130564684792352, \"p4\": 0.02344095031506342, \"phi\": 0.07721414981239945}, {\"truth_threshold\": 47.20000070333481, \"match_probability\": 0.9999999999999938, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 37.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6501.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.005659223003976751, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943407769960233, \"precision\": 1.0, \"recall\": 0.005659223003976751, \"specificity\": 1.0, \"npv\": 0.9994798144231353, \"accuracy\": 0.9994798159631927, \"f1\": 0.011254752851711026, \"f2\": 0.0070640345183092135, \"f0_5\": 0.02766975770266228, \"p4\": 0.022258921847275563, \"phi\": 0.07520823862977925}, {\"truth_threshold\": 47.300000704824924, \"match_probability\": 0.9999999999999942, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 34.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6504.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.005200367084735393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947996329152646, \"precision\": 1.0, \"recall\": 0.005200367084735393, \"specificity\": 1.0, \"npv\": 0.9994795744993425, \"accuracy\": 0.999479575915183, \"f1\": 0.010346926354230066, \"f2\": 0.00649201863591232, \"f0_5\": 0.025471980821096793, \"p4\": 0.020481873101726385, \"phi\": 0.07209480342640319}, {\"truth_threshold\": 47.40000070631504, \"match_probability\": 0.9999999999999946, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 32.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6506.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.004894463138574488, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951055368614256, \"precision\": 1.0, \"recall\": 0.004894463138574488, \"specificity\": 1.0, \"npv\": 0.9994794145502113, \"accuracy\": 0.9994794158831767, \"f1\": 0.009741248097412482, \"f2\": 0.006110601894286587, \"f0_5\": 0.024002400240024, \"p4\": 0.019294494786059904, \"phi\": 0.06994222724706455}, {\"truth_threshold\": 47.50000070780516, \"match_probability\": 0.999999999999995, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 27.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6511.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.004129703273172224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958702967268278, \"precision\": 1.0, \"recall\": 0.004129703273172224, \"specificity\": 1.0, \"npv\": 0.9994790146776072, \"accuracy\": 0.9994790158031607, \"f1\": 0.008225437928408226, \"f2\": 0.005156805072768249, \"f0_5\": 0.020312970207643697, \"p4\": 0.01631662945472141, \"phi\": 0.0642460252341035}, {\"truth_threshold\": 47.60000070929527, \"match_probability\": 0.9999999999999953, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 25.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6513.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0038237993270113183, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961762006729887, \"precision\": 1.0, \"recall\": 0.0038237993270113183, \"specificity\": 1.0, \"npv\": 0.9994788547286552, \"accuracy\": 0.9994788557711543, \"f1\": 0.007618467164406522, \"f2\": 0.004775184322114834, \"f0_5\": 0.018830973184694184, \"p4\": 0.015121700118283716, \"phi\": 0.061820761658794486}, {\"truth_threshold\": 47.70000071078539, \"match_probability\": 0.9999999999999957, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 24.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6514.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0036708473539308656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963291526460691, \"precision\": 1.0, \"recall\": 0.0036708473539308656, \"specificity\": 1.0, \"npv\": 0.9994787747541983, \"accuracy\": 0.999478775755151, \"f1\": 0.00731484303565986, \"f2\": 0.004584352078239609, \"f0_5\": 0.01808863430810974, \"p4\": 0.014523421819345864, \"phi\": 0.06057172620634575}, {\"truth_threshold\": 47.90000071376562, \"match_probability\": 0.9999999999999962, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 23.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6515.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.003517895380850413, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964821046191495, \"precision\": 1.0, \"recall\": 0.003517895380850413, \"specificity\": 1.0, \"npv\": 0.9994786947797544, \"accuracy\": 0.9994786957391478, \"f1\": 0.007011126352690139, \"f2\": 0.004393505253104107, \"f0_5\": 0.017345399698340876, \"p4\": 0.013924600114527723, \"phi\": 0.05929638676702062}, {\"truth_threshold\": 48.300000719726086, \"match_probability\": 0.9999999999999971, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 20.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6518.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0030590394616090547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996940960538391, \"precision\": 1.0, \"recall\": 0.0030590394616090547, \"specificity\": 1.0, \"npv\": 0.9994784548564991, \"accuracy\": 0.9994784556911382, \"f1\": 0.006099420555047271, \"f2\": 0.0038208772734219776, \"f0_5\": 0.015110305228165609, \"p4\": 0.012124867150756665, \"phi\": 0.0552941591348858}, {\"truth_threshold\": 48.4000007212162, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 19.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6519.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.002906087488528602, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970939125114714, \"precision\": 1.0, \"recall\": 0.002906087488528602, \"specificity\": 1.0, \"npv\": 0.9994783748821062, \"accuracy\": 0.999478375675135, \"f1\": 0.0057953332316608205, \"f2\": 0.003629972106530129, \"f0_5\": 0.014363471424251588, \"p4\": 0.011523864401635763, \"phi\": 0.053894077599489436}, {\"truth_threshold\": 48.600000724196434, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 18.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6520.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0027531355154481493, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972468644845518, \"precision\": 1.0, \"recall\": 0.0027531355154481493, \"specificity\": 1.0, \"npv\": 0.9994782949077262, \"accuracy\": 0.9994782956591318, \"f1\": 0.005491153142159854, \"f2\": 0.003439052350019106, \"f0_5\": 0.01361573373676248, \"p4\": 0.010922314529486318, \"phi\": 0.0524566410536361}, {\"truth_threshold\": 48.70000072568655, \"match_probability\": 0.9999999999999978, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 16.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6522.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.002447231569287244, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975527684307127, \"precision\": 1.0, \"recall\": 0.002447231569287244, \"specificity\": 1.0, \"npv\": 0.9994781349590045, \"accuracy\": 0.9994781356271254, \"f1\": 0.004882514494964907, \"f2\": 0.003057169061449098, \"f0_5\": 0.012117540139351712, \"p4\": 0.009717570424759955, \"phi\": 0.04945659151906864}, {\"truth_threshold\": 48.800000727176666, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 15.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6523.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.002294279596206791, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977057204037932, \"precision\": 1.0, \"recall\": 0.002294279596206791, \"specificity\": 1.0, \"npv\": 0.9994780549846629, \"accuracy\": 0.9994780556111222, \"f1\": 0.0045780558522813975, \"f2\": 0.0028662055260442543, \"f0_5\": 0.011367080933616247, \"p4\": 0.009114374693103295, \"phi\": 0.0478861369125529}, {\"truth_threshold\": 49.100000731647015, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 14.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6524.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0021413276231263384, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978586723768736, \"precision\": 1.0, \"recall\": 0.0021413276231263384, \"specificity\": 1.0, \"npv\": 0.9994779750103341, \"accuracy\": 0.999477975595119, \"f1\": 0.004273504273504274, \"f2\": 0.002675227394328518, \"f0_5\": 0.010615711252653927, \"p4\": 0.008510628840252391, \"phi\": 0.0462624015437591}, {\"truth_threshold\": 49.20000073313713, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 12.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6526.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0018354236769654328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981645763230346, \"precision\": 1.0, \"recall\": 0.0018354236769654328, \"specificity\": 1.0, \"npv\": 0.9994778150617148, \"accuracy\": 0.9994778155631127, \"f1\": 0.00366412213740458, \"f2\": 0.0022932273352698363, \"f0_5\": 0.009110233829334954, \"p4\": 0.007301483757742319, \"phi\": 0.04283065778581914}, {\"truth_threshold\": 49.40000073611736, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 10.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6528.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0015295197308045274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984704802691955, \"precision\": 1.0, \"recall\": 0.0015295197308045274, \"specificity\": 1.0, \"npv\": 0.9994776551131467, \"accuracy\": 0.9994776555311062, \"f1\": 0.0030543677458766036, \"f2\": 0.0019111688708814312, \"f0_5\": 0.007601094557616297, \"p4\": 0.006090129137012272, \"phi\": 0.0390988592415917}, {\"truth_threshold\": 49.600000739097595, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 9.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6529.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0013765677577240747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986234322422759, \"precision\": 1.0, \"recall\": 0.0013765677577240747, \"specificity\": 1.0, \"npv\": 0.9994775751388819, \"accuracy\": 0.999477575515103, \"f1\": 0.0027493508477165114, \"f2\": 0.0017201177325025802, \"f0_5\": 0.006845147550958321, \"p4\": 0.005483621356207485, \"phi\": 0.037092433251330735}, {\"truth_threshold\": 49.80000074207783, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 7.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6531.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0010706638115631692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989293361884368, \"precision\": 1.0, \"recall\": 0.0010706638115631692, \"specificity\": 1.0, \"npv\": 0.9994774151903906, \"accuracy\": 0.9994774154830967, \"f1\": 0.0021390374331550803, \"f2\": 0.001337971635001338, \"f0_5\": 0.005330490405117271, \"p4\": 0.004268941054375471, \"phi\": 0.03271244868424019}, {\"truth_threshold\": 50.20000074803829, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 5.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6533.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0007647598654022637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992352401345977, \"precision\": 1.0, \"recall\": 0.0007647598654022637, \"specificity\": 1.0, \"npv\": 0.9994772552419505, \"accuracy\": 0.9994772554510902, \"f1\": 0.0015283509093687911, \"f2\": 0.0009557670986733952, \"f0_5\": 0.003812137846904544, \"p4\": 0.003052036016885189, \"phi\": 0.027647062975865232}, {\"truth_threshold\": 50.50000075250864, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 4.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6534.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.000611807892321811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993881921076782, \"precision\": 1.0, \"recall\": 0.000611807892321811, \"specificity\": 1.0, \"npv\": 0.9994771752677496, \"accuracy\": 0.999477175435087, \"f1\": 0.0012228676245796392, \"f2\": 0.000764642911760208, \"f0_5\": 0.003051571559353067, \"p4\": 0.0024427473112691466, \"phi\": 0.024728283887571315}, {\"truth_threshold\": 50.600000753998756, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 3.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6535.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0004588559192413582, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995411440807587, \"precision\": 1.0, \"recall\": 0.0004588559192413582, \"specificity\": 1.0, \"npv\": 0.9994770952935615, \"accuracy\": 0.9994770954190838, \"f1\": 0.0009172909341079345, \"f2\": 0.0005735041101127892, \"f0_5\": 0.0022900763358778627, \"p4\": 0.0018329001257368872, \"phi\": 0.021415321181845713}, {\"truth_threshold\": 51.10000076144934, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 2.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6536.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.0003059039461609055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996940960538391, \"precision\": 1.0, \"recall\": 0.0003059039461609055, \"specificity\": 1.0, \"npv\": 0.9994770153193864, \"accuracy\": 0.9994770154030806, \"f1\": 0.0006116207951070336, \"f2\": 0.00038235069205475264, \"f0_5\": 0.0015276504735716467, \"p4\": 0.001222493692029335, \"phi\": 0.017485535824884636}, {\"truth_threshold\": 51.60000076889992, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 12497500.0, \"p\": 6538.0, \"n\": 12490962.0, \"tp\": 1.0, \"tn\": 12490962.0, \"fp\": 0.0, \"fn\": 6537.0, \"P_rate\": 0.0005231446289257852, \"N_rate\": 0.9994768553710742, \"tp_rate\": 0.00015295197308045274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998470480269196, \"precision\": 1.0, \"recall\": 0.00015295197308045274, \"specificity\": 1.0, \"npv\": 0.9994769353452239, \"accuracy\": 0.9994769353870774, \"f1\": 0.0003058571647040832, \"f2\": 0.0001911826559094559, \"f0_5\": 0.0007642922653622745, \"p4\": 0.0006115272404776511, \"phi\": 0.012364140459791619}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.evaluation.accuracy_analysis_from_labels_column(\n",
    "    \"cluster\", match_weight_round_to_nearest=0.1, output_type=\"roc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:47.319625Z",
     "iopub.status.busy": "2024-06-07T09:11:47.319347Z",
     "iopub.status.idle": "2024-06-07T09:11:47.588558Z",
     "shell.execute_reply": "2024-06-07T09:11:47.587940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clerical_match_score</th>\n",
       "      <th>found_by_blocking_rules</th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>rec_id_l</th>\n",
       "      <th>rec_id_r</th>\n",
       "      <th>given_name_l</th>\n",
       "      <th>given_name_r</th>\n",
       "      <th>gamma_given_name</th>\n",
       "      <th>tf_given_name_l</th>\n",
       "      <th>...</th>\n",
       "      <th>postcode_l</th>\n",
       "      <th>postcode_r</th>\n",
       "      <th>gamma_postcode</th>\n",
       "      <th>tf_postcode_l</th>\n",
       "      <th>tf_postcode_r</th>\n",
       "      <th>bf_postcode</th>\n",
       "      <th>bf_tf_adj_postcode</th>\n",
       "      <th>cluster_l</th>\n",
       "      <th>cluster_r</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-27.448215</td>\n",
       "      <td>5.460897e-09</td>\n",
       "      <td>rec-993-dup-1</td>\n",
       "      <td>rec-993-dup-3</td>\n",
       "      <td>westbrook</td>\n",
       "      <td>jake</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>...</td>\n",
       "      <td>2704</td>\n",
       "      <td>2074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-993</td>\n",
       "      <td>rec-993</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-27.448215</td>\n",
       "      <td>5.460897e-09</td>\n",
       "      <td>rec-829-dup-0</td>\n",
       "      <td>rec-829-dup-2</td>\n",
       "      <td>wilde</td>\n",
       "      <td>kyra</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3859</td>\n",
       "      <td>3595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-19.362199</td>\n",
       "      <td>1.483873e-06</td>\n",
       "      <td>rec-829-dup-0</td>\n",
       "      <td>rec-829-dup-1</td>\n",
       "      <td>wilde</td>\n",
       "      <td>kyra</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3859</td>\n",
       "      <td>3889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>rec-829</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-15.233122</td>\n",
       "      <td>2.596344e-05</td>\n",
       "      <td>rec-721-dup-0</td>\n",
       "      <td>rec-721-dup-1</td>\n",
       "      <td>mikhaili</td>\n",
       "      <td>elly</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>...</td>\n",
       "      <td>4806</td>\n",
       "      <td>4860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-721</td>\n",
       "      <td>rec-721</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-12.600328</td>\n",
       "      <td>1.610102e-04</td>\n",
       "      <td>rec-401-dup-1</td>\n",
       "      <td>rec-401-dup-3</td>\n",
       "      <td>whitbe</td>\n",
       "      <td>alexa-ose</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>3040</td>\n",
       "      <td>3041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rec-401</td>\n",
       "      <td>rec-401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clerical_match_score  found_by_blocking_rules  match_weight  \\\n",
       "0                   1.0                    False    -27.448215   \n",
       "1                   1.0                    False    -27.448215   \n",
       "2                   1.0                    False    -19.362199   \n",
       "3                   1.0                     True    -15.233122   \n",
       "4                   1.0                     True    -12.600328   \n",
       "\n",
       "   match_probability       rec_id_l       rec_id_r given_name_l given_name_r  \\\n",
       "0       5.460897e-09  rec-993-dup-1  rec-993-dup-3    westbrook         jake   \n",
       "1       5.460897e-09  rec-829-dup-0  rec-829-dup-2        wilde         kyra   \n",
       "2       1.483873e-06  rec-829-dup-0  rec-829-dup-1        wilde         kyra   \n",
       "3       2.596344e-05  rec-721-dup-0  rec-721-dup-1     mikhaili         elly   \n",
       "4       1.610102e-04  rec-401-dup-1  rec-401-dup-3       whitbe    alexa-ose   \n",
       "\n",
       "   gamma_given_name  tf_given_name_l  ...  postcode_l  postcode_r  \\\n",
       "0                 0           0.0004  ...        2704        2074   \n",
       "1                 0           0.0002  ...        3859        3595   \n",
       "2                 0           0.0002  ...        3859        3889   \n",
       "3                 0           0.0008  ...        4806        4860   \n",
       "4                 0           0.0002  ...        3040        3041   \n",
       "\n",
       "   gamma_postcode tf_postcode_l tf_postcode_r  bf_postcode  \\\n",
       "0               0        0.0002        0.0014     0.230037   \n",
       "1               0        0.0004        0.0006     0.230037   \n",
       "2               0        0.0004        0.0002     0.230037   \n",
       "3               0        0.0008        0.0014     0.230037   \n",
       "4               0        0.0020        0.0004     0.230037   \n",
       "\n",
       "   bf_tf_adj_postcode  cluster_l  cluster_r  match_key  \n",
       "0                 1.0    rec-993    rec-993          5  \n",
       "1                 1.0    rec-829    rec-829          5  \n",
       "2                 1.0    rec-829    rec-829          5  \n",
       "3                 1.0    rec-721    rec-721          2  \n",
       "4                 1.0    rec-401    rec-401          0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_errors_df = linker.evaluation.prediction_errors_from_labels_column(\n",
    "    \"cluster\"\n",
    ").as_pandas_dataframe()\n",
    "len(pred_errors_df)\n",
    "pred_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:11:47.591674Z",
     "iopub.status.busy": "2024-06-07T09:11:47.591437Z",
     "iopub.status.idle": "2024-06-07T09:11:48.630581Z",
     "shell.execute_reply": "2024-06-07T09:11:48.629955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'date_of_birth':\n",
      "    m values not fully trained\n",
      "Comparison: 'date_of_birth':\n",
      "    u values not fully trained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-33b129f5a86c498e86cf9aff55c2ef00.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-33b129f5a86c498e86cf9aff55c2ef00.vega-embed details,\n",
       "  #altair-viz-33b129f5a86c498e86cf9aff55c2ef00.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-33b129f5a86c498e86cf9aff55c2ef00\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-33b129f5a86c498e86cf9aff55c2ef00\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-33b129f5a86c498e86cf9aff55c2ef00\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-a537034953ffb6e03b1090f7e9246ebb\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 9, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-a537034953ffb6e03b1090f7e9246ebb\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" westbrook\", \"value_r\": \" jake\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" jake\", \"value_r\": \" westbrook\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05838418410954519, \"u_probability\": 0.9984540013379235, \"bayes_factor\": 0.058474585740866045, \"log2_bayes_factor\": -4.096046453833451, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19001115\", \"value_r\": \"19501111\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"2330929\", \"value_r\": \"3733536\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 24\", \"value_r\": \" 15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"2704\", \"value_r\": \"2074\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.448214992716952, \"bayes_factor\": 5.460896679793524e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" wilde\", \"value_r\": \" kyra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" kyra\", \"value_r\": \" wilde\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05838418410954519, \"u_probability\": 0.9984540013379235, \"bayes_factor\": 0.058474585740866045, \"log2_bayes_factor\": -4.096046453833451, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19090815\", \"value_r\": \"19220601\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"5230360\", \"value_r\": \"6073461\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 26\", \"value_r\": \" 62\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"3859\", \"value_r\": \"3595\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.448214992716952, \"bayes_factor\": 5.460896679793524e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" wilde\", \"value_r\": \" kyra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" kyra\", \"value_r\": \" everett\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05838418410954519, \"u_probability\": 0.9984540013379235, \"bayes_factor\": 0.058474585740866045, \"log2_bayes_factor\": -4.096046453833451, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19090815\", \"value_r\": \"19220601\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"5230360\", \"value_r\": \"6073461\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Exact match on street_number\", \"m_probability\": 0.7681604748522775, \"u_probability\": 0.015875496200246524, \"bayes_factor\": 48.38654900376273, \"log2_bayes_factor\": 5.596534142746451, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on street_number` then comparison is 48.39 times more likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 26\", \"value_r\": \" 26\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"\\\"street_number_l\\\" = \\\"street_number_r\\\"\", \"label_for_charts\": \"Term freq adjustment on street_number with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3229580166872104, \"log2_bayes_factor\": 0.4037672792445454, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on street_number makes comparison 1.32 times more likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \" 26\", \"value_r\": \" 26\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"3859\", \"value_r\": \"3889\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -19.3621992701189, \"bayes_factor\": 1.4838747255572945e-06, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" mikhaili\", \"value_r\": \" elly\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.5619154013925083, \"u_probability\": 0.00307668416914969, \"bayes_factor\": 182.63668628288423, \"log2_bayes_factor\": 7.512832778767654, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 182.64 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" reid\", \"value_r\": \" reid\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.307668416914969, \"log2_bayes_factor\": -1.7005517405846071, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  3.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \" reid\", \"value_r\": \" reid\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"try_strptime(\\\"date_of_birth_l\\\", '%Y%m%d') IS NULL OR try_strptime(\\\"date_of_birth_r\\\", '%Y%m%d') IS NULL\", \"label_for_charts\": \"transformed date_of_birth is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `transformed date_of_birth is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19850523\", \"value_r\": \"\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"2111602\", \"value_r\": \"6391700\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 46\", \"value_r\": \" 58\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"4806\", \"value_r\": \"4860\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.233121538771165, \"bayes_factor\": 2.5964112919417063e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" whitbe\", \"value_r\": \" alexa-ose\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" alexa-rose\", \"value_r\": \" white\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05838418410954519, \"u_probability\": 0.9984540013379235, \"bayes_factor\": 0.058474585740866045, \"log2_bayes_factor\": -4.096046453833451, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19300526\", \"value_r\": \"19160822\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match on soc_sec_id\", \"m_probability\": 0.8589485966871453, \"u_probability\": 0.00045325284132268303, \"bayes_factor\": 1895.0760334575298, \"log2_bayes_factor\": 10.888040017433948, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match on soc_sec_id` then comparison is 1,895.08 times more likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"2502613\", \"value_r\": \"2502613\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 22\", \"value_r\": \" 43\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"3040\", \"value_r\": \"3041\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.600328111011263, \"bayes_factor\": 0.00016103611453093254, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" zarran\", \"value_r\": \" bradshaw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" bradshaw\", \"value_r\": \" zarrna\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.05838418410954519, \"u_probability\": 0.9984540013379235, \"bayes_factor\": 0.058474585740866045, \"log2_bayes_factor\": -4.096046453833451, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  17.10 times less likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19350707\", \"value_r\": \"19550120\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"sql_condition\": \"\\\"soc_sec_id_l\\\" = \\\"soc_sec_id_r\\\"\", \"label_for_charts\": \"Exact match on soc_sec_id\", \"m_probability\": 0.8589485966871453, \"u_probability\": 0.00045325284132268303, \"bayes_factor\": 1895.0760334575298, \"log2_bayes_factor\": 10.888040017433948, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `exact match on soc_sec_id` then comparison is 1,895.08 times more likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"7831798\", \"value_r\": \"7831798\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 89\", \"value_r\": \" 63\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"6174\", \"value_r\": \"6147\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.600328111011263, \"bayes_factor\": 0.00016103611453093254, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" amy\", \"value_r\": \" chandelr\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" chandler\", \"value_r\": \" ay\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9293969479707318, \"u_probability\": 0.0005337128624799857, \"bayes_factor\": 1741.3800815144946, \"log2_bayes_factor\": 10.766015411183535, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,741.38 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19510715\", \"value_r\": \"19510715\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"8026179\", \"value_r\": \"1609739\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" \", \"value_r\": \" 65\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"2068\", \"value_r\": \"2086\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.58615312769997, \"bayes_factor\": 0.0001626261492051098, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" spicer\", \"value_r\": \" anika\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" anika\", \"value_r\": \" spicer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9293969479707318, \"u_probability\": 0.0005337128624799857, \"bayes_factor\": 1741.3800815144946, \"log2_bayes_factor\": 10.766015411183535, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,741.38 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19861012\", \"value_r\": \"19861012\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"5087622\", \"value_r\": \"1434508\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 39\", \"value_r\": \" 3\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"2076\", \"value_r\": \"2067\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.58615312769997, \"bayes_factor\": 0.0001626261492051098, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" morrison\", \"value_r\": \" robin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" rob inq\", \"value_r\": \" morrisn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9293969479707318, \"u_probability\": 0.0005337128624799857, \"bayes_factor\": 1741.3800815144946, \"log2_bayes_factor\": 10.766015411183535, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,741.38 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19250124\", \"value_r\": \"19250124\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"8539119\", \"value_r\": \"1191533\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 87\", \"value_r\": \" 14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"6196\", \"value_r\": \"6169\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.58615312769997, \"bayes_factor\": 0.0001626261492051098, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -10.886123785487664, \"bayes_factor\": 0.0005283846640354178, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 0.25110212025946904, \"log2_bayes_factor\": -1.9936538843786782, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"given_name\", \"value_l\": \" joel\", \"value_r\": \" ryan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.24569223714869898, \"u_probability\": 0.978455446313317, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  3.98 times less likely to be a match\", \"column_name\": \"tf_given_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 0.2021130018850223, \"log2_bayes_factor\": -2.3067659619292895, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \" ryan\", \"value_r\": \" joel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.19940477044070387, \"u_probability\": 0.986600409577514, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.95 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"sql_condition\": \"\\\"date_of_birth_l\\\" = \\\"date_of_birth_r\\\"\", \"label_for_charts\": \"Exact match on date_of_birth\", \"m_probability\": 0.9293969479707318, \"u_probability\": 0.0005337128624799857, \"bayes_factor\": 1741.3800815144946, \"log2_bayes_factor\": 10.766015411183535, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on date_of_birth` then comparison is 1,741.38 times more likely to be a match\", \"column_name\": \"date_of_birth\", \"value_l\": \"19720615\", \"value_r\": \"19720615\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.0642174678587305, \"u_probability\": 0.9992769306921083, \"bayes_factor\": 0.06426393513783302, \"log2_bayes_factor\": -3.9598468642717424, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  15.56 times less likely to be a match\", \"column_name\": \"soc_sec_id\", \"value_l\": \"9499826\", \"value_r\": \"7563426\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 0.2355794660661112, \"log2_bayes_factor\": -2.085714300607056, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"street_number\", \"value_l\": \" 62\", \"value_r\": \" 26\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23183952514772252, \"u_probability\": 0.9841245037997535, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.24 times less likely to be a match\", \"column_name\": \"tf_street_number\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 0.23003674877954972, \"log2_bayes_factor\": -2.1200637422090725, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"postcode\", \"value_l\": \"370\", \"value_r\": \"3070\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.22974918330787747, \"u_probability\": 0.9987499150757524, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.35 times less likely to be a match\", \"column_name\": \"tf_postcode\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -12.58615312769997, \"bayes_factor\": 0.0001626261492051098, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.evaluation.prediction_errors_from_labels_column(\"cluster\").as_record_dict(\n",
    "    limit=10\n",
    ")\n",
    "linker.visualisations.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "94aaeff2f888492ea321d4e4492526ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bdf3a462cd3d48bda4269ac1cc8ed9ef",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e05a7090510949ac956ea05719a3b8c2",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "b179423ef9d24cb1ac973b4b55daa86c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "bdf3a462cd3d48bda4269ac1cc8ed9ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "db3fd6bdb9884f5a88fd4cf5d39330d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "e05a7090510949ac956ea05719a3b8c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "e181cb7618b74e4bbf9f2e144b68b87e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b179423ef9d24cb1ac973b4b55daa86c",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db3fd6bdb9884f5a88fd4cf5d39330d4",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
