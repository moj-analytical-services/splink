{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking a dataset of real historical persons\n",
    "\n",
    "In this example, we deduplicate a more realistic dataset. The data is based on historical persons scraped from wikidata. Duplicate records are introduced with a variety of errors introduced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/moj-analytical-services/splink/blob/splink4_dev/docs/demos/examples/duckdb/deduplicate_50k_synthetic.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:25.613571Z",
     "iopub.status.busy": "2024-06-07T09:09:25.613270Z",
     "iopub.status.idle": "2024-06-07T09:09:25.618664Z",
     "shell.execute_reply": "2024-06-07T09:09:25.617985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're running in Google Colab.\n",
    "# !pip install git+https://github.com/moj-analytical-services/splink.git@splink4_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:25.622132Z",
     "iopub.status.busy": "2024-06-07T09:09:25.621861Z",
     "iopub.status.idle": "2024-06-07T09:09:28.057830Z",
     "shell.execute_reply": "2024-06-07T09:09:28.057112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: https://raw.githubusercontent.com/moj-analytical-services/splink_datasets/master/data/historical_figures_with_errors_50k.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  download progress: 0 %\t(..........)\r",
      "  download progress: 1 %\t(..........)\r",
      "  download progress: 1 %\t(..........)\r",
      "  download progress: 2 %\t(..........)\r",
      "  download progress: 2 %\t(..........)\r",
      "  download progress: 3 %\t(..........)\r",
      "  download progress: 3 %\t(..........)\r",
      "  download progress: 4 %\t(..........)\r",
      "  download progress: 4 %\t(..........)\r",
      "  download progress: 5 %\t(..........)\r",
      "  download progress: 5 %\t(..........)\r",
      "  download progress: 6 %\t(..........)\r",
      "  download progress: 6 %\t(..........)\r",
      "  download progress: 7 %\t(..........)\r",
      "  download progress: 7 %\t(..........)\r",
      "  download progress: 8 %\t(..........)\r",
      "  download progress: 8 %\t(..........)\r",
      "  download progress: 9 %\t(..........)\r",
      "  download progress: 9 %\t(..........)\r",
      "  download progress: 10 %\t(..........)\r",
      "  download progress: 10 %\t(=.........)\r",
      "  download progress: 11 %\t(=.........)\r",
      "  download progress: 11 %\t(=.........)\r",
      "  download progress: 12 %\t(=.........)\r",
      "  download progress: 12 %\t(=.........)\r",
      "  download progress: 13 %\t(=.........)\r",
      "  download progress: 13 %\t(=.........)\r",
      "  download progress: 14 %\t(=.........)\r",
      "  download progress: 14 %\t(=.........)\r",
      "  download progress: 15 %\t(=.........)\r",
      "  download progress: 15 %\t(=.........)\r",
      "  download progress: 16 %\t(=.........)\r",
      "  download progress: 16 %\t(=.........)\r",
      "  download progress: 17 %\t(=.........)\r",
      "  download progress: 17 %\t(=.........)\r",
      "  download progress: 18 %\t(=.........)\r",
      "  download progress: 18 %\t(=.........)\r",
      "  download progress: 19 %\t(=.........)\r",
      "  download progress: 19 %\t(=.........)\r",
      "  download progress: 20 %\t(=.........)\r",
      "  download progress: 20 %\t(==........)\r",
      "  download progress: 21 %\t(==........)\r",
      "  download progress: 21 %\t(==........)\r",
      "  download progress: 22 %\t(==........)\r",
      "  download progress: 22 %\t(==........)\r",
      "  download progress: 23 %\t(==........)\r",
      "  download progress: 23 %\t(==........)\r",
      "  download progress: 24 %\t(==........)\r",
      "  download progress: 24 %\t(==........)\r",
      "  download progress: 25 %\t(==........)\r",
      "  download progress: 25 %\t(==........)\r",
      "  download progress: 26 %\t(==........)\r",
      "  download progress: 26 %\t(==........)\r",
      "  download progress: 27 %\t(==........)\r",
      "  download progress: 27 %\t(==........)\r",
      "  download progress: 28 %\t(==........)\r",
      "  download progress: 28 %\t(==........)\r",
      "  download progress: 29 %\t(==........)\r",
      "  download progress: 29 %\t(==........)\r",
      "  download progress: 30 %\t(==........)\r",
      "  download progress: 30 %\t(===.......)\r",
      "  download progress: 31 %\t(===.......)\r",
      "  download progress: 31 %\t(===.......)\r",
      "  download progress: 32 %\t(===.......)\r",
      "  download progress: 32 %\t(===.......)\r",
      "  download progress: 33 %\t(===.......)\r",
      "  download progress: 33 %\t(===.......)\r",
      "  download progress: 34 %\t(===.......)\r",
      "  download progress: 34 %\t(===.......)\r",
      "  download progress: 35 %\t(===.......)\r",
      "  download progress: 35 %\t(===.......)\r",
      "  download progress: 36 %\t(===.......)\r",
      "  download progress: 36 %\t(===.......)\r",
      "  download progress: 37 %\t(===.......)\r",
      "  download progress: 37 %\t(===.......)\r",
      "  download progress: 38 %\t(===.......)\r",
      "  download progress: 38 %\t(===.......)\r",
      "  download progress: 39 %\t(===.......)\r",
      "  download progress: 39 %\t(===.......)\r",
      "  download progress: 40 %\t(===.......)\r",
      "  download progress: 40 %\t(====......)\r",
      "  download progress: 41 %\t(====......)\r",
      "  download progress: 41 %\t(====......)\r",
      "  download progress: 42 %\t(====......)\r",
      "  download progress: 42 %\t(====......)\r",
      "  download progress: 43 %\t(====......)\r",
      "  download progress: 43 %\t(====......)\r",
      "  download progress: 44 %\t(====......)\r",
      "  download progress: 44 %\t(====......)\r",
      "  download progress: 45 %\t(====......)\r",
      "  download progress: 45 %\t(====......)\r",
      "  download progress: 46 %\t(====......)\r",
      "  download progress: 46 %\t(====......)\r",
      "  download progress: 47 %\t(====......)\r",
      "  download progress: 47 %\t(====......)\r",
      "  download progress: 48 %\t(====......)\r",
      "  download progress: 48 %\t(====......)\r",
      "  download progress: 49 %\t(====......)\r",
      "  download progress: 49 %\t(====......)\r",
      "  download progress: 50 %\t(====......)\r",
      "  download progress: 50 %\t(=====.....)\r",
      "  download progress: 51 %\t(=====.....)\r",
      "  download progress: 51 %\t(=====.....)\r",
      "  download progress: 52 %\t(=====.....)\r",
      "  download progress: 52 %\t(=====.....)\r",
      "  download progress: 53 %\t(=====.....)\r",
      "  download progress: 53 %\t(=====.....)\r",
      "  download progress: 54 %\t(=====.....)\r",
      "  download progress: 54 %\t(=====.....)\r",
      "  download progress: 55 %\t(=====.....)\r",
      "  download progress: 55 %\t(=====.....)\r",
      "  download progress: 56 %\t(=====.....)\r",
      "  download progress: 56 %\t(=====.....)\r",
      "  download progress: 57 %\t(=====.....)\r",
      "  download progress: 57 %\t(=====.....)\r",
      "  download progress: 58 %\t(=====.....)\r",
      "  download progress: 58 %\t(=====.....)\r",
      "  download progress: 59 %\t(=====.....)\r",
      "  download progress: 59 %\t(=====.....)\r",
      "  download progress: 60 %\t(=====.....)\r",
      "  download progress: 60 %\t(======....)\r",
      "  download progress: 61 %\t(======....)\r",
      "  download progress: 61 %\t(======....)\r",
      "  download progress: 62 %\t(======....)\r",
      "  download progress: 62 %\t(======....)\r",
      "  download progress: 63 %\t(======....)\r",
      "  download progress: 63 %\t(======....)\r",
      "  download progress: 64 %\t(======....)\r",
      "  download progress: 64 %\t(======....)\r",
      "  download progress: 65 %\t(======....)\r",
      "  download progress: 65 %\t(======....)\r",
      "  download progress: 66 %\t(======....)\r",
      "  download progress: 66 %\t(======....)\r",
      "  download progress: 67 %\t(======....)\r",
      "  download progress: 67 %\t(======....)\r",
      "  download progress: 68 %\t(======....)\r",
      "  download progress: 68 %\t(======....)\r",
      "  download progress: 69 %\t(======....)\r",
      "  download progress: 69 %\t(======....)\r",
      "  download progress: 70 %\t(======....)\r",
      "  download progress: 70 %\t(=======...)\r",
      "  download progress: 71 %\t(=======...)\r",
      "  download progress: 71 %\t(=======...)\r",
      "  download progress: 72 %\t(=======...)\r",
      "  download progress: 72 %\t(=======...)\r",
      "  download progress: 73 %\t(=======...)\r",
      "  download progress: 73 %\t(=======...)\r",
      "  download progress: 74 %\t(=======...)\r",
      "  download progress: 74 %\t(=======...)\r",
      "  download progress: 75 %\t(=======...)\r",
      "  download progress: 75 %\t(=======...)\r",
      "  download progress: 76 %\t(=======...)\r",
      "  download progress: 76 %\t(=======...)\r",
      "  download progress: 77 %\t(=======...)\r",
      "  download progress: 77 %\t(=======...)\r",
      "  download progress: 78 %\t(=======...)\r",
      "  download progress: 78 %\t(=======...)\r",
      "  download progress: 79 %\t(=======...)\r",
      "  download progress: 79 %\t(=======...)\r",
      "  download progress: 80 %\t(=======...)\r",
      "  download progress: 80 %\t(========..)\r",
      "  download progress: 81 %\t(========..)\r",
      "  download progress: 81 %\t(========..)\r",
      "  download progress: 82 %\t(========..)\r",
      "  download progress: 82 %\t(========..)\r",
      "  download progress: 83 %\t(========..)\r",
      "  download progress: 83 %\t(========..)\r",
      "  download progress: 84 %\t(========..)\r",
      "  download progress: 84 %\t(========..)\r",
      "  download progress: 85 %\t(========..)\r",
      "  download progress: 85 %\t(========..)\r",
      "  download progress: 86 %\t(========..)\r",
      "  download progress: 86 %\t(========..)\r",
      "  download progress: 87 %\t(========..)\r",
      "  download progress: 87 %\t(========..)\r",
      "  download progress: 88 %\t(========..)\r",
      "  download progress: 88 %\t(========..)\r",
      "  download progress: 89 %\t(========..)\r",
      "  download progress: 89 %\t(========..)\r",
      "  download progress: 90 %\t(========..)\r",
      "  download progress: 90 %\t(=========.)\r",
      "  download progress: 91 %\t(=========.)\r",
      "  download progress: 91 %\t(=========.)\r",
      "  download progress: 92 %\t(=========.)\r",
      "  download progress: 92 %\t(=========.)\r",
      "  download progress: 93 %\t(=========.)\r",
      "  download progress: 93 %\t(=========.)\r",
      "  download progress: 94 %\t(=========.)\r",
      "  download progress: 94 %\t(=========.)\r",
      "  download progress: 95 %\t(=========.)\r",
      "  download progress: 95 %\t(=========.)\r",
      "  download progress: 96 %\t(=========.)\r",
      "  download progress: 96 %\t(=========.)\r",
      "  download progress: 97 %\t(=========.)\r",
      "  download progress: 97 %\t(=========.)\r",
      "  download progress: 98 %\t(=========.)\r",
      "  download progress: 98 %\t(=========.)\r",
      "  download progress: 99 %\t(=========.)\r",
      "  download progress: 99 %\t(=========.)\r",
      "  download progress: 100 %\t(=========.)\r",
      "  download progress: 100 %\t(==========)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>full_name</th>\n",
       "      <th>first_and_surname</th>\n",
       "      <th>first_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>dob</th>\n",
       "      <th>birth_place</th>\n",
       "      <th>postcode_fake</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2296770-1</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas clifford, 1st baron clifford of chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>male</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2296770-2</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas of chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>male</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2296770-3</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>tom 1st baron clifford of chudleigh</td>\n",
       "      <td>tom chudleigh</td>\n",
       "      <td>tom</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>male</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2296770-4</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas 1st chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8hu</td>\n",
       "      <td>None</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2296770-5</td>\n",
       "      <td>Q2296770</td>\n",
       "      <td>thomas clifford, 1st baron chudleigh</td>\n",
       "      <td>thomas chudleigh</td>\n",
       "      <td>thomas</td>\n",
       "      <td>chudleigh</td>\n",
       "      <td>1630-08-01</td>\n",
       "      <td>devon</td>\n",
       "      <td>tq13 8df</td>\n",
       "      <td>None</td>\n",
       "      <td>politician</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id   cluster                                         full_name  \\\n",
       "0  Q2296770-1  Q2296770  thomas clifford, 1st baron clifford of chudleigh   \n",
       "1  Q2296770-2  Q2296770                               thomas of chudleigh   \n",
       "2  Q2296770-3  Q2296770               tom 1st baron clifford of chudleigh   \n",
       "3  Q2296770-4  Q2296770                              thomas 1st chudleigh   \n",
       "4  Q2296770-5  Q2296770              thomas clifford, 1st baron chudleigh   \n",
       "\n",
       "  first_and_surname first_name    surname         dob birth_place  \\\n",
       "0  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "1  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "2     tom chudleigh        tom  chudleigh  1630-08-01       devon   \n",
       "3  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "4  thomas chudleigh     thomas  chudleigh  1630-08-01       devon   \n",
       "\n",
       "  postcode_fake gender  occupation  \n",
       "0      tq13 8df   male  politician  \n",
       "1      tq13 8df   male  politician  \n",
       "2      tq13 8df   male  politician  \n",
       "3      tq13 8hu   None  politician  \n",
       "4      tq13 8df   None  politician  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import splink_datasets\n",
    "\n",
    "df = splink_datasets.historical_50k\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:28.061677Z",
     "iopub.status.busy": "2024-06-07T09:09:28.061319Z",
     "iopub.status.idle": "2024-06-07T09:09:28.892623Z",
     "shell.execute_reply": "2024-06-07T09:09:28.891638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4f10c87d6c6a4f28b1c0d6d0bd7ea4bc.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4f10c87d6c6a4f28b1c0d6d0bd7ea4bc.vega-embed details,\n",
       "  #altair-viz-4f10c87d6c6a4f28b1c0d6d0bd7ea4bc.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4f10c87d6c6a4f28b1c0d6d0bd7ea4bc\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4f10c87d6c6a4f28b1c0d6d0bd7ea4bc\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4f10c87d6c6a4f28b1c0d6d0bd7ea4bc\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.25410306453704834, \"percentile_inc_nulls\": 0.25509113073349, \"value_count\": 24, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 192.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.25091564655303955, \"percentile_inc_nulls\": 0.25190794467926025, \"value_count\": 23, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 161.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.24612462520599365, \"percentile_inc_nulls\": 0.24712324142456055, \"value_count\": 22, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 242.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2411355972290039, \"percentile_inc_nulls\": 0.24214082956314087, \"value_count\": 21, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 252.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.23638415336608887, \"percentile_inc_nulls\": 0.23739570379257202, \"value_count\": 20, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 240.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.22998952865600586, \"percentile_inc_nulls\": 0.23100954294204712, \"value_count\": 19, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 323.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2228623628616333, \"percentile_inc_nulls\": 0.22389179468154907, \"value_count\": 18, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 360.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2188236117362976, \"percentile_inc_nulls\": 0.21985840797424316, \"value_count\": 17, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.20995426177978516, \"percentile_inc_nulls\": 0.21100085973739624, \"value_count\": 16, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 448.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.20193618535995483, \"percentile_inc_nulls\": 0.20299339294433594, \"value_count\": 15, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 405.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.194452702999115, \"percentile_inc_nulls\": 0.1955198049545288, \"value_count\": 14, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 378.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.18158423900604248, \"percentile_inc_nulls\": 0.18266832828521729, \"value_count\": 13, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 650.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.17279404401779175, \"percentile_inc_nulls\": 0.17388981580734253, \"value_count\": 12, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 444.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.16538971662521362, \"percentile_inc_nulls\": 0.16649532318115234, \"value_count\": 11, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 374.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.15588682889938354, \"percentile_inc_nulls\": 0.15700501203536987, \"value_count\": 10, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 480.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.14394885301589966, \"percentile_inc_nulls\": 0.14508283138275146, \"value_count\": 9, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 603.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.13143670558929443, \"percentile_inc_nulls\": 0.13258731365203857, \"value_count\": 8, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 632.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.12145870923995972, \"percentile_inc_nulls\": 0.12262248992919922, \"value_count\": 7, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 504.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.11076796054840088, \"percentile_inc_nulls\": 0.11194592714309692, \"value_count\": 6, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 540.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.10017621517181396, \"percentile_inc_nulls\": 0.10136818885803223, \"value_count\": 5, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 535.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.08655542135238647, \"percentile_inc_nulls\": 0.08776545524597168, \"value_count\": 4, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 688.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.0702817440032959, \"percentile_inc_nulls\": 0.07151329517364502, \"value_count\": 3, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 822.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.047276854515075684, \"percentile_inc_nulls\": 0.04853886365890503, \"value_count\": 2, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1162.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.0013247132301330566, \"value_count\": 1, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 2388.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.9449625015258789, \"percentile_inc_nulls\": 0.9450353980064392, \"value_count\": 2780, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 2780.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8907960653305054, \"percentile_inc_nulls\": 0.8909407258033752, \"value_count\": 2736, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 2736.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8621290326118469, \"percentile_inc_nulls\": 0.8623116612434387, \"value_count\": 1448, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1448.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8341153264045715, \"percentile_inc_nulls\": 0.8343350887298584, \"value_count\": 1415, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1415.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.8082596063613892, \"percentile_inc_nulls\": 0.8085135817527771, \"value_count\": 1306, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1306.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7832155227661133, \"percentile_inc_nulls\": 0.7835026979446411, \"value_count\": 1265, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1265.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7582308650016785, \"percentile_inc_nulls\": 0.7585511207580566, \"value_count\": 1262, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1262.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7341569066047668, \"percentile_inc_nulls\": 0.7345091104507446, \"value_count\": 1216, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1216.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.7161211967468262, \"percentile_inc_nulls\": 0.7164973020553589, \"value_count\": 911, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 911.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.698620080947876, \"percentile_inc_nulls\": 0.6990193128585815, \"value_count\": 884, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 884.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6826632022857666, \"percentile_inc_nulls\": 0.6830835342407227, \"value_count\": 806, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 806.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6697155237197876, \"percentile_inc_nulls\": 0.670153021812439, \"value_count\": 654, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 654.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6573221683502197, \"percentile_inc_nulls\": 0.6577761173248291, \"value_count\": 626, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 626.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6471858024597168, \"percentile_inc_nulls\": 0.6476531028747559, \"value_count\": 512, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 512.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6370691657066345, \"percentile_inc_nulls\": 0.6375499367713928, \"value_count\": 511, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 511.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6269921064376831, \"percentile_inc_nulls\": 0.6274862289428711, \"value_count\": 509, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 509.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6171329021453857, \"percentile_inc_nulls\": 0.6176400780677795, \"value_count\": 498, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 498.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.6079269647598267, \"percentile_inc_nulls\": 0.6084463596343994, \"value_count\": 465, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 465.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5987408757209778, \"percentile_inc_nulls\": 0.5992723703384399, \"value_count\": 464, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 464.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5904456377029419, \"percentile_inc_nulls\": 0.5909881591796875, \"value_count\": 419, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 419.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5831403136253357, \"percentile_inc_nulls\": 0.5836925506591797, \"value_count\": 369, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 369.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5762308835983276, \"percentile_inc_nulls\": 0.5767922401428223, \"value_count\": 349, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 349.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5698164701461792, \"percentile_inc_nulls\": 0.5703862905502319, \"value_count\": 324, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 324.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5634812116622925, \"percentile_inc_nulls\": 0.5640594959259033, \"value_count\": 320, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 320.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5573043823242188, \"percentile_inc_nulls\": 0.557890772819519, \"value_count\": 312, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 312.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5513848066329956, \"percentile_inc_nulls\": 0.551979124546051, \"value_count\": 299, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 299.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5457029342651367, \"percentile_inc_nulls\": 0.5463047027587891, \"value_count\": 287, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 287.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5401991605758667, \"percentile_inc_nulls\": 0.5408082604408264, \"value_count\": 278, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 278.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5348538160324097, \"percentile_inc_nulls\": 0.5354700088500977, \"value_count\": 270, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 270.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5298252105712891, \"percentile_inc_nulls\": 0.5304480195045471, \"value_count\": 254, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 254.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5250935554504395, \"percentile_inc_nulls\": 0.5257226228713989, \"value_count\": 239, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 239.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5204806923866272, \"percentile_inc_nulls\": 0.5211158990859985, \"value_count\": 233, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 233.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5164815187454224, \"percentile_inc_nulls\": 0.5171220302581787, \"value_count\": 202, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 202.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.51287841796875, \"percentile_inc_nulls\": 0.5135236978530884, \"value_count\": 182, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 182.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5092949867248535, \"percentile_inc_nulls\": 0.5099450349807739, \"value_count\": 181, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 181.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.5058304071426392, \"percentile_inc_nulls\": 0.5064850449562073, \"value_count\": 175, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 175.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.49898040294647217, \"percentile_inc_nulls\": 0.49964410066604614, \"value_count\": 173, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 346.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.49563461542129517, \"percentile_inc_nulls\": 0.4963027238845825, \"value_count\": 169, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 169.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4923086166381836, \"percentile_inc_nulls\": 0.4929811358451843, \"value_count\": 168, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4890221953392029, \"percentile_inc_nulls\": 0.4896990656852722, \"value_count\": 166, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 166.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.48587435483932495, \"percentile_inc_nulls\": 0.48655539751052856, \"value_count\": 159, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 159.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4827859401702881, \"percentile_inc_nulls\": 0.4834710955619812, \"value_count\": 156, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.47664862871170044, \"percentile_inc_nulls\": 0.4773419499397278, \"value_count\": 155, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 310.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4705509543418884, \"percentile_inc_nulls\": 0.47125232219696045, \"value_count\": 154, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 308.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4675813317298889, \"percentile_inc_nulls\": 0.4682866334915161, \"value_count\": 150, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 150.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.46471065282821655, \"percentile_inc_nulls\": 0.4654197692871094, \"value_count\": 145, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 145.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.46195876598358154, \"percentile_inc_nulls\": 0.46267151832580566, \"value_count\": 139, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 139.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.459286093711853, \"percentile_inc_nulls\": 0.4600023627281189, \"value_count\": 135, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 135.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.45405954122543335, \"percentile_inc_nulls\": 0.45478272438049316, \"value_count\": 132, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 264.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.451485812664032, \"percentile_inc_nulls\": 0.45221245288848877, \"value_count\": 130, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 130.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4464572072029114, \"percentile_inc_nulls\": 0.44719046354293823, \"value_count\": 127, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 254.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.44402211904525757, \"percentile_inc_nulls\": 0.4447585940361023, \"value_count\": 123, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.44164639711380005, \"percentile_inc_nulls\": 0.44238603115081787, \"value_count\": 120, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4393102526664734, \"percentile_inc_nulls\": 0.44005298614501953, \"value_count\": 118, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 118.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4370335340499878, \"percentile_inc_nulls\": 0.4377792477607727, \"value_count\": 115, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4347766041755676, \"percentile_inc_nulls\": 0.4355252981185913, \"value_count\": 114, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 114.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4325592517852783, \"percentile_inc_nulls\": 0.43331092596054077, \"value_count\": 112, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 112.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4304013252258301, \"percentile_inc_nulls\": 0.43115586042404175, \"value_count\": 109, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 109.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4283621311187744, \"percentile_inc_nulls\": 0.42911940813064575, \"value_count\": 103, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 103.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.42634278535842896, \"percentile_inc_nulls\": 0.4271026849746704, \"value_count\": 102, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 102.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4223436713218689, \"percentile_inc_nulls\": 0.42310887575149536, \"value_count\": 101, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 202.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4203639030456543, \"percentile_inc_nulls\": 0.4211317300796509, \"value_count\": 100, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 100.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.418443500995636, \"percentile_inc_nulls\": 0.4192138910293579, \"value_count\": 97, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 97.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4165429472923279, \"percentile_inc_nulls\": 0.41731584072113037, \"value_count\": 96, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4146621823310852, \"percentile_inc_nulls\": 0.4154375195503235, \"value_count\": 95, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 95.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4128011465072632, \"percentile_inc_nulls\": 0.4135790467262268, \"value_count\": 94, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 94.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4055156111717224, \"percentile_inc_nulls\": 0.4063031077384949, \"value_count\": 92, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 368.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.4001108407974243, \"percentile_inc_nulls\": 0.4009055495262146, \"value_count\": 91, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 273.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.39832907915115356, \"percentile_inc_nulls\": 0.3991261124610901, \"value_count\": 90, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3948447108268738, \"percentile_inc_nulls\": 0.395646333694458, \"value_count\": 88, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 176.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.39139991998672485, \"percentile_inc_nulls\": 0.392206072807312, \"value_count\": 87, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 174.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.38971710205078125, \"percentile_inc_nulls\": 0.3905255198478699, \"value_count\": 85, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3864702582359314, \"percentile_inc_nulls\": 0.3872830271720886, \"value_count\": 82, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 164.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3848666548728943, \"percentile_inc_nulls\": 0.38568150997161865, \"value_count\": 81, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 81.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3816990256309509, \"percentile_inc_nulls\": 0.38251811265945435, \"value_count\": 80, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 160.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3801349997520447, \"percentile_inc_nulls\": 0.38095617294311523, \"value_count\": 79, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 79.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.37859082221984863, \"percentile_inc_nulls\": 0.3794139623641968, \"value_count\": 78, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.37706637382507324, \"percentile_inc_nulls\": 0.3778916001319885, \"value_count\": 77, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 77.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.37556177377700806, \"percentile_inc_nulls\": 0.3763889670372009, \"value_count\": 76, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 76.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3740769624710083, \"percentile_inc_nulls\": 0.374906063079834, \"value_count\": 75, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 75.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3726118803024292, \"percentile_inc_nulls\": 0.37344300746917725, \"value_count\": 74, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 74.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3697214722633362, \"percentile_inc_nulls\": 0.3705563545227051, \"value_count\": 73, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 146.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.36687058210372925, \"percentile_inc_nulls\": 0.36770927906036377, \"value_count\": 72, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3654649257659912, \"percentile_inc_nulls\": 0.36630553007125854, \"value_count\": 71, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 71.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3640791177749634, \"percentile_inc_nulls\": 0.364921510219574, \"value_count\": 70, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 70.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.362713098526001, \"percentile_inc_nulls\": 0.36355727910995483, \"value_count\": 69, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3586743474006653, \"percentile_inc_nulls\": 0.3595238924026489, \"value_count\": 68, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.35734790563583374, \"percentile_inc_nulls\": 0.35819923877716064, \"value_count\": 67, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 67.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.35606104135513306, \"percentile_inc_nulls\": 0.35691410303115845, \"value_count\": 65, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3547940254211426, \"percentile_inc_nulls\": 0.3556486964225769, \"value_count\": 64, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3522995114326477, \"percentile_inc_nulls\": 0.35315752029418945, \"value_count\": 63, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3510720729827881, \"percentile_inc_nulls\": 0.35193169116973877, \"value_count\": 62, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.34744906425476074, \"percentile_inc_nulls\": 0.34831351041793823, \"value_count\": 61, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 183.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3427768349647522, \"percentile_inc_nulls\": 0.34364742040634155, \"value_count\": 59, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 236.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.33933204412460327, \"percentile_inc_nulls\": 0.34020721912384033, \"value_count\": 58, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 174.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3382035493850708, \"percentile_inc_nulls\": 0.33908021450042725, \"value_count\": 57, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 57.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.33709490299224854, \"percentile_inc_nulls\": 0.33797305822372437, \"value_count\": 56, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 56.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.33602583408355713, \"percentile_inc_nulls\": 0.3369053602218628, \"value_count\": 54, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3328779935836792, \"percentile_inc_nulls\": 0.33376169204711914, \"value_count\": 53, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 159.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3287600874900818, \"percentile_inc_nulls\": 0.32964926958084106, \"value_count\": 52, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.32674068212509155, \"percentile_inc_nulls\": 0.3276325464248657, \"value_count\": 51, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 102.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.32575082778930664, \"percentile_inc_nulls\": 0.32664400339126587, \"value_count\": 50, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 50.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3238106369972229, \"percentile_inc_nulls\": 0.32470637559890747, \"value_count\": 49, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 98.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.32095980644226074, \"percentile_inc_nulls\": 0.32185930013656616, \"value_count\": 48, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 144.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3200293183326721, \"percentile_inc_nulls\": 0.3209300637245178, \"value_count\": 47, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.31729722023010254, \"percentile_inc_nulls\": 0.31820160150527954, \"value_count\": 46, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 138.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.31373363733291626, \"percentile_inc_nulls\": 0.3146427273750305, \"value_count\": 45, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 180.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.30937814712524414, \"percentile_inc_nulls\": 0.3102930188179016, \"value_count\": 44, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 220.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.3076755404472351, \"percentile_inc_nulls\": 0.30859267711639404, \"value_count\": 43, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.30434954166412354, \"percentile_inc_nulls\": 0.30527108907699585, \"value_count\": 42, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 168.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.30353784561157227, \"percentile_inc_nulls\": 0.30446046590805054, \"value_count\": 41, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 41.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2987864017486572, \"percentile_inc_nulls\": 0.2997152805328369, \"value_count\": 40, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 240.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.29569798707962036, \"percentile_inc_nulls\": 0.2966309189796448, \"value_count\": 39, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 156.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2934410572052002, \"percentile_inc_nulls\": 0.29437702894210815, \"value_count\": 38, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 114.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2912434935569763, \"percentile_inc_nulls\": 0.29218238592147827, \"value_count\": 37, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2891647219657898, \"percentile_inc_nulls\": 0.2901063561439514, \"value_count\": 35, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 105.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.28579914569854736, \"percentile_inc_nulls\": 0.28674525022506714, \"value_count\": 34, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 170.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.281879186630249, \"percentile_inc_nulls\": 0.28283047676086426, \"value_count\": 33, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 198.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2799786329269409, \"percentile_inc_nulls\": 0.2809324264526367, \"value_count\": 32, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2775236964225769, \"percentile_inc_nulls\": 0.27848076820373535, \"value_count\": 31, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 124.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.27336621284484863, \"percentile_inc_nulls\": 0.2743287682533264, \"value_count\": 30, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 210.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.27049553394317627, \"percentile_inc_nulls\": 0.2714619040489197, \"value_count\": 29, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 145.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.26772385835647583, \"percentile_inc_nulls\": 0.2686939239501953, \"value_count\": 28, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 140.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2639821171760559, \"percentile_inc_nulls\": 0.264957070350647, \"value_count\": 27, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.26037895679473877, \"percentile_inc_nulls\": 0.26135867834091187, \"value_count\": 26, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 182.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 0.2579042315483093, \"percentile_inc_nulls\": 0.25888729095458984, \"value_count\": 25, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 125.0, \"distinct_value_count\": 4413}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 24, \"group_name\": \"first_name\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 192.0, \"distinct_value_count\": 4413}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column first_name\", \"subtitle\": \"In this col, 67 values (0.1%) are null and there are 4413 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 2780, \"group_name\": \"first_name\", \"value\": \"william\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 2736, \"group_name\": \"first_name\", \"value\": \"john\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1448, \"group_name\": \"first_name\", \"value\": \"thomas\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1415, \"group_name\": \"first_name\", \"value\": \"george\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1306, \"group_name\": \"first_name\", \"value\": \"henry\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1265, \"group_name\": \"first_name\", \"value\": \"james\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1262, \"group_name\": \"first_name\", \"value\": \"sir\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1216, \"group_name\": \"first_name\", \"value\": \"charles\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 911, \"group_name\": \"first_name\", \"value\": \"edward\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 884, \"group_name\": \"first_name\", \"value\": \"robert\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"feank\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"vsughan\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"pzul\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"pauk\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"swift\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"bhownagri\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"ibrahim\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"zydney\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"thornton\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}, {\"value_count\": 1, \"group_name\": \"first_name\", \"value\": \"rivhard\", \"total_non_null_rows\": 50511, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 4413}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 2780]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}, {\"hconcat\": [{\"mark\": {\"type\": \"line\", \"interpolate\": \"step-after\"}, \"data\": {\"values\": [{\"percentile_ex_nulls\": 0.9620519876480103, \"percentile_inc_nulls\": 0.96543949842453, \"value_count\": 1748, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1748.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.9272083640098572, \"percentile_inc_nulls\": 0.9337063431739807, \"value_count\": 1605, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1605.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8945791721343994, \"percentile_inc_nulls\": 0.903989851474762, \"value_count\": 1503, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1503.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8677246570587158, \"percentile_inc_nulls\": 0.8795325756072998, \"value_count\": 1237, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1237.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8411957621574402, \"percentile_inc_nulls\": 0.85537189245224, \"value_count\": 1222, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1222.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.8200073838233948, \"percentile_inc_nulls\": 0.836074948310852, \"value_count\": 976, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 976.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7988624572753906, \"percentile_inc_nulls\": 0.816817581653595, \"value_count\": 974, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 974.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7782385349273682, \"percentile_inc_nulls\": 0.7980347275733948, \"value_count\": 950, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 950.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7581573128700256, \"percentile_inc_nulls\": 0.7797461152076721, \"value_count\": 925, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 925.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7402036190032959, \"percentile_inc_nulls\": 0.7633951306343079, \"value_count\": 827, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 827.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7224019169807434, \"percentile_inc_nulls\": 0.7471826076507568, \"value_count\": 820, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 820.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.7047739028930664, \"percentile_inc_nulls\": 0.7311281561851501, \"value_count\": 812, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 812.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6874281167984009, \"percentile_inc_nulls\": 0.7153307795524597, \"value_count\": 799, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 799.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6718190312385559, \"percentile_inc_nulls\": 0.7011151313781738, \"value_count\": 719, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 719.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6564704775810242, \"percentile_inc_nulls\": 0.687136709690094, \"value_count\": 707, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 707.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6416212320327759, \"percentile_inc_nulls\": 0.6736130714416504, \"value_count\": 684, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 684.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6276403665542603, \"percentile_inc_nulls\": 0.6608802080154419, \"value_count\": 644, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 644.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6140068769454956, \"percentile_inc_nulls\": 0.6484637260437012, \"value_count\": 628, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 628.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.6006121635437012, \"percentile_inc_nulls\": 0.6362648010253906, \"value_count\": 617, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 617.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5745174884796143, \"percentile_inc_nulls\": 0.612499475479126, \"value_count\": 601, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1202.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5632286071777344, \"percentile_inc_nulls\": 0.6022183895111084, \"value_count\": 520, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 520.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5519614219665527, \"percentile_inc_nulls\": 0.5919569730758667, \"value_count\": 519, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 519.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5411719083786011, \"percentile_inc_nulls\": 0.5821305513381958, \"value_count\": 497, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 497.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5307079553604126, \"percentile_inc_nulls\": 0.5726007223129272, \"value_count\": 482, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 482.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5206781625747681, \"percentile_inc_nulls\": 0.5634663105010986, \"value_count\": 462, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 462.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.5006621479988098, \"percentile_inc_nulls\": 0.5452370643615723, \"value_count\": 461, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 922.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4908711910247803, \"percentile_inc_nulls\": 0.536320149898529, \"value_count\": 451, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 451.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4815361499786377, \"percentile_inc_nulls\": 0.5278184413909912, \"value_count\": 430, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 430.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.47239649295806885, \"percentile_inc_nulls\": 0.5194946527481079, \"value_count\": 421, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 421.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.463473916053772, \"percentile_inc_nulls\": 0.5113685727119446, \"value_count\": 411, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 411.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.45459479093551636, \"percentile_inc_nulls\": 0.5032820701599121, \"value_count\": 409, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 409.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4458025097846985, \"percentile_inc_nulls\": 0.4952746033668518, \"value_count\": 405, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 405.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4373575448989868, \"percentile_inc_nulls\": 0.4875835180282593, \"value_count\": 389, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 389.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4289342761039734, \"percentile_inc_nulls\": 0.4799122214317322, \"value_count\": 388, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 388.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.4205544590950012, \"percentile_inc_nulls\": 0.47228044271469116, \"value_count\": 386, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 386.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.41258710622787476, \"percentile_inc_nulls\": 0.46502429246902466, \"value_count\": 367, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 367.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.40464144945144653, \"percentile_inc_nulls\": 0.45778799057006836, \"value_count\": 366, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 366.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.39678269624710083, \"percentile_inc_nulls\": 0.45063072443008423, \"value_count\": 362, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 362.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3893146514892578, \"percentile_inc_nulls\": 0.44382935762405396, \"value_count\": 344, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 344.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3819117546081543, \"percentile_inc_nulls\": 0.4370872974395752, \"value_count\": 341, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 341.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3745739459991455, \"percentile_inc_nulls\": 0.43040454387664795, \"value_count\": 338, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 338.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.36732304096221924, \"percentile_inc_nulls\": 0.42380088567733765, \"value_count\": 334, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 334.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.36039769649505615, \"percentile_inc_nulls\": 0.4174937605857849, \"value_count\": 319, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 319.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3535592555999756, \"percentile_inc_nulls\": 0.4112657904624939, \"value_count\": 315, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 315.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.34678590297698975, \"percentile_inc_nulls\": 0.4050970673561096, \"value_count\": 312, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 312.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3400343060493469, \"percentile_inc_nulls\": 0.39894813299179077, \"value_count\": 311, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 311.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3333261013031006, \"percentile_inc_nulls\": 0.3928387761116028, \"value_count\": 309, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 309.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.32679158449172974, \"percentile_inc_nulls\": 0.3868875503540039, \"value_count\": 301, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 301.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.32030045986175537, \"percentile_inc_nulls\": 0.3809759020805359, \"value_count\": 299, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 299.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.3138744831085205, \"percentile_inc_nulls\": 0.3751235604286194, \"value_count\": 296, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 296.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.30751359462738037, \"percentile_inc_nulls\": 0.3693305253982544, \"value_count\": 293, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 293.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.30128300189971924, \"percentile_inc_nulls\": 0.3636561632156372, \"value_count\": 287, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 287.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.2950741648674011, \"percentile_inc_nulls\": 0.3580015301704407, \"value_count\": 286, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 286.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.28903889656066895, \"percentile_inc_nulls\": 0.35250502824783325, \"value_count\": 278, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 278.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.28302544355392456, \"percentile_inc_nulls\": 0.34702837467193604, \"value_count\": 277, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 277.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.27117210626602173, \"percentile_inc_nulls\": 0.33623313903808594, \"value_count\": 273, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 546.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.25940561294555664, \"percentile_inc_nulls\": 0.3255169987678528, \"value_count\": 271, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 542.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.25356578826904297, \"percentile_inc_nulls\": 0.3201984763145447, \"value_count\": 269, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 269.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.24776935577392578, \"percentile_inc_nulls\": 0.31491953134536743, \"value_count\": 267, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 267.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.24208152294158936, \"percentile_inc_nulls\": 0.3097394108772278, \"value_count\": 262, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 262.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.23645877838134766, \"percentile_inc_nulls\": 0.30461859703063965, \"value_count\": 259, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 259.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.23096626996994019, \"percentile_inc_nulls\": 0.2996164560317993, \"value_count\": 253, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 253.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.22551721334457397, \"percentile_inc_nulls\": 0.2946537733078003, \"value_count\": 251, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 251.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.22019845247268677, \"percentile_inc_nulls\": 0.28980982303619385, \"value_count\": 245, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 245.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.21496647596359253, \"percentile_inc_nulls\": 0.28504490852355957, \"value_count\": 241, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 241.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.20977789163589478, \"percentile_inc_nulls\": 0.2803195118904114, \"value_count\": 239, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 239.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.20474135875701904, \"percentile_inc_nulls\": 0.27573251724243164, \"value_count\": 232, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 232.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.19974815845489502, \"percentile_inc_nulls\": 0.27118510007858276, \"value_count\": 230, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 230.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.194776713848114, \"percentile_inc_nulls\": 0.26665741205215454, \"value_count\": 229, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 229.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.18989211320877075, \"percentile_inc_nulls\": 0.26220887899398804, \"value_count\": 225, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 225.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.18505090475082397, \"percentile_inc_nulls\": 0.25779980421066284, \"value_count\": 223, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 223.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.18053537607192993, \"percentile_inc_nulls\": 0.25368738174438477, \"value_count\": 208, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 208.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.17604148387908936, \"percentile_inc_nulls\": 0.24959468841552734, \"value_count\": 207, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 207.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.17161279916763306, \"percentile_inc_nulls\": 0.24556130170822144, \"value_count\": 204, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 204.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.167205810546875, \"percentile_inc_nulls\": 0.24154770374298096, \"value_count\": 203, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 203.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.16308099031448364, \"percentile_inc_nulls\": 0.23779112100601196, \"value_count\": 190, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 190.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1589779257774353, \"percentile_inc_nulls\": 0.2340543270111084, \"value_count\": 189, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 189.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1550702452659607, \"percentile_inc_nulls\": 0.23049545288085938, \"value_count\": 180, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 180.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.14747196435928345, \"percentile_inc_nulls\": 0.22357547283172607, \"value_count\": 175, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 350.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1437596082687378, \"percentile_inc_nulls\": 0.22019457817077637, \"value_count\": 171, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 171.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.14013415575027466, \"percentile_inc_nulls\": 0.21689271926879883, \"value_count\": 167, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 167.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.13327401876449585, \"percentile_inc_nulls\": 0.21064496040344238, \"value_count\": 158, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 316.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.12997418642044067, \"percentile_inc_nulls\": 0.2076396942138672, \"value_count\": 152, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 152.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.12695658206939697, \"percentile_inc_nulls\": 0.20489144325256348, \"value_count\": 139, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 139.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1240692138671875, \"percentile_inc_nulls\": 0.20226186513900757, \"value_count\": 133, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 133.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.12129038572311401, \"percentile_inc_nulls\": 0.19973111152648926, \"value_count\": 128, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 128.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11853331327438354, \"percentile_inc_nulls\": 0.19722014665603638, \"value_count\": 127, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 127.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11579793691635132, \"percentile_inc_nulls\": 0.19472891092300415, \"value_count\": 126, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 126.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11312764883041382, \"percentile_inc_nulls\": 0.1922970414161682, \"value_count\": 123, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 123.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.11047911643981934, \"percentile_inc_nulls\": 0.18988490104675293, \"value_count\": 122, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 122.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1078522801399231, \"percentile_inc_nulls\": 0.18749260902404785, \"value_count\": 121, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 121.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.1052471399307251, \"percentile_inc_nulls\": 0.18511998653411865, \"value_count\": 120, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.10268545150756836, \"percentile_inc_nulls\": 0.1827870011329651, \"value_count\": 118, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 118.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.10018885135650635, \"percentile_inc_nulls\": 0.18051326274871826, \"value_count\": 115, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0977357029914856, \"percentile_inc_nulls\": 0.1782791018486023, \"value_count\": 113, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 113.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.09532594680786133, \"percentile_inc_nulls\": 0.1760844588279724, \"value_count\": 111, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 111.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.09298133850097656, \"percentile_inc_nulls\": 0.17394912242889404, \"value_count\": 108, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 108.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0907018780708313, \"percentile_inc_nulls\": 0.17187315225601196, \"value_count\": 105, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 105.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08844411373138428, \"percentile_inc_nulls\": 0.16981691122055054, \"value_count\": 104, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 104.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08627313375473022, \"percentile_inc_nulls\": 0.16783976554870605, \"value_count\": 100, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 100.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08414560556411743, \"percentile_inc_nulls\": 0.16590219736099243, \"value_count\": 98, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 98.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0820615291595459, \"percentile_inc_nulls\": 0.16400408744812012, \"value_count\": 96, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 96.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.08002084493637085, \"percentile_inc_nulls\": 0.16214561462402344, \"value_count\": 94, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 94.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.07802355289459229, \"percentile_inc_nulls\": 0.16032660007476807, \"value_count\": 92, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 92.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.076091468334198, \"percentile_inc_nulls\": 0.15856695175170898, \"value_count\": 89, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 89.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.07418102025985718, \"percentile_inc_nulls\": 0.15682709217071533, \"value_count\": 88, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 88.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0722922682762146, \"percentile_inc_nulls\": 0.15510696172714233, \"value_count\": 87, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 87.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.07042527198791504, \"percentile_inc_nulls\": 0.15340662002563477, \"value_count\": 86, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 86.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06690835952758789, \"percentile_inc_nulls\": 0.1502036452293396, \"value_count\": 81, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 162.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06521505117416382, \"percentile_inc_nulls\": 0.14866149425506592, \"value_count\": 78, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 78.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06356513500213623, \"percentile_inc_nulls\": 0.14715886116027832, \"value_count\": 76, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 76.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06202375888824463, \"percentile_inc_nulls\": 0.14575505256652832, \"value_count\": 71, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 71.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.06052577495574951, \"percentile_inc_nulls\": 0.14439082145690918, \"value_count\": 69, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 69.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.05761677026748657, \"percentile_inc_nulls\": 0.14174145460128784, \"value_count\": 67, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 134.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0562056303024292, \"percentile_inc_nulls\": 0.14045631885528564, \"value_count\": 65, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 65.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.054816246032714844, \"percentile_inc_nulls\": 0.13919097185134888, \"value_count\": 64, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 64.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.05344855785369873, \"percentile_inc_nulls\": 0.13794535398483276, \"value_count\": 63, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 63.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.05210256576538086, \"percentile_inc_nulls\": 0.13671952486038208, \"value_count\": 62, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04949742555618286, \"percentile_inc_nulls\": 0.13434696197509766, \"value_count\": 60, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 120.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04821658134460449, \"percentile_inc_nulls\": 0.1331804394721985, \"value_count\": 59, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 59.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04702258110046387, \"percentile_inc_nulls\": 0.13209301233291626, \"value_count\": 55, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 55.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04595881700515747, \"percentile_inc_nulls\": 0.13112419843673706, \"value_count\": 49, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 49.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.04493844509124756, \"percentile_inc_nulls\": 0.13019496202468872, \"value_count\": 47, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 47.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.043939828872680664, \"percentile_inc_nulls\": 0.12928545475006104, \"value_count\": 46, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 46.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.042984604835510254, \"percentile_inc_nulls\": 0.1284155249595642, \"value_count\": 44, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 44.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.042051076889038086, \"percentile_inc_nulls\": 0.12756532430648804, \"value_count\": 43, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 43.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.040227532386779785, \"percentile_inc_nulls\": 0.12590456008911133, \"value_count\": 42, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 84.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03933745622634888, \"percentile_inc_nulls\": 0.12509393692016602, \"value_count\": 41, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 41.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03846907615661621, \"percentile_inc_nulls\": 0.12430304288864136, \"value_count\": 40, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 40.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03764408826828003, \"percentile_inc_nulls\": 0.12355172634124756, \"value_count\": 38, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 38.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0329548716545105, \"percentile_inc_nulls\": 0.1192811131477356, \"value_count\": 36, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 216.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03221672773361206, \"percentile_inc_nulls\": 0.11860889196395874, \"value_count\": 34, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 34.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03150033950805664, \"percentile_inc_nulls\": 0.11795639991760254, \"value_count\": 33, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 33.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.03015434741973877, \"percentile_inc_nulls\": 0.11673057079315186, \"value_count\": 31, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 62.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.028851807117462158, \"percentile_inc_nulls\": 0.11554431915283203, \"value_count\": 30, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 60.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02759265899658203, \"percentile_inc_nulls\": 0.11439758539199829, \"value_count\": 29, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 58.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.026984810829162598, \"percentile_inc_nulls\": 0.11384397745132446, \"value_count\": 28, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02581244707107544, \"percentile_inc_nulls\": 0.11277627944946289, \"value_count\": 27, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.024683594703674316, \"percentile_inc_nulls\": 0.11174821853637695, \"value_count\": 26, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 52.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02414083480834961, \"percentile_inc_nulls\": 0.11125391721725464, \"value_count\": 25, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 25.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02361983060836792, \"percentile_inc_nulls\": 0.11077940464019775, \"value_count\": 24, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 24.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.023120522499084473, \"percentile_inc_nulls\": 0.11032462120056152, \"value_count\": 23, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 23.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.02266460657119751, \"percentile_inc_nulls\": 0.10990947484970093, \"value_count\": 21, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 21.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.022230446338653564, \"percentile_inc_nulls\": 0.10951399803161621, \"value_count\": 20, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 20.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.020580530166625977, \"percentile_inc_nulls\": 0.10801136493682861, \"value_count\": 19, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 76.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.019408226013183594, \"percentile_inc_nulls\": 0.10694372653961182, \"value_count\": 18, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 54.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.019039154052734375, \"percentile_inc_nulls\": 0.10660761594772339, \"value_count\": 17, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 17.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.01799708604812622, \"percentile_inc_nulls\": 0.10565859079360962, \"value_count\": 16, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 48.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.01702016592025757, \"percentile_inc_nulls\": 0.10476887226104736, \"value_count\": 15, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 45.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.016412317752838135, \"percentile_inc_nulls\": 0.10421526432037354, \"value_count\": 14, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 28.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.015565633773803711, \"percentile_inc_nulls\": 0.1034441590309143, \"value_count\": 13, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 39.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.014784097671508789, \"percentile_inc_nulls\": 0.10273241996765137, \"value_count\": 12, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 36.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.014545321464538574, \"percentile_inc_nulls\": 0.10251492261886597, \"value_count\": 11, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 11.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.014111101627349854, \"percentile_inc_nulls\": 0.10211950540542603, \"value_count\": 10, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 20.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.013524949550628662, \"percentile_inc_nulls\": 0.10158568620681763, \"value_count\": 9, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 27.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.011961877346038818, \"percentile_inc_nulls\": 0.10016214847564697, \"value_count\": 8, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 72.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.010594189167022705, \"percentile_inc_nulls\": 0.09891653060913086, \"value_count\": 7, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 63.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.010333657264709473, \"percentile_inc_nulls\": 0.09867924451828003, \"value_count\": 6, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 12.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.008488357067108154, \"percentile_inc_nulls\": 0.09699869155883789, \"value_count\": 5, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 85.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.006751596927642822, \"percentile_inc_nulls\": 0.09541696310043335, \"value_count\": 4, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 80.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.004797756671905518, \"percentile_inc_nulls\": 0.09363752603530884, \"value_count\": 3, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 90.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0024966001510620117, \"percentile_inc_nulls\": 0.09154176712036133, \"value_count\": 2, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 106.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 0.0, \"percentile_inc_nulls\": 0.08926808834075928, \"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 115.0, \"distinct_value_count\": 447}, {\"percentile_ex_nulls\": 1.0, \"percentile_inc_nulls\": 1.0, \"value_count\": 1748, \"group_name\": \"substr_surname_1_2_\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"sum_tokens_in_value_count_group\": 1748.0, \"distinct_value_count\": 447}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"percentile_ex_nulls\", \"type\": \"quantitative\"}, {\"field\": \"percentile_inc_nulls\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"percentile_ex_nulls\", \"sort\": \"descending\", \"title\": \"Percentile\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Count of values\", \"type\": \"quantitative\"}}, \"title\": {\"text\": \"Distribution of counts of values in column substr(surname,1,2)\", \"subtitle\": \"In this col, 4,515 values (8.9%) are null and there are 447 distinct values\"}}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1748, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ba\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1605, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ma\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1503, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ha\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1237, \"group_name\": \"substr_surname_1_2_\", \"value\": \"st\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1222, \"group_name\": \"substr_surname_1_2_\", \"value\": \"br\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 976, \"group_name\": \"substr_surname_1_2_\", \"value\": \"co\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 974, \"group_name\": \"substr_surname_1_2_\", \"value\": \"be\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 950, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ro\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 925, \"group_name\": \"substr_surname_1_2_\", \"value\": \"wa\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 827, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ca\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Top 10 values by value count\"}, {\"mark\": \"bar\", \"data\": {\"values\": [{\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"lq\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ue\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"1u\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"g2\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"w4\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"cp\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"hj\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"ih\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"fz\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}, {\"value_count\": 1, \"group_name\": \"substr_surname_1_2_\", \"value\": \"wj\", \"total_non_null_rows\": 46063, \"total_rows_inc_nulls\": 50578, \"distinct_value_count\": 447}]}, \"encoding\": {\"tooltip\": [{\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"value_count\", \"type\": \"quantitative\"}, {\"field\": \"total_non_null_rows\", \"type\": \"quantitative\"}, {\"field\": \"total_rows_inc_nulls\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"value\", \"sort\": \"-y\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"value_count\", \"scale\": {\"domain\": [0, 1748]}, \"title\": \"Value count\", \"type\": \"quantitative\"}}, \"title\": \"Bottom 10 values by value count\"}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import DuckDBAPI\n",
    "from splink.exploratory import profile_columns\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "profile_columns(df, db_api, column_expressions=[\"first_name\", \"substr(surname,1,2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:28.898009Z",
     "iopub.status.busy": "2024-06-07T09:09:28.897643Z",
     "iopub.status.idle": "2024-06-07T09:09:29.356811Z",
     "shell.execute_reply": "2024-06-07T09:09:29.356107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e46490fce23e4ef2b152e2a8990fbed1.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e46490fce23e4ef2b152e2a8990fbed1.vega-embed details,\n",
       "  #altair-viz-e46490fce23e4ef2b152e2a8990fbed1.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e46490fce23e4ef2b152e2a8990fbed1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e46490fce23e4ef2b152e2a8990fbed1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e46490fce23e4ef2b152e2a8990fbed1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-8232b7c328acd1a8eec0ecfe8a013878\"}, \"mark\": \"bar\", \"encoding\": {\"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"blocking_rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Total comparisons in Cartesian product\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"blocking_rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-8232b7c328acd1a8eec0ecfe8a013878\": [{\"blocking_rule\": \"(l.\\\"first_name\\\" = r.\\\"first_name\\\") AND (l.\\\"surname\\\" = r.\\\"surname\\\")\", \"row_count\": 243656, \"cumulative_rows\": 243656, \"cartesian\": 1279041753, \"match_key\": \"0\", \"start\": 0}, {\"blocking_rule\": \"(l.\\\"surname\\\" = r.\\\"surname\\\") AND (l.\\\"dob\\\" = r.\\\"dob\\\")\", \"row_count\": 25041, \"cumulative_rows\": 268697, \"cartesian\": 1279041753, \"match_key\": \"1\", \"start\": 243656}, {\"blocking_rule\": \"(l.\\\"first_name\\\" = r.\\\"first_name\\\") AND (l.\\\"dob\\\" = r.\\\"dob\\\")\", \"row_count\": 29905, \"cumulative_rows\": 298602, \"cartesian\": 1279041753, \"match_key\": \"2\", \"start\": 268697}, {\"blocking_rule\": \"(l.\\\"postcode_fake\\\" = r.\\\"postcode_fake\\\") AND (l.\\\"first_name\\\" = r.\\\"first_name\\\")\", \"row_count\": 8421, \"cumulative_rows\": 307023, \"cartesian\": 1279041753, \"match_key\": \"3\", \"start\": 298602}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splink import DuckDBAPI, block_on\n",
    "from splink.blocking_analysis import (\n",
    "    cumulative_comparisons_to_be_scored_from_blocking_rules_chart,\n",
    ")\n",
    "\n",
    "blocking_rules =  [block_on(\"first_name\", \"surname\"),\n",
    "        block_on(\"surname\", \"dob\"),\n",
    "        block_on(\"first_name\", \"dob\"),\n",
    "        block_on(\"postcode_fake\", \"first_name\")]\n",
    "\n",
    "db_api = DuckDBAPI()\n",
    "\n",
    "cumulative_comparisons_to_be_scored_from_blocking_rules_chart(\n",
    "    table_or_tables=df,\n",
    "    blocking_rules=blocking_rules,\n",
    "    db_api=db_api,\n",
    "    link_type=\"dedupe_only\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:29.359888Z",
     "iopub.status.busy": "2024-06-07T09:09:29.359671Z",
     "iopub.status.idle": "2024-06-07T09:09:29.491413Z",
     "shell.execute_reply": "2024-06-07T09:09:29.490645Z"
    }
   },
   "outputs": [],
   "source": [
    "import splink.comparison_library as cl\n",
    "import splink.comparison_template_library as ctl\n",
    "from splink import Linker, SettingsCreator\n",
    "\n",
    "settings = SettingsCreator(\n",
    "    link_type=\"dedupe_only\",\n",
    "    blocking_rules_to_generate_predictions=blocking_rules,\n",
    "    comparisons=[\n",
    "        ctl.NameComparison(\"first_name\").configure(term_frequency_adjustments=True),\n",
    "        ctl.NameComparison(\"surname\").configure(term_frequency_adjustments=True),\n",
    "        ctl.DateComparison(\n",
    "            \"dob\",\n",
    "            input_is_string=True,\n",
    "            datetime_metrics=[\"month\", \"year\", \"year\"],\n",
    "            datetime_thresholds=[1, 1, 10],\n",
    "        ),\n",
    "        # TODO: Restore ctl.PostcodeComparison level here\n",
    "        cl.LevenshteinAtThresholds(\"postcode_fake\"),\n",
    "        cl.ExactMatch(\"birth_place\").configure(term_frequency_adjustments=True),\n",
    "        cl.ExactMatch(\"occupation\").configure(term_frequency_adjustments=True),\n",
    "    ],\n",
    "    retain_intermediate_calculation_columns=True,\n",
    ")\n",
    "\n",
    "linker = Linker(df, settings, database_api=db_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:29.494674Z",
     "iopub.status.busy": "2024-06-07T09:09:29.494441Z",
     "iopub.status.idle": "2024-06-07T09:09:29.778569Z",
     "shell.execute_reply": "2024-06-07T09:09:29.778006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.000136.\n",
      "This means that amongst all possible pairwise record comparisons, one in 7,362.31 are expected to match.  With 1,279,041,753 total possible comparisons, we expect a total of around 173,728.33 matching pairs\n"
     ]
    }
   ],
   "source": [
    "linker.training.estimate_probability_two_random_records_match(\n",
    "    [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname and l.dob = r.dob\",\n",
    "        \"substr(l.first_name,1,2) = substr(r.first_name,1,2) and l.surname = r.surname and substr(l.postcode_fake,1,2) = substr(r.postcode_fake,1,2)\",\n",
    "        \"l.dob = r.dob and l.postcode_fake = r.postcode_fake\",\n",
    "    ],\n",
    "    recall=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:29.781900Z",
     "iopub.status.busy": "2024-06-07T09:09:29.781630Z",
     "iopub.status.idle": "2024-06-07T09:09:37.047025Z",
     "shell.execute_reply": "2024-06-07T09:09:37.046527Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - postcode_fake (no m values are trained).\n",
      "    - birth_place (no m values are trained).\n",
      "    - occupation (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "linker.training.estimate_u_using_random_sampling(max_pairs=5e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:37.049884Z",
     "iopub.status.busy": "2024-06-07T09:09:37.049671Z",
     "iopub.status.idle": "2024-06-07T09:09:40.142517Z",
     "shell.execute_reply": "2024-06-07T09:09:40.141723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "(l.\"first_name\" = r.\"first_name\") AND (l.\"surname\" = r.\"surname\")\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - dob\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - first_name\n",
      "    - surname\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.524 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was -0.0289 in probability_two_random_records_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was -0.0106 in the m_probability of birth_place, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 0.00439 in the m_probability of birth_place, level `Exact match on birth_place`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 5: Largest change in params was -0.00199 in the m_probability of birth_place, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 6: Largest change in params was -0.000951 in the m_probability of birth_place, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 7: Largest change in params was -0.000495 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 8: Largest change in params was -0.000267 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 9: Largest change in params was -0.000144 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10: Largest change in params was -7.75e-05 in the m_probability of dob, level `Abs difference of 'transformed dob <= 10 year'`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 10 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = block_on(\"first_name\", \"surname\")\n",
    "training_session_names = linker.training.estimate_parameters_using_expectation_maximisation(\n",
    "    training_blocking_rule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:40.146047Z",
     "iopub.status.busy": "2024-06-07T09:09:40.145755Z",
     "iopub.status.idle": "2024-06-07T09:09:49.809293Z",
     "shell.execute_reply": "2024-06-07T09:09:49.808482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"dob\" = r.\"dob\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - postcode_fake\n",
      "    - birth_place\n",
      "    - occupation\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1: Largest change in params was -0.362 in the m_probability of first_name, level `Exact match on first_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: Largest change in params was 0.0336 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 3: Largest change in params was 0.00479 in the m_probability of first_name, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 4: Largest change in params was 0.00106 in the m_probability of surname, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 5: Largest change in params was 0.000254 in the m_probability of surname, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 6: Largest change in params was 5.93e-05 in the m_probability of surname, level `All other comparisons`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EM converged after 6 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "training_blocking_rule = block_on(\"dob\")\n",
    "training_session_dob = linker.training.estimate_parameters_using_expectation_maximisation(\n",
    "    training_blocking_rule\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final match weights can be viewed in the match weights chart:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:49.813047Z",
     "iopub.status.busy": "2024-06-07T09:09:49.812768Z",
     "iopub.status.idle": "2024-06-07T09:09:50.107589Z",
     "shell.execute_reply": "2024-06-07T09:09:50.106949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2d8e4c090b4346dea97561b47e263662.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2d8e4c090b4346dea97561b47e263662.vega-embed details,\n",
       "  #altair-viz-2d8e4c090b4346dea97561b47e263662.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2d8e4c090b4346dea97561b47e263662\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2d8e4c090b4346dea97561b47e263662\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2d8e4c090b4346dea97561b47e263662\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"discreteHeight\": 60, \"discreteWidth\": 400}, \"header\": {\"title\": null}, \"mark\": {\"tooltip\": null}, \"title\": {\"anchor\": \"middle\"}}, \"vconcat\": [{\"mark\": {\"type\": \"bar\", \"clip\": true, \"height\": 15}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"probability_two_random_records_match\", \"format\": \".4f\", \"title\": \"Probability two random records match\", \"type\": \"nominal\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Equivalent match weight\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"domain\": false, \"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"labels\": false, \"ticks\": false, \"title\": \"\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-13, 13]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"Prior (starting) match weight\", \"titleAlign\": \"right\", \"titleAngle\": 0, \"titleFontWeight\": \"normal\"}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": 20, \"transform\": [{\"filter\": \"(datum.comparison_name == 'probability_two_random_records_match')\"}]}, {\"mark\": {\"type\": \"bar\", \"clip\": true}, \"encoding\": {\"color\": {\"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-10, 0, 10], \"interpolate\": \"lab\", \"range\": [\"red\", \"#bbbbbb\", \"green\"]}, \"title\": \"Match weight\", \"type\": \"quantitative\"}, \"row\": {\"field\": \"comparison_name\", \"header\": {\"labelAlign\": \"left\", \"labelAnchor\": \"middle\", \"labelAngle\": 0}, \"sort\": {\"field\": \"comparison_sort_order\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"comparison_name\", \"title\": \"Comparison name\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"m_probability\", \"format\": \".4f\", \"title\": \"M probability\", \"type\": \"quantitative\"}, {\"field\": \"u_probability\", \"format\": \".4f\", \"title\": \"U probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"gridColor\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": \"#aaa\"}, \"value\": \"#ddd\"}, \"gridDash\": {\"condition\": {\"test\": \"abs(datum.value / 10) == 1\", \"value\": [3]}, \"value\": null}, \"gridWidth\": {\"condition\": {\"test\": \"abs(datum.value / 10)  <= 1 & datum.value % 10 === 0\", \"value\": 2}, \"value\": 1}, \"title\": \"Comparison level match weight = log2(m/u)\"}, \"field\": \"log2_bayes_factor\", \"scale\": {\"domain\": [-13, 13]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"label_for_charts\", \"sort\": {\"field\": \"comparison_vector_value\", \"order\": \"descending\"}, \"type\": \"nominal\"}}, \"height\": {\"step\": 12}, \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"transform\": [{\"filter\": \"(datum.comparison_name != 'probability_two_random_records_match')\"}]}], \"data\": {\"name\": \"data-ee38336011b9aae33928863d7db1af20\"}, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\", \"views\": []}], \"resolve\": {\"axis\": {\"y\": \"independent\"}, \"scale\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Model parameters (components of final match weight)\", \"subtitle\": \"Use mousewheel to zoom\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-ee38336011b9aae33928863d7db1af20\": [{\"comparison_name\": \"probability_two_random_records_match\", \"sql_condition\": null, \"label_for_charts\": \"\", \"m_probability\": null, \"u_probability\": null, \"m_probability_description\": null, \"u_probability_description\": null, \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": null, \"is_null_level\": false, \"bayes_factor\": 0.00013584539607096294, \"log2_bayes_factor\": -12.845746707461347, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 0, \"bayes_factor_description\": \"The probability that two random records drawn at random match is 0.000 or one in  7,362.3 records.This is equivalent to a starting match weight of -12.846.\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": -1}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"m_probability_description\": \"Amongst matching record comparisons, 55.21% of records are in the exact match on first_name comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.44% of records are in the exact match on first_name comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"first_name\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"m_probability_description\": \"Amongst matching record comparisons, 10.03% of records are in the jaro-winkler distance of first_name >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.42% of records are in the jaro-winkler distance of first_name >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 24.043155919777696, \"log2_bayes_factor\": 4.587554372424933, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.8\", \"m_probability\": 0.1132162061724462, \"u_probability\": 0.0068287063122285455, \"m_probability_description\": \"Amongst matching record comparisons, 11.32% of records are in the jaro-winkler distance of first_name >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.68% of records are in the jaro-winkler distance of first_name >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 16.579451655389487, \"log2_bayes_factor\": 4.051324387177457, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.8` then comparison is 16.58 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"first_name\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"m_probability_description\": \"Amongst matching record comparisons, 23.43% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 97.46% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 0}, {\"comparison_name\": \"surname\", \"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"m_probability_description\": \"Amongst matching record comparisons, 78.09% of records are in the exact match on surname comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.07% of records are in the exact match on surname comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"surname\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.9\", \"m_probability\": 0.1174336825526478, \"u_probability\": 0.0005097048087257963, \"m_probability_description\": \"Amongst matching record comparisons, 11.74% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the jaro-winkler distance of surname >= 0.9 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 230.3954770334982, \"log2_bayes_factor\": 7.84796858483016, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.9` then comparison is 230.40 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"jaro_winkler_similarity(\\\"surname_l\\\", \\\"surname_r\\\") >= 0.8\", \"label_for_charts\": \"Jaro-Winkler distance of surname >= 0.8\", \"m_probability\": 0.03471869144456838, \"u_probability\": 0.0031505931000017987, \"m_probability_description\": \"Amongst matching record comparisons, 3.47% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.32% of records are in the jaro-winkler distance of surname >= 0.8 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 11.019731949691808, \"log2_bayes_factor\": 3.462017226277954, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of surname >= 0.8` then comparison is 11.02 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"surname\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"m_probability_description\": \"Amongst matching record comparisons, 6.69% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.56% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 1}, {\"comparison_name\": \"dob\", \"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"m_probability_description\": \"Amongst matching record comparisons, 61.38% of records are in the exact match on dob comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.19% of records are in the exact match on dob comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"m_probability_description\": \"Amongst matching record comparisons, 33.97% of records are in the damerau-levenshtein distance of dob <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 1.92% of records are in the damerau-levenshtein distance of dob <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 2629800.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 1 month'\", \"m_probability\": 0.00230528835734623, \"u_probability\": 0.0019631384255954314, \"m_probability_description\": \"Amongst matching record comparisons, 0.23% of records are in the abs difference of 'transformed dob <= 1 month' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.20% of records are in the abs difference of 'transformed dob <= 1 month' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1.1742872164743157, \"log2_bayes_factor\": 0.2317853173956578, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 1 month'` then comparison is 1.17 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 31557600.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 1 year'\", \"m_probability\": 0.004710483499763359, \"u_probability\": 0.02643442955415666, \"m_probability_description\": \"Amongst matching record comparisons, 0.47% of records are in the abs difference of 'transformed dob <= 1 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 2.64% of records are in the abs difference of 'transformed dob <= 1 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.1781950123082063, \"log2_bayes_factor\": -2.4884711386050786, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 1 year'` then comparison is  5.61 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.013464734404494298, \"u_probability\": 0.20047773757760617, \"m_probability_description\": \"Amongst matching record comparisons, 1.35% of records are in the abs difference of 'transformed dob <= 10 year' comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 20.05% of records are in the abs difference of 'transformed dob <= 10 year' comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.0671632400045517, \"log2_bayes_factor\": -3.896184361141375, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  14.89 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"dob\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"m_probability_description\": \"Amongst matching record comparisons, 2.61% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 75.00% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 2}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"m_probability_description\": \"Amongst matching record comparisons, 68.71% of records are in the exact match on postcode_fake comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the exact match on postcode_fake comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 1\", \"label_for_charts\": \"Levenshtein distance of postcode_fake <= 1\", \"m_probability\": 0.08641184751415396, \"u_probability\": 8.199956967167982e-05, \"m_probability_description\": \"Amongst matching record comparisons, 8.64% of records are in the levenshtein distance of postcode_fake <= 1 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.01% of records are in the levenshtein distance of postcode_fake <= 1 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 1053.8085487538601, \"log2_bayes_factor\": 10.041397073030216, \"comparison_vector_value\": 2, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of postcode_fake <= 1` then comparison is 1,053.81 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein distance of postcode_fake <= 2\", \"m_probability\": 0.056075932948771445, \"u_probability\": 0.0005255426965321298, \"m_probability_description\": \"Amongst matching record comparisons, 5.61% of records are in the levenshtein distance of postcode_fake <= 2 comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.05% of records are in the levenshtein distance of postcode_fake <= 2 comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 106.70100320829626, \"log2_bayes_factor\": 6.737429930293483, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of postcode_fake <= 2` then comparison is 106.70 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"postcode_fake\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"m_probability_description\": \"Amongst matching record comparisons, 17.05% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.92% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 3}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"m_probability_description\": \"Amongst matching record comparisons, 84.38% of records are in the exact match on birth_place comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 0.54% of records are in the exact match on birth_place comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"birth_place\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 4}, {\"comparison_name\": \"birth_place\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"m_probability_description\": \"Amongst matching record comparisons, 15.62% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 99.46% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 4}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"m_probability_description\": \"Amongst matching record comparisons, 89.88% of records are in the exact match on occupation comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 3.67% of records are in the exact match on occupation comparison level\", \"has_tf_adjustments\": true, \"tf_adjustment_column\": \"occupation\", \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 5}, {\"comparison_name\": \"occupation\", \"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"m_probability_description\": \"Amongst matching record comparisons, 10.12% of records are in the all other comparisons comparison level\", \"u_probability_description\": \"Amongst non-matching record comparisons, 96.33% of records are in the all other comparisons comparison level\", \"has_tf_adjustments\": false, \"tf_adjustment_column\": null, \"tf_adjustment_weight\": 1.0, \"is_null_level\": false, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"max_comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"probability_two_random_records_match\": 0.00013582694460587586, \"comparison_sort_order\": 5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.visualisations.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:50.110966Z",
     "iopub.status.busy": "2024-06-07T09:09:50.110700Z",
     "iopub.status.idle": "2024-06-07T09:09:52.080683Z",
     "shell.execute_reply": "2024-06-07T09:09:52.080017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a01a24c47dd94853a01167d1e29c13ab.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a01a24c47dd94853a01167d1e29c13ab.vega-embed details,\n",
       "  #altair-viz-a01a24c47dd94853a01167d1e29c13ab.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a01a24c47dd94853a01167d1e29c13ab\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a01a24c47dd94853a01167d1e29c13ab\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a01a24c47dd94853a01167d1e29c13ab\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"axis\": {\"format\": \"+\", \"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"point\"}, \"encoding\": {\"opacity\": {\"condition\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"value\": 1, \"empty\": false}, \"value\": 0}, \"tooltip\": [{\"field\": \"match_weight\", \"format\": \"+.5\", \"title\": \"Match weight\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".5\", \"title\": \"Match probability\", \"type\": \"quantitative\"}, {\"field\": \"cum_prop\", \"format\": \".3%\", \"title\": \"Proportion of unlinkable records\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"title\": \"Threshold match weight\"}, \"field\": \"match_weight\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"format\": \"%\", \"title\": \"Percentage of unlinkable records\"}, \"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"name\": \"mouse_coords\"}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"x\": {\"field\": \"match_weight\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"y\": {\"field\": \"cum_prop\", \"type\": \"quantitative\"}}, \"transform\": [{\"filter\": {\"param\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"empty\": false}}]}], \"data\": {\"name\": \"data-4517b1e6af198da890cf5e3cbf5f5470\"}, \"height\": 400, \"params\": [{\"name\": \"x_match_weight_y_cum_prop_coords_of_mouse\", \"select\": {\"type\": \"point\", \"fields\": [\"match_weight\", \"cum_prop\"], \"nearest\": true, \"on\": \"mouseover\"}, \"views\": [\"mouse_coords\"]}], \"title\": {\"text\": \"Unlinkable records\", \"subtitle\": \"Records with insufficient information to exceed a given match threshold\"}, \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-4517b1e6af198da890cf5e3cbf5f5470\": [{\"match_weight\": -12.85, \"match_probability\": 0.00014, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 3.9542883314425126e-05}, {\"match_weight\": -9.5, \"match_probability\": 0.00138, \"prop\": 5.931432679062709e-05, \"cum_prop\": 9.885721010505222e-05}, {\"match_weight\": -8.43, \"match_probability\": 0.00289, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00011862865176226478}, {\"match_weight\": -8.38, \"match_probability\": 0.00299, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00013840009341947734}, {\"match_weight\": -7.87, \"match_probability\": 0.00427, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0001581715350766899}, {\"match_weight\": -7.73, \"match_probability\": 0.00468, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00017794297673390247}, {\"match_weight\": -7.43, \"match_probability\": 0.00576, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00019771441839111503}, {\"match_weight\": -7.08, \"match_probability\": 0.00736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0002174858600483276}, {\"match_weight\": -7.04, \"match_probability\": 0.00755, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00023725730170554016}, {\"match_weight\": -6.94, \"match_probability\": 0.0081, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0002768001850199653}, {\"match_weight\": -6.61, \"match_probability\": 0.01016, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00029657162667717785}, {\"match_weight\": -6.53, \"match_probability\": 0.01074, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0003163430683343904}, {\"match_weight\": -6.3, \"match_probability\": 0.01251, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00033611450999160297}, {\"match_weight\": -6.24, \"match_probability\": 0.01303, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00035588595164881554}, {\"match_weight\": -6.2, \"match_probability\": 0.01344, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0003756573933060281}, {\"match_weight\": -5.51, \"match_probability\": 0.02143, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00039542883496324066}, {\"match_weight\": -5.36, \"match_probability\": 0.02371, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0004152002766204532}, {\"match_weight\": -5.29, \"match_probability\": 0.02487, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0004349717182776658}, {\"match_weight\": -5.16, \"match_probability\": 0.0273, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00045474315993487835}, {\"match_weight\": -5.07, \"match_probability\": 0.02897, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0004745146015920909}, {\"match_weight\": -4.99, \"match_probability\": 0.03061, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.000533828928382718}, {\"match_weight\": -4.92, \"match_probability\": 0.03189, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0005536003700399306}, {\"match_weight\": -4.91, \"match_probability\": 0.03216, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0005733718116971431}, {\"match_weight\": -4.72, \"match_probability\": 0.0365, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0005931432533543557}, {\"match_weight\": -4.72, \"match_probability\": 0.03652, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006129146950115683}, {\"match_weight\": -4.67, \"match_probability\": 0.03791, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006326861366687808}, {\"match_weight\": -4.66, \"match_probability\": 0.03797, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006524575783259934}, {\"match_weight\": -4.6, \"match_probability\": 0.03955, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006722290199832059}, {\"match_weight\": -4.57, \"match_probability\": 0.04035, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0006920004616404185}, {\"match_weight\": -4.5, \"match_probability\": 0.04223, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.0007710862282692688}, {\"match_weight\": -4.44, \"match_probability\": 0.04416, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0007908576699264813}, {\"match_weight\": -4.32, \"match_probability\": 0.04765, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0008106291115836939}, {\"match_weight\": -4.25, \"match_probability\": 0.04999, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.000850171994898119}, {\"match_weight\": -4.15, \"match_probability\": 0.05323, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0008699434365553316}, {\"match_weight\": -3.92, \"match_probability\": 0.06203, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0008897148782125441}, {\"match_weight\": -3.81, \"match_probability\": 0.06671, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0009292577615269693}, {\"match_weight\": -3.7, \"match_probability\": 0.07148, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0009490292031841818}, {\"match_weight\": -3.66, \"match_probability\": 0.07316, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0009688006448413944}, {\"match_weight\": -3.4, \"match_probability\": 0.08652, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0010083435281558195}, {\"match_weight\": -3.32, \"match_probability\": 0.09084, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001028114969813032}, {\"match_weight\": -3.22, \"match_probability\": 0.09675, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0010478864114702446}, {\"match_weight\": -3.02, \"match_probability\": 0.10992, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0010676578531274572}, {\"match_weight\": -2.96, \"match_probability\": 0.11377, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0010874292947846698}, {\"match_weight\": -2.94, \"match_probability\": 0.11555, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0011269721780990949}, {\"match_weight\": -2.72, \"match_probability\": 0.1316, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0011467436197563075}, {\"match_weight\": -2.63, \"match_probability\": 0.13898, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00116651506141352}, {\"match_weight\": -2.51, \"match_probability\": 0.14936, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0012060579447279451}, {\"match_weight\": -2.4, \"match_probability\": 0.15948, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0012258293863851577}, {\"match_weight\": -2.32, \"match_probability\": 0.16652, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0012456008280423703}, {\"match_weight\": -1.99, \"match_probability\": 0.20084, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0012653722696995828}, {\"match_weight\": -1.99, \"match_probability\": 0.20164, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.00132468659649021}, {\"match_weight\": -1.83, \"match_probability\": 0.21944, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0013444580381474225}, {\"match_weight\": -1.78, \"match_probability\": 0.22567, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0013840009214618476}, {\"match_weight\": -1.76, \"match_probability\": 0.22797, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0014235438047762727}, {\"match_weight\": -1.66, \"match_probability\": 0.23996, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0014433152464334853}, {\"match_weight\": -1.53, \"match_probability\": 0.25783, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0014630866880906979}, {\"match_weight\": -1.48, \"match_probability\": 0.2633, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0014828581297479104}, {\"match_weight\": -1.28, \"match_probability\": 0.29202, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001502629571405123}, {\"match_weight\": -1.26, \"match_probability\": 0.29427, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0015224010130623356}, {\"match_weight\": -1.25, \"match_probability\": 0.29625, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0015421724547195481}, {\"match_weight\": -1.24, \"match_probability\": 0.29706, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0015619438963767607}, {\"match_weight\": -1.16, \"match_probability\": 0.30861, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0015817153380339732}, {\"match_weight\": -1.15, \"match_probability\": 0.31006, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.0016805725517770043}, {\"match_weight\": -1.14, \"match_probability\": 0.31217, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017003439934342168}, {\"match_weight\": -1.08, \"match_probability\": 0.32138, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017201154350914294}, {\"match_weight\": -0.96, \"match_probability\": 0.33961, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001739886876748642}, {\"match_weight\": -0.9, \"match_probability\": 0.34836, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017596583184058545}, {\"match_weight\": -0.89, \"match_probability\": 0.35117, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001779429760063067}, {\"match_weight\": -0.88, \"match_probability\": 0.35254, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0017992012017202796}, {\"match_weight\": -0.86, \"match_probability\": 0.35541, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018189726433774922}, {\"match_weight\": -0.82, \"match_probability\": 0.36144, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018387440850347048}, {\"match_weight\": -0.75, \"match_probability\": 0.3725, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018585155266919173}, {\"match_weight\": -0.71, \"match_probability\": 0.37872, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00187828696834913}, {\"match_weight\": -0.7, \"match_probability\": 0.38183, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0018980584100063425}, {\"match_weight\": -0.66, \"match_probability\": 0.38704, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.001917829851663555}, {\"match_weight\": -0.64, \"match_probability\": 0.39101, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00195737273497798}, {\"match_weight\": -0.62, \"match_probability\": 0.39465, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0019771441766351927}, {\"match_weight\": -0.61, \"match_probability\": 0.39513, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0019969156182924053}, {\"match_weight\": -0.55, \"match_probability\": 0.4051, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002016687059949618}, {\"match_weight\": -0.5, \"match_probability\": 0.41418, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0020364585016068304}, {\"match_weight\": -0.45, \"match_probability\": 0.42294, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002056229943264043}, {\"match_weight\": -0.41, \"match_probability\": 0.4302, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0020760013849212555}, {\"match_weight\": -0.31, \"match_probability\": 0.44731, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002095772826578468}, {\"match_weight\": -0.28, \"match_probability\": 0.45167, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0021155442682356806}, {\"match_weight\": -0.28, \"match_probability\": 0.45223, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002135315709892893}, {\"match_weight\": -0.24, \"match_probability\": 0.45921, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.0022144014765217435}, {\"match_weight\": -0.2, \"match_probability\": 0.46494, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002234172918178956}, {\"match_weight\": -0.19, \"match_probability\": 0.46677, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0022539443598361686}, {\"match_weight\": -0.17, \"match_probability\": 0.47075, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002273715801493381}, {\"match_weight\": -0.14, \"match_probability\": 0.47545, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0022934872431505937}, {\"match_weight\": -0.12, \"match_probability\": 0.47938, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0023132586848078063}, {\"match_weight\": -0.08, \"match_probability\": 0.48643, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002333030126465019}, {\"match_weight\": -0.04, \"match_probability\": 0.49242, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0023528015681222314}, {\"match_weight\": 0.02, \"match_probability\": 0.50277, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002372573009779444}, {\"match_weight\": 0.02, \"match_probability\": 0.5041, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0023923444514366565}, {\"match_weight\": 0.04, \"match_probability\": 0.50777, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002412115893093869}, {\"match_weight\": 0.25, \"match_probability\": 0.54243, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0024318873347510817}, {\"match_weight\": 0.25, \"match_probability\": 0.54253, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002451658776408294}, {\"match_weight\": 0.33, \"match_probability\": 0.55692, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0024714302180655068}, {\"match_weight\": 0.34, \"match_probability\": 0.55808, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.002530744544856134}, {\"match_weight\": 0.35, \"match_probability\": 0.56087, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0025505159865133464}, {\"match_weight\": 0.43, \"match_probability\": 0.57441, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002570287428170559}, {\"match_weight\": 0.48, \"match_probability\": 0.58175, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0025900588698277716}, {\"match_weight\": 0.48, \"match_probability\": 0.5826, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002609830311484984}, {\"match_weight\": 0.53, \"match_probability\": 0.59047, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0026493731947994092}, {\"match_weight\": 0.54, \"match_probability\": 0.5928, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002669144636456622}, {\"match_weight\": 0.58, \"match_probability\": 0.59928, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0026889160781138344}, {\"match_weight\": 0.63, \"match_probability\": 0.6069, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002708687519771047}, {\"match_weight\": 0.63, \"match_probability\": 0.60717, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0027284589614282595}, {\"match_weight\": 0.65, \"match_probability\": 0.61154, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002748230403085472}, {\"match_weight\": 0.69, \"match_probability\": 0.61726, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0027680018447426846}, {\"match_weight\": 0.71, \"match_probability\": 0.62035, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.002787773286399897}, {\"match_weight\": 0.74, \"match_probability\": 0.62517, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0028075447280571098}, {\"match_weight\": 0.78, \"match_probability\": 0.63248, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0028273161697143223}, {\"match_weight\": 0.83, \"match_probability\": 0.63959, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0028668590530287474}, {\"match_weight\": 0.91, \"match_probability\": 0.65279, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00288663049468596}, {\"match_weight\": 0.92, \"match_probability\": 0.6545, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.0031634306815249147}, {\"match_weight\": 0.95, \"match_probability\": 0.65887, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0031832021231821273}, {\"match_weight\": 0.97, \"match_probability\": 0.66264, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00320297356483934}, {\"match_weight\": 1.02, \"match_probability\": 0.66904, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0032227450064965524}, {\"match_weight\": 1.07, \"match_probability\": 0.67811, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003242516448153765}, {\"match_weight\": 1.08, \"match_probability\": 0.6788, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0032622878898109775}, {\"match_weight\": 1.09, \"match_probability\": 0.68065, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00328205933146819}, {\"match_weight\": 1.11, \"match_probability\": 0.68411, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0033018307731254026}, {\"match_weight\": 1.12, \"match_probability\": 0.68485, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003321602214782615}, {\"match_weight\": 1.12, \"match_probability\": 0.68493, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0033611450980970403}, {\"match_weight\": 1.15, \"match_probability\": 0.69001, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003380916539754253}, {\"match_weight\": 1.16, \"match_probability\": 0.69149, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034006879814114654}, {\"match_weight\": 1.19, \"match_probability\": 0.69579, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003420459423068678}, {\"match_weight\": 1.23, \"match_probability\": 0.70127, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034402308647258906}, {\"match_weight\": 1.23, \"match_probability\": 0.70141, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003460002306383103}, {\"match_weight\": 1.26, \"match_probability\": 0.70505, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034797737480403157}, {\"match_weight\": 1.27, \"match_probability\": 0.70664, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0034995451896975283}, {\"match_weight\": 1.27, \"match_probability\": 0.70723, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0035390880730119534}, {\"match_weight\": 1.28, \"match_probability\": 0.70899, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003558859514669166}, {\"match_weight\": 1.29, \"match_probability\": 0.70928, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0035786309563263785}, {\"match_weight\": 1.3, \"match_probability\": 0.71173, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003598402397983591}, {\"match_weight\": 1.37, \"match_probability\": 0.72061, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0036181738396408036}, {\"match_weight\": 1.4, \"match_probability\": 0.72559, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0036577167229552288}, {\"match_weight\": 1.43, \"match_probability\": 0.72892, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0036774881646124413}, {\"match_weight\": 1.47, \"match_probability\": 0.73476, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003697259606269654}, {\"match_weight\": 1.48, \"match_probability\": 0.73582, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0037170310479268664}, {\"match_weight\": 1.5, \"match_probability\": 0.73839, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003736802489584079}, {\"match_weight\": 1.5, \"match_probability\": 0.73908, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0037565739312412916}, {\"match_weight\": 1.51, \"match_probability\": 0.74039, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003776345372898504}, {\"match_weight\": 1.52, \"match_probability\": 0.74089, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0037961168145557167}, {\"match_weight\": 1.52, \"match_probability\": 0.74184, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0038158882562129293}, {\"match_weight\": 1.52, \"match_probability\": 0.74205, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003835659697870142}, {\"match_weight\": 1.53, \"match_probability\": 0.74251, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0038554311395273544}, {\"match_weight\": 1.55, \"match_probability\": 0.74555, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003875202581184567}, {\"match_weight\": 1.57, \"match_probability\": 0.7482, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0038949740228417795}, {\"match_weight\": 1.58, \"match_probability\": 0.74953, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.003914745464498992}, {\"match_weight\": 1.58, \"match_probability\": 0.74998, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.003954288347813417}, {\"match_weight\": 1.6, \"match_probability\": 0.75133, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00397405978947063}, {\"match_weight\": 1.64, \"match_probability\": 0.75687, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.004013602672785055}, {\"match_weight\": 1.65, \"match_probability\": 0.75793, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0040333741144422675}, {\"match_weight\": 1.65, \"match_probability\": 0.75881, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00405314555609948}, {\"match_weight\": 1.7, \"match_probability\": 0.76484, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004072916997756693}, {\"match_weight\": 1.72, \"match_probability\": 0.76665, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.004112459881071118}, {\"match_weight\": 1.78, \"match_probability\": 0.77476, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00413223132272833}, {\"match_weight\": 1.81, \"match_probability\": 0.77866, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004152002764385543}, {\"match_weight\": 1.87, \"match_probability\": 0.78488, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004171774206042755}, {\"match_weight\": 1.87, \"match_probability\": 0.7854, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004191545647699968}, {\"match_weight\": 1.9, \"match_probability\": 0.78884, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0042113170893571805}, {\"match_weight\": 1.91, \"match_probability\": 0.78962, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004231088531014393}, {\"match_weight\": 1.91, \"match_probability\": 0.79039, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.004270631414328818}, {\"match_weight\": 1.92, \"match_probability\": 0.79117, \"prop\": 0.0006920004962012172, \"cum_prop\": 0.004962631910530035}, {\"match_weight\": 1.95, \"match_probability\": 0.7941, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.004982403352187248}, {\"match_weight\": 2.0, \"match_probability\": 0.80029, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0050021747938444605}, {\"match_weight\": 2.02, \"match_probability\": 0.8025, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005021946235501673}, {\"match_weight\": 2.03, \"match_probability\": 0.80335, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005041717677158886}, {\"match_weight\": 2.04, \"match_probability\": 0.80465, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005061489118816098}, {\"match_weight\": 2.09, \"match_probability\": 0.80947, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005081260560473311}, {\"match_weight\": 2.12, \"match_probability\": 0.81325, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005101032002130523}, {\"match_weight\": 2.14, \"match_probability\": 0.8156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005120803443787736}, {\"match_weight\": 2.17, \"match_probability\": 0.81856, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0051405748854449484}, {\"match_weight\": 2.23, \"match_probability\": 0.82427, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005160346327102161}, {\"match_weight\": 2.23, \"match_probability\": 0.82441, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005180117768759374}, {\"match_weight\": 2.25, \"match_probability\": 0.82667, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005199889210416586}, {\"match_weight\": 2.28, \"match_probability\": 0.82879, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005219660652073799}, {\"match_weight\": 2.3, \"match_probability\": 0.83102, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005239432093731011}, {\"match_weight\": 2.3, \"match_probability\": 0.83115, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005259203535388224}, {\"match_weight\": 2.35, \"match_probability\": 0.83608, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005278974977045436}, {\"match_weight\": 2.39, \"match_probability\": 0.83945, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005298746418702649}, {\"match_weight\": 2.39, \"match_probability\": 0.83958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0053185178603598615}, {\"match_weight\": 2.4, \"match_probability\": 0.84069, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005338289302017074}, {\"match_weight\": 2.42, \"match_probability\": 0.8429, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005358060743674287}, {\"match_weight\": 2.43, \"match_probability\": 0.84342, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005377832185331499}, {\"match_weight\": 2.46, \"match_probability\": 0.84577, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005397603626988712}, {\"match_weight\": 2.47, \"match_probability\": 0.84689, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005417375068645924}, {\"match_weight\": 2.47, \"match_probability\": 0.84701, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005437146510303137}, {\"match_weight\": 2.51, \"match_probability\": 0.85077, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0054569179519603495}, {\"match_weight\": 2.55, \"match_probability\": 0.85399, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005476689393617562}, {\"match_weight\": 2.56, \"match_probability\": 0.85538, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005496460835274775}, {\"match_weight\": 2.6, \"match_probability\": 0.85802, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005516232276931987}, {\"match_weight\": 2.61, \"match_probability\": 0.85949, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0055360037185892}, {\"match_weight\": 2.62, \"match_probability\": 0.8597, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005555775160246412}, {\"match_weight\": 2.64, \"match_probability\": 0.86161, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005575546601903625}, {\"match_weight\": 2.64, \"match_probability\": 0.86163, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005595318043560837}, {\"match_weight\": 2.65, \"match_probability\": 0.8626, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00561508948521805}, {\"match_weight\": 2.66, \"match_probability\": 0.86373, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0056348609268752625}, {\"match_weight\": 2.68, \"match_probability\": 0.86487, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005654632368532475}, {\"match_weight\": 2.69, \"match_probability\": 0.86561, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.005713946695323102}, {\"match_weight\": 2.69, \"match_probability\": 0.86606, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005733718136980315}, {\"match_weight\": 2.71, \"match_probability\": 0.86746, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005753489578637527}, {\"match_weight\": 2.71, \"match_probability\": 0.86751, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00577326102029474}, {\"match_weight\": 2.71, \"match_probability\": 0.86758, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005793032461951952}, {\"match_weight\": 2.74, \"match_probability\": 0.86971, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005812803903609165}, {\"match_weight\": 2.74, \"match_probability\": 0.87018, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0058325753452663776}, {\"match_weight\": 2.75, \"match_probability\": 0.8705, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00585234678692359}, {\"match_weight\": 2.76, \"match_probability\": 0.87168, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005872118228580803}, {\"match_weight\": 2.77, \"match_probability\": 0.87203, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005891889670238015}, {\"match_weight\": 2.81, \"match_probability\": 0.87541, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005911661111895228}, {\"match_weight\": 2.84, \"match_probability\": 0.8774, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00593143255355244}, {\"match_weight\": 2.85, \"match_probability\": 0.87804, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005951203995209653}, {\"match_weight\": 2.86, \"match_probability\": 0.87882, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0059709754368668655}, {\"match_weight\": 2.87, \"match_probability\": 0.87932, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.005990746878524078}, {\"match_weight\": 2.89, \"match_probability\": 0.88107, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006010518320181291}, {\"match_weight\": 2.9, \"match_probability\": 0.88184, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006030289761838503}, {\"match_weight\": 2.91, \"match_probability\": 0.8826, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006050061203495716}, {\"match_weight\": 2.91, \"match_probability\": 0.88271, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006069832645152928}, {\"match_weight\": 2.98, \"match_probability\": 0.88738, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006089604086810141}, {\"match_weight\": 2.99, \"match_probability\": 0.88805, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006109375528467353}, {\"match_weight\": 3.0, \"match_probability\": 0.88895, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0061489184117817786}, {\"match_weight\": 3.0, \"match_probability\": 0.88907, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006168689853438991}, {\"match_weight\": 3.02, \"match_probability\": 0.89027, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006188461295096204}, {\"match_weight\": 3.04, \"match_probability\": 0.89165, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006208232736753416}, {\"match_weight\": 3.05, \"match_probability\": 0.89232, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006228004178410629}, {\"match_weight\": 3.09, \"match_probability\": 0.89497, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006247775620067841}, {\"match_weight\": 3.1, \"match_probability\": 0.89535, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006267547061725054}, {\"match_weight\": 3.1, \"match_probability\": 0.89568, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0062873185033822665}, {\"match_weight\": 3.13, \"match_probability\": 0.89749, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006307089945039479}, {\"match_weight\": 3.14, \"match_probability\": 0.89825, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006326861386696692}, {\"match_weight\": 3.14, \"match_probability\": 0.89843, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006346632828353904}, {\"match_weight\": 3.19, \"match_probability\": 0.90107, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006366404270011117}, {\"match_weight\": 3.19, \"match_probability\": 0.90123, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006386175711668329}, {\"match_weight\": 3.19, \"match_probability\": 0.90136, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006405947153325542}, {\"match_weight\": 3.21, \"match_probability\": 0.9027, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0064257185949827544}, {\"match_weight\": 3.22, \"match_probability\": 0.90305, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006445490036639967}, {\"match_weight\": 3.23, \"match_probability\": 0.90395, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0064652614782971796}, {\"match_weight\": 3.26, \"match_probability\": 0.90523, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006485032919954392}, {\"match_weight\": 3.28, \"match_probability\": 0.90637, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006504804361611605}, {\"match_weight\": 3.3, \"match_probability\": 0.90755, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006524575803268817}, {\"match_weight\": 3.31, \"match_probability\": 0.90837, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00654434724492603}, {\"match_weight\": 3.31, \"match_probability\": 0.90848, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006564118686583242}, {\"match_weight\": 3.32, \"match_probability\": 0.90906, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006583890128240455}, {\"match_weight\": 3.34, \"match_probability\": 0.90996, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0066036615698976675}, {\"match_weight\": 3.34, \"match_probability\": 0.91, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00662343301155488}, {\"match_weight\": 3.34, \"match_probability\": 0.91032, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006643204453212093}, {\"match_weight\": 3.35, \"match_probability\": 0.91043, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006662975894869305}, {\"match_weight\": 3.35, \"match_probability\": 0.9106, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006682747336526518}, {\"match_weight\": 3.35, \"match_probability\": 0.91062, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00670251877818373}, {\"match_weight\": 3.38, \"match_probability\": 0.91229, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006722290219840943}, {\"match_weight\": 3.38, \"match_probability\": 0.91243, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.006761833103155368}, {\"match_weight\": 3.38, \"match_probability\": 0.91255, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006781604544812581}, {\"match_weight\": 3.39, \"match_probability\": 0.91307, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006801375986469793}, {\"match_weight\": 3.41, \"match_probability\": 0.91414, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006821147428127006}, {\"match_weight\": 3.42, \"match_probability\": 0.91454, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006840918869784218}, {\"match_weight\": 3.43, \"match_probability\": 0.91524, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006860690311441431}, {\"match_weight\": 3.44, \"match_probability\": 0.91559, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006880461753098643}, {\"match_weight\": 3.46, \"match_probability\": 0.9166, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006900233194755856}, {\"match_weight\": 3.49, \"match_probability\": 0.91851, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0069200046364130685}, {\"match_weight\": 3.53, \"match_probability\": 0.92026, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006939776078070281}, {\"match_weight\": 3.53, \"match_probability\": 0.92031, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006959547519727494}, {\"match_weight\": 3.54, \"match_probability\": 0.9206, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006979318961384706}, {\"match_weight\": 3.58, \"match_probability\": 0.92262, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.006999090403041919}, {\"match_weight\": 3.58, \"match_probability\": 0.92264, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007018861844699131}, {\"match_weight\": 3.59, \"match_probability\": 0.92318, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007038633286356344}, {\"match_weight\": 3.59, \"match_probability\": 0.92319, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0070584047280135565}, {\"match_weight\": 3.59, \"match_probability\": 0.9234, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007078176169670769}, {\"match_weight\": 3.6, \"match_probability\": 0.92406, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007097947611327982}, {\"match_weight\": 3.61, \"match_probability\": 0.92409, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007117719052985194}, {\"match_weight\": 3.62, \"match_probability\": 0.92456, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007137490494642407}, {\"match_weight\": 3.62, \"match_probability\": 0.92457, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007157261936299619}, {\"match_weight\": 3.63, \"match_probability\": 0.92519, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007177033377956832}, {\"match_weight\": 3.64, \"match_probability\": 0.92566, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007196804819614044}, {\"match_weight\": 3.65, \"match_probability\": 0.9262, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007216576261271257}, {\"match_weight\": 3.66, \"match_probability\": 0.92677, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0072363477029284695}, {\"match_weight\": 3.68, \"match_probability\": 0.92758, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007256119144585682}, {\"match_weight\": 3.7, \"match_probability\": 0.92873, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007275890586242895}, {\"match_weight\": 3.71, \"match_probability\": 0.92879, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007295662027900107}, {\"match_weight\": 3.72, \"match_probability\": 0.92965, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00731543346955732}, {\"match_weight\": 3.74, \"match_probability\": 0.93056, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007335204911214532}, {\"match_weight\": 3.76, \"match_probability\": 0.93109, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007354976352871745}, {\"match_weight\": 3.76, \"match_probability\": 0.93136, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0073747477945289575}, {\"match_weight\": 3.77, \"match_probability\": 0.9317, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00739451923618617}, {\"match_weight\": 3.78, \"match_probability\": 0.93224, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007414290677843383}, {\"match_weight\": 3.81, \"match_probability\": 0.93365, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007434062119500595}, {\"match_weight\": 3.82, \"match_probability\": 0.93386, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007453833561157808}, {\"match_weight\": 3.83, \"match_probability\": 0.93416, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00747360500281502}, {\"match_weight\": 3.84, \"match_probability\": 0.93486, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007493376444472233}, {\"match_weight\": 3.87, \"match_probability\": 0.93585, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007513147886129445}, {\"match_weight\": 3.88, \"match_probability\": 0.93641, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0075526907694438705}, {\"match_weight\": 3.89, \"match_probability\": 0.93666, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007572462211101083}, {\"match_weight\": 3.9, \"match_probability\": 0.93734, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007592233652758296}, {\"match_weight\": 3.91, \"match_probability\": 0.9376, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007612005094415508}, {\"match_weight\": 3.94, \"match_probability\": 0.93872, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007631776536072721}, {\"match_weight\": 3.95, \"match_probability\": 0.93909, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007651547977729933}, {\"match_weight\": 3.97, \"match_probability\": 0.94008, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0076910908610443585}, {\"match_weight\": 4.0, \"match_probability\": 0.94121, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007710862302701571}, {\"match_weight\": 4.0, \"match_probability\": 0.94135, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007730633744358784}, {\"match_weight\": 4.01, \"match_probability\": 0.94151, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007750405186015996}, {\"match_weight\": 4.02, \"match_probability\": 0.94179, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007770176627673209}, {\"match_weight\": 4.03, \"match_probability\": 0.94232, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.007809719510987634}, {\"match_weight\": 4.03, \"match_probability\": 0.94233, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007829490952644846}, {\"match_weight\": 4.05, \"match_probability\": 0.94319, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007849262394302059}, {\"match_weight\": 4.06, \"match_probability\": 0.94361, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007869033835959272}, {\"match_weight\": 4.07, \"match_probability\": 0.94382, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007888805277616484}, {\"match_weight\": 4.11, \"match_probability\": 0.94541, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00792834816093091}, {\"match_weight\": 4.12, \"match_probability\": 0.94555, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.007967891044245334}, {\"match_weight\": 4.13, \"match_probability\": 0.94614, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.007987662485902547}, {\"match_weight\": 4.14, \"match_probability\": 0.94638, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00800743392755976}, {\"match_weight\": 4.17, \"match_probability\": 0.94724, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008027205369216972}, {\"match_weight\": 4.17, \"match_probability\": 0.9475, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008046976810874185}, {\"match_weight\": 4.18, \"match_probability\": 0.94784, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008066748252531397}, {\"match_weight\": 4.19, \"match_probability\": 0.94792, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00808651969418861}, {\"match_weight\": 4.19, \"match_probability\": 0.94803, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008106291135845822}, {\"match_weight\": 4.2, \"match_probability\": 0.94823, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008126062577503035}, {\"match_weight\": 4.2, \"match_probability\": 0.9483, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008145834019160247}, {\"match_weight\": 4.23, \"match_probability\": 0.94955, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008185376902474673}, {\"match_weight\": 4.24, \"match_probability\": 0.94958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008205148344131885}, {\"match_weight\": 4.24, \"match_probability\": 0.94986, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008224919785789098}, {\"match_weight\": 4.25, \"match_probability\": 0.94998, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008264462669103523}, {\"match_weight\": 4.26, \"match_probability\": 0.95033, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008284234110760735}, {\"match_weight\": 4.27, \"match_probability\": 0.95068, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008304005552417948}, {\"match_weight\": 4.27, \"match_probability\": 0.95083, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00832377699407516}, {\"match_weight\": 4.29, \"match_probability\": 0.95148, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008343548435732373}, {\"match_weight\": 4.34, \"match_probability\": 0.95283, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008363319877389586}, {\"match_weight\": 4.34, \"match_probability\": 0.95293, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008383091319046798}, {\"match_weight\": 4.36, \"match_probability\": 0.95343, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00840286276070401}, {\"match_weight\": 4.36, \"match_probability\": 0.95369, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008422634202361223}, {\"match_weight\": 4.38, \"match_probability\": 0.95421, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008462177085675648}, {\"match_weight\": 4.39, \"match_probability\": 0.95456, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008481948527332861}, {\"match_weight\": 4.39, \"match_probability\": 0.95461, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008501719968990074}, {\"match_weight\": 4.4, \"match_probability\": 0.95482, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008521491410647286}, {\"match_weight\": 4.44, \"match_probability\": 0.95608, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008541262852304499}, {\"match_weight\": 4.45, \"match_probability\": 0.95622, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008561034293961711}, {\"match_weight\": 4.47, \"match_probability\": 0.95679, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008580805735618924}, {\"match_weight\": 4.47, \"match_probability\": 0.95695, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008600577177276136}, {\"match_weight\": 4.48, \"match_probability\": 0.9571, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008640120060590561}, {\"match_weight\": 4.52, \"match_probability\": 0.9582, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008659891502247774}, {\"match_weight\": 4.52, \"match_probability\": 0.95823, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008679662943904987}, {\"match_weight\": 4.56, \"match_probability\": 0.95942, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0086994343855622}, {\"match_weight\": 4.57, \"match_probability\": 0.95966, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008719205827219412}, {\"match_weight\": 4.57, \"match_probability\": 0.95972, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008738977268876624}, {\"match_weight\": 4.58, \"match_probability\": 0.95994, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008758748710533837}, {\"match_weight\": 4.6, \"match_probability\": 0.9603, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00877852015219105}, {\"match_weight\": 4.6, \"match_probability\": 0.96038, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008798291593848262}, {\"match_weight\": 4.61, \"match_probability\": 0.96054, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.008837834477162687}, {\"match_weight\": 4.61, \"match_probability\": 0.96064, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0088576059188199}, {\"match_weight\": 4.64, \"match_probability\": 0.9614, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008877377360477112}, {\"match_weight\": 4.64, \"match_probability\": 0.96151, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008897148802134325}, {\"match_weight\": 4.65, \"match_probability\": 0.96182, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008916920243791537}, {\"match_weight\": 4.66, \"match_probability\": 0.96192, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00893669168544875}, {\"match_weight\": 4.67, \"match_probability\": 0.96227, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008956463127105962}, {\"match_weight\": 4.69, \"match_probability\": 0.96276, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008976234568763175}, {\"match_weight\": 4.7, \"match_probability\": 0.96307, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.008996006010420388}, {\"match_weight\": 4.72, \"match_probability\": 0.96335, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0090157774520776}, {\"match_weight\": 4.73, \"match_probability\": 0.96379, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009055320335392025}, {\"match_weight\": 4.74, \"match_probability\": 0.96394, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009075091777049238}, {\"match_weight\": 4.76, \"match_probability\": 0.96434, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00909486321870645}, {\"match_weight\": 4.76, \"match_probability\": 0.96442, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009114634660363663}, {\"match_weight\": 4.78, \"match_probability\": 0.96476, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009134406102020876}, {\"match_weight\": 4.79, \"match_probability\": 0.96509, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009154177543678088}, {\"match_weight\": 4.8, \"match_probability\": 0.9653, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0091739489853353}, {\"match_weight\": 4.81, \"match_probability\": 0.96548, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009193720426992513}, {\"match_weight\": 4.81, \"match_probability\": 0.96554, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009213491868649726}, {\"match_weight\": 4.81, \"match_probability\": 0.96556, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009233263310306938}, {\"match_weight\": 4.81, \"match_probability\": 0.96569, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009253034751964151}, {\"match_weight\": 4.82, \"match_probability\": 0.96573, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009272806193621363}, {\"match_weight\": 4.84, \"match_probability\": 0.96622, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009292577635278576}, {\"match_weight\": 4.85, \"match_probability\": 0.96648, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009312349076935789}, {\"match_weight\": 4.88, \"match_probability\": 0.96721, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009332120518593001}, {\"match_weight\": 4.89, \"match_probability\": 0.96742, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009371663401907426}, {\"match_weight\": 4.9, \"match_probability\": 0.96765, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009391434843564639}, {\"match_weight\": 4.91, \"match_probability\": 0.96779, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009430977726879064}, {\"match_weight\": 4.93, \"match_probability\": 0.96817, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009470520610193489}, {\"match_weight\": 4.94, \"match_probability\": 0.96853, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009490292051850702}, {\"match_weight\": 4.96, \"match_probability\": 0.96885, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009510063493507914}, {\"match_weight\": 4.96, \"match_probability\": 0.96893, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009529834935165127}, {\"match_weight\": 4.97, \"match_probability\": 0.96914, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00954960637682234}, {\"match_weight\": 5.0, \"match_probability\": 0.96961, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009569377818479552}, {\"match_weight\": 5.0, \"match_probability\": 0.96965, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009589149260136764}, {\"match_weight\": 5.0, \"match_probability\": 0.96967, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009608920701793977}, {\"match_weight\": 5.01, \"match_probability\": 0.96983, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00962869214345119}, {\"match_weight\": 5.02, \"match_probability\": 0.97017, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009648463585108402}, {\"match_weight\": 5.03, \"match_probability\": 0.97021, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009688006468422827}, {\"match_weight\": 5.03, \"match_probability\": 0.97031, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.00970777791008004}, {\"match_weight\": 5.07, \"match_probability\": 0.97108, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009727549351737252}, {\"match_weight\": 5.11, \"match_probability\": 0.97182, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009747320793394465}, {\"match_weight\": 5.13, \"match_probability\": 0.97223, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009767092235051678}, {\"match_weight\": 5.13, \"match_probability\": 0.97226, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.009826406561842305}, {\"match_weight\": 5.14, \"match_probability\": 0.97236, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.00986594944515673}, {\"match_weight\": 5.14, \"match_probability\": 0.97237, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009885720886813942}, {\"match_weight\": 5.16, \"match_probability\": 0.97283, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009905492328471155}, {\"match_weight\": 5.16, \"match_probability\": 0.97286, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.009925263770128367}, {\"match_weight\": 5.17, \"match_probability\": 0.97294, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.009964806653442793}, {\"match_weight\": 5.17, \"match_probability\": 0.97304, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.010043892420071643}, {\"match_weight\": 5.19, \"match_probability\": 0.97326, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010063663861728855}, {\"match_weight\": 5.2, \"match_probability\": 0.97344, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010083435303386068}, {\"match_weight\": 5.23, \"match_probability\": 0.97412, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01010320674504328}, {\"match_weight\": 5.26, \"match_probability\": 0.97451, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010122978186700493}, {\"match_weight\": 5.26, \"match_probability\": 0.97457, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010142749628357706}, {\"match_weight\": 5.27, \"match_probability\": 0.97471, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010162521070014918}, {\"match_weight\": 5.31, \"match_probability\": 0.97535, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01018229251167213}, {\"match_weight\": 5.31, \"match_probability\": 0.97542, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010202063953329343}, {\"match_weight\": 5.31, \"match_probability\": 0.97543, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010221835394986556}, {\"match_weight\": 5.37, \"match_probability\": 0.97635, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010241606836643768}, {\"match_weight\": 5.38, \"match_probability\": 0.97653, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010261378278300981}, {\"match_weight\": 5.38, \"match_probability\": 0.97655, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010300921161615406}, {\"match_weight\": 5.38, \"match_probability\": 0.97657, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010340464044929831}, {\"match_weight\": 5.39, \"match_probability\": 0.97671, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010360235486587044}, {\"match_weight\": 5.39, \"match_probability\": 0.97678, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010399778369901469}, {\"match_weight\": 5.4, \"match_probability\": 0.97682, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010419549811558682}, {\"match_weight\": 5.41, \"match_probability\": 0.97699, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010439321253215894}, {\"match_weight\": 5.42, \"match_probability\": 0.97714, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010459092694873107}, {\"match_weight\": 5.43, \"match_probability\": 0.97731, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01047886413653032}, {\"match_weight\": 5.43, \"match_probability\": 0.97736, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010498635578187532}, {\"match_weight\": 5.45, \"match_probability\": 0.97771, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010518407019844744}, {\"match_weight\": 5.47, \"match_probability\": 0.9779, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010538178461501957}, {\"match_weight\": 5.47, \"match_probability\": 0.97793, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01055794990315917}, {\"match_weight\": 5.48, \"match_probability\": 0.97802, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010577721344816382}, {\"match_weight\": 5.48, \"match_probability\": 0.9781, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010597492786473595}, {\"match_weight\": 5.48, \"match_probability\": 0.97812, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01063703566978802}, {\"match_weight\": 5.48, \"match_probability\": 0.97813, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010676578553102445}, {\"match_weight\": 5.52, \"match_probability\": 0.97863, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010696349994759657}, {\"match_weight\": 5.52, \"match_probability\": 0.97864, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01071612143641687}, {\"match_weight\": 5.52, \"match_probability\": 0.97874, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010735892878074083}, {\"match_weight\": 5.55, \"match_probability\": 0.97905, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010755664319731295}, {\"match_weight\": 5.56, \"match_probability\": 0.97929, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01079520720304572}, {\"match_weight\": 5.59, \"match_probability\": 0.9796, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010814978644702933}, {\"match_weight\": 5.6, \"match_probability\": 0.97974, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010834750086360145}, {\"match_weight\": 5.6, \"match_probability\": 0.97981, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010854521528017358}, {\"match_weight\": 5.6, \"match_probability\": 0.97987, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01087429296967457}, {\"match_weight\": 5.62, \"match_probability\": 0.98001, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.010913835852988996}, {\"match_weight\": 5.62, \"match_probability\": 0.98003, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.010933607294646208}, {\"match_weight\": 5.63, \"match_probability\": 0.98015, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01095337873630342}, {\"match_weight\": 5.64, \"match_probability\": 0.98032, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.011111550269561121}, {\"match_weight\": 5.65, \"match_probability\": 0.98042, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011131321711218334}, {\"match_weight\": 5.67, \"match_probability\": 0.98073, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011151093152875546}, {\"match_weight\": 5.67, \"match_probability\": 0.98074, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011190636036189971}, {\"match_weight\": 5.68, \"match_probability\": 0.98085, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011210407477847184}, {\"match_weight\": 5.68, \"match_probability\": 0.98088, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011230178919504397}, {\"match_weight\": 5.7, \"match_probability\": 0.9811, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011269721802818822}, {\"match_weight\": 5.7, \"match_probability\": 0.98117, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011289493244476034}, {\"match_weight\": 5.73, \"match_probability\": 0.98156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011309264686133247}, {\"match_weight\": 5.74, \"match_probability\": 0.9816, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01132903612779046}, {\"match_weight\": 5.75, \"match_probability\": 0.98182, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011348807569447672}, {\"match_weight\": 5.78, \"match_probability\": 0.98208, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011368579011104885}, {\"match_weight\": 5.8, \"match_probability\": 0.98242, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01140812189441931}, {\"match_weight\": 5.83, \"match_probability\": 0.98275, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.01148720766104816}, {\"match_weight\": 5.83, \"match_probability\": 0.98276, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011506979102705372}, {\"match_weight\": 5.84, \"match_probability\": 0.98286, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011526750544362585}, {\"match_weight\": 5.85, \"match_probability\": 0.98298, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011546521986019798}, {\"match_weight\": 5.86, \"match_probability\": 0.98309, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01156629342767701}, {\"match_weight\": 5.87, \"match_probability\": 0.98315, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011586064869334223}, {\"match_weight\": 5.88, \"match_probability\": 0.98326, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011605836310991435}, {\"match_weight\": 5.89, \"match_probability\": 0.9834, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011625607752648648}, {\"match_weight\": 5.9, \"match_probability\": 0.98351, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01164537919430586}, {\"match_weight\": 5.91, \"match_probability\": 0.98363, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.011704693521096488}, {\"match_weight\": 5.92, \"match_probability\": 0.98377, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0117244649627537}, {\"match_weight\": 5.92, \"match_probability\": 0.9838, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011744236404410913}, {\"match_weight\": 5.94, \"match_probability\": 0.98395, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011764007846068125}, {\"match_weight\": 5.95, \"match_probability\": 0.98406, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011783779287725338}, {\"match_weight\": 5.95, \"match_probability\": 0.9841, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01180355072938255}, {\"match_weight\": 5.96, \"match_probability\": 0.98414, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011823322171039763}, {\"match_weight\": 5.96, \"match_probability\": 0.98418, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011843093612696975}, {\"match_weight\": 5.96, \"match_probability\": 0.9842, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011862865054354188}, {\"match_weight\": 5.96, \"match_probability\": 0.98422, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0118826364960114}, {\"match_weight\": 5.97, \"match_probability\": 0.98432, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011902407937668613}, {\"match_weight\": 5.98, \"match_probability\": 0.9844, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011922179379325826}, {\"match_weight\": 6.0, \"match_probability\": 0.98459, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.011941950820983038}, {\"match_weight\": 6.01, \"match_probability\": 0.98471, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.011981493704297463}, {\"match_weight\": 6.01, \"match_probability\": 0.98474, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012001265145954676}, {\"match_weight\": 6.02, \"match_probability\": 0.98478, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012040808029269101}, {\"match_weight\": 6.02, \"match_probability\": 0.98482, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012060579470926314}, {\"match_weight\": 6.03, \"match_probability\": 0.98492, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012080350912583526}, {\"match_weight\": 6.03, \"match_probability\": 0.98493, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012100122354240739}, {\"match_weight\": 6.04, \"match_probability\": 0.98505, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012119893795897951}, {\"match_weight\": 6.04, \"match_probability\": 0.98507, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012139665237555164}, {\"match_weight\": 6.05, \"match_probability\": 0.98511, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012159436679212376}, {\"match_weight\": 6.06, \"match_probability\": 0.98519, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012179208120869589}, {\"match_weight\": 6.07, \"match_probability\": 0.98531, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012218751004184014}, {\"match_weight\": 6.07, \"match_probability\": 0.98537, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012238522445841227}, {\"match_weight\": 6.08, \"match_probability\": 0.98545, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01225829388749844}, {\"match_weight\": 6.09, \"match_probability\": 0.98554, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012278065329155652}, {\"match_weight\": 6.12, \"match_probability\": 0.9858, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012297836770812864}, {\"match_weight\": 6.12, \"match_probability\": 0.98586, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012317608212470077}, {\"match_weight\": 6.13, \"match_probability\": 0.98592, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01233737965412729}, {\"match_weight\": 6.13, \"match_probability\": 0.98593, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012357151095784502}, {\"match_weight\": 6.13, \"match_probability\": 0.98595, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012376922537441715}, {\"match_weight\": 6.15, \"match_probability\": 0.98615, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01241646542075614}, {\"match_weight\": 6.16, \"match_probability\": 0.98623, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012436236862413352}, {\"match_weight\": 6.17, \"match_probability\": 0.98631, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012456008304070565}, {\"match_weight\": 6.18, \"match_probability\": 0.98636, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01249555118738499}, {\"match_weight\": 6.18, \"match_probability\": 0.98643, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012515322629042203}, {\"match_weight\": 6.2, \"match_probability\": 0.98654, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012554865512356628}, {\"match_weight\": 6.2, \"match_probability\": 0.98656, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01257463695401384}, {\"match_weight\": 6.21, \"match_probability\": 0.98668, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012594408395671053}, {\"match_weight\": 6.22, \"match_probability\": 0.98677, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012614179837328265}, {\"match_weight\": 6.23, \"match_probability\": 0.98689, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012633951278985478}, {\"match_weight\": 6.24, \"match_probability\": 0.98694, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01265372272064269}, {\"match_weight\": 6.24, \"match_probability\": 0.98695, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012673494162299903}, {\"match_weight\": 6.24, \"match_probability\": 0.98696, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012693265603957116}, {\"match_weight\": 6.26, \"match_probability\": 0.98712, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01273280848727154}, {\"match_weight\": 6.26, \"match_probability\": 0.98715, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012752579928928753}, {\"match_weight\": 6.27, \"match_probability\": 0.98718, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012772351370585966}, {\"match_weight\": 6.27, \"match_probability\": 0.98723, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012792122812243178}, {\"match_weight\": 6.29, \"match_probability\": 0.98737, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012811894253900391}, {\"match_weight\": 6.3, \"match_probability\": 0.98744, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012831665695557604}, {\"match_weight\": 6.3, \"match_probability\": 0.98748, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012851437137214816}, {\"match_weight\": 6.3, \"match_probability\": 0.9875, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012871208578872029}, {\"match_weight\": 6.31, \"match_probability\": 0.98751, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012890980020529241}, {\"match_weight\": 6.33, \"match_probability\": 0.98775, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012910751462186454}, {\"match_weight\": 6.34, \"match_probability\": 0.98783, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.012950294345500879}, {\"match_weight\": 6.35, \"match_probability\": 0.98785, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012970065787158092}, {\"match_weight\": 6.36, \"match_probability\": 0.98793, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.012989837228815304}, {\"match_weight\": 6.36, \"match_probability\": 0.98794, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013009608670472517}, {\"match_weight\": 6.36, \"match_probability\": 0.98795, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.013068922997263144}, {\"match_weight\": 6.39, \"match_probability\": 0.98822, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013088694438920356}, {\"match_weight\": 6.4, \"match_probability\": 0.98828, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013108465880577569}, {\"match_weight\": 6.4, \"match_probability\": 0.9883, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013128237322234781}, {\"match_weight\": 6.41, \"match_probability\": 0.9884, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013148008763891994}, {\"match_weight\": 6.42, \"match_probability\": 0.98843, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013167780205549207}, {\"match_weight\": 6.46, \"match_probability\": 0.98874, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013207323088863632}, {\"match_weight\": 6.46, \"match_probability\": 0.98879, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013246865972178057}, {\"match_weight\": 6.46, \"match_probability\": 0.9888, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01326663741383527}, {\"match_weight\": 6.47, \"match_probability\": 0.98888, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013286408855492482}, {\"match_weight\": 6.48, \"match_probability\": 0.9889, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013306180297149695}, {\"match_weight\": 6.49, \"match_probability\": 0.98897, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013325951738806907}, {\"match_weight\": 6.5, \"match_probability\": 0.98904, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01334572318046412}, {\"match_weight\": 6.51, \"match_probability\": 0.98911, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013365494622121332}, {\"match_weight\": 6.51, \"match_probability\": 0.98912, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013385266063778545}, {\"match_weight\": 6.51, \"match_probability\": 0.98914, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013405037505435757}, {\"match_weight\": 6.51, \"match_probability\": 0.98916, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01342480894709297}, {\"match_weight\": 6.51, \"match_probability\": 0.98918, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013444580388750182}, {\"match_weight\": 6.52, \"match_probability\": 0.98919, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013464351830407395}, {\"match_weight\": 6.53, \"match_probability\": 0.98926, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013484123272064608}, {\"match_weight\": 6.54, \"match_probability\": 0.9894, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01350389471372182}, {\"match_weight\": 6.55, \"match_probability\": 0.98941, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013523666155379033}, {\"match_weight\": 6.55, \"match_probability\": 0.98943, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013543437597036245}, {\"match_weight\": 6.56, \"match_probability\": 0.98949, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013563209038693458}, {\"match_weight\": 6.56, \"match_probability\": 0.98951, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01358298048035067}, {\"match_weight\": 6.56, \"match_probability\": 0.98952, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013602751922007883}, {\"match_weight\": 6.56, \"match_probability\": 0.98954, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013622523363665096}, {\"match_weight\": 6.57, \"match_probability\": 0.98958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013642294805322308}, {\"match_weight\": 6.57, \"match_probability\": 0.98961, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01366206624697952}, {\"match_weight\": 6.58, \"match_probability\": 0.98967, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013681837688636733}, {\"match_weight\": 6.59, \"match_probability\": 0.98972, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01374115201542736}, {\"match_weight\": 6.59, \"match_probability\": 0.98975, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013760923457084573}, {\"match_weight\": 6.6, \"match_probability\": 0.98977, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013780694898741785}, {\"match_weight\": 6.6, \"match_probability\": 0.9898, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013800466340398998}, {\"match_weight\": 6.61, \"match_probability\": 0.98989, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01382023778205621}, {\"match_weight\": 6.62, \"match_probability\": 0.98993, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.013840009223713423}, {\"match_weight\": 6.63, \"match_probability\": 0.98998, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013879552107027848}, {\"match_weight\": 6.63, \"match_probability\": 0.98999, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01389932354868506}, {\"match_weight\": 6.64, \"match_probability\": 0.99005, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.013958637875475688}, {\"match_weight\": 6.64, \"match_probability\": 0.99008, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.013998180758790113}, {\"match_weight\": 6.64, \"match_probability\": 0.99009, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014017952200447326}, {\"match_weight\": 6.65, \"match_probability\": 0.99014, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014037723642104538}, {\"match_weight\": 6.67, \"match_probability\": 0.99031, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01405749508376175}, {\"match_weight\": 6.68, \"match_probability\": 0.99032, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014077266525418963}, {\"match_weight\": 6.68, \"match_probability\": 0.99033, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01413658085220959}, {\"match_weight\": 6.68, \"match_probability\": 0.99035, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014156352293866803}, {\"match_weight\": 6.69, \"match_probability\": 0.99043, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014195895177181228}, {\"match_weight\": 6.7, \"match_probability\": 0.99046, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01421566661883844}, {\"match_weight\": 6.71, \"match_probability\": 0.99054, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014235438060495653}, {\"match_weight\": 6.72, \"match_probability\": 0.99063, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014274980943810078}, {\"match_weight\": 6.74, \"match_probability\": 0.99071, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014294752385467291}, {\"match_weight\": 6.75, \"match_probability\": 0.9908, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014334295268781716}, {\"match_weight\": 6.76, \"match_probability\": 0.99086, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014354066710438929}, {\"match_weight\": 6.76, \"match_probability\": 0.99088, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014393609593753354}, {\"match_weight\": 6.77, \"match_probability\": 0.9909, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014413381035410566}, {\"match_weight\": 6.77, \"match_probability\": 0.99091, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014433152477067779}, {\"match_weight\": 6.78, \"match_probability\": 0.99098, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014452923918724991}, {\"match_weight\": 6.8, \"match_probability\": 0.99113, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014492466802039417}, {\"match_weight\": 6.81, \"match_probability\": 0.99116, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.014551781128830044}, {\"match_weight\": 6.83, \"match_probability\": 0.99127, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014571552570487256}, {\"match_weight\": 6.83, \"match_probability\": 0.99131, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014591324012144469}, {\"match_weight\": 6.84, \"match_probability\": 0.99132, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014611095453801681}, {\"match_weight\": 6.85, \"match_probability\": 0.99142, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014630866895458894}, {\"match_weight\": 6.86, \"match_probability\": 0.99147, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014650638337116106}, {\"match_weight\": 6.86, \"match_probability\": 0.99148, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014670409778773319}, {\"match_weight\": 6.88, \"match_probability\": 0.99156, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014690181220430532}, {\"match_weight\": 6.88, \"match_probability\": 0.99158, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014709952662087744}, {\"match_weight\": 6.9, \"match_probability\": 0.9917, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014729724103744957}, {\"match_weight\": 6.9, \"match_probability\": 0.99172, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01474949554540217}, {\"match_weight\": 6.93, \"match_probability\": 0.99185, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014769266987059382}, {\"match_weight\": 6.93, \"match_probability\": 0.99186, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014789038428716594}, {\"match_weight\": 6.93, \"match_probability\": 0.99188, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014808809870373807}, {\"match_weight\": 6.94, \"match_probability\": 0.99192, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01482858131203102}, {\"match_weight\": 6.94, \"match_probability\": 0.99193, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014868124195345445}, {\"match_weight\": 6.95, \"match_probability\": 0.99197, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014887895637002657}, {\"match_weight\": 6.96, \"match_probability\": 0.99201, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01490766707865987}, {\"match_weight\": 6.96, \"match_probability\": 0.99203, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.014947209961974295}, {\"match_weight\": 6.96, \"match_probability\": 0.99205, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.014966981403631507}, {\"match_weight\": 6.97, \"match_probability\": 0.99207, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01498675284528872}, {\"match_weight\": 6.97, \"match_probability\": 0.9921, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015006524286945933}, {\"match_weight\": 6.98, \"match_probability\": 0.99212, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015026295728603145}, {\"match_weight\": 6.98, \"match_probability\": 0.99214, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01506583861191757}, {\"match_weight\": 6.99, \"match_probability\": 0.99221, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015085610053574783}, {\"match_weight\": 7.0, \"match_probability\": 0.99224, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015105381495231995}, {\"match_weight\": 7.01, \"match_probability\": 0.99231, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01514492437854642}, {\"match_weight\": 7.01, \"match_probability\": 0.99232, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015164695820203633}, {\"match_weight\": 7.01, \"match_probability\": 0.99233, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015184467261860846}, {\"match_weight\": 7.03, \"match_probability\": 0.99242, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015204238703518058}, {\"match_weight\": 7.05, \"match_probability\": 0.99249, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01522401014517527}, {\"match_weight\": 7.06, \"match_probability\": 0.99256, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015243781586832483}, {\"match_weight\": 7.06, \"match_probability\": 0.99257, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015263553028489696}, {\"match_weight\": 7.06, \"match_probability\": 0.99259, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015283324470146908}, {\"match_weight\": 7.07, \"match_probability\": 0.9926, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015303095911804121}, {\"match_weight\": 7.07, \"match_probability\": 0.99262, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015322867353461334}, {\"match_weight\": 7.07, \"match_probability\": 0.99263, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015342638795118546}, {\"match_weight\": 7.08, \"match_probability\": 0.99265, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015362410236775759}, {\"match_weight\": 7.08, \"match_probability\": 0.99268, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015382181678432971}, {\"match_weight\": 7.09, \"match_probability\": 0.99272, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015401953120090184}, {\"match_weight\": 7.09, \"match_probability\": 0.99273, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015421724561747396}, {\"match_weight\": 7.1, \"match_probability\": 0.99277, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015441496003404609}, {\"match_weight\": 7.11, \"match_probability\": 0.99283, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015481038886719034}, {\"match_weight\": 7.12, \"match_probability\": 0.99286, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015500810328376247}, {\"match_weight\": 7.13, \"match_probability\": 0.99292, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01552058177003346}, {\"match_weight\": 7.15, \"match_probability\": 0.993, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015560124653347884}, {\"match_weight\": 7.16, \"match_probability\": 0.99303, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015579896095005097}, {\"match_weight\": 7.16, \"match_probability\": 0.99306, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01559966753666231}, {\"match_weight\": 7.17, \"match_probability\": 0.99311, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015619438978319522}, {\"match_weight\": 7.18, \"match_probability\": 0.99314, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015639210419976735}, {\"match_weight\": 7.2, \"match_probability\": 0.99325, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01567875330329116}, {\"match_weight\": 7.21, \"match_probability\": 0.99329, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015718296186605585}, {\"match_weight\": 7.21, \"match_probability\": 0.9933, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015738067628262797}, {\"match_weight\": 7.21, \"match_probability\": 0.99331, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01575783906992001}, {\"match_weight\": 7.22, \"match_probability\": 0.99333, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015777610511577222}, {\"match_weight\": 7.23, \"match_probability\": 0.9934, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015797381953234435}, {\"match_weight\": 7.23, \"match_probability\": 0.99341, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015817153394891648}, {\"match_weight\": 7.24, \"match_probability\": 0.99342, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01583692483654886}, {\"match_weight\": 7.24, \"match_probability\": 0.99344, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015856696278206073}, {\"match_weight\": 7.25, \"match_probability\": 0.99347, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015876467719863285}, {\"match_weight\": 7.26, \"match_probability\": 0.99352, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015896239161520498}, {\"match_weight\": 7.26, \"match_probability\": 0.99354, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01591601060317771}, {\"match_weight\": 7.27, \"match_probability\": 0.99355, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.015955553486492136}, {\"match_weight\": 7.27, \"match_probability\": 0.99356, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.015975324928149348}, {\"match_weight\": 7.27, \"match_probability\": 0.99358, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01599509636980656}, {\"match_weight\": 7.28, \"match_probability\": 0.99359, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016014867811463773}, {\"match_weight\": 7.28, \"match_probability\": 0.99362, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016034639253120986}, {\"match_weight\": 7.3, \"match_probability\": 0.99371, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0160544106947782}, {\"match_weight\": 7.31, \"match_probability\": 0.99373, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01607418213643541}, {\"match_weight\": 7.31, \"match_probability\": 0.99376, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016093953578092624}, {\"match_weight\": 7.32, \"match_probability\": 0.99379, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016113725019749836}, {\"match_weight\": 7.34, \"match_probability\": 0.99385, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01615326790306426}, {\"match_weight\": 7.35, \"match_probability\": 0.99392, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016173039344721474}, {\"match_weight\": 7.36, \"match_probability\": 0.99393, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016192810786378686}, {\"match_weight\": 7.36, \"match_probability\": 0.99395, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0162125822280359}, {\"match_weight\": 7.36, \"match_probability\": 0.99396, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016252125111350324}, {\"match_weight\": 7.37, \"match_probability\": 0.99398, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016271896553007537}, {\"match_weight\": 7.38, \"match_probability\": 0.99402, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01629166799466475}, {\"match_weight\": 7.38, \"match_probability\": 0.99405, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016331210877979174}, {\"match_weight\": 7.39, \"match_probability\": 0.99406, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.0163707537612936}, {\"match_weight\": 7.39, \"match_probability\": 0.99409, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016390525202950812}, {\"match_weight\": 7.4, \"match_probability\": 0.99411, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016410296644608025}, {\"match_weight\": 7.4, \"match_probability\": 0.99412, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01644983952792245}, {\"match_weight\": 7.4, \"match_probability\": 0.99413, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016469610969579662}, {\"match_weight\": 7.41, \"match_probability\": 0.99415, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016489382411236875}, {\"match_weight\": 7.43, \"match_probability\": 0.99421, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016509153852894087}, {\"match_weight\": 7.43, \"match_probability\": 0.99422, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016548696736208512}, {\"match_weight\": 7.44, \"match_probability\": 0.99427, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016568468177865725}, {\"match_weight\": 7.44, \"match_probability\": 0.99429, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016588239619522938}, {\"match_weight\": 7.46, \"match_probability\": 0.99434, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016627782502837363}, {\"match_weight\": 7.46, \"match_probability\": 0.99437, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016647553944494575}, {\"match_weight\": 7.48, \"match_probability\": 0.99442, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016687096827809}, {\"match_weight\": 7.48, \"match_probability\": 0.99444, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016706868269466213}, {\"match_weight\": 7.5, \"match_probability\": 0.99451, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016726639711123426}, {\"match_weight\": 7.51, \"match_probability\": 0.99453, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016746411152780638}, {\"match_weight\": 7.51, \"match_probability\": 0.99455, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01676618259443785}, {\"match_weight\": 7.53, \"match_probability\": 0.99461, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016785954036095063}, {\"match_weight\": 7.54, \"match_probability\": 0.99466, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016805725477752276}, {\"match_weight\": 7.55, \"match_probability\": 0.99468, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01682549691940949}, {\"match_weight\": 7.56, \"match_probability\": 0.99474, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0168452683610667}, {\"match_weight\": 7.58, \"match_probability\": 0.99481, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.016865039802723913}, {\"match_weight\": 7.6, \"match_probability\": 0.99487, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01690458268603834}, {\"match_weight\": 7.61, \"match_probability\": 0.99492, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01692435412769555}, {\"match_weight\": 7.62, \"match_probability\": 0.99493, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.016963897011009976}, {\"match_weight\": 7.62, \"match_probability\": 0.99494, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01698366845266719}, {\"match_weight\": 7.62, \"match_probability\": 0.99495, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0170034398943244}, {\"match_weight\": 7.63, \"match_probability\": 0.99499, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017023211335981614}, {\"match_weight\": 7.65, \"match_probability\": 0.99505, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.017102297102610464}, {\"match_weight\": 7.67, \"match_probability\": 0.99511, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01714183998592489}, {\"match_weight\": 7.67, \"match_probability\": 0.99512, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017161611427582102}, {\"match_weight\": 7.68, \"match_probability\": 0.99514, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017181382869239314}, {\"match_weight\": 7.69, \"match_probability\": 0.99516, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01722092575255374}, {\"match_weight\": 7.69, \"match_probability\": 0.99518, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017240697194210952}, {\"match_weight\": 7.7, \"match_probability\": 0.99521, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017260468635868165}, {\"match_weight\": 7.7, \"match_probability\": 0.99522, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.017319782962658792}, {\"match_weight\": 7.71, \"match_probability\": 0.99523, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017339554404316004}, {\"match_weight\": 7.72, \"match_probability\": 0.99528, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017359325845973217}, {\"match_weight\": 7.73, \"match_probability\": 0.99532, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01737909728763043}, {\"match_weight\": 7.74, \"match_probability\": 0.99533, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017398868729287642}, {\"match_weight\": 7.74, \"match_probability\": 0.99534, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01745818305607827}, {\"match_weight\": 7.75, \"match_probability\": 0.99537, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01747795449773548}, {\"match_weight\": 7.76, \"match_probability\": 0.9954, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017517497381049907}, {\"match_weight\": 7.76, \"match_probability\": 0.99541, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01753726882270712}, {\"match_weight\": 7.77, \"match_probability\": 0.99543, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017557040264364332}, {\"match_weight\": 7.77, \"match_probability\": 0.99544, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017576811706021545}, {\"match_weight\": 7.77, \"match_probability\": 0.99545, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017596583147678757}, {\"match_weight\": 7.78, \"match_probability\": 0.99547, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01761635458933597}, {\"match_weight\": 7.79, \"match_probability\": 0.99549, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017636126030993182}, {\"match_weight\": 7.79, \"match_probability\": 0.9955, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017675668914307607}, {\"match_weight\": 7.79, \"match_probability\": 0.99551, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01769544035596482}, {\"match_weight\": 7.8, \"match_probability\": 0.99552, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017715211797622032}, {\"match_weight\": 7.8, \"match_probability\": 0.99554, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017734983239279245}, {\"match_weight\": 7.81, \"match_probability\": 0.99555, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017754754680936458}, {\"match_weight\": 7.81, \"match_probability\": 0.99557, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017794297564250883}, {\"match_weight\": 7.81, \"match_probability\": 0.99558, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017833840447565308}, {\"match_weight\": 7.82, \"match_probability\": 0.99559, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01785361188922252}, {\"match_weight\": 7.82, \"match_probability\": 0.9956, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.017873383330879733}, {\"match_weight\": 7.82, \"match_probability\": 0.99561, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.017912926214194158}, {\"match_weight\": 7.83, \"match_probability\": 0.99562, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01793269765585137}, {\"match_weight\": 7.84, \"match_probability\": 0.99565, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.017992011982641998}, {\"match_weight\": 7.85, \"match_probability\": 0.99567, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01801178342429921}, {\"match_weight\": 7.85, \"match_probability\": 0.99569, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018051326307613635}, {\"match_weight\": 7.86, \"match_probability\": 0.99572, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018071097749270848}, {\"match_weight\": 7.87, \"match_probability\": 0.99574, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01809086919092806}, {\"match_weight\": 7.89, \"match_probability\": 0.9958, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018110640632585273}, {\"match_weight\": 7.91, \"match_probability\": 0.99586, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018150183515899698}, {\"match_weight\": 7.92, \"match_probability\": 0.99588, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018189726399214123}, {\"match_weight\": 7.93, \"match_probability\": 0.9959, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01822926928252855}, {\"match_weight\": 7.93, \"match_probability\": 0.99591, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018268812165842974}, {\"match_weight\": 7.94, \"match_probability\": 0.99595, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.018387440819424228}, {\"match_weight\": 7.95, \"match_probability\": 0.99596, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01840721226108144}, {\"match_weight\": 7.95, \"match_probability\": 0.99597, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018426983702738653}, {\"match_weight\": 7.96, \"match_probability\": 0.996, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018446755144395865}, {\"match_weight\": 7.98, \"match_probability\": 0.99605, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018466526586053078}, {\"match_weight\": 7.98, \"match_probability\": 0.99606, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01848629802771029}, {\"match_weight\": 7.99, \"match_probability\": 0.99608, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018506069469367503}, {\"match_weight\": 8.0, \"match_probability\": 0.99611, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018525840911024716}, {\"match_weight\": 8.01, \"match_probability\": 0.99612, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01856538379433914}, {\"match_weight\": 8.01, \"match_probability\": 0.99614, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018585155235996353}, {\"match_weight\": 8.03, \"match_probability\": 0.99618, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01862469811931078}, {\"match_weight\": 8.03, \"match_probability\": 0.99619, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01864446956096799}, {\"match_weight\": 8.04, \"match_probability\": 0.99622, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018684012444282416}, {\"match_weight\": 8.05, \"match_probability\": 0.99624, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01870378388593963}, {\"match_weight\": 8.05, \"match_probability\": 0.99625, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018743326769254054}, {\"match_weight\": 8.06, \"match_probability\": 0.99626, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018763098210911267}, {\"match_weight\": 8.06, \"match_probability\": 0.99628, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01878286965256848}, {\"match_weight\": 8.07, \"match_probability\": 0.9963, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01880264109422569}, {\"match_weight\": 8.08, \"match_probability\": 0.99632, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01886195542101632}, {\"match_weight\": 8.08, \"match_probability\": 0.99633, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01888172686267353}, {\"match_weight\": 8.1, \"match_probability\": 0.99636, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.018921269745987956}, {\"match_weight\": 8.11, \"match_probability\": 0.99638, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01894104118764517}, {\"match_weight\": 8.11, \"match_probability\": 0.99639, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01896081262930238}, {\"match_weight\": 8.11, \"match_probability\": 0.9964, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.018980584070959594}, {\"match_weight\": 8.12, \"match_probability\": 0.99642, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019000355512616807}, {\"match_weight\": 8.13, \"match_probability\": 0.99644, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01902012695427402}, {\"match_weight\": 8.14, \"match_probability\": 0.99647, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019039898395931232}, {\"match_weight\": 8.15, \"match_probability\": 0.99649, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019059669837588444}, {\"match_weight\": 8.17, \"match_probability\": 0.99653, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01909921272090287}, {\"match_weight\": 8.17, \"match_probability\": 0.99655, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019118984162560082}, {\"match_weight\": 8.19, \"match_probability\": 0.99658, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.019158527045874507}, {\"match_weight\": 8.2, \"match_probability\": 0.99661, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01917829848753172}, {\"match_weight\": 8.2, \"match_probability\": 0.99662, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.019237612814322347}, {\"match_weight\": 8.21, \"match_probability\": 0.99664, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01925738425597956}, {\"match_weight\": 8.22, \"match_probability\": 0.99665, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019277155697636772}, {\"match_weight\": 8.23, \"match_probability\": 0.99667, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.0193364700244274}, {\"match_weight\": 8.24, \"match_probability\": 0.9967, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01935624146608461}, {\"match_weight\": 8.25, \"match_probability\": 0.99673, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.019395784349399037}, {\"match_weight\": 8.26, \"match_probability\": 0.99674, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.019435327232713462}, {\"match_weight\": 8.26, \"match_probability\": 0.99676, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.019534184446456493}, {\"match_weight\": 8.27, \"match_probability\": 0.99677, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019553955888113705}, {\"match_weight\": 8.28, \"match_probability\": 0.99679, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.01959349877142813}, {\"match_weight\": 8.28, \"match_probability\": 0.9968, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.019652813098218758}, {\"match_weight\": 8.29, \"match_probability\": 0.99682, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.01967258453987597}, {\"match_weight\": 8.31, \"match_probability\": 0.99685, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019692355981533183}, {\"match_weight\": 8.31, \"match_probability\": 0.99686, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.01975167030832381}, {\"match_weight\": 8.31, \"match_probability\": 0.99687, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019771441749981022}, {\"match_weight\": 8.33, \"match_probability\": 0.99689, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019791213191638235}, {\"match_weight\": 8.33, \"match_probability\": 0.9969, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019810984633295448}, {\"match_weight\": 8.35, \"match_probability\": 0.99693, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.019870298960086075}, {\"match_weight\": 8.36, \"match_probability\": 0.99696, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019890070401743287}, {\"match_weight\": 8.36, \"match_probability\": 0.99697, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.0199098418434005}, {\"match_weight\": 8.37, \"match_probability\": 0.99699, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.019929613285057712}, {\"match_weight\": 8.38, \"match_probability\": 0.997, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.019969156168372137}, {\"match_weight\": 8.39, \"match_probability\": 0.99703, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020008699051686563}, {\"match_weight\": 8.4, \"match_probability\": 0.99704, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02006801337847719}, {\"match_weight\": 8.4, \"match_probability\": 0.99705, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020087784820134402}, {\"match_weight\": 8.41, \"match_probability\": 0.99707, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020107556261791615}, {\"match_weight\": 8.42, \"match_probability\": 0.99708, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020127327703448827}, {\"match_weight\": 8.42, \"match_probability\": 0.99709, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02014709914510604}, {\"match_weight\": 8.45, \"match_probability\": 0.99714, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020166870586763253}, {\"match_weight\": 8.46, \"match_probability\": 0.99716, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020206413470077678}, {\"match_weight\": 8.46, \"match_probability\": 0.99717, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020245956353392103}, {\"match_weight\": 8.47, \"match_probability\": 0.99719, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020265727795049315}, {\"match_weight\": 8.48, \"match_probability\": 0.99721, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020285499236706528}, {\"match_weight\": 8.49, \"match_probability\": 0.99722, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02030527067836374}, {\"match_weight\": 8.5, \"match_probability\": 0.99724, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020325042120020953}, {\"match_weight\": 8.51, \"match_probability\": 0.99726, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020344813561678166}, {\"match_weight\": 8.51, \"match_probability\": 0.99727, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020364585003335378}, {\"match_weight\": 8.52, \"match_probability\": 0.99728, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02038435644499259}, {\"match_weight\": 8.52, \"match_probability\": 0.99729, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020404127886649803}, {\"match_weight\": 8.53, \"match_probability\": 0.9973, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02044367076996423}, {\"match_weight\": 8.54, \"match_probability\": 0.99732, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02046344221162144}, {\"match_weight\": 8.54, \"match_probability\": 0.99733, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020502985094935866}, {\"match_weight\": 8.56, \"match_probability\": 0.99735, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02054252797825029}, {\"match_weight\": 8.56, \"match_probability\": 0.99737, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.020582070861564716}, {\"match_weight\": 8.6, \"match_probability\": 0.99742, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02062161374487914}, {\"match_weight\": 8.61, \"match_probability\": 0.99745, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020641385186536354}, {\"match_weight\": 8.61, \"match_probability\": 0.99746, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02068092806985078}, {\"match_weight\": 8.62, \"match_probability\": 0.99747, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02070069951150799}, {\"match_weight\": 8.63, \"match_probability\": 0.99748, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020720470953165204}, {\"match_weight\": 8.64, \"match_probability\": 0.99749, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020740242394822417}, {\"match_weight\": 8.64, \"match_probability\": 0.9975, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02076001383647963}, {\"match_weight\": 8.65, \"match_probability\": 0.99751, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020779785278136842}, {\"match_weight\": 8.65, \"match_probability\": 0.99752, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020799556719794055}, {\"match_weight\": 8.66, \"match_probability\": 0.99753, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.020819328161451267}, {\"match_weight\": 8.67, \"match_probability\": 0.99755, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02083909960310848}, {\"match_weight\": 8.68, \"match_probability\": 0.99757, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.020977499696527957}, {\"match_weight\": 8.68, \"match_probability\": 0.99758, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02099727113818517}, {\"match_weight\": 8.7, \"match_probability\": 0.99759, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021017042579842382}, {\"match_weight\": 8.7, \"match_probability\": 0.9976, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021056585463156807}, {\"match_weight\": 8.72, \"match_probability\": 0.99764, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02107635690481402}, {\"match_weight\": 8.73, \"match_probability\": 0.99765, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021096128346471232}, {\"match_weight\": 8.73, \"match_probability\": 0.99766, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021115899788128445}, {\"match_weight\": 8.74, \"match_probability\": 0.99767, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021135671229785657}, {\"match_weight\": 8.75, \"match_probability\": 0.99768, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021175214113100083}, {\"match_weight\": 8.76, \"match_probability\": 0.9977, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021194985554757295}, {\"match_weight\": 8.78, \"match_probability\": 0.99772, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021254299881547922}, {\"match_weight\": 8.79, \"match_probability\": 0.99774, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02131361420833855}, {\"match_weight\": 8.79, \"match_probability\": 0.99775, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021353157091652974}, {\"match_weight\": 8.8, \"match_probability\": 0.99776, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021372928533310187}, {\"match_weight\": 8.82, \"match_probability\": 0.99779, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021412471416624612}, {\"match_weight\": 8.83, \"match_probability\": 0.9978, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021452014299939037}, {\"match_weight\": 8.83, \"match_probability\": 0.99781, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021511328626729664}, {\"match_weight\": 8.85, \"match_probability\": 0.99783, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021531100068386877}, {\"match_weight\": 8.85, \"match_probability\": 0.99784, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02155087151004409}, {\"match_weight\": 8.87, \"match_probability\": 0.99786, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021610185836834717}, {\"match_weight\": 8.87, \"match_probability\": 0.99787, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02162995727849193}, {\"match_weight\": 8.88, \"match_probability\": 0.99788, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021669500161806354}, {\"match_weight\": 8.89, \"match_probability\": 0.99789, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02172881448859698}, {\"match_weight\": 8.89, \"match_probability\": 0.9979, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021748585930254194}, {\"match_weight\": 8.9, \"match_probability\": 0.99791, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.021768357371911407}, {\"match_weight\": 8.91, \"match_probability\": 0.99792, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02180790025522583}, {\"match_weight\": 8.91, \"match_probability\": 0.99793, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021847443138540257}, {\"match_weight\": 8.92, \"match_probability\": 0.99794, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021886986021854682}, {\"match_weight\": 8.94, \"match_probability\": 0.99796, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.021926528905169107}, {\"match_weight\": 8.94, \"match_probability\": 0.99797, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.021985843231959734}, {\"match_weight\": 8.96, \"match_probability\": 0.99799, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.022064928998588584}, {\"match_weight\": 8.97, \"match_probability\": 0.998, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.022163786212331615}, {\"match_weight\": 8.97, \"match_probability\": 0.99801, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.022242871978960466}, {\"match_weight\": 8.98, \"match_probability\": 0.99802, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.022302186305751093}, {\"match_weight\": 8.98, \"match_probability\": 0.99803, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022321957747408305}, {\"match_weight\": 8.99, \"match_probability\": 0.99804, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022341729189065518}, {\"match_weight\": 9.0, \"match_probability\": 0.99806, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02236150063072273}, {\"match_weight\": 9.02, \"match_probability\": 0.99807, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.022420814957513358}, {\"match_weight\": 9.02, \"match_probability\": 0.99808, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.022460357840827783}, {\"match_weight\": 9.03, \"match_probability\": 0.99809, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.022499900724142208}, {\"match_weight\": 9.04, \"match_probability\": 0.9981, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.022559215050932835}, {\"match_weight\": 9.07, \"match_probability\": 0.99814, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022578986492590047}, {\"match_weight\": 9.08, \"match_probability\": 0.99815, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02259875793424726}, {\"match_weight\": 9.08, \"match_probability\": 0.99816, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022618529375904473}, {\"match_weight\": 9.09, \"match_probability\": 0.99817, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.022658072259218898}, {\"match_weight\": 9.1, \"match_probability\": 0.99818, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02267784370087611}, {\"match_weight\": 9.12, \"match_probability\": 0.9982, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022697615142533323}, {\"match_weight\": 9.12, \"match_probability\": 0.99821, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02275692946932395}, {\"match_weight\": 9.13, \"match_probability\": 0.99822, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022776700910981162}, {\"match_weight\": 9.14, \"match_probability\": 0.99823, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02283601523777179}, {\"match_weight\": 9.14, \"match_probability\": 0.99824, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022855786679429002}, {\"match_weight\": 9.16, \"match_probability\": 0.99825, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.022875558121086215}, {\"match_weight\": 9.17, \"match_probability\": 0.99826, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02299418677466747}, {\"match_weight\": 9.17, \"match_probability\": 0.99827, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.023112815428248723}, {\"match_weight\": 9.18, \"match_probability\": 0.99828, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023152358311563148}, {\"match_weight\": 9.19, \"match_probability\": 0.99829, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02317212975322036}, {\"match_weight\": 9.2, \"match_probability\": 0.9983, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023211672636534786}, {\"match_weight\": 9.21, \"match_probability\": 0.99831, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.023290758403163636}, {\"match_weight\": 9.23, \"match_probability\": 0.99833, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.023350072729954263}, {\"match_weight\": 9.23, \"match_probability\": 0.99834, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02340938705674489}, {\"match_weight\": 9.24, \"match_probability\": 0.99835, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.023429158498402103}, {\"match_weight\": 9.26, \"match_probability\": 0.99837, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02348847282519273}, {\"match_weight\": 9.27, \"match_probability\": 0.99838, \"prop\": 0.000316343066515401, \"cum_prop\": 0.02380481589170813}, {\"match_weight\": 9.28, \"match_probability\": 0.99839, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.023864130218498758}, {\"match_weight\": 9.29, \"match_probability\": 0.9984, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.023923444545289385}, {\"match_weight\": 9.3, \"match_probability\": 0.99841, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.023943215986946598}, {\"match_weight\": 9.3, \"match_probability\": 0.99842, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.023982758870261023}, {\"match_weight\": 9.33, \"match_probability\": 0.99844, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02404207319705165}, {\"match_weight\": 9.34, \"match_probability\": 0.99845, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.024101387523842277}, {\"match_weight\": 9.34, \"match_probability\": 0.99846, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.024160701850632904}, {\"match_weight\": 9.39, \"match_probability\": 0.99851, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02422001617742353}, {\"match_weight\": 9.4, \"match_probability\": 0.99852, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024259559060737956}, {\"match_weight\": 9.41, \"match_probability\": 0.99853, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.024338644827366807}, {\"match_weight\": 9.42, \"match_probability\": 0.99854, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02437818771068123}, {\"match_weight\": 9.43, \"match_probability\": 0.99855, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024417730593995657}, {\"match_weight\": 9.44, \"match_probability\": 0.99856, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.024477044920786284}, {\"match_weight\": 9.45, \"match_probability\": 0.99857, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02451658780410071}, {\"match_weight\": 9.47, \"match_probability\": 0.99859, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024556130687415134}, {\"match_weight\": 9.48, \"match_probability\": 0.9986, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02459567357072956}, {\"match_weight\": 9.49, \"match_probability\": 0.99861, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024635216454043984}, {\"match_weight\": 9.5, \"match_probability\": 0.99862, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.024714302220672835}, {\"match_weight\": 9.5, \"match_probability\": 0.99863, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.024734073662330047}, {\"match_weight\": 9.52, \"match_probability\": 0.99864, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.024773616545644472}, {\"match_weight\": 9.54, \"match_probability\": 0.99865, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.0248329308724351}, {\"match_weight\": 9.54, \"match_probability\": 0.99866, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02491201663906395}, {\"match_weight\": 9.56, \"match_probability\": 0.99867, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.025050416732483427}, {\"match_weight\": 9.57, \"match_probability\": 0.99868, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.025109731059274054}, {\"match_weight\": 9.57, \"match_probability\": 0.99869, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.025129502500931267}, {\"match_weight\": 9.59, \"match_probability\": 0.9987, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02514927394258848}, {\"match_weight\": 9.6, \"match_probability\": 0.99871, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.025169045384245692}, {\"match_weight\": 9.61, \"match_probability\": 0.99872, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.025248131150874542}, {\"match_weight\": 9.62, \"match_probability\": 0.99873, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02530744547766517}, {\"match_weight\": 9.63, \"match_probability\": 0.99874, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.025346988360979594}, {\"match_weight\": 9.64, \"match_probability\": 0.99875, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.025426074127608445}, {\"match_weight\": 9.66, \"match_probability\": 0.99876, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.025505159894237295}, {\"match_weight\": 9.67, \"match_probability\": 0.99877, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.025564474221027922}, {\"match_weight\": 9.69, \"match_probability\": 0.99879, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02562378854781855}, {\"match_weight\": 9.7, \"match_probability\": 0.9988, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.025683102874609176}, {\"match_weight\": 9.72, \"match_probability\": 0.99881, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02580173152819043}, {\"match_weight\": 9.72, \"match_probability\": 0.99882, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.025821502969847643}, {\"match_weight\": 9.74, \"match_probability\": 0.99883, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.025979674503105343}, {\"match_weight\": 9.75, \"match_probability\": 0.99884, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02603898882989597}, {\"match_weight\": 9.77, \"match_probability\": 0.99885, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02611807459652482}, {\"match_weight\": 9.78, \"match_probability\": 0.99886, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02619716036315367}, {\"match_weight\": 9.79, \"match_probability\": 0.99887, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.026296017576896702}, {\"match_weight\": 9.81, \"match_probability\": 0.99888, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.026454189110154402}, {\"match_weight\": 9.82, \"match_probability\": 0.99889, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.026553046323897433}, {\"match_weight\": 9.83, \"match_probability\": 0.9989, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.026632132090526284}, {\"match_weight\": 9.85, \"match_probability\": 0.99891, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.026750760744107538}, {\"match_weight\": 9.87, \"match_probability\": 0.99893, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02677053218576475}, {\"match_weight\": 9.89, \"match_probability\": 0.99894, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.026810075069079176}, {\"match_weight\": 9.9, \"match_probability\": 0.99895, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02692870372266043}, {\"match_weight\": 9.93, \"match_probability\": 0.99897, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02702756093640346}, {\"match_weight\": 9.94, \"match_probability\": 0.99898, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.027067103819717886}, {\"match_weight\": 9.95, \"match_probability\": 0.99899, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02710664670303231}, {\"match_weight\": 9.96, \"match_probability\": 0.999, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.027205503916775342}, {\"match_weight\": 9.98, \"match_probability\": 0.99901, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.02726481824356597}, {\"match_weight\": 10.0, \"match_probability\": 0.99902, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.027324132570356596}, {\"match_weight\": 10.01, \"match_probability\": 0.99903, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.027422989784099627}, {\"match_weight\": 10.02, \"match_probability\": 0.99904, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02754161843768088}, {\"match_weight\": 10.05, \"match_probability\": 0.99905, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.027581161320995307}, {\"match_weight\": 10.06, \"match_probability\": 0.99906, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.027680018534738338}, {\"match_weight\": 10.07, \"match_probability\": 0.99907, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.027739332861528965}, {\"match_weight\": 10.09, \"match_probability\": 0.99908, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02785796151511022}, {\"match_weight\": 10.1, \"match_probability\": 0.99909, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.027897504398424644}, {\"match_weight\": 10.11, \"match_probability\": 0.9991, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.02793704728173907}, {\"match_weight\": 10.14, \"match_probability\": 0.99911, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.027976590165053494}, {\"match_weight\": 10.15, \"match_probability\": 0.99912, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.028075447378796525}, {\"match_weight\": 10.17, \"match_probability\": 0.99913, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.028154533145425376}, {\"match_weight\": 10.19, \"match_probability\": 0.99914, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.028213847472216003}, {\"match_weight\": 10.2, \"match_probability\": 0.99915, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.02835224756563548}, {\"match_weight\": 10.22, \"match_probability\": 0.99916, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.02843133333226433}, {\"match_weight\": 10.24, \"match_probability\": 0.99917, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.028490647659054957}, {\"match_weight\": 10.26, \"match_probability\": 0.99918, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.02860927631263621}, {\"match_weight\": 10.28, \"match_probability\": 0.99919, \"prop\": 0.0009490292286500335, \"cum_prop\": 0.029558305541286245}, {\"match_weight\": 10.3, \"match_probability\": 0.9992, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.029854877182515338}, {\"match_weight\": 10.31, \"match_probability\": 0.99921, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.02995373439625837}, {\"match_weight\": 10.33, \"match_probability\": 0.99922, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.02997350583791558}, {\"match_weight\": 10.34, \"match_probability\": 0.99923, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.030072363051658613}, {\"match_weight\": 10.37, \"match_probability\": 0.99924, \"prop\": 3.9542883314425126e-05, \"cum_prop\": 0.030111905934973038}, {\"match_weight\": 10.38, \"match_probability\": 0.99925, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.030171220261763665}, {\"match_weight\": 10.4, \"match_probability\": 0.99926, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.030250306028392515}, {\"match_weight\": 10.43, \"match_probability\": 0.99927, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.03042824900148844}, {\"match_weight\": 10.45, \"match_probability\": 0.99928, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.030566649094907916}, {\"match_weight\": 10.46, \"match_probability\": 0.99929, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.030645734861536766}, {\"match_weight\": 10.48, \"match_probability\": 0.9993, \"prop\": 5.931432679062709e-05, \"cum_prop\": 0.030705049188327393}, {\"match_weight\": 10.51, \"match_probability\": 0.99931, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.030823677841908648}, {\"match_weight\": 10.52, \"match_probability\": 0.99932, \"prop\": 1.9771441657212563e-05, \"cum_prop\": 0.03084344928356586}, {\"match_weight\": 10.55, \"match_probability\": 0.99933, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.031021392256661784}, {\"match_weight\": 10.57, \"match_probability\": 0.99934, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.031120249470404815}, {\"match_weight\": 10.59, \"match_probability\": 0.99935, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.031199335237033665}, {\"match_weight\": 10.62, \"match_probability\": 0.99936, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.03131796389061492}, {\"match_weight\": 10.64, \"match_probability\": 0.99937, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.03149590686371084}, {\"match_weight\": 10.67, \"match_probability\": 0.99938, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.0316145355172921}, {\"match_weight\": 10.68, \"match_probability\": 0.99939, \"prop\": 0.00011862865358125418, \"cum_prop\": 0.03173316417087335}, {\"match_weight\": 10.71, \"match_probability\": 0.9994, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03189133570413105}, {\"match_weight\": 10.73, \"match_probability\": 0.99941, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.03199019291787408}, {\"match_weight\": 10.76, \"match_probability\": 0.99942, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.032089050131617114}, {\"match_weight\": 10.79, \"match_probability\": 0.99943, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.03232630743877962}, {\"match_weight\": 10.81, \"match_probability\": 0.99944, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03248447897203732}, {\"match_weight\": 10.83, \"match_probability\": 0.99945, \"prop\": 9.885721374303102e-05, \"cum_prop\": 0.032583336185780354}, {\"match_weight\": 10.87, \"match_probability\": 0.99946, \"prop\": 0.00013840009341947734, \"cum_prop\": 0.03272173627919983}, {\"match_weight\": 10.89, \"match_probability\": 0.99947, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03287990781245753}, {\"match_weight\": 10.92, \"match_probability\": 0.99948, \"prop\": 7.908576662885025e-05, \"cum_prop\": 0.03295899357908638}, {\"match_weight\": 10.95, \"match_probability\": 0.99949, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.03323579376592534}, {\"match_weight\": 10.97, \"match_probability\": 0.9995, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.033473051073087845}, {\"match_weight\": 11.0, \"match_probability\": 0.99951, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03376962271431694}, {\"match_weight\": 11.03, \"match_probability\": 0.99952, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03392779424757464}, {\"match_weight\": 11.07, \"match_probability\": 0.99953, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03422436588880373}, {\"match_weight\": 11.1, \"match_probability\": 0.99954, \"prop\": 0.00017794297309592366, \"cum_prop\": 0.034402308861899655}, {\"match_weight\": 11.13, \"match_probability\": 0.99955, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.034639566169062164}, {\"match_weight\": 11.16, \"match_probability\": 0.99956, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.03487682347622467}, {\"match_weight\": 11.2, \"match_probability\": 0.99957, \"prop\": 0.00025702876155264676, \"cum_prop\": 0.03513385223777732}, {\"match_weight\": 11.23, \"match_probability\": 0.99958, \"prop\": 0.0001581715332577005, \"cum_prop\": 0.03529202377103502}, {\"match_weight\": 11.26, \"match_probability\": 0.99959, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.03552928107819753}, {\"match_weight\": 11.3, \"match_probability\": 0.9996, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03582585271942662}, {\"match_weight\": 11.34, \"match_probability\": 0.99961, \"prop\": 0.0003558859461918473, \"cum_prop\": 0.03618173866561847}, {\"match_weight\": 11.38, \"match_probability\": 0.99962, \"prop\": 0.0003361145209055394, \"cum_prop\": 0.03651785318652401}, {\"match_weight\": 11.42, \"match_probability\": 0.99963, \"prop\": 0.00019771442748606205, \"cum_prop\": 0.03671556761401007}, {\"match_weight\": 11.46, \"match_probability\": 0.99964, \"prop\": 0.00025702876155264676, \"cum_prop\": 0.036972596375562716}, {\"match_weight\": 11.49, \"match_probability\": 0.99965, \"prop\": 0.00025702876155264676, \"cum_prop\": 0.03722962513711536}, {\"match_weight\": 11.54, \"match_probability\": 0.99966, \"prop\": 0.0003361145209055394, \"cum_prop\": 0.0375657396580209}, {\"match_weight\": 11.58, \"match_probability\": 0.99967, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.03784253984485986}, {\"match_weight\": 11.63, \"match_probability\": 0.99968, \"prop\": 0.0002768001868389547, \"cum_prop\": 0.03811934003169881}, {\"match_weight\": 11.67, \"match_probability\": 0.99969, \"prop\": 0.0002174858673242852, \"cum_prop\": 0.0383368258990231}, {\"match_weight\": 11.73, \"match_probability\": 0.9997, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.038574083206185605}, {\"match_weight\": 11.78, \"match_probability\": 0.99971, \"prop\": 0.00023725730716250837, \"cum_prop\": 0.038811340513348114}, {\"match_weight\": 11.83, \"match_probability\": 0.99972, \"prop\": 0.0002965716412290931, \"cum_prop\": 0.03910791215457721}, {\"match_weight\": 11.88, \"match_probability\": 0.99973, \"prop\": 0.0003954288549721241, \"cum_prop\": 0.03950334100954933}, {\"match_weight\": 11.93, \"match_probability\": 0.99974, \"prop\": 0.0004942860687151551, \"cum_prop\": 0.039997627078264486}, {\"match_weight\": 11.99, \"match_probability\": 0.99975, \"prop\": 0.0003954288549721241, \"cum_prop\": 0.04039305593323661}, {\"match_weight\": 12.05, \"match_probability\": 0.99976, \"prop\": 0.0004942860687151551, \"cum_prop\": 0.040887342001951765}, {\"match_weight\": 12.12, \"match_probability\": 0.99977, \"prop\": 0.0006920004962012172, \"cum_prop\": 0.04157934249815298}, {\"match_weight\": 12.18, \"match_probability\": 0.99978, \"prop\": 0.0009094863198697567, \"cum_prop\": 0.04248882881802274}, {\"match_weight\": 12.25, \"match_probability\": 0.99979, \"prop\": 0.0008304005605168641, \"cum_prop\": 0.0433192293785396}, {\"match_weight\": 12.32, \"match_probability\": 0.9998, \"prop\": 0.0003756574005819857, \"cum_prop\": 0.04369488677912159}, {\"match_weight\": 12.4, \"match_probability\": 0.99981, \"prop\": 0.0005140575231052935, \"cum_prop\": 0.04420894430222688}, {\"match_weight\": 12.48, \"match_probability\": 0.99982, \"prop\": 0.0003954288549721241, \"cum_prop\": 0.044604373157199007}, {\"match_weight\": 12.56, \"match_probability\": 0.99983, \"prop\": 0.0008106291061267257, \"cum_prop\": 0.04541500226332573}, {\"match_weight\": 12.65, \"match_probability\": 0.99984, \"prop\": 0.0010083435336127877, \"cum_prop\": 0.04642334579693852}, {\"match_weight\": 12.74, \"match_probability\": 0.99985, \"prop\": 0.0005536003736779094, \"cum_prop\": 0.04697694617061643}, {\"match_weight\": 12.85, \"match_probability\": 0.99986, \"prop\": 0.0009292577742598951, \"cum_prop\": 0.047906203944876324}, {\"match_weight\": 12.96, \"match_probability\": 0.99987, \"prop\": 0.0010478864423930645, \"cum_prop\": 0.04895409038726939}, {\"match_weight\": 13.09, \"match_probability\": 0.99988, \"prop\": 0.0008501720149070024, \"cum_prop\": 0.04980426240217639}, {\"match_weight\": 13.22, \"match_probability\": 0.99989, \"prop\": 0.0016805726336315274, \"cum_prop\": 0.05148483503580792}, {\"match_weight\": 13.36, \"match_probability\": 0.9999, \"prop\": 0.0011269721435382962, \"cum_prop\": 0.052611807179346215}, {\"match_weight\": 13.52, \"match_probability\": 0.99991, \"prop\": 0.001561943907290697, \"cum_prop\": 0.05417375108663691}, {\"match_weight\": 13.7, \"match_probability\": 0.99992, \"prop\": 0.0015224009985104203, \"cum_prop\": 0.05569615208514733}, {\"match_weight\": 13.91, \"match_probability\": 0.99993, \"prop\": 0.0018585155485197902, \"cum_prop\": 0.05755466763366712}, {\"match_weight\": 14.14, \"match_probability\": 0.99994, \"prop\": 0.0032820594497025013, \"cum_prop\": 0.060836727083369624}, {\"match_weight\": 14.44, \"match_probability\": 0.99995, \"prop\": 0.0028470875695347786, \"cum_prop\": 0.0636838146529044}, {\"match_weight\": 14.8, \"match_probability\": 0.99996, \"prop\": 0.0032425164245069027, \"cum_prop\": 0.0669263310774113}, {\"match_weight\": 15.29, \"match_probability\": 0.99997, \"prop\": 0.005338289309293032, \"cum_prop\": 0.07226462038670434}, {\"match_weight\": 16.02, \"match_probability\": 0.99998, \"prop\": 0.008442405611276627, \"cum_prop\": 0.08070702599798096}, {\"match_weight\": 17.61, \"match_probability\": 0.99999, \"prop\": 0.019494641572237015, \"cum_prop\": 0.10020166757021798}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.evaluation.unlinkables_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:52.085817Z",
     "iopub.status.busy": "2024-06-07T09:09:52.085551Z",
     "iopub.status.idle": "2024-06-07T09:09:54.516650Z",
     "shell.execute_reply": "2024-06-07T09:09:54.515921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>unique_id_l</th>\n",
       "      <th>unique_id_r</th>\n",
       "      <th>first_name_l</th>\n",
       "      <th>first_name_r</th>\n",
       "      <th>gamma_first_name</th>\n",
       "      <th>tf_first_name_l</th>\n",
       "      <th>tf_first_name_r</th>\n",
       "      <th>bf_first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>bf_birth_place</th>\n",
       "      <th>bf_tf_adj_birth_place</th>\n",
       "      <th>occupation_l</th>\n",
       "      <th>occupation_r</th>\n",
       "      <th>gamma_occupation</th>\n",
       "      <th>tf_occupation_l</th>\n",
       "      <th>tf_occupation_r</th>\n",
       "      <th>bf_occupation</th>\n",
       "      <th>bf_tf_adj_occupation</th>\n",
       "      <th>match_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.829333</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q7528564-9</td>\n",
       "      <td>Q75867928-1</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>38.34881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>historian</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.829333</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q7528564-9</td>\n",
       "      <td>Q75867928-2</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>38.34881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>historian</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.829333</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q7528564-9</td>\n",
       "      <td>Q75867928-3</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>38.34881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>historian</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.829333</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q7528564-9</td>\n",
       "      <td>Q75867928-4</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>38.34881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>historian</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.829333</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Q7528564-9</td>\n",
       "      <td>Q75867928-6</td>\n",
       "      <td>sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>38.34881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>historian</td>\n",
       "      <td>military officer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.105028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_weight  match_probability unique_id_l  unique_id_r first_name_l  \\\n",
       "0    -15.829333           0.000017  Q7528564-9  Q75867928-1          sir   \n",
       "1    -15.829333           0.000017  Q7528564-9  Q75867928-2          sir   \n",
       "2    -15.829333           0.000017  Q7528564-9  Q75867928-3          sir   \n",
       "3    -15.829333           0.000017  Q7528564-9  Q75867928-4          sir   \n",
       "4    -15.829333           0.000017  Q7528564-9  Q75867928-6          sir   \n",
       "\n",
       "  first_name_r  gamma_first_name  tf_first_name_l  tf_first_name_r  \\\n",
       "0          sir                 3         0.024985         0.024985   \n",
       "1          sir                 3         0.024985         0.024985   \n",
       "2          sir                 3         0.024985         0.024985   \n",
       "3          sir                 3         0.024985         0.024985   \n",
       "4          sir                 3         0.024985         0.024985   \n",
       "\n",
       "   bf_first_name  ...  bf_birth_place bf_tf_adj_birth_place occupation_l  \\\n",
       "0       38.34881  ...        0.157016                   1.0    historian   \n",
       "1       38.34881  ...        0.157016                   1.0    historian   \n",
       "2       38.34881  ...        0.157016                   1.0    historian   \n",
       "3       38.34881  ...        0.157016                   1.0    historian   \n",
       "4       38.34881  ...        0.157016                   1.0    historian   \n",
       "\n",
       "       occupation_r  gamma_occupation  tf_occupation_l  tf_occupation_r  \\\n",
       "0  military officer                 0         0.012456         0.010756   \n",
       "1  military officer                 0         0.012456         0.010756   \n",
       "2  military officer                 0         0.012456         0.010756   \n",
       "3  military officer                 0         0.012456         0.010756   \n",
       "4  military officer                 0         0.012456         0.010756   \n",
       "\n",
       "   bf_occupation bf_tf_adj_occupation match_key  \n",
       "0       0.105028                  1.0         0  \n",
       "1       0.105028                  1.0         0  \n",
       "2       0.105028                  1.0         0  \n",
       "3       0.105028                  1.0         0  \n",
       "4       0.105028                  1.0         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = linker.inference.predict()\n",
    "df_e = df_predict.as_pandas_dataframe(limit=5)\n",
    "df_e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view rows in this dataset as a waterfall chart as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:54.520577Z",
     "iopub.status.busy": "2024-06-07T09:09:54.520273Z",
     "iopub.status.idle": "2024-06-07T09:09:55.151653Z",
     "shell.execute_reply": "2024-06-07T09:09:55.150935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8d620cac45c8488a8ffe95fec42c0393.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8d620cac45c8488a8ffe95fec42c0393.vega-embed details,\n",
       "  #altair-viz-8d620cac45c8488a8ffe95fec42c0393.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8d620cac45c8488a8ffe95fec42c0393\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8d620cac45c8488a8ffe95fec42c0393\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8d620cac45c8488a8ffe95fec42c0393\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-4395903f8dfb567b4d5d9bcac13870d7\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 4, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-4395903f8dfb567b4d5d9bcac13870d7\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5762699350813897, \"log2_bayes_factor\": -0.7951833408931542, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.74 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.05203069517288988, \"log2_bayes_factor\": -4.264493206738789, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  19.22 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1650-03-25\", \"value_r\": \"1858-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ex6 7qq\", \"value_r\": \"nw2 1lp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"teignbridge\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"historian\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.829332711276658, \"bayes_factor\": 1.7174972191793332e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5762699350813897, \"log2_bayes_factor\": -0.7951833408931542, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.74 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.05203069517288988, \"log2_bayes_factor\": -4.264493206738789, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  19.22 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1650-03-25\", \"value_r\": \"1858-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ex6 7qq\", \"value_r\": \"nw2 1lp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"teignbridge\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"historian\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.829332711276658, \"bayes_factor\": 1.7174972191793332e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5762699350813897, \"log2_bayes_factor\": -0.7951833408931542, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.74 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.05203069517288988, \"log2_bayes_factor\": -4.264493206738789, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  19.22 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1650-03-25\", \"value_r\": \"1858-03-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ex6 7qq\", \"value_r\": \"nw2 1lp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"teignbridge\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"historian\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.829332711276658, \"bayes_factor\": 1.7174972191793332e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5762699350813897, \"log2_bayes_factor\": -0.7951833408931542, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.74 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.05203069517288988, \"log2_bayes_factor\": -4.264493206738789, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  19.22 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1650-03-25\", \"value_r\": \"1848-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ex6 7qq\", \"value_r\": \"nw2 1tj\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"teignbridge\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"historian\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.829332711276658, \"bayes_factor\": 1.7174972191793332e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5762699350813897, \"log2_bayes_factor\": -0.7951833408931542, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.74 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"sir\", \"value_r\": \"sir\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.05203069517288988, \"log2_bayes_factor\": -4.264493206738789, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  19.22 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"baronet\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1650-03-25\", \"value_r\": \"1858-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ex6 7qq\", \"value_r\": \"n3 1eu\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"teignbridge\", \"value_r\": \"barnet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"historian\", \"value_r\": \"military officer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -15.829332711276658, \"bayes_factor\": 1.7174972191793332e-05, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "records_to_plot = df_e.to_dict(orient=\"records\")\n",
    "linker.visualisations.waterfall_chart(records_to_plot, filter_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:55.155050Z",
     "iopub.status.busy": "2024-06-07T09:09:55.154811Z",
     "iopub.status.idle": "2024-06-07T09:09:55.525689Z",
     "shell.execute_reply": "2024-06-07T09:09:55.524936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 1, root rows count 623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 2, root rows count 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 3, root rows count 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 4, root rows count 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed iteration 5, root rows count 0\n"
     ]
    }
   ],
   "source": [
    "clusters = linker.clustering.cluster_pairwise_predictions_at_threshold(\n",
    "    df_predict, threshold_match_probability=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:55.528997Z",
     "iopub.status.busy": "2024-06-07T09:09:55.528732Z",
     "iopub.status.idle": "2024-06-07T09:09:55.705059Z",
     "shell.execute_reply": "2024-06-07T09:09:55.704305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"./dashboards/50k_cluster.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12e35bc10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "linker.visualisations.cluster_studio_dashboard(\n",
    "    df_predict,\n",
    "    clusters,\n",
    "    \"dashboards/50k_cluster.html\",\n",
    "    sampling_method=\"by_cluster_size\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "\n",
    "IFrame(src=\"./dashboards/50k_cluster.html\", width=\"100%\", height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:09:55.708587Z",
     "iopub.status.busy": "2024-06-07T09:09:55.708313Z",
     "iopub.status.idle": "2024-06-07T09:10:07.358895Z",
     "shell.execute_reply": "2024-06-07T09:10:07.358097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d87c2e63b41e4fbd84e6a52e31706267.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d87c2e63b41e4fbd84e6a52e31706267.vega-embed details,\n",
       "  #altair-viz-d87c2e63b41e4fbd84e6a52e31706267.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d87c2e63b41e4fbd84e6a52e31706267\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d87c2e63b41e4fbd84e6a52e31706267\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d87c2e63b41e4fbd84e6a52e31706267\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9f8ab7cbf1681431804dd53755e2a3c7\"}, \"mark\": {\"type\": \"line\", \"clip\": true, \"point\": true}, \"encoding\": {\"tooltip\": [{\"field\": \"truth_threshold\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"match_probability\", \"format\": \".4%\", \"type\": \"quantitative\"}, {\"field\": \"fp_rate\", \"format\": \".4f\", \"title\": \"FP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp_rate\", \"format\": \".4f\", \"title\": \"TP_rate\", \"type\": \"quantitative\"}, {\"field\": \"tp\", \"format\": \",.0f\", \"title\": \"TP\", \"type\": \"quantitative\"}, {\"field\": \"tn\", \"format\": \",.0f\", \"title\": \"TN\", \"type\": \"quantitative\"}, {\"field\": \"fp\", \"format\": \",.0f\", \"title\": \"FP\", \"type\": \"quantitative\"}, {\"field\": \"fn\", \"format\": \",.0f\", \"title\": \"FN\", \"type\": \"quantitative\"}, {\"field\": \"precision\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"recall\", \"format\": \".4f\", \"type\": \"quantitative\"}, {\"field\": \"f1\", \"format\": \".4f\", \"title\": \"F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"fp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"False Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"tp_rate\", \"sort\": [\"truth_threshold\"], \"title\": \"True Positive Rate amongst clerically reviewed records\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"mouse_zoom\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\"]}, \"bind\": \"scales\"}], \"title\": \"Receiver operating characteristic curve\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-9f8ab7cbf1681431804dd53755e2a3c7\": [{\"truth_threshold\": -15.819999646395445, \"match_probability\": 1.728614165908125e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278563923.0, \"fp\": 173869.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998640307644868, \"fp_rate\": 0.0001359692355131395, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4336938926399651, \"recall\": 0.43806277779057184, \"specificity\": 0.9998640307644868, \"npv\": 0.9998664249933995, \"accuracy\": 0.9997305201341617, \"f1\": 0.43586738768936667, \"f2\": 0.4371819732123685, \"f0_5\": 0.43456068425831224, \"p4\": 0.607088869043114, \"phi\": 0.43573809360359683}, {\"truth_threshold\": -15.339999657124281, \"match_probability\": 2.4109571901395096e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278579234.0, \"fp\": 158558.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998760042903307, \"fp_rate\": 0.0001239957096693049, \"fn_rate\": 0.5619372222094282, \"precision\": 0.45645705353225097, \"recall\": 0.43806277779057184, \"specificity\": 0.9998760042903307, \"npv\": 0.999866426592748, \"accuracy\": 0.9997424908145278, \"f1\": 0.4470707921963896, \"f2\": 0.44162206909726737, \"f0_5\": 0.4526556473342222, \"p4\": 0.6178730232711644, \"phi\": 0.4470366306253448}, {\"truth_threshold\": -14.879999667406082, \"match_probability\": 3.316342386477646e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278579253.0, \"fp\": 158539.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998760191487326, \"fp_rate\": 0.00012398085126743481, \"fn_rate\": 0.5619372222094282, \"precision\": 0.45648678576448526, \"recall\": 0.43806277779057184, \"specificity\": 0.9998760191487326, \"npv\": 0.9998664265947327, \"accuracy\": 0.9997425056693986, \"f1\": 0.44708505273195515, \"f2\": 0.44162763500995333, \"f0_5\": 0.4526790382754722, \"p4\": 0.6178866437592794, \"phi\": 0.4470512015418176}, {\"truth_threshold\": -14.699999671429396, \"match_probability\": 3.757014280558493e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589482.0, \"fp\": 148310.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840184430867, \"fp_rate\": 0.00011598155691327217, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4730764858028025, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840184430867, \"npv\": 0.9998664276632069, \"accuracy\": 0.9997505030627409, \"f1\": 0.45489686979544774, \"f2\": 0.4446446556085989, \"f0_5\": 0.4656330145745924, \"p4\": 0.6253077184774316, \"phi\": 0.4551085955613794}, {\"truth_threshold\": -14.579999674111605, \"match_probability\": 4.08286508550847e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589502.0, \"fp\": 148290.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840340835098, \"fp_rate\": 0.00011596591649025103, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4731101036085331, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840340835098, \"npv\": 0.999866427665296, \"accuracy\": 0.999750518699447, \"f1\": 0.4549124110658433, \"f2\": 0.4446505949423224, \"f0_5\": 0.465659068765794, \"p4\": 0.6253224029651865, \"phi\": 0.45512477845381616}, {\"truth_threshold\": -14.55999967455864, \"match_probability\": 4.139857397374142e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589526.0, \"fp\": 148266.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840528520174, \"fp_rate\": 0.00011594714798262567, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47315045128278016, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840528520174, \"npv\": 0.9998664276678029, \"accuracy\": 0.9997505374634944, \"f1\": 0.4549310619921043, \"f2\": 0.44465772235223716, \"f0_5\": 0.4656903376442058, \"p4\": 0.6253400252609084, \"phi\": 0.45514420020127366}, {\"truth_threshold\": -14.539999675005674, \"match_probability\": 4.1976452259158474e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589542.0, \"fp\": 148250.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840653643558, \"fp_rate\": 0.00011593463564420876, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4731773535557419, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840653643558, \"npv\": 0.9998664276694741, \"accuracy\": 0.9997505499728593, \"f1\": 0.4549434967925995, \"f2\": 0.4446624740857894, \"f0_5\": 0.4657111858962476, \"p4\": 0.6253517740098626, \"phi\": 0.45515714941287433}, {\"truth_threshold\": -14.51999967545271, \"match_probability\": 4.256239674267579e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589554.0, \"fp\": 148238.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840747486096, \"fp_rate\": 0.00011592525139039607, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4731975322681526, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840747486096, \"npv\": 0.9998664276707276, \"accuracy\": 0.9997505593548829, \"f1\": 0.45495282333907916, \"f2\": 0.4446660379526007, \"f0_5\": 0.4657268233103351, \"p4\": 0.6253605858612942, \"phi\": 0.4551668620461665}, {\"truth_threshold\": -14.499999675899744, \"match_probability\": 4.31565200050488e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589560.0, \"fp\": 148232.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998840794407365, \"fp_rate\": 0.00011592055926348973, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47320762226976465, \"recall\": 0.43806277779057184, \"specificity\": 0.9998840794407365, \"npv\": 0.9998664276713544, \"accuracy\": 0.9997505640458948, \"f1\": 0.45495748675571923, \"f2\": 0.44466781990742904, \"f0_5\": 0.4657346424111843, \"p4\": 0.6253649918801367, \"phi\": 0.4551717185957406}, {\"truth_threshold\": -14.419999677687883, \"match_probability\": 4.561710790662038e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589596.0, \"fp\": 148196.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884107593498, \"fp_rate\": 0.00011589240650205167, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732681713168651, \"recall\": 0.43806277779057184, \"specificity\": 0.999884107593498, \"npv\": 0.9998664276751147, \"accuracy\": 0.9997505921919657, \"f1\": 0.4549854692633489, \"f2\": 0.4446785119363289, \"f0_5\": 0.46578156253038944, \"p4\": 0.6253914292970484, \"phi\": 0.45520086115469766}, {\"truth_threshold\": -14.379999678581953, \"match_probability\": 4.6899519194499804e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589603.0, \"fp\": 148189.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884113067646, \"fp_rate\": 0.00011588693235399427, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732799465421212, \"recall\": 0.43806277779057184, \"specificity\": 0.999884113067646, \"npv\": 0.9998664276758459, \"accuracy\": 0.9997505976648129, \"f1\": 0.45499091070623127, \"f2\": 0.44468059100165847, \"f0_5\": 0.46579068698476844, \"p4\": 0.6253965701654712, \"phi\": 0.4552065284127607}, {\"truth_threshold\": -14.05999968573451, \"match_probability\": 5.854542039493212e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589608.0, \"fp\": 148184.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841169777518, \"fp_rate\": 0.00011588302224823899, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732883577760558, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841169777518, \"npv\": 0.9998664276763681, \"accuracy\": 0.9997506015739894, \"f1\": 0.45499479753083466, \"f2\": 0.44468207606022514, \"f0_5\": 0.46579720467105523, \"p4\": 0.625400242266091, \"phi\": 0.4552105765836965}, {\"truth_threshold\": -14.01999968662858, \"match_probability\": 6.019125708717721e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589612.0, \"fp\": 148180.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841201058364, \"fp_rate\": 0.00011587989416363476, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4732950869784669, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841201058364, \"npv\": 0.9998664276767859, \"accuracy\": 0.9997506047013307, \"f1\": 0.4549979070383311, \"f2\": 0.4446832641142202, \"f0_5\": 0.46580241895141455, \"p4\": 0.6254031799776352, \"phi\": 0.45521381519812626}, {\"truth_threshold\": -13.97999968752265, \"match_probability\": 6.188335889736231e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589618.0, \"fp\": 148174.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841247979633, \"fp_rate\": 0.00011587520203672842, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4733051811408747, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841247979633, \"npv\": 0.9998664276774126, \"accuracy\": 0.9997506093923425, \"f1\": 0.45500257137926736, \"f2\": 0.4446850462071158, \"f0_5\": 0.46581024059084586, \"p4\": 0.6254075865966994, \"phi\": 0.45521867324924503}, {\"truth_threshold\": -13.919999688863754, \"match_probability\": 6.451111322608078e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589638.0, \"fp\": 148154.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841404383862, \"fp_rate\": 0.00011585956161370727, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47333883145875694, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841404383862, \"npv\": 0.9998664276795017, \"accuracy\": 0.9997506250290487, \"f1\": 0.455018119873084, \"f2\": 0.44469098661992906, \"f0_5\": 0.46583631461950903, \"p4\": 0.6254222757754132, \"phi\": 0.4552348678751837}, {\"truth_threshold\": -13.779999691992998, \"match_probability\": 7.108465822910962e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589644.0, \"fp\": 148148.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841451305132, \"fp_rate\": 0.00011585486948680094, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4733489274871846, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841451305132, \"npv\": 0.9998664276801285, \"accuracy\": 0.9997506297200605, \"f1\": 0.4550227846284491, \"f2\": 0.444692768774722, \"f0_5\": 0.4658441373973267, \"p4\": 0.6254266826635821, \"phi\": 0.45523972659965994}, {\"truth_threshold\": -13.739999692887068, \"match_probability\": 7.308297388965204e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589649.0, \"fp\": 148143.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884149040619, \"fp_rate\": 0.00011585095938104565, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4733573411732084, \"recall\": 0.43806277779057184, \"specificity\": 0.999884149040619, \"npv\": 0.9998664276806508, \"accuracy\": 0.999750633629237, \"f1\": 0.4550266719976489, \"f2\": 0.44469425391462797, \"f0_5\": 0.4658506565795449, \"p4\": 0.6254303551178306, \"phi\": 0.45524377565544094}, {\"truth_threshold\": -13.699999693781137, \"match_probability\": 7.513746152194597e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589657.0, \"fp\": 148135.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841552967882, \"fp_rate\": 0.00011584470321183719, \"fn_rate\": 0.5619372222094282, \"precision\": 0.473370803692999, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841552967882, \"npv\": 0.9998664276814864, \"accuracy\": 0.9997506398839194, \"f1\": 0.4550328919265271, \"f2\": 0.44469663015911076, \"f0_5\": 0.4658610876506262, \"p4\": 0.6254362311343368, \"phi\": 0.45525025436918676}, {\"truth_threshold\": -13.659999694675207, \"match_probability\": 7.724969986029392e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589669.0, \"fp\": 148123.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884164681042, \"fp_rate\": 0.00011583531895802451, \"fn_rate\": 0.5619372222094282, \"precision\": 0.47339099890854924, \"recall\": 0.43806277779057184, \"specificity\": 0.999884164681042, \"npv\": 0.9998664276827398, \"accuracy\": 0.999750649265943, \"f1\": 0.45504222213868545, \"f2\": 0.44470019457345134, \"f0_5\": 0.46587673513315314, \"p4\": 0.6254450453661217, \"phi\": 0.45525997295791254}, {\"truth_threshold\": -13.619999695569277, \"match_probability\": 7.942131199619611e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589679.0, \"fp\": 148113.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841725012535, \"fp_rate\": 0.00011582749874651394, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4734078295711904, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841725012535, \"npv\": 0.9998664276837844, \"accuracy\": 0.9997506570842961, \"f1\": 0.45504999760777, \"f2\": 0.4447031649623842, \"f0_5\": 0.4658897755049058, \"p4\": 0.6254523907490561, \"phi\": 0.4552680722568243}, {\"truth_threshold\": -13.579999696463346, \"match_probability\": 8.165396662385808e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589681.0, \"fp\": 148111.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998841740652958, \"fp_rate\": 0.00011582593470421183, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4734111958473326, \"recall\": 0.43806277779057184, \"specificity\": 0.9998841740652958, \"npv\": 0.9998664276839934, \"accuracy\": 0.9997506586479668, \"f1\": 0.4550515527334739, \"f2\": 0.4447037590449326, \"f0_5\": 0.46589238366686003, \"p4\": 0.6254538598463469, \"phi\": 0.4552696921684256}, {\"truth_threshold\": -13.559999696910381, \"match_probability\": 8.279371912290328e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589738.0, \"fp\": 148054.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.9998842186405014, \"fp_rate\": 0.00011578135949860158, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4735071548462348, \"recall\": 0.43806277779057184, \"specificity\": 0.9998842186405014, \"npv\": 0.9998664276899473, \"accuracy\": 0.9997507032125792, \"f1\": 0.45509587828473486, \"f2\": 0.4447206910648394, \"f0_5\": 0.4659667285604003, \"p4\": 0.6254957320205017, \"phi\": 0.45531586691168324}, {\"truth_threshold\": -13.539999697357416, \"match_probability\": 8.394937932062662e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133154.0, \"tn\": 1278589748.0, \"fp\": 148044.0, \"fn\": 170807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43806277779057184, \"tn_rate\": 0.999884226460713, \"fp_rate\": 0.000115773539287091, \"fn_rate\": 0.5619372222094282, \"precision\": 0.4735239937695147, \"recall\": 0.43806277779057184, \"specificity\": 0.999884226460713, \"npv\": 0.9998664276909918, \"accuracy\": 0.9997507110309323, \"f1\": 0.4551036555876266, \"f2\": 0.4447236617275935, \"f0_5\": 0.4659797739707283, \"p4\": 0.6255030785940447, \"phi\": 0.45532396919103857}, {\"truth_threshold\": -13.519999697804451, \"match_probability\": 8.512116920564651e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278590678.0, \"fp\": 147114.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998849537403834, \"fp_rate\": 0.00011504625961660794, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47509339308587883, \"recall\": 0.4380594878948286, \"specificity\": 0.9998849537403834, \"npv\": 0.9998664270062322, \"accuracy\": 0.9997514373559313, \"f1\": 0.45582546540049435, \"f2\": 0.44499706238374026, \"f0_5\": 0.4671940009641909, \"p4\": 0.626184571039284, \"phi\": 0.4560767624089176}, {\"truth_threshold\": -13.47999969869852, \"match_probability\": 8.75140415189664e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278591548.0, \"fp\": 146244.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998856340987848, \"fp_rate\": 0.0001143659012151883, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47657276205542654, \"recall\": 0.4380594878948286, \"specificity\": 0.9998856340987848, \"npv\": 0.9998664270971079, \"accuracy\": 0.9997521175526473, \"f1\": 0.45650526777724826, \"f2\": 0.44525598214602197, \"f0_5\": 0.46833770766959143, \"p4\": 0.6268257846872984, \"phi\": 0.456786841771898}, {\"truth_threshold\": -13.43999969959259, \"match_probability\": 8.997417468807435e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593019.0, \"fp\": 144773.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.999886784451898, \"fp_rate\": 0.00011321554810198336, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47909515482538517, \"recall\": 0.4380594878948286, \"specificity\": 0.999886784451898, \"npv\": 0.9998664272507608, \"accuracy\": 0.9997532676323819, \"f1\": 0.4576593049853322, \"f2\": 0.44569445095295795, \"f0_5\": 0.4702842833579978, \"p4\": 0.6279129441516772, \"phi\": 0.4579950212257104}, {\"truth_threshold\": -13.39999970048666, \"match_probability\": 9.250345899225926e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593021.0, \"fp\": 144771.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998867860159403, \"fp_rate\": 0.00011321398405968125, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4790986024956463, \"recall\": 0.4380594878948286, \"specificity\": 0.9998867860159403, \"npv\": 0.9998664272509697, \"accuracy\": 0.9997532691960526, \"f1\": 0.4576608780085412, \"f2\": 0.4456950476914755, \"f0_5\": 0.4702869409751091, \"p4\": 0.6279144248418054, \"phi\": 0.4579966704148526}, {\"truth_threshold\": -13.35999970138073, \"match_probability\": 9.51038378149883e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593022.0, \"fp\": 144770.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998867867979615, \"fp_rate\": 0.0001132132020385302, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47910032634938454, \"recall\": 0.4380594878948286, \"specificity\": 0.9998867867979615, \"npv\": 0.9998664272510742, \"accuracy\": 0.9997532699778879, \"f1\": 0.4576616645242007, \"f2\": 0.44569534606133354, \"f0_5\": 0.47028826979492855, \"p4\": 0.6279151651894882, \"phi\": 0.4579974950160977}, {\"truth_threshold\": -13.3199997022748, \"match_probability\": 9.7777309134657e-05, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593028.0, \"fp\": 144764.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998867914900884, \"fp_rate\": 0.00011320850991162385, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47911066973233013, \"recall\": 0.4380594878948286, \"specificity\": 0.9998867914900884, \"npv\": 0.9998664272517009, \"accuracy\": 0.9997532746688997, \"f1\": 0.4576663836749284, \"f2\": 0.44569713628887087, \"f0_5\": 0.4702962428715433, \"p4\": 0.6279196073122477, \"phi\": 0.45800244271700663}, {\"truth_threshold\": -13.279999703168869, \"match_probability\": 0.00010052592705712347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278593053.0, \"fp\": 144739.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998868110406172, \"fp_rate\": 0.00011318895938284743, \"fn_rate\": 0.5619405121051714, \"precision\": 0.47915377196896636, \"recall\": 0.4380594878948286, \"specificity\": 0.9998868110406172, \"npv\": 0.9998664272543123, \"accuracy\": 0.9997532942147823, \"f1\": 0.45768604785057393, \"f2\": 0.44570459572508125, \"f0_5\": 0.4703294669342698, \"p4\": 0.6279381168336168, \"phi\": 0.4580230598617877}, {\"truth_threshold\": -13.259999703615904, \"match_probability\": 0.00010192907363665686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278596353.0, \"fp\": 141439.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998893917104157, \"fp_rate\": 0.00011060828958435913, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48491216058734415, \"recall\": 0.4380594878948286, \"specificity\": 0.9998893917104157, \"npv\": 0.9998664275990116, \"accuracy\": 0.9997558742712913, \"f1\": 0.4602966366089192, \"f2\": 0.4466914379416493, \"f0_5\": 0.4747566369945997, \"p4\": 0.6303909898884013, \"phi\": 0.460769182512054}, {\"truth_threshold\": -13.179999705404043, \"match_probability\": 0.00010774024339380982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278596363.0, \"fp\": 141429.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998893995306272, \"fp_rate\": 0.00011060046937284856, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4849298206000393, \"recall\": 0.4380594878948286, \"specificity\": 0.9998893995306272, \"npv\": 0.9998664276000561, \"accuracy\": 0.9997558820896444, \"f1\": 0.46030459274418667, \"f2\": 0.44669443501388195, \"f0_5\": 0.4747701793282269, \"p4\": 0.6303984519602139, \"phi\": 0.46077757923673635}, {\"truth_threshold\": -13.159999705851078, \"match_probability\": 0.00010924407680734595, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278596365.0, \"fp\": 141427.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998894010946695, \"fp_rate\": 0.00011059890533054645, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4849333527569379, \"recall\": 0.4380594878948286, \"specificity\": 0.9998894010946695, \"npv\": 0.999866427600265, \"accuracy\": 0.9997558836533149, \"f1\": 0.46030618400424517, \"f2\": 0.4466950344331546, \"f0_5\": 0.47477288788766303, \"p4\": 0.6303999443957757, \"phi\": 0.46077925863670305}, {\"truth_threshold\": -13.039999708533287, \"match_probability\": 0.00011871822168312209, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597609.0, \"fp\": 140183.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903739289814, \"fp_rate\": 0.00010962607101863147, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48714036936225014, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903739289814, \"npv\": 0.9998664277302056, \"accuracy\": 0.9997568562564353, \"f1\": 0.46129808400182226, \"f2\": 0.4470681851757343, \"f0_5\": 0.4764636210419343, \"p4\": 0.6313296104951126, \"phi\": 0.46182741310352865}, {\"truth_threshold\": -12.999999709427357, \"match_probability\": 0.00012205543773770849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597633.0, \"fp\": 140159.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.999890392697489, \"fp_rate\": 0.00010960730251100611, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48718314600163914, \"recall\": 0.4380594878948286, \"specificity\": 0.999890392697489, \"npv\": 0.9998664277327125, \"accuracy\": 0.9997568750204826, \"f1\": 0.4613172623697973, \"f2\": 0.4470753903553422, \"f0_5\": 0.47649635809674856, \"p4\": 0.631347573136727, \"phi\": 0.4618477050495092}, {\"truth_threshold\": -12.979999709874392, \"match_probability\": 0.00012375905725128174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597639.0, \"fp\": 140153.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903973896159, \"fp_rate\": 0.00010960261038409976, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48719384133535304, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903973896159, \"npv\": 0.9998664277333392, \"accuracy\": 0.9997568797114944, \"f1\": 0.4613220572109613, \"f2\": 0.4470771916865326, \"f0_5\": 0.47650454306337386, \"p4\": 0.6313520639568425, \"phi\": 0.46185277845352896}, {\"truth_threshold\": -12.959999710321426, \"match_probability\": 0.00012548645247902702, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597641.0, \"fp\": 140151.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998903989536582, \"fp_rate\": 0.00010960104634179765, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48719740655094695, \"recall\": 0.4380594878948286, \"specificity\": 0.9998903989536582, \"npv\": 0.9998664277335482, \"accuracy\": 0.999756881275165, \"f1\": 0.461323655513499, \"f2\": 0.4470777921334884, \"f0_5\": 0.4765072714480699, \"p4\": 0.6313535609110782, \"phi\": 0.46185446962531906}, {\"truth_threshold\": -12.799999713897705, \"match_probability\": 0.0001402023355190992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597683.0, \"fp\": 140109.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904317985465, \"fp_rate\": 0.00010956820145345325, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48727228813373247, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904317985465, \"npv\": 0.9998664277379352, \"accuracy\": 0.9997569141122479, \"f1\": 0.46135722242530186, \"f2\": 0.447090401892142, \"f0_5\": 0.4765645747450446, \"p4\": 0.6313849985898955, \"phi\": 0.4618899885205684}, {\"truth_threshold\": -12.77999971434474, \"match_probability\": 0.00014215920891711648, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597699.0, \"fp\": 140093.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904443108849, \"fp_rate\": 0.00010955568911503633, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48730082050606416, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904443108849, \"npv\": 0.9998664277396065, \"accuracy\": 0.9997569266216128, \"f1\": 0.4613700111052014, \"f2\": 0.44709520579682893, \"f0_5\": 0.47658640819788894, \"p4\": 0.6313969756720349, \"phi\": 0.4619035216817853}, {\"truth_threshold\": -12.719999715685844, \"match_probability\": 0.00014819521310708466, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597733.0, \"fp\": 140059.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904708996041, \"fp_rate\": 0.0001095291003959004, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48736146289328436, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904708996041, \"npv\": 0.9998664277431579, \"accuracy\": 0.9997569532040131, \"f1\": 0.46139718940421676, \"f2\": 0.4471054144370662, \"f0_5\": 0.47663281092833737, \"p4\": 0.6314224284803899, \"phi\": 0.4619322835954728}, {\"truth_threshold\": -12.69999971613288, \"match_probability\": 0.00015026363028828644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597742.0, \"fp\": 140050.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904779377945, \"fp_rate\": 0.00010952206220554089, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48737751781642225, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904779377945, \"npv\": 0.9998664277440981, \"accuracy\": 0.999756960240531, \"f1\": 0.46140438419582647, \"f2\": 0.4471081168022232, \"f0_5\": 0.47664509551659434, \"p4\": 0.6314291663319839, \"phi\": 0.4619398979416936}, {\"truth_threshold\": -12.679999716579914, \"match_probability\": 0.00015236091275869646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597749.0, \"fp\": 140043.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904834119425, \"fp_rate\": 0.00010951658805748349, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4873900057101861, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904834119425, \"npv\": 0.9998664277448291, \"accuracy\": 0.9997569657133781, \"f1\": 0.4614099802999877, \"f2\": 0.44711021866437434, \"f0_5\": 0.47665465063415297, \"p4\": 0.6314344069826403, \"phi\": 0.4619458204710413}, {\"truth_threshold\": -12.659999717026949, \"match_probability\": 0.00015448746321712552, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597761.0, \"fp\": 140031.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998904927961964, \"fp_rate\": 0.0001095072038036708, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4874114150169849, \"recall\": 0.4380594878948286, \"specificity\": 0.9998904927961964, \"npv\": 0.9998664277460827, \"accuracy\": 0.9997569750954017, \"f1\": 0.4614195739372255, \"f2\": 0.4471138219026103, \"f0_5\": 0.47667103172699593, \"p4\": 0.631443391157585, \"phi\": 0.4619559739079577}, {\"truth_threshold\": -12.639999717473984, \"match_probability\": 0.00015664368997694777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597782.0, \"fp\": 140010.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998905092186405, \"fp_rate\": 0.0001094907813594986, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4874488858300722, \"recall\": 0.4380594878948286, \"specificity\": 0.9998905092186405, \"npv\": 0.9998664277482762, \"accuracy\": 0.9997569915139431, \"f1\": 0.46143636376238034, \"f2\": 0.447120127709272, \"f0_5\": 0.47669970134890627, \"p4\": 0.6314591140789287, \"phi\": 0.46197374403204666}, {\"truth_threshold\": -12.619999717921019, \"match_probability\": 0.0001588300070442831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597806.0, \"fp\": 139986.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998905279871482, \"fp_rate\": 0.00010947201285187324, \"fn_rate\": 0.5619405121051714, \"precision\": 0.48749171667173125, \"recall\": 0.4380594878948286, \"specificity\": 0.9998905279871482, \"npv\": 0.999866427750783, \"accuracy\": 0.9997570102779905, \"f1\": 0.46145555363022006, \"f2\": 0.4471273345632556, \"f0_5\": 0.47673247085427534, \"p4\": 0.6314770840906964, \"phi\": 0.46199405525401604}, {\"truth_threshold\": -12.599999718368053, \"match_probability\": 0.00016104683419726568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133153.0, \"tn\": 1278597836.0, \"fp\": 139956.0, \"fn\": 170808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380594878948286, \"tn_rate\": 0.9998905514477826, \"fp_rate\": 0.00010944855221734152, \"fn_rate\": 0.5619405121051714, \"precision\": 0.4875452658096218, \"recall\": 0.4380594878948286, \"specificity\": 0.9998905514477826, \"npv\": 0.9998664277539167, \"accuracy\": 0.9997570337330497, \"f1\": 0.4614795432096626, \"f2\": 0.4471363434574496, \"f0_5\": 0.4767734390721263, \"p4\": 0.631499548043739, \"phi\": 0.46201944804542644}, {\"truth_threshold\": -12.579999718815088, \"match_probability\": 0.00016329459706641318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133151.0, \"tn\": 1278597967.0, \"fp\": 139825.0, \"fn\": 170810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380529081033422, \"tn_rate\": 0.9998906538925535, \"fp_rate\": 0.00010934610744655304, \"fn_rate\": 0.5619470918966578, \"precision\": 0.4877754820936639, \"recall\": 0.4380529081033422, \"specificity\": 0.9998906538925535, \"npv\": 0.9998664262038046, \"accuracy\": 0.9997571345898041, \"f1\": 0.461578993893614, \"f2\": 0.4471695705323679, \"f0_5\": 0.4769479856576388, \"p4\": 0.6315926666237845, \"phi\": 0.46212512839951614}, {\"truth_threshold\": -12.539999719709158, \"match_probability\": 0.00016788466222723527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620541.0, \"fp\": 117251.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999083072380174, \"fp_rate\": 9.169276198259103e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5317470776873894, \"recall\": 0.438049618207599, \"specificity\": 0.9999083072380174, \"npv\": 0.9998664277798462, \"accuracy\": 0.9997747829581604, \"f1\": 0.48037203127198475, \"f2\": 0.45405099420628886, \"f0_5\": 0.5099324813394966, \"p4\": 0.648964534325096, \"phi\": 0.48251875403273436}, {\"truth_threshold\": -12.479999721050262, \"match_probability\": 0.00017501276425237197, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620557.0, \"fp\": 117235.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999083197503559, \"fp_rate\": 9.168024964417412e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5317810571719552, \"recall\": 0.438049618207599, \"specificity\": 0.9999083197503559, \"npv\": 0.9998664277815176, \"accuracy\": 0.9997747954675252, \"f1\": 0.4803858961731482, \"f2\": 0.45405594896840806, \"f0_5\": 0.5099574799253314, \"p4\": 0.6489771879352062, \"phi\": 0.4825341814117998}, {\"truth_threshold\": -12.459999721497297, \"match_probability\": 0.00017745541780392302, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620595.0, \"fp\": 117197.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999083494671596, \"fp_rate\": 9.165053284043396e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5318617758551131, \"recall\": 0.438049618207599, \"specificity\": 0.9999083494671596, \"npv\": 0.9998664277854867, \"accuracy\": 0.9997748251772669, \"f1\": 0.4804188285213275, \"f2\": 0.45406771696184195, \"f0_5\": 0.5100168613910916, \"p4\": 0.6490072422369407, \"phi\": 0.4825708273629761}, {\"truth_threshold\": -12.439999721944332, \"match_probability\": 0.00017993215734134557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620768.0, \"fp\": 117024.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999084847568187, \"fp_rate\": 9.151524318130109e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5322295682205185, \"recall\": 0.438049618207599, \"specificity\": 0.9999084847568187, \"npv\": 0.9998664278035568, \"accuracy\": 0.9997749604347748, \"f1\": 0.4805688144585706, \"f2\": 0.45412130001132317, \"f0_5\": 0.510287378215117, \"p4\": 0.6491441035915182, \"phi\": 0.4827377683729194}, {\"truth_threshold\": -12.419999722391367, \"match_probability\": 0.00018244345834475073, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620769.0, \"fp\": 117023.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999084855388398, \"fp_rate\": 9.151446116015003e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5322316956665987, \"recall\": 0.438049618207599, \"specificity\": 0.9999084855388398, \"npv\": 0.9998664278036613, \"accuracy\": 0.9997749612166101, \"f1\": 0.4805696817015379, \"f2\": 0.45412160977669425, \"f0_5\": 0.5102889427303658, \"p4\": 0.6491448948654054, \"phi\": 0.4827387338530787}, {\"truth_threshold\": -12.399999722838402, \"match_probability\": 0.00018498980292207934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620779.0, \"fp\": 117013.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999084933590514, \"fp_rate\": 9.150664094863945e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5322529710628671, \"recall\": 0.438049618207599, \"specificity\": 0.9999084933590514, \"npv\": 0.9998664278047058, \"accuracy\": 0.9997749690349632, \"f1\": 0.4805783543033689, \"f2\": 0.4541247074536479, \"f0_5\": 0.5103045884105095, \"p4\": 0.6491528077103763, \"phi\": 0.4827483889729963}, {\"truth_threshold\": -12.379999723285437, \"match_probability\": 0.0001875716799013524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620978.0, \"fp\": 116814.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999086489812604, \"fp_rate\": 9.13510187395791e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5326767054455842, \"recall\": 0.438049618207599, \"specificity\": 0.9999086489812604, \"npv\": 0.9998664278254917, \"accuracy\": 0.999775124620189, \"f1\": 0.48075100419731914, \"f2\": 0.45418636001440843, \"f0_5\": 0.5106161370805873, \"p4\": 0.6493103134515281, \"phi\": 0.48294064630213746}, {\"truth_threshold\": -12.359999723732471, \"match_probability\": 0.00019018958492420193, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278620982.0, \"fp\": 116810.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.999908652109345, \"fp_rate\": 9.134789065497487e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5326852296367419, \"recall\": 0.438049618207599, \"specificity\": 0.999908652109345, \"npv\": 0.9998664278259096, \"accuracy\": 0.9997751277475302, \"f1\": 0.4807544758187539, \"f2\": 0.45418759943348497, \"f0_5\": 0.510622403265529, \"p4\": 0.6493134801796799, \"phi\": 0.48294451312419373}, {\"truth_threshold\": -12.319999724626541, \"match_probability\": 0.00019553549630550054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278621233.0, \"fp\": 116559.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.999908848396654, \"fp_rate\": 9.115160334605955e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5332206688585513, \"recall\": 0.438049618207599, \"specificity\": 0.999908848396654, \"npv\": 0.999866427852127, \"accuracy\": 0.9997753239881919, \"f1\": 0.48097242039482, \"f2\": 0.4542653865128044, \"f0_5\": 0.5110159142214789, \"p4\": 0.6495122541722919, \"phi\": 0.48318734197195373}, {\"truth_threshold\": -12.27999972552061, \"match_probability\": 0.00020103164210777665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623721.0, \"fp\": 114071.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999107940652777, \"fp_rate\": 8.920593472222959e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5385869323398902, \"recall\": 0.438049618207599, \"specificity\": 0.9999107940652777, \"npv\": 0.9998664281120025, \"accuracy\": 0.9997772691944327, \"f1\": 0.48314349888058755, \"f2\": 0.4550378828008325, \"f0_5\": 0.5149495879243065, \"p4\": 0.6514891737371463, \"phi\": 0.48561430758702623}, {\"truth_threshold\": -12.23999972641468, \"match_probability\": 0.00020668224259808178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623743.0, \"fp\": 114049.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999108112697431, \"fp_rate\": 8.918873025690634e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5386348650277711, \"recall\": 0.438049618207599, \"specificity\": 0.9999108112697431, \"npv\": 0.9998664281143005, \"accuracy\": 0.9997772863948093, \"f1\": 0.4831627839465854, \"f2\": 0.4550447252746502, \"f0_5\": 0.5149846413517777, \"p4\": 0.651506708215359, \"phi\": 0.48563593114452086}, {\"truth_threshold\": -12.219999726861715, \"match_probability\": 0.0002095668144843976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623749.0, \"fp\": 114043.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.99991081596187, \"fp_rate\": 8.918403812999999e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.538647939059763, \"recall\": 0.438049618207599, \"specificity\": 0.99991081596187, \"npv\": 0.9998664281149272, \"accuracy\": 0.9997772910858211, \"f1\": 0.4831680437772383, \"f2\": 0.45504659143958764, \"f0_5\": 0.5149942022057146, \"p4\": 0.6515114905095927, \"phi\": 0.4856418289792635}, {\"truth_threshold\": -12.19999972730875, \"match_probability\": 0.0002124916364977025, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278623776.0, \"fp\": 114016.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999108370764411, \"fp_rate\": 8.916292355892145e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.538706780058746, \"recall\": 0.438049618207599, \"specificity\": 0.9999108370764411, \"npv\": 0.9998664281177474, \"accuracy\": 0.9997773121953745, \"f1\": 0.48319171443242664, \"f2\": 0.4550549893712278, \"f0_5\": 0.5150372304419302, \"p4\": 0.6515330117024906, \"phi\": 0.48566837189255296}, {\"truth_threshold\": -12.139999728649855, \"match_probability\": 0.00022151325645684798, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624661.0, \"fp\": 113131.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115291651598, \"fp_rate\": 8.847083484023596e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5406425993072953, \"recall\": 0.438049618207599, \"specificity\": 0.9999115291651598, \"npv\": 0.9998664282101869, \"accuracy\": 0.99977800411962, \"f1\": 0.48396887187819176, \"f2\": 0.4553304266051124, \"f0_5\": 0.5164515916328248, \"p4\": 0.6522392165180672, \"phi\": 0.4865408038971557}, {\"truth_threshold\": -12.11999972909689, \"match_probability\": 0.00022460477168891795, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624664.0, \"fp\": 113128.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115315112233, \"fp_rate\": 8.846848877678278e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5406491850672817, \"recall\": 0.438049618207599, \"specificity\": 0.9999115315112233, \"npv\": 0.9998664282105002, \"accuracy\": 0.9997780064651259, \"f1\": 0.48397151056177407, \"f2\": 0.4553313608577123, \"f0_5\": 0.516456399288481, \"p4\": 0.6522416130362957, \"phi\": 0.4865437692871132}, {\"truth_threshold\": -12.07999972999096, \"match_probability\": 0.00023091781303279083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624678.0, \"fp\": 113114.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115424595193, \"fp_rate\": 8.845754048066799e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5406799207354709, \"recall\": 0.438049618207599, \"specificity\": 0.9999115424595193, \"npv\": 0.9998664282119625, \"accuracy\": 0.9997780174108202, \"f1\": 0.48398382479894586, \"f2\": 0.45533572075387047, \"f0_5\": 0.5164788361984365, \"p4\": 0.6522527970208896, \"phi\": 0.4865576084898797}, {\"truth_threshold\": -12.019999731332064, \"match_probability\": 0.00024072155289150756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624697.0, \"fp\": 113095.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115573179213, \"fp_rate\": 8.84426820787979e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5407216390180511, \"recall\": 0.438049618207599, \"specificity\": 0.9999115573179213, \"npv\": 0.9998664282139471, \"accuracy\": 0.9997780322656911, \"f1\": 0.4840005379803201, \"f2\": 0.4553416378893487, \"f0_5\": 0.5165092894089024, \"p4\": 0.6522679758991837, \"phi\": 0.4865763921523473}, {\"truth_threshold\": -11.999999731779099, \"match_probability\": 0.00024408108027122293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624716.0, \"fp\": 113076.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115721763231, \"fp_rate\": 8.842782367692782e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.540763363739004, \"recall\": 0.438049618207599, \"specificity\": 0.9999115721763231, \"npv\": 0.9998664282159316, \"accuracy\": 0.9997780471205618, \"f1\": 0.4840172523160307, \"f2\": 0.45534755517861664, \"f0_5\": 0.5165397462108134, \"p4\": 0.6522831554839638, \"phi\": 0.48659517798843394}, {\"truth_threshold\": -11.979999732226133, \"match_probability\": 0.00024748748185126745, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624720.0, \"fp\": 113072.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115753044077, \"fp_rate\": 8.842469559232359e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5407721487113255, \"recall\": 0.438049618207599, \"specificity\": 0.9999115753044077, \"npv\": 0.9998664282163494, \"accuracy\": 0.999778050247903, \"f1\": 0.48402077127064996, \"f2\": 0.4553488009433227, \"f0_5\": 0.5165461586268058, \"p4\": 0.6522863512760505, \"phi\": 0.48659913317830455}, {\"truth_threshold\": -11.959999732673168, \"match_probability\": 0.00025094141132320783, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624728.0, \"fp\": 113064.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115815605769, \"fp_rate\": 8.841843942311513e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5407897195122942, \"recall\": 0.438049618207599, \"specificity\": 0.9999115815605769, \"npv\": 0.9998664282171851, \"accuracy\": 0.9997780565025854, \"f1\": 0.4840278093333939, \"f2\": 0.4553512924931843, \"f0_5\": 0.5165589839364316, \"p4\": 0.6522927429541695, \"phi\": 0.48660704384713016}, {\"truth_threshold\": -11.939999733120203, \"match_probability\": 0.00025444353148560106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624746.0, \"fp\": 113046.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999115956369576, \"fp_rate\": 8.84043630423961e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5408292579895693, \"recall\": 0.438049618207599, \"specificity\": 0.9999115956369576, \"npv\": 0.9998664282190652, \"accuracy\": 0.999778070575621, \"f1\": 0.48404364572294817, \"f2\": 0.4553568985800662, \"f0_5\": 0.5165878432118068, \"p4\": 0.6523071246879387, \"phi\": 0.4866248442614177}, {\"truth_threshold\": -11.899999734014273, \"match_probability\": 0.00026159504137238267, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133150.0, \"tn\": 1278624953.0, \"fp\": 112839.0, \"fn\": 170811.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.438049618207599, \"tn_rate\": 0.9999117575153359, \"fp_rate\": 8.82424846641273e-05, \"fn_rate\": 0.561950381792401, \"precision\": 0.5412843663741062, \"recall\": 0.438049618207599, \"specificity\": 0.9999117575153359, \"npv\": 0.9998664282406866, \"accuracy\": 0.9997782324155293, \"f1\": 0.4842258387126102, \"f2\": 0.45542137850219555, \"f0_5\": 0.5169199567984583, \"p4\": 0.6524725602192569, \"phi\": 0.486829689401801}, {\"truth_threshold\": -11.879999734461308, \"match_probability\": 0.0002652458033771831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625046.0, \"fp\": 112746.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999118302433029, \"fp_rate\": 8.8169756697079e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5414872201549442, \"recall\": 0.4380463283118558, \"specificity\": 0.9999118302433029, \"npv\": 0.9998664274685194, \"accuracy\": 0.9997783043443774, \"f1\": 0.4843049816679276, \"f2\": 0.4554472446859528, \"f0_5\": 0.5170670293217847, \"p4\": 0.6525444114155075, \"phi\": 0.48691913768128936}, {\"truth_threshold\": -11.859999734908342, \"match_probability\": 0.00026894750089535765, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625054.0, \"fp\": 112738.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999118364994721, \"fp_rate\": 8.816350052787054e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5415048375879977, \"recall\": 0.4380463283118558, \"specificity\": 0.9999118364994721, \"npv\": 0.999866427469355, \"accuracy\": 0.9997783105990599, \"f1\": 0.48431202805138873, \"f2\": 0.45544973733197147, \"f0_5\": 0.5170798806066599, \"p4\": 0.6525508082000913, \"phi\": 0.4869270640723364}, {\"truth_threshold\": -11.839999735355377, \"match_probability\": 0.00027270084419510283, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625065.0, \"fp\": 112727.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999118451017048, \"fp_rate\": 8.815489829520891e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.541529063430347, \"recall\": 0.4380463283118558, \"specificity\": 0.9999118451017048, \"npv\": 0.9998664274705039, \"accuracy\": 0.9997783191992482, \"f1\": 0.48432171716345024, \"f2\": 0.45545316476479764, \"f0_5\": 0.5170975521664667, \"p4\": 0.6525596039836732, \"phi\": 0.48693796349152596}, {\"truth_threshold\": -11.819999735802412, \"match_probability\": 0.00027650655343809395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625068.0, \"fp\": 112724.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999118474477683, \"fp_rate\": 8.815255223175573e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5415356708544655, \"recall\": 0.4380463283118558, \"specificity\": 0.9999118474477683, \"npv\": 0.9998664274708173, \"accuracy\": 0.9997783215447541, \"f1\": 0.48432435971584153, \"f2\": 0.45545409952815763, \"f0_5\": 0.5171023718924108, \"p4\": 0.6525620028748939, \"phi\": 0.48694093618730955}, {\"truth_threshold\": -11.799999736249447, \"match_probability\": 0.0002803653588169889, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625076.0, \"fp\": 112716.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999118537039374, \"fp_rate\": 8.814629606254727e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5415532914404246, \"recall\": 0.4380463283118558, \"specificity\": 0.9999118537039374, \"npv\": 0.9998664274716529, \"accuracy\": 0.9997783277994365, \"f1\": 0.4843314066631989, \"f2\": 0.45545659224920965, \"f0_5\": 0.5171152249341902, \"p4\": 0.6525684000043764, \"phi\": 0.4869488636420002}, {\"truth_threshold\": -11.759999737143517, \"match_probability\": 0.00028824522974640556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625090.0, \"fp\": 112702.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999118646522336, \"fp_rate\": 8.813534776643248e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5415841302252177, \"recall\": 0.4380463283118558, \"specificity\": 0.9999118646522336, \"npv\": 0.9998664274731153, \"accuracy\": 0.9997783387451309, \"f1\": 0.48434373931452934, \"f2\": 0.45546095457670716, \"f0_5\": 0.5171377192948386, \"p4\": 0.652579595282776, \"phi\": 0.48696273761855774}, {\"truth_threshold\": -11.65999973937869, \"match_probability\": 0.0003089271962698964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625377.0, \"fp\": 112415.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120890923039, \"fp_rate\": 8.79109076960791e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5422171002264176, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120890923039, \"npv\": 0.999866427503093, \"accuracy\": 0.9997785631318636, \"f1\": 0.4845966971475365, \"f2\": 0.4555504007094528, \"f0_5\": 0.5175992853460963, \"p4\": 0.65280918317152, \"phi\": 0.4872474154936898}, {\"truth_threshold\": -11.61999974027276, \"match_probability\": 0.00031760956323944125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278625390.0, \"fp\": 112402.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999120992585789, \"fp_rate\": 8.790074142111536e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5422458063701634, \"recall\": 0.4380463283118558, \"specificity\": 0.9999120992585789, \"npv\": 0.9998664275044508, \"accuracy\": 0.9997785732957226, \"f1\": 0.48460816142322644, \"f2\": 0.45555445310816034, \"f0_5\": 0.5176202120256732, \"p4\": 0.6528195864474046, \"phi\": 0.4872603221219862}, {\"truth_threshold\": -11.559999741613865, \"match_probability\": 0.00033109262906279237, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278633296.0, \"fp\": 104496.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999182819177992, \"fp_rate\": 8.171808220085827e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5602852995013571, \"recall\": 0.4380463283118558, \"specificity\": 0.9999182819177992, \"npv\": 0.9998664283302412, \"accuracy\": 0.9997847544856497, \"f1\": 0.49168214532335314, \"f2\": 0.4580323621300196, \"f0_5\": 0.5306681886044378, \"p4\": 0.6592083975736805, \"phi\": 0.4953045862388452}, {\"truth_threshold\": -11.459999743849039, \"match_probability\": 0.00035484786043581666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133149.0, \"tn\": 1278633311.0, \"fp\": 104481.0, \"fn\": 170812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380463283118558, \"tn_rate\": 0.9999182936481165, \"fp_rate\": 8.170635188359241e-05, \"fn_rate\": 0.5619536716881443, \"precision\": 0.5603206665825022, \"recall\": 0.4380463283118558, \"specificity\": 0.9999182936481165, \"npv\": 0.9998664283318079, \"accuracy\": 0.9997847662131792, \"f1\": 0.49169576303889834, \"f2\": 0.45803708907073676, \"f0_5\": 0.5306935696913704, \"p4\": 0.6592206378752284, \"phi\": 0.4953202289943355}, {\"truth_threshold\": -11.439999744296074, \"match_probability\": 0.00035979956959653455, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133148.0, \"tn\": 1278633356.0, \"fp\": 104436.0, \"fn\": 170813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380430384161126, \"tn_rate\": 0.9999183288390682, \"fp_rate\": 8.167116093179484e-05, \"fn_rate\": 0.5619569615838874, \"precision\": 0.5604249444407031, \"recall\": 0.4380430384161126, \"specificity\": 0.9999183288390682, \"npv\": 0.9998664275546321, \"accuracy\": 0.9997848006139327, \"f1\": 0.4917338355999963, \"f2\": 0.45804814548777095, \"f0_5\": 0.5307674338693308, \"p4\": 0.6592548584369733, \"phi\": 0.4953644873629499}, {\"truth_threshold\": -11.399999745190144, \"match_probability\": 0.00036991117031967156, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133148.0, \"tn\": 1278633366.0, \"fp\": 104426.0, \"fn\": 170813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380430384161126, \"tn_rate\": 0.9999183366592798, \"fp_rate\": 8.166334072028427e-05, \"fn_rate\": 0.5619569615838874, \"precision\": 0.5604485339304807, \"recall\": 0.4380430384161126, \"specificity\": 0.9999183366592798, \"npv\": 0.9998664275556766, \"accuracy\": 0.9997848084322858, \"f1\": 0.4917429159703436, \"f2\": 0.45805129701159614, \"f0_5\": 0.5307843607809245, \"p4\": 0.659263019799087, \"phi\": 0.4953749196394514}, {\"truth_threshold\": -11.379999745637178, \"match_probability\": 0.000375073000919903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633497.0, \"fp\": 104295.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184391040505, \"fp_rate\": 8.15608959494958e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5607558898594183, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184391040505, \"npv\": 0.9998664267874837, \"accuracy\": 0.9997849100708756, \"f1\": 0.4918591141903536, \"f2\": 0.45808946071179385, \"f0_5\": 0.5310039091382588, \"p4\": 0.6593674492093843, \"phi\": 0.49550896433917396}, {\"truth_threshold\": -11.359999746084213, \"match_probability\": 0.00038030683355859456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633506.0, \"fp\": 104286.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184461422409, \"fp_rate\": 8.155385775913629e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5607771455526401, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184461422409, \"npv\": 0.9998664267884237, \"accuracy\": 0.9997849171073933, \"f1\": 0.49186729073465907, \"f2\": 0.45809229761428827, \"f0_5\": 0.5310191570025516, \"p4\": 0.6593747969905056, \"phi\": 0.4955183617099258}, {\"truth_threshold\": -11.339999746531248, \"match_probability\": 0.0003856136718173716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633522.0, \"fp\": 104270.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184586545793, \"fp_rate\": 8.154134542071937e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5608149374307653, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184586545793, \"npv\": 0.999866426790095, \"accuracy\": 0.9997849296167581, \"f1\": 0.491881827484678, \"f2\": 0.45809734108326033, \"f0_5\": 0.5310462664791578, \"p4\": 0.6593878601168595, \"phi\": 0.49553506946589804}, {\"truth_threshold\": -11.319999746978283, \"match_probability\": 0.00039099453324437826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633538.0, \"fp\": 104254.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999184711669177, \"fp_rate\": 8.152883308230245e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5608527344029722, \"recall\": 0.43803974852036937, \"specificity\": 0.9999184711669177, \"npv\": 0.9998664267917662, \"accuracy\": 0.9997849421261231, \"f1\": 0.4918963650939667, \"f2\": 0.458102384663288, \"f0_5\": 0.5310733787238795, \"p4\": 0.6594009237608206, \"phi\": 0.49555177891053576}, {\"truth_threshold\": -11.299999747425318, \"match_probability\": 0.00039645044954803596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633670.0, \"fp\": 104122.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999185743937097, \"fp_rate\": 8.142560629036293e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5611647539290847, \"recall\": 0.43803974852036937, \"specificity\": 0.9999185743937097, \"npv\": 0.9998664268055538, \"accuracy\": 0.9997850453283834, \"f1\": 0.49201633316704546, \"f2\": 0.4581439984364602, \"f0_5\": 0.5312971604190458, \"p4\": 0.6595087185774695, \"phi\": 0.4956896962990535}, {\"truth_threshold\": -11.279999747872353, \"match_probability\": 0.0004019824667934741, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633671.0, \"fp\": 104121.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999185751757308, \"fp_rate\": 8.142482426921187e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.561167119038387, \"recall\": 0.43803974852036937, \"specificity\": 0.9999185751757308, \"npv\": 0.9998664268056583, \"accuracy\": 0.9997850461102187, \"f1\": 0.4920172422394218, \"f2\": 0.4581443137211722, \"f0_5\": 0.5312988564546983, \"p4\": 0.6595095353393771, \"phi\": 0.49569074156689397}, {\"truth_threshold\": -11.259999748319387, \"match_probability\": 0.0004075916456016671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633723.0, \"fp\": 104069.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999186158408306, \"fp_rate\": 8.13841591693569e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5612901322001889, \"recall\": 0.43803974852036937, \"specificity\": 0.9999186158408306, \"npv\": 0.9998664268110897, \"accuracy\": 0.9997850867656546, \"f1\": 0.49206451863253614, \"f2\": 0.4581607091241931, \"f0_5\": 0.5313870652325744, \"p4\": 0.6595520097464742, \"phi\": 0.4957451046002762}, {\"truth_threshold\": -11.239999748766422, \"match_probability\": 0.0004132790613513162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633851.0, \"fp\": 103941.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.999918715939538, \"fp_rate\": 8.12840604620216e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5615931637198003, \"recall\": 0.43803974852036937, \"specificity\": 0.999918715939538, \"npv\": 0.9998664268244596, \"accuracy\": 0.9997851868405737, \"f1\": 0.4921809300081878, \"f2\": 0.45820107203915944, \"f0_5\": 0.5316043193674425, \"p4\": 0.6596565854451024, \"phi\": 0.49587899746919345}, {\"truth_threshold\": -11.219999749213457, \"match_probability\": 0.0004190458043835117, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633853.0, \"fp\": 103939.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999187175035803, \"fp_rate\": 8.128249641971948e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5615979011835368, \"recall\": 0.43803974852036937, \"specificity\": 0.9999187175035803, \"npv\": 0.9998664268246684, \"accuracy\": 0.9997851884042444, \"f1\": 0.492182749372975, \"f2\": 0.45820170276613464, \"f0_5\": 0.5316077153728525, \"p4\": 0.6596582197035213, \"phi\": 0.49588109040539274}, {\"truth_threshold\": -11.199999749660492, \"match_probability\": 0.00042489298020921594, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633856.0, \"fp\": 103936.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999187198496438, \"fp_rate\": 8.128015035626632e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5616050075290089, \"recall\": 0.43803974852036937, \"specificity\": 0.9999187198496438, \"npv\": 0.9998664268249818, \"accuracy\": 0.9997851907497503, \"f1\": 0.49218547844537597, \"f2\": 0.45820264885985323, \"f0_5\": 0.5316128094623224, \"p4\": 0.6596606711063329, \"phi\": 0.49588422985933733}, {\"truth_threshold\": -11.179999750107527, \"match_probability\": 0.000430821709719602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633858.0, \"fp\": 103934.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.999918721413686, \"fp_rate\": 8.12785863139642e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5616097451925713, \"recall\": 0.43803974852036937, \"specificity\": 0.999918721413686, \"npv\": 0.9998664268251907, \"accuracy\": 0.9997851923134209, \"f1\": 0.49218729784379034, \"f2\": 0.4582032795911695, \"f0_5\": 0.5316162055762067, \"p4\": 0.6596623053849959, \"phi\": 0.4958863228617316}, {\"truth_threshold\": -11.159999750554562, \"match_probability\": 0.0004368331293992898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633893.0, \"fp\": 103899.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999187487844263, \"fp_rate\": 8.125121557367721e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5616926672460197, \"recall\": 0.43803974852036937, \"specificity\": 0.9999187487844263, \"npv\": 0.9998664268288465, \"accuracy\": 0.9997852196776567, \"f1\": 0.49221913949357404, \"f2\": 0.4582143176702985, \"f0_5\": 0.531675644593877, \"p4\": 0.6596909065724708, \"phi\": 0.4959229546904144}, {\"truth_threshold\": -11.139999751001596, \"match_probability\": 0.00044292839154251796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633897.0, \"fp\": 103895.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999187519125109, \"fp_rate\": 8.124808748907297e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5617021456113263, \"recall\": 0.43803974852036937, \"specificity\": 0.9999187519125109, \"npv\": 0.9998664268292643, \"accuracy\": 0.9997852228049978, \"f1\": 0.4922227788015963, \"f2\": 0.4582155791989186, \"f0_5\": 0.5316824384707965, \"p4\": 0.6596941754375307, \"phi\": 0.49592714170159546}, {\"truth_threshold\": -11.119999751448631, \"match_probability\": 0.0004491086644722898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633910.0, \"fp\": 103882.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999187620787859, \"fp_rate\": 8.123792121410924e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.561732952507921, \"recall\": 0.43803974852036937, \"specificity\": 0.9999187620787859, \"npv\": 0.9998664268306222, \"accuracy\": 0.9997852329688568, \"f1\": 0.4922346069243424, \"f2\": 0.4582196792149073, \"f0_5\": 0.5317045197699503, \"p4\": 0.65970479947271, \"phi\": 0.4959407502197398}, {\"truth_threshold\": -11.099999751895666, \"match_probability\": 0.0004553751327625365, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278633920.0, \"fp\": 103872.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999187698989974, \"fp_rate\": 8.123010100259867e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5617566524202701, \"recall\": 0.43803974852036937, \"specificity\": 0.9999187698989974, \"npv\": 0.9998664268316667, \"accuracy\": 0.9997852407872099, \"f1\": 0.49224370586713, \"f2\": 0.4582228331232883, \"f0_5\": 0.5317215066327912, \"p4\": 0.6597129720403168, \"phi\": 0.49595121907230033}, {\"truth_threshold\": -11.079999752342701, \"match_probability\": 0.00046172899746333644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634249.0, \"fp\": 103543.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999190271839561, \"fp_rate\": 8.097281604390089e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5625374963031814, \"recall\": 0.43803974852036937, \"specificity\": 0.9999190271839561, \"npv\": 0.9998664268660312, \"accuracy\": 0.9997854980110255, \"f1\": 0.49254324878711037, \"f2\": 0.4583266209259129, \"f0_5\": 0.5322809803305454, \"p4\": 0.6599819624785679, \"phi\": 0.4962960141311816}, {\"truth_threshold\": -11.059999752789736, \"match_probability\": 0.0004681714763292323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634253.0, \"fp\": 103539.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999190303120407, \"fp_rate\": 8.096968795929666e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5625470032025552, \"recall\": 0.43803974852036937, \"specificity\": 0.9999190303120407, \"npv\": 0.9998664268664491, \"accuracy\": 0.9997855011383666, \"f1\": 0.4925468928894454, \"f2\": 0.458327883072983, \"f0_5\": 0.5322877896866167, \"p4\": 0.6599852342287205, \"phi\": 0.49630021059029206}, {\"truth_threshold\": -11.03999975323677, \"match_probability\": 0.0004747038040506886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634376.0, \"fp\": 103416.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999191265006423, \"fp_rate\": 8.087349935771664e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5628394973009304, \"recall\": 0.43803974852036937, \"specificity\": 0.9999191265006423, \"npv\": 0.9998664268792966, \"accuracy\": 0.9997855973041093, \"f1\": 0.49265897536464615, \"f2\": 0.4583666974890647, \"f0_5\": 0.5324972624664757, \"p4\": 0.6600858563832865, \"phi\": 0.49642930364920135}, {\"truth_threshold\": -11.019999753683805, \"match_probability\": 0.0004813272324887312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634407.0, \"fp\": 103385.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.999919150743298, \"fp_rate\": 8.084925670203388e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5629132633216647, \"recall\": 0.43803974852036937, \"specificity\": 0.999919150743298, \"npv\": 0.9998664268825346, \"accuracy\": 0.9997856215410037, \"f1\": 0.4926872318420405, \"f2\": 0.45837648102144346, \"f0_5\": 0.5325500824341307, \"p4\": 0.6601112212795779, \"phi\": 0.4964618551810188}, {\"truth_threshold\": -10.99999975413084, \"match_probability\": 0.0004880430309128137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133147.0, \"tn\": 1278634445.0, \"fp\": 103347.0, \"fn\": 170814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43803974852036937, \"tn_rate\": 0.9999191804601018, \"fp_rate\": 8.08195398982937e-05, \"fn_rate\": 0.5619602514796306, \"precision\": 0.5630037125677607, \"recall\": 0.43803974852036937, \"specificity\": 0.9999191804601018, \"npv\": 0.9998664268865037, \"accuracy\": 0.9997856512507454, \"f1\": 0.4927218732364397, \"f2\": 0.4583884743083222, \"f0_5\": 0.532614843788127, \"p4\": 0.6601423163925687, \"phi\": 0.4965017657878752}, {\"truth_threshold\": -10.979999754577875, \"match_probability\": 0.0004948524862419515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278634589.0, \"fp\": 103203.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999192930711475, \"fp_rate\": 8.07069288525415e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5633393414739407, \"recall\": 0.4380265889373966, \"specificity\": 0.9999192930711475, \"npv\": 0.9998664237740433, \"accuracy\": 0.9997857607076882, \"f1\": 0.49284203240009844, \"f2\": 0.45842141868488284, \"f0_5\": 0.532851214036155, \"p4\": 0.6602501642364997, \"phi\": 0.4966423719476878}, {\"truth_threshold\": -10.95999975502491, \"match_probability\": 0.0005017569032891706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640092.0, \"fp\": 97700.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999235965335417, \"fp_rate\": 7.64034664582745e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5767686262957941, \"recall\": 0.4380265889373966, \"specificity\": 0.9999235965335417, \"npv\": 0.9998664243488508, \"accuracy\": 0.9997900631473756, \"f1\": 0.49791325420153926, \"f2\": 0.4601651912265749, \"f0_5\": 0.5424078061944069, \"p4\": 0.6647859944772555, \"phi\": 0.5025310213099945}, {\"truth_threshold\": -10.939999755471945, \"match_probability\": 0.0005087576050093137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640196.0, \"fp\": 97596.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999236778637415, \"fp_rate\": 7.632213625856458e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5770285907453876, \"recall\": 0.4380265889373966, \"specificity\": 0.9999236778637415, \"npv\": 0.9998664243597138, \"accuracy\": 0.9997901444582474, \"f1\": 0.4980100991210024, \"f2\": 0.4601982741398178, \"f0_5\": 0.5425917156580274, \"p4\": 0.6648723162500413, \"phi\": 0.5026443332830142}, {\"truth_threshold\": -10.91999975591898, \"match_probability\": 0.0005158559327502502, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640220.0, \"fp\": 97572.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999236966322491, \"fp_rate\": 7.63033677509392e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5770886158247188, \"recall\": 0.4380265889373966, \"specificity\": 0.9999236966322491, \"npv\": 0.9998664243622207, \"accuracy\": 0.9997901632222947, \"f1\": 0.49803245329882023, \"f2\": 0.4602059093338053, \"f0_5\": 0.5426341740156062, \"p4\": 0.6648922398428034, \"phi\": 0.5026704930774399}, {\"truth_threshold\": -10.87999975681305, \"match_probability\": 0.000530350925182572, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640550.0, \"fp\": 97242.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999239546992289, \"fp_rate\": 7.604530077109037e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5779152288560453, \"recall\": 0.4380265889373966, \"specificity\": 0.9999239546992289, \"npv\": 0.9998664243966903, \"accuracy\": 0.9997904212279456, \"f1\": 0.49834002687397305, \"f2\": 0.4603109189485206, \"f0_5\": 0.5432186509843729, \"p4\": 0.6651663103785856, \"phi\": 0.5030306045811763}, {\"truth_threshold\": -10.859999757260084, \"match_probability\": 0.0005377503668442961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640598.0, \"fp\": 97194.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999239922362442, \"fp_rate\": 7.600776375583964e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5780356607926647, \"recall\": 0.4380265889373966, \"specificity\": 0.9999239922362442, \"npv\": 0.9998664244017039, \"accuracy\": 0.9997904587560403, \"f1\": 0.4983847964993318, \"f2\": 0.4603261970666189, \"f0_5\": 0.5433037707223239, \"p4\": 0.6652061940074734, \"phi\": 0.5030830488819242}, {\"truth_threshold\": -10.839999757707119, \"match_probability\": 0.0005452529889944806, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640673.0, \"fp\": 97119.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999240508878305, \"fp_rate\": 7.594911216951035e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5782239362117936, \"recall\": 0.4380265889373966, \"specificity\": 0.9999240508878305, \"npv\": 0.9998664244095379, \"accuracy\": 0.9997905173936883, \"f1\": 0.4984547651448927, \"f2\": 0.46035007115660953, \"f0_5\": 0.5434368237294583, \"p4\": 0.6652685217535997, \"phi\": 0.5031650259218226}, {\"truth_threshold\": -10.819999758154154, \"match_probability\": 0.0005528602288366581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640681.0, \"fp\": 97111.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999240571439997, \"fp_rate\": 7.59428560003019e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.578244026162412, \"recall\": 0.4380265889373966, \"specificity\": 0.9999240571439997, \"npv\": 0.9998664244103735, \"accuracy\": 0.9997905236483707, \"f1\": 0.49846222962664843, \"f2\": 0.46035261787237103, \"f0_5\": 0.5434510198967001, \"p4\": 0.6652751707358964, \"phi\": 0.5031737725028586}, {\"truth_threshold\": -10.799999758601189, \"match_probability\": 0.0005605735435487402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640723.0, \"fp\": 97069.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.999924089988888, \"fp_rate\": 7.59100111119575e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5783495213107918, \"recall\": 0.4380265889373966, \"specificity\": 0.999924089988888, \"npv\": 0.9998664244147606, \"accuracy\": 0.9997905564854536, \"f1\": 0.4985014218240158, \"f2\": 0.4603659885924197, \"f0_5\": 0.5435255619447603, \"p4\": 0.6653100800735505, \"phi\": 0.5032196995314367}, {\"truth_threshold\": -10.779999759048223, \"match_probability\": 0.000568394410559373, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640833.0, \"fp\": 96959.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999241760112146, \"fp_rate\": 7.582398878534123e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.578626000643193, \"recall\": 0.4380265889373966, \"specificity\": 0.9999241760112146, \"npv\": 0.9998664244262504, \"accuracy\": 0.9997906424873372, \"f1\": 0.4986040972694233, \"f2\": 0.46040101082613044, \"f0_5\": 0.5437208880656077, \"p4\": 0.6654015266563951, \"phi\": 0.5033400441810089}, {\"truth_threshold\": -10.759999759495258, \"match_probability\": 0.0005763243278280819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640834.0, \"fp\": 96958.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999241767932359, \"fp_rate\": 7.582320676419017e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.578628515304149, \"recall\": 0.4380265889373966, \"specificity\": 0.9999241767932359, \"npv\": 0.9998664244263549, \"accuracy\": 0.9997906432691724, \"f1\": 0.4986050308765649, \"f2\": 0.46040132923451443, \"f0_5\": 0.5437226644015469, \"p4\": 0.6654023581042716, \"phi\": 0.5033411386189989}, {\"truth_threshold\": -10.679999761283398, \"match_probability\": 0.0006091651932674106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640926.0, \"fp\": 96866.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999242487391817, \"fp_rate\": 7.575126081829292e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5788599576538309, \"recall\": 0.4380265889373966, \"specificity\": 0.9999242487391817, \"npv\": 0.9998664244359645, \"accuracy\": 0.9997907151980205, \"f1\": 0.49869093769312883, \"f2\": 0.46043062469006185, \"f0_5\": 0.5438861369758259, \"p4\": 0.665478860199019, \"phi\": 0.5034418574391302}, {\"truth_threshold\": -10.639999762177467, \"match_probability\": 0.0006262804318714204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640954.0, \"fp\": 96838.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999242706357739, \"fp_rate\": 7.572936422606332e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5789304333836274, \"recall\": 0.4380265889373966, \"specificity\": 0.9999242706357739, \"npv\": 0.9998664244388892, \"accuracy\": 0.9997907370894091, \"f1\": 0.4987170891220395, \"f2\": 0.4604395414382792, \"f0_5\": 0.543935909011059, \"p4\": 0.6655021469369802, \"phi\": 0.5034725229857349}, {\"truth_threshold\": -10.619999762624502, \"match_probability\": 0.000635017429035367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640969.0, \"fp\": 96823.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999242823660912, \"fp_rate\": 7.571763390879746e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5789681952984355, \"recall\": 0.4380265889373966, \"specificity\": 0.9999242823660912, \"npv\": 0.999866424440456, \"accuracy\": 0.9997907488169387, \"f1\": 0.4987310999443744, \"f2\": 0.46044431840974953, \"f0_5\": 0.5439625763487427, \"p4\": 0.6655146226455749, \"phi\": 0.5034889532604171}, {\"truth_threshold\": -10.599999763071537, \"match_probability\": 0.0006438762341536904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278640983.0, \"fp\": 96809.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999242933143874, \"fp_rate\": 7.570668561268267e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5790034441970499, \"recall\": 0.4380265889373966, \"specificity\": 0.9999242933143874, \"npv\": 0.9998664244419183, \"accuracy\": 0.999790759762633, \"f1\": 0.49874417742216426, \"f2\": 0.46044877700588466, \"f0_5\": 0.5439874682231696, \"p4\": 0.6655262670622824, \"phi\": 0.5035042896335744}, {\"truth_threshold\": -10.579999763518572, \"match_probability\": 0.0006528585432211498, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641929.0, \"fp\": 95863.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250331063962, \"fp_rate\": 7.496689360378269e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5813952472860973, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250331063962, \"npv\": 0.9998664245407307, \"accuracy\": 0.9997914993788323, \"f1\": 0.49962943296676904, \"f2\": 0.46075025089109595, \"f0_5\": 0.5456747419025644, \"p4\": 0.6663140420779307, \"phi\": 0.5045438454767297}, {\"truth_threshold\": -10.559999763965607, \"match_probability\": 0.0006619660757847269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641931.0, \"fp\": 95861.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250346704385, \"fp_rate\": 7.496532956148057e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5814003248851548, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250346704385, \"npv\": 0.9998664245409395, \"accuracy\": 0.9997915009425028, \"f1\": 0.4996313078719991, \"f2\": 0.46075088867479486, \"f0_5\": 0.5456783201650522, \"p4\": 0.6663157095398095, \"phi\": 0.5045460500889951}, {\"truth_threshold\": -10.519999764859676, \"match_probability\": 0.0006805638093056732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133143.0, \"tn\": 1278641992.0, \"fp\": 95800.0, \"fn\": 170818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380265889373966, \"tn_rate\": 0.9999250823737287, \"fp_rate\": 7.491762627126609e-05, \"fn_rate\": 0.5619734110626035, \"precision\": 0.5815552342722862, \"recall\": 0.4380265889373966, \"specificity\": 0.9999250823737287, \"npv\": 0.9998664245473112, \"accuracy\": 0.9997915486344565, \"f1\": 0.49968849924188974, \"f2\": 0.46077034192583405, \"f0_5\": 0.545787479718922, \"p4\": 0.6663665711364837, \"phi\": 0.504613304636857}, {\"truth_threshold\": -10.499999765306711, \"match_probability\": 0.0006900575700683387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642108.0, \"fp\": 95684.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999251730881823, \"fp_rate\": 7.482691181774348e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5818482165488188, \"recall\": 0.4380232990416534, \"specificity\": 0.9999251730881823, \"npv\": 0.999866423777557, \"accuracy\": 0.9997916385455167, \"f1\": 0.4997944769673434, \"f2\": 0.46080419749839063, \"f0_5\": 0.5459928727553075, \"p4\": 0.666460809479476, \"phi\": 0.5047385837703445}, {\"truth_threshold\": -10.479999765753746, \"match_probability\": 0.0006996836746108304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642112.0, \"fp\": 95680.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999251762162669, \"fp_rate\": 7.482378373313924e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5818583877424374, \"recall\": 0.4380232990416534, \"specificity\": 0.9999251762162669, \"npv\": 0.9998664237779747, \"accuracy\": 0.9997916416728578, \"f1\": 0.4997982292978567, \"f2\": 0.460805473375853, \"f0_5\": 0.5460000377281425, \"p4\": 0.6664641459059562, \"phi\": 0.5047429981932048}, {\"truth_threshold\": -10.45999976620078, \"match_probability\": 0.0007094439652109307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642124.0, \"fp\": 95668.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999251856005207, \"fp_rate\": 7.481439947932656e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5818889034570167, \"recall\": 0.4380232990416534, \"specificity\": 0.9999251856005207, \"npv\": 0.9998664237792282, \"accuracy\": 0.9997916510548815, \"f1\": 0.49980948662746283, \"f2\": 0.46080930105063217, \"f0_5\": 0.5460215337749887, \"p4\": 0.6664741553858329, \"phi\": 0.5047562421561773}, {\"truth_threshold\": -10.439999766647816, \"match_probability\": 0.0007193403097184756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642134.0, \"fp\": 95658.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999251934207322, \"fp_rate\": 7.4806579267816e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5819143356643357, \"recall\": 0.4380232990416534, \"specificity\": 0.9999251934207322, \"npv\": 0.9998664237802727, \"accuracy\": 0.9997916588732346, \"f1\": 0.49981886812285437, \"f2\": 0.4608124908281902, \"f0_5\": 0.5460394484403619, \"p4\": 0.6664824968487374, \"phi\": 0.5047672795877205}, {\"truth_threshold\": -10.41999976709485, \"match_probability\": 0.0007293746019082532, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642135.0, \"fp\": 95657.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999251942027534, \"fp_rate\": 7.480579724666494e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5819168790073384, \"recall\": 0.4380232990416534, \"specificity\": 0.9999251942027534, \"npv\": 0.9998664237803772, \"accuracy\": 0.9997916596550699, \"f1\": 0.49981980629176365, \"f2\": 0.4608128098083748, \"f0_5\": 0.5460412399715541, \"p4\": 0.6664833310065119, \"phi\": 0.5047683833706649}, {\"truth_threshold\": -10.399999767541885, \"match_probability\": 0.0007395487618377182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642156.0, \"fp\": 95636.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999252106251975, \"fp_rate\": 7.478937480249274e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5819702943464844, \"recall\": 0.4380232990416534, \"specificity\": 0.9999252106251975, \"npv\": 0.9998664237825707, \"accuracy\": 0.9997916760736113, \"f1\": 0.4998395086524546, \"f2\": 0.46081950849426356, \"f0_5\": 0.5460788648423843, \"p4\": 0.6665008488021248, \"phi\": 0.5047915644838682}, {\"truth_threshold\": -10.37999976798892, \"match_probability\": 0.0007498647362095799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642163.0, \"fp\": 95629.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999252160993456, \"fp_rate\": 7.478390065443534e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5819881016387567, \"recall\": 0.4380232990416534, \"specificity\": 0.9999252160993456, \"npv\": 0.9998664237833019, \"accuracy\": 0.9997916815464585, \"f1\": 0.4998460764511987, \"f2\": 0.4608217414328385, \"f0_5\": 0.5460914076182586, \"p4\": 0.6665066882719692, \"phi\": 0.504799292230745}, {\"truth_threshold\": -10.359999768435955, \"match_probability\": 0.0007603244987393332, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642182.0, \"fp\": 95610.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999252309577474, \"fp_rate\": 7.476904225256526e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5820364412114429, \"recall\": 0.4380232990416534, \"specificity\": 0.9999252309577474, \"npv\": 0.9998664237852865, \"accuracy\": 0.9997916964013293, \"f1\": 0.4998639042035768, \"f2\": 0.46082780237519694, \"f0_5\": 0.5461254552002553, \"p4\": 0.6665225387773541, \"phi\": 0.504820269331331}, {\"truth_threshold\": -10.33999976888299, \"match_probability\": 0.0007709300505277953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642203.0, \"fp\": 95589.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999252473801916, \"fp_rate\": 7.475261980839305e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5820898785035697, \"recall\": 0.4380232990416534, \"specificity\": 0.9999252473801916, \"npv\": 0.99986642378748, \"accuracy\": 0.9997917128198707, \"f1\": 0.4998836100410744, \"f2\": 0.4608345014969801, \"f0_5\": 0.54616309167805, \"p4\": 0.6665400586341225, \"phi\": 0.5048434575879904}, {\"truth_threshold\": -10.29999976977706, \"match_probability\": 0.0007925866654815217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133142.0, \"tn\": 1278642220.0, \"fp\": 95572.0, \"fn\": 170819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380232990416534, \"tn_rate\": 0.9999252606745511, \"fp_rate\": 7.473932544882509e-05, \"fn_rate\": 0.5619767009583466, \"precision\": 0.5821331444511486, \"recall\": 0.4380232990416534, \"specificity\": 0.9999252606745511, \"npv\": 0.9998664237892557, \"accuracy\": 0.9997917261110709, \"f1\": 0.4998995635237246, \"f2\": 0.46083992473822444, \"f0_5\": 0.5461935631025823, \"p4\": 0.6665542420499208, \"phi\": 0.504862231372419}, {\"truth_threshold\": -10.279999770224094, \"match_probability\": 0.0008036418711992888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133140.0, \"tn\": 1278644327.0, \"fp\": 93465.0, \"fn\": 170821.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43801671925016694, \"tn_rate\": 0.9999269083931165, \"fp_rate\": 7.309160688354787e-05, \"fn_rate\": 0.5619832807498331, \"precision\": 0.587542198980605, \"recall\": 0.43801671925016694, \"specificity\": 0.9999269083931165, \"npv\": 0.9998664224455996, \"accuracy\": 0.9997933718743894, \"f1\": 0.5018791253114598, \"f2\": 0.46150678464195266, \"f0_5\": 0.5499921099224129, \"p4\": 0.6683118302831129, \"phi\": 0.5072000222558475}, {\"truth_threshold\": -10.25999977067113, \"match_probability\": 0.0008148511520619635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645954.0, \"fp\": 91838.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999281807415292, \"fp_rate\": 7.181925847077804e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.591789382914698, \"recall\": 0.4380134293544238, \"specificity\": 0.9999281807415292, \"npv\": 0.9998664218336779, \"accuracy\": 0.9997946431385966, \"f1\": 0.5034200605742072, \"f2\": 0.46202477615193005, \"f0_5\": 0.5529629884979179, \"p4\": 0.6696767729709713, \"phi\": 0.5090291698460124}, {\"truth_threshold\": -10.239999771118164, \"match_probability\": 0.0008262166518649536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278645972.0, \"fp\": 91820.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.99992819481791, \"fp_rate\": 7.180518209005901e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5918367346938775, \"recall\": 0.4380134293544238, \"specificity\": 0.99992819481791, \"npv\": 0.9998664218355581, \"accuracy\": 0.9997946572116321, \"f1\": 0.5034371927701732, \"f2\": 0.4620305482428896, \"f0_5\": 0.552996061628331, \"p4\": 0.6696919327459324, \"phi\": 0.5090495470957593}, {\"truth_threshold\": -10.219999771565199, \"match_probability\": 0.0008377405441331278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278646067.0, \"fp\": 91725.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999282691099193, \"fp_rate\": 7.173089008070859e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5920867724491248, \"recall\": 0.4380134293544238, \"specificity\": 0.9999282691099193, \"npv\": 0.9998664218454812, \"accuracy\": 0.9997947314859862, \"f1\": 0.5035276320143715, \"f2\": 0.4620610144456753, \"f0_5\": 0.5531706798225386, \"p4\": 0.669771954041137, \"phi\": 0.5091571342137642}, {\"truth_threshold\": -10.179999772459269, \"match_probability\": 0.0008612723512743095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278646984.0, \"fp\": 90808.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999289862233148, \"fp_rate\": 7.101377668518926e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5945112013110245, \"recall\": 0.4380134293544238, \"specificity\": 0.9999289862233148, \"npv\": 0.999866421941266, \"accuracy\": 0.9997954484289615, \"f1\": 0.5044022822158406, \"f2\": 0.4623553001789843, \"f0_5\": 0.554861891945732, \"p4\": 0.6705453544503441, \"phi\": 0.5101991494431004}, {\"truth_threshold\": -10.159999772906303, \"match_probability\": 0.0008732847655576527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647028.0, \"fp\": 90764.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999290206322454, \"fp_rate\": 7.097936775454276e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5946280308883758, \"recall\": 0.4380134293544238, \"specificity\": 0.9999290206322454, \"npv\": 0.999866421945862, \"accuracy\": 0.999795482829715, \"f1\": 0.5044443265689648, \"f2\": 0.4623694301846088, \"f0_5\": 0.5549433006578174, \"p4\": 0.6705825090855623, \"phi\": 0.5102493088458919}, {\"truth_threshold\": -10.139999773353338, \"match_probability\": 0.0008854645719739357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647087.0, \"fp\": 90705.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999290667714934, \"fp_rate\": 7.093322850663039e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.594784760815568, \"recall\": 0.4380134293544238, \"specificity\": 0.9999290667714934, \"npv\": 0.9998664219520248, \"accuracy\": 0.999795528957998, \"f1\": 0.5045007152262673, \"f2\": 0.46238837859313964, \"f0_5\": 0.5550524998394947, \"p4\": 0.6706323365363953, \"phi\": 0.5103165912504398}, {\"truth_threshold\": -10.119999773800373, \"match_probability\": 0.0008978140989500266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647094.0, \"fp\": 90698.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999290722456414, \"fp_rate\": 7.092775435857298e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5948033613745717, \"recall\": 0.4380134293544238, \"specificity\": 0.9999290722456414, \"npv\": 0.999866421952756, \"accuracy\": 0.9997955344308451, \"f1\": 0.5045074062425398, \"f2\": 0.4623906268124675, \"f0_5\": 0.5550654585265349, \"p4\": 0.6706382487592407, \"phi\": 0.5103245756735006}, {\"truth_threshold\": -10.099999774247408, \"match_probability\": 0.0009103357071841042, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647125.0, \"fp\": 90667.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999290964882971, \"fp_rate\": 7.090351170289022e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5948857492649884, \"recall\": 0.4380134293544238, \"specificity\": 0.9999290964882971, \"npv\": 0.9998664219559941, \"accuracy\": 0.9997955586677396, \"f1\": 0.5045370400195541, \"f2\": 0.46240058347515023, \"f0_5\": 0.5551228542718596, \"p4\": 0.670664432713506, \"phi\": 0.5103599397630652}, {\"truth_threshold\": -10.079999774694443, \"match_probability\": 0.0009230317900896363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647168.0, \"fp\": 90624.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999291301152066, \"fp_rate\": 7.086988479339476e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5950000670352114, \"recall\": 0.4380134293544238, \"specificity\": 0.9999291301152066, \"npv\": 0.9998664219604856, \"accuracy\": 0.9997955922866577, \"f1\": 0.5045781506999871, \"f2\": 0.4624143950397574, \"f0_5\": 0.5552024873792027, \"p4\": 0.6707007557771881, \"phi\": 0.5104090053412931}, {\"truth_threshold\": -10.059999775141478, \"match_probability\": 0.0009359047742453745, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647198.0, \"fp\": 90594.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999291535758411, \"fp_rate\": 7.084642415886305e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5950798496422075, \"recall\": 0.4380134293544238, \"specificity\": 0.9999291535758411, \"npv\": 0.9998664219636192, \"accuracy\": 0.9997956157417169, \"f1\": 0.504606836537842, \"f2\": 0.46242403150369865, \"f0_5\": 0.5552580588926618, \"p4\": 0.6707260997796711, \"phi\": 0.5104432455149022}, {\"truth_threshold\": -10.039999775588512, \"match_probability\": 0.0009489571198514448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647236.0, \"fp\": 90556.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999291832926449, \"fp_rate\": 7.081670735512289e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5951809383312099, \"recall\": 0.4380134293544238, \"specificity\": 0.9999291832926449, \"npv\": 0.9998664219675885, \"accuracy\": 0.9997956454514585, \"f1\": 0.5046431766150674, \"f2\": 0.4624362382679455, \"f0_5\": 0.5553284654483329, \"p4\": 0.670758204932561, \"phi\": 0.5104866262871118}, {\"truth_threshold\": -10.019999776035547, \"match_probability\": 0.0009621913211916086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133139.0, \"tn\": 1278647239.0, \"fp\": 90553.0, \"fn\": 170822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380134293544238, \"tn_rate\": 0.9999291856387084, \"fp_rate\": 7.081436129166972e-05, \"fn_rate\": 0.5619865706455762, \"precision\": 0.5951889204799456, \"recall\": 0.4380134293544238, \"specificity\": 0.9999291856387084, \"npv\": 0.9998664219679018, \"accuracy\": 0.9997956477969645, \"f1\": 0.5046460457914577, \"f2\": 0.46243720198730703, \"f0_5\": 0.5553340246210778, \"p4\": 0.6707607396807956, \"phi\": 0.5104900515556048}, {\"truth_threshold\": -9.999999776482582, \"match_probability\": 0.0009756099071017838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656730.0, \"fp\": 81062.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.999936607801453, \"fp_rate\": 6.339219854698718e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6215575236112213, \"recall\": 0.43800684956293734, \"specificity\": 0.999936607801453, \"npv\": 0.9998664213955465, \"accuracy\": 0.9998030666321805, \"f1\": 0.5138837424733673, \"f2\": 0.4654999884618854, \"f0_5\": 0.5734921262589845, \"p4\": 0.6788718938982397, \"phi\": 0.521678589713324}, {\"truth_threshold\": -9.979999776929617, \"match_probability\": 0.0009892154414448979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656748.0, \"fp\": 81044.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366218778337, \"fp_rate\": 6.337812216626815e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6216097599693717, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366218778337, \"npv\": 0.9998664213974267, \"accuracy\": 0.9998030807052161, \"f1\": 0.5139015945435808, \"f2\": 0.46550584779986365, \"f0_5\": 0.5735277013143101, \"p4\": 0.6788874730783181, \"phi\": 0.5217005235626374}, {\"truth_threshold\": -9.959999777376652, \"match_probability\": 0.0010030105235921652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656762.0, \"fp\": 81030.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366328261299, \"fp_rate\": 6.336717387015336e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6216503943184524, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366328261299, \"npv\": 0.999866421398889, \"accuracy\": 0.9998030916509103, \"f1\": 0.5139154803446253, \"f2\": 0.46551040516471553, \"f0_5\": 0.5735553738533158, \"p4\": 0.6788995907127376, \"phi\": 0.5217175851345406}, {\"truth_threshold\": -9.939999777823687, \"match_probability\": 0.0010169977889108628, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656806.0, \"fp\": 80986.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366672350605, \"fp_rate\": 6.333276493950685e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6217781368652597, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366672350605, \"npv\": 0.999866421403485, \"accuracy\": 0.9998031260516638, \"f1\": 0.5139591263192841, \"f2\": 0.4655247288923451, \"f0_5\": 0.573642362077568, \"p4\": 0.678937677522979, \"phi\": 0.5217712181086189}, {\"truth_threshold\": -9.919999778270721, \"match_probability\": 0.001031179909258699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656815.0, \"fp\": 80977.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366742732508, \"fp_rate\": 6.332572674914733e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6218042724903556, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366742732508, \"npv\": 0.999866421404425, \"accuracy\": 0.9998031330881815, \"f1\": 0.5139680548183179, \"f2\": 0.465527658854316, \"f0_5\": 0.5736601583741017, \"p4\": 0.6789454685333475, \"phi\": 0.5217821905258635}, {\"truth_threshold\": -9.899999778717756, \"match_probability\": 0.0010455595934848532, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133137.0, \"tn\": 1278656822.0, \"fp\": 80970.0, \"fn\": 170824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800684956293734, \"tn_rate\": 0.9999366797473989, \"fp_rate\": 6.332025260108993e-05, \"fn_rate\": 0.5619931504370627, \"precision\": 0.6218246017178327, \"recall\": 0.43800684956293734, \"specificity\": 0.9999366797473989, \"npv\": 0.9998664214051562, \"accuracy\": 0.9998031385610286, \"f1\": 0.5139749994209254, \"f2\": 0.4655299377391253, \"f0_5\": 0.5736740007014889, \"p4\": 0.6789515283317001, \"phi\": 0.521790725106374}, {\"truth_threshold\": -9.879999779164791, \"match_probability\": 0.001060139587937777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133136.0, \"tn\": 1278661506.0, \"fp\": 76286.0, \"fn\": 170825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380035596671941, \"tn_rate\": 0.9999403427344704, \"fp_rate\": 5.965726552953868e-05, \"fn_rate\": 0.5619964403328058, \"precision\": 0.635730725520719, \"recall\": 0.4380035596671941, \"specificity\": 0.9999403427344704, \"npv\": 0.9998664211125579, \"accuracy\": 0.9998067998957654, \"f1\": 0.5186615061270046, \"f2\": 0.4670566757363187, \"f0_5\": 0.5830863952055316, \"p4\": 0.6830282958454098, \"phi\": 0.5275944415476156}, {\"truth_threshold\": -9.859999779611826, \"match_probability\": 0.001074922676979845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133136.0, \"tn\": 1278661514.0, \"fp\": 76278.0, \"fn\": 170825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4380035596671941, \"tn_rate\": 0.9999403489906397, \"fp_rate\": 5.965100936033022e-05, \"fn_rate\": 0.5619964403328058, \"precision\": 0.6357550116038088, \"recall\": 0.4380035596671941, \"specificity\": 0.9999403489906397, \"npv\": 0.9998664211133935, \"accuracy\": 0.9998068061504478, \"f1\": 0.5186695885074264, \"f2\": 0.467059297334237, \"f0_5\": 0.5831027393600481, \"p4\": 0.6830353049342471, \"phi\": 0.5276045248771696}, {\"truth_threshold\": -9.83999978005886, \"match_probability\": 0.0010899116835089422, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661566.0, \"fp\": 76226.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999403896557395, \"fp_rate\": 5.961034426047526e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.6359111773443956, \"recall\": 0.43800026977145096, \"specificity\": 0.9999403896557395, \"npv\": 0.9998664203369663, \"accuracy\": 0.9998068460240485, \"f1\": 0.5187192444508515, \"f2\": 0.4670731578965833, \"f0_5\": 0.5832066619648592, \"p4\": 0.6830783653990167, \"phi\": 0.5276673766470793}, {\"truth_threshold\": -9.819999780505896, \"match_probability\": 0.001105109469487079, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661594.0, \"fp\": 76198.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999404115523317, \"fp_rate\": 5.958844766824566e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.6359962356627956, \"recall\": 0.43800026977145096, \"specificity\": 0.9999404115523317, \"npv\": 0.9998664203398909, \"accuracy\": 0.999806867915437, \"f1\": 0.5187475403959524, \"f2\": 0.4670823343346125, \"f0_5\": 0.5832638945476754, \"p4\": 0.6831029016205046, \"phi\": 0.5277026859872581}, {\"truth_threshold\": -9.79999978095293, \"match_probability\": 0.0011205189364761256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661603.0, \"fp\": 76189.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999404185905221, \"fp_rate\": 5.9581409477886146e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.6360235806692018, \"recall\": 0.43800026977145096, \"specificity\": 0.9999404185905221, \"npv\": 0.9998664203408311, \"accuracy\": 0.9998068749519547, \"f1\": 0.5187566361767829, \"f2\": 0.46708528398055527, \"f0_5\": 0.5832822931206556, \"p4\": 0.6831107886374758, \"phi\": 0.527714036922299}, {\"truth_threshold\": -9.779999781399965, \"match_probability\": 0.0011361430261807566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661618.0, \"fp\": 76174.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999404303208393, \"fp_rate\": 5.9569679160620285e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.6360691609056467, \"recall\": 0.43800026977145096, \"specificity\": 0.9999404303208393, \"npv\": 0.9998664203423979, \"accuracy\": 0.9998068866794844, \"f1\": 0.5187717965203499, \"f2\": 0.4670902001399148, \"f0_5\": 0.5833129599885033, \"p4\": 0.683123934070491, \"phi\": 0.5277329567739409}, {\"truth_threshold\": -9.739999782294035, \"match_probability\": 0.0011680470445783785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133135.0, \"tn\": 1278661694.0, \"fp\": 76098.0, \"fn\": 170826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43800026977145096, \"tn_rate\": 0.9999404897544468, \"fp_rate\": 5.951024555313995e-05, \"fn_rate\": 0.5619997302285491, \"precision\": 0.63630020121109, \"recall\": 0.43800026977145096, \"specificity\": 0.9999404897544468, \"npv\": 0.9998664203503365, \"accuracy\": 0.9998069460989676, \"f1\": 0.5188486225481982, \"f2\": 0.4671151102712345, \"f0_5\": 0.5834683883589434, \"p4\": 0.6831905453740759, \"phi\": 0.5278288486163252}, {\"truth_threshold\": -9.71999978274107, \"match_probability\": 0.0011843330623840628, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133134.0, \"tn\": 1278661734.0, \"fp\": 76058.0, \"fn\": 170827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799697987570774, \"tn_rate\": 0.9999405210352929, \"fp_rate\": 5.947896470709767e-05, \"fn_rate\": 0.5620030201242923, \"precision\": 0.6364201307889403, \"recall\": 0.43799697987570774, \"specificity\": 0.9999405210352929, \"npv\": 0.9998664195726559, \"accuracy\": 0.9998069765905445, \"f1\": 0.5188861801451029, \"f2\": 0.46712504105159447, \"f0_5\": 0.5835478891130146, \"p4\": 0.6832231070616964, \"phi\": 0.5278766349523711}, {\"truth_threshold\": -9.699999783188105, \"match_probability\": 0.0012008458822685877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133134.0, \"tn\": 1278661746.0, \"fp\": 76046.0, \"fn\": 170827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799697987570774, \"tn_rate\": 0.9999405304195467, \"fp_rate\": 5.946958045328498e-05, \"fn_rate\": 0.5620030201242923, \"precision\": 0.6364566402141696, \"recall\": 0.43799697987570774, \"specificity\": 0.9999405304195467, \"npv\": 0.9998664195739093, \"accuracy\": 0.9998069859725681, \"f1\": 0.5188983144983542, \"f2\": 0.4671289746699003, \"f0_5\": 0.5835724448816102, \"p4\": 0.6832336269051781, \"phi\": 0.5278917848830853}, {\"truth_threshold\": -9.67999978363514, \"match_probability\": 0.0012175886550537785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133134.0, \"tn\": 1278661760.0, \"fp\": 76032.0, \"fn\": 170827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799697987570774, \"tn_rate\": 0.9999405413678428, \"fp_rate\": 5.945863215717018e-05, \"fn_rate\": 0.5620030201242923, \"precision\": 0.6364992398382147, \"recall\": 0.43799697987570774, \"specificity\": 0.9999405413678428, \"npv\": 0.9998664195753717, \"accuracy\": 0.9998069969182625, \"f1\": 0.5189124719611324, \"f2\": 0.4671335639749897, \"f0_5\": 0.583601095890411, \"p4\": 0.6832459004653585, \"phi\": 0.5279094614496916}, {\"truth_threshold\": -9.659999784082174, \"match_probability\": 0.0012345645751186526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133132.0, \"tn\": 1278661816.0, \"fp\": 75976.0, \"fn\": 170829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43799040008422135, \"tn_rate\": 0.9999405851610272, \"fp_rate\": 5.941483897271099e-05, \"fn_rate\": 0.5620095999157787, \"precision\": 0.6366662203263386, \"recall\": 0.43799040008422135, \"specificity\": 0.9999405851610272, \"npv\": 0.9998664180175038, \"accuracy\": 0.999807039137369, \"f1\": 0.5189633363153884, \"f2\": 0.46714555999079266, \"f0_5\": 0.5837110539962977, \"p4\": 0.6832899948624842, \"phi\": 0.5279747772864499}, {\"truth_threshold\": -9.63999978452921, \"match_probability\": 0.0012517768809955122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662281.0, \"fp\": 75511.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999409488008625, \"fp_rate\": 5.905119913746946e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6380834156114301, \"recall\": 0.43798711018847813, \"specificity\": 0.9999409488008625, \"npv\": 0.9998664172842174, \"accuracy\": 0.9998074019089508, \"f1\": 0.5194312167505848, \"f2\": 0.46729486986885094, \"f0_5\": 0.5846623142669181, \"p4\": 0.6836954598229225, \"phi\": 0.5285604336805444}, {\"truth_threshold\": -9.619999784976244, \"match_probability\": 0.001269228855974021, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662282.0, \"fp\": 75510.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999409495828837, \"fp_rate\": 5.90504171163184e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6380864738953513, \"recall\": 0.43798711018847813, \"specificity\": 0.9999409495828837, \"npv\": 0.9998664172843219, \"accuracy\": 0.9998074026907862, \"f1\": 0.5194322300732342, \"f2\": 0.46729519791363194, \"f0_5\": 0.5846643683713577, \"p4\": 0.6836963376965206, \"phi\": 0.5285617010906531}, {\"truth_threshold\": -9.599999785423279, \"match_probability\": 0.0012869238287133728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662321.0, \"fp\": 75471.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999409800817086, \"fp_rate\": 5.901991829142718e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6382057698392154, \"recall\": 0.43798711018847813, \"specificity\": 0.9999409800817086, \"npv\": 0.9998664172883958, \"accuracy\": 0.9998074331823631, \"f1\": 0.5194717527406387, \"f2\": 0.46730799201935347, \"f0_5\": 0.5847444897041293, \"p4\": 0.6837305765253715, \"phi\": 0.5286111371919021}, {\"truth_threshold\": -9.579999785870314, \"match_probability\": 0.0013048651738626527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662330.0, \"fp\": 75462.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.999940987119899, \"fp_rate\": 5.9012880101067664e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6382333060073924, \"recall\": 0.43798711018847813, \"specificity\": 0.999940987119899, \"npv\": 0.9998664172893359, \"accuracy\": 0.9998074402188808, \"f1\": 0.5194808742103271, \"f2\": 0.4673109446047807, \"f0_5\": 0.584762982361049, \"p4\": 0.6837384782805735, \"phi\": 0.5286225474914384}, {\"truth_threshold\": -9.559999786317348, \"match_probability\": 0.0013230563126894958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662333.0, \"fp\": 75459.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999409894659624, \"fp_rate\": 5.901053403761449e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.638242485258162, \"recall\": 0.43798711018847813, \"specificity\": 0.9999409894659624, \"npv\": 0.9998664172896492, \"accuracy\": 0.9998074425643867, \"f1\": 0.5194839147714081, \"f2\": 0.46731192880821437, \"f0_5\": 0.5847691468399511, \"p4\": 0.6837411122395607, \"phi\": 0.5286263510886906}, {\"truth_threshold\": -9.539999786764383, \"match_probability\": 0.0013415007137171481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662337.0, \"fp\": 75455.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.999940992594047, \"fp_rate\": 5.900740595301026e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6382547246699203, \"recall\": 0.43798711018847813, \"specificity\": 0.999940992594047, \"npv\": 0.9998664172900671, \"accuracy\": 0.999807445691728, \"f1\": 0.5194879689082172, \"f2\": 0.46731324108590805, \"f0_5\": 0.5847773663473322, \"p4\": 0.6837446242164448, \"phi\": 0.5286314226793141}, {\"truth_threshold\": -9.519999787211418, \"match_probability\": 0.0013602018933700395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662381.0, \"fp\": 75411.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410270029776, \"fp_rate\": 5.8972997022363755e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6383893891877895, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410270029776, \"npv\": 0.9998664172946632, \"accuracy\": 0.9998074800924814, \"f1\": 0.5195325685898424, \"f2\": 0.4673276766269817, \"f0_5\": 0.5848677961812765, \"p4\": 0.6837832583434478, \"phi\": 0.5286872198043856}, {\"truth_threshold\": -9.499999787658453, \"match_probability\": 0.0013791634166279733, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662409.0, \"fp\": 75383.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410488995699, \"fp_rate\": 5.895110043013416e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.638475114380809, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410488995699, \"npv\": 0.999866417297588, \"accuracy\": 0.9998075019838699, \"f1\": 0.5195609541928875, \"f2\": 0.467336863344749, \"f0_5\": 0.5849253570025755, \"p4\": 0.6838078459702548, \"phi\": 0.5287227362591523}, {\"truth_threshold\": -9.479999788105488, \"match_probability\": 0.0013983888976890446, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662415.0, \"fp\": 75377.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410535916968, \"fp_rate\": 5.894640830322781e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6384934870604485, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410535916968, \"npv\": 0.9998664172982147, \"accuracy\": 0.9998075066748818, \"f1\": 0.5195670372256663, \"f2\": 0.46733883197411874, \"f0_5\": 0.5849376929383573, \"p4\": 0.683813114977483, \"phi\": 0.5287303478586012}, {\"truth_threshold\": -9.459999788552523, \"match_probability\": 0.0014178820006413976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662422.0, \"fp\": 75370.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410590658449, \"fp_rate\": 5.8940934155170415e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6385149231898168, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410590658449, \"npv\": 0.9998664172989459, \"accuracy\": 0.9998075121477289, \"f1\": 0.5195741342772733, \"f2\": 0.46734112872934575, \"f0_5\": 0.5849520855210837, \"p4\": 0.6838192622552106, \"phi\": 0.5287392284731336}, {\"truth_threshold\": -9.419999789446592, \"match_probability\": 0.0014576859821160684, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662461.0, \"fp\": 75331.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999410895646698, \"fp_rate\": 5.8910435330279186e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6386343794072781, \"recall\": 0.43798711018847813, \"specificity\": 0.9999410895646698, \"npv\": 0.9998664173030197, \"accuracy\": 0.9998075426393058, \"f1\": 0.5196136785429225, \"f2\": 0.46735392535031095, \"f0_5\": 0.5850322857351278, \"p4\": 0.6838535133973538, \"phi\": 0.5287887143692567}, {\"truth_threshold\": -9.399999789893627, \"match_probability\": 0.0014780044444367049, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662487.0, \"fp\": 75305.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999411098972196, \"fp_rate\": 5.889010278035171e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6387140417202403, \"recall\": 0.43798711018847813, \"specificity\": 0.9999411098972196, \"npv\": 0.9998664173057356, \"accuracy\": 0.9998075629670238, \"f1\": 0.519640044730941, \"f2\": 0.46736245682028815, \"f0_5\": 0.5850857647632735, \"p4\": 0.6838763493983698, \"phi\": 0.5288217126808935}, {\"truth_threshold\": -9.379999790340662, \"match_probability\": 0.0014986056976524496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662519.0, \"fp\": 75273.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999411349218965, \"fp_rate\": 5.886507810351788e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6388121149306155, \"recall\": 0.43798711018847813, \"specificity\": 0.9999411349218965, \"npv\": 0.9998664173090782, \"accuracy\": 0.9998075879857535, \"f1\": 0.5196724990973232, \"f2\": 0.4673729575186344, \"f0_5\": 0.5851515985291545, \"p4\": 0.6839044573395304, \"phi\": 0.5288623344627588}, {\"truth_threshold\": -9.359999790787697, \"match_probability\": 0.001519493665695272, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133131.0, \"tn\": 1278662588.0, \"fp\": 75204.0, \"fn\": 170830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43798711018847813, \"tn_rate\": 0.9999411888813559, \"fp_rate\": 5.8811118644094945e-05, \"fn_rate\": 0.5620128898115219, \"precision\": 0.6390236878104976, \"recall\": 0.43798711018847813, \"specificity\": 0.9999411888813559, \"npv\": 0.9998664173162857, \"accuracy\": 0.9998076419323897, \"f1\": 0.5197424926214532, \"f2\": 0.4673956012551793, \"f0_5\": 0.5852936030127468, \"p4\": 0.6839650729506794, \"phi\": 0.5289499570193003}, {\"truth_threshold\": -9.339999791234732, \"match_probability\": 0.0015406723266096838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663058.0, \"fp\": 74734.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999415564312969, \"fp_rate\": 5.8443568703098126e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6404633843607779, \"recall\": 0.43797724050124853, \"specificity\": 0.9999415564312969, \"npv\": 0.9998664150198066, \"accuracy\": 0.9998080070494775, \"f1\": 0.5202110885989883, \"f2\": 0.46754034892035296, \"f0_5\": 0.5862557016898756, \"p4\": 0.6843707419829006, \"phi\": 0.529539852499133}, {\"truth_threshold\": -9.319999791681767, \"match_probability\": 0.0015621457132895629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663081.0, \"fp\": 74711.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999415744177834, \"fp_rate\": 5.8425582216623813e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6405342596913958, \"recall\": 0.43797724050124853, \"specificity\": 0.9999415744177834, \"npv\": 0.9998664150222091, \"accuracy\": 0.9998080250316895, \"f1\": 0.5202344665885111, \"f2\": 0.4675479021664233, \"f0_5\": 0.5863032087073479, \"p4\": 0.6843909740085868, \"phi\": 0.5295691688003846}, {\"truth_threshold\": -9.299999792128801, \"match_probability\": 0.001583917914224747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663366.0, \"fp\": 74426.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999417972938114, \"fp_rate\": 5.8202706188572554e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.64141380074583, \"recall\": 0.43797724050124853, \"specificity\": 0.9999417972938114, \"npv\": 0.9998664150519797, \"accuracy\": 0.9998082478547516, \"f1\": 0.5205243247998592, \"f2\": 0.46764151698962625, \"f0_5\": 0.5868925220666615, \"p4\": 0.6846417744820454, \"phi\": 0.5299328401403193}, {\"truth_threshold\": -9.279999792575836, \"match_probability\": 0.001605993074257518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663374.0, \"fp\": 74418.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999418035499806, \"fp_rate\": 5.8196450019364096e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6414385244716834, \"recall\": 0.43797724050124853, \"specificity\": 0.9999418035499806, \"npv\": 0.9998664150528154, \"accuracy\": 0.9998082541094341, \"f1\": 0.5205324658313571, \"f2\": 0.4676441453150577, \"f0_5\": 0.5869090812903112, \"p4\": 0.6846488171476484, \"phi\": 0.529943059263823}, {\"truth_threshold\": -9.259999793022871, \"match_probability\": 0.0016283753953490986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663389.0, \"fp\": 74403.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999418152802979, \"fp_rate\": 5.818471970209824e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6414848865952556, \"recall\": 0.43797724050124853, \"specificity\": 0.9999418152802979, \"npv\": 0.9998664150543822, \"accuracy\": 0.9998082658369637, \"f1\": 0.5205477309518037, \"f2\": 0.467649073504874, \"f0_5\": 0.586940132353395, \"p4\": 0.6846620225361874, \"phi\": 0.5299622217127133}, {\"truth_threshold\": -9.239999793469906, \"match_probability\": 0.0016510691373562859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278663397.0, \"fp\": 74395.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999418215364672, \"fp_rate\": 5.817846353288978e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.641509615801622, \"recall\": 0.43797724050124853, \"specificity\": 0.9999418215364672, \"npv\": 0.9998664150552179, \"accuracy\": 0.9998082720916461, \"f1\": 0.5205558727154711, \"f2\": 0.46765170191524746, \"f0_5\": 0.5869566942638483, \"p4\": 0.6846690656183676, \"phi\": 0.5299724425347986}, {\"truth_threshold\": -9.21999979391694, \"match_probability\": 0.0016740786188183547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278667874.0, \"fp\": 69918.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999453226451603, \"fp_rate\": 5.4677354839607335e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6556543837357052, \"recall\": 0.43797724050124853, \"specificity\": 0.9999453226451603, \"npv\": 0.9998664155228764, \"accuracy\": 0.9998117723683099, \"f1\": 0.5251525126872015, \"f2\": 0.4691272755463778, \"f0_5\": 0.596374127017547, \"p4\": 0.6886334131140333, \"phi\": 0.5357866633344849}, {\"truth_threshold\": -9.199999794363976, \"match_probability\": 0.001697408217754341, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278667888.0, \"fp\": 69904.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999453335934565, \"fp_rate\": 5.4666406543492536e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6556995941526459, \"recall\": 0.43797724050124853, \"specificity\": 0.9999453335934565, \"npv\": 0.9998664155243389, \"accuracy\": 0.9998117833140041, \"f1\": 0.5251670141402347, \"f2\": 0.46913190440884195, \"f0_5\": 0.5964040502146334, \"p4\": 0.6886458820072415, \"phi\": 0.5358051459688862}, {\"truth_threshold\": -9.17999979481101, \"match_probability\": 0.0017210623724708569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278668529.0, \"fp\": 69263.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999458348690143, \"fp_rate\": 5.416513098566496e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6577762845185804, \"recall\": 0.43797724050124853, \"specificity\": 0.9999458348690143, \"npv\": 0.9998664155912962, \"accuracy\": 0.9998122844704351, \"f1\": 0.5258318324011755, \"f2\": 0.46934393806386104, \"f0_5\": 0.5977773287532835, \"p4\": 0.6892172632178674, \"phi\": 0.5366534391270782}, {\"truth_threshold\": -9.159999795258045, \"match_probability\": 0.001745045582380546, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133128.0, \"tn\": 1278668549.0, \"fp\": 69243.0, \"fn\": 170833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43797724050124853, \"tn_rate\": 0.9999458505094374, \"fp_rate\": 5.4149490562643824e-05, \"fn_rate\": 0.5620227594987515, \"precision\": 0.6578412914893933, \"recall\": 0.43797724050124853, \"specificity\": 0.9999458505094374, \"npv\": 0.9998664155933853, \"accuracy\": 0.9998123001071412, \"f1\": 0.525852602640165, \"f2\": 0.46935055686197086, \"f0_5\": 0.5978202785050003, \"p4\": 0.68923510627871, \"phi\": 0.536679971740367}, {\"truth_threshold\": -9.13999979570508, \"match_probability\": 0.0017693624088313273, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133123.0, \"tn\": 1278668743.0, \"fp\": 69049.0, \"fn\": 170838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379607910225325, \"tn_rate\": 0.9999460022215406, \"fp_rate\": 5.399777845933876e-05, \"fn_rate\": 0.5620392089774675, \"precision\": 0.6584640800902202, \"recall\": 0.4379607910225325, \"specificity\": 0.9999460022215406, \"npv\": 0.9998664117043778, \"accuracy\": 0.999812447874014, \"f1\": 0.5260395982874067, \"f2\": 0.46939879380768623, \"f0_5\": 0.5982254960908606, \"p4\": 0.6893957273434989, \"phi\": 0.5369240119016526}, {\"truth_threshold\": -9.119999796152115, \"match_probability\": 0.0017940174759465434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133123.0, \"tn\": 1278668805.0, \"fp\": 68987.0, \"fn\": 170838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379607910225325, \"tn_rate\": 0.999946050706852, \"fp_rate\": 5.3949293147973216e-05, \"fn_rate\": 0.5620392089774675, \"precision\": 0.6586660729305823, \"recall\": 0.4379607910225325, \"specificity\": 0.999946050706852, \"npv\": 0.9998664117108543, \"accuracy\": 0.999812496347803, \"f1\": 0.5261040446893815, \"f2\": 0.4694193182571508, \"f0_5\": 0.598358865193397, \"p4\": 0.6894510745700316, \"phi\": 0.5370064064101433}, {\"truth_threshold\": -9.09999979659915, \"match_probability\": 0.0018190154714761667, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133123.0, \"tn\": 1278668823.0, \"fp\": 68969.0, \"fn\": 170838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379607910225325, \"tn_rate\": 0.9999460647832328, \"fp_rate\": 5.393521676725419e-05, \"fn_rate\": 0.5620392089774675, \"precision\": 0.6587247392276785, \"recall\": 0.4379607910225325, \"specificity\": 0.9999460647832328, \"npv\": 0.9998664117127346, \"accuracy\": 0.9998125104208385, \"f1\": 0.5261227578929479, \"f2\": 0.46942527730447636, \"f0_5\": 0.5983975963945919, \"p4\": 0.6894671447842796, \"phi\": 0.5370303344968665}, {\"truth_threshold\": -9.079999797046185, \"match_probability\": 0.0018443611476591784, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278669237.0, \"fp\": 68555.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999463885399893, \"fp_rate\": 5.361146001071657e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6600735833713481, \"recall\": 0.4379542112310461, \"specificity\": 0.9999463885399893, \"npv\": 0.999866410192273, \"accuracy\": 0.9998128325369844, \"f1\": 0.5265477012164853, \"f2\": 0.4695559851007393, \"f0_5\": 0.5992851129728586, \"p4\": 0.6898319648477539, \"phi\": 0.5375761518095858}, {\"truth_threshold\": -9.05999979749322, \"match_probability\": 0.0018700593220972754, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672344.0, \"fp\": 65448.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488182797056, \"fp_rate\": 5.118172029438229e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6704017243376358, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488182797056, \"npv\": 0.9998664105168347, \"accuracy\": 0.9998152616992794, \"f1\": 0.5298031958291047, \"f2\": 0.4705874451097381, \"f0_5\": 0.6060668143579209, \"p4\": 0.6926201289664173, \"phi\": 0.5417678901866497}, {\"truth_threshold\": -9.039999797940254, \"match_probability\": 0.001896114878640028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672356.0, \"fp\": 65436.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488276639594, \"fp_rate\": 5.117233604056961e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6704422407671349, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488276639594, \"npv\": 0.9998664105180882, \"accuracy\": 0.999815271081303, \"f1\": 0.5298158473925312, \"f2\": 0.4705914376474564, \"f0_5\": 0.6060933045222635, \"p4\": 0.6926309412368747, \"phi\": 0.5417842701624068}, {\"truth_threshold\": -9.019999798387289, \"match_probability\": 0.0019225327682816397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672377.0, \"fp\": 65415.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488440864036, \"fp_rate\": 5.115591359639741e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6705131563041463, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488440864036, \"npv\": 0.9998664105202819, \"accuracy\": 0.9998152874998444, \"f1\": 0.5298379890825219, \"f2\": 0.4705984247514812, \"f0_5\": 0.6061396678823974, \"p4\": 0.6926498635224843, \"phi\": 0.5418129386926872}, {\"truth_threshold\": -8.999999798834324, \"match_probability\": 0.0019493180100694405, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672385.0, \"fp\": 65407.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488503425729, \"fp_rate\": 5.114965742718895e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6705401756931012, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488503425729, \"npv\": 0.9998664105211176, \"accuracy\": 0.9998152937545268, \"f1\": 0.5298464244988448, \"f2\": 0.4706010865599715, \"f0_5\": 0.6061573319806607, \"p4\": 0.6926570722841966, \"phi\": 0.541823861233819}, {\"truth_threshold\": -8.979999799281359, \"match_probability\": 0.001976475692024266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672397.0, \"fp\": 65395.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488597268267, \"fp_rate\": 5.114027317337627e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6705807088597393, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488597268267, \"npv\": 0.9998664105223711, \"accuracy\": 0.9998153031365505, \"f1\": 0.5298590781269591, \"f2\": 0.47060507932916656, \"f0_5\": 0.6061838300585142, \"p4\": 0.6926678857081142, \"phi\": 0.5418402462832431}, {\"truth_threshold\": -8.959999799728394, \"match_probability\": 0.002004010972072853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278672406.0, \"fp\": 65386.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999488667650169, \"fp_rate\": 5.1133234983016755e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6706111119507121, \"recall\": 0.4379542112310461, \"specificity\": 0.9999488667650169, \"npv\": 0.9998664105233113, \"accuracy\": 0.9998153101730682, \"f1\": 0.5298685687446762, \"f2\": 0.47060807395052573, \"f0_5\": 0.606203705137301, \"p4\": 0.6926759959976233, \"phi\": 0.5418525360451396}, {\"truth_threshold\": -8.939999800175428, \"match_probability\": 0.0020319290789924103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278673921.0, \"fp\": 63871.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999500515270608, \"fp_rate\": 4.994847293916531e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6757685591293048, \"recall\": 0.4379542112310461, \"specificity\": 0.9999500515270608, \"npv\": 0.9998664106815698, \"accuracy\": 0.9998164946535565, \"f1\": 0.5314710162430407, \"f2\": 0.4711127123034804, \"f0_5\": 0.6095680213640264, \"p4\": 0.6940439402358313, \"phi\": 0.5439332986209126}, {\"truth_threshold\": -8.919999800622463, \"match_probability\": 0.0020602353133675005, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278673951.0, \"fp\": 63841.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999500749876954, \"fp_rate\": 4.99250123046336e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6758714879012195, \"recall\": 0.4379542112310461, \"specificity\": 0.9999500749876954, \"npv\": 0.9998664106847036, \"accuracy\": 0.9998165181086156, \"f1\": 0.5315028457467516, \"f2\": 0.4711227160700054, \"f0_5\": 0.609635018579257, \"p4\": 0.6940710827972467, \"phi\": 0.5439747440380123}, {\"truth_threshold\": -8.899999801069498, \"match_probability\": 0.0020889350485593884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278673981.0, \"fp\": 63811.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999500984483299, \"fp_rate\": 4.990155167010189e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6759744480328235, \"recall\": 0.4379542112310461, \"specificity\": 0.9999500984483299, \"npv\": 0.9998664106878374, \"accuracy\": 0.9998165415636748, \"f1\": 0.5315346790631932, \"f2\": 0.4711327202613861, \"f0_5\": 0.609702030523345, \"p4\": 0.6940982274817191, \"phi\": 0.5440161989235134}, {\"truth_threshold\": -8.879999801516533, \"match_probability\": 0.0021180337316879963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278673990.0, \"fp\": 63802.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999501054865203, \"fp_rate\": 4.9894513479742375e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6760053421895867, \"recall\": 0.4379542112310461, \"specificity\": 0.9999501054865203, \"npv\": 0.9998664106887776, \"accuracy\": 0.9998165486001925, \"f1\": 0.5315442298017106, \"f2\": 0.47113572160165124, \"f0_5\": 0.6097221369794248, \"p4\": 0.6941063713010942, \"phi\": 0.5440286372360411}, {\"truth_threshold\": -8.839999802410603, \"match_probability\": 0.0021774501050096083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278674013.0, \"fp\": 63779.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.9999501234730067, \"fp_rate\": 4.987652699326806e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6760843067546978, \"recall\": 0.4379542112310461, \"specificity\": 0.9999501234730067, \"npv\": 0.9998664106911802, \"accuracy\": 0.9998165665824046, \"f1\": 0.5315686388039795, \"f2\": 0.4711433918671748, \"f0_5\": 0.6097735261703194, \"p4\": 0.6941271841521843, \"phi\": 0.5440604279083936}, {\"truth_threshold\": -8.819999802857637, \"match_probability\": 0.0022077790672529775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278674054.0, \"fp\": 63738.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.999950155535874, \"fp_rate\": 4.9844464126074723e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.676225115437953, \"recall\": 0.4379542112310461, \"specificity\": 0.999950155535874, \"npv\": 0.9998664106954631, \"accuracy\": 0.9998165986376522, \"f1\": 0.531612156064055, \"f2\": 0.4711570655686298, \"f0_5\": 0.6098651544763272, \"p4\": 0.6941642884172872, \"phi\": 0.5441171120521153}, {\"truth_threshold\": -8.799999803304672, \"match_probability\": 0.0022385295235884278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133121.0, \"tn\": 1278674061.0, \"fp\": 63731.0, \"fn\": 170840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379542112310461, \"tn_rate\": 0.999950161010022, \"fp_rate\": 4.983898997801732e-05, \"fn_rate\": 0.562045788768954, \"precision\": 0.6762491618068397, \"recall\": 0.4379542112310461, \"specificity\": 0.999950161010022, \"npv\": 0.9998664106961943, \"accuracy\": 0.9998166041104993, \"f1\": 0.531619586552266, \"f2\": 0.47115940018234637, \"f0_5\": 0.6098808010856089, \"p4\": 0.694170623688263, \"phi\": 0.5441267916022435}, {\"truth_threshold\": -8.779999803751707, \"match_probability\": 0.002269707305110611, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133120.0, \"tn\": 1278674076.0, \"fp\": 63716.0, \"fn\": 170841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379509213353029, \"tn_rate\": 0.9999501727403393, \"fp_rate\": 4.982725966075147e-05, \"fn_rate\": 0.5620490786646971, \"precision\": 0.6762990509866081, \"recall\": 0.4379509213353029, \"specificity\": 0.9999501727403393, \"npv\": 0.99986640991591, \"accuracy\": 0.9998166150561936, \"f1\": 0.5316325776711921, \"f2\": 0.4711611971571764, \"f0_5\": 0.6099119861083748, \"p4\": 0.6941816999988654, \"phi\": 0.5441448291634992}, {\"truth_threshold\": -8.759999804198742, \"match_probability\": 0.002301318322837974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133120.0, \"tn\": 1278674103.0, \"fp\": 63689.0, \"fn\": 170841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379509213353029, \"tn_rate\": 0.9999501938549104, \"fp_rate\": 4.9806145089672926e-05, \"fn_rate\": 0.5620490786646971, \"precision\": 0.6763918316743645, \"recall\": 0.4379509213353029, \"specificity\": 0.9999501938549104, \"npv\": 0.9998664099187305, \"accuracy\": 0.9998166361657468, \"f1\": 0.5316612416878008, \"f2\": 0.4711702024488675, \"f0_5\": 0.6099723514635762, \"p4\": 0.6942061380907427, \"phi\": 0.5441821736791724}, {\"truth_threshold\": -8.739999804645777, \"match_probability\": 0.0023333685687873104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133120.0, \"tn\": 1278674132.0, \"fp\": 63660.0, \"fn\": 170841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379509213353029, \"tn_rate\": 0.9999502165335237, \"fp_rate\": 4.978346647629227e-05, \"fn_rate\": 0.5620490786646971, \"precision\": 0.6764915133651794, \"recall\": 0.4379509213353029, \"specificity\": 0.9999502165335237, \"npv\": 0.9998664099217599, \"accuracy\": 0.9998166588389706, \"f1\": 0.5316920324079714, \"f2\": 0.4711798751826388, \"f0_5\": 0.610037201637642, \"p4\": 0.6942323883282694, \"phi\": 0.544222293014488}, {\"truth_threshold\": -8.719999805092812, \"match_probability\": 0.0023658641170621482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133120.0, \"tn\": 1278674149.0, \"fp\": 63643.0, \"fn\": 170841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379509213353029, \"tn_rate\": 0.9999502298278833, \"fp_rate\": 4.97701721167243e-05, \"fn_rate\": 0.5620490786646971, \"precision\": 0.6765499611207392, \"recall\": 0.4379509213353029, \"specificity\": 0.9999502298278833, \"npv\": 0.9998664099235358, \"accuracy\": 0.9998166721301709, \"f1\": 0.5317100837986596, \"f2\": 0.4711855455905287, \"f0_5\": 0.6100752236682789, \"p4\": 0.6942477773215365, \"phi\": 0.5442458153683065}, {\"truth_threshold\": -8.699999805539846, \"match_probability\": 0.002398811124955169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133120.0, \"tn\": 1278674167.0, \"fp\": 63625.0, \"fn\": 170841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379509213353029, \"tn_rate\": 0.999950243904264, \"fp_rate\": 4.9756095736005274e-05, \"fn_rate\": 0.5620490786646971, \"precision\": 0.6766118579887672, \"recall\": 0.4379509213353029, \"specificity\": 0.999950243904264, \"npv\": 0.9998664099254161, \"accuracy\": 0.9998166862032064, \"f1\": 0.5317291983718989, \"f2\": 0.47119154970058524, \"f0_5\": 0.6101154874553253, \"p4\": 0.6942640722933515, \"phi\": 0.5442707247123114}, {\"truth_threshold\": -8.679999805986881, \"match_probability\": 0.002432215834064805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133118.0, \"tn\": 1278674206.0, \"fp\": 63586.0, \"fn\": 170843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43794434154381645, \"tn_rate\": 0.9999502744030889, \"fp_rate\": 4.972559691111405e-05, \"fn_rate\": 0.5620556584561835, \"precision\": 0.676742720026029, \"recall\": 0.43794434154381645, \"specificity\": 0.9999502744030889, \"npv\": 0.9998664083657879, \"accuracy\": 0.9998167151311127, \"f1\": 0.5317647528786714, \"f2\": 0.4711981468948312, \"f0_5\": 0.6101980514807335, \"p4\": 0.694294381385305, \"phi\": 0.5443192945535782}, {\"truth_threshold\": -8.659999806433916, \"match_probability\": 0.002466084571426181, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674558.0, \"fp\": 63234.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.999950549674534, \"fp_rate\": 4.945032546594197e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6779460747863465, \"recall\": 0.43792460216935725, \"specificity\": 0.999950549674534, \"npv\": 0.9998664037114534, \"accuracy\": 0.9998169856461284, \"f1\": 0.5321212775355931, \"f2\": 0.4712963553062973, \"f0_5\": 0.6109726487017428, \"p4\": 0.6945982272743332, \"phi\": 0.544791007583558}, {\"truth_threshold\": -8.639999806880951, \"match_probability\": 0.0025004237506565706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674587.0, \"fp\": 63205.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999505723531474, \"fp_rate\": 4.942764685256131e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6780462211627113, \"recall\": 0.43792460216935725, \"specificity\": 0.9999505723531474, \"npv\": 0.999866403714483, \"accuracy\": 0.9998170083193524, \"f1\": 0.5321521234193788, \"f2\": 0.4713060338020948, \"f0_5\": 0.611037715668606, \"p4\": 0.6946245087524902, \"phi\": 0.5448312664753288}, {\"truth_threshold\": -8.619999807327986, \"match_probability\": 0.0025352398731155307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674767.0, \"fp\": 63025.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999507131169546, \"fp_rate\": 4.928688304537104e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6786684817245089, \"recall\": 0.43792460216935725, \"specificity\": 0.9999507131169546, \"npv\": 0.999866403733287, \"accuracy\": 0.9998171490497074, \"f1\": 0.532343660642514, \"f2\": 0.47136611611629337, \"f0_5\": 0.6114418897776683, \"p4\": 0.6947876796615333, \"phi\": 0.5450813488852777}, {\"truth_threshold\": -8.59999980777502, \"match_probability\": 0.0025705395290798855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674803.0, \"fp\": 62989.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999507412697161, \"fp_rate\": 4.9258730283932984e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6787930709175374, \"recall\": 0.43792460216935725, \"specificity\": 0.9999507412697161, \"npv\": 0.9998664037370477, \"accuracy\": 0.9998171771957783, \"f1\": 0.5323819846339054, \"f2\": 0.4713781344174171, \"f0_5\": 0.6115227887703114, \"p4\": 0.6948203230429003, \"phi\": 0.5451314066741684}, {\"truth_threshold\": -8.579999808222055, \"match_probability\": 0.0026063293989337295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674828.0, \"fp\": 62964.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999507608202448, \"fp_rate\": 4.923917975515656e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6788796181072645, \"recall\": 0.43792460216935725, \"specificity\": 0.9999507608202448, \"npv\": 0.9998664037396594, \"accuracy\": 0.999817196741661, \"f1\": 0.5324086017634695, \"f2\": 0.4713864808204431, \"f0_5\": 0.6115789812224045, \"p4\": 0.694842993862489, \"phi\": 0.5451661771368159}, {\"truth_threshold\": -8.55999980866909, \"match_probability\": 0.002642616254373618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674851.0, \"fp\": 62941.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999507788067313, \"fp_rate\": 4.922119326868225e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6789592610161538, \"recall\": 0.43792460216935725, \"specificity\": 0.9999507788067313, \"npv\": 0.999866403742062, \"accuracy\": 0.9998172147238731, \"f1\": 0.5324330918734276, \"f2\": 0.471394159772278, \"f0_5\": 0.6116306873998896, \"p4\": 0.6948638523231748, \"phi\": 0.545198171835114}, {\"truth_threshold\": -8.539999809116125, \"match_probability\": 0.0026794069596291262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674865.0, \"fp\": 62927.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999507897550274, \"fp_rate\": 4.921024497256745e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.679007748458215, \"recall\": 0.43792460216935725, \"specificity\": 0.9999507897550274, \"npv\": 0.9998664037435246, \"accuracy\": 0.9998172256695673, \"f1\": 0.532448, \"f2\": 0.47139883403936444, \"f0_5\": 0.6116621650061528, \"p4\": 0.6948765493906456, \"phi\": 0.5452176496250567}, {\"truth_threshold\": -8.51999980956316, \"match_probability\": 0.002716708472698939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674903.0, \"fp\": 62889.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999508194718312, \"fp_rate\": 4.918052816882728e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6791393921459584, \"recall\": 0.43792460216935725, \"specificity\": 0.9999508194718312, \"npv\": 0.9998664037474944, \"accuracy\": 0.999817255379309, \"f1\": 0.5324884691236534, \"f2\": 0.4714115218030308, \"f0_5\": 0.6117476205576466, \"p4\": 0.6949110151986524, \"phi\": 0.545270528429381}, {\"truth_threshold\": -8.499999810010195, \"match_probability\": 0.0027545278466026574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278674909.0, \"fp\": 62883.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999508241639581, \"fp_rate\": 4.917583604192094e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6791601826577208, \"recall\": 0.43792460216935725, \"specificity\": 0.9999508241639581, \"npv\": 0.9998664037481211, \"accuracy\": 0.9998172600703208, \"f1\": 0.5324948595476402, \"f2\": 0.47141352519656987, \"f0_5\": 0.611761115722268, \"p4\": 0.6949164574808804, \"phi\": 0.545278879119771}, {\"truth_threshold\": -8.47999981045723, \"match_probability\": 0.0027928722306484947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675169.0, \"fp\": 62623.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510274894573, \"fp_rate\": 4.89725105426461e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6800623291695405, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510274894573, \"npv\": 0.9998664037752824, \"accuracy\": 0.9998174633475003, \"f1\": 0.532771925330601, \"f2\": 0.47150035527590023, \"f0_5\": 0.6123464786581299, \"p4\": 0.6951523716199813, \"phi\": 0.5456411110440033}, {\"truth_threshold\": -8.459999810904264, \"match_probability\": 0.0028317488717170386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675184.0, \"fp\": 62608.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510392197746, \"fp_rate\": 4.896078022538025e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6801144492131617, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510392197746, \"npv\": 0.9998664037768493, \"accuracy\": 0.9998174750750298, \"f1\": 0.5327879186921256, \"f2\": 0.4715053656794874, \"f0_5\": 0.6123802837765597, \"p4\": 0.6951659869382942, \"phi\": 0.5456620310552404}, {\"truth_threshold\": -8.4399998113513, \"match_probability\": 0.002871165115561265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278675208.0, \"fp\": 62584.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999510579882822, \"fp_rate\": 4.894201171775488e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6801978579020521, \"recall\": 0.43792460216935725, \"specificity\": 0.9999510579882822, \"npv\": 0.9998664037793565, \"accuracy\": 0.9998174938390773, \"f1\": 0.5328135100679066, \"f2\": 0.47151338254672204, \"f0_5\": 0.6124343797302955, \"p4\": 0.6951877725569803, \"phi\": 0.545695508075121}, {\"truth_threshold\": -8.419999811798334, \"match_probability\": 0.002911128408122972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278676898.0, \"fp\": 60894.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999523796040275, \"fp_rate\": 4.762039597246845e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6861231095945486, \"recall\": 0.43792460216935725, \"specificity\": 0.9999523796040275, \"npv\": 0.9998664039559042, \"accuracy\": 0.9998188151407439, \"f1\": 0.5346217721254621, \"f2\": 0.47207858992091356, \"f0_5\": 0.6162678185345167, \"p4\": 0.696725284214579, \"phi\": 0.5480684425522644}, {\"truth_threshold\": -8.399999812245369, \"match_probability\": 0.002951646296865832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278676946.0, \"fp\": 60846.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524171410428, \"fp_rate\": 4.758285895721771e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6862929087740645, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524171410428, \"npv\": 0.9998664039609186, \"accuracy\": 0.9998188526688385, \"f1\": 0.5346733103175416, \"f2\": 0.47209466293848357, \"f0_5\": 0.6163773982605926, \"p4\": 0.6967690525145365, \"phi\": 0.548136292022766}, {\"truth_threshold\": -8.379999812692404, \"match_probability\": 0.0029927264321252347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278676959.0, \"fp\": 60833.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524273073177, \"fp_rate\": 4.757269268225397e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6863389105158679, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524273073177, \"npv\": 0.9998664039622767, \"accuracy\": 0.9998188628326975, \"f1\": 0.534687270287966, \"f2\": 0.47209901623576295, \"f0_5\": 0.6164070828096738, \"p4\": 0.6967809073754672, \"phi\": 0.5481546722548277}, {\"truth_threshold\": -8.359999813139439, \"match_probability\": 0.0030343765684751074, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278676967.0, \"fp\": 60825.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.999952433563487, \"fp_rate\": 4.7566436513045516e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6863672223454008, \"recall\": 0.43792460216935725, \"specificity\": 0.999952433563487, \"npv\": 0.9998664039631123, \"accuracy\": 0.9998188690873799, \"f1\": 0.5346958614013312, \"f2\": 0.47210169522784035, \"f0_5\": 0.6164253516456749, \"p4\": 0.6967882028750092, \"phi\": 0.5481659840852696}, {\"truth_threshold\": -8.339999813586473, \"match_probability\": 0.0030766045661118962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677015.0, \"fp\": 60777.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524711005022, \"fp_rate\": 4.7528899497794774e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.6865371423855917, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524711005022, \"npv\": 0.9998664039681268, \"accuracy\": 0.9998189066154747, \"f1\": 0.5347474138796826, \"f2\": 0.47211776981882386, \"f0_5\": 0.6165349874064049, \"p4\": 0.6968319790806751, \"phi\": 0.5482338697667434}, {\"truth_threshold\": -8.319999814033508, \"match_probability\": 0.003119418392255908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133112.0, \"tn\": 1278677022.0, \"fp\": 60770.0, \"fn\": 170849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43792460216935725, \"tn_rate\": 0.9999524765746503, \"fp_rate\": 4.752342534973738e-05, \"fn_rate\": 0.5620753978306428, \"precision\": 0.686561929420988, \"recall\": 0.43792460216935725, \"specificity\": 0.9999524765746503, \"npv\": 0.999866403968858, \"accuracy\": 0.9998189120883217, \"f1\": 0.534754932780013, \"f2\": 0.4721201141214676, \"f0_5\": 0.6165509792133129, \"p4\": 0.6968383635702444, \"phi\": 0.5482437718678285}, {\"truth_threshold\": -8.299999814480543, \"match_probability\": 0.0031628261225701785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278677842.0, \"fp\": 59950.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999531178319941, \"fp_rate\": 4.688216800587059e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.6894763831120734, \"recall\": 0.437921312273614, \"specificity\": 0.9999531178319941, \"npv\": 0.9998664032726712, \"accuracy\": 0.9998195524114372, \"f1\": 0.5356342375186611, \"f2\": 0.4723916800635955, \"f0_5\": 0.6184277159091437, \"p4\": 0.6975845726367607, \"phi\": 0.5494047503759246}, {\"truth_threshold\": -8.259999815374613, \"match_probability\": 0.0032514561492128285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685605.0, \"fp\": 52187.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999591886621898, \"fp_rate\": 4.0811337810214656e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7183617740072747, \"recall\": 0.437921312273614, \"specificity\": 0.9999591886621898, \"npv\": 0.9998664040836389, \"accuracy\": 0.9998256217989155, \"f1\": 0.5441330665353116, \"f2\": 0.4750089569793782, \"f0_5\": 0.6368015017896901, \"p4\": 0.7047531797025237, \"phi\": 0.5608013145568215}, {\"truth_threshold\": -8.239999815821648, \"match_probability\": 0.003296695152100145, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685627.0, \"fp\": 52165.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999592058666551, \"fp_rate\": 4.07941333448914e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7184470735551286, \"recall\": 0.437921312273614, \"specificity\": 0.9999592058666551, \"npv\": 0.9998664040859372, \"accuracy\": 0.9998256389992923, \"f1\": 0.544157535100575, \"f2\": 0.4750164154390773, \"f0_5\": 0.6368551238439715, \"p4\": 0.7047737045857488, \"phi\": 0.5608346260499689}, {\"truth_threshold\": -8.219999816268682, \"match_probability\": 0.0033425614752391583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685685.0, \"fp\": 52107.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999592512238819, \"fp_rate\": 4.074877611813009e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7186720513125074, \"recall\": 0.437921312273614, \"specificity\": 0.9999592512238819, \"npv\": 0.9998664040919961, \"accuracy\": 0.99982568434574, \"f1\": 0.5442220536858696, \"f2\": 0.4750360797737716, \"f0_5\": 0.6369965343743929, \"p4\": 0.7048278213725226, \"phi\": 0.5609224757015396}, {\"truth_threshold\": -8.199999816715717, \"match_probability\": 0.0033890637584168535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685712.0, \"fp\": 52080.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999592723384529, \"fp_rate\": 4.0727661547051546e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7187768304075252, \"recall\": 0.437921312273614, \"specificity\": 0.9999592723384529, \"npv\": 0.9998664040948166, \"accuracy\": 0.9998257054552933, \"f1\": 0.5442520934188146, \"f2\": 0.47504523441598534, \"f0_5\": 0.6370623848381153, \"p4\": 0.7048530165048363, \"phi\": 0.5609633853037044}, {\"truth_threshold\": -8.179999817162752, \"match_probability\": 0.003436210758755191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685776.0, \"fp\": 52016.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999593223878066, \"fp_rate\": 4.0677612193383894e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7190253177548386, \"recall\": 0.437921312273614, \"specificity\": 0.9999593223878066, \"npv\": 0.9998664041015025, \"accuracy\": 0.9998257554927529, \"f1\": 0.5443233119602199, \"f2\": 0.4750669357181555, \"f0_5\": 0.6372185292239406, \"p4\": 0.7049127454957799, \"phi\": 0.5610603919537505}, {\"truth_threshold\": -8.159999817609787, \"match_probability\": 0.0034840113522581137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685781.0, \"fp\": 52011.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999593262979124, \"fp_rate\": 4.067370208762861e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7190447380646277, \"recall\": 0.437921312273614, \"specificity\": 0.9999593262979124, \"npv\": 0.9998664041020248, \"accuracy\": 0.9998257594019294, \"f1\": 0.5443288766937309, \"f2\": 0.4750686312158896, \"f0_5\": 0.6372307312276617, \"p4\": 0.7049174122495154, \"phi\": 0.5610679727164251}, {\"truth_threshold\": -8.139999818056822, \"match_probability\": 0.003532474535377645, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133111.0, \"tn\": 1278685787.0, \"fp\": 52005.0, \"fn\": 170850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437921312273614, \"tn_rate\": 0.9999593309900393, \"fp_rate\": 4.066900996072227e-05, \"fn_rate\": 0.5620786877263859, \"precision\": 0.7190680438211716, \"recall\": 0.437921312273614, \"specificity\": 0.9999593309900393, \"npv\": 0.9998664041026516, \"accuracy\": 0.9998257640929412, \"f1\": 0.5443355545241343, \"f2\": 0.47507066582914576, \"f0_5\": 0.6372453742489886, \"p4\": 0.7049230124355628, \"phi\": 0.5610770700369809}, {\"truth_threshold\": -8.119999818503857, \"match_probability\": 0.00358160942659926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685891.0, \"fp\": 51901.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.999959412320239, \"fp_rate\": 4.0587679761012334e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.7194707341725627, \"recall\": 0.43791802237787086, \"specificity\": 0.999959412320239, \"npv\": 0.999866403331672, \"accuracy\": 0.9998258446219778, \"f1\": 0.5444483528709211, \"f2\": 0.4751027051336505, \"f0_5\": 0.6374969468537028, \"p4\": 0.7050176006349987, \"phi\": 0.5612321270681463}, {\"truth_threshold\": -8.079999819397926, \"match_probability\": 0.00368193142710673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685902.0, \"fp\": 51890.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.9999594209224717, \"fp_rate\": 4.057907752835071e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.7195135135135136, \"recall\": 0.43791802237787086, \"specificity\": 0.9999594209224717, \"npv\": 0.9998664033328212, \"accuracy\": 0.9998258532221661, \"f1\": 0.5444606011522392, \"f2\": 0.475106435834397, \"f0_5\": 0.6375238155448336, \"p4\": 0.7050278707065744, \"phi\": 0.5612488207117107}, {\"truth_threshold\": -8.059999819844961, \"match_probability\": 0.0037331373980731015, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133110.0, \"tn\": 1278685939.0, \"fp\": 51853.0, \"fn\": 170851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791802237787086, \"tn_rate\": 0.9999594498572543, \"fp_rate\": 4.05501427457616e-05, \"fn_rate\": 0.5620819776221292, \"precision\": 0.719657445002514, \"recall\": 0.43791802237787086, \"specificity\": 0.9999594498572543, \"npv\": 0.9998664033366863, \"accuracy\": 0.9998258821500724, \"f1\": 0.5445018039613518, \"f2\": 0.4751189849850836, \"f0_5\": 0.6376142086753087, \"p4\": 0.7050624176887502, \"phi\": 0.561304982984882}, {\"truth_threshold\": -8.039999820291996, \"match_probability\": 0.003785052803811502, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685939.0, \"fp\": 51853.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594498572543, \"fp_rate\": 4.05501427457616e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7196559293260237, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594498572543, \"npv\": 0.9998664025548424, \"accuracy\": 0.9998258813682371, \"f1\": 0.5444988270136606, \"f2\": 0.475115754786887, \"f0_5\": 0.6376118619402592, \"p4\": 0.705059921856206, \"phi\": 0.5613022828630396}, {\"truth_threshold\": -8.01999982073903, \"match_probability\": 0.0038376873974441095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685948.0, \"fp\": 51844.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594568954446, \"fp_rate\": 4.0543104555402084e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7196909485112434, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594568954446, \"npv\": 0.9998664025557826, \"accuracy\": 0.9998258884047548, \"f1\": 0.5445088502272384, \"f2\": 0.47511880736466455, \"f0_5\": 0.6376338533378426, \"p4\": 0.7050683256917626, \"phi\": 0.5613159465124318}, {\"truth_threshold\": -7.999999821186066, \"match_probability\": 0.0038910510640548955, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685956.0, \"fp\": 51836.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594631516138, \"fp_rate\": 4.0536848386193626e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7197220795371597, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594631516138, \"npv\": 0.9998664025566184, \"accuracy\": 0.9998258946594373, \"f1\": 0.5445177600602161, \"f2\": 0.47512152080006337, \"f0_5\": 0.6376534025203571, \"p4\": 0.7050757959359979, \"phi\": 0.5613280928157062}, {\"truth_threshold\": -7.9799998216331005, \"match_probability\": 0.003945153822415584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685965.0, \"fp\": 51827.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594701898041, \"fp_rate\": 4.052981019583411e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7197571051607042, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594701898041, \"npv\": 0.9998664025575585, \"accuracy\": 0.9998259016959551, \"f1\": 0.5445277839708569, \"f2\": 0.47512457345193393, \"f0_5\": 0.6376753967835739, \"p4\": 0.7050842001499774, \"phi\": 0.5613417583487915}, {\"truth_threshold\": -7.959999822080135, \"match_probability\": 0.004000005826732493, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133109.0, \"tn\": 1278685972.0, \"fp\": 51820.0, \"fn\": 170852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43791473248212764, \"tn_rate\": 0.9999594756639523, \"fp_rate\": 4.052433604777671e-05, \"fn_rate\": 0.5620852675178724, \"precision\": 0.7197843496693326, \"recall\": 0.43791473248212764, \"specificity\": 0.9999594756639523, \"npv\": 0.9998664025582898, \"accuracy\": 0.9998259071688022, \"f1\": 0.5445355806009532, \"f2\": 0.47512694776384184, \"f0_5\": 0.6376925044817506, \"p4\": 0.705090736899365, \"phi\": 0.561352387786318}, {\"truth_threshold\": -7.93999982252717, \"match_probability\": 0.004055617368414475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133106.0, \"tn\": 1278685977.0, \"fp\": 51815.0, \"fn\": 170855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43790486279489804, \"tn_rate\": 0.999959479574058, \"fp_rate\": 4.0520425942021425e-05, \"fn_rate\": 0.562095137205102, \"precision\": 0.7197992656323511, \"recall\": 0.43790486279489804, \"specificity\": 0.999959479574058, \"npv\": 0.9998664002132804, \"accuracy\": 0.9998259087324728, \"f1\": 0.5445322184085322, \"f2\": 0.4751189528579026, \"f0_5\": 0.6376976845574884, \"p4\": 0.7050879185096789, \"phi\": 0.5613518802863444}, {\"truth_threshold\": -7.919999822974205, \"match_probability\": 0.004111998877862162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133106.0, \"tn\": 1278686017.0, \"fp\": 51775.0, \"fn\": 170855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43790486279489804, \"tn_rate\": 0.999959510854904, \"fp_rate\": 4.048914509597915e-05, \"fn_rate\": 0.562095137205102, \"precision\": 0.719954998079846, \"recall\": 0.43790486279489804, \"specificity\": 0.999959510854904, \"npv\": 0.9998664002174592, \"accuracy\": 0.999825940005885, \"f1\": 0.5445767753179964, \"f2\": 0.47513252065894446, \"f0_5\": 0.6377954642376268, \"p4\": 0.7051252742317975, \"phi\": 0.5614126340804723}, {\"truth_threshold\": -7.89999982342124, \"match_probability\": 0.0041691609262787125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133106.0, \"tn\": 1278686020.0, \"fp\": 51772.0, \"fn\": 170855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43790486279489804, \"tn_rate\": 0.9999595132009674, \"fp_rate\": 4.0486799032525974e-05, \"fn_rate\": 0.562095137205102, \"precision\": 0.7199666807299949, \"recall\": 0.43790486279489804, \"specificity\": 0.9999595132009674, \"npv\": 0.9998664002177726, \"accuracy\": 0.9998259423513909, \"f1\": 0.5445801173801599, \"f2\": 0.4751335382752609, \"f0_5\": 0.6378027989224445, \"p4\": 0.7051280760705231, \"phi\": 0.5614171914097177}, {\"truth_threshold\": -7.879999823868275, \"match_probability\": 0.004227114227502277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133106.0, \"tn\": 1278686025.0, \"fp\": 51767.0, \"fn\": 170855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43790486279489804, \"tn_rate\": 0.9999595171110732, \"fp_rate\": 4.048288892677069e-05, \"fn_rate\": 0.562095137205102, \"precision\": 0.7199861526561477, \"recall\": 0.43790486279489804, \"specificity\": 0.9999595171110732, \"npv\": 0.999866400218295, \"accuracy\": 0.9998259462605674, \"f1\": 0.5445856875749232, \"f2\": 0.47513523431214155, \"f0_5\": 0.6378150237720338, \"p4\": 0.7051327458512138, \"phi\": 0.5614247872049276}, {\"truth_threshold\": -7.8599998243153095, \"match_probability\": 0.004285869639860376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133105.0, \"tn\": 1278686088.0, \"fp\": 51704.0, \"fn\": 170856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4379015728991548, \"tn_rate\": 0.9999595663784058, \"fp_rate\": 4.0433621594254093e-05, \"fn_rate\": 0.5620984271008451, \"precision\": 0.720230075375117, \"recall\": 0.4379015728991548, \"specificity\": 0.9999595663784058, \"npv\": 0.9998663994430326, \"accuracy\": 0.9998259947343564, \"f1\": 0.5446529042289829, \"f2\": 0.47515337489014053, \"f0_5\": 0.6379667502878171, \"p4\": 0.7051890945362096, \"phi\": 0.5615178206020093}, {\"truth_threshold\": -7.839999824762344, \"match_probability\": 0.004345438168046409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133104.0, \"tn\": 1278686284.0, \"fp\": 51508.0, \"fn\": 170857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378982830034116, \"tn_rate\": 0.9999597196545513, \"fp_rate\": 4.028034544864691e-05, \"fn_rate\": 0.5621017169965884, \"precision\": 0.7209932182090005, \"recall\": 0.4378982830034116, \"specificity\": 0.9999597196545513, \"npv\": 0.9998663986816648, \"accuracy\": 0.999826147192241, \"f1\": 0.544868422937821, \"f2\": 0.4752166437217592, \"f0_5\": 0.6384442191116922, \"p4\": 0.7053697335401395, \"phi\": 0.5618132715133481}, {\"truth_threshold\": -7.819999825209379, \"match_probability\": 0.004405830965018488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133104.0, \"tn\": 1278686309.0, \"fp\": 51483.0, \"fn\": 170857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378982830034116, \"tn_rate\": 0.9999597392050801, \"fp_rate\": 4.0260794919870485e-05, \"fn_rate\": 0.5621017169965884, \"precision\": 0.7210908677209121, \"recall\": 0.4378982830034116, \"specificity\": 0.9999597392050801, \"npv\": 0.9998663986842765, \"accuracy\": 0.9998261667381236, \"f1\": 0.5448963049690102, \"f2\": 0.475225127121579, \"f0_5\": 0.6385054719857547, \"p4\": 0.7053930994206291, \"phi\": 0.5618513351101131}, {\"truth_threshold\": -7.799999825656414, \"match_probability\": 0.004467059333920819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133104.0, \"tn\": 1278686454.0, \"fp\": 51338.0, \"fn\": 170857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378982830034116, \"tn_rate\": 0.999959852598147, \"fp_rate\": 4.014740185296721e-05, \"fn_rate\": 0.5621017169965884, \"precision\": 0.7216577569100313, \"recall\": 0.4378982830034116, \"specificity\": 0.999959852598147, \"npv\": 0.9998663986994246, \"accuracy\": 0.999826280104243, \"f1\": 0.5450580770388388, \"f2\": 0.47527433681405085, \"f0_5\": 0.6388609705595217, \"p4\": 0.7055286520603514, \"phi\": 0.5620722565352654}, {\"truth_threshold\": -7.779999826103449, \"match_probability\": 0.004529134730027815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133104.0, \"tn\": 1278686482.0, \"fp\": 51310.0, \"fn\": 170857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378982830034116, \"tn_rate\": 0.9999598744947392, \"fp_rate\": 4.012550526073761e-05, \"fn_rate\": 0.5621017169965884, \"precision\": 0.7217673278601408, \"recall\": 0.4378982830034116, \"specificity\": 0.9999598744947392, \"npv\": 0.9998663987023497, \"accuracy\": 0.9998263019956316, \"f1\": 0.5450893268492449, \"f2\": 0.4752838405493845, \"f0_5\": 0.6389296641663874, \"p4\": 0.7055548337441312, \"phi\": 0.5621149472315929}, {\"truth_threshold\": -7.759999826550484, \"match_probability\": 0.00459206876271118, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133099.0, \"tn\": 1278686526.0, \"fp\": 51266.0, \"fn\": 170862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378818335246956, \"tn_rate\": 0.9999599089036699, \"fp_rate\": 4.00910963300911e-05, \"fn_rate\": 0.5621181664753044, \"precision\": 0.7219320369918368, \"recall\": 0.4378818335246956, \"specificity\": 0.9999599089036699, \"npv\": 0.9998663947977287, \"accuracy\": 0.9998263324872085, \"f1\": 0.5451235445173921, \"f2\": 0.4752826185233776, \"f0_5\": 0.639025907870112, \"p4\": 0.7055835015533306, \"phi\": 0.5621685539558444}, {\"truth_threshold\": -7.7399998269975185, \"match_probability\": 0.004655873197430131, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133098.0, \"tn\": 1278686553.0, \"fp\": 51239.0, \"fn\": 170863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378785436289524, \"tn_rate\": 0.999959930018241, \"fp_rate\": 4.0069981759012565e-05, \"fn_rate\": 0.5621214563710476, \"precision\": 0.7220362705262644, \"recall\": 0.4378785436289524, \"specificity\": 0.999959930018241, \"npv\": 0.9998663940187058, \"accuracy\": 0.9998263528149265, \"f1\": 0.5451507071501419, \"f2\": 0.4752885519800654, \"f0_5\": 0.6390898378867368, \"p4\": 0.705606257216632, \"phi\": 0.5622070443939773}, {\"truth_threshold\": -7.719999827444553, \"match_probability\": 0.004720559957745, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133091.0, \"tn\": 1278695015.0, \"fp\": 42777.0, \"fn\": 170870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43785551435875, \"tn_rate\": 0.9999665474812213, \"fp_rate\": 3.3452518778767744e-05, \"fn_rate\": 0.5621444856412501, \"precision\": 0.7567664384652125, \"recall\": 0.43785551435875, \"specificity\": 0.9999665474812213, \"npv\": 0.9998663894298815, \"accuracy\": 0.9998329632324364, \"f1\": 0.5547434606912046, \"f2\": 0.4781556816352809, \"f0_5\": 0.6605451677679806, \"p4\": 0.7135928716206381, \"phi\": 0.5755610695354909}, {\"truth_threshold\": -7.699999827891588, \"match_probability\": 0.004786141127354402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133089.0, \"tn\": 1278695683.0, \"fp\": 42109.0, \"fn\": 170872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43784893456726354, \"tn_rate\": 0.9999670698713501, \"fp_rate\": 3.293012864986163e-05, \"fn_rate\": 0.5621510654327364, \"precision\": 0.7596490827520862, \"recall\": 0.43784893456726354, \"specificity\": 0.9999670698713501, \"npv\": 0.9998663879359954, \"accuracy\": 0.99983348393475, \"f1\": 0.5555108012162977, \"f2\": 0.4783787980521077, \"f0_5\": 0.6622971018747891, \"p4\": 0.7142274801799264, \"phi\": 0.5766524331744114}, {\"truth_threshold\": -7.679999828338623, \"match_probability\": 0.004852628952156185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133088.0, \"tn\": 1278695701.0, \"fp\": 42091.0, \"fn\": 170873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378456446715204, \"tn_rate\": 0.9999670839477308, \"fp_rate\": 3.29160522691426e-05, \"fn_rate\": 0.5621543553284797, \"precision\": 0.7597257662162702, \"recall\": 0.4378456446715204, \"specificity\": 0.9999670839477308, \"npv\": 0.999866387156038, \"accuracy\": 0.9998334972259502, \"f1\": 0.5555286555077847, \"f2\": 0.4783817377570321, \"f0_5\": 0.6623422254117493, \"p4\": 0.7142422387962384, \"phi\": 0.5766793851922427}, {\"truth_threshold\": -7.659999828785658, \"match_probability\": 0.004920035842332357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133086.0, \"tn\": 1278695744.0, \"fp\": 42048.0, \"fn\": 170875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783906488003393, \"tn_rate\": 0.9999671175746404, \"fp_rate\": 3.288242535964715e-05, \"fn_rate\": 0.562160935119966, \"precision\": 0.7599095549693378, \"recall\": 0.43783906488003393, \"specificity\": 0.9999671175746404, \"npv\": 0.9998663855968548, \"accuracy\": 0.9998335292811977, \"f1\": 0.5555724856239368, \"f2\": 0.47839002486020626, \"f0_5\": 0.6624509580416865, \"p4\": 0.7142784678968572, \"phi\": 0.5767448344460436}, {\"truth_threshold\": -7.639999829232693, \"match_probability\": 0.004988374374458207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133086.0, \"tn\": 1278696052.0, \"fp\": 41740.0, \"fn\": 170875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783906488003393, \"tn_rate\": 0.9999673584371549, \"fp_rate\": 3.264156284512157e-05, \"fn_rate\": 0.562160935119966, \"precision\": 0.761248326907897, \"recall\": 0.43783906488003393, \"specificity\": 0.9999673584371549, \"npv\": 0.9998663856290343, \"accuracy\": 0.9998337700864719, \"f1\": 0.5559298811371236, \"f2\": 0.47849597675940375, \"f0_5\": 0.663264441598182, \"p4\": 0.714573805135148, \"phi\": 0.577252899542206}, {\"truth_threshold\": -7.6199998296797276, \"match_probability\": 0.005057657293635818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133085.0, \"tn\": 1278696068.0, \"fp\": 41724.0, \"fn\": 170876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783577498429077, \"tn_rate\": 0.9999673709494933, \"fp_rate\": 3.262905050670466e-05, \"fn_rate\": 0.5621642250157093, \"precision\": 0.7613166370152566, \"recall\": 0.43783577498429077, \"specificity\": 0.9999673709494933, \"npv\": 0.9998663848488683, \"accuracy\": 0.9998337818140015, \"f1\": 0.5559454435323851, \"f2\": 0.47849823068731023, \"f0_5\": 0.6633044157827426, \"p4\": 0.7145866623483415, \"phi\": 0.5772766421772998}, {\"truth_threshold\": -7.599999830126762, \"match_probability\": 0.005127897515652181, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133085.0, \"tn\": 1278696326.0, \"fp\": 41466.0, \"fn\": 170876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43783577498429077, \"tn_rate\": 0.9999675727109503, \"fp_rate\": 3.2427289049731944e-05, \"fn_rate\": 0.5621642250157093, \"precision\": 0.7624419224180898, \"recall\": 0.43783577498429077, \"specificity\": 0.9999675727109503, \"npv\": 0.9998663848758239, \"accuracy\": 0.9998339835275104, \"f1\": 0.5562451934329755, \"f2\": 0.4785870202352569, \"f0_5\": 0.6639874671336556, \"p4\": 0.714834254043218, \"phi\": 0.5777033225706495}, {\"truth_threshold\": -7.579999830573797, \"match_probability\": 0.005199108129162101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133082.0, \"tn\": 1278696437.0, \"fp\": 41355.0, \"fn\": 170879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378259052970611, \"tn_rate\": 0.9999676595152981, \"fp_rate\": 3.2340484701964605e-05, \"fn_rate\": 0.5621740947029389, \"precision\": 0.7629230037205409, \"recall\": 0.4378259052970611, \"specificity\": 0.9999676595152981, \"npv\": 0.9998663825419086, \"accuracy\": 0.9998340679657234, \"f1\": 0.5563652021956613, \"f2\": 0.478615474137962, \"f0_5\": 0.6642747544446541, \"p4\": 0.7149333543382973, \"phi\": 0.5778791262996695}, {\"truth_threshold\": -7.559999831020832, \"match_probability\": 0.005271302397896121, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133081.0, \"tn\": 1278696479.0, \"fp\": 41313.0, \"fn\": 170880.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43782261540131795, \"tn_rate\": 0.9999676923601863, \"fp_rate\": 3.230763981362021e-05, \"fn_rate\": 0.562177384598682, \"precision\": 0.7631053820658967, \"recall\": 0.43782261540131795, \"specificity\": 0.9999676923601863, \"npv\": 0.9998663817644594, \"accuracy\": 0.999834100020971, \"f1\": 0.5564110336465595, \"f2\": 0.4786266811869622, \"f0_5\": 0.6643838420347925, \"p4\": 0.7149711967718478, \"phi\": 0.5779460557012475}, {\"truth_threshold\": -7.539999831467867, \"match_probability\": 0.005344493762893631, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133079.0, \"tn\": 1278696639.0, \"fp\": 41153.0, \"fn\": 170882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4378160356098315, \"tn_rate\": 0.9999678174835706, \"fp_rate\": 3.218251642945108e-05, \"fn_rate\": 0.5621839643901685, \"precision\": 0.763803434501125, \"recall\": 0.4378160356098315, \"specificity\": 0.9999678174835706, \"npv\": 0.9998663802175018, \"accuracy\": 0.9998342235509492, \"f1\": 0.5565911671647222, \"f2\": 0.47867526667606664, \"f0_5\": 0.6648039892535536, \"p4\": 0.7151199087813913, \"phi\": 0.5782061172096373}, {\"truth_threshold\": -7.519999831914902, \"match_probability\": 0.005418695844761402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696871.0, \"fp\": 40921.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999679989124776, \"fp_rate\": 3.200108752240585e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.764820487474066, \"recall\": 0.43781274571408835, \"specificity\": 0.9999679989124776, \"npv\": 0.9998663794599046, \"accuracy\": 0.9998344041549049, \"f1\": 0.5568583145033057, \"f2\": 0.4787519165833839, \"f0_5\": 0.665418613000359, \"p4\": 0.7153403927274166, \"phi\": 0.5785889611913707}, {\"truth_threshold\": -7.499999832361937, \"match_probability\": 0.005493922445957709, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696886.0, \"fp\": 40906.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999680106427948, \"fp_rate\": 3.198935720513999e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.764886426338054, \"recall\": 0.43781274571408835, \"specificity\": 0.9999680106427948, \"npv\": 0.9998663794614719, \"accuracy\": 0.9998344158824345, \"f1\": 0.556875791147517, \"f2\": 0.478757083610346, \"f0_5\": 0.6654585422298497, \"p4\": 0.7153548140289925, \"phi\": 0.5786139142372616}, {\"truth_threshold\": -7.479999832808971, \"match_probability\": 0.0055701875531022705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696950.0, \"fp\": 40842.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999680606921485, \"fp_rate\": 3.1939307851472335e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7651678932842686, \"recall\": 0.43781274571408835, \"specificity\": 0.9999680606921485, \"npv\": 0.9998663794681588, \"accuracy\": 0.999834465919894, \"f1\": 0.5569503704897244, \"f2\": 0.47877913084523704, \"f0_5\": 0.6656289607969261, \"p4\": 0.715416351449399, \"phi\": 0.5787204168283392}, {\"truth_threshold\": -7.459999833256006, \"match_probability\": 0.00564750533931217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696962.0, \"fp\": 40830.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999680700764023, \"fp_rate\": 3.1929923597659655e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7652206914000506, \"recall\": 0.43781274571408835, \"specificity\": 0.9999680700764023, \"npv\": 0.9998663794694127, \"accuracy\": 0.9998344753019177, \"f1\": 0.5569643563403359, \"f2\": 0.47878326492784323, \"f0_5\": 0.6656609239960664, \"p4\": 0.7154278908944134, \"phi\": 0.5787403926079383}, {\"truth_threshold\": -7.439999833703041, \"match_probability\": 0.005725890166563975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696969.0, \"fp\": 40823.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999680755505505, \"fp_rate\": 3.192444944960225e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7652514936659364, \"recall\": 0.43781274571408835, \"specificity\": 0.9999680755505505, \"npv\": 0.999866379470144, \"accuracy\": 0.9998344807747648, \"f1\": 0.5569725150775747, \"f2\": 0.47878567650899984, \"f0_5\": 0.6656795706132167, \"p4\": 0.7154346224092497, \"phi\": 0.5787520461007174}, {\"truth_threshold\": -7.419999834150076, \"match_probability\": 0.005805356588082265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696971.0, \"fp\": 40821.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999680771145927, \"fp_rate\": 3.192288540730014e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7652602947688025, \"recall\": 0.43781274571408835, \"specificity\": 0.9999680771145927, \"npv\": 0.999866379470353, \"accuracy\": 0.9998344823384354, \"f1\": 0.5569748461892604, \"f2\": 0.4787863655366496, \"f0_5\": 0.6656848984099957, \"p4\": 0.7154365457224698, \"phi\": 0.5787553757993006}, {\"truth_threshold\": -7.399999834597111, \"match_probability\": 0.005885919350754696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133078.0, \"tn\": 1278696981.0, \"fp\": 40811.0, \"fn\": 170883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43781274571408835, \"tn_rate\": 0.9999680849348042, \"fp_rate\": 3.1915065195789565e-05, \"fn_rate\": 0.5621872542859117, \"precision\": 0.7653043033199339, \"recall\": 0.43781274571408835, \"specificity\": 0.9999680849348042, \"npv\": 0.9998663794713978, \"accuracy\": 0.9998344901567885, \"f1\": 0.5569865020403892, \"f2\": 0.47878981070464616, \"f0_5\": 0.6657115386731791, \"p4\": 0.7154461624436863, \"phi\": 0.5787720251537469}, {\"truth_threshold\": -7.379999835044146, \"match_probability\": 0.005967593397573865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133077.0, \"tn\": 1278696987.0, \"fp\": 40805.0, \"fn\": 170884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43780945581834513, \"tn_rate\": 0.9999680896269311, \"fp_rate\": 3.1910373068883225e-05, \"fn_rate\": 0.5621905441816549, \"precision\": 0.7653293612909905, \"recall\": 0.43780945581834513, \"specificity\": 0.9999680896269311, \"npv\": 0.9998663786901876, \"accuracy\": 0.999834494065965, \"f1\": 0.5569904759513061, \"f2\": 0.4787886245202292, \"f0_5\": 0.6657251855698262, \"p4\": 0.7154494412660961, \"phi\": 0.5787793299990437}, {\"truth_threshold\": -7.35999983549118, \"match_probability\": 0.006050393870106122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133077.0, \"tn\": 1278697029.0, \"fp\": 40763.0, \"fn\": 170884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43780945581834513, \"tn_rate\": 0.9999681224718194, \"fp_rate\": 3.187752818053883e-05, \"fn_rate\": 0.5621905441816549, \"precision\": 0.7655142659917166, \"recall\": 0.43780945581834513, \"specificity\": 0.9999681224718194, \"npv\": 0.999866378694576, \"accuracy\": 0.9998345269030479, \"f1\": 0.5570394369203916, \"f2\": 0.47880309480428646, \"f0_5\": 0.665837103393204, \"p4\": 0.7154898349922912, \"phi\": 0.5788492766696095}, {\"truth_threshold\": -7.339999835938215, \"match_probability\": 0.006134336110987506, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133069.0, \"tn\": 1278698872.0, \"fp\": 38920.0, \"fn\": 170892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377831366523995, \"tn_rate\": 0.9999695637368009, \"fp_rate\": 3.0436263199140672e-05, \"fn_rate\": 0.5622168633476005, \"precision\": 0.7737064579711493, \"recall\": 0.4377831366523995, \"specificity\": 0.9999695637368009, \"npv\": 0.999866372632452, \"accuracy\": 0.9998359615708339, \"f1\": 0.5591721819518857, \"f2\": 0.4794128688394065, \"f0_5\": 0.6707668081099527, \"p4\": 0.7172469295118215, \"phi\": 0.5819223277589922}, {\"truth_threshold\": -7.299999836832285, \"match_probability\": 0.006305708288857409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133069.0, \"tn\": 1278698886.0, \"fp\": 38906.0, \"fn\": 170892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377831366523995, \"tn_rate\": 0.999969574685097, \"fp_rate\": 3.0425314903025874e-05, \"fn_rate\": 0.5622168633476005, \"precision\": 0.7737694432330281, \"recall\": 0.4377831366523995, \"specificity\": 0.999969574685097, \"npv\": 0.9998663726339149, \"accuracy\": 0.9998359725165281, \"f1\": 0.559188630404088, \"f2\": 0.47941770504655146, \"f0_5\": 0.6708046792846981, \"p4\": 0.7172604621335047, \"phi\": 0.581946024974439}, {\"truth_threshold\": -7.27999983727932, \"match_probability\": 0.006393169939313586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133069.0, \"tn\": 1278698925.0, \"fp\": 38867.0, \"fn\": 170892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377831366523995, \"tn_rate\": 0.9999696051839219, \"fp_rate\": 3.039481607813465e-05, \"fn_rate\": 0.5622168633476005, \"precision\": 0.7739449562627955, \"recall\": 0.4377831366523995, \"specificity\": 0.9999696051839219, \"npv\": 0.9998663726379899, \"accuracy\": 0.999836003008105, \"f1\": 0.5592344561953532, \"f2\": 0.47943117785239736, \"f0_5\": 0.6709102001099118, \"p4\": 0.71729816284384, \"phi\": 0.5820120539046646}, {\"truth_threshold\": -7.259999837726355, \"match_probability\": 0.006481836790238961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133068.0, \"tn\": 1278698926.0, \"fp\": 38866.0, \"fn\": 170893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43777984675665627, \"tn_rate\": 0.999969605965943, \"fp_rate\": 3.0394034056983593e-05, \"fn_rate\": 0.5622201532433437, \"precision\": 0.77394814289204, \"recall\": 0.43777984675665627, \"specificity\": 0.999969605965943, \"npv\": 0.9998663718562585, \"accuracy\": 0.999836003008105, \"f1\": 0.559232603830677, \"f2\": 0.4794282659042008, \"f0_5\": 0.6709105704665841, \"p4\": 0.7172966391118003, \"phi\": 0.5820110654788889}, {\"truth_threshold\": -7.239999838173389, \"match_probability\": 0.006571725228019751, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133068.0, \"tn\": 1278698927.0, \"fp\": 38865.0, \"fn\": 170893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43777984675665627, \"tn_rate\": 0.9999696067479642, \"fp_rate\": 3.0393252035832534e-05, \"fn_rate\": 0.5622201532433437, \"precision\": 0.7739526443440178, \"recall\": 0.43777984675665627, \"specificity\": 0.9999696067479642, \"npv\": 0.999866371856363, \"accuracy\": 0.9998360037899404, \"f1\": 0.5592337789507748, \"f2\": 0.4794286113691177, \"f0_5\": 0.6709132765886217, \"p4\": 0.7172976058519516, \"phi\": 0.5820127588405599}, {\"truth_threshold\": -7.219999838620424, \"match_probability\": 0.006662851855667506, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133068.0, \"tn\": 1278698954.0, \"fp\": 38838.0, \"fn\": 170893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43777984675665627, \"tn_rate\": 0.9999696278625353, \"fp_rate\": 3.0372137464753993e-05, \"fn_rate\": 0.5622201532433437, \"precision\": 0.7740742033436878, \"recall\": 0.43777984675665627, \"specificity\": 0.9999696278625353, \"npv\": 0.9998663718591841, \"accuracy\": 0.9998360248994936, \"f1\": 0.5592655090603047, \"f2\": 0.47943793911007027, \"f0_5\": 0.6709863501363977, \"p4\": 0.7173237088210862, \"phi\": 0.5820584851898751}, {\"truth_threshold\": -7.199999839067459, \"match_probability\": 0.006755233495509978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133068.0, \"tn\": 1278698956.0, \"fp\": 38836.0, \"fn\": 170893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43777984675665627, \"tn_rate\": 0.9999696294265775, \"fp_rate\": 3.0370573422451878e-05, \"fn_rate\": 0.5622201532433437, \"precision\": 0.7740832092330603, \"recall\": 0.43777984675665627, \"specificity\": 0.9999696294265775, \"npv\": 0.9998663718593932, \"accuracy\": 0.9998360264631643, \"f1\": 0.5592678595820243, \"f2\": 0.4794386300682833, \"f0_5\": 0.6709917636250134, \"p4\": 0.7173256424499311, \"phi\": 0.582061872755341}, {\"truth_threshold\": -7.179999839514494, \"match_probability\": 0.006848887191910523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133068.0, \"tn\": 1278698973.0, \"fp\": 38819.0, \"fn\": 170893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43777984675665627, \"tn_rate\": 0.9999696427209371, \"fp_rate\": 3.035727906288391e-05, \"fn_rate\": 0.5622201532433437, \"precision\": 0.7741597677543968, \"recall\": 0.43777984675665627, \"specificity\": 0.9999696427209371, \"npv\": 0.9998663718611694, \"accuracy\": 0.9998360397543644, \"f1\": 0.5592878398143946, \"f2\": 0.47944450329350574, \"f0_5\": 0.6710377818053089, \"p4\": 0.7173420787160173, \"phi\": 0.5820906694485203}, {\"truth_threshold\": -7.159999839961529, \"match_probability\": 0.006943830214016168, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133067.0, \"tn\": 1278699058.0, \"fp\": 38734.0, \"fn\": 170894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377765568609131, \"tn_rate\": 0.999969709192735, \"fp_rate\": 3.029080726504406e-05, \"fn_rate\": 0.5622234431390869, \"precision\": 0.7745414753115524, \"recall\": 0.4377765568609131, \"specificity\": 0.999969709192735, \"npv\": 0.9998663710882152, \"accuracy\": 0.9998361054285302, \"f1\": 0.5593847343839987, \"f2\": 0.4794706138817925, \"f0_5\": 0.6712656318574607, \"p4\": 0.7174217809296769, \"phi\": 0.5822320355014358}, {\"truth_threshold\": -7.139999840408564, \"match_probability\": 0.0070400800585345, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133060.0, \"tn\": 1278699076.0, \"fp\": 38716.0, \"fn\": 170901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377535275907106, \"tn_rate\": 0.9999697232691157, \"fp_rate\": 3.0276730884325033e-05, \"fn_rate\": 0.5622464724092894, \"precision\": 0.7746134500745157, \"recall\": 0.4377535275907106, \"specificity\": 0.9999697232691157, \"npv\": 0.9998663656172452, \"accuracy\": 0.9998361140287185, \"f1\": 0.5593847020517639, \"f2\": 0.4794540292010781, \"f0_5\": 0.6712980480594108, \"p4\": 0.7174217554459501, \"phi\": 0.5822437828349194}, {\"truth_threshold\": -7.1199998408555984, \"match_probability\": 0.00713765445253955, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133060.0, \"tn\": 1278699087.0, \"fp\": 38705.0, \"fn\": 170901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377535275907106, \"tn_rate\": 0.9999697318713483, \"fp_rate\": 3.0268128651663404e-05, \"fn_rate\": 0.5622464724092894, \"precision\": 0.7746630570838063, \"recall\": 0.4377535275907106, \"specificity\": 0.9999697318713483, \"npv\": 0.9998663656183947, \"accuracy\": 0.9998361226289069, \"f1\": 0.5593976364545978, \"f2\": 0.4794578299794827, \"f0_5\": 0.6713278527902032, \"p4\": 0.7174323940806486, \"phi\": 0.5822624352081065}, {\"truth_threshold\": -7.099999841302633, \"match_probability\": 0.007236571356306779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699105.0, \"fp\": 38687.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.999969745947729, \"fp_rate\": 3.0254052270944377e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7747429343332596, \"recall\": 0.43775023769496746, \"specificity\": 0.999969745947729, \"npv\": 0.9998663648384397, \"accuracy\": 0.999836135920107, \"f1\": 0.5594157748361912, \"f2\": 0.47946079173242817, \"f0_5\": 0.6713742942342915, \"p4\": 0.7174473128847558, \"phi\": 0.5822902796397317}, {\"truth_threshold\": -7.079999841749668, \"match_probability\": 0.007336848966177337, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699128.0, \"fp\": 38664.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999697639342155, \"fp_rate\": 3.0236065784470065e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7748467007913908, \"recall\": 0.43775023769496746, \"specificity\": 0.9999697639342155, \"npv\": 0.9998663648408431, \"accuracy\": 0.9998361539023191, \"f1\": 0.5594428233869544, \"f2\": 0.47946873916718974, \"f0_5\": 0.6714366308624993, \"p4\": 0.7174695594147457, \"phi\": 0.5823292920253031}, {\"truth_threshold\": -7.059999842196703, \"match_probability\": 0.007438505717451711, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699201.0, \"fp\": 38591.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698210217596, \"fp_rate\": 3.01789782404429e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7751762307020099, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698210217596, \"npv\": 0.9998663648484712, \"accuracy\": 0.9998362109762964, \"f1\": 0.5595286904634249, \"f2\": 0.4794939653793098, \"f0_5\": 0.6716345585986123, \"p4\": 0.7175401771058104, \"phi\": 0.582453165870288}, {\"truth_threshold\": -7.039999842643738, \"match_probability\": 0.007541560287312903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699220.0, \"fp\": 38572.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698358801614, \"fp_rate\": 3.0164119838572816e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7752620447355082, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698358801614, \"npv\": 0.9998663648504567, \"accuracy\": 0.9998362258311673, \"f1\": 0.5595510437517872, \"f2\": 0.47950053154110883, \"f0_5\": 0.6716860931765751, \"p4\": 0.7175585593327762, \"phi\": 0.5824854199670075}, {\"truth_threshold\": -7.019999843090773, \"match_probability\": 0.007646031597779248, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699276.0, \"fp\": 38516.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698796733459, \"fp_rate\": 3.0120326654113622e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7755150808684249, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698796733459, \"npv\": 0.9998663648563083, \"accuracy\": 0.9998362696139443, \"f1\": 0.559616937518926, \"f2\": 0.4795198854852067, \"f0_5\": 0.6718380305798168, \"p4\": 0.7176127440073415, \"phi\": 0.5825805158326552}, {\"truth_threshold\": -6.9999998435378075, \"match_probability\": 0.007751938818687018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699294.0, \"fp\": 38498.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999698937497266, \"fp_rate\": 3.0106250273394595e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7755964489936289, \"recall\": 0.43775023769496746, \"specificity\": 0.9999698937497266, \"npv\": 0.9998663648581892, \"accuracy\": 0.9998362836869799, \"f1\": 0.5596381209544118, \"f2\": 0.47952610672761514, \"f0_5\": 0.6718868822012767, \"p4\": 0.7176301622478184, \"phi\": 0.5826110922473843}, {\"truth_threshold\": -6.979999843984842, \"match_probability\": 0.00785930137070288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699308.0, \"fp\": 38484.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999699046980227, \"fp_rate\": 3.0095301977279797e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7756597471187981, \"recall\": 0.43775023769496746, \"specificity\": 0.9999699046980227, \"npv\": 0.9998663648596522, \"accuracy\": 0.9998362946326741, \"f1\": 0.5596545980685756, \"f2\": 0.479530945583316, \"f0_5\": 0.6719248828187728, \"p4\": 0.7176437103527904, \"phi\": 0.5826348772298903}, {\"truth_threshold\": -6.959999844431877, \"match_probability\": 0.007968138928366363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699325.0, \"fp\": 38467.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999699179923823, \"fp_rate\": 3.0082007617711825e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7757366230192507, \"recall\": 0.43775023769496746, \"specificity\": 0.9999699179923823, \"npv\": 0.9998663648614285, \"accuracy\": 0.9998363079238743, \"f1\": 0.5596746072973604, \"f2\": 0.47953682146795734, \"f0_5\": 0.6719710322049562, \"p4\": 0.7176601623108481, \"phi\": 0.5826637629085103}, {\"truth_threshold\": -6.939999844878912, \"match_probability\": 0.0080784714231624, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133059.0, \"tn\": 1278699350.0, \"fp\": 38442.0, \"fn\": 170902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43775023769496746, \"tn_rate\": 0.9999699375429111, \"fp_rate\": 3.0062457088935398e-05, \"fn_rate\": 0.5622497623050325, \"precision\": 0.7758497035002712, \"recall\": 0.43775023769496746, \"specificity\": 0.9999699375429111, \"npv\": 0.9998663648640409, \"accuracy\": 0.9998363274697569, \"f1\": 0.5597040352330996, \"f2\": 0.47954546273637777, \"f0_5\": 0.6720389104665316, \"p4\": 0.717684357737168, \"phi\": 0.5827062496483669}, {\"truth_threshold\": -6.919999845325947, \"match_probability\": 0.00819031904662406, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133058.0, \"tn\": 1278699380.0, \"fp\": 38412.0, \"fn\": 170903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43774694779922424, \"tn_rate\": 0.9999699610035456, \"fp_rate\": 3.0038996454403687e-05, \"fn_rate\": 0.5622530522007757, \"precision\": 0.7759841371668513, \"recall\": 0.43774694779922424, \"specificity\": 0.9999699610035456, \"npv\": 0.9998663640853401, \"accuracy\": 0.9998363501429808, \"f1\": 0.55973632346229, \"f2\": 0.47955257425499925, \"f0_5\": 0.6721180472419308, \"p4\": 0.7177109039833265, \"phi\": 0.5827545650625044}, {\"truth_threshold\": -6.899999845772982, \"match_probability\": 0.008303702253465536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133058.0, \"tn\": 1278699391.0, \"fp\": 38401.0, \"fn\": 170903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43774694779922424, \"tn_rate\": 0.9999699696057782, \"fp_rate\": 3.0030394221742058e-05, \"fn_rate\": 0.5622530522007757, \"precision\": 0.776033920645752, \"recall\": 0.43774694779922424, \"specificity\": 0.9999699696057782, \"npv\": 0.9998663640864897, \"accuracy\": 0.9998363587431692, \"f1\": 0.5597492743258592, \"f2\": 0.4795563766531176, \"f0_5\": 0.6721479252816487, \"p4\": 0.7177215513553978, \"phi\": 0.5827732671002167}, {\"truth_threshold\": -6.8799998462200165, \"match_probability\": 0.008418641764745485, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133057.0, \"tn\": 1278699399.0, \"fp\": 38393.0, \"fn\": 170904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437743657903481, \"tn_rate\": 0.9999699758619475, \"fp_rate\": 3.0024138052533603e-05, \"fn_rate\": 0.562256342096519, \"precision\": 0.7760688247302421, \"recall\": 0.437743657903481, \"specificity\": 0.9999699758619475, \"npv\": 0.99986636330549, \"accuracy\": 0.9998363642160163, \"f1\": 0.5597556640464777, \"f2\": 0.47955588361226964, \"f0_5\": 0.6721673212017851, \"p4\": 0.7177268046685266, \"phi\": 0.5827841888054113}, {\"truth_threshold\": -6.859999846667051, \"match_probability\": 0.008535158571060781, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133055.0, \"tn\": 1278700654.0, \"fp\": 37138.0, \"fn\": 170906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43773707811199464, \"tn_rate\": 0.9999709572984921, \"fp_rate\": 2.9042701507956997e-05, \"fn_rate\": 0.5622629218880054, \"precision\": 0.7817889102372013, \"recall\": 0.43773707811199464, \"specificity\": 0.9999709572984921, \"npv\": 0.9998663618729624, \"accuracy\": 0.9998373438556544, \"f1\": 0.5612311611839191, \"f2\": 0.4799835790819437, \"f0_5\": 0.6755892206313793, \"p4\": 0.7189386981196048, \"phi\": 0.5849246049907536}, {\"truth_threshold\": -6.839999847114086, \"match_probability\": 0.008653273935770752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133054.0, \"tn\": 1278700664.0, \"fp\": 37128.0, \"fn\": 170907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377337882162514, \"tn_rate\": 0.9999709651187035, \"fp_rate\": 2.9034881296446427e-05, \"fn_rate\": 0.5622662117837486, \"precision\": 0.7818335664171299, \"recall\": 0.4377337882162514, \"specificity\": 0.9999709651187035, \"npv\": 0.9998663610921725, \"accuracy\": 0.9998373508921722, \"f1\": 0.561239963470936, \"f2\": 0.4799837809680338, \"f0_5\": 0.6756143310222822, \"p4\": 0.7189459211251652, \"phi\": 0.584939119868394}, {\"truth_threshold\": -6.819999847561121, \"match_probability\": 0.008773009398251957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133052.0, \"tn\": 1278700807.0, \"fp\": 36985.0, \"fn\": 170909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43772720842476504, \"tn_rate\": 0.9999710769477281, \"fp_rate\": 2.8923052271845266e-05, \"fn_rate\": 0.562272791575235, \"precision\": 0.782488517205079, \"recall\": 0.43772720842476504, \"specificity\": 0.9999710769477281, \"npv\": 0.9998663595434462, \"accuracy\": 0.9998374611309503, \"f1\": 0.5614032126717834, \"f2\": 0.48002678440645336, \"f0_5\": 0.6760023533978452, \"p4\": 0.7190798632418535, \"phi\": 0.5851797912655885}, {\"truth_threshold\": -6.799999848008156, \"match_probability\": 0.00889438677718353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133052.0, \"tn\": 1278700813.0, \"fp\": 36979.0, \"fn\": 170909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43772720842476504, \"tn_rate\": 0.999971081639855, \"fp_rate\": 2.8918360144938923e-05, \"fn_rate\": 0.562272791575235, \"precision\": 0.7825161294116955, \"recall\": 0.43772720842476504, \"specificity\": 0.999971081639855, \"npv\": 0.9998663595440732, \"accuracy\": 0.9998374658219621, \"f1\": 0.5614103191615049, \"f2\": 0.48002886263191125, \"f0_5\": 0.6760188398359898, \"p4\": 0.7190856932991341, \"phi\": 0.5851901208944332}, {\"truth_threshold\": -6.779999848455191, \"match_probability\": 0.009017428173863171, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133050.0, \"tn\": 1278700974.0, \"fp\": 36818.0, \"fn\": 170911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377206286332786, \"tn_rate\": 0.9999712075452604, \"fp_rate\": 2.8792454739618738e-05, \"fn_rate\": 0.5622793713667213, \"precision\": 0.7832552334754044, \"recall\": 0.4377206286332786, \"specificity\": 0.9999712075452604, \"npv\": 0.9998663579972281, \"accuracy\": 0.9998375901337757, \"f1\": 0.5615950057932292, \"f2\": 0.48007811146904983, \"f0_5\": 0.6764568608130904, \"p4\": 0.71923718914358, \"phi\": 0.585462148496994}, {\"truth_threshold\": -6.7599998489022255, \"match_probability\": 0.009142155975553755, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133049.0, \"tn\": 1278700998.0, \"fp\": 36794.0, \"fn\": 170912.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43771733873753543, \"tn_rate\": 0.999971226313768, \"fp_rate\": 2.877368623199337e-05, \"fn_rate\": 0.5622826612624646, \"precision\": 0.7833646367527658, \"recall\": 0.43771733873753543, \"specificity\": 0.999971226313768, \"npv\": 0.9998663572179015, \"accuracy\": 0.9998376081159878, \"f1\": 0.561620416881242, \"f2\": 0.48008316452416744, \"f0_5\": 0.6765205683120571, \"p4\": 0.7192580308118806, \"phi\": 0.5855008538462839}, {\"truth_threshold\": -6.73999984934926, \"match_probability\": 0.009268592858860633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133047.0, \"tn\": 1278701135.0, \"fp\": 36657.0, \"fn\": 170914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437710758946049, \"tn_rate\": 0.9999713334506657, \"fp_rate\": 2.8666549334298552e-05, \"fn_rate\": 0.562289241053951, \"precision\": 0.7839944845142129, \"recall\": 0.437710758946049, \"specificity\": 0.9999713334506657, \"npv\": 0.999866355668549, \"accuracy\": 0.9998377136637541, \"f1\": 0.5617767831695396, \"f2\": 0.4801241097385294, \"f0_5\": 0.6768931303846142, \"p4\": 0.7193862637462933, \"phi\": 0.5857318948794218}, {\"truth_threshold\": -6.719999849796295, \"match_probability\": 0.009396761793139606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133046.0, \"tn\": 1278701201.0, \"fp\": 36591.0, \"fn\": 170915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377074690503058, \"tn_rate\": 0.9999713850640617, \"fp_rate\": 2.8614935938328786e-05, \"fn_rate\": 0.5622925309496942, \"precision\": 0.7842982368233345, \"recall\": 0.4377074690503058, \"specificity\": 0.9999713850640617, \"npv\": 0.9998663548936115, \"accuracy\": 0.999837764483049, \"f1\": 0.5618520348481202, \"f2\": 0.4801437190405354, \"f0_5\": 0.6770726782146524, \"p4\": 0.7194479670312582, \"phi\": 0.5858432042276618}, {\"truth_threshold\": -6.69999985024333, \"match_probability\": 0.009526686043935558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133045.0, \"tn\": 1278701230.0, \"fp\": 36562.0, \"fn\": 170916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377041791545626, \"tn_rate\": 0.999971407742675, \"fp_rate\": 2.859225732494813e-05, \"fn_rate\": 0.5622958208454374, \"precision\": 0.7844310671139753, \"recall\": 0.4377041791545626, \"specificity\": 0.999971407742675, \"npv\": 0.9998663541148076, \"accuracy\": 0.9998377863744374, \"f1\": 0.5618834042840732, \"f2\": 0.48015050694683536, \"f0_5\": 0.6771502938245441, \"p4\": 0.719473687016438, \"phi\": 0.5858906332570077}, {\"truth_threshold\": -6.679999850690365, \"match_probability\": 0.009658389176451789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133045.0, \"tn\": 1278701234.0, \"fp\": 36558.0, \"fn\": 170916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4377041791545626, \"tn_rate\": 0.9999714108707597, \"fp_rate\": 2.8589129240343904e-05, \"fn_rate\": 0.5622958208454374, \"precision\": 0.7844495675194425, \"recall\": 0.4377041791545626, \"specificity\": 0.9999714108707597, \"npv\": 0.9998663541152256, \"accuracy\": 0.9998377895017787, \"f1\": 0.5618881502816937, \"f2\": 0.4801518932156914, \"f0_5\": 0.6771613226340708, \"p4\": 0.7194775781739715, \"phi\": 0.5858975454528784}, {\"truth_threshold\": -6.6599998511374, \"match_probability\": 0.00979189505904994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133042.0, \"tn\": 1278702388.0, \"fp\": 35404.0, \"fn\": 170919.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43769430946733295, \"tn_rate\": 0.9999723133231679, \"fp_rate\": 2.768667683202406e-05, \"fn_rate\": 0.562305690532667, \"precision\": 0.7898198829298411, \"recall\": 0.43769430946733295, \"specificity\": 0.9999723133231679, \"npv\": 0.9998663518903206, \"accuracy\": 0.9998386893942156, \"f1\": 0.5632516029610061, \"f2\": 0.4805423719018414, \"f0_5\": 0.6803512163191834, \"p4\": 0.7205944705569378, \"phi\": 0.5878939593650258}, {\"truth_threshold\": -6.6399998515844345, \"match_probability\": 0.009927227866780578, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133042.0, \"tn\": 1278702530.0, \"fp\": 35262.0, \"fn\": 170919.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43769430946733295, \"tn_rate\": 0.9999724243701714, \"fp_rate\": 2.7575629828573958e-05, \"fn_rate\": 0.562305690532667, \"precision\": 0.7904862629527522, \"recall\": 0.43769430946733295, \"specificity\": 0.9999724243701714, \"npv\": 0.9998663519051603, \"accuracy\": 0.999838800414829, \"f1\": 0.5634209606894435, \"f2\": 0.4805916708328878, \"f0_5\": 0.6807466815121519, \"p4\": 0.7207330663831311, \"phi\": 0.5881420300614416}, {\"truth_threshold\": -6.619999852031469, \"match_probability\": 0.010064412084944284, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133041.0, \"tn\": 1278702544.0, \"fp\": 35248.0, \"fn\": 170920.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376910195715898, \"tn_rate\": 0.9999724353184676, \"fp_rate\": 2.756468153245916e-05, \"fn_rate\": 0.5623089804284103, \"precision\": 0.7905507787199401, \"recall\": 0.4376910195715898, \"specificity\": 0.9999724353184676, \"npv\": 0.9998663511247896, \"accuracy\": 0.999838810578688, \"f1\": 0.5634346214928534, \"f2\": 0.48059326668752206, \"f0_5\": 0.6807833657586553, \"p4\": 0.7207442447061225, \"phi\": 0.588163830792176}, {\"truth_threshold\": -6.599999852478504, \"match_probability\": 0.010203472512683304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133040.0, \"tn\": 1278702600.0, \"fp\": 35192.0, \"fn\": 170921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43768772967584657, \"tn_rate\": 0.999972479111652, \"fp_rate\": 2.7520888347999963e-05, \"fn_rate\": 0.5623122703241534, \"precision\": 0.7908126872414285, \"recall\": 0.43768772967584657, \"specificity\": 0.999972479111652, \"npv\": 0.9998663503488082, \"accuracy\": 0.9998388535796298, \"f1\": 0.5634984000186365, \"f2\": 0.4806094463020817, \"f0_5\": 0.6809371382009625, \"p4\": 0.7207964300529897, \"phi\": 0.5882590863519589}, {\"truth_threshold\": -6.579999852925539, \"match_probability\": 0.010344434266603562, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133033.0, \"tn\": 1278702687.0, \"fp\": 35105.0, \"fn\": 170928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43766470040564415, \"tn_rate\": 0.9999725471474922, \"fp_rate\": 2.7452852507858e-05, \"fn_rate\": 0.5623352995943559, \"precision\": 0.7912131701340566, \"recall\": 0.43766470040564415, \"specificity\": 0.9999725471474922, \"npv\": 0.9998663448850651, \"accuracy\": 0.9998389161264543, \"f1\": 0.5635809438274599, \"f2\": 0.48061679992947887, \"f0_5\": 0.6811634868148196, \"p4\": 0.720863964249776, \"phi\": 0.5883926083395663}, {\"truth_threshold\": -6.559999853372574, \"match_probability\": 0.010487322784427081, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133033.0, \"tn\": 1278702696.0, \"fp\": 35096.0, \"fn\": 170928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43766470040564415, \"tn_rate\": 0.9999725541856825, \"fp_rate\": 2.7445814317498485e-05, \"fn_rate\": 0.5623352995943559, \"precision\": 0.7912555240321419, \"recall\": 0.43766470040564415, \"specificity\": 0.9999725541856825, \"npv\": 0.9998663448860057, \"accuracy\": 0.999838923162972, \"f1\": 0.5635916880255883, \"f2\": 0.48061992538871784, \"f0_5\": 0.6811885994242568, \"p4\": 0.720872754075173, \"phi\": 0.588408363945056}, {\"truth_threshold\": -6.539999853819609, \"match_probability\": 0.010632163828674601, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133033.0, \"tn\": 1278702900.0, \"fp\": 34892.0, \"fn\": 170928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43766470040564415, \"tn_rate\": 0.9999727137179973, \"fp_rate\": 2.7286282002682845e-05, \"fn_rate\": 0.5623352995943559, \"precision\": 0.7922167634360577, \"recall\": 0.43766470040564415, \"specificity\": 0.9999727137179973, \"npv\": 0.9998663449073257, \"accuracy\": 0.9998390826573743, \"f1\": 0.5638353331101156, \"f2\": 0.48069078003626325, \"f0_5\": 0.6817583156444708, \"p4\": 0.7210720476286433, \"phi\": 0.588765830620642}, {\"truth_threshold\": -6.5199998542666435, \"match_probability\": 0.010778983490378357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133027.0, \"tn\": 1278703076.0, \"fp\": 34716.0, \"fn\": 170934.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43764496103118494, \"tn_rate\": 0.9999728513537199, \"fp_rate\": 2.7148646280096803e-05, \"fn_rate\": 0.5623550389688151, \"precision\": 0.7930405441657774, \"recall\": 0.43764496103118494, \"specificity\": 0.9999728513537199, \"npv\": 0.9998663402347194, \"accuracy\": 0.9998392155693764, \"f1\": 0.5640274409375371, \"f2\": 0.4807323283609921, \"f0_5\": 0.6822366254911876, \"p4\": 0.7212291425938945, \"phi\": 0.5890587204823269}, {\"truth_threshold\": -6.499999854713678, \"match_probability\": 0.010927808192824842, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133027.0, \"tn\": 1278703084.0, \"fp\": 34708.0, \"fn\": 170934.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43764496103118494, \"tn_rate\": 0.9999728576098891, \"fp_rate\": 2.7142390110888348e-05, \"fn_rate\": 0.5623550389688151, \"precision\": 0.7930783676632784, \"recall\": 0.43764496103118494, \"specificity\": 0.9999728576098891, \"npv\": 0.9998663402355555, \"accuracy\": 0.9998392218240588, \"f1\": 0.5640370068857908, \"f2\": 0.48073510800612035, \"f0_5\": 0.6822590191209159, \"p4\": 0.7212369640322692, \"phi\": 0.5890727742594045}, {\"truth_threshold\": -6.479999855160713, \"match_probability\": 0.011078664695327443, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133026.0, \"tn\": 1278703097.0, \"fp\": 34695.0, \"fn\": 170935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4376416711354417, \"tn_rate\": 0.9999728677761641, \"fp_rate\": 2.7132223835924605e-05, \"fn_rate\": 0.5623583288645583, \"precision\": 0.7931386051836085, \"recall\": 0.4376416711354417, \"specificity\": 0.9999728677761641, \"npv\": 0.9998663394550809, \"accuracy\": 0.9998392312060824, \"f1\": 0.5640495079311909, \"f2\": 0.48073635860982317, \"f0_5\": 0.6822930824900368, \"p4\": 0.7212471853170371, \"phi\": 0.5890929410565735}, {\"truth_threshold\": -6.459999855607748, \"match_probability\": 0.01123158009702879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133011.0, \"tn\": 1278703190.0, \"fp\": 34602.0, \"fn\": 170950.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43759232269929366, \"tn_rate\": 0.9999729405041311, \"fp_rate\": 2.7059495868876298e-05, \"fn_rate\": 0.5624076773007063, \"precision\": 0.7935601653809669, \"recall\": 0.43759232269929366, \"specificity\": 0.9999729405041311, \"npv\": 0.9998663277373018, \"accuracy\": 0.9998392921892363, \"f1\": 0.5641150699572072, \"f2\": 0.4807196754217876, \"f0_5\": 0.6825186035079581, \"p4\": 0.7213007899437046, \"phi\": 0.5892163204578311}, {\"truth_threshold\": -6.439999856054783, \"match_probability\": 0.011386581840732598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133010.0, \"tn\": 1278703253.0, \"fp\": 34539.0, \"fn\": 170951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43758903280355044, \"tn_rate\": 0.9999729897714636, \"fp_rate\": 2.7010228536359705e-05, \"fn_rate\": 0.5624109671964496, \"precision\": 0.793857319351354, \"recall\": 0.43758903280355044, \"specificity\": 0.9999729897714636, \"npv\": 0.9998663269620536, \"accuracy\": 0.9998393406630253, \"f1\": 0.5641873979342962, \"f2\": 0.48073830068534396, \"f0_5\": 0.6826928308270638, \"p4\": 0.7213599188696931, \"phi\": 0.5893244641507}, {\"truth_threshold\": -6.419999856501818, \"match_probability\": 0.0115436977167649, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133010.0, \"tn\": 1278703298.0, \"fp\": 34494.0, \"fn\": 170951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43758903280355044, \"tn_rate\": 0.9999730249624155, \"fp_rate\": 2.6975037584562136e-05, \"fn_rate\": 0.5624109671964496, \"precision\": 0.79407058935906, \"recall\": 0.43758903280355044, \"specificity\": 0.9999730249624155, \"npv\": 0.9998663269667571, \"accuracy\": 0.999839375845614, \"f1\": 0.5642412480247738, \"f2\": 0.48075393899438174, \"f0_5\": 0.6828189988059267, \"p4\": 0.7214039382501293, \"phi\": 0.5894036569651482}, {\"truth_threshold\": -6.3999998569488525, \"match_probability\": 0.011702955866864343, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133009.0, \"tn\": 1278703348.0, \"fp\": 34444.0, \"fn\": 170952.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375857429078073, \"tn_rate\": 0.999973064063473, \"fp_rate\": 2.6935936527009283e-05, \"fn_rate\": 0.5624142570921927, \"precision\": 0.7943064621117567, \"recall\": 0.4375857429078073, \"specificity\": 0.999973064063473, \"npv\": 0.9998663261901501, \"accuracy\": 0.999839414155544, \"f1\": 0.5642980480002715, \"f2\": 0.4807680490885182, \"f0_5\": 0.6829569109022329, \"p4\": 0.7214503658668353, \"phi\": 0.5894890141287092}, {\"truth_threshold\": -6.379999857395887, \"match_probability\": 0.011864384788101447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133005.0, \"tn\": 1278704564.0, \"fp\": 33228.0, \"fn\": 170956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43757258332483445, \"tn_rate\": 0.9999740150011927, \"fp_rate\": 2.59849988073239e-05, \"fn_rate\": 0.5624274166751656, \"precision\": 0.8001118911407482, \"recall\": 0.43757258332483445, \"specificity\": 0.9999740150011927, \"npv\": 0.9998663231899223, \"accuracy\": 0.9998403617399345, \"f1\": 0.56574520304385, \"f2\": 0.481177966205935, \"f0_5\": 0.6863761013858083, \"p4\": 0.722632113561839, \"phi\": 0.591631427846184}, {\"truth_threshold\": -6.359999857842922, \"match_probability\": 0.012028013336826474, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133004.0, \"tn\": 1278704603.0, \"fp\": 33189.0, \"fn\": 170957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43756929342909123, \"tn_rate\": 0.9999740455000176, \"fp_rate\": 2.5954499982432676e-05, \"fn_rate\": 0.5624307065709088, \"precision\": 0.8002984481897553, \"recall\": 0.43756929342909123, \"specificity\": 0.9999740455000176, \"npv\": 0.9998663224121666, \"accuracy\": 0.9998403914496762, \"f1\": 0.5657890818753004, \"f2\": 0.48118827498829625, \"f0_5\": 0.6864843047568319, \"p4\": 0.7226679110639399, \"phi\": 0.5916982046809077}, {\"truth_threshold\": -6.339999858289957, \"match_probability\": 0.012193870732645717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133004.0, \"tn\": 1278704618.0, \"fp\": 33174.0, \"fn\": 170957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43756929342909123, \"tn_rate\": 0.9999740572303348, \"fp_rate\": 2.5942769665166822e-05, \"fn_rate\": 0.5624307065709088, \"precision\": 0.8003706868538555, \"recall\": 0.43756929342909123, \"specificity\": 0.9999740572303348, \"npv\": 0.9998663224137344, \"accuracy\": 0.9998404031772058, \"f1\": 0.5658071336349463, \"f2\": 0.48119349764330815, \"f0_5\": 0.6865268258741598, \"p4\": 0.7226826375162457, \"phi\": 0.591724921189415}, {\"truth_threshold\": -6.319999858736992, \"match_probability\": 0.01236198656242589, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133004.0, \"tn\": 1278704628.0, \"fp\": 33164.0, \"fn\": 170957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43756929342909123, \"tn_rate\": 0.9999740650505463, \"fp_rate\": 2.593494945365625e-05, \"fn_rate\": 0.5624307065709088, \"precision\": 0.8004188532088007, \"recall\": 0.43756929342909123, \"specificity\": 0.9999740650505463, \"npv\": 0.9998663224147797, \"accuracy\": 0.9998404109955588, \"f1\": 0.5658191687813345, \"f2\": 0.48119697947629975, \"f0_5\": 0.6865551762122496, \"p4\": 0.7226924554845586, \"phi\": 0.5917427342044919}, {\"truth_threshold\": -6.299999859184027, \"match_probability\": 0.012532390784326317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133004.0, \"tn\": 1278704633.0, \"fp\": 33159.0, \"fn\": 170957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43756929342909123, \"tn_rate\": 0.9999740689606521, \"fp_rate\": 2.5931039347900964e-05, \"fn_rate\": 0.5624307065709088, \"precision\": 0.8004429385603293, \"recall\": 0.43756929342909123, \"specificity\": 0.9999740689606521, \"npv\": 0.9998663224153024, \"accuracy\": 0.9998404149047353, \"f1\": 0.5658251865465281, \"f2\": 0.4811987204116911, \"f0_5\": 0.6865693522593647, \"p4\": 0.7226973645687519, \"phi\": 0.5917516413149425}, {\"truth_threshold\": -6.2799998596310616, \"match_probability\": 0.012705113731858605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133002.0, \"tn\": 1278704644.0, \"fp\": 33148.0, \"fn\": 170959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43756271363760485, \"tn_rate\": 0.9999740775628848, \"fp_rate\": 2.5922437115239336e-05, \"fn_rate\": 0.5624372863623952, \"precision\": 0.8004935299428227, \"recall\": 0.43756271363760485, \"specificity\": 0.9999740775628848, \"npv\": 0.9998663208527875, \"accuracy\": 0.9998404219412531, \"f1\": 0.5658323247062927, \"f2\": 0.4811960109812344, \"f0_5\": 0.686595888126819, \"p4\": 0.7227031878965684, \"phi\": 0.5917659004393663}, {\"truth_threshold\": -6.259999860078096, \"match_probability\": 0.012880186117973461, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133001.0, \"tn\": 1278704668.0, \"fp\": 33124.0, \"fn\": 170960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43755942374186163, \"tn_rate\": 0.9999740963313923, \"fp_rate\": 2.590366860761397e-05, \"fn_rate\": 0.5624405762581384, \"precision\": 0.8006079759217457, \"recall\": 0.43755942374186163, \"specificity\": 0.9999740963313923, \"npv\": 0.9998663200734638, \"accuracy\": 0.9998404399234652, \"f1\": 0.5658581621235264, \"f2\": 0.4812010978538592, \"f0_5\": 0.6866616208603135, \"p4\": 0.7227242647015523, \"phi\": 0.5918059956226734}, {\"truth_threshold\": -6.239999860525131, \"match_probability\": 0.013057639039174252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133001.0, \"tn\": 1278704671.0, \"fp\": 33121.0, \"fn\": 170960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43755942374186163, \"tn_rate\": 0.9999740986774558, \"fp_rate\": 2.59013225441608e-05, \"fn_rate\": 0.5624405762581384, \"precision\": 0.8006224341146868, \"recall\": 0.43755942374186163, \"specificity\": 0.9999740986774558, \"npv\": 0.9998663200737774, \"accuracy\": 0.9998404422689711, \"f1\": 0.5658617733464091, \"f2\": 0.48120214245502424, \"f0_5\": 0.6866701292479005, \"p4\": 0.7227272104697952, \"phi\": 0.5918113417949422}, {\"truth_threshold\": -6.219999860972166, \"match_probability\": 0.013237503979656957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133000.0, \"tn\": 1278704683.0, \"fp\": 33109.0, \"fn\": 170961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375561338461184, \"tn_rate\": 0.9999741080617096, \"fp_rate\": 2.589193829034811e-05, \"fn_rate\": 0.5624438661538815, \"precision\": 0.8006790721754993, \"recall\": 0.4375561338461184, \"specificity\": 0.9999741080617096, \"npv\": 0.9998663192931994, \"accuracy\": 0.9998404508691594, \"f1\": 0.5658731678260684, \"f2\": 0.48120305104442773, \"f0_5\": 0.6867018381923943, \"p4\": 0.7227365053103004, \"phi\": 0.591830059043554}, {\"truth_threshold\": -6.199999861419201, \"match_probability\": 0.013419812815476096, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 133000.0, \"tn\": 1278704691.0, \"fp\": 33101.0, \"fn\": 170961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375561338461184, \"tn_rate\": 0.9999741143178789, \"fp_rate\": 2.5885682121139656e-05, \"fn_rate\": 0.5624438661538815, \"precision\": 0.8007176356554144, \"recall\": 0.4375561338461184, \"specificity\": 0.9999741143178789, \"npv\": 0.9998663192940357, \"accuracy\": 0.9998404571238418, \"f1\": 0.5658827984393549, \"f2\": 0.4812058367011712, \"f0_5\": 0.6867245305230982, \"p4\": 0.7227443610708001, \"phi\": 0.5918443177771899}, {\"truth_threshold\": -6.179999861866236, \"match_probability\": 0.013604597818736125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132999.0, \"tn\": 1278704776.0, \"fp\": 33016.0, \"fn\": 170962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375528439503752, \"tn_rate\": 0.9999741807896767, \"fp_rate\": 2.5819210323299807e-05, \"fn_rate\": 0.5624471560496248, \"precision\": 0.8011264042405807, \"recall\": 0.4375528439503752, \"specificity\": 0.9999741807896767, \"npv\": 0.9998663185210884, \"accuracy\": 0.9998405227980075, \"f1\": 0.5659820927026061, \"f2\": 0.4812321662340369, \"f0_5\": 0.6869634026534548, \"p4\": 0.7228253506389261, \"phi\": 0.5919932118093469}, {\"truth_threshold\": -6.159999862313271, \"match_probability\": 0.013791891661807958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132998.0, \"tn\": 1278704795.0, \"fp\": 32997.0, \"fn\": 170963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43754955405463203, \"tn_rate\": 0.9999741956480785, \"fp_rate\": 2.580435192142972e-05, \"fn_rate\": 0.562450445945368, \"precision\": 0.8012169041236182, \"recall\": 0.43754955405463203, \"specificity\": 0.9999741956480785, \"npv\": 0.9998663177412422, \"accuracy\": 0.999840536871043, \"f1\": 0.5660019235843355, \"f2\": 0.48123551296496914, \"f0_5\": 0.6870150143448825, \"p4\": 0.7228415246331428, \"phi\": 0.5920244378860067}, {\"truth_threshold\": -6.139999862760305, \"match_probability\": 0.01398172742157, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132996.0, \"tn\": 1278704802.0, \"fp\": 32990.0, \"fn\": 170965.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4375429742631456, \"tn_rate\": 0.9999742011222267, \"fp_rate\": 2.579887777337232e-05, \"fn_rate\": 0.5624570257368544, \"precision\": 0.801248298049233, \"recall\": 0.4375429742631456, \"specificity\": 0.9999742011222267, \"npv\": 0.9998663161783095, \"accuracy\": 0.9998405407802196, \"f1\": 0.5660042515432592, \"f2\": 0.48123141052083107, \"f0_5\": 0.6870302354053343, \"p4\": 0.722843423576022, \"phi\": 0.5920315896780985}, {\"truth_threshold\": -6.11999986320734, \"match_probability\": 0.01417413858367327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132982.0, \"tn\": 1278704919.0, \"fp\": 32873.0, \"fn\": 170979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43749691572274074, \"tn_rate\": 0.9999742926187013, \"fp_rate\": 2.5707381298698646e-05, \"fn_rate\": 0.5625030842772593, \"precision\": 0.8017967501733442, \"recall\": 0.43749691572274074, \"specificity\": 0.9999742926187013, \"npv\": 0.9998663052448894, \"accuracy\": 0.999840621309256, \"f1\": 0.5661024741600967, \"f2\": 0.48122637419582703, \"f0_5\": 0.687330017852325, \"p4\": 0.7229235287223209, \"phi\": 0.592203094838677}, {\"truth_threshold\": -6.099999863654375, \"match_probability\": 0.014369159046830017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132980.0, \"tn\": 1278704966.0, \"fp\": 32826.0, \"fn\": 170981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43749033593125436, \"tn_rate\": 0.9999743293736953, \"fp_rate\": 2.5670626304598966e-05, \"fn_rate\": 0.5625096640687457, \"precision\": 0.802021639747657, \"recall\": 0.43749033593125436, \"specificity\": 0.9999743293736953, \"npv\": 0.9998663036861385, \"accuracy\": 0.9998406564918448, \"f1\": 0.5661530077676806, \"f2\": 0.48123620309050774, \"f0_5\": 0.6874589659682481, \"p4\": 0.7229647365179133, \"phi\": 0.5922817241704658}, {\"truth_threshold\": -6.07999986410141, \"match_probability\": 0.014566823127125275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132980.0, \"tn\": 1278704997.0, \"fp\": 32795.0, \"fn\": 170981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43749033593125436, \"tn_rate\": 0.9999743536163511, \"fp_rate\": 2.5646383648916195e-05, \"fn_rate\": 0.5625096640687457, \"precision\": 0.8021716181571407, \"recall\": 0.43749033593125436, \"specificity\": 0.9999743536163511, \"npv\": 0.9998663036893793, \"accuracy\": 0.9998406807287393, \"f1\": 0.566190370761449, \"f2\": 0.4812470008012339, \"f0_5\": 0.6875471144012633, \"p4\": 0.7229952023520636, \"phi\": 0.592337125702918}, {\"truth_threshold\": -6.059999864548445, \"match_probability\": 0.014767165562350774, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132979.0, \"tn\": 1278705072.0, \"fp\": 32720.0, \"fn\": 170982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43748704603551114, \"tn_rate\": 0.9999744122679374, \"fp_rate\": 2.5587732062586915e-05, \"fn_rate\": 0.5625129539644889, \"precision\": 0.802533509556485, \"recall\": 0.43748704603551114, \"specificity\": 0.9999744122679374, \"npv\": 0.9998663029153879, \"accuracy\": 0.9998407385845519, \"f1\": 0.5662777328280032, \"f2\": 0.48126985551662166, \"f0_5\": 0.6877581439803384, \"p4\": 0.7230664319805901, \"phi\": 0.5924685579052774}, {\"truth_threshold\": -6.03999986499548, \"match_probability\": 0.014970221516360545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132979.0, \"tn\": 1278705122.0, \"fp\": 32670.0, \"fn\": 170982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43748704603551114, \"tn_rate\": 0.999974451368995, \"fp_rate\": 2.5548631005034065e-05, \"fn_rate\": 0.5625129539644889, \"precision\": 0.8027757487216947, \"recall\": 0.43748704603551114, \"specificity\": 0.999974451368995, \"npv\": 0.9998663029206151, \"accuracy\": 0.9998407776763172, \"f1\": 0.5663380251698218, \"f2\": 0.48128727398546356, \"f0_5\": 0.6879004549136781, \"p4\": 0.7231155858874262, \"phi\": 0.5925580087985223}, {\"truth_threshold\": -6.019999865442514, \"match_probability\": 0.015176026583447584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132978.0, \"tn\": 1278705157.0, \"fp\": 32635.0, \"fn\": 170983.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374837561397679, \"tn_rate\": 0.9999744787397352, \"fp_rate\": 2.5521260264747066e-05, \"fn_rate\": 0.562516243860232, \"precision\": 0.8029442133165875, \"recall\": 0.4374837561397679, \"specificity\": 0.9999744787397352, \"npv\": 0.999866302142442, \"accuracy\": 0.9998408042587176, \"f1\": 0.5663771844267357, \"f2\": 0.48129619669667606, \"f0_5\": 0.687997781486797, \"p4\": 0.7231475089750913, \"phi\": 0.5926179806885808}, {\"truth_threshold\": -5.999999865889549, \"match_probability\": 0.015384616792740884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132968.0, \"tn\": 1278705194.0, \"fp\": 32598.0, \"fn\": 170993.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374508571823359, \"tn_rate\": 0.9999745076745178, \"fp_rate\": 2.5492325482157955e-05, \"fn_rate\": 0.5625491428176641, \"precision\": 0.8031117499969801, \"recall\": 0.4374508571823359, \"specificity\": 0.9999745076745178, \"npv\": 0.9998662943279903, \"accuracy\": 0.9998408253682708, \"f1\": 0.5663912831423965, \"f2\": 0.4812763770350584, \"f0_5\": 0.6880798985743486, \"p4\": 0.7231590035330133, \"phi\": 0.5926575436210132}, {\"truth_threshold\": -5.979999866336584, \"match_probability\": 0.015596028612622095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132966.0, \"tn\": 1278705195.0, \"fp\": 32597.0, \"fn\": 170995.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43744427739084946, \"tn_rate\": 0.999974508456539, \"fp_rate\": 2.54915434610069e-05, \"fn_rate\": 0.5625557226091505, \"precision\": 0.8031142223806044, \"recall\": 0.43744427739084946, \"specificity\": 0.999974508456539, \"npv\": 0.999866292764431, \"accuracy\": 0.9998408245864355, \"f1\": 0.5663863828047129, \"f2\": 0.4812701832262324, \"f0_5\": 0.6880780945816295, \"p4\": 0.7231550092120459, \"phi\": 0.592653998547088}, {\"truth_threshold\": -5.959999866783619, \"match_probability\": 0.015810298955161086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132966.0, \"tn\": 1278705205.0, \"fp\": 32587.0, \"fn\": 170995.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43744427739084946, \"tn_rate\": 0.9999745162767505, \"fp_rate\": 2.5483723249496327e-05, \"fn_rate\": 0.5625557226091505, \"precision\": 0.8031627333844751, \"recall\": 0.43744427739084946, \"specificity\": 0.9999745162767505, \"npv\": 0.9998662927654764, \"accuracy\": 0.9998408324047886, \"f1\": 0.5663984460527268, \"f2\": 0.4812736671644719, \"f0_5\": 0.6881065813265326, \"p4\": 0.7231648428286696, \"phi\": 0.5926719057780446}, {\"truth_threshold\": -5.939999867230654, \"match_probability\": 0.016027465180569564, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132963.0, \"tn\": 1278705290.0, \"fp\": 32502.0, \"fn\": 170998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43743440770361985, \"tn_rate\": 0.9999745827485483, \"fp_rate\": 2.5417251451656478e-05, \"fn_rate\": 0.5625655922963801, \"precision\": 0.8035717523343305, \"recall\": 0.43743440770361985, \"specificity\": 0.9999745827485483, \"npv\": 0.9998662904288675, \"accuracy\": 0.9998408965152836, \"f1\": 0.5664918432298168, \"f2\": 0.4812934687314714, \"f0_5\": 0.688341835598936, \"p4\": 0.7232409728953791, \"phi\": 0.592816179920822}, {\"truth_threshold\": -5.919999867677689, \"match_probability\": 0.01624756510167204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132963.0, \"tn\": 1278705309.0, \"fp\": 32483.0, \"fn\": 170998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43743440770361985, \"tn_rate\": 0.9999745976069502, \"fp_rate\": 2.5402393049786394e-05, \"fn_rate\": 0.5625655922963801, \"precision\": 0.8036640353952347, \"recall\": 0.43743440770361985, \"specificity\": 0.9999745976069502, \"npv\": 0.999866290430854, \"accuracy\": 0.9998409113701545, \"f1\": 0.5665147728943113, \"f2\": 0.481300089047195, \"f0_5\": 0.6883960051566407, \"p4\": 0.7232596618596532, \"phi\": 0.5928502345082337}, {\"truth_threshold\": -5.899999868124723, \"match_probability\": 0.01647063698839313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132962.0, \"tn\": 1278705527.0, \"fp\": 32265.0, \"fn\": 170999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4374311178078767, \"tn_rate\": 0.9999747680875611, \"fp_rate\": 2.5231912438855957e-05, \"fn_rate\": 0.5625688821921233, \"precision\": 0.8047231989929007, \"recall\": 0.4374311178078767, \"specificity\": 0.9999747680875611, \"npv\": 0.9998662896718147, \"accuracy\": 0.9998410810284158, \"f1\": 0.5667749388304901, \"f2\": 0.48137278966830815, \"f0_5\": 0.6890158145820832, \"p4\": 0.7234716735552906, \"phi\": 0.5932387192956534}, {\"truth_threshold\": -5.879999868571758, \"match_probability\": 0.016696719572260398, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132957.0, \"tn\": 1278705542.0, \"fp\": 32250.0, \"fn\": 171004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43741466832916065, \"tn_rate\": 0.9999747798178784, \"fp_rate\": 2.52201821215901e-05, \"fn_rate\": 0.5625853316708394, \"precision\": 0.804790353919628, \"recall\": 0.43741466832916065, \"specificity\": 0.9999747798178784, \"npv\": 0.9998662857642242, \"accuracy\": 0.9998410888467689, \"f1\": 0.566777785356205, \"f2\": 0.48136165862086194, \"f0_5\": 0.689047035154837, \"p4\": 0.7234739936075056, \"phi\": 0.5932523270743832}, {\"truth_threshold\": -5.859999869018793, \"match_probability\": 0.016925852050921814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132957.0, \"tn\": 1278705561.0, \"fp\": 32231.0, \"fn\": 171004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43741466832916065, \"tn_rate\": 0.9999747946762803, \"fp_rate\": 2.5205323719720016e-05, \"fn_rate\": 0.5625853316708394, \"precision\": 0.8048829212775747, \"recall\": 0.43741466832916065, \"specificity\": 0.9999747946762803, \"npv\": 0.9998662857662107, \"accuracy\": 0.9998411037016397, \"f1\": 0.5668007392107838, \"f2\": 0.4813682811115166, \"f0_5\": 0.6891013182158839, \"p4\": 0.7234926954605155, \"phi\": 0.593286459918761}, {\"truth_threshold\": -5.839999869465828, \"match_probability\": 0.017158074092676785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132957.0, \"tn\": 1278705570.0, \"fp\": 32222.0, \"fn\": 171004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43741466832916065, \"tn_rate\": 0.9999748017144706, \"fp_rate\": 2.5198285529360502e-05, \"fn_rate\": 0.5625853316708394, \"precision\": 0.8049267764062018, \"recall\": 0.43741466832916065, \"specificity\": 0.9999748017144706, \"npv\": 0.9998662857671518, \"accuracy\": 0.9998411107381574, \"f1\": 0.5668116127382018, \"f2\": 0.48137141814437556, \"f0_5\": 0.6891270342301102, \"p4\": 0.7235015545704716, \"phi\": 0.5933026301633882}, {\"truth_threshold\": -5.819999869912863, \"match_probability\": 0.017393425841019813, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132957.0, \"tn\": 1278705834.0, \"fp\": 31958.0, \"fn\": 171004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43741466832916065, \"tn_rate\": 0.9999750081680545, \"fp_rate\": 2.499183194548144e-05, \"fn_rate\": 0.5625853316708394, \"precision\": 0.8062153230452052, \"recall\": 0.43741466832916065, \"specificity\": 0.9999750081680545, \"npv\": 0.9998662857947546, \"accuracy\": 0.9998413171426781, \"f1\": 0.567130755252988, \"f2\": 0.4814634559687824, \"f0_5\": 0.6898822254807647, \"p4\": 0.7237615183528076, \"phi\": 0.5937775459891227}, {\"truth_threshold\": -5.799999870359898, \"match_probability\": 0.017631947919195687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132954.0, \"tn\": 1278705862.0, \"fp\": 31930.0, \"fn\": 171007.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43740479864193105, \"tn_rate\": 0.9999750300646467, \"fp_rate\": 2.496993535325184e-05, \"fn_rate\": 0.562595201358069, \"precision\": 0.8063487057567744, \"recall\": 0.43740479864193105, \"specificity\": 0.9999750300646467, \"npv\": 0.9998662834521874, \"accuracy\": 0.9998413366885608, \"f1\": 0.5671554564941506, \"f2\": 0.48146340191551124, \"f0_5\": 0.6899554435561294, \"p4\": 0.7237816352873535, \"phi\": 0.5938199844067992}, {\"truth_threshold\": -5.7799998708069324, \"match_probability\": 0.01787368143476514, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132949.0, \"tn\": 1278705925.0, \"fp\": 31867.0, \"fn\": 171012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.437388349163215, \"tn_rate\": 0.9999750793319793, \"fp_rate\": 2.4920668020735247e-05, \"fn_rate\": 0.562611650836785, \"precision\": 0.8066510532957966, \"recall\": 0.437388349163215, \"specificity\": 0.9999750793319793, \"npv\": 0.999866279549617, \"accuracy\": 0.9998413820350085, \"f1\": 0.5672163950023146, \"f2\": 0.4814690075760868, \"f0_5\": 0.6901243219393184, \"p4\": 0.7238312611225998, \"phi\": 0.5939201847336643}, {\"truth_threshold\": -5.759999871253967, \"match_probability\": 0.01811866798417982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132947.0, \"tn\": 1278705934.0, \"fp\": 31858.0, \"fn\": 171014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373817693717286, \"tn_rate\": 0.9999750863701696, \"fp_rate\": 2.4913629830375733e-05, \"fn_rate\": 0.5626182306282714, \"precision\": 0.8066927581080671, \"recall\": 0.4373817693717286, \"specificity\": 0.9999750863701696, \"npv\": 0.9998662779868951, \"accuracy\": 0.9998413875078557, \"f1\": 0.5672211721839895, \"f2\": 0.48146560059797966, \"f0_5\": 0.690145465909315, \"p4\": 0.7238351515527954, \"phi\": 0.5939310768066518}, {\"truth_threshold\": -5.739999871701002, \"match_probability\": 0.018366949657365413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132947.0, \"tn\": 1278706876.0, \"fp\": 30916.0, \"fn\": 171014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373817693717286, \"tn_rate\": 0.9999758230340939, \"fp_rate\": 2.4176965906079987e-05, \"fn_rate\": 0.5626182306282714, \"precision\": 0.8113301965666441, \"recall\": 0.4373817693717286, \"specificity\": 0.9999758230340939, \"npv\": 0.9998662780853925, \"accuracy\": 0.9998421239967137, \"f1\": 0.5683633161188824, \"f2\": 0.481794322997564, \"f0_5\": 0.6928559442075519, \"p4\": 0.7247645332827267, \"phi\": 0.5956365814168113}, {\"truth_threshold\": -5.719999872148037, \"match_probability\": 0.018618569042311694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132947.0, \"tn\": 1278708662.0, \"fp\": 29130.0, \"fn\": 171014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373817693717286, \"tn_rate\": 0.9999772197238697, \"fp_rate\": 2.2780276130292082e-05, \"fn_rate\": 0.5626182306282714, \"precision\": 0.8202706121164631, \"recall\": 0.4373817693717286, \"specificity\": 0.9999772197238697, \"npv\": 0.9998662782721398, \"accuracy\": 0.9998435203545697, \"f1\": 0.5705414579926958, \"f2\": 0.48241880340019494, \"f0_5\": 0.6980538062249217, \"p4\": 0.7265331774403949, \"phi\": 0.598910879263657}, {\"truth_threshold\": -5.699999872595072, \"match_probability\": 0.01887356922966818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132942.0, \"tn\": 1278708669.0, \"fp\": 29123.0, \"fn\": 171019.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373653198930126, \"tn_rate\": 0.9999772251980178, \"fp_rate\": 2.2774801982234683e-05, \"fn_rate\": 0.5626346801069874, \"precision\": 0.8203004967142813, \"recall\": 0.4373653198930126, \"specificity\": 0.9999772251980178, \"npv\": 0.9998662743637227, \"accuracy\": 0.9998435219182403, \"f1\": 0.5705346911974868, \"f2\": 0.4824048612789379, \"f0_5\": 0.6980627396371221, \"p4\": 0.7265276911972767, \"phi\": 0.5989105300980662}, {\"truth_threshold\": -5.679999873042107, \"match_probability\": 0.01913199381734419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132941.0, \"tn\": 1278708696.0, \"fp\": 29096.0, \"fn\": 171020.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43736202999726936, \"tn_rate\": 0.9999772463125889, \"fp_rate\": 2.2753687411156142e-05, \"fn_rate\": 0.5626379700027306, \"precision\": 0.820436073242531, \"recall\": 0.43736202999726936, \"specificity\": 0.9999772463125889, \"npv\": 0.999866273584716, \"accuracy\": 0.9998435422459583, \"f1\": 0.5705646805351096, \"f2\": 0.48241103549580844, \"f0_5\": 0.6981396037638548, \"p4\": 0.7265520085754209, \"phi\": 0.5989577904299322}, {\"truth_threshold\": -5.6599998734891415, \"match_probability\": 0.0193938869151118, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132940.0, \"tn\": 1278708696.0, \"fp\": 29096.0, \"fn\": 171021.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373587401015262, \"tn_rate\": 0.9999772463125889, \"fp_rate\": 2.2753687411156142e-05, \"fn_rate\": 0.5626412598984738, \"precision\": 0.8204349650694908, \"recall\": 0.4373587401015262, \"specificity\": 0.9999772463125889, \"npv\": 0.9998662728028863, \"accuracy\": 0.9998435414641229, \"f1\": 0.5705616130575948, \"f2\": 0.48240775684384707, \"f0_5\": 0.6981372852784095, \"p4\": 0.72654952147163, \"phi\": 0.5989551327283502}, {\"truth_threshold\": -5.619999874383211, \"match_probability\": 0.019928257666951374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132938.0, \"tn\": 1278708724.0, \"fp\": 29068.0, \"fn\": 171023.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43735216031003976, \"tn_rate\": 0.9999772682091811, \"fp_rate\": 2.2731790818926545e-05, \"fn_rate\": 0.5626478396899602, \"precision\": 0.82057454662173, \"recall\": 0.43735216031003976, \"specificity\": 0.9999772682091811, \"npv\": 0.9998662712421545, \"accuracy\": 0.9998435617918409, \"f1\": 0.570589762794361, \"f2\": 0.4824110026490547, \"f0_5\": 0.6982147827959474, \"p4\": 0.7265723465865073, \"phi\": 0.5990015976692006}, {\"truth_threshold\": -5.599999874830246, \"match_probability\": 0.0202008261413212, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132938.0, \"tn\": 1278709135.0, \"fp\": 28657.0, \"fn\": 171023.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43735216031003976, \"tn_rate\": 0.9999775896198742, \"fp_rate\": 2.2410380125842093e-05, \"fn_rate\": 0.5626478396899602, \"precision\": 0.8226615922522356, \"recall\": 0.43735216031003976, \"specificity\": 0.9999775896198742, \"npv\": 0.9998662712851316, \"accuracy\": 0.9998438831261516, \"f1\": 0.5710934882162404, \"f2\": 0.48255494435688256, \"f0_5\": 0.6994226282986844, \"p4\": 0.7269806467548775, \"phi\": 0.5997632073336803}, {\"truth_threshold\": -5.579999875277281, \"match_probability\": 0.020477044775581793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132936.0, \"tn\": 1278709157.0, \"fp\": 28635.0, \"fn\": 171025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373455805185534, \"tn_rate\": 0.9999776068243394, \"fp_rate\": 2.2393175660518836e-05, \"fn_rate\": 0.5626544194814467, \"precision\": 0.8227714131867724, \"recall\": 0.4373455805185534, \"specificity\": 0.9999776068243394, \"npv\": 0.9998662697237731, \"accuracy\": 0.9998438987628576, \"f1\": 0.5711143380046914, \"f2\": 0.48255609239045605, \"f0_5\": 0.699482764971139, \"p4\": 0.726997541448219, \"phi\": 0.5997987441790886}, {\"truth_threshold\": -5.559999875724316, \"match_probability\": 0.02075696030786607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132936.0, \"tn\": 1278709169.0, \"fp\": 28623.0, \"fn\": 171025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373455805185534, \"tn_rate\": 0.9999776162085933, \"fp_rate\": 2.2383791406706152e-05, \"fn_rate\": 0.5626544194814467, \"precision\": 0.8228325255788906, \"recall\": 0.4373455805185534, \"specificity\": 0.9999776162085933, \"npv\": 0.9998662697250279, \"accuracy\": 0.9998439081448813, \"f1\": 0.5711290599759409, \"f2\": 0.4825602964419273, \"f0_5\": 0.6995180999308565, \"p4\": 0.727009470249741, \"phi\": 0.5998210292294545}, {\"truth_threshold\": -5.5399998761713505, \"match_probability\": 0.02104062001576727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132933.0, \"tn\": 1278709181.0, \"fp\": 28611.0, \"fn\": 171028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373357108313238, \"tn_rate\": 0.9999776255928471, \"fp_rate\": 2.2374407152893468e-05, \"fn_rate\": 0.5626642891686763, \"precision\": 0.822890358044867, \"recall\": 0.4373357108313238, \"specificity\": 0.9999776255928471, \"npv\": 0.9998662673807942, \"accuracy\": 0.999843915181399, \"f1\": 0.5711345742795458, \"f2\": 0.4825546614316373, \"f0_5\": 0.6995464864540587, \"p4\": 0.7270139387438664, \"phi\": 0.5998353481831391}, {\"truth_threshold\": -5.519999876618385, \"match_probability\": 0.021328071720920265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132933.0, \"tn\": 1278709220.0, \"fp\": 28572.0, \"fn\": 171028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373357108313238, \"tn_rate\": 0.999977656091672, \"fp_rate\": 2.2343908328002243e-05, \"fn_rate\": 0.5626642891686763, \"precision\": 0.8230890684498932, \"recall\": 0.4373357108313238, \"specificity\": 0.999977656091672, \"npv\": 0.9998662673848725, \"accuracy\": 0.999843945672976, \"f1\": 0.5711824279324376, \"f2\": 0.48256832509407566, \"f0_5\": 0.6996613616482856, \"p4\": 0.7270527114040684, \"phi\": 0.5999078002002859}, {\"truth_threshold\": -5.49999987706542, \"match_probability\": 0.021619363793573064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132933.0, \"tn\": 1278709271.0, \"fp\": 28521.0, \"fn\": 171028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373357108313238, \"tn_rate\": 0.9999776959747507, \"fp_rate\": 2.2304025249298334e-05, \"fn_rate\": 0.5626642891686763, \"precision\": 0.8233490653684641, \"recall\": 0.4373357108313238, \"specificity\": 0.9999776959747507, \"npv\": 0.9998662673902056, \"accuracy\": 0.9998439855465766, \"f1\": 0.5712450178872619, \"f2\": 0.4825861941279229, \"f0_5\": 0.6998116399954937, \"p4\": 0.7271034203541036, \"phi\": 0.6000025847475077}, {\"truth_threshold\": -5.479999877512455, \"match_probability\": 0.021914545157146633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132933.0, \"tn\": 1278709272.0, \"fp\": 28520.0, \"fn\": 171028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4373357108313238, \"tn_rate\": 0.9999776967567718, \"fp_rate\": 2.2303243228147275e-05, \"fn_rate\": 0.5626642891686763, \"precision\": 0.8233541649891919, \"recall\": 0.4373357108313238, \"specificity\": 0.9999776967567718, \"npv\": 0.9998662673903101, \"accuracy\": 0.9998439863284119, \"f1\": 0.5712462452783973, \"f2\": 0.482586544514364, \"f0_5\": 0.6998145872750646, \"p4\": 0.7271044147179492, \"phi\": 0.6000044437168991}, {\"truth_threshold\": -5.45999987795949, \"match_probability\": 0.022213665292781185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132925.0, \"tn\": 1278709297.0, \"fp\": 28495.0, \"fn\": 171036.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43730939166537813, \"tn_rate\": 0.9999777163073006, \"fp_rate\": 2.228369269937085e-05, \"fn_rate\": 0.5626906083346219, \"precision\": 0.8234729277660761, \"recall\": 0.43730939166537813, \"specificity\": 0.9999777163073006, \"npv\": 0.999866261138289, \"accuracy\": 0.9998439996196121, \"f1\": 0.5712523717126398, \"f2\": 0.48256906446403885, \"f0_5\": 0.69986974024921, \"p4\": 0.7271093792316506, \"phi\": 0.6000296765965505}, {\"truth_threshold\": -5.439999878406525, \"match_probability\": 0.022516774243866916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132922.0, \"tn\": 1278709315.0, \"fp\": 28477.0, \"fn\": 171039.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43729952197814853, \"tn_rate\": 0.9999777303836813, \"fp_rate\": 2.226961631865182e-05, \"fn_rate\": 0.5627004780218515, \"precision\": 0.8235614842718976, \"recall\": 0.43729952197814853, \"specificity\": 0.9999777303836813, \"npv\": 0.9998662587946832, \"accuracy\": 0.9998440113471417, \"f1\": 0.5712652570053292, \"f2\": 0.48256553128242435, \"f0_5\": 0.6999158554989326, \"p4\": 0.7271198184675793, \"phi\": 0.6000551816347037}, {\"truth_threshold\": -5.4199998788535595, \"match_probability\": 0.022823922620557144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132921.0, \"tn\": 1278709320.0, \"fp\": 28472.0, \"fn\": 171040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372962320824053, \"tn_rate\": 0.9999777342937871, \"fp_rate\": 2.2265706212896536e-05, \"fn_rate\": 0.5627037679175947, \"precision\": 0.8235859052127416, \"recall\": 0.4372962320824053, \"specificity\": 0.9999777342937871, \"npv\": 0.9998662580133766, \"accuracy\": 0.9998440144744829, \"f1\": 0.5712683247592155, \"f2\": 0.48256400314542813, \"f0_5\": 0.6999282805336939, \"p4\": 0.7271223038789435, \"phi\": 0.6000618247605329}, {\"truth_threshold\": -5.399999879300594, \"match_probability\": 0.023135161604261833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132920.0, \"tn\": 1278709341.0, \"fp\": 28451.0, \"fn\": 171041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372929421866621, \"tn_rate\": 0.9999777507162313, \"fp_rate\": 2.224928376872434e-05, \"fn_rate\": 0.5627070578133379, \"precision\": 0.8236919892669686, \"recall\": 0.4372929421866621, \"specificity\": 0.9999777507162313, \"npv\": 0.9998662572337433, \"accuracy\": 0.999844030111189, \"f1\": 0.571291035217866, \"f2\": 0.48256808123640826, \"f0_5\": 0.699987887660686, \"p4\": 0.7271407019838181, \"phi\": 0.6000982295368469}, {\"truth_threshold\": -5.379999879747629, \"match_probability\": 0.02345054295211926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132920.0, \"tn\": 1278709385.0, \"fp\": 28407.0, \"fn\": 171041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372929421866621, \"tn_rate\": 0.9999777851251619, \"fp_rate\": 2.221487483807783e-05, \"fn_rate\": 0.5627070578133379, \"precision\": 0.8239166413557557, \"recall\": 0.4372929421866621, \"specificity\": 0.9999777851251619, \"npv\": 0.9998662572383448, \"accuracy\": 0.9998440645119425, \"f1\": 0.571345059404068, \"f2\": 0.4825834990716476, \"f0_5\": 0.7001176694909451, \"p4\": 0.7271844653328349, \"phi\": 0.6001800956507013}, {\"truth_threshold\": -5.359999880194664, \"match_probability\": 0.023770119001443636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132920.0, \"tn\": 1278709415.0, \"fp\": 28377.0, \"fn\": 171041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372929421866621, \"tn_rate\": 0.9999778085857964, \"fp_rate\": 2.2191414203546118e-05, \"fn_rate\": 0.5627070578133379, \"precision\": 0.8240698835068229, \"recall\": 0.4372929421866621, \"specificity\": 0.9999778085857964, \"npv\": 0.9998662572414821, \"accuracy\": 0.9998440879670016, \"f1\": 0.5713818999350898, \"f2\": 0.48259401179690387, \"f0_5\": 0.7002061846980822, \"p4\": 0.7272143070003168, \"phi\": 0.6002359326577952}, {\"truth_threshold\": -5.339999880641699, \"match_probability\": 0.024093942674146367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132920.0, \"tn\": 1278709422.0, \"fp\": 28370.0, \"fn\": 171041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372929421866621, \"tn_rate\": 0.9999778140599445, \"fp_rate\": 2.2185940055488718e-05, \"fn_rate\": 0.5627070578133379, \"precision\": 0.8241056482112964, \"recall\": 0.4372929421866621, \"specificity\": 0.9999778140599445, \"npv\": 0.9998662572422142, \"accuracy\": 0.9998440934398488, \"f1\": 0.5713904967426185, \"f2\": 0.4825964648320352, \"f0_5\": 0.7002268414669994, \"p4\": 0.7272212704084845, \"phi\": 0.6002489635339774}, {\"truth_threshold\": -5.319999881088734, \"match_probability\": 0.024422067481128608, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132920.0, \"tn\": 1278709453.0, \"fp\": 28339.0, \"fn\": 171041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372929421866621, \"tn_rate\": 0.9999778383026002, \"fp_rate\": 2.2161697399805948e-05, \"fn_rate\": 0.5627070578133379, \"precision\": 0.8242640720827985, \"recall\": 0.4372929421866621, \"specificity\": 0.9999778383026002, \"npv\": 0.9998662572454561, \"accuracy\": 0.9998441176767433, \"f1\": 0.5714285714285714, \"f2\": 0.48260732857309874, \"f0_5\": 0.7003183360958991, \"p4\": 0.7272521099619984, \"phi\": 0.600306681897044}, {\"truth_threshold\": -5.2999998815357685, \"match_probability\": 0.024754547526642672, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132920.0, \"tn\": 1278709487.0, \"fp\": 28305.0, \"fn\": 171041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372929421866621, \"tn_rate\": 0.9999778648913193, \"fp_rate\": 2.2135108680670007e-05, \"fn_rate\": 0.5627070578133379, \"precision\": 0.8244378973484261, \"recall\": 0.4372929421866621, \"specificity\": 0.9999778648913193, \"npv\": 0.9998662572490118, \"accuracy\": 0.9998441442591437, \"f1\": 0.5714703365965442, \"f2\": 0.4826192442063542, \"f0_5\": 0.7004187125406145, \"p4\": 0.7272859369961616, \"phi\": 0.6003700050456843}, {\"truth_threshold\": -5.279999881982803, \"match_probability\": 0.02509143751261976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132918.0, \"tn\": 1278709554.0, \"fp\": 28238.0, \"fn\": 171043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372863623951757, \"tn_rate\": 0.9999779172867365, \"fp_rate\": 2.2082713263549186e-05, \"fn_rate\": 0.5627136376048243, \"precision\": 0.8247784755144084, \"recall\": 0.4372863623951757, \"specificity\": 0.9999779172867365, \"npv\": 0.99986625569236, \"accuracy\": 0.9998441950784386, \"f1\": 0.5715465141029031, \"f2\": 0.48263616557734207, \"f0_5\": 0.7006119641360553, \"p4\": 0.7273476314374184, \"phi\": 0.6004895372815514}, {\"truth_threshold\": -5.259999882429838, \"match_probability\": 0.025432792742961483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132917.0, \"tn\": 1278709571.0, \"fp\": 28221.0, \"fn\": 171044.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372830724994325, \"tn_rate\": 0.999977930581096, \"fp_rate\": 2.2069418903981217e-05, \"fn_rate\": 0.5627169275005675, \"precision\": 0.8248644019411933, \"recall\": 0.4372830724994325, \"specificity\": 0.999977930581096, \"npv\": 0.9998662549123086, \"accuracy\": 0.9998442075878035, \"f1\": 0.5715643336149938, \"f2\": 0.48263884349976977, \"f0_5\": 0.7006598749832633, \"p4\": 0.7273620622771254, \"phi\": 0.6005185711424964}, {\"truth_threshold\": -5.239999882876873, \"match_probability\": 0.02577866912779244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132912.0, \"tn\": 1278709721.0, \"fp\": 28071.0, \"fn\": 171049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43726662302071645, \"tn_rate\": 0.9999780478842687, \"fp_rate\": 2.1952115731322657e-05, \"fn_rate\": 0.5627333769792835, \"precision\": 0.8256275507351708, \"recall\": 0.43726662302071645, \"specificity\": 0.9999780478842687, \"npv\": 0.9998662510188498, \"accuracy\": 0.9998443209539227, \"f1\": 0.5717333700402629, \"f2\": 0.4826750201731953, \"f0_5\": 0.701091789896117, \"p4\": 0.7274989366865438, \"phi\": 0.6007851243847852}, {\"truth_threshold\": -5.219999883323908, \"match_probability\": 0.02612912318767124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132912.0, \"tn\": 1278709775.0, \"fp\": 28017.0, \"fn\": 171049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43726662302071645, \"tn_rate\": 0.9999780901134109, \"fp_rate\": 2.1909886589165578e-05, \"fn_rate\": 0.5627333769792835, \"precision\": 0.8259045914658016, \"recall\": 0.43726662302071645, \"specificity\": 0.9999780901134109, \"npv\": 0.9998662510244973, \"accuracy\": 0.9998443631730293, \"f1\": 0.5717997805932586, \"f2\": 0.4826939517262468, \"f0_5\": 0.7012515867748188, \"p4\": 0.7275527031588996, \"phi\": 0.6008859585139242}, {\"truth_threshold\": -5.199999883770943, \"match_probability\": 0.02648421205775701, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132908.0, \"tn\": 1278709814.0, \"fp\": 27978.0, \"fn\": 171053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372534634377437, \"tn_rate\": 0.9999781206122357, \"fp_rate\": 2.1879387764274352e-05, \"fn_rate\": 0.5627465365622564, \"precision\": 0.8261004686548239, \"recall\": 0.4372534634377437, \"specificity\": 0.9999781206122357, \"npv\": 0.9998662479012598, \"accuracy\": 0.9998443905372649, \"f1\": 0.571835464141965, \"f2\": 0.48269450073725423, \"f0_5\": 0.7013577764761136, \"p4\": 0.727581591566412, \"phi\": 0.6009481973118621}, {\"truth_threshold\": -5.1799998842179775, \"match_probability\": 0.026843993491928626, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132908.0, \"tn\": 1278709835.0, \"fp\": 27957.0, \"fn\": 171053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4372534634377437, \"tn_rate\": 0.9999781370346799, \"fp_rate\": 2.186296532010215e-05, \"fn_rate\": 0.5627465365622564, \"precision\": 0.8262083113169427, \"recall\": 0.4372534634377437, \"specificity\": 0.9999781370346799, \"npv\": 0.999866247903456, \"accuracy\": 0.9998444069558063, \"f1\": 0.571861298636479, \"f2\": 0.48270186364729223, \"f0_5\": 0.7014199600811044, \"p4\": 0.7276025051864634, \"phi\": 0.6009874388350281}, {\"truth_threshold\": -5.159999884665012, \"match_probability\": 0.02720852586685368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132881.0, \"tn\": 1278720060.0, \"fp\": 17732.0, \"fn\": 171080.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43716463625267715, \"tn_rate\": 0.9999861332009494, \"fp_rate\": 1.3866799050543741e-05, \"fn_rate\": 0.5628353637473228, \"precision\": 0.8822677989283794, \"recall\": 0.43716463625267715, \"specificity\": 0.9999861332009494, \"npv\": 0.9998662278636163, \"accuracy\": 0.9998523801122542, \"f1\": 0.5846396846278054, \"f2\": 0.48622459396819656, \"f0_5\": 0.7330047119800798, \"p4\": 0.7378633339460923, \"phi\": 0.6209875752165633}, {\"truth_threshold\": -5.139999885112047, \"match_probability\": 0.027577868186004006, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132879.0, \"tn\": 1278720132.0, \"fp\": 17660.0, \"fn\": 171082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43715805646119077, \"tn_rate\": 0.9999861895064723, \"fp_rate\": 1.3810493527667633e-05, \"fn_rate\": 0.5628419435388092, \"precision\": 0.8826882070426932, \"recall\": 0.43715805646119077, \"specificity\": 0.9999861895064723, \"npv\": 0.999866226307502, \"accuracy\": 0.9998524348407256, \"f1\": 0.5847260726072607, \"f2\": 0.4862436081245156, \"f0_5\": 0.7332331255235252, \"p4\": 0.7379321392582944, \"phi\": 0.621130897872815}, {\"truth_threshold\": -5.119999885559082, \"match_probability\": 0.027952080083614855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132877.0, \"tn\": 1278720144.0, \"fp\": 17648.0, \"fn\": 171084.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43715147666970433, \"tn_rate\": 0.9999861988907262, \"fp_rate\": 1.3801109273854948e-05, \"fn_rate\": 0.5628485233302957, \"precision\": 0.8827570171067929, \"recall\": 0.43715147666970433, \"specificity\": 0.9999861988907262, \"npv\": 0.9998662247451118, \"accuracy\": 0.9998524426590787, \"f1\": 0.5847352833750654, \"f2\": 0.48624127157451613, \"f0_5\": 0.7332674069405923, \"p4\": 0.7379394751733052, \"phi\": 0.621150442597245}, {\"truth_threshold\": -5.099999886006117, \"match_probability\": 0.028331221828584288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132874.0, \"tn\": 1278720148.0, \"fp\": 17644.0, \"fn\": 171087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43714160698247473, \"tn_rate\": 0.9999862020188107, \"fp_rate\": 1.379798118925072e-05, \"fn_rate\": 0.5628583930175253, \"precision\": 0.8827781394916223, \"recall\": 0.43714160698247473, \"specificity\": 0.9999862020188107, \"npv\": 0.9998662224000621, \"accuracy\": 0.999852443440914, \"f1\": 0.5847310876850196, \"f2\": 0.4862327845768544, \"f0_5\": 0.7332735121126934, \"p4\": 0.7379361341185725, \"phi\": 0.6211508641554399}, {\"truth_threshold\": -5.079999886453152, \"match_probability\": 0.02871535432830961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132872.0, \"tn\": 1278720170.0, \"fp\": 17622.0, \"fn\": 171089.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4371350271909883, \"tn_rate\": 0.999986219223276, \"fp_rate\": 1.3780776723927465e-05, \"fn_rate\": 0.5628649728090117, \"precision\": 0.8829056307892673, \"recall\": 0.4371350271909883, \"specificity\": 0.999986219223276, \"npv\": 0.9998662208387179, \"accuracy\": 0.9998524590776201, \"f1\": 0.5847531658800101, \"f2\": 0.4862340065196167, \"f0_5\": 0.7333401770763309, \"p4\": 0.7379537176178832, \"phi\": 0.6211910592426882}, {\"truth_threshold\": -5.0599998869001865, \"match_probability\": 0.029104539132457422, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132866.0, \"tn\": 1278720404.0, \"fp\": 17388.0, \"fn\": 171095.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4371152878165291, \"tn_rate\": 0.9999864022162254, \"fp_rate\": 1.3597783774580113e-05, \"fn_rate\": 0.5628847121834709, \"precision\": 0.8842759593754576, \"recall\": 0.4371152878165291, \"specificity\": 0.9999864022162254, \"npv\": 0.9998662161722602, \"accuracy\": 0.9998526373360698, \"f1\": 0.5850357209691446, \"f2\": 0.48629746914203814, \"f0_5\": 0.7340849546452561, \"p4\": 0.7381787037198466, \"phi\": 0.6216591020496232}, {\"truth_threshold\": -5.039999887347221, \"match_probability\": 0.029498838436663805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132860.0, \"tn\": 1278722816.0, \"fp\": 14976.0, \"fn\": 171101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370955484420699, \"tn_rate\": 0.9999882884512418, \"fp_rate\": 1.1711548758230492e-05, \"fn_rate\": 0.5629044515579301, \"precision\": 0.898698557861414, \"recall\": 0.4370955484420699, \"specificity\": 0.9999882884512418, \"npv\": 0.9998662117336508, \"accuracy\": 0.9998545184318154, \"f1\": 0.5881402488285669, \"f2\": 0.4871377449254957, \"f0_5\": 0.7419817827444278, \"p4\": 0.7406454212655715, \"phi\": 0.6266962080559969}, {\"truth_threshold\": -5.019999887794256, \"match_probability\": 0.029898315086161076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132854.0, \"tn\": 1278722933.0, \"fp\": 14859.0, \"fn\": 171107.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370758090676106, \"tn_rate\": 0.9999883799477164, \"fp_rate\": 1.1620052283556815e-05, \"fn_rate\": 0.5629241909323893, \"precision\": 0.8994062810991585, \"recall\": 0.4370758090676106, \"specificity\": 0.9999883799477164, \"npv\": 0.9998662070549644, \"accuracy\": 0.9998546052155344, \"f1\": 0.5882738435243118, \"f2\": 0.4871596860270601, \"f0_5\": 0.7423562241496268, \"p4\": 0.7407513540525028, \"phi\": 0.6269288641774895}, {\"truth_threshold\": -4.999999888241291, \"match_probability\": 0.03030303257932744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132846.0, \"tn\": 1278723014.0, \"fp\": 14778.0, \"fn\": 171115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43704948990166503, \"tn_rate\": 0.9999884432914297, \"fp_rate\": 1.1556708570321194e-05, \"fn_rate\": 0.562950510098335, \"precision\": 0.8998943261258332, \"recall\": 0.43704948990166503, \"specificity\": 0.9999884432914297, \"npv\": 0.9998662008088709, \"accuracy\": 0.9998546622895117, \"f1\": 0.5883543518938849, \"f2\": 0.4871621482865751, \"f0_5\": 0.7426069671320141, \"p4\": 0.7408151845391976, \"phi\": 0.6270801233178045}, {\"truth_threshold\": -4.979999888688326, \"match_probability\": 0.0307130550711558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132845.0, \"tn\": 1278723204.0, \"fp\": 14588.0, \"fn\": 171116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370462000059218, \"tn_rate\": 0.9999885918754484, \"fp_rate\": 1.1408124551620353e-05, \"fn_rate\": 0.5629537999940782, \"precision\": 0.9010533598312453, \"recall\": 0.4370462000059218, \"specificity\": 0.9999885918754484, \"npv\": 0.999866200046928, \"accuracy\": 0.9998548100563844, \"f1\": 0.5885988737112146, \"f2\": 0.48722673381858567, \"f0_5\": 0.7432362119877856, \"p4\": 0.7410090087591812, \"phi\": 0.6274816271041035}, {\"truth_threshold\": -4.959999889135361, \"match_probability\": 0.031128447376637926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132845.0, \"tn\": 1278723225.0, \"fp\": 14567.0, \"fn\": 171116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370462000059218, \"tn_rate\": 0.9999886082978926, \"fp_rate\": 1.1391702107448154e-05, \"fn_rate\": 0.5629537999940782, \"precision\": 0.9011817219765013, \"recall\": 0.4370462000059218, \"specificity\": 0.9999886082978926, \"npv\": 0.9998662000491251, \"accuracy\": 0.9998548264749259, \"f1\": 0.5886262581058238, \"f2\": 0.48723423920378856, \"f0_5\": 0.7433060768188324, \"p4\": 0.7410307117160949, \"phi\": 0.6275263387898709}, {\"truth_threshold\": -4.9399998895823956, \"match_probability\": 0.03154927497405991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132844.0, \"tn\": 1278723233.0, \"fp\": 14559.0, \"fn\": 171117.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370429101101786, \"tn_rate\": 0.9999886145540617, \"fp_rate\": 1.1385445938239697e-05, \"fn_rate\": 0.5629570898898214, \"precision\": 0.9012299613983433, \"recall\": 0.4370429101101786, \"specificity\": 0.9999886145540617, \"npv\": 0.9998661992681412, \"accuracy\": 0.999854831947773, \"f1\": 0.5886335640414389, \"f2\": 0.487233788154311, \"f0_5\": 0.7433304273965305, \"p4\": 0.7410365019136294, \"phi\": 0.6275407787269024}, {\"truth_threshold\": -4.91999989002943, \"match_probability\": 0.031975604008205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132843.0, \"tn\": 1278723253.0, \"fp\": 14539.0, \"fn\": 171118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43703962021443543, \"tn_rate\": 0.9999886301944848, \"fp_rate\": 1.1369805515218557e-05, \"fn_rate\": 0.5629603797855646, \"precision\": 0.9013515897463734, \"recall\": 0.43703962021443543, \"specificity\": 0.9999886301944848, \"npv\": 0.999866198488413, \"accuracy\": 0.9998548468026438, \"f1\": 0.5886565206505917, \"f2\": 0.4872376260429305, \"f0_5\": 0.7433947144284933, \"p4\": 0.7410546951236249, \"phi\": 0.6275807782506132}, {\"truth_threshold\": -4.899999890476465, \"match_probability\": 0.03240750129345963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132837.0, \"tn\": 1278723256.0, \"fp\": 14536.0, \"fn\": 171124.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43701988083997617, \"tn_rate\": 0.9999886325405483, \"fp_rate\": 1.1367459451765385e-05, \"fn_rate\": 0.5629801191600238, \"precision\": 0.9013659218445712, \"recall\": 0.43701988083997617, \"specificity\": 0.9999886325405483, \"npv\": 0.9998661937978022, \"accuracy\": 0.9998548444571379, \"f1\": 0.5886416711349023, \"f2\": 0.48721883603270794, \"f0_5\": 0.7433910905218294, \"p4\": 0.7410429278772281, \"phi\": 0.6275715951727407}, {\"truth_threshold\": -4.8799998909235, \"match_probability\": 0.03284503431681841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132836.0, \"tn\": 1278723275.0, \"fp\": 14517.0, \"fn\": 171125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43701659094423295, \"tn_rate\": 0.9999886473989501, \"fp_rate\": 1.1352601049895302e-05, \"fn_rate\": 0.562983409055767, \"precision\": 0.9014814764545004, \"recall\": 0.43701659094423295, \"specificity\": 0.9999886473989501, \"npv\": 0.9998661930179693, \"accuracy\": 0.9998548585301734, \"f1\": 0.5886633253123102, \"f2\": 0.4872223163636657, \"f0_5\": 0.7434520631360025, \"p4\": 0.7410600887519588, \"phi\": 0.6276094750144307}, {\"truth_threshold\": -4.859999891370535, \"match_probability\": 0.0332882712407837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132836.0, \"tn\": 1278723297.0, \"fp\": 14495.0, \"fn\": 171125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43701659094423295, \"tn_rate\": 0.9999886646034154, \"fp_rate\": 1.1335396584572047e-05, \"fn_rate\": 0.562983409055767, \"precision\": 0.901616088942585, \"recall\": 0.43701659094423295, \"specificity\": 0.9999886646034154, \"npv\": 0.999866193020271, \"accuracy\": 0.9998548757305501, \"f1\": 0.5886920220167874, \"f2\": 0.4872301795440791, \"f0_5\": 0.7435253026749582, \"p4\": 0.7410828298900204, \"phi\": 0.6276563510400059}, {\"truth_threshold\": -4.83999989181757, \"match_probability\": 0.033737280906155444, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132834.0, \"tn\": 1278723300.0, \"fp\": 14492.0, \"fn\": 171127.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43701001115274657, \"tn_rate\": 0.9999886669494789, \"fp_rate\": 1.1333050521118876e-05, \"fn_rate\": 0.5629899888472534, \"precision\": 0.9016331129603736, \"recall\": 0.43701001115274657, \"specificity\": 0.9999886669494789, \"npv\": 0.9998661914569434, \"accuracy\": 0.9998548765123855, \"f1\": 0.5886896808461134, \"f2\": 0.48722463082374173, \"f0_5\": 0.743530755151047, \"p4\": 0.7410809749247936, \"phi\": 0.6276575534002943}, {\"truth_threshold\": -4.819999892264605, \"match_probability\": 0.03419213283470654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132832.0, \"tn\": 1278723326.0, \"fp\": 14466.0, \"fn\": 171129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4370034313612602, \"tn_rate\": 0.9999886872820288, \"fp_rate\": 1.1312717971191392e-05, \"fn_rate\": 0.5629965686387398, \"precision\": 0.9017909272359435, \"recall\": 0.4370034313612602, \"specificity\": 0.9999886872820288, \"npv\": 0.9998661898960224, \"accuracy\": 0.9998548952764328, \"f1\": 0.5887173441416127, \"f2\": 0.4872273028048435, \"f0_5\": 0.7436127964637638, \"p4\": 0.7411028967093918, \"phi\": 0.6277077774771457}, {\"truth_threshold\": -4.799999892711639, \"match_probability\": 0.034652897231739366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132827.0, \"tn\": 1278723347.0, \"fp\": 14445.0, \"fn\": 171134.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43698698188254415, \"tn_rate\": 0.999988703704473, \"fp_rate\": 1.1296295527019194e-05, \"fn_rate\": 0.5630130181174559, \"precision\": 0.9019161823021348, \"recall\": 0.43698698188254415, \"specificity\": 0.999988703704473, \"npv\": 0.999866185989116, \"accuracy\": 0.9998549077857977, \"f1\": 0.588729104475958, \"f2\": 0.48721825581975414, \"f0_5\": 0.7436713998895917, \"p4\": 0.7411122165804291, \"phi\": 0.6277395707093454}, {\"truth_threshold\": -4.779999893158674, \"match_probability\": 0.0351196449885184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132825.0, \"tn\": 1278723349.0, \"fp\": 14443.0, \"fn\": 171136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369804020910577, \"tn_rate\": 0.9999887052685152, \"fp_rate\": 1.129473148471708e-05, \"fn_rate\": 0.5630195979089423, \"precision\": 0.9019270988945324, \"recall\": 0.4369804020910577, \"specificity\": 0.9999887052685152, \"npv\": 0.9998661844256839, \"accuracy\": 0.9998549077857977, \"f1\": 0.5887254586917064, \"f2\": 0.48721234938875163, \"f0_5\": 0.7436735260623067, \"p4\": 0.7411093279040303, \"phi\": 0.6277386446884511}, {\"truth_threshold\": -4.759999893605709, \"match_probability\": 0.035592447684574355, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132825.0, \"tn\": 1278723380.0, \"fp\": 14412.0, \"fn\": 171136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369804020910577, \"tn_rate\": 0.999988729511171, \"fp_rate\": 1.127048882903431e-05, \"fn_rate\": 0.5630195979089423, \"precision\": 0.9021169950487988, \"recall\": 0.4369804020910577, \"specificity\": 0.999988729511171, \"npv\": 0.9998661844289275, \"accuracy\": 0.9998549320226922, \"f1\": 0.5887659076502999, \"f2\": 0.4872234298622019, \"f0_5\": 0.7437768014433722, \"p4\": 0.7411413795498286, \"phi\": 0.6278047520178541}, {\"truth_threshold\": -4.739999894052744, \"match_probability\": 0.0360713775898747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132825.0, \"tn\": 1278723389.0, \"fp\": 14403.0, \"fn\": 171136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369804020910577, \"tn_rate\": 0.9999887365493614, \"fp_rate\": 1.1263450638674797e-05, \"fn_rate\": 0.5630195979089423, \"precision\": 0.9021721411687994, \"recall\": 0.4369804020910577, \"specificity\": 0.9999887365493614, \"npv\": 0.9998661844298692, \"accuracy\": 0.9998549390592099, \"f1\": 0.5887776519374364, \"f2\": 0.4872266468682505, \"f0_5\": 0.7438067899914097, \"p4\": 0.7411506853856322, \"phi\": 0.6278239483784416}, {\"truth_threshold\": -4.719999894499779, \"match_probability\": 0.03655650766685558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132819.0, \"tn\": 1278723419.0, \"fp\": 14373.0, \"fn\": 171142.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369606627165985, \"tn_rate\": 0.9999887600099958, \"fp_rate\": 1.1239990004143086e-05, \"fn_rate\": 0.5630393372834015, \"precision\": 0.9023520300016306, \"recall\": 0.4369606627165985, \"specificity\": 0.9999887600099958, \"npv\": 0.9998661797420844, \"accuracy\": 0.9998549578232573, \"f1\": 0.5887980352563321, \"f2\": 0.4872175056271441, \"f0_5\": 0.7438931635468322, \"p4\": 0.7411668371157851, \"phi\": 0.6278723802819627}, {\"truth_threshold\": -4.699999894946814, \"match_probability\": 0.037047911572309855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132818.0, \"tn\": 1278723424.0, \"fp\": 14368.0, \"fn\": 171143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369573728208553, \"tn_rate\": 0.9999887639201016, \"fp_rate\": 1.1236079898387801e-05, \"fn_rate\": 0.5630426271791447, \"precision\": 0.9023820200290789, \"recall\": 0.4369573728208553, \"specificity\": 0.9999887639201016, \"npv\": 0.9998661789607869, \"accuracy\": 0.9998549609505984, \"f1\": 0.5888014327924158, \"f2\": 0.4872159820400138, \"f0_5\": 0.743907561848539, \"p4\": 0.741169529281111, \"phi\": 0.6278804543303669}, {\"truth_threshold\": -4.679999895393848, \"match_probability\": 0.03754566365912619, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132814.0, \"tn\": 1278723465.0, \"fp\": 14327.0, \"fn\": 171147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369442132378825, \"tn_rate\": 0.9999887959829689, \"fp_rate\": 1.1204017031194461e-05, \"fn_rate\": 0.5630557867621175, \"precision\": 0.9026308099034259, \"recall\": 0.4369442132378825, \"specificity\": 0.9999887959829689, \"npv\": 0.9998661758377945, \"accuracy\": 0.9998549898785047, \"f1\": 0.5888424347486821, \"f2\": 0.48721739417528437, \"f0_5\": 0.7440351810873645, \"p4\": 0.7412020166028009, \"phi\": 0.6279575812048607}, {\"truth_threshold\": -4.659999895840883, \"match_probability\": 0.03804983897787343, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132814.0, \"tn\": 1278723473.0, \"fp\": 14319.0, \"fn\": 171147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369442132378825, \"tn_rate\": 0.999988802239138, \"fp_rate\": 1.1197760861986005e-05, \"fn_rate\": 0.5630557867621175, \"precision\": 0.9026798882643594, \"recall\": 0.4369442132378825, \"specificity\": 0.999988802239138, \"npv\": 0.9998661758386317, \"accuracy\": 0.9998549961331872, \"f1\": 0.5888528776707294, \"f2\": 0.4872202539001025, \"f0_5\": 0.7440618581882434, \"p4\": 0.7412102904840496, \"phi\": 0.6279746598354397}, {\"truth_threshold\": -4.639999896287918, \"match_probability\": 0.03856051327822519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132811.0, \"tn\": 1278723474.0, \"fp\": 14318.0, \"fn\": 171150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43693434355065286, \"tn_rate\": 0.9999888030211591, \"fp_rate\": 1.1196978840834947e-05, \"fn_rate\": 0.5630656564493471, \"precision\": 0.902684039176505, \"recall\": 0.43693434355065286, \"specificity\": 0.9999888030211591, \"npv\": 0.9998661734932744, \"accuracy\": 0.9998549945695167, \"f1\": 0.5888447981555787, \"f2\": 0.48721067842136273, \"f0_5\": 0.7440583903002542, \"p4\": 0.7412038895793142, \"phi\": 0.6279690110656243}, {\"truth_threshold\": -4.619999896734953, \"match_probability\": 0.03907776301021867, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132811.0, \"tn\": 1278723481.0, \"fp\": 14311.0, \"fn\": 171150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43693434355065286, \"tn_rate\": 0.9999888084953072, \"fp_rate\": 1.1191504692777548e-05, \"fn_rate\": 0.5630656564493471, \"precision\": 0.9027269884857465, \"recall\": 0.43693434355065286, \"specificity\": 0.9999888084953072, \"npv\": 0.999866173494007, \"accuracy\": 0.9998550000423637, \"f1\": 0.5888539359718722, \"f2\": 0.4872131806662822, \"f0_5\": 0.7440817346425398, \"p4\": 0.7412111294154113, \"phi\": 0.6279839562817857}, {\"truth_threshold\": -4.599999897181988, \"match_probability\": 0.039601665325342136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132811.0, \"tn\": 1278723660.0, \"fp\": 14132.0, \"fn\": 171150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43693434355065286, \"tn_rate\": 0.9999889484770933, \"fp_rate\": 1.1051522906738334e-05, \"fn_rate\": 0.5630656564493471, \"precision\": 0.9038266538725901, \"recall\": 0.43693434355065286, \"specificity\": 0.9999889484770933, \"npv\": 0.9998661735127379, \"accuracy\": 0.9998551399908835, \"f1\": 0.589087699377251, \"f2\": 0.4872771753766363, \"f0_5\": 0.74467918087589, \"p4\": 0.7413963104286304, \"phi\": 0.6283664894972195}, {\"truth_threshold\": -4.579999897629023, \"match_probability\": 0.040132298077445214, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132811.0, \"tn\": 1278723678.0, \"fp\": 14114.0, \"fn\": 171150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43693434355065286, \"tn_rate\": 0.999988962553474, \"fp_rate\": 1.1037446526019308e-05, \"fn_rate\": 0.5630656564493471, \"precision\": 0.9039373830185469, \"recall\": 0.43693434355065286, \"specificity\": 0.999988962553474, \"npv\": 0.9998661735146215, \"accuracy\": 0.999855154063919, \"f1\": 0.5891112165824621, \"f2\": 0.4872836115291733, \"f0_5\": 0.7447393123619851, \"p4\": 0.7414149371033221, \"phi\": 0.6284049951974762}, {\"truth_threshold\": -4.559999898076057, \"match_probability\": 0.04066973982346596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132809.0, \"tn\": 1278723688.0, \"fp\": 14104.0, \"fn\": 171152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369277637591665, \"tn_rate\": 0.9999889703736855, \"fp_rate\": 1.1029626314508737e-05, \"fn_rate\": 0.5630722362408336, \"precision\": 0.9039976040241503, \"recall\": 0.4369277637591665, \"specificity\": 0.9999889703736855, \"npv\": 0.999866171952027, \"accuracy\": 0.9998551603186014, \"f1\": 0.5891180241042953, \"f2\": 0.48728056432658207, \"f0_5\": 0.7447681897863759, \"p4\": 0.7414203291610468, \"phi\": 0.6284212035732873}, {\"truth_threshold\": -4.539999898523092, \"match_probability\": 0.0412140698239687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132809.0, \"tn\": 1278723710.0, \"fp\": 14082.0, \"fn\": 171152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369277637591665, \"tn_rate\": 0.9999889875781508, \"fp_rate\": 1.1012421849185482e-05, \"fn_rate\": 0.5630722362408336, \"precision\": 0.9041329965756921, \"recall\": 0.4369277637591665, \"specificity\": 0.9999889875781508, \"npv\": 0.9998661719543291, \"accuracy\": 0.9998551775189781, \"f1\": 0.5891467710024576, \"f2\": 0.4872884309862152, \"f0_5\": 0.7448417038221026, \"p4\": 0.741443097041855, \"phi\": 0.628468280763455}, {\"truth_threshold\": -4.519999898970127, \"match_probability\": 0.041765368043486434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132809.0, \"tn\": 1278723712.0, \"fp\": 14080.0, \"fn\": 171152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4369277637591665, \"tn_rate\": 0.9999889891421931, \"fp_rate\": 1.1010857806883368e-05, \"fn_rate\": 0.5630722362408336, \"precision\": 0.9041453070005242, \"recall\": 0.4369277637591665, \"specificity\": 0.9999889891421931, \"npv\": 0.9998661719545384, \"accuracy\": 0.9998551790826488, \"f1\": 0.5891493844959521, \"f2\": 0.48728914614968594, \"f0_5\": 0.744848387635906, \"p4\": 0.7414451669185402, \"phi\": 0.6284725610323825}, {\"truth_threshold\": -4.499999899417162, \"match_probability\": 0.042323715150661426, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132807.0, \"tn\": 1278723759.0, \"fp\": 14033.0, \"fn\": 171154.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43692118396768004, \"tn_rate\": 0.9999890258971872, \"fp_rate\": 1.0974102812783686e-05, \"fn_rate\": 0.5630788160323199, \"precision\": 0.9044333968945791, \"recall\": 0.43692118396768004, \"specificity\": 0.9999890258971872, \"npv\": 0.9998661703958158, \"accuracy\": 0.9998552142652375, \"f1\": 0.5892045492356938, \"f2\": 0.4872993298519686, \"f0_5\": 0.7450009592503711, \"p4\": 0.7414888558895315, \"phi\": 0.6285679865579817}, {\"truth_threshold\": -4.459999900311232, \"match_probability\": 0.0434618822224787, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132801.0, \"tn\": 1278723769.0, \"fp\": 14023.0, \"fn\": 171160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43690144459322083, \"tn_rate\": 0.9999890337173988, \"fp_rate\": 1.0966282601273115e-05, \"fn_rate\": 0.5630985554067791, \"precision\": 0.9044910913747072, \"recall\": 0.43690144459322083, \"specificity\": 0.9999890337173988, \"npv\": 0.9998661657059397, \"accuracy\": 0.9998552173925788, \"f1\": 0.5891988420200317, \"f2\": 0.48728303592657934, \"f0_5\": 0.7450207964706027, \"p4\": 0.7414843370014353, \"phi\": 0.6285738418114802}, {\"truth_threshold\": -4.4399999007582664, \"match_probability\": 0.04404186704326371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132800.0, \"tn\": 1278723808.0, \"fp\": 13984.0, \"fn\": 171161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368981546974776, \"tn_rate\": 0.9999890642162236, \"fp_rate\": 1.093578377638189e-05, \"fn_rate\": 0.5631018453025224, \"precision\": 0.9047307608458688, \"recall\": 0.4368981546974776, \"specificity\": 0.9999890642162236, \"npv\": 0.9998661649282006, \"accuracy\": 0.9998552471023203, \"f1\": 0.5892466915883704, \"f2\": 0.4872936707597378, \"f0_5\": 0.745148956847571, \"p4\": 0.7415222302617763, \"phi\": 0.6286547821653129}, {\"truth_threshold\": -4.419999901205301, \"match_probability\": 0.044629230462756006, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132799.0, \"tn\": 1278723818.0, \"fp\": 13974.0, \"fn\": 171162.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43689486480173445, \"tn_rate\": 0.9999890720364352, \"fp_rate\": 1.0927963564871319e-05, \"fn_rate\": 0.5631051351982655, \"precision\": 0.9047917532516199, \"recall\": 0.43689486480173445, \"specificity\": 0.9999890720364352, \"npv\": 0.9998661641474267, \"accuracy\": 0.9998552541388381, \"f1\": 0.5892566347335679, \"f2\": 0.48729393512630476, \"f0_5\": 0.7451801407997055, \"p4\": 0.741530104317602, \"phi\": 0.6286736136065478}, {\"truth_threshold\": -4.399999901652336, \"match_probability\": 0.04522405666473612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132797.0, \"tn\": 1278723820.0, \"fp\": 13972.0, \"fn\": 171164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.436888285010248, \"tn_rate\": 0.9999890736004774, \"fp_rate\": 1.0926399522569206e-05, \"fn_rate\": 0.563111714989752, \"precision\": 0.904802785329327, \"recall\": 0.436888285010248, \"specificity\": 0.9999890736004774, \"npv\": 0.9998661625839953, \"accuracy\": 0.9998552541388381, \"f1\": 0.5892529895946576, \"f2\": 0.48728802675447835, \"f0_5\": 0.745182298827097, \"p4\": 0.7415272180692978, \"phi\": 0.6286727132471364}, {\"truth_threshold\": -4.379999902099371, \"match_probability\": 0.04582643053333292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132792.0, \"tn\": 1278725812.0, \"fp\": 11980.0, \"fn\": 171169.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.436871835531532, \"tn_rate\": 0.9999906313866104, \"fp_rate\": 9.368613389663548e-06, \"fn_rate\": 0.563128164468468, \"precision\": 0.9172491918326748, \"recall\": 0.436871835531532, \"specificity\": 0.9999906313866104, \"npv\": 0.9998661588833636, \"accuracy\": 0.9998568076455906, \"f1\": 0.5918530618430113, \"f2\": 0.48798485391910723, \"f0_5\": 0.7518948552118851, \"p4\": 0.7435828314717622, \"phi\": 0.632971780225869}, {\"truth_threshold\": -4.359999902546406, \"match_probability\": 0.04643643765156575, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132789.0, \"tn\": 1278725822.0, \"fp\": 11970.0, \"fn\": 171172.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43686196584430237, \"tn_rate\": 0.9999906392068219, \"fp_rate\": 9.360793178152977e-06, \"fn_rate\": 0.5631380341556976, \"precision\": 0.9173108407767393, \"recall\": 0.43686196584430237, \"specificity\": 0.9999906392068219, \"npv\": 0.9998661565389526, \"accuracy\": 0.9998568131184378, \"f1\": 0.591856837225887, \"f2\": 0.4879784918892579, \"f0_5\": 0.7519221469608617, \"p4\": 0.7435858118486527, \"phi\": 0.6329859086664789}, {\"truth_threshold\": -4.339999902993441, \"match_probability\": 0.04705416429963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132788.0, \"tn\": 1278725823.0, \"fp\": 11969.0, \"fn\": 171173.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368586759485592, \"tn_rate\": 0.999990639988843, \"fp_rate\": 9.36001115700192e-06, \"fn_rate\": 0.5631413240514408, \"precision\": 0.9173166064508107, \"recall\": 0.4368586759485592, \"specificity\": 0.999990639988843, \"npv\": 0.9998661557572381, \"accuracy\": 0.9998568131184378, \"f1\": 0.5918550180737122, \"f2\": 0.48797553434107427, \"f0_5\": 0.7519232968927133, \"p4\": 0.7435843761331927, \"phi\": 0.6329855150476693}, {\"truth_threshold\": -4.3199999034404755, \"match_probability\": 0.04767969745291911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132785.0, \"tn\": 1278726013.0, \"fp\": 11779.0, \"fn\": 171176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368488062613296, \"tn_rate\": 0.9999907885728617, \"fp_rate\": 9.211427138301078e-06, \"fn_rate\": 0.5631511937386704, \"precision\": 0.9185205168645029, \"recall\": 0.4368488062613296, \"specificity\": 0.9999907885728617, \"npv\": 0.9998661534316657, \"accuracy\": 0.9998569593216399, \"f1\": 0.5920963157014659, \"f2\": 0.4880337369377422, \"f0_5\": 0.7525642784031593, \"p4\": 0.7437748051850924, \"phi\": 0.6333937645361694}, {\"truth_threshold\": -4.29999990388751, \"match_probability\": 0.04831312477977547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132785.0, \"tn\": 1278726204.0, \"fp\": 11588.0, \"fn\": 171176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368488062613296, \"tn_rate\": 0.9999909379389016, \"fp_rate\": 9.06206109844918e-06, \"fn_rate\": 0.5631511937386704, \"precision\": 0.919735684650177, \"recall\": 0.4368488062613296, \"specificity\": 0.9999909379389016, \"npv\": 0.9998661534516554, \"accuracy\": 0.9998571086521834, \"f1\": 0.5923485615634773, \"f2\": 0.4881022660354929, \"f0_5\": 0.7532165640141902, \"p4\": 0.743973812285327, \"phi\": 0.6338127733980019}, {\"truth_threshold\": -4.279999904334545, \"match_probability\": 0.04895453463896244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132784.0, \"tn\": 1278726252.0, \"fp\": 11540.0, \"fn\": 171177.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368455163655864, \"tn_rate\": 0.9999909754759168, \"fp_rate\": 9.024524083198441e-06, \"fn_rate\": 0.5631544836344137, \"precision\": 0.9200410188187689, \"recall\": 0.4368455163655864, \"specificity\": 0.9999909754759168, \"npv\": 0.99986615267486, \"accuracy\": 0.9998571453984427, \"f1\": 0.5924088470504255, \"f2\": 0.48811617388440254, \"f0_5\": 0.753378412880692, \"p4\": 0.7440213647926806, \"phi\": 0.6339156265743233}, {\"truth_threshold\": -4.25999990478158, \"match_probability\": 0.0496040160768501, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132782.0, \"tn\": 1278726284.0, \"fp\": 11508.0, \"fn\": 171179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43683893657409995, \"tn_rate\": 0.9999910005005936, \"fp_rate\": 8.999499406364617e-06, \"fn_rate\": 0.5631610634259, \"precision\": 0.9202439531499065, \"recall\": 0.43683893657409995, \"specificity\": 0.9999910005005936, \"npv\": 0.9998661511145714, \"accuracy\": 0.9998571688535018, \"f1\": 0.592444857903273, \"f2\": 0.4881210233697562, \"f0_5\": 0.7534833467821105, \"p4\": 0.7440497682358485, \"phi\": 0.6339807875224939}, {\"truth_threshold\": -4.239999905228615, \"match_probability\": 0.05026165882430686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132780.0, \"tn\": 1278726310.0, \"fp\": 11482.0, \"fn\": 171181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43683235678261356, \"tn_rate\": 0.9999910208331436, \"fp_rate\": 8.979166856437133e-06, \"fn_rate\": 0.5631676432173864, \"precision\": 0.920408700835979, \"recall\": 0.43683235678261356, \"specificity\": 0.9999910208331436, \"npv\": 0.9998661495536549, \"accuracy\": 0.9998571876175492, \"f1\": 0.5924729431555275, \"f2\": 0.48812371976890034, \"f0_5\": 0.753567784211058, \"p4\": 0.7440719195613479, \"phi\": 0.6340327818670226}, {\"truth_threshold\": -4.21999990567565, \"match_probability\": 0.05092755329328894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132779.0, \"tn\": 1278726346.0, \"fp\": 11446.0, \"fn\": 171182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43682906688687034, \"tn_rate\": 0.999991048985905, \"fp_rate\": 8.951014094999078e-06, \"fn_rate\": 0.5631709331131296, \"precision\": 0.9206378921823539, \"recall\": 0.43682906688687034, \"specificity\": 0.999991048985905, \"npv\": 0.9998661487756039, \"accuracy\": 0.9998572149817849, \"f1\": 0.5925173923326476, \"f2\": 0.48813332264760095, \"f0_5\": 0.753688720467815, \"p4\": 0.7441069754790718, \"phi\": 0.6341093610983938}, {\"truth_threshold\": -4.1999999061226845, \"match_probability\": 0.051601790573119886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132775.0, \"tn\": 1278726390.0, \"fp\": 11402.0, \"fn\": 171186.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368159073038975, \"tn_rate\": 0.9999910833948357, \"fp_rate\": 8.916605164352568e-06, \"fn_rate\": 0.5631840926961025, \"precision\": 0.9209166510608489, \"recall\": 0.4368159073038975, \"specificity\": 0.9999910833948357, \"npv\": 0.9998661456529339, \"accuracy\": 0.9998572462551971, \"f1\": 0.5925630051457363, \"f2\": 0.48813584496121754, \"f0_5\": 0.7538303267175295, \"p4\": 0.7441429475351482, \"phi\": 0.6341958392481858}, {\"truth_threshold\": -4.179999906569719, \"match_probability\": 0.05228446242645182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132773.0, \"tn\": 1278726453.0, \"fp\": 11339.0, \"fn\": 171188.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43680932751241114, \"tn_rate\": 0.9999911326621682, \"fp_rate\": 8.867337831835974e-06, \"fn_rate\": 0.5631906724875889, \"precision\": 0.9213181414455424, \"recall\": 0.43680932751241114, \"specificity\": 0.9999911326621682, \"npv\": 0.9998661440958901, \"accuracy\": 0.9998572939471507, \"f1\": 0.5926400385651445, \"f2\": 0.48815182255896516, \"f0_5\": 0.7540415874894509, \"p4\": 0.7442036937296013, \"phi\": 0.6343293464991895}, {\"truth_threshold\": -4.159999907016754, \"match_probability\": 0.05297566128490057, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132772.0, \"tn\": 1278726478.0, \"fp\": 11314.0, \"fn\": 171189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4368060376166679, \"tn_rate\": 0.999991152212697, \"fp_rate\": 8.847787303059547e-06, \"fn_rate\": 0.5631939623833321, \"precision\": 0.9214774509667837, \"recall\": 0.4368060376166679, \"specificity\": 0.999991152212697, \"npv\": 0.9998661433166881, \"accuracy\": 0.9998573127111982, \"f1\": 0.5926699654277341, \"f2\": 0.4881574786937563, \"f0_5\": 0.7541249907702444, \"p4\": 0.7442272915850698, \"phi\": 0.6343818194512725}, {\"truth_threshold\": -4.139999907463789, \"match_probability\": 0.053675480244345916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132765.0, \"tn\": 1278726546.0, \"fp\": 11246.0, \"fn\": 171196.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4367830083464655, \"tn_rate\": 0.9999912053901352, \"fp_rate\": 8.794609864787668e-06, \"fn_rate\": 0.5632169916535344, \"precision\": 0.9219087430821257, \"recall\": 0.4367830083464655, \"specificity\": 0.9999912053901352, \"npv\": 0.9998661378510746, \"accuracy\": 0.9998573604031518, \"f1\": 0.592737938978329, \"f2\": 0.48815866397520324, \"f0_5\": 0.7543423048732678, \"p4\": 0.7442808873303952, \"phi\": 0.634513592338058}, {\"truth_threshold\": -4.119999907910824, \"match_probability\": 0.05438401305988898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132758.0, \"tn\": 1278726590.0, \"fp\": 11202.0, \"fn\": 171203.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43675997907626307, \"tn_rate\": 0.9999912397990659, \"fp_rate\": 8.760200934141156e-06, \"fn_rate\": 0.5632400209237369, \"precision\": 0.9221867185329258, \"recall\": 0.43675997907626307, \"specificity\": 0.9999912397990659, \"npv\": 0.9998661323829495, \"accuracy\": 0.999857389331058, \"f1\": 0.5927741722312639, \"f2\": 0.48815123356013074, \"f0_5\": 0.7544774329649546, \"p4\": 0.7443094551220043, \"phi\": 0.6345925515675239}, {\"truth_threshold\": -4.099999908357859, \"match_probability\": 0.05510135414045803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132756.0, \"tn\": 1278726591.0, \"fp\": 11201.0, \"fn\": 171205.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4367533992847767, \"tn_rate\": 0.999991240581087, \"fp_rate\": 8.759418912990099e-06, \"fn_rate\": 0.5632466007152234, \"precision\": 0.9221920434574213, \"recall\": 0.4367533992847767, \"specificity\": 0.999991240581087, \"npv\": 0.9998661308194169, \"accuracy\": 0.9998573885492228, \"f1\": 0.59276921222188, \"f2\": 0.488144956504665, \"f0_5\": 0.7544763573993309, \"p4\": 0.7443055449630765, \"phi\": 0.6345896038069908}, {\"truth_threshold\": -4.0799999088048935, \"match_probability\": 0.05582759854305424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132755.0, \"tn\": 1278726617.0, \"fp\": 11175.0, \"fn\": 171206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43675010938903347, \"tn_rate\": 0.999991260913637, \"fp_rate\": 8.739086363062617e-06, \"fn_rate\": 0.5632498906109665, \"precision\": 0.9223580907385535, \"recall\": 0.43675010938903347, \"specificity\": 0.999991260913637, \"npv\": 0.9998661300403199, \"accuracy\": 0.9998574080951054, \"f1\": 0.5928004804740439, \"f2\": 0.48815097214684205, \"f0_5\": 0.7545633019242203, \"p4\": 0.7443301965017062, \"phi\": 0.6346443649078416}, {\"truth_threshold\": -4.059999909251928, \"match_probability\": 0.05656284196662854, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132755.0, \"tn\": 1278726632.0, \"fp\": 11160.0, \"fn\": 171206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43675010938903347, \"tn_rate\": 0.9999912726439542, \"fp_rate\": 8.727356045796761e-06, \"fn_rate\": 0.5632498906109665, \"precision\": 0.9224542264531147, \"recall\": 0.43675010938903347, \"specificity\": 0.9999912726439542, \"npv\": 0.9998661300418901, \"accuracy\": 0.999857419822635, \"f1\": 0.5928203341996445, \"f2\": 0.488156357119166, \"f0_5\": 0.7546147715891276, \"p4\": 0.744345848359049, \"phi\": 0.6346774512874916}, {\"truth_threshold\": -4.039999909698963, \"match_probability\": 0.05730718074558111, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132753.0, \"tn\": 1278726670.0, \"fp\": 11122.0, \"fn\": 171208.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43674352959754703, \"tn_rate\": 0.999991302360758, \"fp_rate\": 8.697639242056591e-06, \"fn_rate\": 0.563256470402453, \"precision\": 0.9226967854039966, \"recall\": 0.43674352959754703, \"specificity\": 0.999991302360758, \"npv\": 0.9998661284822306, \"accuracy\": 0.999857447968706, \"f1\": 0.5928643521289043, \"f2\": 0.4881633631654776, \"f0_5\": 0.7547406877621634, \"p4\": 0.7443805491829519, \"phi\": 0.6347561414961383}, {\"truth_threshold\": -4.019999910145998, \"match_probability\": 0.0580607118428744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132753.0, \"tn\": 1278726689.0, \"fp\": 11103.0, \"fn\": 171208.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43674352959754703, \"tn_rate\": 0.9999913172191598, \"fp_rate\": 8.682780840186508e-06, \"fn_rate\": 0.563256470402453, \"precision\": 0.9228186519853186, \"recall\": 0.43674352959754703, \"specificity\": 0.9999913172191598, \"npv\": 0.9998661284842194, \"accuracy\": 0.9998574628235768, \"f1\": 0.5928895062045434, \"f2\": 0.48817018459954403, \"f0_5\": 0.7548059154977627, \"p4\": 0.7444003779612866, \"phi\": 0.634798075184913}, {\"truth_threshold\": -3.999999910593033, \"match_probability\": 0.05882353284275095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132749.0, \"tn\": 1278727000.0, \"fp\": 10792.0, \"fn\": 171212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43673037001457427, \"tn_rate\": 0.9999915604277378, \"fp_rate\": 8.439572262207763e-06, \"fn_rate\": 0.5632696299854257, \"precision\": 0.9248159062567489, \"recall\": 0.43673037001457427, \"specificity\": 0.9999915604277378, \"npv\": 0.9998661253895005, \"accuracy\": 0.9998577028470157, \"f1\": 0.5932889685409227, \"f2\": 0.48826859204713896, \"f0_5\": 0.7558661921708185, \"p4\": 0.744715187956294, \"phi\": 0.6354753511394987}, {\"truth_threshold\": -3.9799999110400677, \"match_probability\": 0.05959574194304676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132749.0, \"tn\": 1278727004.0, \"fp\": 10788.0, \"fn\": 171212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43673037001457427, \"tn_rate\": 0.9999915635558224, \"fp_rate\": 8.436444177603535e-06, \"fn_rate\": 0.5632696299854257, \"precision\": 0.9248416784522457, \"recall\": 0.43673037001457427, \"specificity\": 0.9999915635558224, \"npv\": 0.9998661253899193, \"accuracy\": 0.9998577059743569, \"f1\": 0.5932942717062423, \"f2\": 0.4882700287851603, \"f0_5\": 0.7558799647879705, \"p4\": 0.7447193662281174, \"phi\": 0.6354842091520334}, {\"truth_threshold\": -3.9599999114871025, \"match_probability\": 0.06037743794709161, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132737.0, \"tn\": 1278727062.0, \"fp\": 10730.0, \"fn\": 171224.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4366908912656558, \"tn_rate\": 0.9999916089130492, \"fp_rate\": 8.391086950842226e-06, \"fn_rate\": 0.5633091087343443, \"precision\": 0.925209281576948, \"recall\": 0.4366908912656558, \"specificity\": 0.9999916089130492, \"npv\": 0.9998661160141706, \"accuracy\": 0.999857741938781, \"f1\": 0.593333452533145, \"f2\": 0.4882510330601312, \"f0_5\": 0.7560527164174343, \"p4\": 0.7447502370433982, \"phi\": 0.6355818102132087}, {\"truth_threshold\": -3.9399999119341373, \"match_probability\": 0.061168720255186666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132736.0, \"tn\": 1278727085.0, \"fp\": 10707.0, \"fn\": 171225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4366876013699126, \"tn_rate\": 0.9999916268995356, \"fp_rate\": 8.373100464367913e-06, \"fn_rate\": 0.5633123986300874, \"precision\": 0.925357110489881, \"recall\": 0.4366876013699126, \"specificity\": 0.9999916268995356, \"npv\": 0.9998661152347601, \"accuracy\": 0.9998577591391576, \"f1\": 0.5933608103637875, \"f2\": 0.48825597537532545, \"f0_5\": 0.7561297114270513, \"p4\": 0.7447717904497615, \"phi\": 0.6356302102531045}, {\"truth_threshold\": -3.919999912381172, \"match_probability\": 0.06196968885565049, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132702.0, \"tn\": 1278727141.0, \"fp\": 10651.0, \"fn\": 171259.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365757449146437, \"tn_rate\": 0.9999916706927201, \"fp_rate\": 8.329307279908718e-06, \"fn_rate\": 0.5634242550853563, \"precision\": 0.9257008922031629, \"recall\": 0.4365757449146437, \"specificity\": 0.9999916706927201, \"npv\": 0.999866088658802, \"accuracy\": 0.9998577763395344, \"f1\": 0.5933281766276038, \"f2\": 0.4881632316728186, \"f0_5\": 0.7562462031541887, \"p4\": 0.7447460856575208, \"phi\": 0.6356668819487281}, {\"truth_threshold\": -3.899999912828207, \"match_probability\": 0.06278044431542429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132697.0, \"tn\": 1278727175.0, \"fp\": 10617.0, \"fn\": 171264.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43655929543592764, \"tn_rate\": 0.9999916972814392, \"fp_rate\": 8.302718560772778e-06, \"fn_rate\": 0.5634407045640724, \"precision\": 0.925917914509399, \"recall\": 0.43655929543592764, \"specificity\": 0.9999916972814392, \"npv\": 0.999866084753271, \"accuracy\": 0.9998577990127583, \"f1\": 0.5933575540774692, \"f2\": 0.48815884540281557, \"f0_5\": 0.7563521910770084, \"p4\": 0.744769230894229, \"phi\": 0.6357294423887985}, {\"truth_threshold\": -3.879999913275242, \"match_probability\": 0.06360108777022676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132694.0, \"tn\": 1278727179.0, \"fp\": 10613.0, \"fn\": 171267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43654942574869804, \"tn_rate\": 0.9999917004095238, \"fp_rate\": 8.29959047616855e-06, \"fn_rate\": 0.563450574251302, \"precision\": 0.9259422079870487, \"recall\": 0.43654942574869804, \"specificity\": 0.9999917004095238, \"npv\": 0.9998660824082353, \"accuracy\": 0.9998577997945935, \"f1\": 0.593353425686613, \"f2\": 0.4881503232532662, \"f0_5\": 0.7563592338709217, \"p4\": 0.7447659789136193, \"phi\": 0.6357305983636271}, {\"truth_threshold\": -3.8599999137222767, \"match_probability\": 0.06443172091424951, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132688.0, \"tn\": 1278727207.0, \"fp\": 10585.0, \"fn\": 171273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365296863742388, \"tn_rate\": 0.9999917223061161, \"fp_rate\": 8.277693883938952e-06, \"fn_rate\": 0.5634703136257612, \"precision\": 0.926120064492263, \"recall\": 0.4365296863742388, \"specificity\": 0.9999917223061161, \"npv\": 0.9998660777202582, \"accuracy\": 0.9998578169949703, \"f1\": 0.593371702509201, \"f2\": 0.4881404617851149, \"f0_5\": 0.7564423130643187, \"p4\": 0.7447803785142217, \"phi\": 0.6357773000171499}, {\"truth_threshold\": -3.8399999141693115, \"match_probability\": 0.06527244598938357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132680.0, \"tn\": 1278727245.0, \"fp\": 10547.0, \"fn\": 171281.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4365033672082932, \"tn_rate\": 0.9999917520229198, \"fp_rate\": 8.247977080198784e-06, \"fn_rate\": 0.5634966327917068, \"precision\": 0.9263616496889553, \"recall\": 0.4365033672082932, \"specificity\": 0.9999917520229198, \"npv\": 0.9998660714696922, \"accuracy\": 0.9998578404500295, \"f1\": 0.5933969605624481, \"f2\": 0.48812755183504025, \"f0_5\": 0.7565554261811057, \"p4\": 0.7448002777689633, \"phi\": 0.6358410804457341}, {\"truth_threshold\": -3.8199999146163464, \"match_probability\": 0.06612336577396749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132674.0, \"tn\": 1278727278.0, \"fp\": 10514.0, \"fn\": 171287.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43648362783383393, \"tn_rate\": 0.9999917778296178, \"fp_rate\": 8.2221703822139e-06, \"fn_rate\": 0.563516372166166, \"precision\": 0.9265720591110987, \"recall\": 0.43648362783383393, \"specificity\": 0.9999917778296178, \"npv\": 0.9998660667822393, \"accuracy\": 0.9998578615595827, \"f1\": 0.5934218795077256, \"f2\": 0.48811948504523806, \"f0_5\": 0.7566558269353825, \"p4\": 0.7448199089619889, \"phi\": 0.6358989360121486}, {\"truth_threshold\": -3.799999915063381, \"match_probability\": 0.06698458357104768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132672.0, \"tn\": 1278727358.0, \"fp\": 10434.0, \"fn\": 171289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43647704804234755, \"tn_rate\": 0.9999918403913098, \"fp_rate\": 8.159608690129336e-06, \"fn_rate\": 0.5635229519576525, \"precision\": 0.9270890109429374, \"recall\": 0.43647704804234755, \"specificity\": 0.9999918403913098, \"npv\": 0.9998660652269812, \"accuracy\": 0.9998579225427365, \"f1\": 0.5935217763780373, \"f2\": 0.4881415798962434, \"f0_5\": 0.7569276060179031, \"p4\": 0.7448985984668351, \"phi\": 0.6360715775161004}, {\"truth_threshold\": -3.779999915510416, \"match_probability\": 0.06785620319614147, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132671.0, \"tn\": 1278727380.0, \"fp\": 10412.0, \"fn\": 171290.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43647375814660433, \"tn_rate\": 0.9999918575957752, \"fp_rate\": 8.14240422480608e-06, \"fn_rate\": 0.5635262418533956, \"precision\": 0.9272310477135649, \"recall\": 0.43647375814660433, \"specificity\": 0.9999918575957752, \"npv\": 0.9998660644474672, \"accuracy\": 0.999857938961278, \"f1\": 0.5935478386914934, \"f2\": 0.4881461623766398, \"f0_5\": 0.7570013682638113, \"p4\": 0.7449191263927838, \"phi\": 0.6361179229611023}, {\"truth_threshold\": -3.759999915957451, \"match_probability\": 0.06873832896449351, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132670.0, \"tn\": 1278727383.0, \"fp\": 10409.0, \"fn\": 171291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364704682508611, \"tn_rate\": 0.9999918599418387, \"fp_rate\": 8.14005816135291e-06, \"fn_rate\": 0.5635295317491389, \"precision\": 0.9272499807798489, \"recall\": 0.4364704682508611, \"specificity\": 0.9999918599418387, \"npv\": 0.9998660636659633, \"accuracy\": 0.9998579405249486, \"f1\": 0.5935486757337151, \"f2\": 0.48814391985417865, \"f0_5\": 0.757009484443846, \"p4\": 0.744919785820032, \"phi\": 0.6361220223067471}, {\"truth_threshold\": -3.7399999164044857, \"match_probability\": 0.06963106567781589, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132665.0, \"tn\": 1278727386.0, \"fp\": 10406.0, \"fn\": 171296.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364540187721451, \"tn_rate\": 0.9999918622879022, \"fp_rate\": 8.137712097899739e-06, \"fn_rate\": 0.5635459812278549, \"precision\": 0.9272668814784268, \"recall\": 0.4364540187721451, \"specificity\": 0.9999918622879022, \"npv\": 0.9998660597571872, \"accuracy\": 0.999857938961278, \"f1\": 0.593536928005154, \"f2\": 0.4881283965516607, \"f0_5\": 0.757008599193148, \"p4\": 0.744910533649463, \"phi\": 0.6361158333176203}, {\"truth_threshold\": -3.7199999168515205, \"match_probability\": 0.07053451861050251, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132663.0, \"tn\": 1278727391.0, \"fp\": 10401.0, \"fn\": 171298.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4364474389806587, \"tn_rate\": 0.9999918661980078, \"fp_rate\": 8.133801992144454e-06, \"fn_rate\": 0.5635525610193413, \"precision\": 0.9272982721019963, \"recall\": 0.4364474389806587, \"specificity\": 0.9999918661980078, \"npv\": 0.9998660581940748, \"accuracy\": 0.999857941306784, \"f1\": 0.5935372742016666, \"f2\": 0.48812355214628217, \"f0_5\": 0.7570213771246164, \"p4\": 0.7449108066248945, \"phi\": 0.6361218091693296}, {\"truth_threshold\": -3.6999999172985554, \"match_probability\": 0.07144879349530835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132659.0, \"tn\": 1278727441.0, \"fp\": 10351.0, \"fn\": 171302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43643427939768586, \"tn_rate\": 0.9999919052990655, \"fp_rate\": 8.0947009345916e-06, \"fn_rate\": 0.5635657206023141, \"precision\": 0.9276204461226487, \"recall\": 0.43643427939768586, \"specificity\": 0.9999919052990655, \"npv\": 0.9998660550720394, \"accuracy\": 0.999857977271208, \"f1\": 0.5935910830904019, \"f2\": 0.48812823158337837, \"f0_5\": 0.7571852086926841, \"p4\": 0.7449531878074083, \"phi\": 0.6362227558600342}, {\"truth_threshold\": -3.67999991774559, \"match_probability\": 0.07237399650848404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132652.0, \"tn\": 1278727460.0, \"fp\": 10332.0, \"fn\": 171309.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43641125012748344, \"tn_rate\": 0.9999919201574673, \"fp_rate\": 8.079842532721516e-06, \"fn_rate\": 0.5635887498725165, \"precision\": 0.927740166731942, \"recall\": 0.43641125012748344, \"specificity\": 0.9999919201574673, \"npv\": 0.9998660496013035, \"accuracy\": 0.9998579866532317, \"f1\": 0.5935942901251832, \"f2\": 0.48811181400442144, \"f0_5\": 0.7572351543617571, \"p4\": 0.744955714660021, \"phi\": 0.6362470381729539}, {\"truth_threshold\": -3.659999918192625, \"match_probability\": 0.07331023425435647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132649.0, \"tn\": 1278727461.0, \"fp\": 10331.0, \"fn\": 171312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43640138044025384, \"tn_rate\": 0.9999919209394884, \"fp_rate\": 8.07906051157046e-06, \"fn_rate\": 0.5635986195597461, \"precision\": 0.927745139180305, \"recall\": 0.43640138044025384, \"specificity\": 0.9999919209394884, \"npv\": 0.9998660472559543, \"accuracy\": 0.999857985089561, \"f1\": 0.593586178041397, \"f2\": 0.4881022119126539, \"f0_5\": 0.7572318614058302, \"p4\": 0.7449493261309428, \"phi\": 0.6362415485063033}, {\"truth_threshold\": -3.63999991863966, \"match_probability\": 0.0742576137493457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132644.0, \"tn\": 1278727467.0, \"fp\": 10325.0, \"fn\": 171317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43638493096153785, \"tn_rate\": 0.9999919256316153, \"fp_rate\": 8.074368384664117e-06, \"fn_rate\": 0.5636150690384621, \"precision\": 0.9277815470486609, \"recall\": 0.43638493096153785, \"specificity\": 0.9999919256316153, \"npv\": 0.999866043347493, \"accuracy\": 0.9998579858713963, \"f1\": 0.5935784127268252, \"f2\": 0.48808776483592664, \"f0_5\": 0.7572413588373179, \"p4\": 0.7449432109492298, \"phi\": 0.6362420447622795}, {\"truth_threshold\": -3.6199999190866947, \"match_probability\": 0.07521624240540926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132643.0, \"tn\": 1278727504.0, \"fp\": 10288.0, \"fn\": 171318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43638164106579463, \"tn_rate\": 0.9999919545663979, \"fp_rate\": 8.045433602075006e-06, \"fn_rate\": 0.5636183589342054, \"precision\": 0.928021213032862, \"recall\": 0.43638164106579463, \"specificity\": 0.9999919545663979, \"npv\": 0.9998660425695505, \"accuracy\": 0.9998580140174673, \"f1\": 0.5936244103720809, \"f2\": 0.4880977350922706, \"f0_5\": 0.7573670897640133, \"p4\": 0.7449794377549698, \"phi\": 0.6363218510066365}, {\"truth_threshold\": -3.5999999195337296, \"match_probability\": 0.07618622801290433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132642.0, \"tn\": 1278727519.0, \"fp\": 10273.0, \"fn\": 171319.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4363783511700514, \"tn_rate\": 0.9999919662967152, \"fp_rate\": 8.03370328480915e-06, \"fn_rate\": 0.5636216488299486, \"precision\": 0.9281181121645733, \"recall\": 0.4363783511700514, \"specificity\": 0.9999919662967152, \"npv\": 0.9998660417893037, \"accuracy\": 0.9998580249631617, \"f1\": 0.5936411890546819, \"f2\": 0.48809980283479265, \"f0_5\": 0.7574167362363396, \"p4\": 0.7449926518765295, \"phi\": 0.6363526851243595}, {\"truth_threshold\": -3.5799999199807644, \"match_probability\": 0.07716767872285835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132639.0, \"tn\": 1278727522.0, \"fp\": 10270.0, \"fn\": 171322.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4363684814828218, \"tn_rate\": 0.9999919686427786, \"fp_rate\": 8.031357221355979e-06, \"fn_rate\": 0.5636315185171782, \"precision\": 0.928136086600564, \"recall\": 0.4363684814828218, \"specificity\": 0.9999919686427786, \"npv\": 0.9998660394441642, \"accuracy\": 0.9998580249631617, \"f1\": 0.5936357329872223, \"f2\": 0.48809091865850524, \"f0_5\": 0.7574203657618744, \"p4\": 0.7449883554524326, \"phi\": 0.6363516523419985}, {\"truth_threshold\": -3.5599999204277992, \"match_probability\": 0.07816070302863944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132629.0, \"tn\": 1278727641.0, \"fp\": 10151.0, \"fn\": 171332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4363355825253898, \"tn_rate\": 0.9999920617032956, \"fp_rate\": 7.938296704380189e-06, \"fn_rate\": 0.5636644174746103, \"precision\": 0.9289046084885838, \"recall\": 0.4363355825253898, \"specificity\": 0.9999920617032956, \"npv\": 0.9998660316384507, \"accuracy\": 0.9998581101832099, \"f1\": 0.5937623813350464, \"f2\": 0.4881004604658831, \"f0_5\": 0.7578098484597425, \"p4\": 0.7450880899595053, \"phi\": 0.6365911603497154}, {\"truth_threshold\": -3.539999920874834, \"match_probability\": 0.07916540974701694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132625.0, \"tn\": 1278727656.0, \"fp\": 10136.0, \"fn\": 171336.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43632242294241697, \"tn_rate\": 0.9999920734336128, \"fp_rate\": 7.926566387114333e-06, \"fn_rate\": 0.563677577057583, \"precision\": 0.9290002171461393, \"recall\": 0.43632242294241697, \"specificity\": 0.9999920734336128, \"npv\": 0.9998660285127506, \"accuracy\": 0.9998581187833984, \"f1\": 0.5937697270338153, \"f2\": 0.4880925655359726, \"f0_5\": 0.7578528122696442, \"p4\": 0.7450938746571588, \"phi\": 0.6366143323672129}, {\"truth_threshold\": -3.519999921321869, \"match_probability\": 0.08018190799860368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132622.0, \"tn\": 1278727685.0, \"fp\": 10107.0, \"fn\": 171339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43631255325518736, \"tn_rate\": 0.9999920961122263, \"fp_rate\": 7.903887773733679e-06, \"fn_rate\": 0.5636874467448126, \"precision\": 0.92918748117061, \"recall\": 0.43631255325518736, \"specificity\": 0.9999920961122263, \"npv\": 0.999866026170335, \"accuracy\": 0.9998581391111162, \"f1\": 0.5937988314043297, \"f2\": 0.48809302113320374, \"f0_5\": 0.7579465456286998, \"p4\": 0.7451167917572072, \"phi\": 0.6366713161152754}, {\"truth_threshold\": -3.4999999217689037, \"match_probability\": 0.08121030718767058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132619.0, \"tn\": 1278727758.0, \"fp\": 10034.0, \"fn\": 171342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4363026835679577, \"tn_rate\": 0.9999921531997703, \"fp_rate\": 7.846800229706513e-06, \"fn_rate\": 0.5636973164320422, \"precision\": 0.929661486263871, \"recall\": 0.4363026835679577, \"specificity\": 0.9999921531997703, \"npv\": 0.9998660238325291, \"accuracy\": 0.9998581938395876, \"f1\": 0.5938864433268998, \"f2\": 0.48810928548241184, \"f0_5\": 0.7581928552562222, \"p4\": 0.7451857723974827, \"phi\": 0.6368265488252053}, {\"truth_threshold\": -3.4799999222159386, \"match_probability\": 0.08225071698132529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132604.0, \"tn\": 1278727775.0, \"fp\": 10017.0, \"fn\": 171357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4362533351318097, \"tn_rate\": 0.9999921664941298, \"fp_rate\": 7.833505870138543e-06, \"fn_rate\": 0.5637466648681904, \"precision\": 0.9297649013819844, \"recall\": 0.4362533351318097, \"specificity\": 0.9999921664941298, \"npv\": 0.999866012107044, \"accuracy\": 0.9998581954032583, \"f1\": 0.5938618215691631, \"f2\": 0.48806557401184425, \"f0_5\": 0.7582180697470967, \"p4\": 0.7451663897462131, \"phi\": 0.6368259606690054}, {\"truth_threshold\": -3.4599999226629734, \"match_probability\": 0.08330324728804604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132602.0, \"tn\": 1278727829.0, \"fp\": 9963.0, \"fn\": 171359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43624675534032326, \"tn_rate\": 0.999992208723272, \"fp_rate\": 7.791276727981462e-06, \"fn_rate\": 0.5637532446596767, \"precision\": 0.9301160873987304, \"recall\": 0.43624675534032326, \"specificity\": 0.999992208723272, \"npv\": 0.9998660105490661, \"accuracy\": 0.9998582360586942, \"f1\": 0.5939273412970353, \"f2\": 0.4880783328143438, \"f0_5\": 0.7584009077796118, \"p4\": 0.7452179728516466, \"phi\": 0.636941462778516}, {\"truth_threshold\": -3.4399999231100082, \"match_probability\": 0.0843680082355622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132583.0, \"tn\": 1278727914.0, \"fp\": 9878.0, \"fn\": 171378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43618424732120237, \"tn_rate\": 0.9999922751950698, \"fp_rate\": 7.724804930141613e-06, \"fn_rate\": 0.5638157526787976, \"precision\": 0.9306617249633233, \"recall\": 0.43618424732120237, \"specificity\": 0.9999922751950698, \"npv\": 0.9998659957034365, \"accuracy\": 0.9998582876598243, \"f1\": 0.5939805833941876, \"f2\": 0.4880457629177541, \"f0_5\": 0.7586532464337009, \"p4\": 0.7452598893436154, \"phi\": 0.637082683256593}, {\"truth_threshold\": -3.419999923557043, \"match_probability\": 0.08544511014807338, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132583.0, \"tn\": 1278727924.0, \"fp\": 9868.0, \"fn\": 171378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43618424732120237, \"tn_rate\": 0.9999922830152813, \"fp_rate\": 7.716984718631042e-06, \"fn_rate\": 0.5638157526787976, \"precision\": 0.9307270570231168, \"recall\": 0.43618424732120237, \"specificity\": 0.9999922830152813, \"npv\": 0.9998659957044843, \"accuracy\": 0.9998582954781774, \"f1\": 0.5939938890531616, \"f2\": 0.48804935599409555, \"f0_5\": 0.7586879767443191, \"p4\": 0.745270363493859, \"phi\": 0.6371050532635584}, {\"truth_threshold\": -3.399999924004078, \"match_probability\": 0.08653466352279893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132574.0, \"tn\": 1278727936.0, \"fp\": 9856.0, \"fn\": 171387.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43615463825951356, \"tn_rate\": 0.9999922923995351, \"fp_rate\": 7.707600464818358e-06, \"fn_rate\": 0.5638453617404865, \"precision\": 0.9308010952748719, \"recall\": 0.43615463825951356, \"specificity\": 0.9999922923995351, \"npv\": 0.9998659886693834, \"accuracy\": 0.9998582978236833, \"f1\": 0.5939815094838382, \"f2\": 0.48802377134510416, \"f0_5\": 0.7587094145345956, \"p4\": 0.7452606196989408, \"phi\": 0.637108775742176}, {\"truth_threshold\": -3.3799999244511127, \"match_probability\": 0.08763677900584982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132570.0, \"tn\": 1278727946.0, \"fp\": 9846.0, \"fn\": 171391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43614147867654074, \"tn_rate\": 0.9999923002197467, \"fp_rate\": 7.699780253307787e-06, \"fn_rate\": 0.5638585213234593, \"precision\": 0.9308645096056622, \"recall\": 0.43614147867654074, \"specificity\": 0.9999923002197467, \"npv\": 0.9998659855431609, \"accuracy\": 0.9998583025146952, \"f1\": 0.5939822168256877, \"f2\": 0.48801407683359593, \"f0_5\": 0.7587351552439547, \"p4\": 0.7452611771127133, \"phi\": 0.6371208739189675}, {\"truth_threshold\": -3.3599999248981476, \"match_probability\": 0.0887515673674152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132568.0, \"tn\": 1278727995.0, \"fp\": 9797.0, \"fn\": 171393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43613489888505436, \"tn_rate\": 0.9999923385387831, \"fp_rate\": 7.661461216905991e-06, \"fn_rate\": 0.5638651011149457, \"precision\": 0.9311839286341447, \"recall\": 0.43613489888505436, \"specificity\": 0.9999923385387831, \"npv\": 0.9998659839846604, \"accuracy\": 0.9998583392609546, \"f1\": 0.5940411268893141, \"f2\": 0.48802503885631743, \"f0_5\": 0.758900919487853, \"p4\": 0.7453075497043578, \"phi\": 0.6372254124673189}, {\"truth_threshold\": -3.3399999253451824, \"match_probability\": 0.08987913947625616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132568.0, \"tn\": 1278728058.0, \"fp\": 9734.0, \"fn\": 171393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43613489888505436, \"tn_rate\": 0.9999923878061157, \"fp_rate\": 7.612193884389396e-06, \"fn_rate\": 0.5638651011149457, \"precision\": 0.9315961827662296, \"recall\": 0.43613489888505436, \"specificity\": 0.9999923878061157, \"npv\": 0.9998659839912621, \"accuracy\": 0.9998583885165788, \"f1\": 0.5941249890759485, \"f2\": 0.48804767675934696, \"f0_5\": 0.7591199412713919, \"p4\": 0.7453735576755283, \"phi\": 0.6373665095087936}, {\"truth_threshold\": -3.3199999257922173, \"match_probability\": 0.09101960627349945, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132564.0, \"tn\": 1278728060.0, \"fp\": 9732.0, \"fn\": 171397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43612173930208153, \"tn_rate\": 0.9999923893701579, \"fp_rate\": 7.610629842087283e-06, \"fn_rate\": 0.5638782606979185, \"precision\": 0.9316073536852758, \"recall\": 0.43612173930208153, \"specificity\": 0.9999923893701579, \"npv\": 0.9998659808642018, \"accuracy\": 0.9998583869529082, \"f1\": 0.5941150502961298, \"f2\": 0.4880351068372922, \"f0_5\": 0.759117901379496, \"p4\": 0.7453657358132135, \"phi\": 0.6373607155123939}, {\"truth_threshold\": -3.299999926239252, \"match_probability\": 0.09217307874572404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132558.0, \"tn\": 1278728069.0, \"fp\": 9723.0, \"fn\": 171403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4361019999276223, \"tn_rate\": 0.9999923964083482, \"fp_rate\": 7.603591651727769e-06, \"fn_rate\": 0.5638980000723777, \"precision\": 0.9316633984860945, \"recall\": 0.4361019999276223, \"specificity\": 0.9999923964083482, \"npv\": 0.9998659761742399, \"accuracy\": 0.9998583892984141, \"f1\": 0.5941081296695515, \"f2\": 0.4880184077312471, \"f0_5\": 0.7591357084361775, \"p4\": 0.7453602896700656, \"phi\": 0.637365468402331}, {\"truth_threshold\": -3.279999926686287, \"match_probability\": 0.09333966789733368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132553.0, \"tn\": 1278728098.0, \"fp\": 9694.0, \"fn\": 171408.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360855504489063, \"tn_rate\": 0.9999924190869617, \"fp_rate\": 7.580913038347114e-06, \"fn_rate\": 0.5639144495510937, \"precision\": 0.9318509353448579, \"recall\": 0.4360855504489063, \"specificity\": 0.9999924190869617, \"npv\": 0.9998659722681916, \"accuracy\": 0.9998584080624614, \"f1\": 0.594130988238669, \"f2\": 0.4880122171489245, \"f0_5\": 0.7592253384791093, \"p4\": 0.7453782815801394, \"phi\": 0.6374176160525661}, {\"truth_threshold\": -3.2599999271333218, \"match_probability\": 0.09451948472220921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132547.0, \"tn\": 1278728134.0, \"fp\": 9658.0, \"fn\": 171414.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43606581107444703, \"tn_rate\": 0.9999924472397231, \"fp_rate\": 7.55276027690906e-06, \"fn_rate\": 0.5639341889255529, \"precision\": 0.9320839632924299, \"recall\": 0.43606581107444703, \"specificity\": 0.9999924472397231, \"npv\": 0.9998659675810597, \"accuracy\": 0.9998584315175206, \"f1\": 0.5941600211580443, \"f2\": 0.48800521925202994, \"f0_5\": 0.7593371074759877, \"p4\": 0.745401132506628, \"phi\": 0.6374829124711542}, {\"truth_threshold\": -3.2399999275803566, \"match_probability\": 0.09571264017463423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132545.0, \"tn\": 1278728150.0, \"fp\": 9642.0, \"fn\": 171416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43605923128296065, \"tn_rate\": 0.9999924597520615, \"fp_rate\": 7.540247938492147e-06, \"fn_rate\": 0.5639407687170394, \"precision\": 0.9321878934079768, \"recall\": 0.43605923128296065, \"specificity\": 0.9999924597520615, \"npv\": 0.9998659660191017, \"accuracy\": 0.9998584424632149, \"f1\": 0.5941750271210451, \"f2\": 0.48800432390718623, \"f0_5\": 0.7593882955257709, \"p4\": 0.7454129427533197, \"phi\": 0.6375136559626754}, {\"truth_threshold\": -3.2199999280273914, \"match_probability\": 0.09691924513948837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132536.0, \"tn\": 1278728186.0, \"fp\": 9606.0, \"fn\": 171425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360296222212718, \"tn_rate\": 0.999992487904823, \"fp_rate\": 7.5120951770540934e-06, \"fn_rate\": 0.5639703777787282, \"precision\": 0.9324196929830733, \"recall\": 0.4360296222212718, \"specificity\": 0.999992487904823, \"npv\": 0.9998659589865181, \"accuracy\": 0.9998584635727681, \"f1\": 0.594194614248279, \"f2\": 0.4879873577489017, \"f0_5\": 0.7594933807357692, \"p4\": 0.745428359159179, \"phi\": 0.6375712957874305}, {\"truth_threshold\": -3.1999999284744263, \"match_probability\": 0.09813941040170256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132533.0, \"tn\": 1278728217.0, \"fp\": 9575.0, \"fn\": 171428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4360197525340422, \"tn_rate\": 0.9999925121474786, \"fp_rate\": 7.487852521371324e-06, \"fn_rate\": 0.5639802474659578, \"precision\": 0.9326216680271343, \"recall\": 0.4360197525340422, \"specificity\": 0.9999925121474786, \"npv\": 0.9998659566443151, \"accuracy\": 0.9998584854641567, \"f1\": 0.5942264537549123, \"f2\": 0.48798852978603074, \"f0_5\": 0.7595945863848059, \"p4\": 0.745453416489348, \"phi\": 0.6376331555216453}, {\"truth_threshold\": -3.179999928921461, \"match_probability\": 0.09937324661497114, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132516.0, \"tn\": 1278728227.0, \"fp\": 9565.0, \"fn\": 171445.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43596382430640773, \"tn_rate\": 0.9999925199676901, \"fp_rate\": 7.480032309860754e-06, \"fn_rate\": 0.5640361756935923, \"precision\": 0.9326792463453946, \"recall\": 0.43596382430640773, \"specificity\": 0.9999925199676901, \"npv\": 0.9998659433544682, \"accuracy\": 0.9998584799913095, \"f1\": 0.5941861977123231, \"f2\": 0.48793563709335935, \"f0_5\": 0.7595911886596697, \"p4\": 0.7454217383599114, \"phi\": 0.6376119445022554}, {\"truth_threshold\": -3.159999929368496, \"match_probability\": 0.10062086426971596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132513.0, \"tn\": 1278728243.0, \"fp\": 9549.0, \"fn\": 171448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43595395461917813, \"tn_rate\": 0.9999925324800285, \"fp_rate\": 7.467519971443841e-06, \"fn_rate\": 0.5640460453808219, \"precision\": 0.9327828694513663, \"recall\": 0.43595395461917813, \"specificity\": 0.9999925324800285, \"npv\": 0.9998659410106934, \"accuracy\": 0.9998584901551685, \"f1\": 0.5941980570508696, \"f2\": 0.4879314179332001, \"f0_5\": 0.7596401779848637, \"p4\": 0.7454310720195237, \"phi\": 0.6376401591949716}, {\"truth_threshold\": -3.1399999298155308, \"match_probability\": 0.10188237366029808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132511.0, \"tn\": 1278728250.0, \"fp\": 9542.0, \"fn\": 171450.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4359473748276917, \"tn_rate\": 0.9999925379541766, \"fp_rate\": 7.462045823386442e-06, \"fn_rate\": 0.5640526251723083, \"precision\": 0.9328278881825798, \"recall\": 0.4359473748276917, \"specificity\": 0.9999925379541766, \"npv\": 0.9998659394477925, \"accuracy\": 0.999858494064345, \"f1\": 0.5942010788899004, \"f2\": 0.4879272875630479, \"f0_5\": 0.7596600674407485, \"p4\": 0.7454334504598017, \"phi\": 0.6376507397230645}, {\"truth_threshold\": -3.1199999302625656, \"match_probability\": 0.10315788485147312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132507.0, \"tn\": 1278728271.0, \"fp\": 9521.0, \"fn\": 171454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43593421524471887, \"tn_rate\": 0.9999925543766208, \"fp_rate\": 7.445623379214243e-06, \"fn_rate\": 0.5640657847552811, \"precision\": 0.9329639226068099, \"recall\": 0.43593421524471887, \"specificity\": 0.9999925543766208, \"npv\": 0.9998659363227246, \"accuracy\": 0.9998585073555453, \"f1\": 0.5942164492846236, \"f2\": 0.48792154194209764, \"f0_5\": 0.7597242432686254, \"p4\": 0.7454455471913752, \"phi\": 0.6376876249461659}, {\"truth_threshold\": -3.0999999307096004, \"match_probability\": 0.10444750764408649, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132506.0, \"tn\": 1278728271.0, \"fp\": 9521.0, \"fn\": 171455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4359309253489757, \"tn_rate\": 0.9999925543766208, \"fp_rate\": 7.445623379214243e-06, \"fn_rate\": 0.5640690746510243, \"precision\": 0.9329634506115034, \"recall\": 0.4359309253489757, \"specificity\": 0.9999925543766208, \"npv\": 0.9998659355409073, \"accuracy\": 0.99985850657371, \"f1\": 0.5942132972187593, \"f2\": 0.4879182190355343, \"f0_5\": 0.7597219944752078, \"p4\": 0.7454430667573575, \"phi\": 0.637685057063321}, {\"truth_threshold\": -3.0799999311566353, \"match_probability\": 0.10575135154000553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132502.0, \"tn\": 1278728274.0, \"fp\": 9518.0, \"fn\": 171459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4359177657660029, \"tn_rate\": 0.9999925567226843, \"fp_rate\": 7.443277315761072e-06, \"fn_rate\": 0.5640822342339972, \"precision\": 0.9329812702436276, \"recall\": 0.4359177657660029, \"specificity\": 0.9999925567226843, \"npv\": 0.9998659324139526, \"accuracy\": 0.9998585057918746, \"f1\": 0.5942046858498456, \"f2\": 0.48790600531422884, \"f0_5\": 0.7597234533697383, \"p4\": 0.7454362904088716, \"phi\": 0.6376815231313634}, {\"truth_threshold\": -3.05999993160367, \"match_probability\": 0.10706952570628571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132497.0, \"tn\": 1278728277.0, \"fp\": 9515.0, \"fn\": 171464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43590131628728684, \"tn_rate\": 0.9999925590687477, \"fp_rate\": 7.440931252307901e-06, \"fn_rate\": 0.5640986837127131, \"precision\": 0.9329986198349435, \"recall\": 0.43590131628728684, \"specificity\": 0.9999925590687477, \"npv\": 0.9998659285051806, \"accuracy\": 0.999858504228204, \"f1\": 0.5941929219930354, \"f2\": 0.48789046850328754, \"f0_5\": 0.7597226634128776, \"p4\": 0.7454270331576641, \"phi\": 0.6376754214788536}, {\"truth_threshold\": -3.039999932050705, \"match_probability\": 0.10840213893856886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132485.0, \"tn\": 1278728707.0, \"fp\": 9085.0, \"fn\": 171476.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43586183753836844, \"tn_rate\": 0.9999928953378426, \"fp_rate\": 7.104662157353366e-06, \"fn_rate\": 0.5641381624616316, \"precision\": 0.935826799463163, \"recall\": 0.43586183753836844, \"specificity\": 0.9999928953378426, \"npv\": 0.9998659191684548, \"accuracy\": 0.9998588310353619, \"f1\": 0.5947285374081713, \"f2\": 0.4880051332902121, \"f0_5\": 0.7611971856072054, \"p4\": 0.7458484184447327, \"phi\": 0.6386126368413011}, {\"truth_threshold\": -3.01999993249774, \"match_probability\": 0.10974929962371176, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132480.0, \"tn\": 1278728717.0, \"fp\": 9075.0, \"fn\": 171481.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4358453880596524, \"tn_rate\": 0.9999929031580541, \"fp_rate\": 7.096841945842796e-06, \"fn_rate\": 0.5641546119403477, \"precision\": 0.9358906432128854, \"recall\": 0.4358453880596524, \"specificity\": 0.9999929031580541, \"npv\": 0.9998659152604181, \"accuracy\": 0.9998588349445383, \"f1\": 0.5947261153359251, \"f2\": 0.48799210843679713, \"f0_5\": 0.7612209413903545, \"p4\": 0.7458465143116326, \"phi\": 0.6386223762449658}, {\"truth_threshold\": -2.9999999329447746, \"match_probability\": 0.11111111570164359, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132480.0, \"tn\": 1278728725.0, \"fp\": 9067.0, \"fn\": 171481.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4358453880596524, \"tn_rate\": 0.9999929094142234, \"fp_rate\": 7.090585776634339e-06, \"fn_rate\": 0.5641546119403477, \"precision\": 0.9359435381887289, \"recall\": 0.4358453880596524, \"specificity\": 0.9999929094142234, \"npv\": 0.9998659152612569, \"accuracy\": 0.9998588411992207, \"f1\": 0.5947367948499241, \"f2\": 0.48799498449599266, \"f0_5\": 0.7612489355271339, \"p4\": 0.745854913329281, \"phi\": 0.6386404300947442}, {\"truth_threshold\": -2.9799999333918095, \"match_probability\": 0.1124876946264522, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132469.0, \"tn\": 1278728738.0, \"fp\": 9054.0, \"fn\": 171492.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43580919920647715, \"tn_rate\": 0.9999929195804983, \"fp_rate\": 7.080419501670597e-06, \"fn_rate\": 0.5641908007935229, \"precision\": 0.9360245331147587, \"recall\": 0.43580919920647715, \"specificity\": 0.9999929195804983, \"npv\": 0.9998659066626331, \"accuracy\": 0.9998588427628914, \"f1\": 0.5947194512036347, \"f2\": 0.4879630932533353, \"f0_5\": 0.7612697157529483, \"p4\": 0.7458412748076466, \"phi\": 0.6386415556534523}, {\"truth_threshold\": -2.9599999338388443, \"match_probability\": 0.11387914332669864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132468.0, \"tn\": 1278728772.0, \"fp\": 9020.0, \"fn\": 171493.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43580590931073393, \"tn_rate\": 0.9999929461692174, \"fp_rate\": 7.0538307825346576e-06, \"fn_rate\": 0.5641940906892661, \"precision\": 0.936249010516793, \"recall\": 0.43580590931073393, \"specificity\": 0.9999929461692174, \"npv\": 0.9998659058843811, \"accuracy\": 0.9998588685634565, \"f1\": 0.5947616898904252, \"f2\": 0.48797199211394116, \"f0_5\": 0.7613864834759339, \"p4\": 0.7458744936416261, \"phi\": 0.6387157498961036}, {\"truth_threshold\": -2.939999934285879, \"match_probability\": 0.11528556816496083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132466.0, \"tn\": 1278728777.0, \"fp\": 9015.0, \"fn\": 171495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43579932951924755, \"tn_rate\": 0.9999929500793232, \"fp_rate\": 7.049920676779372e-06, \"fn_rate\": 0.5642006704807525, \"precision\": 0.9362811967684707, \"recall\": 0.43579932951924755, \"specificity\": 0.9999929500793232, \"npv\": 0.9998659043212714, \"accuracy\": 0.9998588709089624, \"f1\": 0.594762056564042, \"f2\": 0.4879671412520951, \"f0_5\": 0.7613994953355904, \"p4\": 0.7458747823015022, \"phi\": 0.6387219107119251}, {\"truth_threshold\": -2.919999934732914, \"match_probability\": 0.11670707489660731, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132443.0, \"tn\": 1278728811.0, \"fp\": 8981.0, \"fn\": 171518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43572366191715384, \"tn_rate\": 0.9999929766680423, \"fp_rate\": 7.023331957643432e-06, \"fn_rate\": 0.5642763380828462, \"precision\": 0.9364959271410793, \"recall\": 0.43572366191715384, \"specificity\": 0.9999929766680423, \"npv\": 0.9998658863430474, \"accuracy\": 0.9998588795091508, \"f1\": 0.5947348922842035, \"f2\": 0.4879029049531854, \"f0_5\": 0.7614668771711146, \"p4\": 0.7458534225299965, \"phi\": 0.6387397137103987}, {\"truth_threshold\": -2.899999935179949, \"match_probability\": 0.11814376862780324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132442.0, \"tn\": 1278728842.0, \"fp\": 8950.0, \"fn\": 171519.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4357203720214106, \"tn_rate\": 0.9999930009106981, \"fp_rate\": 6.999089301960664e-06, \"fn_rate\": 0.5642796279785893, \"precision\": 0.9367008034400814, \"recall\": 0.4357203720214106, \"specificity\": 0.9999930009106981, \"npv\": 0.9998658855644814, \"accuracy\": 0.99985890296421, \"f1\": 0.594773135018738, \"f2\": 0.4879107244429119, \"f0_5\": 0.7615732195245932, \"p4\": 0.7458834982333599, \"phi\": 0.6388071939498141}, {\"truth_threshold\": -2.8799999356269836, \"match_probability\": 0.11959575377275039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132420.0, \"tn\": 1278728857.0, \"fp\": 8935.0, \"fn\": 171541.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4356479943150602, \"tn_rate\": 0.9999930126410153, \"fp_rate\": 6.987358984694807e-06, \"fn_rate\": 0.5643520056849398, \"precision\": 0.9367903505358848, \"recall\": 0.4356479943150602, \"specificity\": 0.9999930126410153, \"npv\": 0.9998658683660837, \"accuracy\": 0.9998588974913628, \"f1\": 0.5947237467326573, \"f2\": 0.48784297660107323, \"f0_5\": 0.7615763399476179, \"p4\": 0.7458446603788321, \"phi\": 0.6387846729330031}, {\"truth_threshold\": -2.8599999360740185, \"match_probability\": 0.12106313401016536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132419.0, \"tn\": 1278728886.0, \"fp\": 8906.0, \"fn\": 171542.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43564470441931696, \"tn_rate\": 0.9999930353196287, \"fp_rate\": 6.964680371314153e-06, \"fn_rate\": 0.5643552955806831, \"precision\": 0.936982133380506, \"recall\": 0.43564470441931696, \"specificity\": 0.9999930353196287, \"npv\": 0.9998658675873083, \"accuracy\": 0.9998589193827514, \"f1\": 0.5947593232214802, \"f2\": 0.48785007615116466, \"f0_5\": 0.7616757222514297, \"p4\": 0.7458726396817348, \"phi\": 0.6388476701222038}, {\"truth_threshold\": -2.8399999365210533, \"match_probability\": 0.12254601223899865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132418.0, \"tn\": 1278728898.0, \"fp\": 8894.0, \"fn\": 171543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43564141452357374, \"tn_rate\": 0.9999930447038825, \"fp_rate\": 6.955296117501468e-06, \"fn_rate\": 0.5643585854764263, \"precision\": 0.9370612545289855, \"recall\": 0.43564141452357374, \"specificity\": 0.9999930447038825, \"npv\": 0.9998658668067502, \"accuracy\": 0.9998589279829397, \"f1\": 0.5947721959337305, \"f2\": 0.4878510650212651, \"f0_5\": 0.7617155367696377, \"p4\": 0.7458827632760596, \"phi\": 0.6388722406229829}, {\"truth_threshold\": -2.819999936968088, \"match_probability\": 0.1240444905334001, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132389.0, \"tn\": 1278728945.0, \"fp\": 8847.0, \"fn\": 171572.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43554600754702083, \"tn_rate\": 0.9999930814588766, \"fp_rate\": 6.918541123401787e-06, \"fn_rate\": 0.5644539924529791, \"precision\": 0.937360163131213, \"recall\": 0.43554600754702083, \"specificity\": 0.9999930814588766, \"npv\": 0.9998658441389934, \"accuracy\": 0.9998589420559753, \"f1\": 0.5947434506521831, \"f2\": 0.48777153889232766, \"f0_5\": 0.761815158158832, \"p4\": 0.7458601612903558, \"phi\": 0.6389041879649094}, {\"truth_threshold\": -2.799999937415123, \"match_probability\": 0.1255586700969354, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132388.0, \"tn\": 1278728959.0, \"fp\": 8833.0, \"fn\": 171573.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4355427176512776, \"tn_rate\": 0.9999930924071727, \"fp_rate\": 6.9075928272869875e-06, \"fn_rate\": 0.5644572823487224, \"precision\": 0.9374526451448439, \"recall\": 0.4355427176512776, \"specificity\": 0.9999930924071727, \"npv\": 0.9998658433586451, \"accuracy\": 0.9998589522198342, \"f1\": 0.594758997443742, \"f2\": 0.48777324593884597, \"f0_5\": 0.7618620122116143, \"p4\": 0.7458723880750635, \"phi\": 0.6389333041665064}, {\"truth_threshold\": -2.779999937862158, \"match_probability\": 0.1270886512160602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132384.0, \"tn\": 1278728983.0, \"fp\": 8809.0, \"fn\": 171577.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4355295580683048, \"tn_rate\": 0.9999931111756803, \"fp_rate\": 6.888824319661618e-06, \"fn_rate\": 0.5644704419316952, \"precision\": 0.9376102214699029, \"recall\": 0.4355295580683048, \"specificity\": 0.9999931111756803, \"npv\": 0.9998658402338959, \"accuracy\": 0.9998589678565404, \"f1\": 0.5947784362265643, \"f2\": 0.4877685722644261, \"f0_5\": 0.761937212008753, \"p4\": 0.7458876757912107, \"phi\": 0.638977367944732}, {\"truth_threshold\": -2.7599999383091927, \"match_probability\": 0.1286345332128581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132353.0, \"tn\": 1278729006.0, \"fp\": 8786.0, \"fn\": 171608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4354275713002655, \"tn_rate\": 0.9999931291621668, \"fp_rate\": 6.870837833187306e-06, \"fn_rate\": 0.5645724286997345, \"precision\": 0.9377493109629514, \"recall\": 0.4354275713002655, \"specificity\": 0.9999931291621668, \"npv\": 0.9998658159999914, \"accuracy\": 0.9998589616018578, \"f1\": 0.5947113008312739, \"f2\": 0.4876737586248317, \"f0_5\": 0.7619482405065185, \"p4\": 0.7458348819300407, \"phi\": 0.638949947450015}, {\"truth_threshold\": -2.7399999387562275, \"match_probability\": 0.13019641439705099, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132347.0, \"tn\": 1278729019.0, \"fp\": 8773.0, \"fn\": 171614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4354078319258063, \"tn_rate\": 0.9999931393284418, \"fp_rate\": 6.860671558223564e-06, \"fn_rate\": 0.5645921680741938, \"precision\": 0.9378330498866213, \"recall\": 0.4354078319258063, \"specificity\": 0.9999931393284418, \"npv\": 0.9998658113104554, \"accuracy\": 0.999858967074705, \"f1\": 0.5947097269935135, \"f2\": 0.48765847878057195, \"f0_5\": 0.7619803763295376, \"p4\": 0.7458336450257093, \"phi\": 0.6389640012623634}, {\"truth_threshold\": -2.7199999392032623, \"match_probability\": 0.13177439201728938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132333.0, \"tn\": 1278729102.0, \"fp\": 8690.0, \"fn\": 171628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43536177338540144, \"tn_rate\": 0.9999932042361973, \"fp_rate\": 6.795763802685828e-06, \"fn_rate\": 0.5646382266145986, \"precision\": 0.9383788460038434, \"recall\": 0.43536177338540144, \"specificity\": 0.9999932042361973, \"npv\": 0.9998658003737319, \"accuracy\": 0.9998590210213412, \"f1\": 0.5947764414001402, \"f2\": 0.4876417511812138, \"f0_5\": 0.762240324035514, \"p4\": 0.7458861145897756, \"phi\": 0.6391161686479963}, {\"truth_threshold\": -2.699999939650297, \"match_probability\": 0.13336856221173263, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132327.0, \"tn\": 1278729122.0, \"fp\": 8670.0, \"fn\": 171634.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4353420340109422, \"tn_rate\": 0.9999932198766204, \"fp_rate\": 6.780123379664687e-06, \"fn_rate\": 0.5646579659890578, \"precision\": 0.9385093299857443, \"recall\": 0.4353420340109422, \"specificity\": 0.9999932198766204, \"npv\": 0.9998657956849312, \"accuracy\": 0.9998590319670354, \"f1\": 0.5947842268259027, \"f2\": 0.4876289852679864, \"f0_5\": 0.7622970934928204, \"p4\": 0.7458922380347169, \"phi\": 0.6391461284992791}, {\"truth_threshold\": -2.679999940097332, \"match_probability\": 0.13497901995792916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132316.0, \"tn\": 1278729144.0, \"fp\": 8648.0, \"fn\": 171645.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43530584515776694, \"tn_rate\": 0.9999932370810857, \"fp_rate\": 6.762918914341432e-06, \"fn_rate\": 0.5646941548422331, \"precision\": 0.9386510030929883, \"recall\": 0.43530584515776694, \"specificity\": 0.9999932370810857, \"npv\": 0.9998657870872578, \"accuracy\": 0.9998590405672237, \"f1\": 0.5947788953194358, \"f2\": 0.48760030896044243, \"f0_5\": 0.76234966588578, \"p4\": 0.7458880469089995, \"phi\": 0.6391678163293384}, {\"truth_threshold\": -2.659999940544367, \"match_probability\": 0.13660585902200775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132315.0, \"tn\": 1278729168.0, \"fp\": 8624.0, \"fn\": 171646.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43530255526202377, \"tn_rate\": 0.9999932558495933, \"fp_rate\": 6.744150406716063e-06, \"fn_rate\": 0.5646974447379762, \"precision\": 0.9388104073393454, \"recall\": 0.43530255526202377, \"specificity\": 0.9999932558495933, \"npv\": 0.99986578630796, \"accuracy\": 0.9998590585494358, \"f1\": 0.594807821982468, \"f2\": 0.4876056082660234, \"f0_5\": 0.7624317605855365, \"p4\": 0.7459107949725148, \"phi\": 0.6392196923475285}, {\"truth_threshold\": -2.6399999409914017, \"match_probability\": 0.13824917190719177, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132308.0, \"tn\": 1278729187.0, \"fp\": 8605.0, \"fn\": 171653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4352795259918213, \"tn_rate\": 0.9999932707079952, \"fp_rate\": 6.729292004845979e-06, \"fn_rate\": 0.5647204740081787, \"precision\": 0.9389339521548757, \"recall\": 0.4352795259918213, \"specificity\": 0.9999932707079952, \"npv\": 0.9998657808372383, \"accuracy\": 0.9998590679314595, \"f1\": 0.5948111150572971, \"f2\": 0.48758915561150595, \"f0_5\": 0.7624828120371641, \"p4\": 0.7459133856304709, \"phi\": 0.6392448555291771}, {\"truth_threshold\": -2.6199999414384365, \"match_probability\": 0.13990904980164973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132290.0, \"tn\": 1278729265.0, \"fp\": 8527.0, \"fn\": 171671.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4352203078684436, \"tn_rate\": 0.999993331705645, \"fp_rate\": 6.6682943550635284e-06, \"fn_rate\": 0.5647796921315563, \"precision\": 0.9394462316339647, \"recall\": 0.4352203078684436, \"specificity\": 0.999993331705645, \"npv\": 0.9998657667727283, \"accuracy\": 0.9998591148415779, \"f1\": 0.5948585586517319, \"f2\": 0.48755731903548494, \"f0_5\": 0.7627166526949629, \"p4\": 0.7459506959800501, \"phi\": 0.6393757842788445}, {\"truth_threshold\": -2.5999999418854713, \"match_probability\": 0.14158558252569556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132285.0, \"tn\": 1278729273.0, \"fp\": 8519.0, \"fn\": 171676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43520385838972764, \"tn_rate\": 0.9999933379618141, \"fp_rate\": 6.662038185855072e-06, \"fn_rate\": 0.5647961416102724, \"precision\": 0.9394974574585949, \"recall\": 0.43520385838972764, \"specificity\": 0.9999933379618141, \"npv\": 0.9998657628644859, \"accuracy\": 0.9998591171870838, \"f1\": 0.5948534619405753, \"f2\": 0.4875435632529588, \"f0_5\": 0.7627335595847214, \"p4\": 0.7459466889846132, \"phi\": 0.6393811381643663}, {\"truth_threshold\": -2.579999942332506, \"match_probability\": 0.14327885847835395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132268.0, \"tn\": 1278729347.0, \"fp\": 8445.0, \"fn\": 171693.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4351479301620932, \"tn_rate\": 0.9999933958313794, \"fp_rate\": 6.604168620676849e-06, \"fn_rate\": 0.5648520698379068, \"precision\": 0.9399842232061003, \"recall\": 0.4351479301620932, \"specificity\": 0.9999933958313794, \"npv\": 0.999865749581375, \"accuracy\": 0.9998591617516962, \"f1\": 0.594898734803474, \"f2\": 0.4875136098225139, \"f0_5\": 0.7629557932333733, \"p4\": 0.7459822903700845, \"phi\": 0.6395057180304732}, {\"truth_threshold\": -2.559999942779541, \"match_probability\": 0.14498896458330635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132264.0, \"tn\": 1278729351.0, \"fp\": 8441.0, \"fn\": 171697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43513477057912037, \"tn_rate\": 0.9999933989594639, \"fp_rate\": 6.601040536072621e-06, \"fn_rate\": 0.5648652294208797, \"precision\": 0.9400092391883729, \"recall\": 0.43513477057912037, \"specificity\": 0.9999933989594639, \"npv\": 0.9998657464545294, \"accuracy\": 0.9998591617516962, \"f1\": 0.594891446613863, \"f2\": 0.48750174155153997, \"f0_5\": 0.762960886313844, \"p4\": 0.7459765602649354, \"phi\": 0.6395045598726402}, {\"truth_threshold\": -2.539999943226576, \"match_probability\": 0.14671598623423449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132257.0, \"tn\": 1278729395.0, \"fp\": 8397.0, \"fn\": 171704.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43511174130891794, \"tn_rate\": 0.9999934333683945, \"fp_rate\": 6.566631605426111e-06, \"fn_rate\": 0.5648882586910821, \"precision\": 0.9403003114024485, \"recall\": 0.43511174130891794, \"specificity\": 0.9999934333683945, \"npv\": 0.9998657409864342, \"accuracy\": 0.9998591906796025, \"f1\": 0.5949281963046681, \"f2\": 0.48749426832918297, \"f0_5\": 0.7631001053570543, \"p4\": 0.7460054570227543, \"phi\": 0.6395866746972956}, {\"truth_threshold\": -2.5199999436736107, \"match_probability\": 0.14846000723957972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132253.0, \"tn\": 1278729399.0, \"fp\": 8393.0, \"fn\": 171708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4350985817259451, \"tn_rate\": 0.9999934364964792, \"fp_rate\": 6.563503520821883e-06, \"fn_rate\": 0.5649014182740549, \"precision\": 0.9403253558579696, \"recall\": 0.4350985817259451, \"specificity\": 0.9999934364964792, \"npv\": 0.9998657378595889, \"accuracy\": 0.9998591906796025, \"f1\": 0.5949209076780168, \"f2\": 0.4874823994279353, \"f0_5\": 0.7631052051538004, \"p4\": 0.7459997267856465, \"phi\": 0.6395855224130085}, {\"truth_threshold\": -2.4999999441206455, \"match_probability\": 0.15022110976673644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132248.0, \"tn\": 1278729410.0, \"fp\": 8382.0, \"fn\": 171713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4350821322472291, \"tn_rate\": 0.9999934450987118, \"fp_rate\": 6.5549012881602545e-06, \"fn_rate\": 0.5649178677527709, \"precision\": 0.9403967858920572, \"recall\": 0.4350821322472291, \"specificity\": 0.9999934450987118, \"npv\": 0.9998657339516622, \"accuracy\": 0.9998591953706143, \"f1\": 0.5949198251876444, \"f2\": 0.4874697192869159, \"f0_5\": 0.7631327172782785, \"p4\": 0.7459988763922759, \"phi\": 0.6395977319204278}, {\"truth_threshold\": -2.4799999445676804, \"match_probability\": 0.1519993742857004, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132200.0, \"tn\": 1278732225.0, \"fp\": 5567.0, \"fn\": 171761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4349242172515553, \"tn_rate\": 0.999995646488252, \"fp_rate\": 4.3535117479346385e-06, \"fn_rate\": 0.5650757827484447, \"precision\": 0.9595911938272591, \"recall\": 0.4349242172515553, \"specificity\": 0.999995646488252, \"npv\": 0.9998656967200976, \"accuracy\": 0.9998613587089052, \"f1\": 0.5985583888727904, \"f2\": 0.48832345481826017, \"f0_5\": 0.7730731940086243, \"p4\": 0.7488532835564145, \"phi\": 0.6459774455049306}, {\"truth_threshold\": -2.459999945014715, \"match_probability\": 0.1537948795121923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132190.0, \"tn\": 1278732235.0, \"fp\": 5557.0, \"fn\": 171771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43489131829412325, \"tn_rate\": 0.9999956543084636, \"fp_rate\": 4.3456915364240674e-06, \"fn_rate\": 0.5651086817058767, \"precision\": 0.9596579235845427, \"recall\": 0.43489131829412325, \"specificity\": 0.9999956543084636, \"npv\": 0.9998656889030028, \"accuracy\": 0.9998613587089052, \"f1\": 0.5985402120858123, \"f2\": 0.48829373126742126, \"f0_5\": 0.7730870496368789, \"p4\": 0.748839057894312, \"phi\": 0.6459754786177307}, {\"truth_threshold\": -2.43999994546175, \"match_probability\": 0.15560770235027924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132185.0, \"tn\": 1278732241.0, \"fp\": 5551.0, \"fn\": 171776.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43487486881540727, \"tn_rate\": 0.9999956590005905, \"fp_rate\": 4.3409994095177255e-06, \"fn_rate\": 0.5651251311845927, \"precision\": 0.9596982633443689, \"recall\": 0.43487486881540727, \"specificity\": 0.9999956590005905, \"npv\": 0.9998656849945604, \"accuracy\": 0.9998613594907406, \"f1\": 0.5985324781467839, \"f2\": 0.4882792298940587, \"f0_5\": 0.7730975956392816, \"p4\": 0.7488330051087637, \"phi\": 0.6459768422221908}, {\"truth_threshold\": -2.419999945908785, \"match_probability\": 0.1574379178345172, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132168.0, \"tn\": 1278732255.0, \"fp\": 5537.0, \"fn\": 171793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43481894058777276, \"tn_rate\": 0.9999956699488866, \"fp_rate\": 4.330051113402926e-06, \"fn_rate\": 0.5651810594122272, \"precision\": 0.9597908572673469, \"recall\": 0.43481894058777276, \"specificity\": 0.9999956699488866, \"npv\": 0.9998656717051849, \"accuracy\": 0.9998613571452346, \"f1\": 0.5984975071660485, \"f2\": 0.48822761495889694, \"f0_5\": 0.7731103054466583, \"p4\": 0.748805634336865, \"phi\": 0.6459664696361211}, {\"truth_threshold\": -2.3999999463558197, \"match_probability\": 0.15928559907163878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132160.0, \"tn\": 1278732268.0, \"fp\": 5524.0, \"fn\": 171801.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4347926214218271, \"tn_rate\": 0.9999956801151616, \"fp_rate\": 4.319884838439185e-06, \"fn_rate\": 0.5652073785781728, \"precision\": 0.959879143546091, \"recall\": 0.4347926214218271, \"specificity\": 0.9999956801151616, \"npv\": 0.9998656654520348, \"accuracy\": 0.9998613610544111, \"f1\": 0.5984897372323925, \"f2\": 0.4882056374157018, \"f0_5\": 0.7731394868590857, \"p4\": 0.7487995534939633, \"phi\": 0.6459766368942741}, {\"truth_threshold\": -2.3799999468028545, \"match_probability\": 0.16115081718181212, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132159.0, \"tn\": 1278732277.0, \"fp\": 5515.0, \"fn\": 171802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43478933152608396, \"tn_rate\": 0.999995687153352, \"fp_rate\": 4.312846648079671e-06, \"fn_rate\": 0.5652106684739161, \"precision\": 0.9599416011737874, \"recall\": 0.43478933152608396, \"specificity\": 0.999995687153352, \"npv\": 0.9998656646711657, \"accuracy\": 0.9998613673090936, \"f1\": 0.5984987602884735, \"f2\": 0.4882055502771297, \"f0_5\": 0.7731698213435332, \"p4\": 0.7488066165537645, \"phi\": 0.6459952167075668}, {\"truth_threshold\": -2.3599999472498894, \"match_probability\": 0.16303364123949682, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132153.0, \"tn\": 1278732277.0, \"fp\": 5515.0, \"fn\": 171808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4347695921516247, \"tn_rate\": 0.999995687153352, \"fp_rate\": 4.312846648079671e-06, \"fn_rate\": 0.5652304078483753, \"precision\": 0.9599398553040649, \"recall\": 0.4347695921516247, \"specificity\": 0.999995687153352, \"npv\": 0.9998656599802791, \"accuracy\": 0.9998613626180818, \"f1\": 0.5984797194024849, \"f2\": 0.48818554988799506, \"f0_5\": 0.7731564308890483, \"p4\": 0.7487917128457804, \"phi\": 0.6459799632581918}, {\"truth_threshold\": -2.339999947696924, \"match_probability\": 0.1649341382139255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132151.0, \"tn\": 1278732281.0, \"fp\": 5511.0, \"fn\": 171810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4347630123601383, \"tn_rate\": 0.9999956902814365, \"fp_rate\": 4.309718563475443e-06, \"fn_rate\": 0.5652369876398617, \"precision\": 0.9599671659571996, \"recall\": 0.4347630123601383, \"specificity\": 0.9999956902814365, \"npv\": 0.9998656584170704, \"accuracy\": 0.9998613641817524, \"f1\": 0.5984787929976473, \"f2\": 0.48818032576139303, \"f0_5\": 0.7731664421975429, \"p4\": 0.7487909879711754, \"phi\": 0.6459842672060646}, {\"truth_threshold\": -2.319999948143959, \"match_probability\": 0.16685237290923954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132137.0, \"tn\": 1278732334.0, \"fp\": 5458.0, \"fn\": 171824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43471695381973346, \"tn_rate\": 0.9999957317285575, \"fp_rate\": 4.268271442469419e-06, \"fn_rate\": 0.5652830461802666, \"precision\": 0.9603328609324466, \"recall\": 0.43471695381973346, \"specificity\": 0.9999957317285575, \"npv\": 0.9998656474772365, \"accuracy\": 0.9998613946733294, \"f1\": 0.598506191740119, \"f2\": 0.488152772308172, \"f0_5\": 0.7733270438852871, \"p4\": 0.7488124367943157, \"phi\": 0.6460731167988935}, {\"truth_threshold\": -2.299999948590994, \"match_probability\": 0.16878840790430902, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132133.0, \"tn\": 1278732344.0, \"fp\": 5448.0, \"fn\": 171828.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43470379423676064, \"tn_rate\": 0.9999957395487691, \"fp_rate\": 4.2604512309588485e-06, \"fn_rate\": 0.5652962057632394, \"precision\": 0.9604015089292853, \"recall\": 0.43470379423676064, \"specificity\": 0.9999957395487691, \"npv\": 0.9998656443510296, \"accuracy\": 0.9998613993643412, \"f1\": 0.5985070502919314, \"f2\": 0.4881430444982175, \"f0_5\": 0.7733543255470949, \"p4\": 0.7488131094147846, \"phi\": 0.6460864368182563}, {\"truth_threshold\": -2.2799999490380287, \"match_probability\": 0.17074230349226796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132130.0, \"tn\": 1278732356.0, \"fp\": 5436.0, \"fn\": 171831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43469392454953104, \"tn_rate\": 0.9999957489330229, \"fp_rate\": 4.251066977146164e-06, \"fn_rate\": 0.565306075450469, \"precision\": 0.9604844220228835, \"recall\": 0.43469392454953104, \"specificity\": 0.9999957489330229, \"npv\": 0.9998656420068472, \"accuracy\": 0.9998614064008589, \"f1\": 0.5985137941734028, \"f2\": 0.4881373715282139, \"f0_5\": 0.7733910854868448, \"p4\": 0.7488183886088304, \"phi\": 0.6461070002422458}, {\"truth_threshold\": -2.2599999494850636, \"match_probability\": 0.17271411761979777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132116.0, \"tn\": 1278732379.0, \"fp\": 5413.0, \"fn\": 171845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4346478660091262, \"tn_rate\": 0.9999957669195093, \"fp_rate\": 4.233080490671852e-06, \"fn_rate\": 0.5653521339908738, \"precision\": 0.9606410284376387, \"recall\": 0.4346478660091262, \"specificity\": 0.9999957669195093, \"npv\": 0.999865631063863, \"accuracy\": 0.9998614134373767, \"f1\": 0.5985005322883871, \"f2\": 0.4880989941427825, \"f0_5\": 0.7734431438851532, \"p4\": 0.7488080099259635, \"phi\": 0.6461254552622738}, {\"truth_threshold\": -2.2399999499320984, \"match_probability\": 0.1747039058261921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132105.0, \"tn\": 1278732392.0, \"fp\": 5400.0, \"fn\": 171856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43461167715595095, \"tn_rate\": 0.9999957770857842, \"fp_rate\": 4.22291421570811e-06, \"fn_rate\": 0.565388322844049, \"precision\": 0.9607287007745173, \"recall\": 0.43461167715595095, \"specificity\": 0.9999957770857842, \"npv\": 0.9998656224652716, \"accuracy\": 0.9998614150010473, \"f1\": 0.5984832354020468, \"f2\": 0.48806701006170616, \"f0_5\": 0.7734656860047238, \"p4\": 0.7487944721451951, \"phi\": 0.6461280472029574}, {\"truth_threshold\": -2.2199999503791332, \"match_probability\": 0.17671172118223738, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132100.0, \"tn\": 1278732410.0, \"fp\": 5382.0, \"fn\": 171861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4345952276772349, \"tn_rate\": 0.999995791162165, \"fp_rate\": 4.208837834989083e-06, \"fn_rate\": 0.5654047723227651, \"precision\": 0.9608530571274785, \"recall\": 0.4345952276772349, \"specificity\": 0.999995791162165, \"npv\": 0.9998656185580914, \"accuracy\": 0.9998614251649063, \"f1\": 0.5984917645086681, \"f2\": 0.48805683183504933, \"f0_5\": 0.7735197431984719, \"p4\": 0.7488011492044285, \"phi\": 0.6461576495594793}, {\"truth_threshold\": -2.199999950826168, \"match_probability\": 0.17873761422894588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132090.0, \"tn\": 1278732426.0, \"fp\": 5366.0, \"fn\": 171871.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4345623287198029, \"tn_rate\": 0.9999958036745035, \"fp_rate\": 4.19632549657217e-06, \"fn_rate\": 0.5654376712801972, \"precision\": 0.9609620533116051, \"recall\": 0.4345623287198029, \"specificity\": 0.9999958036745035, \"npv\": 0.99986561074163, \"accuracy\": 0.9998614298559181, \"f1\": 0.5984817077729222, \"f2\": 0.4880292618044779, \"f0_5\": 0.7735554032923979, \"p4\": 0.7487932785631546, \"phi\": 0.6461698501506843}, {\"truth_threshold\": -2.179999951273203, \"match_probability\": 0.18078163291617783, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132082.0, \"tn\": 1278732432.0, \"fp\": 5360.0, \"fn\": 171879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43453600955385724, \"tn_rate\": 0.9999958083666304, \"fp_rate\": 4.191633369665827e-06, \"fn_rate\": 0.5654639904461428, \"precision\": 0.961001731639528, \"recall\": 0.43453600955385724, \"specificity\": 0.9999958083666304, \"npv\": 0.9998656044877465, \"accuracy\": 0.9998614282922474, \"f1\": 0.5984644417912882, \"f2\": 0.4880047528755932, \"f0_5\": 0.7735592910630891, \"p4\": 0.748779764214309, \"phi\": 0.6461636250577719}, {\"truth_threshold\": -2.1599999517202377, \"match_probability\": 0.18284382254119044, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132080.0, \"tn\": 1278732452.0, \"fp\": 5340.0, \"fn\": 171881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43452942976237086, \"tn_rate\": 0.9999958240070533, \"fp_rate\": 4.175992946644686e-06, \"fn_rate\": 0.5654705702376291, \"precision\": 0.9611410275069131, \"recall\": 0.43452942976237086, \"specificity\": 0.9999958240070533, \"npv\": 0.9998656029262198, \"accuracy\": 0.999861442365283, \"f1\": 0.5984852089238096, \"f2\": 0.48800529682308846, \"f0_5\": 0.7736273210869675, \"p4\": 0.7487960206419597, \"phi\": 0.646205578715517}, {\"truth_threshold\": -2.1399999521672726, \"match_probability\": 0.1849242256871536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132078.0, \"tn\": 1278732456.0, \"fp\": 5336.0, \"fn\": 171883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4345228499708844, \"tn_rate\": 0.9999958271351379, \"fp_rate\": 4.172864862040458e-06, \"fn_rate\": 0.5654771500291156, \"precision\": 0.9611684398969538, \"recall\": 0.4345228499708844, \"specificity\": 0.9999958271351379, \"npv\": 0.9998656013630117, \"accuracy\": 0.9998614439289536, \"f1\": 0.5984842820730671, \"f2\": 0.48800007093990944, \"f0_5\": 0.7736373572691265, \"p4\": 0.7487952954233099, \"phi\": 0.6462099041814005}, {\"truth_threshold\": -2.1199999526143074, \"match_probability\": 0.18702288216167304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132071.0, \"tn\": 1278732480.0, \"fp\": 5312.0, \"fn\": 171890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.434499820700682, \"tn_rate\": 0.9999958459036455, \"fp_rate\": 4.154096354415088e-06, \"fn_rate\": 0.565500179299318, \"precision\": 0.9613343717927254, \"recall\": 0.434499820700682, \"specificity\": 0.9999958459036455, \"npv\": 0.9998655958928344, \"accuracy\": 0.9998614572201537, \"f1\": 0.5984945983178654, \"f2\": 0.4879853860438788, \"f0_5\": 0.7737087474648299, \"p4\": 0.7488033716741594, \"phi\": 0.6462485750077871}, {\"truth_threshold\": -2.0999999530613422, \"match_probability\": 0.18913982893536135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132059.0, \"tn\": 1278732500.0, \"fp\": 5292.0, \"fn\": 171902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43446034195176353, \"tn_rate\": 0.9999958615440686, \"fp_rate\": 4.138455931393947e-06, \"fn_rate\": 0.5655396580482365, \"precision\": 0.9614709758210715, \"recall\": 0.43446034195176353, \"specificity\": 0.9999958615440686, \"npv\": 0.9998655865131661, \"accuracy\": 0.9998614634748362, \"f1\": 0.5984836125009064, \"f2\": 0.48795258628652927, \"f0_5\": 0.7737544895794882, \"p4\": 0.7487947740956712, \"phi\": 0.6462651415274285}, {\"truth_threshold\": -2.079999953508377, \"match_probability\": 0.19127510008050128, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132055.0, \"tn\": 1278732500.0, \"fp\": 5292.0, \"fn\": 171906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4344471823687907, \"tn_rate\": 0.9999958615440686, \"fp_rate\": 4.138455931393947e-06, \"fn_rate\": 0.5655528176312092, \"precision\": 0.9614698537281484, \"recall\": 0.4344471823687907, \"specificity\": 0.9999958615440686, \"npv\": 0.9998655833859095, \"accuracy\": 0.999861460347495, \"f1\": 0.5984709092062687, \"f2\": 0.48793924878306166, \"f0_5\": 0.7737455601401068, \"p4\": 0.7487848308066898, \"phi\": 0.6462549756258209}, {\"truth_threshold\": -2.059999953955412, \"match_probability\": 0.19342872670984337, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132042.0, \"tn\": 1278732505.0, \"fp\": 5287.0, \"fn\": 171919.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4344044137241291, \"tn_rate\": 0.9999958654541744, \"fp_rate\": 4.1345458256386625e-06, \"fn_rate\": 0.5655955862758709, \"precision\": 0.9615012124168967, \"recall\": 0.4344044137241291, \"specificity\": 0.9999958654541744, \"npv\": 0.999865573222851, \"accuracy\": 0.9998614540928126, \"f1\": 0.5984364023657912, \"f2\": 0.4878977041368694, \"f0_5\": 0.7737346723279779, \"p4\": 0.7487578206775828, \"phi\": 0.6462337039141912}, {\"truth_threshold\": -2.0399999544024467, \"match_probability\": 0.19560073691558413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132037.0, \"tn\": 1278732563.0, \"fp\": 5229.0, \"fn\": 171924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43438796424541304, \"tn_rate\": 0.9999959108114012, \"fp_rate\": 4.089188598877353e-06, \"fn_rate\": 0.565612035754587, \"precision\": 0.961906080165518, \"recall\": 0.43438796424541304, \"specificity\": 0.9999959108114012, \"npv\": 0.9998655693198768, \"accuracy\": 0.9998614955300837, \"f1\": 0.598499185226652, \"f2\": 0.48790194440954543, \"f0_5\": 0.7739339409747663, \"p4\": 0.7488069671256715, \"phi\": 0.6463575605059864}, {\"truth_threshold\": -2.0199999548494816, \"match_probability\": 0.19779115570857017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132031.0, \"tn\": 1278732766.0, \"fp\": 5026.0, \"fn\": 171930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43436822487095383, \"tn_rate\": 0.9999960695616947, \"fp_rate\": 3.9304383052127705e-06, \"fn_rate\": 0.5656317751290462, \"precision\": 0.9633291258381549, \"recall\": 0.43436822487095383, \"specificity\": 0.9999960695616947, \"npv\": 0.999865564650331, \"accuracy\": 0.999861649551639, \"f1\": 0.5987556063471332, \"f2\": 0.48795514232009585, \"f0_5\": 0.7746579690655476, \"p4\": 0.7490076514859929, \"phi\": 0.646820981520625}, {\"truth_threshold\": -1.9999999552965164, \"match_probability\": 0.20000000495777503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132021.0, \"tn\": 1278732790.0, \"fp\": 5002.0, \"fn\": 171940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4343353259135218, \"tn_rate\": 0.9999960883302024, \"fp_rate\": 3.911669797587401e-06, \"fn_rate\": 0.5656646740864782, \"precision\": 0.9634951796413741, \"recall\": 0.4343353259135218, \"specificity\": 0.9999960883302024, \"npv\": 0.9998655568347143, \"accuracy\": 0.9998616604973333, \"f1\": 0.5987564174663933, \"f2\": 0.48793044696928817, \"f0_5\": 0.7747229339019991, \"p4\": 0.7490082876624528, \"phi\": 0.6468522482766332}, {\"truth_threshold\": -1.9799999557435513, \"match_probability\": 0.20222730333009747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132015.0, \"tn\": 1278732808.0, \"fp\": 4984.0, \"fn\": 171946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4343155865390626, \"tn_rate\": 0.9999961024065831, \"fp_rate\": 3.8975934168683735e-06, \"fn_rate\": 0.5656844134609375, \"precision\": 0.9636201724100176, \"recall\": 0.4343155865390626, \"specificity\": 0.9999961024065831, \"npv\": 0.9998655521457229, \"accuracy\": 0.999861669879357, \"f1\": 0.5987617924528302, \"f2\": 0.4879169275370461, \"f0_5\": 0.7747750179879971, \"p4\": 0.7490124944901848, \"phi\": 0.6468795191585701}, {\"truth_threshold\": -1.959999956190586, \"match_probability\": 0.20447306623052947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 132010.0, \"tn\": 1278732822.0, \"fp\": 4970.0, \"fn\": 171951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43429913706034656, \"tn_rate\": 0.9999961133548793, \"fp_rate\": 3.886645120753575e-06, \"fn_rate\": 0.5657008629396535, \"precision\": 0.9637173309972259, \"recall\": 0.43429913706034656, \"specificity\": 0.9999961133548793, \"npv\": 0.9998655482381251, \"accuracy\": 0.9998616769158747, \"f1\": 0.5987649141268333, \"f2\": 0.48790530031992335, \"f0_5\": 0.7748147922068928, \"p4\": 0.7490149379330998, \"phi\": 0.6468998901169647}, {\"truth_threshold\": -1.939999956637621, \"match_probability\": 0.20673730574274402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131998.0, \"tn\": 1278732840.0, \"fp\": 4952.0, \"fn\": 171963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4342596583114281, \"tn_rate\": 0.99999612743126, \"fp_rate\": 3.8725687400345485e-06, \"fn_rate\": 0.5657403416885719, \"precision\": 0.9638408178167215, \"recall\": 0.4342596583114281, \"specificity\": 0.99999612743126, \"npv\": 0.9998655388582507, \"accuracy\": 0.9998616816068865, \"f1\": 0.5987512219019258, \"f2\": 0.4878717676157641, \"f0_5\": 0.7748535093764566, \"p4\": 0.7490042254702528, \"phi\": 0.6469119423407743}, {\"truth_threshold\": -1.9199999570846558, \"match_probability\": 0.20902003057015453, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131988.0, \"tn\": 1278732939.0, \"fp\": 4853.0, \"fn\": 171973.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4342267593539961, \"tn_rate\": 0.9999962048513539, \"fp_rate\": 3.7951486460798993e-06, \"fn_rate\": 0.565773240646004, \"precision\": 0.9645354827865917, \"recall\": 0.4342267593539961, \"specificity\": 0.9999962048513539, \"npv\": 0.9998655310505211, \"accuracy\": 0.9998617511902287, \"f1\": 0.5988539071964283, \"f2\": 0.48787411703389927, \"f0_5\": 0.775191613073738, \"p4\": 0.7490845741709138, \"phi\": 0.6471205968836071}, {\"truth_threshold\": -1.8999999575316906, \"match_probability\": 0.211321245977496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131982.0, \"tn\": 1278732948.0, \"fp\": 4844.0, \"fn\": 171979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43420701997953687, \"tn_rate\": 0.9999962118895442, \"fp_rate\": 3.788110455720386e-06, \"fn_rate\": 0.5657929800204632, \"precision\": 0.9645973718445324, \"recall\": 0.43420701997953687, \"specificity\": 0.9999962118895442, \"npv\": 0.9998655263605846, \"accuracy\": 0.9998617535357347, \"f1\": 0.5988470621864982, \"f2\": 0.4878573487990419, \"f0_5\": 0.77521100949763, \"p4\": 0.7490792194211963, \"phi\": 0.6471266548508742}, {\"truth_threshold\": -1.8799999579787254, \"match_probability\": 0.2136409537329821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131970.0, \"tn\": 1278732951.0, \"fp\": 4841.0, \"fn\": 171991.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4341675412306184, \"tn_rate\": 0.9999962142356077, \"fp_rate\": 3.7857643922672146e-06, \"fn_rate\": 0.5658324587693816, \"precision\": 0.9646154183508636, \"recall\": 0.4341675412306184, \"specificity\": 0.9999962142356077, \"npv\": 0.9998655169791345, \"accuracy\": 0.9998617464992169, \"f1\": 0.5988129917508371, \"f2\": 0.48781840158798806, \"f0_5\": 0.7751951645020883, \"p4\": 0.7490525633166838, \"phi\": 0.6471032877048689}, {\"truth_threshold\": -1.8599999584257603, \"match_probability\": 0.21597915205109092, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131969.0, \"tn\": 1278732957.0, \"fp\": 4835.0, \"fn\": 171992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4341642513348752, \"tn_rate\": 0.9999962189277346, \"fp_rate\": 3.7810722653608722e-06, \"fn_rate\": 0.5658357486651248, \"precision\": 0.9646574661559604, \"recall\": 0.4341642513348752, \"specificity\": 0.9999962189277346, \"npv\": 0.9998655161979516, \"accuracy\": 0.9998617504083934, \"f1\": 0.5988179642212971, \"f2\": 0.4878172296118428, \"f0_5\": 0.7752147908131917, \"p4\": 0.7490564541646523, \"phi\": 0.647114944656565}, {\"truth_threshold\": -1.839999958872795, \"match_probability\": 0.218335835536034, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131952.0, \"tn\": 1278732996.0, \"fp\": 4796.0, \"fn\": 172009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43410832310724073, \"tn_rate\": 0.9999962494265595, \"fp_rate\": 3.750573440469647e-06, \"fn_rate\": 0.5658916768927593, \"precision\": 0.9649281890777196, \"recall\": 0.43410832310724073, \"specificity\": 0.9999962494265595, \"npv\": 0.999865502911219, \"accuracy\": 0.9998617676087701, \"f1\": 0.5988169063940151, \"f2\": 0.4877745839100039, \"f0_5\": 0.775318965912336, \"p4\": 0.7490556289708563, \"phi\": 0.6471640852551732}, {\"truth_threshold\": -1.81999995931983, \"match_probability\": 0.22071099512596293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131941.0, \"tn\": 1278733767.0, \"fp\": 4025.0, \"fn\": 172020.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4340721342540655, \"tn_rate\": 0.999996852364867, \"fp_rate\": 3.1476351330046557e-06, \"fn_rate\": 0.5659278657459346, \"precision\": 0.9703970110174602, \"recall\": 0.4340721342540655, \"specificity\": 0.999996852364867, \"npv\": 0.999865494392356, \"accuracy\": 0.9998623618036026, \"f1\": 0.5998313356534152, \"f2\": 0.4880160673467425, \"f0_5\": 0.778114587326394, \"p4\": 0.7498488643565497, \"phi\": 0.6489690766728299}, {\"truth_threshold\": -1.7999999597668648, \"match_probability\": 0.22310461803797055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131934.0, \"tn\": 1278733780.0, \"fp\": 4012.0, \"fn\": 172027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43404910498386307, \"tn_rate\": 0.999996862531142, \"fp_rate\": 3.137468858040914e-06, \"fn_rate\": 0.5659508950161369, \"precision\": 0.9704882821120151, \"recall\": 0.43404910498386307, \"specificity\": 0.999996862531142, \"npv\": 0.9998654889210304, \"accuracy\": 0.9998623664946144, \"f1\": 0.5998267815697409, \"f2\": 0.4879973960452437, \"f0_5\": 0.7781467304437065, \"p4\": 0.7498453065617597, \"phi\": 0.6489823891138125}, {\"truth_threshold\": -1.7799999602138996, \"match_probability\": 0.22551668771394165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131918.0, \"tn\": 1278733803.0, \"fp\": 3989.0, \"fn\": 172043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4339964666519718, \"tn_rate\": 0.9999968805176285, \"fp_rate\": 3.119482371566602e-06, \"fn_rate\": 0.5660035333480282, \"precision\": 0.9706490467746327, \"recall\": 0.4339964666519718, \"specificity\": 0.9999968805176285, \"npv\": 0.9998654764144381, \"accuracy\": 0.9998623719674615, \"f1\": 0.5998072148917403, \"f2\": 0.4879522929888715, \"f0_5\": 0.7781955641236495, \"p4\": 0.7498300181561249, \"phi\": 0.6489967999886698}, {\"truth_threshold\": -1.7599999606609344, \"match_probability\": 0.22794718376731132, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131915.0, \"tn\": 1278733823.0, \"fp\": 3969.0, \"fn\": 172046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4339865969647422, \"tn_rate\": 0.9999968961580514, \"fp_rate\": 3.103841948545461e-06, \"fn_rate\": 0.5660134030352578, \"precision\": 0.9707912631362045, \"recall\": 0.4339865969647422, \"specificity\": 0.9999968961580514, \"npv\": 0.9998654740711023, \"accuracy\": 0.9998623852586617, \"f1\": 0.5998249383305483, \"f2\": 0.48794949871571797, \"f0_5\": 0.7782623419315938, \"p4\": 0.7498438689308534, \"phi\": 0.6490369800222484}, {\"truth_threshold\": -1.7399999611079693, \"match_probability\": 0.23039608193078784, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131911.0, \"tn\": 1278733845.0, \"fp\": 3947.0, \"fn\": 172050.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43397343738176936, \"tn_rate\": 0.9999969133625167, \"fp_rate\": 3.0866374832222055e-06, \"fn_rate\": 0.5660265626182306, \"precision\": 0.970947607060313, \"recall\": 0.43397343738176936, \"specificity\": 0.9999969133625167, \"npv\": 0.9998654709461637, \"accuracy\": 0.9998623993316972, \"f1\": 0.5998422078173067, \"f2\": 0.48794408826797625, \"f0_5\": 0.7783342557703451, \"p4\": 0.7498573648072291, \"phi\": 0.6490794188461153}, {\"truth_threshold\": -1.7199999615550041, \"match_probability\": 0.232863354005098, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131899.0, \"tn\": 1278733859.0, \"fp\": 3933.0, \"fn\": 172062.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43393395863285095, \"tn_rate\": 0.9999969243108129, \"fp_rate\": 3.0756891871074066e-06, \"fn_rate\": 0.5660660413671491, \"precision\": 0.9710451145532717, \"recall\": 0.43393395863285095, \"specificity\": 0.9999969243108129, \"npv\": 0.9998654615658785, \"accuracy\": 0.9998624008953678, \"f1\": 0.5998230985941113, \"f2\": 0.48790908472148653, \"f0_5\": 0.7783589778694164, \"p4\": 0.7498424335937903, \"phi\": 0.6490824936437003}, {\"truth_threshold\": -1.699999962002039, \"match_probability\": 0.23534896780881392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131894.0, \"tn\": 1278734257.0, \"fp\": 3535.0, \"fn\": 172067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4339175091541349, \"tn_rate\": 0.999997235555231, \"fp_rate\": 2.7644447689866976e-06, \"fn_rate\": 0.5660824908458651, \"precision\": 0.9738977619269137, \"recall\": 0.4339175091541349, \"specificity\": 0.999997235555231, \"npv\": 0.9998654576986828, \"accuracy\": 0.9998627081566429, \"f1\": 0.6003504859009081, \"f2\": 0.4880360963328654, \"f0_5\": 0.7798130964895581, \"p4\": 0.750254432232017, \"phi\": 0.650023244854529}, {\"truth_threshold\": -1.6799999624490738, \"match_probability\": 0.2378528871293195, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131883.0, \"tn\": 1278734271.0, \"fp\": 3521.0, \"fn\": 172078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43388132030095966, \"tn_rate\": 0.9999972465035272, \"fp_rate\": 2.753496472871899e-06, \"fn_rate\": 0.5661186796990403, \"precision\": 0.9739963368881274, \"recall\": 0.43388132030095966, \"specificity\": 0.9999972465035272, \"npv\": 0.999865449100214, \"accuracy\": 0.9998627105021489, \"f1\": 0.600334573759858, \"f2\": 0.4880044225782388, \"f0_5\": 0.7798402747473028, \"p4\": 0.7502420071631979, \"phi\": 0.6500290424052447}, {\"truth_threshold\": -1.6599999628961086, \"match_probability\": 0.24037507167497607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131876.0, \"tn\": 1278734277.0, \"fp\": 3515.0, \"fn\": 172085.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43385829103075724, \"tn_rate\": 0.9999972511956541, \"fp_rate\": 2.748804345965557e-06, \"fn_rate\": 0.5661417089692428, \"precision\": 0.9740381561551359, \"recall\": 0.43385829103075724, \"specificity\": 0.9999972511956541, \"npv\": 0.9998654436281552, \"accuracy\": 0.9998627097203135, \"f1\": 0.6003204719678071, \"f2\": 0.48798321535484207, \"f0_5\": 0.7798468407202626, \"p4\": 0.7502309951045052, \"phi\": 0.6500257489978636}, {\"truth_threshold\": -1.6399999633431435, \"match_probability\": 0.24291547702854654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131871.0, \"tn\": 1278734441.0, \"fp\": 3351.0, \"fn\": 172090.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4338418415520412, \"tn_rate\": 0.9999973794471229, \"fp_rate\": 2.6205528771921994e-06, \"fn_rate\": 0.5661581584479588, \"precision\": 0.9752185295292186, \"recall\": 0.4338418415520412, \"specificity\": 0.9999973794471229, \"npv\": 0.9998654397363461, \"accuracy\": 0.9998628340321272, \"f1\": 0.6005287089891913, \"f2\": 0.48802575151769045, \"f0_5\": 0.7804412386118703, \"p4\": 0.7503936030990663, \"phi\": 0.6504073105638846}, {\"truth_threshold\": -1.6199999637901783, \"match_probability\": 0.24547405460193694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131853.0, \"tn\": 1278734472.0, \"fp\": 3320.0, \"fn\": 172108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4337826234286635, \"tn_rate\": 0.9999974036897785, \"fp_rate\": 2.5963102215094303e-06, \"fn_rate\": 0.5662173765713364, \"precision\": 0.9754388820252565, \"recall\": 0.4337826234286635, \"specificity\": 0.9999974036897785, \"npv\": 0.9998654256669788, \"accuracy\": 0.9998628441959861, \"f1\": 0.600513738403312, \"f2\": 0.48797683522857227, \"f0_5\": 0.7805157857723822, \"p4\": 0.7503819169784813, \"phi\": 0.6504364142938732}, {\"truth_threshold\": -1.5999999642372131, \"match_probability\": 0.24805075159231657, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131842.0, \"tn\": 1278734486.0, \"fp\": 3306.0, \"fn\": 172119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4337464345754883, \"tn_rate\": 0.9999974146380746, \"fp_rate\": 2.5853619253946315e-06, \"fn_rate\": 0.5662535654245117, \"precision\": 0.9755379287891792, \"recall\": 0.4337464345754883, \"specificity\": 0.9999974146380746, \"npv\": 0.9998654170685122, \"accuracy\": 0.999862846541492, \"f1\": 0.6004978262800352, \"f2\": 0.4879451543754515, \"f0_5\": 0.780543080185613, \"p4\": 0.750369494457791, \"phi\": 0.6504423124060298}, {\"truth_threshold\": -1.579999964684248, \"match_probability\": 0.25064551093967435, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131834.0, \"tn\": 1278734500.0, \"fp\": 3292.0, \"fn\": 172127.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4337201154095427, \"tn_rate\": 0.9999974255863707, \"fp_rate\": 2.5744136292798327e-06, \"fn_rate\": 0.5662798845904573, \"precision\": 0.9756375530985895, \"recall\": 0.4337201154095427, \"specificity\": 0.9999974255863707, \"npv\": 0.9998654108154841, \"accuracy\": 0.9998628512325038, \"f1\": 0.6004914743547406, \"f2\": 0.48792349200944507, \"f0_5\": 0.7805770517428194, \"p4\": 0.7503645359990151, \"phi\": 0.650455799223158}, {\"truth_threshold\": -1.5599999651312828, \"match_probability\": 0.2532582712858729, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131818.0, \"tn\": 1278734526.0, \"fp\": 3266.0, \"fn\": 172143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4336674770776514, \"tn_rate\": 0.9999974459189207, \"fp_rate\": 2.5540810793523495e-06, \"fn_rate\": 0.5663325229223486, \"precision\": 0.97582245121554, \"recall\": 0.4336674770776514, \"specificity\": 0.9999974459189207, \"npv\": 0.9998653983092178, \"accuracy\": 0.9998628590508569, \"f1\": 0.600476033208441, \"f2\": 0.4878794428718629, \"f0_5\": 0.7806376192264096, \"p4\": 0.7503524816164419, \"phi\": 0.6504779751327827}, {\"truth_threshold\": -1.5399999655783176, \"match_probability\": 0.2558889669352588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131813.0, \"tn\": 1278734527.0, \"fp\": 3265.0, \"fn\": 172148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43365102759893537, \"tn_rate\": 0.9999974467009418, \"fp_rate\": 2.5532990582012922e-06, \"fn_rate\": 0.5663489724010646, \"precision\": 0.9758287804083566, \"recall\": 0.43365102759893537, \"specificity\": 0.9999974467009418, \"npv\": 0.9998653944002599, \"accuracy\": 0.9998628559235158, \"f1\": 0.6004614624213339, \"f2\": 0.4878631038653601, \"f0_5\": 0.7806301989996127, \"p4\": 0.750341105001243, \"phi\": 0.6504677473088379}, {\"truth_threshold\": -1.5199999660253525, \"match_probability\": 0.25853752781688866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131805.0, \"tn\": 1278734533.0, \"fp\": 3259.0, \"fn\": 172156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4336247084329898, \"tn_rate\": 0.9999974513930687, \"fp_rate\": 2.54860693129495e-06, \"fn_rate\": 0.5663752915670103, \"precision\": 0.9758706983356039, \"recall\": 0.4336247084329898, \"specificity\": 0.9999974513930687, \"npv\": 0.9998653881463904, \"accuracy\": 0.9998628543598451, \"f1\": 0.6004441660497694, \"f2\": 0.48783855007150745, \"f0_5\": 0.7806345998718339, \"p4\": 0.7503276003311704, \"phi\": 0.6504619813951836}, {\"truth_threshold\": -1.4999999664723873, \"match_probability\": 0.2612038794484303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131791.0, \"tn\": 1278734539.0, \"fp\": 3253.0, \"fn\": 172170.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335786498925849, \"tn_rate\": 0.9999974560851956, \"fp_rate\": 2.5439148043886075e-06, \"fn_rate\": 0.5664213501074151, \"precision\": 0.9759115547525251, \"recall\": 0.4335786498925849, \"specificity\": 0.9999974560851956, \"npv\": 0.9998653772016455, \"accuracy\": 0.9998628481051627, \"f1\": 0.600407740230749, \"f2\": 0.4877939547912188, \"f0_5\": 0.7806256567358142, \"p4\": 0.7502991583893962, \"phi\": 0.650441052255802}, {\"truth_threshold\": -1.4799999669194221, \"match_probability\": 0.2638879429017973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131788.0, \"tn\": 1278734553.0, \"fp\": 3239.0, \"fn\": 172173.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335687802053553, \"tn_rate\": 0.9999974670334917, \"fp_rate\": 2.5329665082738087e-06, \"fn_rate\": 0.5664312197946447, \"precision\": 0.9760122049664142, \"recall\": 0.4335687802053553, \"specificity\": 0.9999974670334917, \"npv\": 0.9998653748576813, \"accuracy\": 0.999862856705351, \"f1\": 0.6004173234803685, \"f2\": 0.4877889894741985, \"f0_5\": 0.7806707745456829, \"p4\": 0.7503066422696977, \"phi\": 0.650467201362883}, {\"truth_threshold\": -1.459999967366457, \"match_probability\": 0.2665896347705756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131786.0, \"tn\": 1278734560.0, \"fp\": 3232.0, \"fn\": 172175.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335622004138689, \"tn_rate\": 0.9999974725076398, \"fp_rate\": 2.5274923602164095e-06, \"fn_rate\": 0.5664377995861312, \"precision\": 0.9760624509324682, \"recall\": 0.4335622004138689, \"specificity\": 0.9999974725076398, \"npv\": 0.9998653732947931, \"accuracy\": 0.9998628606145276, \"f1\": 0.6004205212550031, \"f2\": 0.4877848366450459, \"f0_5\": 0.7806922241191991, \"p4\": 0.7503091396453446, \"phi\": 0.6504790144708521}, {\"truth_threshold\": -1.4399999678134918, \"match_probability\": 0.2693088671393003, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131779.0, \"tn\": 1278734560.0, \"fp\": 3232.0, \"fn\": 172182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43353917114366647, \"tn_rate\": 0.9999974725076398, \"fp_rate\": 2.5274923602164095e-06, \"fn_rate\": 0.5664608288563335, \"precision\": 0.9760612098273475, \"recall\": 0.43353917114366647, \"specificity\": 0.9999974725076398, \"npv\": 0.999865367822105, \"accuracy\": 0.9998628551416804, \"f1\": 0.6003982030744558, \"f2\": 0.48776145478234156, \"f0_5\": 0.7806766547591543, \"p4\": 0.7502917126118479, \"phi\": 0.6504613231578412}, {\"truth_threshold\": -1.4199999682605267, \"match_probability\": 0.27204554755463817, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131771.0, \"tn\": 1278734566.0, \"fp\": 3226.0, \"fn\": 172190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335128519777208, \"tn_rate\": 0.9999974771997667, \"fp_rate\": 2.522800233310067e-06, \"fn_rate\": 0.5664871480222792, \"precision\": 0.9761031726630962, \"recall\": 0.4335128519777208, \"specificity\": 0.9999974771997667, \"npv\": 0.9998653615682361, \"accuracy\": 0.9998628535780099, \"f1\": 0.6003809020452981, \"f2\": 0.4877368987171695, \"f0_5\": 0.7806810601114522, \"p4\": 0.7502782032373225, \"phi\": 0.6504555638485191}, {\"truth_threshold\": -1.3999999687075615, \"match_probability\": 0.27479957899853474, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131768.0, \"tn\": 1278734568.0, \"fp\": 3224.0, \"fn\": 172193.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4335029822904912, \"tn_rate\": 0.999997478763809, \"fp_rate\": 2.521236191007953e-06, \"fn_rate\": 0.5664970177095088, \"precision\": 0.9761171032357473, \"recall\": 0.4335029822904912, \"specificity\": 0.999997478763809, \"npv\": 0.9998653592230091, \"accuracy\": 0.9998628527961745, \"f1\": 0.6003740719393648, \"f2\": 0.4877275997974588, \"f0_5\": 0.7806817872119574, \"p4\": 0.750272869898462, \"phi\": 0.6504528018671163}, {\"truth_threshold\": -1.3799999691545963, \"match_probability\": 0.2775708598633799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131754.0, \"tn\": 1278734596.0, \"fp\": 3196.0, \"fn\": 172207.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4334569237500864, \"tn_rate\": 0.9999975006604013, \"fp_rate\": 2.4993395987783553e-06, \"fn_rate\": 0.5665430762499136, \"precision\": 0.9763171545016673, \"recall\": 0.4334569237500864, \"specificity\": 0.9999975006604013, \"npv\": 0.9998653482805815, \"accuracy\": 0.9998628637418688, \"f1\": 0.6003677283093839, \"f2\": 0.4876909432526351, \"f0_5\": 0.7807542657221654, \"p4\": 0.7502679180304974, \"phi\": 0.6504849151694979}, {\"truth_threshold\": -1.3599999696016312, \"match_probability\": 0.2803592839292471, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131747.0, \"tn\": 1278734600.0, \"fp\": 3192.0, \"fn\": 172214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43343389447988395, \"tn_rate\": 0.9999975037884858, \"fp_rate\": 2.496211514174127e-06, \"fn_rate\": 0.5665661055201161, \"precision\": 0.9763448669398765, \"recall\": 0.43343389447988395, \"specificity\": 0.9999975037884858, \"npv\": 0.9998653428083151, \"accuracy\": 0.9998628613963628, \"f1\": 0.6003508771929824, \"f2\": 0.4876690038296307, \"f0_5\": 0.7807534990998166, \"p4\": 0.750254759353591, \"phi\": 0.6504768683166352}, {\"truth_threshold\": -1.339999970048666, \"match_probability\": 0.2831647403432607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131738.0, \"tn\": 1278734616.0, \"fp\": 3176.0, \"fn\": 172223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4334042854181951, \"tn_rate\": 0.9999975163008242, \"fp_rate\": 2.483699175757214e-06, \"fn_rate\": 0.5665957145818049, \"precision\": 0.9764590776346413, \"recall\": 0.4334042854181951, \"specificity\": 0.9999975163008242, \"npv\": 0.9998653357736873, \"accuracy\": 0.99986286686921, \"f1\": 0.6003440615209342, \"f2\": 0.48764471504148044, \"f0_5\": 0.7807927056946458, \"p4\": 0.7502494379662102, \"phi\": 0.6504927054421397}, {\"truth_threshold\": -1.3199999704957008, \"match_probability\": 0.2859871136011437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131736.0, \"tn\": 1278734667.0, \"fp\": 3125.0, \"fn\": 172225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4333977056267087, \"tn_rate\": 0.999997556183903, \"fp_rate\": 2.4438160970533043e-06, \"fn_rate\": 0.5666022943732913, \"precision\": 0.9768279932671418, \"recall\": 0.4333977056267087, \"specificity\": 0.999997556183903, \"npv\": 0.9998653342154324, \"accuracy\": 0.99986290517914, \"f1\": 0.6004074545031927, \"f2\": 0.48765644607815917, \"f0_5\": 0.7809771106407953, \"p4\": 0.7502989433262028, \"phi\": 0.6506106826459181}, {\"truth_threshold\": -1.2999999709427357, \"match_probability\": 0.2888262835309975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131727.0, \"tn\": 1278734702.0, \"fp\": 3090.0, \"fn\": 172234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43336809656501984, \"tn_rate\": 0.9999975835546432, \"fp_rate\": 2.4164453567663074e-06, \"fn_rate\": 0.5666319034349802, \"precision\": 0.9770800418344867, \"recall\": 0.43336809656501984, \"specificity\": 0.9999975835546432, \"npv\": 0.9998653271828061, \"accuracy\": 0.999862925506858, \"f1\": 0.6004266394395343, \"f2\": 0.4876390152673395, \"f0_5\": 0.7810867510486476, \"p4\": 0.7503139258388309, \"phi\": 0.6506724170302091}, {\"truth_threshold\": -1.2799999713897705, \"match_probability\": 0.2916821252793642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131715.0, \"tn\": 1278734708.0, \"fp\": 3084.0, \"fn\": 172246.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4333286178161014, \"tn_rate\": 0.9999975882467701, \"fp_rate\": 2.411753229859965e-06, \"fn_rate\": 0.5666713821838986, \"precision\": 0.9771214919991988, \"recall\": 0.4333286178161014, \"specificity\": 0.9999975882467701, \"npv\": 0.999865317801689, \"accuracy\": 0.9998629208158462, \"f1\": 0.6003965721578995, \"f2\": 0.48760109073974395, \"f0_5\": 0.7810822895380101, \"p4\": 0.750290448403543, \"phi\": 0.6506565819727692}, {\"truth_threshold\": -1.2599999718368053, \"match_probability\": 0.2945545092996211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131701.0, \"tn\": 1278734759.0, \"fp\": 3033.0, \"fn\": 172260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43328255927569653, \"tn_rate\": 0.9999976281298488, \"fp_rate\": 2.371870151156055e-06, \"fn_rate\": 0.5667174407243034, \"precision\": 0.9774889782831356, \"recall\": 0.43328255927569653, \"specificity\": 0.9999976281298488, \"npv\": 0.9998653068616867, \"accuracy\": 0.9998629497437524, \"f1\": 0.600421705284993, \"f2\": 0.487572728120849, \"f0_5\": 0.7812401752527296, \"p4\": 0.750310076684644, \"phi\": 0.6507443797906836}, {\"truth_threshold\": -1.2399999722838402, \"match_probability\": 0.29744330134275365, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131682.0, \"tn\": 1278734760.0, \"fp\": 3032.0, \"fn\": 172279.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4332200512565757, \"tn_rate\": 0.9999976289118699, \"fp_rate\": 2.371088130004998e-06, \"fn_rate\": 0.5667799487434243, \"precision\": 0.9774930593702214, \"recall\": 0.4332200512565757, \"specificity\": 0.9999976289118699, \"npv\": 0.9998652920073575, \"accuracy\": 0.9998629356707169, \"f1\": 0.6003624551205334, \"f2\": 0.48750960714015984, \"f0_5\": 0.781201613161576, \"p4\": 0.7502638105700429, \"phi\": 0.6506987918208019}, {\"truth_threshold\": -1.219999972730875, \"match_probability\": 0.3003483624505542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131668.0, \"tn\": 1278734781.0, \"fp\": 3011.0, \"fn\": 172293.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4331739927161708, \"tn_rate\": 0.9999976453343141, \"fp_rate\": 2.3546656858328e-06, \"fn_rate\": 0.5668260072838291, \"precision\": 0.9776431366434262, \"recall\": 0.4331739927161708, \"specificity\": 0.9999976453343141, \"npv\": 0.9998652810641971, \"accuracy\": 0.9998629411435641, \"f1\": 0.6003465256246581, \"f2\": 0.48747040961168375, \"f0_5\": 0.7812483312111284, \"p4\": 0.750251372574439, \"phi\": 0.6507141634439417}, {\"truth_threshold\": -1.1999999731779099, \"match_probability\": 0.30326954895129116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131660.0, \"tn\": 1278734782.0, \"fp\": 3010.0, \"fn\": 172301.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4331476735502252, \"tn_rate\": 0.9999976461163353, \"fp_rate\": 2.3538836646817426e-06, \"fn_rate\": 0.5668523264497748, \"precision\": 0.977649068092374, \"recall\": 0.4331476735502252, \"specificity\": 0.9999976461163353, \"npv\": 0.9998652748098041, \"accuracy\": 0.9998629356707169, \"f1\": 0.6003223666361931, \"f2\": 0.4874440398248371, \"f0_5\": 0.781234238542867, \"p4\": 0.750232506452675, \"phi\": 0.6506963673903611}, {\"truth_threshold\": -1.1799999736249447, \"match_probability\": 0.3062067124578904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131647.0, \"tn\": 1278734790.0, \"fp\": 3002.0, \"fn\": 172314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4331049049055635, \"tn_rate\": 0.9999976523725045, \"fp_rate\": 2.347627495473286e-06, \"fn_rate\": 0.5668950950944365, \"precision\": 0.9777049959524393, \"recall\": 0.4331049049055635, \"specificity\": 0.9999976523725045, \"npv\": 0.9998652646470872, \"accuracy\": 0.9998629317615404, \"f1\": 0.6002918310116049, \"f2\": 0.4874034889481101, \"f0_5\": 0.7812349787610808, \"p4\": 0.7502086603272963, \"phi\": 0.6506828565319993}, {\"truth_threshold\": -1.1599999740719795, \"match_probability\": 0.30915969986867026, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131626.0, \"tn\": 1278734822.0, \"fp\": 2970.0, \"fn\": 172335.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43303581709495625, \"tn_rate\": 0.9999976773971814, \"fp_rate\": 2.32260281863946e-06, \"fn_rate\": 0.5669641829050437, \"precision\": 0.977933965348153, \"recall\": 0.43303581709495625, \"specificity\": 0.9999976773971814, \"npv\": 0.9998652482324016, \"accuracy\": 0.9998629403617287, \"f1\": 0.600268608185481, \"f2\": 0.4873448653772104, \"f0_5\": 0.7813069466786174, \"p4\": 0.7501905259911635, \"phi\": 0.6507071617620722}, {\"truth_threshold\": -1.1399999745190144, \"match_probability\": 0.31212835337067063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131584.0, \"tn\": 1278734897.0, \"fp\": 2895.0, \"fn\": 172377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4328976414737417, \"tn_rate\": 0.9999977360487677, \"fp_rate\": 2.263951232310181e-06, \"fn_rate\": 0.5671023585262583, \"precision\": 0.9784724752563597, \"recall\": 0.4328976414737417, \"specificity\": 0.9999977360487677, \"npv\": 0.9998652154041936, \"accuracy\": 0.9998629661622939, \"f1\": 0.6002372046346136, \"f2\": 0.48723157348278895, \"f0_5\": 0.7814918331300178, \"p4\": 0.7501660046142071, \"phi\": 0.6507825012575248}, {\"truth_threshold\": -1.1199999749660492, \"match_probability\": 0.3151125104456104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131571.0, \"tn\": 1278734900.0, \"fp\": 2892.0, \"fn\": 172390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43285487282908003, \"tn_rate\": 0.9999977383948312, \"fp_rate\": 2.26160516885701e-06, \"fn_rate\": 0.5671451271709199, \"precision\": 0.978492224626849, \"recall\": 0.43285487282908003, \"specificity\": 0.9999977383948312, \"npv\": 0.9998652052409522, \"accuracy\": 0.9998629583439408, \"f1\": 0.6001998065799318, \"f2\": 0.487189209564936, \"f0_5\": 0.7814740328315196, \"p4\": 0.7501367957640734, \"phi\": 0.6507569194627071}, {\"truth_threshold\": -1.099999975413084, \"match_probability\": 0.318112003878512, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131568.0, \"tn\": 1278734903.0, \"fp\": 2889.0, \"fn\": 172393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4328450031418504, \"tn_rate\": 0.9999977407408946, \"fp_rate\": 2.2592591054038385e-06, \"fn_rate\": 0.5671549968581495, \"precision\": 0.9785135768312546, \"recall\": 0.4328450031418504, \"specificity\": 0.9999977407408946, \"npv\": 0.9998652028958321, \"accuracy\": 0.9998629583439408, \"f1\": 0.6001943350866068, \"f2\": 0.4871802657333439, \"f0_5\": 0.7814784940169093, \"p4\": 0.7501325224324736, \"phi\": 0.650756602405019}, {\"truth_threshold\": -1.0799999758601189, \"match_probability\": 0.3211266617690227, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131555.0, \"tn\": 1278734927.0, \"fp\": 2865.0, \"fn\": 172406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4328022344971888, \"tn_rate\": 0.9999977595094022, \"fp_rate\": 2.2404905977784695e-06, \"fn_rate\": 0.5671977655028112, \"precision\": 0.9786862074096117, \"recall\": 0.4328022344971888, \"specificity\": 0.9999977595094022, \"npv\": 0.9998651927348047, \"accuracy\": 0.9998629669441291, \"f1\": 0.6001856832298845, \"f2\": 0.4871454767364012, \"f0_5\": 0.7815386845460238, \"p4\": 0.7501257663324039, \"phi\": 0.6507818683073805}, {\"truth_threshold\": -1.0599999763071537, \"match_probability\": 0.32415630754546576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131548.0, \"tn\": 1278734968.0, \"fp\": 2824.0, \"fn\": 172413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4327792052269864, \"tn_rate\": 0.9999977915722694, \"fp_rate\": 2.20842773058513e-06, \"fn_rate\": 0.5672207947730137, \"precision\": 0.9789837168457715, \"recall\": 0.4327792052269864, \"specificity\": 0.9999977915722694, \"npv\": 0.9998651872664421, \"accuracy\": 0.9998629935265295, \"f1\": 0.600219467847504, \"f2\": 0.4871368729151484, \"f0_5\": 0.7816754194253008, \"p4\": 0.7501521562672946, \"phi\": 0.6508634949372459}, {\"truth_threshold\": -1.0399999767541885, \"match_probability\": 0.327200759981648, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131524.0, \"tn\": 1278734975.0, \"fp\": 2817.0, \"fn\": 172437.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43270024772914945, \"tn_rate\": 0.9999977970464174, \"fp_rate\": 2.2029535825277306e-06, \"fn_rate\": 0.5672997522708505, \"precision\": 0.9790309734183905, \"recall\": 0.43270024772914945, \"specificity\": 0.9999977970464174, \"npv\": 0.9998651685036914, \"accuracy\": 0.9998629802353294, \"f1\": 0.6001524063317074, \"f2\": 0.4870591807789303, \"f0_5\": 0.7816479957210353, \"p4\": 0.7500997774551874, \"phi\": 0.6508198265634129}, {\"truth_threshold\": -1.0199999772012234, \"match_probability\": 0.3302598332164518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131483.0, \"tn\": 1278735035.0, \"fp\": 2757.0, \"fn\": 172478.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4325653620036781, \"tn_rate\": 0.9999978439676865, \"fp_rate\": 2.156032313464307e-06, \"fn_rate\": 0.5674346379963219, \"precision\": 0.979462157330155, \"recall\": 0.4325653620036781, \"specificity\": 0.9999978439676865, \"npv\": 0.9998651364557274, \"accuracy\": 0.9998629950902002, \"f1\": 0.600103605423082, \"f2\": 0.4869437753502745, \"f0_5\": 0.7817797391193703, \"p4\": 0.7500616618950251, \"phi\": 0.6508617010512154}, {\"truth_threshold\": -0.9999999776482582, \"match_probability\": 0.3333333367762326, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131472.0, \"tn\": 1278735042.0, \"fp\": 2750.0, \"fn\": 172489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4325291731505029, \"tn_rate\": 0.9999978494418346, \"fp_rate\": 2.150558165406908e-06, \"fn_rate\": 0.5674708268494971, \"precision\": 0.9795115554827077, \"recall\": 0.4325291731505029, \"specificity\": 0.9999978494418346, \"npv\": 0.9998651278565346, \"accuracy\": 0.9998629919628589, \"f1\": 0.6000780495820239, \"f2\": 0.48690952886747757, \"f0_5\": 0.7817812710724518, \"p4\": 0.750041699246895, \"phi\": 0.650850889867319}, {\"truth_threshold\": -0.979999978095293, \"match_probability\": 0.3364210756000459, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131468.0, \"tn\": 1278735043.0, \"fp\": 2749.0, \"fn\": 172493.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43251601356753006, \"tn_rate\": 0.9999978502238558, \"fp_rate\": 2.1497761442558505e-06, \"fn_rate\": 0.56748398643247, \"precision\": 0.9795182428455411, \"recall\": 0.43251601356753006, \"specificity\": 0.9999978502238558, \"npv\": 0.9998651247293925, \"accuracy\": 0.999862989617353, \"f1\": 0.6000666395848263, \"f2\": 0.48689651800918626, \"f0_5\": 0.7817760805110194, \"p4\": 0.750032786120777, \"phi\": 0.6508432103378305}, {\"truth_threshold\": -0.9599999785423279, \"match_probability\": 0.33952285006771876, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131463.0, \"tn\": 1278735066.0, \"fp\": 2726.0, \"fn\": 172498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.432499564088814, \"tn_rate\": 0.9999978682103422, \"fp_rate\": 2.1317896577815384e-06, \"fn_rate\": 0.5675004359111859, \"precision\": 0.9796853691435214, \"recall\": 0.432499564088814, \"specificity\": 0.9999978682103422, \"npv\": 0.9998651208227587, \"accuracy\": 0.9998630036903885, \"f1\": 0.6000821636425882, \"f2\": 0.48688809829093066, \"f0_5\": 0.7818504919015554, \"p4\": 0.7500449145198693, \"phi\": 0.6508863738916314}, {\"truth_threshold\": -0.9399999789893627, \"match_probability\": 0.34263845603078413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131452.0, \"tn\": 1278735082.0, \"fp\": 2710.0, \"fn\": 172509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43246337523563877, \"tn_rate\": 0.9999978807226806, \"fp_rate\": 2.1192773193646254e-06, \"fn_rate\": 0.5675366247643612, \"precision\": 0.9798005396460995, \"recall\": 0.43246337523563877, \"specificity\": 0.9999978807226806, \"npv\": 0.9998651122245157, \"accuracy\": 0.999863007599565, \"f1\": 0.6000689304145183, \"f2\": 0.48685709544994615, \"f0_5\": 0.7818855139547638, \"p4\": 0.7500345781180445, \"phi\": 0.6508974099097276}, {\"truth_threshold\": -0.9199999794363976, \"match_probability\": 0.34576768484629017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131434.0, \"tn\": 1278735089.0, \"fp\": 2703.0, \"fn\": 172527.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4324041571122611, \"tn_rate\": 0.9999978861968287, \"fp_rate\": 2.1138031713072262e-06, \"fn_rate\": 0.5675958428877389, \"precision\": 0.9798489603912418, \"recall\": 0.4324041571122611, \"specificity\": 0.9999978861968287, \"npv\": 0.9998650981526409, \"accuracy\": 0.9998629989993767, \"f1\": 0.6000209998676095, \"f2\": 0.48679944384402446, \"f0_5\": 0.781871461221712, \"p4\": 0.7499971351973267, \"phi\": 0.6508689274907937}, {\"truth_threshold\": -0.8999999798834324, \"match_probability\": 0.3489103234134934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131412.0, \"tn\": 1278735151.0, \"fp\": 2641.0, \"fn\": 172549.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4323317794059106, \"tn_rate\": 0.99999793468214, \"fp_rate\": 2.0653178599416885e-06, \"fn_rate\": 0.5676682205940894, \"precision\": 0.9802988370271459, \"recall\": 0.4323317794059106, \"specificity\": 0.99999793468214, \"npv\": 0.9998650809593218, \"accuracy\": 0.9998630302727889, \"f1\": 0.6000356152999676, \"f2\": 0.48674824819967744, \"f0_5\": 0.7820532199915969, \"p4\": 0.7500085569130149, \"phi\": 0.6509638902600613}, {\"truth_threshold\": -0.8799999803304672, \"match_probability\": 0.35206615421344434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131398.0, \"tn\": 1278735174.0, \"fp\": 2618.0, \"fn\": 172563.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43228572086550576, \"tn_rate\": 0.9999979526686266, \"fp_rate\": 2.0473313734673763e-06, \"fn_rate\": 0.5677142791344942, \"precision\": 0.9804650191021967, \"recall\": 0.43228572086550576, \"specificity\": 0.9999979526686266, \"npv\": 0.9998650700163838, \"accuracy\": 0.9998630373093067, \"f1\": 0.6000223756041984, \"f2\": 0.48670973286118563, \"f0_5\": 0.7821076753668046, \"p4\": 0.7499982152970519, \"phi\": 0.6509844024246842}, {\"truth_threshold\": -0.8599999807775021, \"match_probability\": 0.35523495535147065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131386.0, \"tn\": 1278735177.0, \"fp\": 2615.0, \"fn\": 172575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4322462421165873, \"tn_rate\": 0.99999795501469, \"fp_rate\": 2.044985310014205e-06, \"fn_rate\": 0.5677537578834126, \"precision\": 0.9804852202595503, \"recall\": 0.4322462421165873, \"specificity\": 0.99999795501469, \"npv\": 0.9998650606349597, \"accuracy\": 0.9998630302727889, \"f1\": 0.5999881268237883, \"f2\": 0.4866706918201719, \"f0_5\": 0.7820921109808147, \"p4\": 0.7499714589978925, \"phi\": 0.6509613813988274}, {\"truth_threshold\": -0.8399999812245369, \"match_probability\": 0.358416500602555, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131385.0, \"tn\": 1278735181.0, \"fp\": 2611.0, \"fn\": 172576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43224295222084413, \"tn_rate\": 0.9999979581427746, \"fp_rate\": 2.0418572254099767e-06, \"fn_rate\": 0.5677570477791559, \"precision\": 0.9805143437117526, \"recall\": 0.43224295222084413, \"specificity\": 0.9999979581427746, \"npv\": 0.99986505985357, \"accuracy\": 0.9998630326182948, \"f1\": 0.5999904100174218, \"f2\": 0.4866687903751556, \"f0_5\": 0.782104780670163, \"p4\": 0.7499732430051611, \"phi\": 0.6509685752006902}, {\"truth_threshold\": -0.8199999816715717, \"match_probability\": 0.3616105594596116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131372.0, \"tn\": 1278735202.0, \"fp\": 2590.0, \"fn\": 172589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43220018357618245, \"tn_rate\": 0.9999979745652188, \"fp_rate\": 2.0254347812377786e-06, \"fn_rate\": 0.5677998164238175, \"precision\": 0.980666159060032, \"recall\": 0.43220018357618245, \"specificity\": 0.9999979745652188, \"npv\": 0.9998650496922339, \"accuracy\": 0.9998630388729772, \"f1\": 0.5999776216366804, \"f2\": 0.4866328939121622, \"f0_5\": 0.7821540374061244, \"p4\": 0.749963253276355, \"phi\": 0.6509867759201343}, {\"truth_threshold\": -0.7999999821186066, \"match_probability\": 0.36481689718465177, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131352.0, \"tn\": 1278735208.0, \"fp\": 2584.0, \"fn\": 172609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4321343856613184, \"tn_rate\": 0.9999979792573457, \"fp_rate\": 2.0207426543314363e-06, \"fn_rate\": 0.5678656143386817, \"precision\": 0.9807072034404491, \"recall\": 0.4321343856613184, \"specificity\": 0.9999979792573457, \"npv\": 0.9998650340566336, \"accuracy\": 0.999863027927283, \"f1\": 0.5999218994421063, \"f2\": 0.4865681814814266, \"f0_5\": 0.7821318201034887, \"p4\": 0.7499197182750187, \"phi\": 0.6509508429698823}, {\"truth_threshold\": -0.7799999825656414, \"match_probability\": 0.3680352748628328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131346.0, \"tn\": 1278735234.0, \"fp\": 2558.0, \"fn\": 172615.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4321146462868592, \"tn_rate\": 0.9999979995898955, \"fp_rate\": 2.0004101044039527e-06, \"fn_rate\": 0.5678853537131409, \"precision\": 0.9808967618592425, \"recall\": 0.4321146462868592, \"specificity\": 0.9999979995898955, \"npv\": 0.9998650293685077, \"accuracy\": 0.9998630435639891, \"f1\": 0.5999383371587133, \"f2\": 0.48655749073160326, \"f0_5\": 0.782215329862538, \"p4\": 0.749932562902636, \"phi\": 0.6509989036720788}, {\"truth_threshold\": -0.7599999830126762, \"match_probability\": 0.37126544945937895, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131341.0, \"tn\": 1278735234.0, \"fp\": 2558.0, \"fn\": 172620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43209819680814315, \"tn_rate\": 0.9999979995898955, \"fp_rate\": 2.0004101044039527e-06, \"fn_rate\": 0.5679018031918569, \"precision\": 0.9808960485141786, \"recall\": 0.43209819680814315, \"specificity\": 0.9999979995898955, \"npv\": 0.9998650254594496, \"accuracy\": 0.9998630396548126, \"f1\": 0.5999223496094642, \"f2\": 0.48654077109494176, \"f0_5\": 0.7822041862553704, \"p4\": 0.7499200716340556, \"phi\": 0.6509862745398403}, {\"truth_threshold\": -0.7399999834597111, \"match_probability\": 0.3745071738793591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131325.0, \"tn\": 1278735237.0, \"fp\": 2555.0, \"fn\": 172636.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43204555847625187, \"tn_rate\": 0.999998001935959, \"fp_rate\": 1.9980640409507818e-06, \"fn_rate\": 0.5679544415237481, \"precision\": 0.9809157454436809, \"recall\": 0.43204555847625187, \"specificity\": 0.999998001935959, \"npv\": 0.9998650129507803, \"accuracy\": 0.9998630294909536, \"f1\": 0.5998752971969277, \"f2\": 0.4864883487290735, \"f0_5\": 0.7821797038884739, \"p4\": 0.7498833077465433, \"phi\": 0.6509531556421948}, {\"truth_threshold\": -0.7199999839067459, \"match_probability\": 0.3777601970303052, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131303.0, \"tn\": 1278735243.0, \"fp\": 2549.0, \"fn\": 172658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4319731807699014, \"tn_rate\": 0.9999980066280859, \"fp_rate\": 1.9933719140444394e-06, \"fn_rate\": 0.5680268192300986, \"precision\": 0.9809565789080477, \"recall\": 0.4319731807699014, \"specificity\": 0.9999980066280859, \"npv\": 0.9998649957515588, \"accuracy\": 0.9998630169815887, \"f1\": 0.5998131622405, \"f2\": 0.48641694129641044, \"f0_5\": 0.782153022091595, \"p4\": 0.7498347560937555, \"phi\": 0.6509121755131594}, {\"truth_threshold\": -0.6999999843537807, \"match_probability\": 0.3810242638876482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131289.0, \"tn\": 1278735252.0, \"fp\": 2540.0, \"fn\": 172672.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43192712222949653, \"tn_rate\": 0.9999980136662763, \"fp_rate\": 1.9863337236849256e-06, \"fn_rate\": 0.5680728777705034, \"precision\": 0.9810205560827623, \"recall\": 0.43192712222949653, \"specificity\": 0.9999980136662763, \"npv\": 0.999864984807147, \"accuracy\": 0.9998630130724122, \"f1\": 0.5997807167820188, \"f2\": 0.4863733659930961, \"f0_5\": 0.782155355144964, \"p4\": 0.7498094023970793, \"phi\": 0.6508987022164606}, {\"truth_threshold\": -0.6799999848008156, \"match_probability\": 0.38429911556295054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131286.0, \"tn\": 1278735258.0, \"fp\": 2534.0, \"fn\": 172675.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4319172525422669, \"tn_rate\": 0.9999980183584032, \"fp_rate\": 1.9816415967785833e-06, \"fn_rate\": 0.568082747457733, \"precision\": 0.9810641159766851, \"recall\": 0.4319172525422669, \"specificity\": 0.9999980183584032, \"npv\": 0.9998649824623459, \"accuracy\": 0.9998630154179181, \"f1\": 0.5997793417256574, \"f2\": 0.4863654954121915, \"f0_5\": 0.7821710331120619, \"p4\": 0.7498083282238892, \"phi\": 0.6509057207358406}, {\"truth_threshold\": -0.6599999852478504, \"match_probability\": 0.38758448937490547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131270.0, \"tn\": 1278735281.0, \"fp\": 2511.0, \"fn\": 172691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4318646142103757, \"tn_rate\": 0.9999980363448897, \"fp_rate\": 1.963655110304271e-06, \"fn_rate\": 0.5681353857896243, \"precision\": 0.981230518534022, \"recall\": 0.4318646142103757, \"specificity\": 0.9999980363448897, \"npv\": 0.9998649699557898, \"accuracy\": 0.9998630208907653, \"f1\": 0.5997596757907626, \"f2\": 0.48632027415022694, \"f0_5\": 0.7822211098994738, \"p4\": 0.7497929613438666, \"phi\": 0.6509212687468607}, {\"truth_threshold\": -0.6399999856948853, \"match_probability\": 0.3908801189230734, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131258.0, \"tn\": 1278735290.0, \"fp\": 2502.0, \"fn\": 172703.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43182513546145723, \"tn_rate\": 0.9999980433830801, \"fp_rate\": 1.9566169199447574e-06, \"fn_rate\": 0.5681748645385428, \"precision\": 0.9812948564593301, \"recall\": 0.43182513546145723, \"specificity\": 0.9999980433830801, \"npv\": 0.9998649605750021, \"accuracy\": 0.9998630185452593, \"f1\": 0.5997336202741015, \"f2\": 0.48628338386667497, \"f0_5\": 0.782227911528115, \"p4\": 0.7497725997397506, \"phi\": 0.6509128598716497}, {\"truth_threshold\": -0.6199999861419201, \"match_probability\": 0.39418573416432234, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131237.0, \"tn\": 1278735302.0, \"fp\": 2490.0, \"fn\": 172724.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43175604765084996, \"tn_rate\": 0.9999980527673339, \"fp_rate\": 1.9472326661320726e-06, \"fn_rate\": 0.56824395234915, \"precision\": 0.9813799756219761, \"recall\": 0.43175604765084996, \"specificity\": 0.9999980527673339, \"npv\": 0.9998649441582284, \"accuracy\": 0.9998630115087416, \"f1\": 0.5996828791285116, \"f2\": 0.48621747207075433, \"f0_5\": 0.7822258302547835, \"p4\": 0.7497329448069904, \"phi\": 0.6508890209779353}, {\"truth_threshold\": -0.5999999865889549, \"match_probability\": 0.39750106149193387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131230.0, \"tn\": 1278735306.0, \"fp\": 2486.0, \"fn\": 172731.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43173301838064754, \"tn_rate\": 0.9999980558954185, \"fp_rate\": 1.9441045815278444e-06, \"fn_rate\": 0.5682669816193525, \"precision\": 0.9814083580125041, \"recall\": 0.43173301838064754, \"specificity\": 0.9999980558954185, \"npv\": 0.9998649386859706, \"accuracy\": 0.9998630091632357, \"f1\": 0.5996659637129664, \"f2\": 0.48619550075580187, \"f0_5\": 0.782225136351444, \"p4\": 0.7497197246081794, \"phi\": 0.6508810755752923}, {\"truth_threshold\": -0.5799999870359898, \"match_probability\": 0.40082582381733545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131200.0, \"tn\": 1278735313.0, \"fp\": 2479.0, \"fn\": 172761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4316343215083514, \"tn_rate\": 0.9999980613695665, \"fp_rate\": 1.938630433470445e-06, \"fn_rate\": 0.5683656784916487, \"precision\": 0.981455576418136, \"recall\": 0.4316343215083514, \"specificity\": 0.9999980613695665, \"npv\": 0.9998649152323672, \"accuracy\": 0.9998629911810236, \"f1\": 0.599579563111233, \"f2\": 0.48609768043968127, \"f0_5\": 0.7821843212583629, \"p4\": 0.7496521932388772, \"phi\": 0.650822327657892}, {\"truth_threshold\": -0.5599999874830246, \"match_probability\": 0.4041597406544148, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131195.0, \"tn\": 1278735319.0, \"fp\": 2473.0, \"fn\": 172766.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43161787202963536, \"tn_rate\": 0.9999980660616934, \"fp_rate\": 1.933938306564103e-06, \"fn_rate\": 0.5683821279703646, \"precision\": 0.9814989376664572, \"recall\": 0.43161787202963536, \"specificity\": 0.9999980660616934, \"npv\": 0.999864911323944, \"accuracy\": 0.9998629919628589, \"f1\": 0.5995717834055787, \"f2\": 0.4860831174528274, \"f0_5\": 0.7821955491854006, \"p4\": 0.7496461125411059, \"phi\": 0.6508243067763443}, {\"truth_threshold\": -0.5399999879300594, \"match_probability\": 0.407502528206371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131168.0, \"tn\": 1278735323.0, \"fp\": 2469.0, \"fn\": 172793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4315290448445689, \"tn_rate\": 0.9999980691897781, \"fp_rate\": 1.9308102219598746e-06, \"fn_rate\": 0.5684709551554311, \"precision\": 0.9815245777741194, \"recall\": 0.4315290448445689, \"specificity\": 0.9999980691897781, \"npv\": 0.9998648902154594, \"accuracy\": 0.9998629739806469, \"f1\": 0.5994908569051961, \"f2\": 0.4859942451950046, \"f0_5\": 0.7821502214048984, \"p4\": 0.7495828523794961, \"phi\": 0.6507658295156915}, {\"truth_threshold\": -0.5199999883770943, \"match_probability\": 0.41085389945505063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131159.0, \"tn\": 1278735335.0, \"fp\": 2457.0, \"fn\": 172802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43149943578288, \"tn_rate\": 0.9999980785740319, \"fp_rate\": 1.92142596814719e-06, \"fn_rate\": 0.5685005642171199, \"precision\": 0.9816114836546521, \"recall\": 0.43149943578288, \"specificity\": 0.9999980785740319, \"npv\": 0.999864883180425, \"accuracy\": 0.9998629763261528, \"f1\": 0.5994784917854458, \"f2\": 0.4859684614586575, \"f0_5\": 0.7821749112920059, \"p4\": 0.7495731867302289, \"phi\": 0.6507723201622734}, {\"truth_threshold\": -0.4999999888241291, \"match_probability\": 0.4142135642527169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131153.0, \"tn\": 1278735337.0, \"fp\": 2455.0, \"fn\": 172808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4314796964084208, \"tn_rate\": 0.9999980801380741, \"fp_rate\": 1.9198619258450758e-06, \"fn_rate\": 0.5685203035915792, \"precision\": 0.9816253517753428, \"recall\": 0.4314796964084208, \"specificity\": 0.9999980801380741, \"npv\": 0.9998648784897683, \"accuracy\": 0.9998629731988116, \"f1\": 0.5994620277030595, \"f2\": 0.48594911119476647, \"f0_5\": 0.7821689828040072, \"p4\": 0.7495603158661518, \"phi\": 0.6507620319724389}, {\"truth_threshold\": -0.47999998927116394, \"match_probability\": 0.41758122941619635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131136.0, \"tn\": 1278735342.0, \"fp\": 2450.0, \"fn\": 172825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43142376818078637, \"tn_rate\": 0.9999980840481799, \"fp_rate\": 1.9159518200897907e-06, \"fn_rate\": 0.5685762318192137, \"precision\": 0.9816597547647209, \"recall\": 0.43142376818078637, \"specificity\": 0.9999980840481799, \"npv\": 0.9998648651995042, \"accuracy\": 0.999862963816788, \"f1\": 0.5994144629034138, \"f2\": 0.4858940441519753, \"f0_5\": 0.7821496949201067, \"p4\": 0.7495231303513317, \"phi\": 0.650731257550533}, {\"truth_threshold\": -0.4599999897181988, \"match_probability\": 0.4209565988233432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131126.0, \"tn\": 1278735348.0, \"fp\": 2444.0, \"fn\": 172835.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4313908692233543, \"tn_rate\": 0.9999980887403068, \"fp_rate\": 1.9112596931834483e-06, \"fn_rate\": 0.5686091307766457, \"precision\": 0.98170247810137, \"recall\": 0.4313908692233543, \"specificity\": 0.9999980887403068, \"npv\": 0.9998648573820252, \"accuracy\": 0.9998629606894467, \"f1\": 0.5993906717466877, \"f2\": 0.4858627522761732, \"f0_5\": 0.7821497636121354, \"p4\": 0.7495045301381228, \"phi\": 0.6507206082685174}, {\"truth_threshold\": -0.4399999901652336, \"match_probability\": 0.4243393735117586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131117.0, \"tn\": 1278735350.0, \"fp\": 2442.0, \"fn\": 172844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4313612601616655, \"tn_rate\": 0.9999980903043492, \"fp_rate\": 1.909695650881334e-06, \"fn_rate\": 0.5686387398383346, \"precision\": 0.9817159457617981, \"recall\": 0.4313612601616655, \"specificity\": 0.9999980903043492, \"npv\": 0.999864850345935, \"accuracy\": 0.9998629552165995, \"f1\": 0.5993646004754069, \"f2\": 0.4858333648287428, \"f0_5\": 0.7821371348262998, \"p4\": 0.7494841463810046, \"phi\": 0.6507027390744142}, {\"truth_threshold\": -0.41999999061226845, \"match_probability\": 0.4277292517797018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131106.0, \"tn\": 1278735359.0, \"fp\": 2433.0, \"fn\": 172855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43132507130849024, \"tn_rate\": 0.9999980973425395, \"fp_rate\": 1.9026574605218206e-06, \"fn_rate\": 0.5686749286915098, \"precision\": 0.9817806034192258, \"recall\": 0.43132507130849024, \"specificity\": 0.9999980973425395, \"npv\": 0.9998648417469621, \"accuracy\": 0.999862953652929, \"f1\": 0.5993417142857143, \"f2\": 0.485799806281834, \"f0_5\": 0.7821461681364297, \"p4\": 0.7494662527794248, \"phi\": 0.6506968755887267}, {\"truth_threshold\": -0.3999999910593033, \"match_probability\": 0.43112592928912336, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131098.0, \"tn\": 1278735359.0, \"fp\": 2433.0, \"fn\": 172863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4312987521425446, \"tn_rate\": 0.9999980973425395, \"fp_rate\": 1.9026574605218206e-06, \"fn_rate\": 0.5687012478574553, \"precision\": 0.9817795118736473, \"recall\": 0.4312987521425446, \"specificity\": 0.9999980973425395, \"npv\": 0.9998648354924721, \"accuracy\": 0.9998629473982465, \"f1\": 0.5993161017801468, \"f2\": 0.4857730430754979, \"f0_5\": 0.7821283044082641, \"p4\": 0.7494462263636108, \"phi\": 0.6506766588205304}, {\"truth_threshold\": -0.3799999915063381, \"match_probability\": 0.43452909917075166, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131087.0, \"tn\": 1278735360.0, \"fp\": 2432.0, \"fn\": 172874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43126256328936935, \"tn_rate\": 0.9999980981245606, \"fp_rate\": 1.9018754393707636e-06, \"fn_rate\": 0.5687374367106306, \"precision\": 0.981785363880796, \"recall\": 0.43126256328936935, \"specificity\": 0.9999980981245606, \"npv\": 0.9998648268926541, \"accuracy\": 0.9998629395798935, \"f1\": 0.5992822529029899, \"f2\": 0.4857366031231033, \"f0_5\": 0.7821074725817595, \"p4\": 0.7494197590085975, \"phi\": 0.6506512972015568}, {\"truth_threshold\": -0.35999999195337296, \"match_probability\": 0.4379384521311571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131073.0, \"tn\": 1278735364.0, \"fp\": 2428.0, \"fn\": 172888.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4312165047489645, \"tn_rate\": 0.9999981012526452, \"fp_rate\": 1.8987473547665353e-06, \"fn_rate\": 0.5687834952510354, \"precision\": 0.9818128703155782, \"recall\": 0.4312165047489645, \"specificity\": 0.9999981012526452, \"npv\": 0.9998648159477198, \"accuracy\": 0.9998629317615404, \"f1\": 0.599242905669521, \"f2\": 0.485691205733152, \"f0_5\": 0.7820911374580084, \"p4\": 0.7493889911100862, \"phi\": 0.6506256655732233}, {\"truth_threshold\": -0.3399999924004078, \"match_probability\": 0.441353676561721, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131056.0, \"tn\": 1278735373.0, \"fp\": 2419.0, \"fn\": 172905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43116057652133005, \"tn_rate\": 0.9999981082908356, \"fp_rate\": 1.8917091644070218e-06, \"fn_rate\": 0.56883942347867, \"precision\": 0.9818767559468066, \"recall\": 0.43116057652133005, \"specificity\": 0.9999981082908356, \"npv\": 0.9998648026578807, \"accuracy\": 0.999862925506858, \"f1\": 0.5992007973737873, \"f2\": 0.4856375697666749, \"f0_5\": 0.78208676618198, \"p4\": 0.7493560627955528, \"phi\": 0.6506046412633731}, {\"truth_threshold\": -0.3199999928474426, \"match_probability\": 0.44477445864942694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131043.0, \"tn\": 1278735374.0, \"fp\": 2418.0, \"fn\": 172918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43111780787666837, \"tn_rate\": 0.9999981090728567, \"fp_rate\": 1.8909271432559647e-06, \"fn_rate\": 0.5688821921233316, \"precision\": 0.9818823476521231, \"recall\": 0.43111780787666837, \"specificity\": 0.9999981090728567, \"npv\": 0.999864792494441, \"accuracy\": 0.9998629161248342, \"f1\": 0.5991605360498558, \"f2\": 0.4855944356539107, \"f0_5\": 0.7820614582152171, \"p4\": 0.7493245766973291, \"phi\": 0.6505742221582868}, {\"truth_threshold\": -0.29999999329447746, \"match_probability\": 0.44820048248939814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131028.0, \"tn\": 1278735379.0, \"fp\": 2413.0, \"fn\": 172933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43106845944052036, \"tn_rate\": 0.9999981129829625, \"fp_rate\": 1.8870170375006794e-06, \"fn_rate\": 0.5689315405594797, \"precision\": 0.9819171019401833, \"recall\": 0.43106845944052036, \"specificity\": 0.9999981129829625, \"npv\": 0.9998647807678022, \"accuracy\": 0.9998629083064812, \"f1\": 0.5991193455905551, \"f2\": 0.4855460484627043, \"f0_5\": 0.7820466143424155, \"p4\": 0.7492923625844703, \"phi\": 0.6505485001492242}, {\"truth_threshold\": -0.2799999937415123, \"match_probability\": 0.45163143019909374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131006.0, \"tn\": 1278735387.0, \"fp\": 2405.0, \"fn\": 172955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43099608173416987, \"tn_rate\": 0.9999981192391317, \"fp_rate\": 1.880760868292223e-06, \"fn_rate\": 0.5690039182658302, \"precision\": 0.9819730007270765, \"recall\": 0.43099608173416987, \"specificity\": 0.9999981192391317, \"npv\": 0.9998647635688032, \"accuracy\": 0.9998628973607869, \"f1\": 0.5990598392215323, \"f2\": 0.48547531786059717, \"f0_5\": 0.782027327917097, \"p4\": 0.7492458211376726, \"phi\": 0.6505124001186413}, {\"truth_threshold\": -0.25999999418854713, \"match_probability\": 0.45506698203407975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130984.0, \"tn\": 1278735406.0, \"fp\": 2386.0, \"fn\": 172977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4309237040278194, \"tn_rate\": 0.9999981340975336, \"fp_rate\": 1.8659024664221388e-06, \"fn_rate\": 0.5690762959721807, \"precision\": 0.9821099197720626, \"recall\": 0.4309237040278194, \"specificity\": 0.9999981340975336, \"npv\": 0.9998647463709681, \"accuracy\": 0.999862895015281, \"f1\": 0.5990153910882147, \"f2\": 0.485408541565682, \"f0_5\": 0.7820491234606378, \"p4\": 0.7492110556792675, \"phi\": 0.65050313460189}, {\"truth_threshold\": -0.23999999463558197, \"match_probability\": 0.45850681650528874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130949.0, \"tn\": 1278735450.0, \"fp\": 2342.0, \"fn\": 173012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4308085576768072, \"tn_rate\": 0.9999981685064642, \"fp_rate\": 1.8314935357756284e-06, \"fn_rate\": 0.5691914423231927, \"precision\": 0.9824294213412759, \"recall\": 0.4308085576768072, \"specificity\": 0.9999981685064642, \"npv\": 0.9998647190122353, \"accuracy\": 0.9998629020517987, \"f1\": 0.5989635267534511, \"f2\": 0.48530725242470174, \"f0_5\": 0.7821352844557264, \"p4\": 0.7491704885088718, \"phi\": 0.6505220386387437}, {\"truth_threshold\": -0.2199999950826168, \"match_probability\": 0.4619506104976753, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130904.0, \"tn\": 1278735456.0, \"fp\": 2336.0, \"fn\": 173057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43066051236836306, \"tn_rate\": 0.9999981731985911, \"fp_rate\": 1.826801408869286e-06, \"fn_rate\": 0.569339487631637, \"precision\": 0.9824677274091864, \"recall\": 0.43066051236836306, \"specificity\": 0.9999981731985911, \"npv\": 0.9998646838313758, \"accuracy\": 0.9998628715602218, \"f1\": 0.59882754156555, \"f2\": 0.4851588188726573, \"f0_5\": 0.7820570878254937, \"p4\": 0.7490641044438634, \"phi\": 0.6504229278051914}, {\"truth_threshold\": -0.19999999552965164, \"match_probability\": 0.4653980393901789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130898.0, \"tn\": 1278735461.0, \"fp\": 2331.0, \"fn\": 173063.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4306407729939038, \"tn_rate\": 0.9999981771086969, \"fp_rate\": 1.8228913031140007e-06, \"fn_rate\": 0.5693592270060962, \"precision\": 0.982503809230723, \"recall\": 0.4306407729939038, \"specificity\": 0.9999981771086969, \"npv\": 0.9998646791410392, \"accuracy\": 0.9998628707783865, \"f1\": 0.598815160456552, \"f2\": 0.4851405372429809, \"f0_5\": 0.7820623580287187, \"p4\": 0.7490544178237425, \"phi\": 0.6504199677487574}, {\"truth_threshold\": -0.17999999597668648, \"match_probability\": 0.4688487771768984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130882.0, \"tn\": 1278735465.0, \"fp\": 2327.0, \"fn\": 173079.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43058813466201257, \"tn_rate\": 0.9999981802367814, \"fp_rate\": 1.8197632185097725e-06, \"fn_rate\": 0.5694118653379875, \"precision\": 0.9825312103536548, \"recall\": 0.43058813466201257, \"specificity\": 0.9999981802367814, \"npv\": 0.9998646666324875, \"accuracy\": 0.9998628613963628, \"f1\": 0.598769357458197, \"f2\": 0.4850884286977606, \"f0_5\": 0.7820415226154014, \"p4\": 0.7490185806731962, \"phi\": 0.6503892837702909}, {\"truth_threshold\": -0.1599999964237213, \"match_probability\": 0.4723024965893847, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130860.0, \"tn\": 1278735466.0, \"fp\": 2326.0, \"fn\": 173101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4305157569556621, \"tn_rate\": 0.9999981810188027, \"fp_rate\": 1.8189811973587154e-06, \"fn_rate\": 0.569484243044338, \"precision\": 0.9825357019506554, \"recall\": 0.4305157569556621, \"specificity\": 0.9999981810188027, \"npv\": 0.9998646494327534, \"accuracy\": 0.9998628449778214, \"f1\": 0.5987002083967178, \"f2\": 0.48501515904019926, \"f0_5\": 0.7819960440059519, \"p4\": 0.7489644729058711, \"phi\": 0.6503361007521951}, {\"truth_threshold\": -0.13999999687075615, \"match_probability\": 0.4757588692199541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130827.0, \"tn\": 1278735481.0, \"fp\": 2311.0, \"fn\": 173134.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.43040719039613634, \"tn_rate\": 0.9999981927491199, \"fp_rate\": 1.8072508800928595e-06, \"fn_rate\": 0.5695928096038636, \"precision\": 0.9826420706334781, \"recall\": 0.43040719039613634, \"specificity\": 0.9999981927491199, \"npv\": 0.9998646236345824, \"accuracy\": 0.999862830904786, \"f1\": 0.5986149590824962, \"f2\": 0.48491010258105743, \"f0_5\": 0.7819782836608636, \"p4\": 0.7488977614340914, \"phi\": 0.6502892973048409}, {\"truth_threshold\": -0.11999999731779099, \"match_probability\": 0.47921756564592466, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130820.0, \"tn\": 1278735493.0, \"fp\": 2299.0, \"fn\": 173141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4303841611259339, \"tn_rate\": 0.9999982021333738, \"fp_rate\": 1.7978666262801748e-06, \"fn_rate\": 0.5696158388740661, \"precision\": 0.9827297380539217, \"recall\": 0.4303841611259339, \"specificity\": 0.9999982021333738, \"npv\": 0.9998646181631767, \"accuracy\": 0.9998628348139624, \"f1\": 0.59860895030658, \"f2\": 0.48489098663195357, \"f0_5\": 0.7820074912994045, \"p4\": 0.7488930597123282, \"phi\": 0.650300915848942}, {\"truth_threshold\": -0.09999999776482582, \"match_probability\": 0.48267825555467603, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130795.0, \"tn\": 1278735498.0, \"fp\": 2294.0, \"fn\": 173166.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4303019137323538, \"tn_rate\": 0.9999982060434794, \"fp_rate\": 1.7939565205248895e-06, \"fn_rate\": 0.5696980862676462, \"precision\": 0.9827634139560745, \"recall\": 0.4303019137323538, \"specificity\": 0.9999982060434794, \"npv\": 0.9998645986184358, \"accuracy\": 0.9998628191772564, \"f1\": 0.598535636654845, \"f2\": 0.48480910467754884, \"f0_5\": 0.781970233774992, \"p4\": 0.748835681822777, \"phi\": 0.650249914652744}, {\"truth_threshold\": -0.07999999821186066, \"match_probability\": 0.4861406078694332, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130768.0, \"tn\": 1278735505.0, \"fp\": 2287.0, \"fn\": 173193.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4302130865472873, \"tn_rate\": 0.9999982115176276, \"fp_rate\": 1.78848237246749e-06, \"fn_rate\": 0.5697869134527127, \"precision\": 0.9828116192551952, \"recall\": 0.4302130865472873, \"specificity\": 0.9999982115176276, \"npv\": 0.999864577510286, \"accuracy\": 0.9998628035405502, \"f1\": 0.5984586376700166, \"f2\": 0.48472124302857367, \"f0_5\": 0.7819359684087536, \"p4\": 0.74877541410367, \"phi\": 0.6501987405309022}, {\"truth_threshold\": -0.05999999865889549, \"match_probability\": 0.489604290875671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130735.0, \"tn\": 1278735514.0, \"fp\": 2278.0, \"fn\": 173226.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4301045199877616, \"tn_rate\": 0.9999982185558179, \"fp_rate\": 1.7814441821079768e-06, \"fn_rate\": 0.5698954800122384, \"precision\": 0.9828738544352807, \"recall\": 0.4301045199877616, \"specificity\": 0.9999982185558179, \"npv\": 0.9998645517114849, \"accuracy\": 0.9998627847765029, \"f1\": 0.5983651201215633, \"f2\": 0.4846140102323671, \"f0_5\": 0.7818957360710898, \"p4\": 0.7487022093971295, \"phi\": 0.6501372776234849}, {\"truth_threshold\": -0.03999999910593033, \"match_probability\": 0.4930689723480393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130711.0, \"tn\": 1278735518.0, \"fp\": 2274.0, \"fn\": 173250.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4300255624899247, \"tn_rate\": 0.9999982216839025, \"fp_rate\": 1.7783160975037485e-06, \"fn_rate\": 0.5699744375100753, \"precision\": 0.9829003271045607, \"recall\": 0.4300255624899247, \"specificity\": 0.9999982216839025, \"npv\": 0.9998645329484519, \"accuracy\": 0.9998627691397968, \"f1\": 0.5982936106521172, \"f2\": 0.4845351041533063, \"f0_5\": 0.7818569423891106, \"p4\": 0.7486462264597024, \"phi\": 0.6500863512434776}, {\"truth_threshold\": -0.019999999552965164, \"match_probability\": 0.49653431967770384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130676.0, \"tn\": 1278735536.0, \"fp\": 2256.0, \"fn\": 173285.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42991041613891257, \"tn_rate\": 0.9999982357602832, \"fp_rate\": 1.7642397167847214e-06, \"fn_rate\": 0.5700895838610874, \"precision\": 0.9830289170402913, \"recall\": 0.42991041613891257, \"specificity\": 0.9999982357602832, \"npv\": 0.9998645055869858, \"accuracy\": 0.9998627558485966, \"f1\": 0.598205968051674, \"f2\": 0.4844243966381371, \"f0_5\": 0.7818458780718665, \"p4\": 0.7485776072974712, \"phi\": 0.6500418342555188}, {\"truth_threshold\": -0.0, \"match_probability\": 0.5, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130658.0, \"tn\": 1278735540.0, \"fp\": 2252.0, \"fn\": 173303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4298511980155349, \"tn_rate\": 0.9999982388883678, \"fp_rate\": 1.7611116321804932e-06, \"fn_rate\": 0.5701488019844652, \"precision\": 0.9830562034459409, \"recall\": 0.4298511980155349, \"specificity\": 0.9999982388883678, \"npv\": 0.9998644915148186, \"accuracy\": 0.9998627449029023, \"f1\": 0.5981536883885632, \"f2\": 0.4843655700001631, \"f0_5\": 0.7818205100281115, \"p4\": 0.7485366712938818, \"phi\": 0.6500060824715991}, {\"truth_threshold\": 0.019999999552965164, \"match_probability\": 0.5034656803222961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130627.0, \"tn\": 1278735544.0, \"fp\": 2248.0, \"fn\": 173334.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42974921124749554, \"tn_rate\": 0.9999982420164524, \"fp_rate\": 1.757983547576265e-06, \"fn_rate\": 0.5702507887525045, \"precision\": 0.9830818438381937, \"recall\": 0.42974921124749554, \"specificity\": 0.9999982420164524, \"npv\": 0.9998644672791145, \"accuracy\": 0.9998627237933491, \"f1\": 0.5980596837257003, \"f2\": 0.484263215688368, \"f0_5\": 0.7817659950614092, \"p4\": 0.7484630568583164, \"phi\": 0.6499374384491599}, {\"truth_threshold\": 0.03999999910593033, \"match_probability\": 0.5069310276519607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130599.0, \"tn\": 1278735546.0, \"fp\": 2246.0, \"fn\": 173362.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42965709416668585, \"tn_rate\": 0.9999982435804947, \"fp_rate\": 1.7564195052741508e-06, \"fn_rate\": 0.5703429058333142, \"precision\": 0.9830930783996387, \"recall\": 0.42965709416668585, \"specificity\": 0.9999982435804947, \"npv\": 0.9998644453886312, \"accuracy\": 0.9998627034656311, \"f1\": 0.5979725553220423, \"f2\": 0.48417018304442316, \"f0_5\": 0.7817107025753555, \"p4\": 0.7483948193365512, \"phi\": 0.6498714848909601}, {\"truth_threshold\": 0.05999999865889549, \"match_probability\": 0.5103957091243291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130577.0, \"tn\": 1278735549.0, \"fp\": 2243.0, \"fn\": 173384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42958471646033536, \"tn_rate\": 0.9999982459265582, \"fp_rate\": 1.7540734418209797e-06, \"fn_rate\": 0.5704152835396646, \"precision\": 0.9831124830597802, \"recall\": 0.42958471646033536, \"specificity\": 0.9999982459265582, \"npv\": 0.999864428189118, \"accuracy\": 0.9998626886107603, \"f1\": 0.5979060444479041, \"f2\": 0.4840975958429972, \"f0_5\": 0.7816725950953078, \"p4\": 0.7483427242072241, \"phi\": 0.6498231555525089}, {\"truth_threshold\": 0.07999999821186066, \"match_probability\": 0.5138593921305669, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130557.0, \"tn\": 1278735556.0, \"fp\": 2236.0, \"fn\": 173404.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4295189185454713, \"tn_rate\": 0.9999982514007062, \"fp_rate\": 1.7485992937635802e-06, \"fn_rate\": 0.5704810814545287, \"precision\": 0.9831617630447388, \"recall\": 0.4295189185454713, \"specificity\": 0.9999982514007062, \"npv\": 0.9998644125536504, \"accuracy\": 0.9998626784469014, \"f1\": 0.5978514220819958, \"f2\": 0.484033138642941, \"f0_5\": 0.7816539401508502, \"p4\": 0.7482999378811791, \"phi\": 0.6497896743762818}, {\"truth_threshold\": 0.09999999776482582, \"match_probability\": 0.517321744445324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130538.0, \"tn\": 1278735562.0, \"fp\": 2230.0, \"fn\": 173423.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4294564105263504, \"tn_rate\": 0.9999982560928331, \"fp_rate\": 1.7439071668572379e-06, \"fn_rate\": 0.5705435894736496, \"precision\": 0.983203784044348, \"recall\": 0.4294564105263504, \"specificity\": 0.9999982560928331, \"npv\": 0.9998643976998879, \"accuracy\": 0.9998626682830424, \"f1\": 0.5977986348513609, \"f2\": 0.48397166864895164, \"f0_5\": 0.7816337797428365, \"p4\": 0.748258586210502, \"phi\": 0.6497562760411767}, {\"truth_threshold\": 0.11999999731779099, \"match_probability\": 0.5207824343540752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130513.0, \"tn\": 1278735568.0, \"fp\": 2224.0, \"fn\": 173448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4293741631327703, \"tn_rate\": 0.99999826078496, \"fp_rate\": 1.7392150399508955e-06, \"fn_rate\": 0.5706258368672297, \"precision\": 0.9832450635467127, \"recall\": 0.4293741631327703, \"specificity\": 0.99999826078496, \"npv\": 0.9998643781552635, \"accuracy\": 0.9998626534281716, \"f1\": 0.5977265753449752, \"f2\": 0.4838901037460857, \"f0_5\": 0.7816001504355564, \"p4\": 0.7482021327651781, \"phi\": 0.649707691165792}, {\"truth_threshold\": 0.13999999687075615, \"match_probability\": 0.5242411307800459, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130490.0, \"tn\": 1278735581.0, \"fp\": 2211.0, \"fn\": 173471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4292984955306766, \"tn_rate\": 0.9999982709512351, \"fp_rate\": 1.7290487649871537e-06, \"fn_rate\": 0.5707015044693233, \"precision\": 0.983338482754463, \"recall\": 0.4292984955306766, \"specificity\": 0.9999982709512351, \"npv\": 0.9998643601750032, \"accuracy\": 0.9998626456098185, \"f1\": 0.5976705094558262, \"f2\": 0.4838177443096078, \"f0_5\": 0.7815972159829413, \"p4\": 0.7481582061712059, \"phi\": 0.64968130746193}, {\"truth_threshold\": 0.1599999964237213, \"match_probability\": 0.5276975034106154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130470.0, \"tn\": 1278735581.0, \"fp\": 2211.0, \"fn\": 173491.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42923269761581256, \"tn_rate\": 0.9999982709512351, \"fp_rate\": 1.7290487649871537e-06, \"fn_rate\": 0.5707673023841875, \"precision\": 0.9833359712392882, \"recall\": 0.42923269761581256, \"specificity\": 0.9999982709512351, \"npv\": 0.9998643445387961, \"accuracy\": 0.9998626299731124, \"f1\": 0.5976062769957997, \"f2\": 0.48375076472442113, \"f0_5\": 0.7815523221334995, \"p4\": 0.7481078764948065, \"phi\": 0.649630682647344}, {\"truth_threshold\": 0.17999999597668648, \"match_probability\": 0.5311512228231017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130463.0, \"tn\": 1278735584.0, \"fp\": 2208.0, \"fn\": 173498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42920966834561014, \"tn_rate\": 0.9999982732972985, \"fp_rate\": 1.7267027015339826e-06, \"fn_rate\": 0.5707903316543899, \"precision\": 0.9833573275244778, \"recall\": 0.42920966834561014, \"specificity\": 0.9999982732972985, \"npv\": 0.9998643390664419, \"accuracy\": 0.9998626268457712, \"f1\": 0.5975879001081001, \"f2\": 0.48372839753358327, \"f0_5\": 0.7815478436940256, \"p4\": 0.7480934766333579, \"phi\": 0.6496203104092412}, {\"truth_threshold\": 0.19999999552965164, \"match_probability\": 0.5346019606098211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130451.0, \"tn\": 1278735584.0, \"fp\": 2208.0, \"fn\": 173510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4291701895966917, \"tn_rate\": 0.9999982732972985, \"fp_rate\": 1.7267027015339826e-06, \"fn_rate\": 0.5708298104033083, \"precision\": 0.9833558220701196, \"recall\": 0.4291701895966917, \"specificity\": 0.9999982732972985, \"npv\": 0.999864329684718, \"accuracy\": 0.9998626174637475, \"f1\": 0.59754935641977, \"f2\": 0.4836882083317575, \"f0_5\": 0.781520901704655, \"p4\": 0.7480632728896691, \"phi\": 0.6495899331232123}, {\"truth_threshold\": 0.2199999950826168, \"match_probability\": 0.5380493895023247, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130439.0, \"tn\": 1278735585.0, \"fp\": 2207.0, \"fn\": 173522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4291307108477732, \"tn_rate\": 0.9999982740793196, \"fp_rate\": 1.7259206803829255e-06, \"fn_rate\": 0.5708692891522268, \"precision\": 0.9833617297166896, \"recall\": 0.4291307108477732, \"specificity\": 0.9999982740793196, \"npv\": 0.9998643203031004, \"accuracy\": 0.9998626088635592, \"f1\": 0.5975121791450893, \"f2\": 0.4836483770736157, \"f0_5\": 0.7814977023407965, \"p4\": 0.7480341385821501, \"phi\": 0.6495620038140065}, {\"truth_threshold\": 0.23999999463558197, \"match_probability\": 0.5414931834947113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130432.0, \"tn\": 1278735594.0, \"fp\": 2198.0, \"fn\": 173529.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4291076815775708, \"tn_rate\": 0.99999828111751, \"fp_rate\": 1.7188824900234122e-06, \"fn_rate\": 0.5708923184224292, \"precision\": 0.9834275804870692, \"recall\": 0.4291076815775708, \"specificity\": 0.99999828111751, \"npv\": 0.999864314831383, \"accuracy\": 0.9998626104272297, \"f1\": 0.5975020098902635, \"f2\": 0.48362816042430185, \"f0_5\": 0.7815156965826664, \"p4\": 0.748026169665552, \"phi\": 0.6495663286769836}, {\"truth_threshold\": 0.25999999418854713, \"match_probability\": 0.5449330179659203, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130417.0, \"tn\": 1278735597.0, \"fp\": 2195.0, \"fn\": 173544.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4290583331414227, \"tn_rate\": 0.9999982834635734, \"fp_rate\": 1.716536426570241e-06, \"fn_rate\": 0.5709416668585773, \"precision\": 0.9834479534280457, \"recall\": 0.4290583331414227, \"specificity\": 0.9999982834635734, \"npv\": 0.9998643031045471, \"accuracy\": 0.9998626010452061, \"f1\": 0.5974579279982958, \"f2\": 0.4835789970158463, \"f0_5\": 0.781493248514817, \"p4\": 0.747991622409545, \"phi\": 0.6495357032943596}, {\"truth_threshold\": 0.2799999937415123, \"match_probability\": 0.5483685698009062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130377.0, \"tn\": 1278735602.0, \"fp\": 2190.0, \"fn\": 173584.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4289267373116946, \"tn_rate\": 0.9999982873736792, \"fp_rate\": 1.7126263208149557e-06, \"fn_rate\": 0.5710732626883054, \"precision\": 0.9834800515965512, \"recall\": 0.4289267373116946, \"specificity\": 0.9999982873736792, \"npv\": 0.9998642718326679, \"accuracy\": 0.9998625736809703, \"f1\": 0.5973362533445735, \"f2\": 0.48344681258162386, \"f0_5\": 0.7814221274973658, \"p4\": 0.747896255118652, \"phi\": 0.6494466784895431}, {\"truth_threshold\": 0.29999999329447746, \"match_probability\": 0.5517995175106017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130347.0, \"tn\": 1278735602.0, \"fp\": 2190.0, \"fn\": 173614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4288280404393985, \"tn_rate\": 0.9999982873736792, \"fp_rate\": 1.7126263208149557e-06, \"fn_rate\": 0.5711719595606015, \"precision\": 0.9834763122750628, \"recall\": 0.4288280404393985, \"specificity\": 0.9999982873736792, \"npv\": 0.9998642483783619, \"accuracy\": 0.9998625502259112, \"f1\": 0.5972398498962195, \"f2\": 0.48334632422141816, \"f0_5\": 0.7813547150312489, \"p4\": 0.7478206845646129, \"phi\": 0.6493707120086808}, {\"truth_threshold\": 0.3199999928474426, \"match_probability\": 0.5552255413505731, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130335.0, \"tn\": 1278735605.0, \"fp\": 2187.0, \"fn\": 173626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42878856169048, \"tn_rate\": 0.9999982897197426, \"fp_rate\": 1.7102802573617845e-06, \"fn_rate\": 0.5712114383095199, \"precision\": 0.983497079730158, \"recall\": 0.42878856169048, \"specificity\": 0.9999982897197426, \"npv\": 0.9998642389969582, \"accuracy\": 0.9998625431893935, \"f1\": 0.5972053894424296, \"f2\": 0.48330720294044793, \"f0_5\": 0.7813389860787555, \"p4\": 0.7477936690294221, \"phi\": 0.6493476754833304}, {\"truth_threshold\": 0.3399999924004078, \"match_probability\": 0.558646323438279, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130303.0, \"tn\": 1278735615.0, \"fp\": 2177.0, \"fn\": 173658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4286832850266975, \"tn_rate\": 0.9999982975399542, \"fp_rate\": 1.702460045851214e-06, \"fn_rate\": 0.5713167149733025, \"precision\": 0.9835673309178744, \"recall\": 0.4286832850266975, \"specificity\": 0.9999982975399542, \"npv\": 0.9998642139800952, \"accuracy\": 0.9998625259890167, \"f1\": 0.5971162196035661, \"f2\": 0.48320359201497565, \"f0_5\": 0.7813045266650757, \"p4\": 0.747723758385369, \"phi\": 0.6492911450288144}, {\"truth_threshold\": 0.35999999195337296, \"match_probability\": 0.5620615478688429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130271.0, \"tn\": 1278735619.0, \"fp\": 2173.0, \"fn\": 173690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.428578008362915, \"tn_rate\": 0.9999983006680387, \"fp_rate\": 1.6993319612469857e-06, \"fn_rate\": 0.5714219916370851, \"precision\": 0.9835930657485428, \"recall\": 0.428578008362915, \"specificity\": 0.9999983006680387, \"npv\": 0.9998641889625968, \"accuracy\": 0.9998625040976281, \"f1\": 0.5970188242572839, \"f2\": 0.48309782479707597, \"f0_5\": 0.7812475636801534, \"p4\": 0.7476473894525503, \"phi\": 0.6492199013537823}, {\"truth_threshold\": 0.3799999915063381, \"match_probability\": 0.5654709008292483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130260.0, \"tn\": 1278735619.0, \"fp\": 2173.0, \"fn\": 173701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42854181950973974, \"tn_rate\": 0.9999983006680387, \"fp_rate\": 1.6993319612469857e-06, \"fn_rate\": 0.5714581804902603, \"precision\": 0.9835917029743342, \"recall\": 0.42854181950973974, \"specificity\": 0.9999983006680387, \"npv\": 0.9998641803626859, \"accuracy\": 0.9998624954974398, \"f1\": 0.5969834599009153, \"f2\": 0.48306097337564907, \"f0_5\": 0.7812228242290628, \"p4\": 0.7476196574138512, \"phi\": 0.649192038178835}, {\"truth_threshold\": 0.3999999910593033, \"match_probability\": 0.5688740707108767, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130243.0, \"tn\": 1278735630.0, \"fp\": 2162.0, \"fn\": 173718.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4284858912821053, \"tn_rate\": 0.9999983092702714, \"fp_rate\": 1.690729728585358e-06, \"fn_rate\": 0.5715141087178948, \"precision\": 0.983671311506363, \"recall\": 0.4284858912821053, \"specificity\": 0.9999983092702714, \"npv\": 0.9998641670730832, \"accuracy\": 0.999862490806428, \"f1\": 0.5969438498874797, \"f2\": 0.4830079606956875, \"f0_5\": 0.7812258196863892, \"p4\": 0.7475885952463784, \"phi\": 0.6491759493804536}, {\"truth_threshold\": 0.41999999061226845, \"match_probability\": 0.5722707482202983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130223.0, \"tn\": 1278735637.0, \"fp\": 2155.0, \"fn\": 173738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4284200933672412, \"tn_rate\": 0.9999983147444195, \"fp_rate\": 1.6852555805279586e-06, \"fn_rate\": 0.5715799066327588, \"precision\": 0.9837208599616251, \"recall\": 0.4284200933672412, \"specificity\": 0.9999983147444195, \"npv\": 0.9998641514376263, \"accuracy\": 0.999862480642569, \"f1\": 0.5968891160313426, \"f2\": 0.48294346183343695, \"f0_5\": 0.7812070696951191, \"p4\": 0.7475456699130697, \"phi\": 0.6491424534153939}, {\"truth_threshold\": 0.4399999901652336, \"match_probability\": 0.5756606264882413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130215.0, \"tn\": 1278735639.0, \"fp\": 2153.0, \"fn\": 173746.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42839377420129554, \"tn_rate\": 0.9999983163084618, \"fp_rate\": 1.6836915382258445e-06, \"fn_rate\": 0.5716062257987045, \"precision\": 0.983734739514082, \"recall\": 0.42839377420129554, \"specificity\": 0.9999983163084618, \"npv\": 0.9998641451833588, \"accuracy\": 0.9998624759515572, \"f1\": 0.596866126248771, \"f2\": 0.4829173750122384, \"f0_5\": 0.7811965688903607, \"p4\": 0.7475276391108536, \"phi\": 0.6491270926703048}, {\"truth_threshold\": 0.4599999897181988, \"match_probability\": 0.5790434011766568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130198.0, \"tn\": 1278735653.0, \"fp\": 2139.0, \"fn\": 173763.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4283378459736611, \"tn_rate\": 0.9999983272567579, \"fp_rate\": 1.6727432421110456e-06, \"fn_rate\": 0.5716621540263389, \"precision\": 0.9838367198893734, \"recall\": 0.4283378459736611, \"specificity\": 0.9999983272567579, \"npv\": 0.9998641318940762, \"accuracy\": 0.9998624736060512, \"f1\": 0.5968306066037433, \"f2\": 0.48286543127369397, \"f0_5\": 0.7812108113556916, \"p4\": 0.7474997808479202, \"phi\": 0.6491183701424774}, {\"truth_threshold\": 0.47999998927116394, \"match_probability\": 0.5824187705838036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130186.0, \"tn\": 1278735653.0, \"fp\": 2139.0, \"fn\": 173775.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4282983672247426, \"tn_rate\": 0.9999983272567579, \"fp_rate\": 1.6727432421110456e-06, \"fn_rate\": 0.5717016327752573, \"precision\": 0.9838352541092008, \"recall\": 0.4282983672247426, \"specificity\": 0.9999983272567579, \"npv\": 0.9998641225123567, \"accuracy\": 0.9998624642240276, \"f1\": 0.5967920125789047, \"f2\": 0.4828252244340287, \"f0_5\": 0.7811838067544263, \"p4\": 0.7474695089712621, \"phi\": 0.6490879688998447}, {\"truth_threshold\": 0.4999999888241291, \"match_probability\": 0.5857864357472833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130167.0, \"tn\": 1278735657.0, \"fp\": 2135.0, \"fn\": 173794.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4282358592056218, \"tn_rate\": 0.9999983303848425, \"fp_rate\": 1.6696151575068174e-06, \"fn_rate\": 0.5717641407943782, \"precision\": 0.9838626778128826, \"recall\": 0.4282358592056218, \"specificity\": 0.9999983303848425, \"npv\": 0.9998641076583927, \"accuracy\": 0.999862452496498, \"f1\": 0.5967363723258676, \"f2\": 0.4827629945124638, \"f0_5\": 0.7811560439718712, \"p4\": 0.7474258642729986, \"phi\": 0.6490496458320612}, {\"truth_threshold\": 0.5199999883770943, \"match_probability\": 0.5891461005449494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130153.0, \"tn\": 1278735657.0, \"fp\": 2135.0, \"fn\": 173808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42818980066521695, \"tn_rate\": 0.9999983303848425, \"fp_rate\": 1.6696151575068174e-06, \"fn_rate\": 0.571810199334783, \"precision\": 0.983860970004838, \"recall\": 0.42818980066521695, \"specificity\": 0.9999983303848425, \"npv\": 0.9998640967130539, \"accuracy\": 0.9998624415508037, \"f1\": 0.5966913391205482, \"f2\": 0.48271608418166767, \"f0_5\": 0.7811245293255537, \"p4\": 0.7473905374050814, \"phi\": 0.6490141737936307}, {\"truth_threshold\": 0.5399999879300594, \"match_probability\": 0.592497471793629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130122.0, \"tn\": 1278735926.0, \"fp\": 1866.0, \"fn\": 173839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4280878138971776, \"tn_rate\": 0.9999985407485321, \"fp_rate\": 1.459251467872469e-06, \"fn_rate\": 0.5719121861028224, \"precision\": 0.9858623511228294, \"recall\": 0.4280878138971776, \"specificity\": 0.9999985407485321, \"npv\": 0.9998640725055375, \"accuracy\": 0.9998626276276065, \"f1\": 0.5969597361159218, \"f2\": 0.48270852747226656, \"f0_5\": 0.7820649515033423, \"p4\": 0.7476010722734856, \"phi\": 0.6495968221666576}, {\"truth_threshold\": 0.5599999874830246, \"match_probability\": 0.5958402593455852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130098.0, \"tn\": 1278735932.0, \"fp\": 1860.0, \"fn\": 173863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4280088563993407, \"tn_rate\": 0.999998545440659, \"fp_rate\": 1.4545593409661267e-06, \"fn_rate\": 0.5719911436006593, \"precision\": 0.9859046060110035, \"recall\": 0.4280088563993407, \"specificity\": 0.999998545440659, \"npv\": 0.9998640537427427, \"accuracy\": 0.999862613554571, \"f1\": 0.5968907067597421, \"f2\": 0.4826302379726399, \"f0_5\": 0.7820335107412542, \"p4\": 0.7475469360285247, \"phi\": 0.6495508316340605}, {\"truth_threshold\": 0.5799999870359898, \"match_probability\": 0.5991741761826646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130085.0, \"tn\": 1278735932.0, \"fp\": 1860.0, \"fn\": 173876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42796608775467904, \"tn_rate\": 0.999998545440659, \"fp_rate\": 1.4545593409661267e-06, \"fn_rate\": 0.572033912245321, \"precision\": 0.9859032172496116, \"recall\": 0.42796608775467904, \"specificity\": 0.999998545440659, \"npv\": 0.999864043579217, \"accuracy\": 0.999862603390712, \"f1\": 0.5968488619105954, \"f2\": 0.4825866660137455, \"f0_5\": 0.7820042537280235, \"p4\": 0.7475141167157937, \"phi\": 0.6495179167633351}, {\"truth_threshold\": 0.5999999865889549, \"match_probability\": 0.6024989385080661, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130064.0, \"tn\": 1278735932.0, \"fp\": 1860.0, \"fn\": 173897.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42789699994407177, \"tn_rate\": 0.999998545440659, \"fp_rate\": 1.4545593409661267e-06, \"fn_rate\": 0.5721030000559282, \"precision\": 0.9859009732876505, \"recall\": 0.42789699994407177, \"specificity\": 0.999998545440659, \"npv\": 0.9998640271612144, \"accuracy\": 0.9998625869721706, \"f1\": 0.5967812611124493, \"f2\": 0.48251627876607844, \"f0_5\": 0.7819569846703629, \"p4\": 0.7474610931342137, \"phi\": 0.6494647430678947}, {\"truth_threshold\": 0.6199999861419201, \"match_probability\": 0.6058142658356777, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130056.0, \"tn\": 1278735941.0, \"fp\": 1851.0, \"fn\": 173905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4278706807781261, \"tn_rate\": 0.9999985524788494, \"fp_rate\": 1.4475211506066132e-06, \"fn_rate\": 0.5721293192218738, \"precision\": 0.9859673861129432, \"recall\": 0.4278706807781261, \"specificity\": 0.9999985524788494, \"npv\": 0.9998640209076942, \"accuracy\": 0.9998625877540058, \"f1\": 0.5967678287922031, \"f2\": 0.48249268596350514, \"f0_5\": 0.7819728255183751, \"p4\": 0.7474505573464124, \"phi\": 0.6494666490610319}, {\"truth_threshold\": 0.6399999856948853, \"match_probability\": 0.6091198810769267, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130036.0, \"tn\": 1278735979.0, \"fp\": 1813.0, \"fn\": 173925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42780488286326207, \"tn_rate\": 0.9999985821956532, \"fp_rate\": 1.417804346866445e-06, \"fn_rate\": 0.572195117136738, \"precision\": 0.9862494216869298, \"recall\": 0.42780488286326207, \"specificity\": 0.9999985821956532, \"npv\": 0.9998640052755429, \"accuracy\": 0.9998626018270413, \"f1\": 0.5967554668318763, \"f2\": 0.48243924988851317, \"f0_5\": 0.782070759012073, \"p4\": 0.7474408628164472, \"phi\": 0.6495096157838368}, {\"truth_threshold\": 0.6599999852478504, \"match_probability\": 0.6124155106250946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130016.0, \"tn\": 1278736070.0, \"fp\": 1722.0, \"fn\": 173945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42773908494839796, \"tn_rate\": 0.9999986533595778, \"fp_rate\": 1.3466404221202529e-06, \"fn_rate\": 0.572260915051602, \"precision\": 0.9869286007074648, \"recall\": 0.42773908494839796, \"specificity\": 0.9999986533595778, \"npv\": 0.9998639896490293, \"accuracy\": 0.999862657337348, \"f1\": 0.5968156915668845, \"f2\": 0.4824047813045885, \"f0_5\": 0.7823683105210775, \"p4\": 0.7474881083431734, \"phi\": 0.6496833311530748}, {\"truth_threshold\": 0.6799999848008156, \"match_probability\": 0.6157008844370494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129994.0, \"tn\": 1278736077.0, \"fp\": 1715.0, \"fn\": 173967.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4276667072420475, \"tn_rate\": 0.999998658833726, \"fp_rate\": 1.3411662740628535e-06, \"fn_rate\": 0.5723332927579525, \"precision\": 0.9869788700848082, \"recall\": 0.4276667072420475, \"specificity\": 0.999998658833726, \"npv\": 0.9998639724499654, \"accuracy\": 0.9998626456098185, \"f1\": 0.5967544242201667, \"f2\": 0.4823335334491482, \"f0_5\": 0.7823451456854081, \"p4\": 0.7474400511218671, \"phi\": 0.6496449072469442}, {\"truth_threshold\": 0.6999999843537807, \"match_probability\": 0.6189757361123518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129965.0, \"tn\": 1278736078.0, \"fp\": 1714.0, \"fn\": 173996.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4275713002654946, \"tn_rate\": 0.9999986596157471, \"fp_rate\": 1.3403842529117964e-06, \"fn_rate\": 0.5724286997345054, \"precision\": 0.9869834977483122, \"recall\": 0.4275713002654946, \"specificity\": 0.9999986596157471, \"npv\": 0.9998639497775978, \"accuracy\": 0.9998626237184299, \"f1\": 0.5966623817831237, \"f2\": 0.48223666683240285, \"f0_5\": 0.7822836072263949, \"p4\": 0.7473678468359899, \"phi\": 0.649573955410436}, {\"truth_threshold\": 0.7199999839067459, \"match_probability\": 0.6222398029696947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129959.0, \"tn\": 1278736101.0, \"fp\": 1691.0, \"fn\": 174002.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42755156089103535, \"tn_rate\": 0.9999986776022336, \"fp_rate\": 1.322397766437484e-06, \"fn_rate\": 0.5724484391089646, \"precision\": 0.987155336118496, \"recall\": 0.42755156089103535, \"specificity\": 0.9999986776022336, \"npv\": 0.9998639450891882, \"accuracy\": 0.9998626370096302, \"f1\": 0.5966745559685132, \"f2\": 0.48222478170589256, \"f0_5\": 0.7823567444173276, \"p4\": 0.7473773990168688, \"phi\": 0.6496155240431067}, {\"truth_threshold\": 0.7399999834597111, \"match_probability\": 0.6254928261206408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129948.0, \"tn\": 1278736107.0, \"fp\": 1685.0, \"fn\": 174013.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4275153720378601, \"tn_rate\": 0.9999986822943605, \"fp_rate\": 1.3177056395311417e-06, \"fn_rate\": 0.5724846279621398, \"precision\": 0.9871992585445899, \"recall\": 0.4275153720378601, \"specificity\": 0.9999986822943605, \"npv\": 0.9998639364899231, \"accuracy\": 0.9998626331004536, \"f1\": 0.5966473367401754, \"f2\": 0.48219004851288744, \"f0_5\": 0.7823545773414105, \"p4\": 0.7473560455102598, \"phi\": 0.6496024849023594}, {\"truth_threshold\": 0.7599999830126762, \"match_probability\": 0.6287345505406211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129931.0, \"tn\": 1278736119.0, \"fp\": 1673.0, \"fn\": 174030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42745944381022566, \"tn_rate\": 0.9999986916786143, \"fp_rate\": 1.308321385718457e-06, \"fn_rate\": 0.5725405561897744, \"precision\": 0.9872876204370687, \"recall\": 0.42745944381022566, \"specificity\": 0.9999986916786143, \"npv\": 0.9998639232004406, \"accuracy\": 0.9998626291912771, \"f1\": 0.5966090021007198, \"f2\": 0.48213734407561554, \"f0_5\": 0.7823615056775417, \"p4\": 0.7473259709429709, \"phi\": 0.6495890687875067}, {\"truth_threshold\": 0.7799999825656414, \"match_probability\": 0.6319647251371673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129910.0, \"tn\": 1278736127.0, \"fp\": 1665.0, \"fn\": 174051.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4273903559996184, \"tn_rate\": 0.9999986979347835, \"fp_rate\": 1.3020652165100005e-06, \"fn_rate\": 0.5726096440003816, \"precision\": 0.9873456203686111, \"recall\": 0.4273903559996184, \"specificity\": 0.9999986979347835, \"npv\": 0.9998639067832956, \"accuracy\": 0.9998626190274181, \"f1\": 0.5965522941846368, \"f2\": 0.482069794176867, \"f0_5\": 0.7823443471390322, \"p4\": 0.7472814787802015, \"phi\": 0.6495556526152949}, {\"truth_threshold\": 0.7999999821186066, \"match_probability\": 0.6351831028153483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129888.0, \"tn\": 1278736138.0, \"fp\": 1654.0, \"fn\": 174073.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4273179782932679, \"tn_rate\": 0.9999987065370162, \"fp_rate\": 1.2934629838483728e-06, \"fn_rate\": 0.5726820217067321, \"precision\": 0.9874260692402427, \"recall\": 0.4273179782932679, \"specificity\": 0.9999987065370162, \"npv\": 0.9998638895846614, \"accuracy\": 0.9998626104272297, \"f1\": 0.5964964650071297, \"f2\": 0.4819999614067535, \"f0_5\": 0.7823362393073847, \"p4\": 0.7472376731712886, \"phi\": 0.6495271142695166}, {\"truth_threshold\": 0.8199999816715717, \"match_probability\": 0.6383894405403884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129871.0, \"tn\": 1278736139.0, \"fp\": 1653.0, \"fn\": 174090.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42726205006563345, \"tn_rate\": 0.9999987073190373, \"fp_rate\": 1.2926809626973157e-06, \"fn_rate\": 0.5727379499343666, \"precision\": 0.987431951582981, \"recall\": 0.42726205006563345, \"specificity\": 0.9999987073190373, \"npv\": 0.99986387629401, \"accuracy\": 0.9998625979178648, \"f1\": 0.596443046258769, \"f2\": 0.48194331466978585, \"f0_5\": 0.7823016973533143, \"p4\": 0.7471957554071983, \"phi\": 0.6494865381064097}, {\"truth_threshold\": 0.8399999812245369, \"match_probability\": 0.641583499397445, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129846.0, \"tn\": 1278736667.0, \"fp\": 1125.0, \"fn\": 174115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4271798026720533, \"tn_rate\": 0.9999991202262051, \"fp_rate\": 8.797737949391895e-07, \"fn_rate\": 0.5728201973279466, \"precision\": 0.991410312206519, \"recall\": 0.4271798026720533, \"specificity\": 0.9999991202262051, \"npv\": 0.9998638568049855, \"accuracy\": 0.9998629911810236, \"f1\": 0.5970864410988385, \"f2\": 0.4820483882344643, \"f0_5\": 0.7842410113004246, \"p4\": 0.7477004756526706, \"phi\": 0.6507314590637222}, {\"truth_threshold\": 0.8599999807775021, \"match_probability\": 0.6447650446485294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129817.0, \"tn\": 1278736671.0, \"fp\": 1121.0, \"fn\": 174144.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4270843956955004, \"tn_rate\": 0.9999991233542896, \"fp_rate\": 8.766457103349613e-07, \"fn_rate\": 0.5729156043044996, \"precision\": 0.9914386961768165, \"recall\": 0.4270843956955004, \"specificity\": 0.9999991233542896, \"npv\": 0.9998638341329532, \"accuracy\": 0.9998629716351409, \"f1\": 0.5969983835327283, \"f2\": 0.48195253574817604, \"f0_5\": 0.7841908970863088, \"p4\": 0.7476314264437257, \"phi\": 0.6506680974872348}, {\"truth_threshold\": 0.8799999803304672, \"match_probability\": 0.6479338457865556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129779.0, \"tn\": 1278736675.0, \"fp\": 1117.0, \"fn\": 174182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42695937965725866, \"tn_rate\": 0.9999991264823743, \"fp_rate\": 8.735176257307331e-07, \"fn_rate\": 0.5730406203427414, \"precision\": 0.9914665077618873, \"recall\": 0.42695937965725866, \"specificity\": 0.9999991264823743, \"npv\": 0.9998638044246425, \"accuracy\": 0.9998629450527405, \"f1\": 0.5968812736140846, \"f2\": 0.4818264846963779, \"f0_5\": 0.7841205009999456, \"p4\": 0.7475395843268585, \"phi\": 0.6505819772957876}, {\"truth_threshold\": 0.8999999798834324, \"match_probability\": 0.6510896765865067, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129760.0, \"tn\": 1278736684.0, \"fp\": 1108.0, \"fn\": 174201.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4268968716381378, \"tn_rate\": 0.9999991335205646, \"fp_rate\": 8.664794353712195e-07, \"fn_rate\": 0.5731031283618622, \"precision\": 0.9915334535562551, \"recall\": 0.4268968716381378, \"specificity\": 0.9999991335205646, \"npv\": 0.9998637895712335, \"accuracy\": 0.9998629372343876, \"f1\": 0.5968323179916702, \"f2\": 0.48176596035380986, \"f0_5\": 0.784111825368338, \"p4\": 0.7475011879069545, \"phi\": 0.6505563177899941}, {\"truth_threshold\": 0.9199999794363976, \"match_probability\": 0.6542323151537098, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129724.0, \"tn\": 1278736693.0, \"fp\": 1099.0, \"fn\": 174237.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42677843539138244, \"tn_rate\": 0.9999991405587549, \"fp_rate\": 8.594412450117061e-07, \"fn_rate\": 0.5732215646086175, \"precision\": 0.9915993365081064, \"recall\": 0.42677843539138244, \"specificity\": 0.9999991405587549, \"npv\": 0.9998637614270761, \"accuracy\": 0.9998629161248342, \"f1\": 0.5967284904688305, \"f2\": 0.48164839563158524, \"f0_5\": 0.7840648507772109, \"p4\": 0.7474197464428486, \"phi\": 0.6504876767324581}, {\"truth_threshold\": 0.9399999789893627, \"match_probability\": 0.6573615439692159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129712.0, \"tn\": 1278736699.0, \"fp\": 1093.0, \"fn\": 174249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.426738956642464, \"tn_rate\": 0.9999991452508818, \"fp_rate\": 8.547491181053637e-07, \"fn_rate\": 0.573261043357536, \"precision\": 0.9916440503038875, \"recall\": 0.426738956642464, \"specificity\": 0.9999991452508818, \"npv\": 0.9998637520460103, \"accuracy\": 0.9998629114338224, \"f1\": 0.5966979938633655, \"f2\": 0.48161027855068395, \"f0_5\": 0.7840605623194924, \"p4\": 0.7473958233523696, \"phi\": 0.6504722573540229}, {\"truth_threshold\": 0.9599999785423279, \"match_probability\": 0.6604771499322812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129688.0, \"tn\": 1278736715.0, \"fp\": 1077.0, \"fn\": 174273.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4266599991446271, \"tn_rate\": 0.9999991577632203, \"fp_rate\": 8.422367796884508e-07, \"fn_rate\": 0.5733400008553728, \"precision\": 0.9917638511834206, \"recall\": 0.4266599991446271, \"specificity\": 0.9999991577632203, \"npv\": 0.9998637332843058, \"accuracy\": 0.99986290517914, \"f1\": 0.5966424828512672, \"f2\": 0.4815354716922284, \"f0_5\": 0.7840671518619237, \"p4\": 0.7473522756609311, \"phi\": 0.6504513733981698}, {\"truth_threshold\": 0.979999978095293, \"match_probability\": 0.663578924399954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129669.0, \"tn\": 1278736718.0, \"fp\": 1074.0, \"fn\": 174292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4265974911255062, \"tn_rate\": 0.9999991601092838, \"fp_rate\": 8.398907162352796e-07, \"fn_rate\": 0.5734025088744937, \"precision\": 0.991785411073633, \"recall\": 0.4265974911255062, \"specificity\": 0.9999991601092838, \"npv\": 0.9998637184302605, \"accuracy\": 0.9998628926697751, \"f1\": 0.5965852626154808, \"f2\": 0.48147279009822613, \"f0_5\": 0.7840357078505755, \"p4\": 0.7473073830888731, \"phi\": 0.6504107916126972}, {\"truth_threshold\": 0.9999999776482582, \"match_probability\": 0.6666666632237674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129648.0, \"tn\": 1278736718.0, \"fp\": 1074.0, \"fn\": 174313.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42652840331489894, \"tn_rate\": 0.9999991601092838, \"fp_rate\": 8.398907162352796e-07, \"fn_rate\": 0.5734715966851011, \"precision\": 0.9917840914306697, \"recall\": 0.42652840331489894, \"specificity\": 0.9999991601092838, \"npv\": 0.9998637020122786, \"accuracy\": 0.9998628762512337, \"f1\": 0.5965174621505787, \"f2\": 0.4814023226488713, \"f0_5\": 0.7839883703070331, \"p4\": 0.7472541853295463, \"phi\": 0.6503576839802755}, {\"truth_threshold\": 1.0199999772012234, \"match_probability\": 0.6697401667835483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129616.0, \"tn\": 1278736718.0, \"fp\": 1074.0, \"fn\": 174345.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4264231266511164, \"tn_rate\": 0.9999991601092838, \"fp_rate\": 8.398907162352796e-07, \"fn_rate\": 0.5735768733488835, \"precision\": 0.9917820797306603, \"recall\": 0.4264231266511164, \"specificity\": 0.9999991601092838, \"npv\": 0.9998636769944026, \"accuracy\": 0.9998628512325038, \"f1\": 0.5964141345585309, \"f2\": 0.4812949394519559, \"f0_5\": 0.7839162184098384, \"p4\": 0.7471731035036618, \"phi\": 0.650276749729643}, {\"truth_threshold\": 1.0399999767541885, \"match_probability\": 0.672799240018352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129584.0, \"tn\": 1278736720.0, \"fp\": 1072.0, \"fn\": 174377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4263178499873339, \"tn_rate\": 0.999999161673326, \"fp_rate\": 8.383266739331655e-07, \"fn_rate\": 0.5736821500126661, \"precision\": 0.9917952485917217, \"recall\": 0.4263178499873339, \"specificity\": 0.999999161673326, \"npv\": 0.999863651976741, \"accuracy\": 0.9998628277774447, \"f1\": 0.596313535825796, \"f2\": 0.48118826587448943, \"f0_5\": 0.7838516305038199, \"p4\": 0.747094153074227, \"phi\": 0.6502007836638176}, {\"truth_threshold\": 1.0599999763071537, \"match_probability\": 0.6758436924545342, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129554.0, \"tn\": 1278736724.0, \"fp\": 1068.0, \"fn\": 174407.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4262191531150378, \"tn_rate\": 0.9999991648014107, \"fp_rate\": 8.351985893289372e-07, \"fn_rate\": 0.5737808468849622, \"precision\": 0.9918237356647426, \"recall\": 0.4262191531150378, \"specificity\": 0.9999991648014107, \"npv\": 0.999863628522911, \"accuracy\": 0.9998628074497268, \"f1\": 0.5962221255778528, \"f2\": 0.48108901375898094, \"f0_5\": 0.7837991213008909, \"p4\": 0.7470224053265249, \"phi\": 0.6501348477531859}, {\"truth_threshold\": 1.0799999758601189, \"match_probability\": 0.6788733382309773, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129537.0, \"tn\": 1278736739.0, \"fp\": 1053.0, \"fn\": 174424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4261632248874033, \"tn_rate\": 0.999999176531728, \"fp_rate\": 8.234682720630814e-07, \"fn_rate\": 0.5738367751125967, \"precision\": 0.9919365954514128, \"recall\": 0.4261632248874033, \"specificity\": 0.999999176531728, \"npv\": 0.9998636152337659, \"accuracy\": 0.9998628058860561, \"f1\": 0.5961877892353257, \"f2\": 0.4810373178336257, \"f0_5\": 0.7838176689204317, \"p4\": 0.7469954535144213, \"phi\": 0.6501291867879768}, {\"truth_threshold\": 1.099999975413084, \"match_probability\": 0.681887996121488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129525.0, \"tn\": 1278736739.0, \"fp\": 1053.0, \"fn\": 174436.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42612374613848486, \"tn_rate\": 0.999999176531728, \"fp_rate\": 8.234682720630814e-07, \"fn_rate\": 0.5738762538615151, \"precision\": 0.9919358544318339, \"recall\": 0.42612374613848486, \"specificity\": 0.999999176531728, \"npv\": 0.999863605852064, \"accuracy\": 0.9998627965040325, \"f1\": 0.5961490222971931, \"f2\": 0.4809970425319848, \"f0_5\": 0.7837905873724543, \"p4\": 0.7469650215141945, \"phi\": 0.6500988268862775}, {\"truth_threshold\": 1.1199999749660492, \"match_probability\": 0.6848874895543896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129493.0, \"tn\": 1278736742.0, \"fp\": 1050.0, \"fn\": 174468.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42601846947470234, \"tn_rate\": 0.9999991788777914, \"fp_rate\": 8.211222086099103e-07, \"fn_rate\": 0.5739815305252977, \"precision\": 0.9919566732800686, \"recall\": 0.42601846947470234, \"specificity\": 0.9999991788777914, \"npv\": 0.9998635808345131, \"accuracy\": 0.9998627738308087, \"f1\": 0.5960497486789534, \"f2\": 0.48089070972907494, \"f0_5\": 0.7837297384319474, \"p4\": 0.7468870852917768, \"phi\": 0.650025332003505}, {\"truth_threshold\": 1.1399999745190144, \"match_probability\": 0.6878716466293294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129453.0, \"tn\": 1278736745.0, \"fp\": 1047.0, \"fn\": 174508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4258868736449742, \"tn_rate\": 0.9999991812238549, \"fp_rate\": 8.187761451567391e-07, \"fn_rate\": 0.5741131263550258, \"precision\": 0.9919770114942529, \"recall\": 0.4258868736449742, \"specificity\": 0.9999991812238549, \"npv\": 0.9998635495624965, \"accuracy\": 0.9998627449029023, \"f1\": 0.5959246054306371, \"f2\": 0.4807575181380093, \"f0_5\": 0.7836508019143761, \"p4\": 0.7467888258719935, \"phi\": 0.649931583789667}, {\"truth_threshold\": 1.1599999740719795, \"match_probability\": 0.6908403001313297, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129433.0, \"tn\": 1278736764.0, \"fp\": 1028.0, \"fn\": 174528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42582107573011013, \"tn_rate\": 0.9999991960822567, \"fp_rate\": 8.039177432866549e-07, \"fn_rate\": 0.5741789242698899, \"precision\": 0.9921202504963169, \"recall\": 0.42582107573011013, \"specificity\": 0.9999991960822567, \"npv\": 0.9998635339283563, \"accuracy\": 0.999862744121067, \"f1\": 0.5958860278715167, \"f2\": 0.4806971674323426, \"f0_5\": 0.7836777447460357, \"p4\": 0.7467585337432292, \"phi\": 0.6499283073671854}, {\"truth_threshold\": 1.1799999736249447, \"match_probability\": 0.6937932875421096, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129393.0, \"tn\": 1278736770.0, \"fp\": 1022.0, \"fn\": 174568.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.425689479900382, \"tn_rate\": 0.9999992007743836, \"fp_rate\": 7.992256163803126e-07, \"fn_rate\": 0.574310520099618, \"precision\": 0.992163478127516, \"recall\": 0.425689479900382, \"specificity\": 0.9999992007743836, \"npv\": 0.9998635026566635, \"accuracy\": 0.9998627175386666, \"f1\": 0.5957649593900215, \"f2\": 0.4805650324343236, \"f0_5\": 0.783610155264946, \"p4\": 0.7466634546655468, \"phi\": 0.6498420243749925}, {\"truth_threshold\": 1.1999999731779099, \"match_probability\": 0.6967304510487088, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129382.0, \"tn\": 1278736770.0, \"fp\": 1022.0, \"fn\": 174579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4256532910472067, \"tn_rate\": 0.9999992007743836, \"fp_rate\": 7.992256163803126e-07, \"fn_rate\": 0.5743467089527933, \"precision\": 0.9921628170915002, \"recall\": 0.4256532910472067, \"specificity\": 0.9999992007743836, \"npv\": 0.9998634940567722, \"accuracy\": 0.9998627089384783, \"f1\": 0.5957293980868624, \"f2\": 0.4805281047771287, \"f0_5\": 0.7835852985245471, \"p4\": 0.7466355243481618, \"phi\": 0.6498141821265848}, {\"truth_threshold\": 1.219999972730875, \"match_probability\": 0.6996516375494458, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129356.0, \"tn\": 1278736785.0, \"fp\": 1007.0, \"fn\": 174605.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4255677537578834, \"tn_rate\": 0.9999992125047009, \"fp_rate\": 7.874952991144568e-07, \"fn_rate\": 0.5744322462421166, \"precision\": 0.9922754155703689, \"recall\": 0.4255677537578834, \"specificity\": 0.9999992125047009, \"npv\": 0.9998634737313583, \"accuracy\": 0.99986270033829, \"f1\": 0.5956659084001805, \"f2\": 0.4804461720968618, \"f0_5\": 0.7835834909312066, \"p4\": 0.7465856565560007, \"phi\": 0.6497857625642979}, {\"truth_threshold\": 1.2399999722838402, \"match_probability\": 0.7025566986572463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129322.0, \"tn\": 1278736791.0, \"fp\": 1001.0, \"fn\": 174639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42545589730261446, \"tn_rate\": 0.9999992171968278, \"fp_rate\": 7.828031722081144e-07, \"fn_rate\": 0.5745441026973855, \"precision\": 0.9923190841217591, \"recall\": 0.42545589730261446, \"specificity\": 0.9999992171968278, \"npv\": 0.9998634471505192, \"accuracy\": 0.9998626784469014, \"f1\": 0.5955641930165514, \"f2\": 0.4803341635918872, \"f0_5\": 0.7835294146158814, \"p4\": 0.7465057550975112, \"phi\": 0.6497146546344739}, {\"truth_threshold\": 1.2599999718368053, \"match_probability\": 0.7054454907003789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129289.0, \"tn\": 1278736798.0, \"fp\": 994.0, \"fn\": 174672.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4253473307430887, \"tn_rate\": 0.9999992226709759, \"fp_rate\": 7.77329024150715e-07, \"fn_rate\": 0.5746526692569113, \"precision\": 0.9923704550862353, \"recall\": 0.4253473307430887, \"specificity\": 0.9999992226709759, \"npv\": 0.9998634213515968, \"accuracy\": 0.9998626581191834, \"f1\": 0.5954670645996261, \"f2\": 0.48022586279006363, \"f0_5\": 0.7834813772508069, \"p4\": 0.7464294474552864, \"phi\": 0.6496485661675154}, {\"truth_threshold\": 1.2799999713897705, \"match_probability\": 0.7083178747206358, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129264.0, \"tn\": 1278736798.0, \"fp\": 994.0, \"fn\": 174697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42526508334950863, \"tn_rate\": 0.9999992226709759, \"fp_rate\": 7.77329024150715e-07, \"fn_rate\": 0.5747349166504914, \"precision\": 0.9923689907721599, \"recall\": 0.42526508334950863, \"specificity\": 0.9999992226709759, \"npv\": 0.9998634018063932, \"accuracy\": 0.9998626385733007, \"f1\": 0.5953861991299322, \"f2\": 0.4801419208945533, \"f0_5\": 0.7834248290591557, \"p4\": 0.7463659091276671, \"phi\": 0.6495852675676714}, {\"truth_threshold\": 1.2999999709427357, \"match_probability\": 0.7111737164690025, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129244.0, \"tn\": 1278736798.0, \"fp\": 994.0, \"fn\": 174717.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4251992854346446, \"tn_rate\": 0.9999992226709759, \"fp_rate\": 7.77329024150715e-07, \"fn_rate\": 0.5748007145653554, \"precision\": 0.9923678189161381, \"recall\": 0.4251992854346446, \"specificity\": 0.9999992226709759, \"npv\": 0.9998633861702309, \"accuracy\": 0.9998626229365947, \"f1\": 0.5953215000495164, \"f2\": 0.4800747651331791, \"f0_5\": 0.7833795806345639, \"p4\": 0.7463150685599127, \"phi\": 0.6495346242492127}, {\"truth_threshold\": 1.3199999704957008, \"match_probability\": 0.7140128863988563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129230.0, \"tn\": 1278736801.0, \"fp\": 991.0, \"fn\": 174731.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42515322689423973, \"tn_rate\": 0.9999992250170393, \"fp_rate\": 7.749829606975438e-07, \"fn_rate\": 0.5748467731057603, \"precision\": 0.9923898603143886, \"recall\": 0.42515322689423973, \"specificity\": 0.9999992250170393, \"npv\": 0.999863375225238, \"accuracy\": 0.9998626143364062, \"f1\": 0.5952803202343717, \"f2\": 0.480028824759577, \"f0_5\": 0.7833592978074668, \"p4\": 0.7462827074828532, \"phi\": 0.6495066558601014}, {\"truth_threshold\": 1.339999970048666, \"match_probability\": 0.7168352596567393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129189.0, \"tn\": 1278736805.0, \"fp\": 987.0, \"fn\": 174772.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42501834116876835, \"tn_rate\": 0.9999992281451239, \"fp_rate\": 7.718548760933156e-07, \"fn_rate\": 0.5749816588312316, \"precision\": 0.9924179572271387, \"recall\": 0.42501834116876835, \"specificity\": 0.9999992281451239, \"npv\": 0.999863343171535, \"accuracy\": 0.9998625854084999, \"f1\": 0.595153142901895, \"f2\": 0.47989257217574777, \"f0_5\": 0.7832816962039131, \"p4\": 0.7461827545486195, \"phi\": 0.6494128012066535}, {\"truth_threshold\": 1.3599999696016312, \"match_probability\": 0.7196407160707529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129176.0, \"tn\": 1278736814.0, \"fp\": 978.0, \"fn\": 174785.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4249755725241067, \"tn_rate\": 0.9999992351833142, \"fp_rate\": 7.648166857338021e-07, \"fn_rate\": 0.5750244274758933, \"precision\": 0.992485824484841, \"recall\": 0.4249755725241067, \"specificity\": 0.9999992351833142, \"npv\": 0.9998633330089924, \"accuracy\": 0.9998625822811588, \"f1\": 0.5951234119991247, \"f2\": 0.4798521245945388, \"f0_5\": 0.7832864608156667, \"p4\": 0.7461593862422614, \"phi\": 0.6494023347544748}, {\"truth_threshold\": 1.3799999691545963, \"match_probability\": 0.7224291401366201, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129138.0, \"tn\": 1278736817.0, \"fp\": 975.0, \"fn\": 174823.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42485055648586495, \"tn_rate\": 0.9999992375293777, \"fp_rate\": 7.62470622280631e-07, \"fn_rate\": 0.575149443514135, \"precision\": 0.9925065135689747, \"recall\": 0.42485055648586495, \"specificity\": 0.9999992375293777, \"npv\": 0.9998633033006096, \"accuracy\": 0.999862554916923, \"f1\": 0.5950045383966789, \"f2\": 0.4797255781574003, \"f0_5\": 0.7832118125260034, \"p4\": 0.7460659415496964, \"phi\": 0.6493135700753426}, {\"truth_threshold\": 1.3999999687075615, \"match_probability\": 0.7252004210014652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129099.0, \"tn\": 1278736821.0, \"fp\": 971.0, \"fn\": 174862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42472225055188, \"tn_rate\": 0.9999992406574624, \"fp_rate\": 7.593425376764027e-07, \"fn_rate\": 0.5752777494481199, \"precision\": 0.9925347889597909, \"recall\": 0.42472225055188, \"specificity\": 0.9999992406574624, \"npv\": 0.9998632728105276, \"accuracy\": 0.9998625275526873, \"f1\": 0.5948837755828501, \"f2\": 0.47959602173690147, \"f0_5\": 0.7831386693940243, \"p4\": 0.7459709975763528, \"phi\": 0.6492247566662495}, {\"truth_threshold\": 1.4199999682605267, \"match_probability\": 0.7279544524453618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 129023.0, \"tn\": 1278736836.0, \"fp\": 956.0, \"fn\": 174938.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4244722184753965, \"tn_rate\": 0.9999992523877795, \"fp_rate\": 7.476122204105468e-07, \"fn_rate\": 0.5755277815246035, \"precision\": 0.9926449657252325, \"recall\": 0.4244722184753965, \"specificity\": 0.9999992523877795, \"npv\": 0.9998632133947342, \"accuracy\": 0.9998624798607337, \"f1\": 0.5946582476840117, \"f2\": 0.479346095288905, \"f0_5\": 0.7830234367508743, \"p4\": 0.745793649052581, \"phi\": 0.6490696469831145}, {\"truth_threshold\": 1.4399999678134918, \"match_probability\": 0.7306911328606996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128990.0, \"tn\": 1278736855.0, \"fp\": 937.0, \"fn\": 174971.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4243636519158708, \"tn_rate\": 0.9999992672461815, \"fp_rate\": 7.327538185404628e-07, \"fn_rate\": 0.5756363480841292, \"precision\": 0.9927882580218123, \"recall\": 0.4243636519158708, \"specificity\": 0.9999992672461815, \"npv\": 0.9998631875971096, \"accuracy\": 0.9998624689150394, \"f1\": 0.5945774024633085, \"f2\": 0.4792420107135612, \"f0_5\": 0.783020849394599, \"p4\": 0.7457300633847765, \"phi\": 0.6490334854021608}, {\"truth_threshold\": 1.459999967366457, \"match_probability\": 0.7334103652294244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128962.0, \"tn\": 1278736856.0, \"fp\": 936.0, \"fn\": 174999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4242715348350611, \"tn_rate\": 0.9999992680282026, \"fp_rate\": 7.319717973894057e-07, \"fn_rate\": 0.5757284651649389, \"precision\": 0.9927943463332769, \"recall\": 0.4242715348350611, \"specificity\": 0.9999992680282026, \"npv\": 0.9998631657065998, \"accuracy\": 0.9998624478054862, \"f1\": 0.594488071009245, \"f2\": 0.4791483062875351, \"f0_5\": 0.7829611451843415, \"p4\": 0.7456597944478172, \"phi\": 0.6489650218628183}, {\"truth_threshold\": 1.4799999669194221, \"match_probability\": 0.7361120570982027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128950.0, \"tn\": 1278736866.0, \"fp\": 926.0, \"fn\": 175011.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4242320560861426, \"tn_rate\": 0.9999992758484141, \"fp_rate\": 7.241515858788351e-07, \"fn_rate\": 0.5757679439138573, \"precision\": 0.9928701222704733, \"recall\": 0.4242320560861426, \"specificity\": 0.9999992758484141, \"npv\": 0.9998631563259772, \"accuracy\": 0.9998624462418155, \"f1\": 0.5944628973554584, \"f2\": 0.47911155366643876, \"f0_5\": 0.7829719538778211, \"p4\": 0.7456399918099564, \"phi\": 0.6489595989233318}, {\"truth_threshold\": 1.4999999664723873, \"match_probability\": 0.7387961205515697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128928.0, \"tn\": 1278736892.0, \"fp\": 900.0, \"fn\": 175033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4241596783797921, \"tn_rate\": 0.9999992961809641, \"fp_rate\": 7.038190359513517e-07, \"fn_rate\": 0.5758403216202078, \"precision\": 0.9930677511784823, \"recall\": 0.4241596783797921, \"specificity\": 0.9999992961809641, \"npv\": 0.9998631391289905, \"accuracy\": 0.9998624493691568, \"f1\": 0.5944272445820433, \"f2\": 0.47904689998751554, \"f0_5\": 0.7830209420204477, \"p4\": 0.7456119455357929, \"phi\": 0.6489688345695164}, {\"truth_threshold\": 1.5199999660253525, \"match_probability\": 0.7414624721831113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128884.0, \"tn\": 1278736903.0, \"fp\": 889.0, \"fn\": 175077.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42401492296709115, \"tn_rate\": 0.9999993047831968, \"fp_rate\": 6.95216803289724e-07, \"fn_rate\": 0.5759850770329088, \"precision\": 0.9931495765683155, \"recall\": 0.42401492296709115, \"specificity\": 0.9999993047831968, \"npv\": 0.999863104730632, \"accuracy\": 0.9998624235685917, \"f1\": 0.594299732093864, \"f2\": 0.4789029865110206, \"f0_5\": 0.7829629440631405, \"p4\": 0.7455116223571897, \"phi\": 0.6488848165947605}, {\"truth_threshold\": 1.5399999655783176, \"match_probability\": 0.7441110330647412, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128808.0, \"tn\": 1278736905.0, \"fp\": 887.0, \"fn\": 175153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4237648908906077, \"tn_rate\": 0.999999306347239, \"fp_rate\": 6.936527609876099e-07, \"fn_rate\": 0.5762351091093924, \"precision\": 0.9931608774432322, \"recall\": 0.4237648908906077, \"specificity\": 0.999999306347239, \"npv\": 0.9998630453134723, \"accuracy\": 0.9998623657127791, \"f1\": 0.5940561182135149, \"f2\": 0.4786483334931206, \"f0_5\": 0.7827979886744431, \"p4\": 0.7453199081151116, \"phi\": 0.6486971446406808}, {\"truth_threshold\": 1.5599999651312828, \"match_probability\": 0.7467417287141271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128799.0, \"tn\": 1278736907.0, \"fp\": 885.0, \"fn\": 175162.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42373528182891884, \"tn_rate\": 0.9999993079112813, \"fp_rate\": 6.920887186854958e-07, \"fn_rate\": 0.5762647181710812, \"precision\": 0.9931757194411029, \"recall\": 0.42373528182891884, \"specificity\": 0.9999993079112813, \"npv\": 0.9998630382774188, \"accuracy\": 0.9998623602399319, \"f1\": 0.5940296786541988, \"f2\": 0.47861880243294824, \"f0_5\": 0.7827851566251002, \"p4\": 0.7452990978419091, \"phi\": 0.6486793280180708}, {\"truth_threshold\": 1.579999964684248, \"match_probability\": 0.7493544890603256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128790.0, \"tn\": 1278736913.0, \"fp\": 879.0, \"fn\": 175171.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42370567276723, \"tn_rate\": 0.9999993126034082, \"fp_rate\": 6.873965917791534e-07, \"fn_rate\": 0.57629432723277, \"precision\": 0.9932212016750341, \"recall\": 0.42370567276723, \"specificity\": 0.9999993126034082, \"npv\": 0.9998630312417941, \"accuracy\": 0.999862357894426, \"f1\": 0.5940087171090561, \"f2\": 0.4785906936610795, \"f0_5\": 0.7827875478491728, \"p4\": 0.7452825990370696, \"phi\": 0.6486715196305725}, {\"truth_threshold\": 1.5999999642372131, \"match_probability\": 0.7519492484076834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128763.0, \"tn\": 1278736926.0, \"fp\": 866.0, \"fn\": 175198.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4236168455821635, \"tn_rate\": 0.9999993227696832, \"fp_rate\": 6.772303168154116e-07, \"fn_rate\": 0.5763831544178365, \"precision\": 0.9933193961227812, \"recall\": 0.4236168455821635, \"specificity\": 0.9999993227696832, \"npv\": 0.9998630101343852, \"accuracy\": 0.9998623469487317, \"f1\": 0.5939389746073479, \"f2\": 0.4785045853762952, \"f0_5\": 0.782775688560288, \"p4\": 0.7452277012448723, \"phi\": 0.6486355875321119}, {\"truth_threshold\": 1.6199999637901783, \"match_probability\": 0.754525945398063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128753.0, \"tn\": 1278736934.0, \"fp\": 858.0, \"fn\": 175208.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4235839466247315, \"tn_rate\": 0.9999993290258524, \"fp_rate\": 6.709741476069553e-07, \"fn_rate\": 0.5764160533752686, \"precision\": 0.9933801914960921, \"recall\": 0.4235839466247315, \"specificity\": 0.9999993290258524, \"npv\": 0.9998630023171677, \"accuracy\": 0.9998623453850611, \"f1\": 0.5939175038978531, \"f2\": 0.47847382483992407, \"f0_5\": 0.7827834217933987, \"p4\": 0.7452107998652231, \"phi\": 0.6486302533439743}, {\"truth_threshold\": 1.6399999633431435, \"match_probability\": 0.7570845229714535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128730.0, \"tn\": 1278736934.0, \"fp\": 858.0, \"fn\": 175231.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42350827902263777, \"tn_rate\": 0.9999993290258524, \"fp_rate\": 6.709741476069553e-07, \"fn_rate\": 0.5764917209773622, \"precision\": 0.9933790165756089, \"recall\": 0.42350827902263777, \"specificity\": 0.9999993290258524, \"npv\": 0.9998629843355974, \"accuracy\": 0.9998623274028491, \"f1\": 0.5938429104899331, \"f2\": 0.4783965298877981, \"f0_5\": 0.7827311498176485, \"p4\": 0.745152075913232, \"phi\": 0.6485719266351275}, {\"truth_threshold\": 1.6599999628961086, \"match_probability\": 0.7596249283250239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128678.0, \"tn\": 1278736978.0, \"fp\": 814.0, \"fn\": 175283.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42333720444399114, \"tn_rate\": 0.999999363434783, \"fp_rate\": 6.365652169604447e-07, \"fn_rate\": 0.5766627955560089, \"precision\": 0.9937138973836221, \"recall\": 0.42333720444399114, \"specificity\": 0.999999363434783, \"npv\": 0.99986294368633, \"accuracy\": 0.9998623211481666, \"f1\": 0.5937344994728379, \"f2\": 0.47823740686341554, \"f0_5\": 0.7827805078054187, \"p4\": 0.7450667218777106, \"phi\": 0.6485502369303305}, {\"truth_threshold\": 1.6799999624490738, \"match_probability\": 0.7621471128706805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128659.0, \"tn\": 1278736978.0, \"fp\": 814.0, \"fn\": 175302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4232746964248703, \"tn_rate\": 0.999999363434783, \"fp_rate\": 6.365652169604447e-07, \"fn_rate\": 0.5767253035751297, \"precision\": 0.993712974905965, \"recall\": 0.4232746964248703, \"specificity\": 0.999999363434783, \"npv\": 0.9998629288319915, \"accuracy\": 0.9998623062932958, \"f1\": 0.5936728544599639, \"f2\": 0.4781735457145045, \"f0_5\": 0.7827373021696095, \"p4\": 0.7450181808506053, \"phi\": 0.6485020482264409}, {\"truth_threshold\": 1.699999962002039, \"match_probability\": 0.764651032191186, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128649.0, \"tn\": 1278736989.0, \"fp\": 803.0, \"fn\": 175312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42324179746743823, \"tn_rate\": 0.9999993720370157, \"fp_rate\": 6.279629842988171e-07, \"fn_rate\": 0.5767582025325617, \"precision\": 0.9937969285912925, \"recall\": 0.42324179746743823, \"specificity\": 0.9999993720370157, \"npv\": 0.9998629210150978, \"accuracy\": 0.9998623070751311, \"f1\": 0.5936554741089908, \"f2\": 0.47814384343668603, \"f0_5\": 0.782756468058542, \"p4\": 0.7450044950819668, \"phi\": 0.6485042458126458}, {\"truth_threshold\": 1.7199999615550041, \"match_probability\": 0.767136645994902, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128612.0, \"tn\": 1278736991.0, \"fp\": 801.0, \"fn\": 175349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42312007132493973, \"tn_rate\": 0.999999373601058, \"fp_rate\": 6.26398941996703e-07, \"fn_rate\": 0.5768799286750603, \"precision\": 0.9938105136269154, \"recall\": 0.42312007132493973, \"specificity\": 0.999999373601058, \"npv\": 0.9998628920884445, \"accuracy\": 0.9998622797108954, \"f1\": 0.593538144881788, \"f2\": 0.47802018499067467, \"f0_5\": 0.7826799235163027, \"p4\": 0.7449120944651991, \"phi\": 0.6484154068681657}, {\"truth_threshold\": 1.7399999611079693, \"match_probability\": 0.7696039180692122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128594.0, \"tn\": 1278736992.0, \"fp\": 800.0, \"fn\": 175367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42306085320156206, \"tn_rate\": 0.9999993743830792, \"fp_rate\": 6.256169208456459e-07, \"fn_rate\": 0.5769391467984379, \"precision\": 0.9938173331066356, \"recall\": 0.42306085320156206, \"specificity\": 0.9999993743830792, \"npv\": 0.999862878016022, \"accuracy\": 0.9998622664196952, \"f1\": 0.5934810951760104, \"f2\": 0.4779600338378785, \"f0_5\": 0.7826427781098112, \"p4\": 0.7448671610357255, \"phi\": 0.6483722513062276}, {\"truth_threshold\": 1.7599999606609344, \"match_probability\": 0.7720528162326886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128552.0, \"tn\": 1278736995.0, \"fp\": 797.0, \"fn\": 175409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42292267758034746, \"tn_rate\": 0.9999993767291426, \"fp_rate\": 6.232708573924747e-07, \"fn_rate\": 0.5770773224196525, \"precision\": 0.993838375248359, \"recall\": 0.42292267758034746, \"specificity\": 0.9999993767291426, \"npv\": 0.9998628451804429, \"accuracy\": 0.9998622359281183, \"f1\": 0.5933488726316032, \"f2\": 0.4778199113435767, \"f0_5\": 0.7825586194553648, \"p4\": 0.7447630077281944, \"phi\": 0.648273215175204}, {\"truth_threshold\": 1.7799999602138996, \"match_probability\": 0.7744833122860583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128532.0, \"tn\": 1278736999.0, \"fp\": 793.0, \"fn\": 175429.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4228568796654834, \"tn_rate\": 0.9999993798572272, \"fp_rate\": 6.201427727882465e-07, \"fn_rate\": 0.5771431203345166, \"precision\": 0.993868161608351, \"recall\": 0.4228568796654834, \"specificity\": 0.9999993798572272, \"npv\": 0.9998628295447294, \"accuracy\": 0.9998622234187534, \"f1\": 0.5932894208444307, \"f2\": 0.47775409632544313, \"f0_5\": 0.782528331431786, \"p4\": 0.7447161713653495, \"phi\": 0.6482324967870613}, {\"truth_threshold\": 1.7999999597668648, \"match_probability\": 0.7768953819620296, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128503.0, \"tn\": 1278736999.0, \"fp\": 793.0, \"fn\": 175458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4227614726889305, \"tn_rate\": 0.9999993798572272, \"fp_rate\": 6.201427727882465e-07, \"fn_rate\": 0.5772385273110695, \"precision\": 0.9938667862888256, \"recall\": 0.4227614726889305, \"specificity\": 0.9999993798572272, \"npv\": 0.9998628068723238, \"accuracy\": 0.9998622007455296, \"f1\": 0.5931952628578419, \"f2\": 0.47765660079991673, \"f0_5\": 0.7824622935048012, \"p4\": 0.7446419857676931, \"phi\": 0.6481589079887384}, {\"truth_threshold\": 1.81999995931983, \"match_probability\": 0.7792890048740371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128484.0, \"tn\": 1278737004.0, \"fp\": 788.0, \"fn\": 175477.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4226989646698096, \"tn_rate\": 0.999999383767333, \"fp_rate\": 6.162326670329612e-07, \"fn_rate\": 0.5773010353301904, \"precision\": 0.9939043257627328, \"recall\": 0.4226989646698096, \"specificity\": 0.999999383767333, \"npv\": 0.9998627920185259, \"accuracy\": 0.9998621897998352, \"f1\": 0.5931404117414878, \"f2\": 0.47759449742624427, \"f0_5\": 0.7824380761684139, \"p4\": 0.744598765707486, \"phi\": 0.6481232285740709}, {\"truth_threshold\": 1.839999958872795, \"match_probability\": 0.781664164463966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128439.0, \"tn\": 1278737004.0, \"fp\": 788.0, \"fn\": 175522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42255091936136546, \"tn_rate\": 0.999999383767333, \"fp_rate\": 6.162326670329612e-07, \"fn_rate\": 0.5774490806386345, \"precision\": 0.9939022030999713, \"recall\": 0.42255091936136546, \"specificity\": 0.999999383767333, \"npv\": 0.99986275683721, \"accuracy\": 0.9998621546172465, \"f1\": 0.5929942657691348, \"f2\": 0.4774431981657474, \"f0_5\": 0.7823355492776558, \"p4\": 0.7444835942979781, \"phi\": 0.6480090161873789}, {\"truth_threshold\": 1.8599999584257603, \"match_probability\": 0.784020847948909, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128416.0, \"tn\": 1278737006.0, \"fp\": 786.0, \"fn\": 175545.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42247525175927175, \"tn_rate\": 0.9999993853313752, \"fp_rate\": 6.14668624730847e-07, \"fn_rate\": 0.5775247482407283, \"precision\": 0.9939165028405132, \"recall\": 0.42247525175927175, \"specificity\": 0.9999993853313752, \"npv\": 0.9998627388558641, \"accuracy\": 0.9998621381987051, \"f1\": 0.5929222948405104, \"f2\": 0.47736657333652527, \"f0_5\": 0.7822907541586, \"p4\": 0.7444268694384543, \"phi\": 0.6479556500902631}, {\"truth_threshold\": 1.8799999579787254, \"match_probability\": 0.7863590462670179, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128383.0, \"tn\": 1278737006.0, \"fp\": 786.0, \"fn\": 175578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.422366685199746, \"tn_rate\": 0.9999993853313752, \"fp_rate\": 6.14668624730847e-07, \"fn_rate\": 0.5776333148002539, \"precision\": 0.993914948633186, \"recall\": 0.422366685199746, \"specificity\": 0.9999993853313752, \"npv\": 0.999862713056235, \"accuracy\": 0.9998621123981399, \"f1\": 0.5928150901576894, \"f2\": 0.4772556101688237, \"f0_5\": 0.7822155228194683, \"p4\": 0.7443423649298104, \"phi\": 0.6478718746398602}, {\"truth_threshold\": 1.8999999575316906, \"match_probability\": 0.7886787540225041, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128378.0, \"tn\": 1278737006.0, \"fp\": 786.0, \"fn\": 175583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42235023572103, \"tn_rate\": 0.9999993853313752, \"fp_rate\": 6.14668624730847e-07, \"fn_rate\": 0.57764976427897, \"precision\": 0.9939147130779474, \"recall\": 0.42235023572103, \"specificity\": 0.9999993853313752, \"npv\": 0.9998627091472003, \"accuracy\": 0.9998621084889635, \"f1\": 0.5927988455988455, \"f2\": 0.4772387970926567, \"f0_5\": 0.7822041220203823, \"p4\": 0.7443295591008068, \"phi\": 0.647859180445278}, {\"truth_threshold\": 1.9199999570846558, \"match_probability\": 0.7909799694298455, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128310.0, \"tn\": 1278737007.0, \"fp\": 785.0, \"fn\": 175651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4221265228104921, \"tn_rate\": 0.9999993861133964, \"fp_rate\": 6.1388660357979e-07, \"fn_rate\": 0.5778734771895079, \"precision\": 0.9939192067857004, \"recall\": 0.4221265228104921, \"specificity\": 0.9999993861133964, \"npv\": 0.9998626559844401, \"accuracy\": 0.999862056105998, \"f1\": 0.5925792507204611, \"f2\": 0.4770104815162621, \"f0_5\": 0.7820528292502752, \"p4\": 0.7441564236019919, \"phi\": 0.6476890242191238}, {\"truth_threshold\": 1.939999956637621, \"match_probability\": 0.7932626942572559, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128271.0, \"tn\": 1278737008.0, \"fp\": 784.0, \"fn\": 175690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4219982168765072, \"tn_rate\": 0.9999993868954176, \"fp_rate\": 6.131045824287329e-07, \"fn_rate\": 0.5780017831234928, \"precision\": 0.993925070706288, \"recall\": 0.4219982168765072, \"specificity\": 0.9999993868954176, \"npv\": 0.999862625494082, \"accuracy\": 0.9998620263962563, \"f1\": 0.5924538585179301, \"f2\": 0.4768796764664112, \"f0_5\": 0.7819676388504488, \"p4\": 0.7440575390647485, \"phi\": 0.6475924848657354}, {\"truth_threshold\": 1.959999956190586, \"match_probability\": 0.7955269337694706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128224.0, \"tn\": 1278737024.0, \"fp\": 768.0, \"fn\": 175737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4218435917765766, \"tn_rate\": 0.999999399407756, \"fp_rate\": 6.005922440118201e-07, \"fn_rate\": 0.5781564082234234, \"precision\": 0.9940461423964276, \"recall\": 0.4218435917765766, \"specificity\": 0.999999399407756, \"npv\": 0.9998625887508835, \"accuracy\": 0.9998620021593618, \"f1\": 0.5923229542236687, \"f2\": 0.47672727380885105, \"f0_5\": 0.7819213614837383, \"p4\": 0.743954292005982, \"phi\": 0.64751326790376}, {\"truth_threshold\": 1.9799999557435513, \"match_probability\": 0.7977726966699026, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128218.0, \"tn\": 1278737032.0, \"fp\": 760.0, \"fn\": 175743.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4218238524021174, \"tn_rate\": 0.9999994056639252, \"fp_rate\": 5.943360748033636e-07, \"fn_rate\": 0.5781761475978826, \"precision\": 0.9941075222130906, \"recall\": 0.4218238524021174, \"specificity\": 0.9999994056639252, \"npv\": 0.9998625840609028, \"accuracy\": 0.9998620037230325, \"f1\": 0.5923143907109316, \"f2\": 0.47670992889765335, \"f0_5\": 0.781938178230043, \"p4\": 0.7439475376219894, \"phi\": 0.6475181145332898}, {\"truth_threshold\": 1.9999999552965164, \"match_probability\": 0.7999999950422251, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128201.0, \"tn\": 1278737033.0, \"fp\": 759.0, \"fn\": 175760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4217679241744829, \"tn_rate\": 0.9999994064459463, \"fp_rate\": 5.935540536523065e-07, \"fn_rate\": 0.5782320758255171, \"precision\": 0.9941144540942928, \"recall\": 0.4217679241744829, \"specificity\": 0.9999994064459463, \"npv\": 0.9998625707702965, \"accuracy\": 0.9998619912136676, \"f1\": 0.5922604817045142, \"f2\": 0.4766531033518639, \"f0_5\": 0.7819031691837409, \"p4\": 0.7439050126762689, \"phi\": 0.6474774409005876}, {\"truth_threshold\": 2.0199999548494816, \"match_probability\": 0.8022088442914298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128162.0, \"tn\": 1278737033.0, \"fp\": 759.0, \"fn\": 175799.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42163961824049795, \"tn_rate\": 0.9999994064459463, \"fp_rate\": 5.935540536523065e-07, \"fn_rate\": 0.578360381759502, \"precision\": 0.9941126736528572, \"recall\": 0.42163961824049795, \"specificity\": 0.9999994064459463, \"npv\": 0.9998625402798367, \"accuracy\": 0.9998619607220907, \"f1\": 0.5921336530509469, \"f2\": 0.47652192018679845, \"f0_5\": 0.7818140780459834, \"p4\": 0.7438049551523891, \"phi\": 0.647378359049081}, {\"truth_threshold\": 2.0399999544024467, \"match_probability\": 0.8043992630844159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128137.0, \"tn\": 1278737033.0, \"fp\": 759.0, \"fn\": 175824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42155737084691786, \"tn_rate\": 0.9999994064459463, \"fp_rate\": 5.935540536523065e-07, \"fn_rate\": 0.5784426291530821, \"precision\": 0.9941115317775571, \"recall\": 0.42155737084691786, \"specificity\": 0.9999994064459463, \"npv\": 0.9998625207346712, \"accuracy\": 0.9998619411762081, \"f1\": 0.5920523406113335, \"f2\": 0.47643782441215404, \"f0_5\": 0.7817569505030231, \"p4\": 0.7437407978455869, \"phi\": 0.6473148370690904}, {\"truth_threshold\": 2.059999953955412, \"match_probability\": 0.8065712732901567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128108.0, \"tn\": 1278737033.0, \"fp\": 759.0, \"fn\": 175853.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42146196387036494, \"tn_rate\": 0.9999994064459463, \"fp_rate\": 5.935540536523065e-07, \"fn_rate\": 0.5785380361296351, \"precision\": 0.9941102066471633, \"recall\": 0.42146196387036494, \"specificity\": 0.9999994064459463, \"npv\": 0.9998624980622801, \"accuracy\": 0.9998619185029841, \"f1\": 0.5919580064136332, \"f2\": 0.4763402693961751, \"f0_5\": 0.7816906650850776, \"p4\": 0.7436663578739007, \"phi\": 0.6472411437662567}, {\"truth_threshold\": 2.079999953508377, \"match_probability\": 0.8087248999194987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128069.0, \"tn\": 1278737034.0, \"fp\": 758.0, \"fn\": 175892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42133365793638, \"tn_rate\": 0.9999994072279675, \"fp_rate\": 5.927720325012495e-07, \"fn_rate\": 0.57866634206362, \"precision\": 0.9941161402501029, \"recall\": 0.42133365793638, \"specificity\": 0.9999994072279675, \"npv\": 0.9998624675719323, \"accuracy\": 0.9998618887932426, \"f1\": 0.5918324907344935, \"f2\": 0.4762094222304192, \"f0_5\": 0.781605309123133, \"p4\": 0.7435672986981321, \"phi\": 0.6471445383694812}, {\"truth_threshold\": 2.0999999530613422, \"match_probability\": 0.8108601710646386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128048.0, \"tn\": 1278737036.0, \"fp\": 756.0, \"fn\": 175913.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42126457012577273, \"tn_rate\": 0.9999994087920098, \"fp_rate\": 5.912079901991354e-07, \"fn_rate\": 0.5787354298742273, \"precision\": 0.9941306170615819, \"recall\": 0.42126457012577273, \"specificity\": 0.9999994087920098, \"npv\": 0.9998624511542107, \"accuracy\": 0.9998618739383718, \"f1\": 0.5917668942728733, \"f2\": 0.4761394803695837, \"f0_5\": 0.7815649121008036, \"p4\": 0.7435155226980524, \"phi\": 0.6470961867707764}, {\"truth_threshold\": 2.1199999526143074, \"match_probability\": 0.8129771178383269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 128013.0, \"tn\": 1278737037.0, \"fp\": 755.0, \"fn\": 175948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42114942377476056, \"tn_rate\": 0.999999409574031, \"fp_rate\": 5.904259690480783e-07, \"fn_rate\": 0.5788505762252394, \"precision\": 0.9941367420477137, \"recall\": 0.42114942377476056, \"specificity\": 0.999999409574031, \"npv\": 0.9998624237910916, \"accuracy\": 0.9998618473559714, \"f1\": 0.5916543610435169, \"f2\": 0.47602207923177836, \"f0_5\": 0.7814886579661625, \"p4\": 0.743426688905857, \"phi\": 0.6470097287079112}, {\"truth_threshold\": 2.1399999521672726, \"match_probability\": 0.8150757743128464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127993.0, \"tn\": 1278737039.0, \"fp\": 753.0, \"fn\": 175968.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4210836258598965, \"tn_rate\": 0.9999994111380732, \"fp_rate\": 5.888619267459642e-07, \"fn_rate\": 0.5789163741401036, \"precision\": 0.9941512746027061, \"recall\": 0.4210836258598965, \"specificity\": 0.9999994111380732, \"npv\": 0.999862408155178, \"accuracy\": 0.9998618332829359, \"f1\": 0.5915920010538309, \"f2\": 0.4759554957273221, \"f0_5\": 0.781450524760515, \"p4\": 0.7433774565785113, \"phi\": 0.6469639096218786}, {\"truth_threshold\": 2.1599999517202377, \"match_probability\": 0.8171561774588095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127951.0, \"tn\": 1278737039.0, \"fp\": 753.0, \"fn\": 176010.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42094545023868196, \"tn_rate\": 0.9999994111380732, \"fp_rate\": 5.888619267459642e-07, \"fn_rate\": 0.5790545497613181, \"precision\": 0.9941493659870712, \"recall\": 0.42094545023868196, \"specificity\": 0.9999994111380732, \"npv\": 0.9998623753193091, \"accuracy\": 0.999861800445853, \"f1\": 0.5914552829556354, \"f2\": 0.4758141769576095, \"f0_5\": 0.7813543858706339, \"p4\": 0.743269505804845, \"phi\": 0.6468571207392567}, {\"truth_threshold\": 2.179999951273203, \"match_probability\": 0.8192183670838221, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127931.0, \"tn\": 1278737040.0, \"fp\": 752.0, \"fn\": 176030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42087965232381785, \"tn_rate\": 0.9999994119200944, \"fp_rate\": 5.880799055949071e-07, \"fn_rate\": 0.5791203476761821, \"precision\": 0.9941561822462952, \"recall\": 0.42087965232381785, \"specificity\": 0.9999994119200944, \"npv\": 0.9998623596832895, \"accuracy\": 0.9998617855909822, \"f1\": 0.5913915366906741, \"f2\": 0.4757472330418058, \"f0_5\": 0.7813124089249572, \"p4\": 0.7432191663338881, \"phi\": 0.6468087768177095}, {\"truth_threshold\": 2.199999950826168, \"match_probability\": 0.8212623857710541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127914.0, \"tn\": 1278737041.0, \"fp\": 751.0, \"fn\": 176047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4208237240961834, \"tn_rate\": 0.9999994127021156, \"fp_rate\": 5.872978844438501e-07, \"fn_rate\": 0.5791762759038166, \"precision\": 0.9941631368281972, \"recall\": 0.4208237240961834, \"specificity\": 0.9999994127021156, \"npv\": 0.9998623463926893, \"accuracy\": 0.9998617730816173, \"f1\": 0.5913375525280496, \"f2\": 0.4756903821395022, \"f0_5\": 0.7812772943767629, \"p4\": 0.7431765327052696, \"phi\": 0.6467680588174236}, {\"truth_threshold\": 2.2199999503791332, \"match_probability\": 0.8232882788177627, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127878.0, \"tn\": 1278737041.0, \"fp\": 751.0, \"fn\": 176083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42070528784942807, \"tn_rate\": 0.9999994127021156, \"fp_rate\": 5.872978844438501e-07, \"fn_rate\": 0.5792947121505719, \"precision\": 0.9941615032379946, \"recall\": 0.42070528784942807, \"specificity\": 0.9999994127021156, \"npv\": 0.9998623182476623, \"accuracy\": 0.9998617449355462, \"f1\": 0.5912203240944081, \"f2\": 0.475569237909575, \"f0_5\": 0.781194828932273, \"p4\": 0.7430839422441197, \"phi\": 0.6466764988456163}, {\"truth_threshold\": 2.2399999499320984, \"match_probability\": 0.8252960941738079, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127839.0, \"tn\": 1278737042.0, \"fp\": 750.0, \"fn\": 176122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4205769819154431, \"tn_rate\": 0.9999994134841367, \"fp_rate\": 5.86515863292793e-07, \"fn_rate\": 0.5794230180845569, \"precision\": 0.99416746377995, \"recall\": 0.4205769819154431, \"specificity\": 0.9999994134841367, \"npv\": 0.9998622877573258, \"accuracy\": 0.9998617152258047, \"f1\": 0.5910946711362848, \"f2\": 0.47543834464045437, \"f0_5\": 0.7811092767228348, \"p4\": 0.7429846827618153, \"phi\": 0.6465798093209277}, {\"truth_threshold\": 2.2599999494850636, \"match_probability\": 0.8272858823802022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127814.0, \"tn\": 1278737043.0, \"fp\": 749.0, \"fn\": 176147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.420494734521863, \"tn_rate\": 0.9999994142661579, \"fp_rate\": 5.857338421417359e-07, \"fn_rate\": 0.579505265478137, \"precision\": 0.9941740625218765, \"recall\": 0.420494734521863, \"specificity\": 0.9999994142661579, \"npv\": 0.999862268212278, \"accuracy\": 0.9998616964617574, \"f1\": 0.5910146026578872, \"f2\": 0.47535456152787064, \"f0_5\": 0.7810557886516103, \"p4\": 0.7429214245590609, \"phi\": 0.6465187242117786}, {\"truth_threshold\": 2.2799999490380287, \"match_probability\": 0.8292576965077321, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127792.0, \"tn\": 1278737043.0, \"fp\": 749.0, \"fn\": 176169.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42042235681551254, \"tn_rate\": 0.9999994142661579, \"fp_rate\": 5.857338421417359e-07, \"fn_rate\": 0.5795776431844875, \"precision\": 0.9941730654032566, \"recall\": 0.42042235681551254, \"specificity\": 0.9999994142661579, \"npv\": 0.9998622510125418, \"accuracy\": 0.9998616792613806, \"f1\": 0.5909429320558055, \"f2\": 0.47528051860144227, \"f0_5\": 0.7810053475935829, \"p4\": 0.7428647956534798, \"phi\": 0.6464627508567362}, {\"truth_threshold\": 2.299999948590994, \"match_probability\": 0.831211592095691, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127756.0, \"tn\": 1278737045.0, \"fp\": 747.0, \"fn\": 176205.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.42030392056875715, \"tn_rate\": 0.9999994158302001, \"fp_rate\": 5.841697998396218e-07, \"fn_rate\": 0.5796960794312428, \"precision\": 0.994186906142269, \"recall\": 0.42030392056875715, \"specificity\": 0.9999994158302001, \"npv\": 0.9998622228677355, \"accuracy\": 0.9998616526789802, \"f1\": 0.5908283695290244, \"f2\": 0.47516005912164044, \"f0_5\": 0.7809304219087916, \"p4\": 0.742774266194023, \"phi\": 0.646376179532772}, {\"truth_threshold\": 2.319999948143959, \"match_probability\": 0.8331476270907604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127714.0, \"tn\": 1278737048.0, \"fp\": 744.0, \"fn\": 176247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4201657449475426, \"tn_rate\": 0.9999994181762636, \"fp_rate\": 5.818237363864506e-07, \"fn_rate\": 0.5798342550524573, \"precision\": 0.994208223699575, \"recall\": 0.4201657449475426, \"specificity\": 0.9999994181762636, \"npv\": 0.9998621900322023, \"accuracy\": 0.9998616221874033, \"f1\": 0.5906955984820278, \"f2\": 0.4750197500264078, \"f0_5\": 0.7808455195874751, \"p4\": 0.7426693317523186, \"phi\": 0.6462768428020316}, {\"truth_threshold\": 2.339999947696924, \"match_probability\": 0.8350658617860744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127676.0, \"tn\": 1278737048.0, \"fp\": 744.0, \"fn\": 176285.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4200407289093009, \"tn_rate\": 0.9999994181762636, \"fp_rate\": 5.818237363864506e-07, \"fn_rate\": 0.5799592710906991, \"precision\": 0.9942065098894253, \"recall\": 0.4200407289093009, \"specificity\": 0.9999994181762636, \"npv\": 0.9998621603235721, \"accuracy\": 0.9998615924776617, \"f1\": 0.5905717411264603, \"f2\": 0.47489183672254853, \"f0_5\": 0.7807583034608098, \"p4\": 0.7425714262028147, \"phi\": 0.646180122295184}, {\"truth_threshold\": 2.3599999472498894, \"match_probability\": 0.8369663587605032, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127640.0, \"tn\": 1278737052.0, \"fp\": 740.0, \"fn\": 176321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41992229266254555, \"tn_rate\": 0.9999994213043483, \"fp_rate\": 5.786956517822225e-07, \"fn_rate\": 0.5800777073374545, \"precision\": 0.9942358622838449, \"recall\": 0.41992229266254555, \"specificity\": 0.9999994213043483, \"npv\": 0.9998621321789869, \"accuracy\": 0.9998615674589318, \"f1\": 0.5904598453535519, \"f2\": 0.47477206179922393, \"f0_5\": 0.7806909273732355, \"p4\": 0.7424829630701225, \"phi\": 0.6460985479676331}, {\"truth_threshold\": 2.3799999468028545, \"match_probability\": 0.8388491828181879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127612.0, \"tn\": 1278737054.0, \"fp\": 738.0, \"fn\": 176349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4198301755817358, \"tn_rate\": 0.9999994228683905, \"fp_rate\": 5.771316094801084e-07, \"fn_rate\": 0.5801698244182641, \"precision\": 0.9942500973899494, \"recall\": 0.4198301755817358, \"specificity\": 0.9999994228683905, \"npv\": 0.9998621102886354, \"accuracy\": 0.9998615471312139, \"f1\": 0.590371283636086, \"f2\": 0.4746785062275237, \"f0_5\": 0.7806342607489224, \"p4\": 0.7424129385978796, \"phi\": 0.646032297152448}, {\"truth_threshold\": 2.3999999463558197, \"match_probability\": 0.8407144009283612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127595.0, \"tn\": 1278737054.0, \"fp\": 738.0, \"fn\": 176366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41977424735410135, \"tn_rate\": 0.9999994228683905, \"fp_rate\": 5.771316094801084e-07, \"fn_rate\": 0.5802257526458987, \"precision\": 0.9942493357125602, \"recall\": 0.41977424735410135, \"specificity\": 0.9999994228683905, \"npv\": 0.9998620969979344, \"accuracy\": 0.9998615338400137, \"f1\": 0.5903158498614369, \"f2\": 0.47462127383521663, \"f0_5\": 0.7805952088174009, \"p4\": 0.7423691038657093, \"phi\": 0.6459890128469864}, {\"truth_threshold\": 2.419999945908785, \"match_probability\": 0.8425620821654828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127581.0, \"tn\": 1278737057.0, \"fp\": 735.0, \"fn\": 176380.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4197281888136965, \"tn_rate\": 0.999999425214454, \"fp_rate\": 5.747855460269372e-07, \"fn_rate\": 0.5802718111863036, \"precision\": 0.9942719536145141, \"recall\": 0.4197281888136965, \"specificity\": 0.999999425214454, \"npv\": 0.999862086052975, \"accuracy\": 0.9998615252398254, \"f1\": 0.5902742917157285, \"f2\": 0.47457519938102605, \"f0_5\": 0.7805745051852305, \"p4\": 0.7423362395899789, \"phi\": 0.645960918704686}, {\"truth_threshold\": 2.43999994546175, \"match_probability\": 0.8443922976497208, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127545.0, \"tn\": 1278737067.0, \"fp\": 725.0, \"fn\": 176416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41960975256694116, \"tn_rate\": 0.9999994330346654, \"fp_rate\": 5.669653345163666e-07, \"fn_rate\": 0.5803902474330589, \"precision\": 0.9943478599828487, \"recall\": 0.41960975256694116, \"specificity\": 0.9999994330346654, \"npv\": 0.9998620579090415, \"accuracy\": 0.9998615049121075, \"f1\": 0.5901705338117812, \"f2\": 0.4744575236921868, \"f0_5\": 0.7805299856433153, \"p4\": 0.7422541802649001, \"phi\": 0.6458944294260914}, {\"truth_threshold\": 2.459999945014715, \"match_probability\": 0.8462051204878077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127490.0, \"tn\": 1278737102.0, \"fp\": 690.0, \"fn\": 176471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41942880830106494, \"tn_rate\": 0.9999994604054058, \"fp_rate\": 5.395945942293696e-07, \"fn_rate\": 0.580571191698935, \"precision\": 0.9946169449212046, \"recall\": 0.41942880830106494, \"specificity\": 0.9999994604054058, \"npv\": 0.9998620149134972, \"accuracy\": 0.9998614892754013, \"f1\": 0.5900388993407244, \"f2\": 0.4742846853925228, \"f0_5\": 0.7805373211817098, \"p4\": 0.7421500601036679, \"phi\": 0.6458425414824273}, {\"truth_threshold\": 2.4799999445676804, \"match_probability\": 0.8480006257142996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127463.0, \"tn\": 1278737104.0, \"fp\": 688.0, \"fn\": 176498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41933998111599846, \"tn_rate\": 0.9999994619694481, \"fp_rate\": 5.380305519272555e-07, \"fn_rate\": 0.5806600188840015, \"precision\": 0.9946313333489399, \"recall\": 0.41933998111599846, \"specificity\": 0.9999994619694481, \"npv\": 0.9998619938049575, \"accuracy\": 0.9998614697295187, \"f1\": 0.5899535305661495, \"f2\": 0.4741944724496743, \"f0_5\": 0.78048287643972, \"p4\": 0.7420825246464293, \"phi\": 0.6457788150449875}, {\"truth_threshold\": 2.4999999441206455, \"match_probability\": 0.8497788902332636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127451.0, \"tn\": 1278737109.0, \"fp\": 683.0, \"fn\": 176510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41930050236708, \"tn_rate\": 0.9999994658795538, \"fp_rate\": 5.341204461719702e-07, \"fn_rate\": 0.5806994976329201, \"precision\": 0.9946696427177798, \"recall\": 0.41930050236708, \"specificity\": 0.9999994658795538, \"npv\": 0.9998619844238283, \"accuracy\": 0.9998614642566716, \"f1\": 0.5899211978847244, \"f2\": 0.47415582695550074, \"f0_5\": 0.7804743924349997, \"p4\": 0.742056944551449, \"phi\": 0.6457608533201354}, {\"truth_threshold\": 2.5199999436736107, \"match_probability\": 0.8515399927604203, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127425.0, \"tn\": 1278737109.0, \"fp\": 683.0, \"fn\": 176536.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4192149650777567, \"tn_rate\": 0.9999994658795538, \"fp_rate\": 5.341204461719702e-07, \"fn_rate\": 0.5807850349222433, \"precision\": 0.9946685609017392, \"recall\": 0.4192149650777567, \"specificity\": 0.9999994658795538, \"npv\": 0.9998619640968801, \"accuracy\": 0.9998614439289536, \"f1\": 0.5898363455836915, \"f2\": 0.4740682702953677, \"f0_5\": 0.7804145797428444, \"p4\": 0.741989807637474, \"phi\": 0.6456946244990517}, {\"truth_threshold\": 2.539999943226576, \"match_probability\": 0.8532840137657655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127407.0, \"tn\": 1278737109.0, \"fp\": 683.0, \"fn\": 176554.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.419155746954379, \"tn_rate\": 0.9999994658795538, \"fp_rate\": 5.341204461719702e-07, \"fn_rate\": 0.580844253045621, \"precision\": 0.994667811694902, \"recall\": 0.419155746954379, \"specificity\": 0.9999994658795538, \"npv\": 0.9998619500243778, \"accuracy\": 0.9998614298559181, \"f1\": 0.5897775957005076, \"f2\": 0.4740076521614901, \"f0_5\": 0.7803731620281728, \"p4\": 0.7419433193039787, \"phi\": 0.6456487697991263}, {\"truth_threshold\": 2.559999942779541, \"match_probability\": 0.8550110354166937, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127392.0, \"tn\": 1278737110.0, \"fp\": 682.0, \"fn\": 176569.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41910639851823095, \"tn_rate\": 0.999999466661575, \"fp_rate\": 5.333384250209131e-07, \"fn_rate\": 0.580893601481769, \"precision\": 0.9946749535424833, \"recall\": 0.41910639851823095, \"specificity\": 0.999999466661575, \"npv\": 0.9998619382974009, \"accuracy\": 0.9998614189102238, \"f1\": 0.589729998726955, \"f2\": 0.4739574884777196, \"f0_5\": 0.7803424656695134, \"p4\": 0.7419056537262019, \"phi\": 0.6456130764690178}, {\"truth_threshold\": 2.579999942332506, \"match_probability\": 0.856721141521646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127365.0, \"tn\": 1278737111.0, \"fp\": 681.0, \"fn\": 176596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4190175713331645, \"tn_rate\": 0.9999994674435961, \"fp_rate\": 5.325564038698561e-07, \"fn_rate\": 0.5809824286668356, \"precision\": 0.994681598800431, \"recall\": 0.4190175713331645, \"specificity\": 0.9999994674435961, \"npv\": 0.9998619171887568, \"accuracy\": 0.9998613985825059, \"f1\": 0.5896432233736953, \"f2\": 0.4738669087499721, \"f0_5\": 0.780284140685785, \"p4\": 0.7418369787190062, \"phi\": 0.6455468062072783}, {\"truth_threshold\": 2.5999999418854713, \"match_probability\": 0.8584144174743045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127342.0, \"tn\": 1278737114.0, \"fp\": 678.0, \"fn\": 176619.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41894190373107076, \"tn_rate\": 0.9999994697896596, \"fp_rate\": 5.302103404166849e-07, \"fn_rate\": 0.5810580962689292, \"precision\": 0.9947039525074207, \"recall\": 0.41894190373107076, \"specificity\": 0.9999994697896596, \"npv\": 0.999861899207552, \"accuracy\": 0.9998613829457997, \"f1\": 0.5895722265562606, \"f2\": 0.4737905026103832, \"f0_5\": 0.7802426593761833, \"p4\": 0.7417807855863345, \"phi\": 0.6454957660390079}, {\"truth_threshold\": 2.6199999414384365, \"match_probability\": 0.8600909501983502, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127320.0, \"tn\": 1278737114.0, \"fp\": 678.0, \"fn\": 176641.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4188695260247203, \"tn_rate\": 0.9999994697896596, \"fp_rate\": 5.302103404166849e-07, \"fn_rate\": 0.5811304739752797, \"precision\": 0.9947030422350349, \"recall\": 0.4188695260247203, \"specificity\": 0.9999994697896596, \"npv\": 0.9998618820078293, \"accuracy\": 0.9998613657454231, \"f1\": 0.5895003923983526, \"f2\": 0.4737164041606082, \"f0_5\": 0.7801919963527311, \"p4\": 0.7417239244105149, \"phi\": 0.6454397036825464}, {\"truth_threshold\": 2.6399999409914017, \"match_probability\": 0.8617508280928082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127299.0, \"tn\": 1278737148.0, \"fp\": 644.0, \"fn\": 176662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.418800438214113, \"tn_rate\": 0.9999994963783787, \"fp_rate\": 5.03621621280745e-07, \"fn_rate\": 0.581199561785887, \"precision\": 0.9949665085233268, \"recall\": 0.418800438214113, \"specificity\": 0.9999994963783787, \"npv\": 0.9998618655935853, \"accuracy\": 0.999861375909282, \"f1\": 0.5894782173816404, \"f2\": 0.4736576555659491, \"f0_5\": 0.7802736924949708, \"p4\": 0.7417063726053321, \"phi\": 0.6454719653175633}, {\"truth_threshold\": 2.659999940544367, \"match_probability\": 0.8633941409779923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127257.0, \"tn\": 1278737151.0, \"fp\": 641.0, \"fn\": 176704.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4186622625928984, \"tn_rate\": 0.9999994987244422, \"fp_rate\": 5.012755578275738e-07, \"fn_rate\": 0.5813377374071016, \"precision\": 0.9949881937168681, \"recall\": 0.4186622625928984, \"specificity\": 0.9999994987244422, \"npv\": 0.9998618327580789, \"accuracy\": 0.9998613454177051, \"f1\": 0.5893451334810668, \"f2\": 0.4735172376840197, \"f0_5\": 0.7801884120345336, \"p4\": 0.7416010121414103, \"phi\": 0.645372500444979}, {\"truth_threshold\": 2.679999940097332, \"match_probability\": 0.8650209800420708, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127229.0, \"tn\": 1278737151.0, \"fp\": 641.0, \"fn\": 176732.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4185701455120887, \"tn_rate\": 0.9999994987244422, \"fp_rate\": 5.012755578275738e-07, \"fn_rate\": 0.5814298544879113, \"precision\": 0.9949870962696489, \"recall\": 0.4185701455120887, \"specificity\": 0.9999994987244422, \"npv\": 0.9998618108675266, \"accuracy\": 0.9998613235263165, \"f1\": 0.5892536663648511, \"f2\": 0.4734229158883512, \"f0_5\": 0.7801238838861426, \"p4\": 0.741528588682708, \"phi\": 0.6453011336806321}, {\"truth_threshold\": 2.699999939650297, \"match_probability\": 0.8666314377882673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127161.0, \"tn\": 1278737151.0, \"fp\": 641.0, \"fn\": 176800.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41834643260155085, \"tn_rate\": 0.9999994987244422, \"fp_rate\": 5.012755578275738e-07, \"fn_rate\": 0.5816535673984491, \"precision\": 0.9949844290386692, \"recall\": 0.41834643260155085, \"specificity\": 0.9999994987244422, \"npv\": 0.9998617577047605, \"accuracy\": 0.9998612703615157, \"f1\": 0.5890314825494543, \"f2\": 0.4731938323040444, \"f0_5\": 0.7799670988469876, \"p4\": 0.7413526293145831, \"phi\": 0.6451277815435426}, {\"truth_threshold\": 2.7199999392032623, \"match_probability\": 0.8682256079827106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127097.0, \"tn\": 1278737153.0, \"fp\": 639.0, \"fn\": 176864.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4181358792739858, \"tn_rate\": 0.9999995002884845, \"fp_rate\": 4.997115155254597e-07, \"fn_rate\": 0.5818641207260142, \"precision\": 0.9949974948330933, \"recall\": 0.4181358792739858, \"specificity\": 0.9999995002884845, \"npv\": 0.9998617076694375, \"accuracy\": 0.9998612218877267, \"f1\": 0.5888250323722426, \"f2\": 0.47297890709894463, \"f0_5\": 0.779827096410011, \"p4\": 0.7411890862891728, \"phi\": 0.6449696351376646}, {\"truth_threshold\": 2.7399999387562275, \"match_probability\": 0.869803585602949, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127072.0, \"tn\": 1278737154.0, \"fp\": 638.0, \"fn\": 176889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41805363188040573, \"tn_rate\": 0.9999995010705056, \"fp_rate\": 4.989294943744026e-07, \"fn_rate\": 0.5819463681195943, \"precision\": 0.9950043066322136, \"recall\": 0.41805363188040573, \"specificity\": 0.9999995010705056, \"npv\": 0.9998616881244144, \"accuracy\": 0.9998612031236794, \"f1\": 0.588744668972435, \"f2\": 0.472895023199663, \"f0_5\": 0.7797732207005146, \"p4\": 0.7411254135760881, \"phi\": 0.6449084012279056}, {\"truth_threshold\": 2.7599999383091927, \"match_probability\": 0.8713654667871419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 127010.0, \"tn\": 1278737170.0, \"fp\": 622.0, \"fn\": 176951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4178496583443271, \"tn_rate\": 0.999999513582844, \"fp_rate\": 4.864171559574896e-07, \"fn_rate\": 0.5821503416556729, \"precision\": 0.995126614015294, \"recall\": 0.4178496583443271, \"specificity\": 0.999999513582844, \"npv\": 0.9998616396542235, \"accuracy\": 0.9998611671592553, \"f1\": 0.5885637626189488, \"f2\": 0.47269173397961706, \"f0_5\": 0.7796913156592661, \"p4\": 0.7409820569816133, \"phi\": 0.6447906775637113}, {\"truth_threshold\": 2.779999937862158, \"match_probability\": 0.8729113487839398, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126991.0, \"tn\": 1278737170.0, \"fp\": 622.0, \"fn\": 176970.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4177871503252062, \"tn_rate\": 0.999999513582844, \"fp_rate\": 4.864171559574896e-07, \"fn_rate\": 0.5822128496747938, \"precision\": 0.995125888428295, \"recall\": 0.4177871503252062, \"specificity\": 0.999999513582844, \"npv\": 0.999861624799926, \"accuracy\": 0.9998611523043845, \"f1\": 0.5885016242869126, \"f2\": 0.4726277059853795, \"f0_5\": 0.7796474270425447, \"p4\": 0.740932808492391, \"phi\": 0.6447422072284281}, {\"truth_threshold\": 2.799999937415123, \"match_probability\": 0.8744413299030646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126978.0, \"tn\": 1278737176.0, \"fp\": 616.0, \"fn\": 176983.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41774438168054456, \"tn_rate\": 0.9999995182749709, \"fp_rate\": 4.817250290511474e-07, \"fn_rate\": 0.5822556183194555, \"precision\": 0.9951721867799427, \"recall\": 0.41774438168054456, \"specificity\": 0.9999995182749709, \"npv\": 0.9998616146371088, \"accuracy\": 0.9998611468315374, \"f1\": 0.5884672869043344, \"f2\": 0.47258600694635705, \"f0_5\": 0.7796403700188006, \"p4\": 0.7409055927060718, \"phi\": 0.6447242052160916}, {\"truth_threshold\": 2.819999936968088, \"match_probability\": 0.8759555094666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126954.0, \"tn\": 1278737188.0, \"fp\": 604.0, \"fn\": 177007.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41766542418270763, \"tn_rate\": 0.9999995276592247, \"fp_rate\": 4.7234077523846266e-07, \"fn_rate\": 0.5823345758172923, \"precision\": 0.9952648991047209, \"recall\": 0.41766542418270763, \"specificity\": 0.9999995276592247, \"npv\": 0.9998615958750853, \"accuracy\": 0.9998611374495138, \"f1\": 0.5884051455439969, \"f2\": 0.47250934567612674, \"f0_5\": 0.7796308737608896, \"p4\": 0.740856336586028, \"phi\": 0.6446933066213514}, {\"truth_threshold\": 2.8399999365210533, \"match_probability\": 0.8774539877610013, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126943.0, \"tn\": 1278737188.0, \"fp\": 604.0, \"fn\": 177018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4176292353295324, \"tn_rate\": 0.9999995276592247, \"fp_rate\": 4.7234077523846266e-07, \"fn_rate\": 0.5823707646704676, \"precision\": 0.995264490736748, \"recall\": 0.4176292353295324, \"specificity\": 0.9999995276592247, \"npv\": 0.9998615872752297, \"accuracy\": 0.9998611288493253, \"f1\": 0.5883691611743004, \"f2\": 0.4724722735227495, \"f0_5\": 0.7796054530558902, \"p4\": 0.7408278115113934, \"phi\": 0.6446652410189304}, {\"truth_threshold\": 2.8599999360740185, \"match_probability\": 0.8789368659898347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126914.0, \"tn\": 1278737189.0, \"fp\": 603.0, \"fn\": 177047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4175338283529795, \"tn_rate\": 0.999999528441246, \"fp_rate\": 4.715587540874056e-07, \"fn_rate\": 0.5824661716470205, \"precision\": 0.9952712187394622, \"recall\": 0.4175338283529795, \"specificity\": 0.999999528441246, \"npv\": 0.9998615646029919, \"accuracy\": 0.9998611069579368, \"f1\": 0.5882756478893478, \"f2\": 0.47237488657181503, \"f0_5\": 0.7795422521802049, \"p4\": 0.7407536768620696, \"phi\": 0.6445937724528181}, {\"truth_threshold\": 2.8799999356269836, \"match_probability\": 0.8804042462272496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126893.0, \"tn\": 1278737191.0, \"fp\": 601.0, \"fn\": 177068.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4174647405423722, \"tn_rate\": 0.9999995300052882, \"fp_rate\": 4.699947117852915e-07, \"fn_rate\": 0.5825352594576277, \"precision\": 0.9952860526769888, \"recall\": 0.4174647405423722, \"specificity\": 0.9999995300052882, \"npv\": 0.9998615481853034, \"accuracy\": 0.999861092103066, \"f1\": 0.5882096626531156, \"f2\": 0.4723048108517737, \"f0_5\": 0.7795013618990168, \"p4\": 0.7407013604885025, \"phi\": 0.6445452406784423}, {\"truth_threshold\": 2.899999935179949, \"match_probability\": 0.8818562313721967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126877.0, \"tn\": 1278737209.0, \"fp\": 583.0, \"fn\": 177084.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.417412102210481, \"tn_rate\": 0.9999995440816689, \"fp_rate\": 4.5591833106626445e-07, \"fn_rate\": 0.582587897789519, \"precision\": 0.9954260160050212, \"recall\": 0.417412102210481, \"specificity\": 0.9999995440816689, \"npv\": 0.9998615356783724, \"accuracy\": 0.9998610936667366, \"f1\": 0.5881818455754356, \"f2\": 0.4722572105792881, \"f0_5\": 0.7795333257147632, \"p4\": 0.7406793054987147, \"phi\": 0.6445499324972802}, {\"truth_threshold\": 2.919999934732914, \"match_probability\": 0.8832929251033927, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126849.0, \"tn\": 1278737212.0, \"fp\": 580.0, \"fn\": 177112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4173199851296712, \"tn_rate\": 0.9999995464277324, \"fp_rate\": 4.5357226761309327e-07, \"fn_rate\": 0.5826800148703287, \"precision\": 0.9954484458011913, \"recall\": 0.4173199851296712, \"specificity\": 0.9999995464277324, \"npv\": 0.999861513788159, \"accuracy\": 0.999861074120854, \"f1\": 0.5880942998215072, \"f2\": 0.4721638862688374, \"f0_5\": 0.7794800639565823, \"p4\": 0.7406098857568204, \"phi\": 0.6444860635345391}, {\"truth_threshold\": 2.939999934285879, \"match_probability\": 0.8847144318350393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126830.0, \"tn\": 1278737212.0, \"fp\": 580.0, \"fn\": 177131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4172574771105504, \"tn_rate\": 0.9999995464277324, \"fp_rate\": 4.5357226761309327e-07, \"fn_rate\": 0.5827425228894496, \"precision\": 0.9954477670512518, \"recall\": 0.4172574771105504, \"specificity\": 0.9999995464277324, \"npv\": 0.9998614989338657, \"accuracy\": 0.9998610592659831, \"f1\": 0.5880321115698551, \"f2\": 0.47209984113205694, \"f0_5\": 0.779436111804189, \"p4\": 0.740560568561621, \"phi\": 0.6444375701532485}, {\"truth_threshold\": 2.9599999338388443, \"match_probability\": 0.8861208566733013, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126796.0, \"tn\": 1278737216.0, \"fp\": 576.0, \"fn\": 177165.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41714562065528143, \"tn_rate\": 0.999999549555817, \"fp_rate\": 4.5044418300886503e-07, \"fn_rate\": 0.5828543793447186, \"precision\": 0.99547781302013, \"recall\": 0.41714562065528143, \"specificity\": 0.999999549555817, \"npv\": 0.9998614723529331, \"accuracy\": 0.999861035810924, \"f1\": 0.5879262657853677, \"f2\": 0.4719866350609284, \"f0_5\": 0.779372769528268, \"p4\": 0.740476620970423, \"phi\": 0.644360904784531}, {\"truth_threshold\": 2.9799999333918095, \"match_probability\": 0.8875123053735477, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126773.0, \"tn\": 1278737228.0, \"fp\": 564.0, \"fn\": 177188.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4170699530531877, \"tn_rate\": 0.9999995589400708, \"fp_rate\": 4.4105992919618036e-07, \"fn_rate\": 0.5829300469468123, \"precision\": 0.9955708081704453, \"recall\": 0.4170699530531877, \"specificity\": 0.9999995589400708, \"npv\": 0.9998614543727217, \"accuracy\": 0.9998610272107357, \"f1\": 0.5878673214343679, \"f2\": 0.47191331622469346, \"f0_5\": 0.7793655301982395, \"p4\": 0.7404298672426672, \"phi\": 0.6443325600660142}, {\"truth_threshold\": 2.9999999329447746, \"match_probability\": 0.8888888842983563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126743.0, \"tn\": 1278737231.0, \"fp\": 561.0, \"fn\": 177218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41697125618089165, \"tn_rate\": 0.9999995612861342, \"fp_rate\": 4.387138657430092e-07, \"fn_rate\": 0.5830287438191084, \"precision\": 0.995593225664551, \"recall\": 0.41697125618089165, \"specificity\": 0.9999995612861342, \"npv\": 0.9998614309189027, \"accuracy\": 0.9998610061011823, \"f1\": 0.5877731789039222, \"f2\": 0.4718132327934077, \"f0_5\": 0.7793075800225535, \"p4\": 0.7403551866651263, \"phi\": 0.6442635655591276}, {\"truth_threshold\": 3.01999993249774, \"match_probability\": 0.8902507003762883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126707.0, \"tn\": 1278737232.0, \"fp\": 560.0, \"fn\": 177254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4168528199341363, \"tn_rate\": 0.9999995620681554, \"fp_rate\": 4.379318445919521e-07, \"fn_rate\": 0.5831471800658637, \"precision\": 0.9955998019910896, \"recall\": 0.4168528199341363, \"specificity\": 0.9999995620681554, \"npv\": 0.9998614027740398, \"accuracy\": 0.9998609787369467, \"f1\": 0.587656645672359, \"f2\": 0.4716922130784425, \"f0_5\": 0.779228047216028, \"p4\": 0.7402627317502821, \"phi\": 0.6441741801696302}, {\"truth_threshold\": 3.039999932050705, \"match_probability\": 0.8915978610614311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126679.0, \"tn\": 1278737233.0, \"fp\": 559.0, \"fn\": 177282.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41676070285332656, \"tn_rate\": 0.9999995628501765, \"fp_rate\": 4.3714982344089506e-07, \"fn_rate\": 0.5832392971466734, \"precision\": 0.9956066583882174, \"recall\": 0.41676070285332656, \"specificity\": 0.9999995628501765, \"npv\": 0.999861380883616, \"accuracy\": 0.9998609576273935, \"f1\": 0.5875662976954956, \"f2\": 0.47159816005277416, \"f0_5\": 0.7791670203330492, \"p4\": 0.7401910423181726, \"phi\": 0.6441052123265846}, {\"truth_threshold\": 3.05999993160367, \"match_probability\": 0.8929304742937143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126655.0, \"tn\": 1278737233.0, \"fp\": 559.0, \"fn\": 177306.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4166817453554897, \"tn_rate\": 0.9999995628501765, \"fp_rate\": 4.3714982344089506e-07, \"fn_rate\": 0.5833182546445104, \"precision\": 0.9956058295470624, \"recall\": 0.4166817453554897, \"specificity\": 0.9999995628501765, \"npv\": 0.9998613621203035, \"accuracy\": 0.999860938863346, \"f1\": 0.5874876790166406, \"f2\": 0.47151723901722786, \"f0_5\": 0.7791114113016829, \"p4\": 0.7401286531719473, \"phi\": 0.6440439206294697}, {\"truth_threshold\": 3.0799999311566353, \"match_probability\": 0.8942486484599944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126628.0, \"tn\": 1278737258.0, \"fp\": 534.0, \"fn\": 177333.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41659291817042315, \"tn_rate\": 0.9999995824007053, \"fp_rate\": 4.175992946644686e-07, \"fn_rate\": 0.5834070818295768, \"precision\": 0.9958006322643557, \"recall\": 0.41659291817042315, \"specificity\": 0.9999995824007053, \"npv\": 0.9998613410142883, \"accuracy\": 0.9998609372996755, \"f1\": 0.5874332847006539, \"f2\": 0.47143497497405074, \"f0_5\": 0.7791447055102761, \"p4\": 0.7400854856154067, \"phi\": 0.644038283933288}, {\"truth_threshold\": 3.0999999307096004, \"match_probability\": 0.8955524923559135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126593.0, \"tn\": 1278737260.0, \"fp\": 532.0, \"fn\": 177368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41647777181941104, \"tn_rate\": 0.9999995839647476, \"fp_rate\": 4.160352523623545e-07, \"fn_rate\": 0.583522228180589, \"precision\": 0.9958151425762045, \"recall\": 0.41647777181941104, \"specificity\": 0.9999995839647476, \"npv\": 0.999861313651344, \"accuracy\": 0.9998609114991104, \"f1\": 0.5873213233554325, \"f2\": 0.47131765513574775, \"f0_5\": 0.7790712415734417, \"p4\": 0.7399966202186629, \"phi\": 0.6439539562004345}, {\"truth_threshold\": 3.1199999302625656, \"match_probability\": 0.8968421151485269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126537.0, \"tn\": 1278737265.0, \"fp\": 527.0, \"fn\": 177424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41629353765779165, \"tn_rate\": 0.9999995878748534, \"fp_rate\": 4.1212514660706925e-07, \"fn_rate\": 0.5837064623422084, \"precision\": 0.9958524837876975, \"recall\": 0.41629353765779165, \"specificity\": 0.9999995878748534, \"npv\": 0.9998612698708319, \"accuracy\": 0.9998608716255097, \"f1\": 0.587144597181138, \"f2\": 0.4711305614383115, \"f0_5\": 0.7789605487203543, \"p4\": 0.7398563246130083, \"phi\": 0.643823571055263}, {\"truth_threshold\": 3.1399999298155308, \"match_probability\": 0.8981176263397019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126522.0, \"tn\": 1278737265.0, \"fp\": 527.0, \"fn\": 177439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4162441892216436, \"tn_rate\": 0.9999995878748534, \"fp_rate\": 4.1212514660706925e-07, \"fn_rate\": 0.5837558107783565, \"precision\": 0.9958519941125078, \"recall\": 0.4162441892216436, \"specificity\": 0.9999995878748534, \"npv\": 0.9998612581437644, \"accuracy\": 0.9998608598979802, \"f1\": 0.5870954270202547, \"f2\": 0.4710799743538763, \"f0_5\": 0.7789257495779757, \"p4\": 0.7398172848126103, \"phi\": 0.6437852475975104}, {\"truth_threshold\": 3.159999929368496, \"match_probability\": 0.899379135730284, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126506.0, \"tn\": 1278737271.0, \"fp\": 521.0, \"fn\": 177455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4161915508897523, \"tn_rate\": 0.9999995925669803, \"fp_rate\": 4.074330197007269e-07, \"fn_rate\": 0.5838084491102477, \"precision\": 0.9958985097656404, \"recall\": 0.4161915508897523, \"specificity\": 0.9999995925669803, \"npv\": 0.9998612456355437, \"accuracy\": 0.9998608520796272, \"f1\": 0.5870511475957567, \"f2\": 0.47102811811410034, \"f0_5\": 0.7789116442075735, \"p4\": 0.7397821264324684, \"phi\": 0.6437595756247942}, {\"truth_threshold\": 3.179999928921461, \"match_probability\": 0.9006267533850288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126476.0, \"tn\": 1278737271.0, \"fp\": 521.0, \"fn\": 177485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41609285401745616, \"tn_rate\": 0.9999995925669803, \"fp_rate\": 4.074330197007269e-07, \"fn_rate\": 0.5839071459825438, \"precision\": 0.9958975408867926, \"recall\": 0.41609285401745616, \"specificity\": 0.9999995925669803, \"npv\": 0.9998612221814102, \"accuracy\": 0.9998608286245679, \"f1\": 0.586952788902863, \"f2\": 0.47092693773871963, \"f0_5\": 0.7788420208658425, \"p4\": 0.7397040206295615, \"phi\": 0.6436829187829523}, {\"truth_threshold\": 3.1999999284744263, \"match_probability\": 0.9018605895982974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126448.0, \"tn\": 1278737404.0, \"fp\": 388.0, \"fn\": 177513.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41600073693664646, \"tn_rate\": 0.9999996965757934, \"fp_rate\": 3.034242066101383e-07, \"fn_rate\": 0.5839992630633535, \"precision\": 0.9969409315967076, \"recall\": 0.41600073693664646, \"specificity\": 0.9999996965757934, \"npv\": 0.999861200305321, \"accuracy\": 0.9998609107172751, \"f1\": 0.5870421567466811, \"f2\": 0.47087913724789227, \"f0_5\": 0.7792876908191124, \"p4\": 0.7397749955974426, \"phi\": 0.6439488481217807}, {\"truth_threshold\": 3.2199999280273914, \"match_probability\": 0.9030807548605116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126437.0, \"tn\": 1278737405.0, \"fp\": 387.0, \"fn\": 177524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4159645480834712, \"tn_rate\": 0.9999996973578146, \"fp_rate\": 3.026421854590812e-07, \"fn_rate\": 0.5840354519165287, \"precision\": 0.9969485270926638, \"recall\": 0.4159645480834712, \"specificity\": 0.9999996973578146, \"npv\": 0.9998611917055822, \"accuracy\": 0.999860902898922, \"f1\": 0.5870074399062177, \"f2\": 0.47084238248025573, \"f0_5\": 0.7792660032517439, \"p4\": 0.7397474281046643, \"phi\": 0.6439232893198169}, {\"truth_threshold\": 3.2399999275803566, \"match_probability\": 0.9042873598253658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126404.0, \"tn\": 1278737406.0, \"fp\": 386.0, \"fn\": 177557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4158559815239455, \"tn_rate\": 0.9999996981398357, \"fp_rate\": 3.0186016430802416e-07, \"fn_rate\": 0.5841440184760545, \"precision\": 0.996955595867182, \"recall\": 0.4158559815239455, \"specificity\": 0.9999996981398357, \"npv\": 0.9998611659061495, \"accuracy\": 0.9998608778801923, \"f1\": 0.5869005527555362, \"f2\": 0.47073141302842025, \"f0_5\": 0.7791932399728277, \"p4\": 0.7396625448572989, \"phi\": 0.6438415270604236}, {\"truth_threshold\": 3.2599999271333218, \"match_probability\": 0.9054805152777908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126373.0, \"tn\": 1278737406.0, \"fp\": 386.0, \"fn\": 177588.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4157539947559062, \"tn_rate\": 0.9999996981398357, \"fp_rate\": 3.0186016430802416e-07, \"fn_rate\": 0.5842460052440939, \"precision\": 0.9969548513320553, \"recall\": 0.4157539947559062, \"specificity\": 0.9999996981398357, \"npv\": 0.999861141670218, \"accuracy\": 0.9998608536432978, \"f1\": 0.5867988484398217, \"f2\": 0.47062683458922705, \"f0_5\": 0.779121254455935, \"p4\": 0.7395817668261461, \"phi\": 0.6437623243311394}, {\"truth_threshold\": 3.279999926686287, \"match_probability\": 0.9066603321026663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126359.0, \"tn\": 1278737407.0, \"fp\": 385.0, \"fn\": 177602.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41570793621550134, \"tn_rate\": 0.9999996989218568, \"fp_rate\": 3.010781431569671e-07, \"fn_rate\": 0.5842920637844987, \"precision\": 0.9969623808622105, \"recall\": 0.41570793621550134, \"specificity\": 0.9999996989218568, \"npv\": 0.9998611307250675, \"accuracy\": 0.9998608434794388, \"f1\": 0.5867542749677854, \"f2\": 0.4705799545355686, \"f0_5\": 0.7790925805580459, \"p4\": 0.7395463614179382, \"phi\": 0.6437290925935105}, {\"truth_threshold\": 3.299999926239252, \"match_probability\": 0.907826921254276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126327.0, \"tn\": 1278737409.0, \"fp\": 383.0, \"fn\": 177634.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4156026595517188, \"tn_rate\": 0.9999997004858991, \"fp_rate\": 2.99514100854853e-07, \"fn_rate\": 0.5843973404482812, \"precision\": 0.9969773498539973, \"recall\": 0.4156026595517188, \"specificity\": 0.9999997004858991, \"npv\": 0.9998611057075509, \"accuracy\": 0.9998608200243796, \"f1\": 0.5866519918917225, \"f2\": 0.47047269607032566, \"f0_5\": 0.7790259262137071, \"p4\": 0.7394651088288555, \"phi\": 0.6436524020833244}, {\"truth_threshold\": 3.3199999257922173, \"match_probability\": 0.9089803937265005, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126300.0, \"tn\": 1278737413.0, \"fp\": 379.0, \"fn\": 177661.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4155138323666523, \"tn_rate\": 0.9999997036139837, \"fp_rate\": 2.9638601625062474e-07, \"fn_rate\": 0.5844861676333477, \"precision\": 0.9970081860450429, \"recall\": 0.4155138323666523, \"specificity\": 0.9999997036139837, \"npv\": 0.9998610845992734, \"accuracy\": 0.9998608020421675, \"f1\": 0.5865688277911945, \"f2\": 0.4703830027493011, \"f0_5\": 0.7789785574279275, \"p4\": 0.7393990365786842, \"phi\": 0.6435935639484422}, {\"truth_threshold\": 3.3399999253451824, \"match_probability\": 0.9101208605237439, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126262.0, \"tn\": 1278737413.0, \"fp\": 379.0, \"fn\": 177699.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41538881632841057, \"tn_rate\": 0.9999997036139837, \"fp_rate\": 2.9638601625062474e-07, \"fn_rate\": 0.5846111836715895, \"precision\": 0.9970072883189488, \"recall\": 0.41538881632841057, \"specificity\": 0.9999997036139837, \"npv\": 0.9998610548907174, \"accuracy\": 0.999860772332426, \"f1\": 0.5864440945467044, \"f2\": 0.47025478869410087, \"f0_5\": 0.7788902254711453, \"p4\": 0.7392999250979002, \"phi\": 0.6434964379569557}, {\"truth_threshold\": 3.3599999248981476, \"match_probability\": 0.9112484326325848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126207.0, \"tn\": 1278737414.0, \"fp\": 378.0, \"fn\": 177754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41520787206253434, \"tn_rate\": 0.9999997043960049, \"fp_rate\": 2.956039950995677e-07, \"fn_rate\": 0.5847921279374657, \"precision\": 0.9970138642019196, \"recall\": 0.41520787206253434, \"specificity\": 0.9999997043960049, \"npv\": 0.9998610118916035, \"accuracy\": 0.9998607301133194, \"f1\": 0.5862648822657741, \"f2\": 0.4700695530266405, \"f0_5\": 0.7787661622039218, \"p4\": 0.7391574980362243, \"phi\": 0.6433583770614931}, {\"truth_threshold\": 3.3799999244511127, \"match_probability\": 0.9123632209941501, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126169.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41508285602429257, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5849171439757074, \"precision\": 0.9971390410255194, \"recall\": 0.41508285602429257, \"specificity\": 0.9999997169083433, \"npv\": 0.999860982184791, \"accuracy\": 0.9998607129129428, \"f1\": 0.5861618798955613, \"f2\": 0.4699469224322563, \"f0_5\": 0.7787392681014955, \"p4\": 0.739075624396149, \"phi\": 0.64330190023661}, {\"truth_threshold\": 3.399999924004078, \"match_probability\": 0.9134653364772011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126138.0, \"tn\": 1278737430.0, \"fp\": 362.0, \"fn\": 177823.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41498086925625327, \"tn_rate\": 0.9999997169083433, \"fp_rate\": 2.8309165668265477e-07, \"fn_rate\": 0.5850191307437468, \"precision\": 0.9971383399209486, \"recall\": 0.41498086925625327, \"specificity\": 0.9999997169083433, \"npv\": 0.9998609579488689, \"accuracy\": 0.9998606886760483, \"f1\": 0.5860600611902124, \"f2\": 0.46984230569809227, \"f0_5\": 0.7786671210095301, \"p4\": 0.7389946801786462, \"phi\": 0.6432226310040001}, {\"truth_threshold\": 3.419999923557043, \"match_probability\": 0.9145548898519266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126095.0, \"tn\": 1278737432.0, \"fp\": 360.0, \"fn\": 177866.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4148394037392955, \"tn_rate\": 0.9999997184723857, \"fp_rate\": 2.8152761438054065e-07, \"fn_rate\": 0.5851605962607045, \"precision\": 0.9971531374797359, \"recall\": 0.4148394037392955, \"specificity\": 0.9999997184723857, \"npv\": 0.999860924331519, \"accuracy\": 0.9998606566208007, \"f1\": 0.5859215270807777, \"f2\": 0.46969788400348955, \"f0_5\": 0.7785747010611511, \"p4\": 0.7388845312481386, \"phi\": 0.6431177483435546}, {\"truth_threshold\": 3.4399999231100082, \"match_probability\": 0.9156319917644378, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126059.0, \"tn\": 1278737438.0, \"fp\": 354.0, \"fn\": 177902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41472096749254017, \"tn_rate\": 0.9999997231645126, \"fp_rate\": 2.768354874741983e-07, \"fn_rate\": 0.5852790325074598, \"precision\": 0.9971996550987636, \"recall\": 0.41472096749254017, \"specificity\": 0.9999997231645126, \"npv\": 0.9998608961872332, \"accuracy\": 0.9998606331657416, \"f1\": 0.5858114105405996, \"f2\": 0.46957847863710156, \"f0_5\": 0.7785139319650253, \"p4\": 0.7387969637713215, \"phi\": 0.6430409321779059}, {\"truth_threshold\": 3.4599999226629734, \"match_probability\": 0.9166967527119539, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126036.0, \"tn\": 1278737442.0, \"fp\": 350.0, \"fn\": 177925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41464529989044646, \"tn_rate\": 0.9999997262925971, \"fp_rate\": 2.737074028699701e-07, \"fn_rate\": 0.5853547001095535, \"precision\": 0.9972307059326191, \"recall\": 0.41464529989044646, \"specificity\": 0.9999997262925971, \"npv\": 0.9998608782061807, \"accuracy\": 0.9998606183108707, \"f1\": 0.5857412739022231, \"f2\": 0.469502246261818, \"f0_5\": 0.7784757351714937, \"p4\": 0.7387411830027999, \"phi\": 0.6429922752351891}, {\"truth_threshold\": 3.4799999222159386, \"match_probability\": 0.9177492830186748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 126017.0, \"tn\": 1278737443.0, \"fp\": 349.0, \"fn\": 177944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4145827918713256, \"tn_rate\": 0.9999997270746183, \"fp_rate\": 2.7292538171891304e-07, \"fn_rate\": 0.5854172081286744, \"precision\": 0.9972381811563237, \"recall\": 0.4145827918713256, \"specificity\": 0.9999997270746183, \"npv\": 0.9998608633520178, \"accuracy\": 0.9998606042378352, \"f1\": 0.5856801920400068, \"f2\": 0.4694384634297167, \"f0_5\": 0.7784353090156593, \"p4\": 0.7386925994651556, \"phi\": 0.6429462135442296}, {\"truth_threshold\": 3.4999999217689037, \"match_probability\": 0.9187896928123295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125991.0, \"tn\": 1278737445.0, \"fp\": 347.0, \"fn\": 177970.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4144972545820023, \"tn_rate\": 0.9999997286386606, \"fp_rate\": 2.713613394167989e-07, \"fn_rate\": 0.5855027454179977, \"precision\": 0.9972533996105685, \"recall\": 0.4144972545820023, \"specificity\": 0.9999997286386606, \"npv\": 0.999860843025338, \"accuracy\": 0.9998605854737879, \"f1\": 0.5855974566522348, \"f2\": 0.46935139943763216, \"f0_5\": 0.7783824058182681, \"p4\": 0.7386267871317597, \"phi\": 0.6428847840001654}, {\"truth_threshold\": 3.519999921321869, \"match_probability\": 0.9198180920013963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125963.0, \"tn\": 1278737445.0, \"fp\": 347.0, \"fn\": 177998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41440513750119257, \"tn_rate\": 0.9999997286386606, \"fp_rate\": 2.713613394167989e-07, \"fn_rate\": 0.5855948624988074, \"precision\": 0.9972527907529095, \"recall\": 0.41440513750119257, \"specificity\": 0.9999997286386606, \"npv\": 0.999860821134834, \"accuracy\": 0.9998605635823993, \"f1\": 0.5855054140297626, \"f2\": 0.4692568811030627, \"f0_5\": 0.7783171301073528, \"p4\": 0.7385535630971516, \"phi\": 0.6428131399252554}, {\"truth_threshold\": 3.539999920874834, \"match_probability\": 0.9208345902529831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125920.0, \"tn\": 1278737445.0, \"fp\": 347.0, \"fn\": 178041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4142636719842348, \"tn_rate\": 0.9999997286386606, \"fp_rate\": 2.713613394167989e-07, \"fn_rate\": 0.5857363280157651, \"precision\": 0.997251855195736, \"recall\": 0.4142636719842348, \"specificity\": 0.9999997286386606, \"npv\": 0.9998607875172761, \"accuracy\": 0.9998605299634812, \"f1\": 0.5853640395325269, \"f2\": 0.46911172026754866, \"f0_5\": 0.7782168500758316, \"p4\": 0.7384410767872696, \"phi\": 0.6427030995524874}, {\"truth_threshold\": 3.5599999204277992, \"match_probability\": 0.9218392969713606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125899.0, \"tn\": 1278737454.0, \"fp\": 338.0, \"fn\": 178062.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41419458417362753, \"tn_rate\": 0.999999735676851, \"fp_rate\": 2.643231490572854e-07, \"fn_rate\": 0.5858054158263725, \"precision\": 0.9973224965739046, \"recall\": 0.41419458417362753, \"specificity\": 0.999999735676851, \"npv\": 0.9998607711003797, \"accuracy\": 0.9998605205814575, \"f1\": 0.5853072306240382, \"f2\": 0.4690439697752967, \"f0_5\": 0.7782024924929751, \"p4\": 0.7383958710126096, \"phi\": 0.6426722689836771}, {\"truth_threshold\": 3.5799999199807644, \"match_probability\": 0.9228323212771417, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125873.0, \"tn\": 1278737457.0, \"fp\": 335.0, \"fn\": 178088.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4141090468843042, \"tn_rate\": 0.9999997380229144, \"fp_rate\": 2.619770856041142e-07, \"fn_rate\": 0.5858909531156957, \"precision\": 0.997345651622718, \"recall\": 0.4141090468843042, \"specificity\": 0.9999997380229144, \"npv\": 0.9998607507738129, \"accuracy\": 0.9998605025992455, \"f1\": 0.5852258066015915, \"f2\": 0.4689572386166855, \"f0_5\": 0.7781533717527229, \"p4\": 0.738331071455966, \"phi\": 0.642613360892945}, {\"truth_threshold\": 3.5999999195337296, \"match_probability\": 0.9238137719870957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125836.0, \"tn\": 1278737457.0, \"fp\": 335.0, \"fn\": 178125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41398732074180566, \"tn_rate\": 0.9999997380229144, \"fp_rate\": 2.619770856041142e-07, \"fn_rate\": 0.5860126792581943, \"precision\": 0.9973448732276038, \"recall\": 0.41398732074180566, \"specificity\": 0.9999997380229144, \"npv\": 0.9998607218470812, \"accuracy\": 0.9998604736713391, \"f1\": 0.585104107576279, \"f2\": 0.4688323155851462, \"f0_5\": 0.7780670133371257, \"p4\": 0.7382342072156036, \"phi\": 0.6425186466466878}, {\"truth_threshold\": 3.6199999190866947, \"match_probability\": 0.9247837575945907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125825.0, \"tn\": 1278737459.0, \"fp\": 333.0, \"fn\": 178136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4139511318886305, \"tn_rate\": 0.9999997395869566, \"fp_rate\": 2.604130433020001e-07, \"fn_rate\": 0.5860488681113696, \"precision\": 0.9973604527655797, \"recall\": 0.4139511318886305, \"specificity\": 0.9999997395869566, \"npv\": 0.9998607132474603, \"accuracy\": 0.9998604666348214, \"f1\": 0.5850706432405915, \"f2\": 0.4687958736276101, \"f0_5\": 0.7780490308474103, \"p4\": 0.7382075693728695, \"phi\": 0.6424955803155373}, {\"truth_threshold\": 3.63999991863966, \"match_probability\": 0.9257423862506543, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125804.0, \"tn\": 1278737459.0, \"fp\": 333.0, \"fn\": 178157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41388204407802315, \"tn_rate\": 0.9999997395869566, \"fp_rate\": 2.604130433020001e-07, \"fn_rate\": 0.5861179559219768, \"precision\": 0.9973600133188517, \"recall\": 0.41388204407802315, \"specificity\": 0.9999997395869566, \"npv\": 0.9998606968295866, \"accuracy\": 0.99986045021628, \"f1\": 0.5850015577845049, \"f2\": 0.46872496704498795, \"f0_5\": 0.7779999975263108, \"p4\": 0.7381525730563903, \"phi\": 0.6424418154384828}, {\"truth_threshold\": 3.659999918192625, \"match_probability\": 0.9266897657456435, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125775.0, \"tn\": 1278737463.0, \"fp\": 329.0, \"fn\": 178186.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41378663710147023, \"tn_rate\": 0.9999997427150413, \"fp_rate\": 2.572849586977719e-07, \"fn_rate\": 0.5862133628985298, \"precision\": 0.9973910423142803, \"recall\": 0.41378663710147023, \"specificity\": 0.9999997427150413, \"npv\": 0.9998606741577215, \"accuracy\": 0.9998604306703973, \"f1\": 0.5849115831327822, \"f2\": 0.4686284416385732, \"f0_5\": 0.777947665507554, \"p4\": 0.7380809407050262, \"phi\": 0.6423777529808702}, {\"truth_threshold\": 3.67999991774559, \"match_probability\": 0.9276260034915159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125742.0, \"tn\": 1278737463.0, \"fp\": 329.0, \"fn\": 178219.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4136780705419445, \"tn_rate\": 0.9999997427150413, \"fp_rate\": 2.572849586977719e-07, \"fn_rate\": 0.5863219294580555, \"precision\": 0.9973903594006552, \"recall\": 0.4136780705419445, \"specificity\": 0.9999997427150413, \"npv\": 0.9998606483582082, \"accuracy\": 0.9998604048698323, \"f1\": 0.5848029914052908, \"f2\": 0.4685170074110506, \"f0_5\": 0.777870571423269, \"p4\": 0.7379944754370115, \"phi\": 0.6422932477910787}, {\"truth_threshold\": 3.6999999172985554, \"match_probability\": 0.9285512065046917, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125726.0, \"tn\": 1278737463.0, \"fp\": 329.0, \"fn\": 178235.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41362543221005327, \"tn_rate\": 0.9999997427150413, \"fp_rate\": 2.572849586977719e-07, \"fn_rate\": 0.5863745677899468, \"precision\": 0.9973900281623101, \"recall\": 0.41362543221005327, \"specificity\": 0.9999997427150413, \"npv\": 0.9998606358493537, \"accuracy\": 0.9998603923604674, \"f1\": 0.5847503348712606, \"f2\": 0.468462976721795, \"f0_5\": 0.7778331834081722, \"p4\": 0.7379525438404477, \"phi\": 0.6422522715771359}, {\"truth_threshold\": 3.7199999168515205, \"match_probability\": 0.9294654813894975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125696.0, \"tn\": 1278737464.0, \"fp\": 328.0, \"fn\": 178265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41352673533775713, \"tn_rate\": 0.9999997434970624, \"fp_rate\": 2.5650293754671484e-07, \"fn_rate\": 0.5864732646622428, \"precision\": 0.9973973211451787, \"recall\": 0.41352673533775713, \"specificity\": 0.9999997434970624, \"npv\": 0.9998606123953614, \"accuracy\": 0.9998603696872435, \"f1\": 0.5846529530099888, \"f2\": 0.46836201474362604, \"f0_5\": 0.777766914957732, \"p4\": 0.7378749891692702, \"phi\": 0.6421779829199286}, {\"truth_threshold\": 3.7399999164044857, \"match_probability\": 0.9303689343221841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125666.0, \"tn\": 1278737473.0, \"fp\": 319.0, \"fn\": 178295.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41342803846546106, \"tn_rate\": 0.9999997505352528, \"fp_rate\": 2.494647471872013e-07, \"fn_rate\": 0.5865719615345389, \"precision\": 0.9974679525340319, \"recall\": 0.41342803846546106, \"specificity\": 0.9999997505352528, \"npv\": 0.9998605889422422, \"accuracy\": 0.999860353268702, \"f1\": 0.5845664339242602, \"f2\": 0.4682638398782557, \"f0_5\": 0.77773142996481, \"p4\": 0.7378060780969309, \"phi\": 0.6421240797617254}, {\"truth_threshold\": 3.759999915957451, \"match_probability\": 0.9312616710355065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125647.0, \"tn\": 1278737473.0, \"fp\": 319.0, \"fn\": 178314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41336553044634017, \"tn_rate\": 0.9999997505352528, \"fp_rate\": 2.494647471872013e-07, \"fn_rate\": 0.5866344695536598, \"precision\": 0.9974675706142927, \"recall\": 0.41336553044634017, \"specificity\": 0.9999997505352528, \"npv\": 0.9998605740879795, \"accuracy\": 0.9998603384138313, \"f1\": 0.5845038808914071, \"f2\": 0.46819967059419737, \"f0_5\": 0.7776869990406338, \"p4\": 0.7377562505104269, \"phi\": 0.6420754073827354}, {\"truth_threshold\": 3.779999915510416, \"match_probability\": 0.9321437968038585, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125619.0, \"tn\": 1278737475.0, \"fp\": 317.0, \"fn\": 178342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4132734133655305, \"tn_rate\": 0.9999997520992951, \"fp_rate\": 2.479007048850872e-07, \"fn_rate\": 0.5867265866344695, \"precision\": 0.997482848430949, \"recall\": 0.4132734133655305, \"specificity\": 0.9999997520992951, \"npv\": 0.9998605521977058, \"accuracy\": 0.9998603180861133, \"f1\": 0.5844144062414951, \"f2\": 0.46810579975852973, \"f0_5\": 0.7776292086838635, \"p4\": 0.7376849713806388, \"phi\": 0.6420087727073968}, {\"truth_threshold\": 3.799999915063381, \"match_probability\": 0.9330154164289524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125589.0, \"tn\": 1278737476.0, \"fp\": 316.0, \"fn\": 178372.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41317471649323434, \"tn_rate\": 0.9999997528813163, \"fp_rate\": 2.471186837340301e-07, \"fn_rate\": 0.5868252835067657, \"precision\": 0.9974901711607959, \"recall\": 0.41317471649323434, \"specificity\": 0.9999997528813163, \"npv\": 0.9998605287437177, \"accuracy\": 0.9998602954128895, \"f1\": 0.5843169731962984, \"f2\": 0.46800482057374365, \"f0_5\": 0.7775628698545409, \"p4\": 0.7376073430418776, \"phi\": 0.6419344563219707}, {\"truth_threshold\": 3.8199999146163464, \"match_probability\": 0.9338766342260325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125570.0, \"tn\": 1278737479.0, \"fp\": 313.0, \"fn\": 178391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41311220847411345, \"tn_rate\": 0.9999997552273797, \"fp_rate\": 2.4477262028085894e-07, \"fn_rate\": 0.5868877915258865, \"precision\": 0.997513564182614, \"recall\": 0.41311220847411345, \"specificity\": 0.9999997552273797, \"npv\": 0.9998605138897838, \"accuracy\": 0.9998602829035246, \"f1\": 0.5842584751677353, \"f2\": 0.46794169007555186, \"f0_5\": 0.7775299600120372, \"p4\": 0.7375607311655785, \"phi\": 0.6418934210111945}, {\"truth_threshold\": 3.8399999141693115, \"match_probability\": 0.9347275540106165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125515.0, \"tn\": 1278737482.0, \"fp\": 310.0, \"fn\": 178446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4129312642082372, \"tn_rate\": 0.9999997575734432, \"fp_rate\": 2.424265568276878e-07, \"fn_rate\": 0.5870687357917628, \"precision\": 0.9975362606795152, \"recall\": 0.4129312642082372, \"specificity\": 0.9999997575734432, \"npv\": 0.9998604708909372, \"accuracy\": 0.9998602422480887, \"f1\": 0.5840813800356457, \"f2\": 0.4677569504848066, \"f0_5\": 0.7774127574601027, \"p4\": 0.737419598442027, \"phi\": 0.6417601198961301}, {\"truth_threshold\": 3.8599999137222767, \"match_probability\": 0.9355682790857505, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125502.0, \"tn\": 1278737485.0, \"fp\": 307.0, \"fn\": 178459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4128884955635756, \"tn_rate\": 0.9999997599195066, \"fp_rate\": 2.4008049337451663e-07, \"fn_rate\": 0.5871115044364245, \"precision\": 0.9975597930195773, \"recall\": 0.4128884955635756, \"specificity\": 0.9999997599195066, \"npv\": 0.9998604607278241, \"accuracy\": 0.9998602344297356, \"f1\": 0.5840426274518928, \"f2\": 0.4677140810626891, \"f0_5\": 0.7773938703934727, \"p4\": 0.7373887112187196, \"phi\": 0.6417344533007853}, {\"truth_threshold\": 3.879999913275242, \"match_probability\": 0.9363989122297732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125488.0, \"tn\": 1278737522.0, \"fp\": 270.0, \"fn\": 178473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41284243702317075, \"tn_rate\": 0.9999997888542892, \"fp_rate\": 2.111457107854055e-07, \"fn_rate\": 0.5871575629768293, \"precision\": 0.9978530192910192, \"recall\": 0.41284243702317075, \"specificity\": 0.9999997888542892, \"npv\": 0.9998604497866179, \"accuracy\": 0.9998602524119476, \"f1\": 0.5840467840612121, \"f2\": 0.46767968443696417, \"f0_5\": 0.7775036462521979, \"p4\": 0.7373920265919235, \"phi\": 0.6417929957252058}, {\"truth_threshold\": 3.899999912828207, \"match_probability\": 0.9372195556845757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125455.0, \"tn\": 1278737522.0, \"fp\": 270.0, \"fn\": 178506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.412733870463645, \"tn_rate\": 0.9999997888542892, \"fp_rate\": 2.111457107854055e-07, \"fn_rate\": 0.587266129536355, \"precision\": 0.9978524557566116, \"recall\": 0.412733870463645, \"specificity\": 0.9999997888542892, \"npv\": 0.9998604239871173, \"accuracy\": 0.9998602266113825, \"f1\": 0.583938038474607, \"f2\": 0.46756819813218703, \"f0_5\": 0.7774263472890621, \"p4\": 0.737305344250336, \"phi\": 0.6417084133820152}, {\"truth_threshold\": 3.919999912381172, \"match_probability\": 0.9380303111443494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125385.0, \"tn\": 1278737522.0, \"fp\": 270.0, \"fn\": 178576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4125035777616207, \"tn_rate\": 0.9999997888542892, \"fp_rate\": 2.111457107854055e-07, \"fn_rate\": 0.5874964222383793, \"precision\": 0.9978512594007402, \"recall\": 0.4125035777616207, \"specificity\": 0.9999997888542892, \"npv\": 0.9998603692609083, \"accuracy\": 0.9998601718829112, \"f1\": 0.5837073107146847, \"f2\": 0.4673316938737934, \"f0_5\": 0.7772622960372237, \"p4\": 0.7371213891177346, \"phi\": 0.6415289593890307}, {\"truth_threshold\": 3.9399999119341373, \"match_probability\": 0.9388312797448133, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125369.0, \"tn\": 1278737522.0, \"fp\": 270.0, \"fn\": 178592.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4124509394297295, \"tn_rate\": 0.9999997888542892, \"fp_rate\": 2.111457107854055e-07, \"fn_rate\": 0.5875490605702706, \"precision\": 0.9978509857607908, \"recall\": 0.4124509394297295, \"specificity\": 0.9999997888542892, \"npv\": 0.9998603567520614, \"accuracy\": 0.9998601593735462, \"f1\": 0.5836545623836127, \"f2\": 0.46727763229202307, \"f0_5\": 0.7772247826146256, \"p4\": 0.7370793262864797, \"phi\": 0.641487934287662}, {\"truth_threshold\": 3.9599999114871025, \"match_probability\": 0.9396225620529085, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125339.0, \"tn\": 1278737524.0, \"fp\": 268.0, \"fn\": 178622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41235224255743336, \"tn_rate\": 0.9999997904183315, \"fp_rate\": 2.0958166848329137e-07, \"fn_rate\": 0.5876477574425667, \"precision\": 0.9978663609512208, \"recall\": 0.41235224255743336, \"specificity\": 0.9999997904183315, \"npv\": 0.9998603332981927, \"accuracy\": 0.9998601374821577, \"f1\": 0.583558365613826, \"f2\": 0.46717695987404684, \"f0_5\": 0.7771621388684617, \"p4\": 0.7370026095005723, \"phi\": 0.6414161135549488}, {\"truth_threshold\": 3.9799999110400677, \"match_probability\": 0.9404042580569533, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125306.0, \"tn\": 1278737524.0, \"fp\": 268.0, \"fn\": 178655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4122436759979076, \"tn_rate\": 0.9999997904183315, \"fp_rate\": 2.0958166848329137e-07, \"fn_rate\": 0.5877563240020923, \"precision\": 0.9978658002452737, \"recall\": 0.4122436759979076, \"specificity\": 0.9999997904183315, \"npv\": 0.999860307498698, \"accuracy\": 0.9998601116815926, \"f1\": 0.5834495442746226, \"f2\": 0.467065448652098, \"f0_5\": 0.7770847260860991, \"p4\": 0.7369158132628281, \"phi\": 0.6413314815213401}, {\"truth_threshold\": 3.999999910593033, \"match_probability\": 0.941176467157249, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125263.0, \"tn\": 1278737534.0, \"fp\": 258.0, \"fn\": 178698.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41210221048094986, \"tn_rate\": 0.999999798238543, \"fp_rate\": 2.017614569727208e-07, \"fn_rate\": 0.5878977895190501, \"precision\": 0.9979445670445583, \"recall\": 0.41210221048094986, \"specificity\": 0.999999798238543, \"npv\": 0.9998602738822694, \"accuracy\": 0.9998600858810275, \"f1\": 0.5833213033375089, \"f2\": 0.46692361885094663, \"f0_5\": 0.7770223746813143, \"p4\": 0.7368135132061591, \"phi\": 0.6412467382029944}, {\"truth_threshold\": 4.019999910145998, \"match_probability\": 0.9419392881571256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125213.0, \"tn\": 1278737534.0, \"fp\": 258.0, \"fn\": 178748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4119377156937897, \"tn_rate\": 0.999999798238543, \"fp_rate\": 2.017614569727208e-07, \"fn_rate\": 0.5880622843062103, \"precision\": 0.9979437479576954, \"recall\": 0.4119377156937897, \"specificity\": 0.999999798238543, \"npv\": 0.9998602347921316, \"accuracy\": 0.9998600467892622, \"f1\": 0.5831563553717468, \"f2\": 0.46675464003608397, \"f0_5\": 0.7769049879319224, \"p4\": 0.7366819061384376, \"phi\": 0.6411184695871301}, {\"truth_threshold\": 4.039999909698963, \"match_probability\": 0.942692819254419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125176.0, \"tn\": 1278737535.0, \"fp\": 257.0, \"fn\": 178785.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4118159895512911, \"tn_rate\": 0.9999997990205641, \"fp_rate\": 2.0097943582166373e-07, \"fn_rate\": 0.5881840104487088, \"precision\": 0.9979510973986112, \"recall\": 0.4118159895512911, \"specificity\": 0.9999997990205641, \"npv\": 0.9998602058655409, \"accuracy\": 0.9998600186431912, \"f1\": 0.5830356269533342, \"f2\": 0.46662993550176435, \"f0_5\": 0.7768219408633313, \"p4\": 0.7365855632126822, \"phi\": 0.6410260904983802}, {\"truth_threshold\": 4.059999909251928, \"match_probability\": 0.9434371580333715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125148.0, \"tn\": 1278737538.0, \"fp\": 254.0, \"fn\": 178813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4117238724704814, \"tn_rate\": 0.9999998013666276, \"fp_rate\": 1.9863337236849258e-07, \"fn_rate\": 0.5882761275295186, \"precision\": 0.9979745139630947, \"recall\": 0.4117238724704814, \"specificity\": 0.9999998013666276, \"npv\": 0.9998601839753943, \"accuracy\": 0.9998599990973086, \"f1\": 0.5829472963436533, \"f2\": 0.46653634008973743, \"f0_5\": 0.7767677256696819, \"p4\": 0.7365150650143464, \"phi\": 0.6409619081641098}, {\"truth_threshold\": 4.0799999088048935, \"match_probability\": 0.9441724014569458, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125073.0, \"tn\": 1278737538.0, \"fp\": 254.0, \"fn\": 178888.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41147713028974114, \"tn_rate\": 0.9999998013666276, \"fp_rate\": 1.9863337236849258e-07, \"fn_rate\": 0.5885228697102589, \"precision\": 0.9979733018423803, \"recall\": 0.41147713028974114, \"specificity\": 0.9999998013666276, \"npv\": 0.9998601253401995, \"accuracy\": 0.9998599404596606, \"f1\": 0.582699726058031, \"f2\": 0.4662828229957254, \"f0_5\": 0.7765914247288794, \"p4\": 0.7363174324038726, \"phi\": 0.6407694101010493}, {\"truth_threshold\": 4.099999908357859, \"match_probability\": 0.944898645859542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125043.0, \"tn\": 1278737539.0, \"fp\": 253.0, \"fn\": 178918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.411378433417445, \"tn_rate\": 0.9999998021486488, \"fp_rate\": 1.9785135121743552e-07, \"fn_rate\": 0.588621566582555, \"precision\": 0.9979807815093857, \"recall\": 0.411378433417445, \"specificity\": 0.9999998021486488, \"npv\": 0.9998601018862329, \"accuracy\": 0.9998599177864368, \"f1\": 0.5826020309511551, \"f2\": 0.4661817558196758, \"f0_5\": 0.7765247253600284, \"p4\": 0.7362394265358381, \"phi\": 0.64069495236579}, {\"truth_threshold\": 4.119999907910824, \"match_probability\": 0.9456159869401111, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 125016.0, \"tn\": 1278737539.0, \"fp\": 253.0, \"fn\": 178945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4112896062323785, \"tn_rate\": 0.9999998021486488, \"fp_rate\": 1.9785135121743552e-07, \"fn_rate\": 0.5887103937676215, \"precision\": 0.9979803462947736, \"recall\": 0.4112896062323785, \"specificity\": 0.9999998021486488, \"npv\": 0.9998600807775655, \"accuracy\": 0.9998598966768836, \"f1\": 0.5825128718868672, \"f2\": 0.4660904785801047, \"f0_5\": 0.7764612061308983, \"p4\": 0.7361682279155137, \"phi\": 0.6406256308556925}, {\"truth_threshold\": 4.139999907463789, \"match_probability\": 0.9463245197556541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124942.0, \"tn\": 1278737541.0, \"fp\": 251.0, \"fn\": 179019.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4110461539473814, \"tn_rate\": 0.999999803712691, \"fp_rate\": 1.962873089153214e-07, \"fn_rate\": 0.5889538460526186, \"precision\": 0.9979950955724362, \"recall\": 0.4110461539473814, \"specificity\": 0.999999803712691, \"npv\": 0.9998600229244041, \"accuracy\": 0.9998598403847415, \"f1\": 0.5822711660616002, \"f2\": 0.4658409872359972, \"f0_5\": 0.7762947462077484, \"p4\": 0.7359751717388363, \"phi\": 0.6404407176222783}, {\"truth_threshold\": 4.159999907016754, \"match_probability\": 0.9470243387150994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124908.0, \"tn\": 1278737543.0, \"fp\": 249.0, \"fn\": 179053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41093429749211247, \"tn_rate\": 0.9999998052767334, \"fp_rate\": 1.9472326661320728e-07, \"fn_rate\": 0.5890657025078875, \"precision\": 0.9980104988134902, \"recall\": 0.41093429749211247, \"specificity\": 0.9999998052767334, \"npv\": 0.9998599963433424, \"accuracy\": 0.9998598153660118, \"f1\": 0.5821615499699383, \"f2\": 0.46572672205315285, \"f0_5\": 0.7762223942907497, \"p4\": 0.7358875993963481, \"phi\": 0.6403585063125007}, {\"truth_threshold\": 4.179999906569719, \"match_probability\": 0.9477155375735482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124887.0, \"tn\": 1278737543.0, \"fp\": 249.0, \"fn\": 179074.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4108652096815052, \"tn_rate\": 0.9999998052767334, \"fp_rate\": 1.9472326661320728e-07, \"fn_rate\": 0.5891347903184948, \"precision\": 0.9980101649405447, \"recall\": 0.4108652096815052, \"specificity\": 0.9999998052767334, \"npv\": 0.9998599799254935, \"accuracy\": 0.9998597989474703, \"f1\": 0.5820921609799183, \"f2\": 0.4656557144774717, \"f0_5\": 0.776172926209284, \"p4\": 0.7358321581524874, \"phi\": 0.6403045619053205}, {\"truth_threshold\": 4.1999999061226845, \"match_probability\": 0.9483982094268801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124829.0, \"tn\": 1278737543.0, \"fp\": 249.0, \"fn\": 179132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41067439572839937, \"tn_rate\": 0.9999998052767334, \"fp_rate\": 1.9472326661320728e-07, \"fn_rate\": 0.5893256042716006, \"precision\": 0.9980092422328467, \"recall\": 0.41067439572839937, \"specificity\": 0.9999998052767334, \"npv\": 0.9998599345809609, \"accuracy\": 0.9998597536010226, \"f1\": 0.5819004799097518, \"f2\": 0.4654595867619444, \"f0_5\": 0.7760362463989218, \"p4\": 0.7356789812510879, \"phi\": 0.6401555489845104}, {\"truth_threshold\": 4.21999990567565, \"match_probability\": 0.9490724467067111, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124795.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179166.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4105625392731304, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5894374607268695, \"precision\": 0.9980246637129925, \"recall\": 0.4105625392731304, \"specificity\": 0.9999998068407757, \"npv\": 0.9998599079999041, \"accuracy\": 0.9998597285822928, \"f1\": 0.5817908033277157, \"f2\": 0.4653453015394299, \"f0_5\": 0.7759638068021425, \"p4\": 0.7355913195161543, \"phi\": 0.640073301203321}, {\"truth_threshold\": 4.239999905228615, \"match_probability\": 0.9497383411756931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124765.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179196.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41046384240083433, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5895361575991657, \"precision\": 0.9980241896777909, \"recall\": 0.41046384240083433, \"specificity\": 0.9999998068407757, \"npv\": 0.9998598845458385, \"accuracy\": 0.9998597051272337, \"f1\": 0.5816916216172113, \"f2\": 0.4652438442308495, \"f0_5\": 0.7758930559235033, \"p4\": 0.7355120354893339, \"phi\": 0.6399962020402282}, {\"truth_threshold\": 4.25999990478158, \"match_probability\": 0.95039598392315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124734.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179227.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.410361855632795, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.589638144367205, \"precision\": 0.9980236996023396, \"recall\": 0.410361855632795, \"specificity\": 0.9999998068407757, \"npv\": 0.9998598603099718, \"accuracy\": 0.9998596808903392, \"f1\": 0.581589119274867, \"f2\": 0.4651390002423881, \"f0_5\": 0.7758199244916872, \"p4\": 0.7354300865638486, \"phi\": 0.6399165231502162}, {\"truth_threshold\": 4.279999904334545, \"match_probability\": 0.9510454653610375, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124705.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41026644865624207, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5897335513437579, \"precision\": 0.998023240924515, \"recall\": 0.41026644865624207, \"specificity\": 0.9999998068407757, \"npv\": 0.9998598376377105, \"accuracy\": 0.9998596582171153, \"f1\": 0.581493216573058, \"f2\": 0.46504091599318614, \"f0_5\": 0.7757514907890203, \"p4\": 0.735353404324499, \"phi\": 0.6398419758546329}, {\"truth_threshold\": 4.29999990388751, \"match_probability\": 0.9516868752202245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124670.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41015130230522995, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5898486976947701, \"precision\": 0.9980226870642106, \"recall\": 0.41015130230522995, \"specificity\": 0.9999998068407757, \"npv\": 0.9998598102746378, \"accuracy\": 0.9998596308528795, \"f1\": 0.581377454660766, \"f2\": 0.46492253280040213, \"f0_5\": 0.7756688720790315, \"p4\": 0.7352608305967248, \"phi\": 0.6397519934169137}, {\"truth_threshold\": 4.3199999034404755, \"match_probability\": 0.9523203025470809, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124642.0, \"tn\": 1278737545.0, \"fp\": 247.0, \"fn\": 179319.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.41005918522442025, \"tn_rate\": 0.9999998068407757, \"fp_rate\": 1.9315922431109316e-07, \"fn_rate\": 0.5899408147755798, \"precision\": 0.9980222437524522, \"recall\": 0.41005918522442025, \"specificity\": 0.9999998068407757, \"npv\": 0.9998597883841807, \"accuracy\": 0.9998596089614911, \"f1\": 0.5812848315261746, \"f2\": 0.4648278217959877, \"f0_5\": 0.7756027563822545, \"p4\": 0.7351867509755574, \"phi\": 0.6396799983569262}, {\"truth_threshold\": 4.339999902993441, \"match_probability\": 0.9529458357003701, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124582.0, \"tn\": 1278737548.0, \"fp\": 244.0, \"fn\": 179379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.409861791479828, \"tn_rate\": 0.9999998091868392, \"fp_rate\": 1.90813160857922e-07, \"fn_rate\": 0.590138208520172, \"precision\": 0.9980452790284076, \"recall\": 0.409861791479828, \"specificity\": 0.9999998091868392, \"npv\": 0.9998597414763907, \"accuracy\": 0.9998595643968786, \"f1\": 0.5810903782064288, \"f2\": 0.46462589600722026, \"f0_5\": 0.7754726024412865, \"p4\": 0.7350311999242118, \"phi\": 0.6395333838177644}, {\"truth_threshold\": 4.359999902546406, \"match_probability\": 0.9535635623484342, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124562.0, \"tn\": 1278737548.0, \"fp\": 244.0, \"fn\": 179399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40979599356496393, \"tn_rate\": 0.9999998091868392, \"fp_rate\": 1.90813160857922e-07, \"fn_rate\": 0.5902040064350361, \"precision\": 0.9980449657869013, \"recall\": 0.40979599356496393, \"specificity\": 0.9999998091868392, \"npv\": 0.999859725840352, \"accuracy\": 0.9998595487601725, \"f1\": 0.5810241926267646, \"f2\": 0.46455823667623913, \"f0_5\": 0.7754253378735908, \"p4\": 0.7349782466199495, \"phi\": 0.6394819420243083}, {\"truth_threshold\": 4.379999902099371, \"match_probability\": 0.9541735694666671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124536.0, \"tn\": 1278737548.0, \"fp\": 244.0, \"fn\": 179425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4097104562756406, \"tn_rate\": 0.9999998091868392, \"fp_rate\": 1.90813160857922e-07, \"fn_rate\": 0.5902895437243594, \"precision\": 0.9980445584228241, \"recall\": 0.4097104562756406, \"specificity\": 0.9999998091868392, \"npv\": 0.9998597055135025, \"accuracy\": 0.9998595284324545, \"f1\": 0.5809381421417592, \"f2\": 0.4644702765279452, \"f0_5\": 0.7753638798576981, \"p4\": 0.7349093933101795, \"phi\": 0.639415061508167}, {\"truth_threshold\": 4.399999901652336, \"match_probability\": 0.9547759433352639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124516.0, \"tn\": 1278737548.0, \"fp\": 244.0, \"fn\": 179445.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40964465836077657, \"tn_rate\": 0.9999998091868392, \"fp_rate\": 1.90813160857922e-07, \"fn_rate\": 0.5903553416392234, \"precision\": 0.9980442449503046, \"recall\": 0.40964465836077657, \"specificity\": 0.9999998091868392, \"npv\": 0.999859689877465, \"accuracy\": 0.9998595127957485, \"f1\": 0.5808719423587835, \"f2\": 0.46440261255374443, \"f0_5\": 0.7753165936281524, \"p4\": 0.7348564184424153, \"phi\": 0.6393636101986039}, {\"truth_threshold\": 4.419999901205301, \"match_probability\": 0.955370769537244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124461.0, \"tn\": 1278737554.0, \"fp\": 238.0, \"fn\": 179500.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40946371409490034, \"tn_rate\": 0.9999998138789661, \"fp_rate\": 1.8612103395157965e-07, \"fn_rate\": 0.5905362859050997, \"precision\": 0.9980914041010754, \"recall\": 0.40946371409490034, \"specificity\": 0.9999998138789661, \"npv\": 0.9998596468790227, \"accuracy\": 0.9998594744858185, \"f1\": 0.5806979890822563, \"f2\": 0.46421860395377096, \"f0_5\": 0.7752096836277977, \"p4\": 0.7347171955261254, \"phi\": 0.6392374817542685}, {\"truth_threshold\": 4.4399999007582664, \"match_probability\": 0.9559581329567363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124438.0, \"tn\": 1278737559.0, \"fp\": 233.0, \"fn\": 179523.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40938804649280663, \"tn_rate\": 0.9999998177890718, \"fp_rate\": 1.8221092819629437e-07, \"fn_rate\": 0.5906119535071933, \"precision\": 0.9981310810052058, \"recall\": 0.40938804649280663, \"specificity\": 0.9999998177890718, \"npv\": 0.9998596288981305, \"accuracy\": 0.999859460412783, \"f1\": 0.5806286044905653, \"f2\": 0.4641425123926252, \"f0_5\": 0.7751745790480224, \"p4\": 0.7346616554178733, \"phi\": 0.6391911179768399}, {\"truth_threshold\": 4.459999900311232, \"match_probability\": 0.9565381177775213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124419.0, \"tn\": 1278737559.0, \"fp\": 233.0, \"fn\": 179542.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40932553847368575, \"tn_rate\": 0.9999998177890718, \"fp_rate\": 1.8221092819629437e-07, \"fn_rate\": 0.5906744615263142, \"precision\": 0.9981307961364438, \"recall\": 0.40932553847368575, \"specificity\": 0.9999998177890718, \"npv\": 0.9998596140438973, \"accuracy\": 0.9998594455579122, \"f1\": 0.5805656851285426, \"f2\": 0.4640782217925305, \"f0_5\": 0.775129615023755, \"p4\": 0.7346112860176711, \"phi\": 0.6391422221961899}, {\"truth_threshold\": 4.479999899864197, \"match_probability\": 0.9571108074818223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124396.0, \"tn\": 1278737559.0, \"fp\": 233.0, \"fn\": 179565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4092498708715921, \"tn_rate\": 0.9999998177890718, \"fp_rate\": 1.8221092819629437e-07, \"fn_rate\": 0.590750129128408, \"precision\": 0.9981304511790996, \"recall\": 0.4092498708715921, \"specificity\": 0.9999998177890718, \"npv\": 0.9998595960624576, \"accuracy\": 0.9998594275757001, \"f1\": 0.5804895121211414, \"f2\": 0.46400039389081316, \"f0_5\": 0.775075173494069, \"p4\": 0.7345503011924708, \"phi\": 0.6390830275637497}, {\"truth_threshold\": 4.499999899417162, \"match_probability\": 0.9576762848493385, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124286.0, \"tn\": 1278737560.0, \"fp\": 232.0, \"fn\": 179675.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40888798233983964, \"tn_rate\": 0.999999818571093, \"fp_rate\": 1.814289070452373e-07, \"fn_rate\": 0.5911120176601603, \"precision\": 0.9981368155608025, \"recall\": 0.40888798233983964, \"specificity\": 0.999999818571093, \"npv\": 0.9998595100643866, \"accuracy\": 0.9998593423556518, \"f1\": 0.5801264472704614, \"f2\": 0.46362848245473987, \"f0_5\": 0.7748184925059194, \"p4\": 0.7342595473391855, \"phi\": 0.6388024130371414}, {\"truth_threshold\": 4.519999898970127, \"match_probability\": 0.9582346319565136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124259.0, \"tn\": 1278737560.0, \"fp\": 232.0, \"fn\": 179702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40879915515477316, \"tn_rate\": 0.999999818571093, \"fp_rate\": 1.814289070452373e-07, \"fn_rate\": 0.5912008448452268, \"precision\": 0.9981364114674957, \"recall\": 0.40879915515477316, \"specificity\": 0.999999818571093, \"npv\": 0.9998594889557445, \"accuracy\": 0.9998593212460986, \"f1\": 0.580036970302391, \"f2\": 0.463537100799427, \"f0_5\": 0.7747544969916139, \"p4\": 0.7341878708089471, \"phi\": 0.6387328861704572}, {\"truth_threshold\": 4.539999898523092, \"match_probability\": 0.9587859301760313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124233.0, \"tn\": 1278737560.0, \"fp\": 232.0, \"fn\": 179728.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40871361786544985, \"tn_rate\": 0.999999818571093, \"fp_rate\": 1.814289070452373e-07, \"fn_rate\": 0.5912863821345502, \"precision\": 0.9981360221749086, \"recall\": 0.40871361786544985, \"specificity\": 0.999999818571093, \"npv\": 0.9998594686289048, \"accuracy\": 0.9998593009183806, \"f1\": 0.5799507966369921, \"f2\": 0.46344910017018465, \"f0_5\": 0.7746928553879232, \"p4\": 0.7341188327533319, \"phi\": 0.6386659272222065}, {\"truth_threshold\": 4.559999898076057, \"match_probability\": 0.959330260176534, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124211.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179750.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40864124015909936, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5913587598409007, \"precision\": 0.9981757983895595, \"recall\": 0.40864124015909936, \"specificity\": 0.9999998224811987, \"npv\": 0.9998594514298214, \"accuracy\": 0.9998592876271803, \"f1\": 0.5798846402535953, \"f2\": 0.46337636407860433, \"f0_5\": 0.7746600092551823, \"p4\": 0.7340658267510042, \"phi\": 0.6386220987709923}, {\"truth_threshold\": 4.579999897629023, \"match_probability\": 0.9598677019225548, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124184.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179777.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40855241297403283, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5914475870259671, \"precision\": 0.9981754024965638, \"recall\": 0.40855241297403283, \"specificity\": 0.9999998224811987, \"npv\": 0.9998594303211817, \"accuracy\": 0.9998592665176271, \"f1\": 0.5797951313344476, \"f2\": 0.4632849718896777, \"f0_5\": 0.7745959668415242, \"p4\": 0.7339941026775618, \"phi\": 0.6385525522694888}, {\"truth_threshold\": 4.599999897181988, \"match_probability\": 0.9603983346746578, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124099.0, \"tn\": 1278737565.0, \"fp\": 227.0, \"fn\": 179862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4082727718358605, \"tn_rate\": 0.9999998224811987, \"fp_rate\": 1.77518801289952e-07, \"fn_rate\": 0.5917272281641395, \"precision\": 0.9981741550439972, \"recall\": 0.4082727718358605, \"specificity\": 0.9999998224811987, \"npv\": 0.9998593638680631, \"accuracy\": 0.9998592000616261, \"f1\": 0.5795132703070605, \"f2\": 0.46299723169448653, \"f0_5\": 0.7743942391094083, \"p4\": 0.7337681925274178, \"phi\": 0.638333560124807}, {\"truth_threshold\": 4.619999896734953, \"match_probability\": 0.9609222369897813, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124070.0, \"tn\": 1278737568.0, \"fp\": 224.0, \"fn\": 179891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4081773648593076, \"tn_rate\": 0.9999998248272621, \"fp_rate\": 1.7517273783678086e-07, \"fn_rate\": 0.5918226351406924, \"precision\": 0.9981978212946723, \"recall\": 0.4081773648593076, \"specificity\": 0.9999998248272621, \"npv\": 0.9998593411961546, \"accuracy\": 0.9998591797339081, \"f1\": 0.5794211392744977, \"f2\": 0.46290008939377886, \"f0_5\": 0.7743369735763047, \"p4\": 0.7336943326879719, \"phi\": 0.6382665334576597}, {\"truth_threshold\": 4.639999896287918, \"match_probability\": 0.9614394867217748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124043.0, \"tn\": 1278737571.0, \"fp\": 221.0, \"fn\": 179918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4080885376742411, \"tn_rate\": 0.9999998271733256, \"fp_rate\": 1.7282667438360968e-07, \"fn_rate\": 0.5919114623257589, \"precision\": 0.9982215283589777, \"recall\": 0.4080885376742411, \"specificity\": 0.9999998271733256, \"npv\": 0.9998593200878497, \"accuracy\": 0.9998591609698608, \"f1\": 0.5793356296339541, \"f2\": 0.46280971384395886, \"f0_5\": 0.7742844409045001, \"p4\": 0.7336257734070492, \"phi\": 0.6382046548156303}, {\"truth_threshold\": 4.659999895840883, \"match_probability\": 0.9619501610221266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 124013.0, \"tn\": 1278737572.0, \"fp\": 220.0, \"fn\": 179948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.407989840801945, \"tn_rate\": 0.9999998279553468, \"fp_rate\": 1.7204465323255262e-07, \"fn_rate\": 0.592010159198055, \"precision\": 0.9982291339660154, \"recall\": 0.407989840801945, \"specificity\": 0.9999998279553468, \"npv\": 0.9998592966339221, \"accuracy\": 0.999859138296637, \"f1\": 0.579237448446265, \"f2\": 0.46270848615415383, \"f0_5\": 0.7742170302399946, \"p4\": 0.7335470451206147, \"phi\": 0.6381298991513826}, {\"truth_threshold\": 4.679999895393848, \"match_probability\": 0.9624543363408739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123945.0, \"tn\": 1278737572.0, \"fp\": 220.0, \"fn\": 180016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40776612789140715, \"tn_rate\": 0.9999998279553468, \"fp_rate\": 1.7204465323255262e-07, \"fn_rate\": 0.5922338721085929, \"precision\": 0.9982281641364313, \"recall\": 0.40776612789140715, \"specificity\": 0.9999998279553468, \"npv\": 0.999859243471441, \"accuracy\": 0.9998590851318362, \"f1\": 0.5790117862498423, \"f2\": 0.46247823708646735, \"f0_5\": 0.7740553895038976, \"p4\": 0.7333660567301034, \"phi\": 0.6379545953920488}, {\"truth_threshold\": 4.699999894946814, \"match_probability\": 0.9629520884276901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123904.0, \"tn\": 1278737576.0, \"fp\": 216.0, \"fn\": 180057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40763124216593577, \"tn_rate\": 0.9999998310834314, \"fp_rate\": 1.6891656862832438e-07, \"fn_rate\": 0.5923687578340643, \"precision\": 0.9982597486303577, \"recall\": 0.40763124216593577, \"specificity\": 0.9999998310834314, \"npv\": 0.9998592114180351, \"accuracy\": 0.9998590562039299, \"f1\": 0.5788810996049814, \"f2\": 0.4623407793045186, \"f0_5\": 0.7739733471923602, \"p4\": 0.7332612184050895, \"phi\": 0.6378591560172736}, {\"truth_threshold\": 4.719999894499779, \"match_probability\": 0.9634434923331444, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123858.0, \"tn\": 1278737577.0, \"fp\": 215.0, \"fn\": 180103.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4074799069617484, \"tn_rate\": 0.9999998318654525, \"fp_rate\": 1.6813454747726735e-07, \"fn_rate\": 0.5925200930382516, \"precision\": 0.9982671491783063, \"recall\": 0.4074799069617484, \"specificity\": 0.9999998318654525, \"npv\": 0.9998591754552959, \"accuracy\": 0.9998590210213412, \"f1\": 0.5787297270777555, \"f2\": 0.46218534431610314, \"f0_5\": 0.773867764319534, \"p4\": 0.7331397637099417, \"phi\": 0.6377430941047141}, {\"truth_threshold\": 4.739999894052744, \"match_probability\": 0.9639286224101253, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123839.0, \"tn\": 1278737578.0, \"fp\": 214.0, \"fn\": 180122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4074173989426275, \"tn_rate\": 0.9999998326474737, \"fp_rate\": 1.6735252632621029e-07, \"fn_rate\": 0.5925826010573725, \"precision\": 0.998274930876319, \"recall\": 0.4074173989426275, \"specificity\": 0.9999998326474737, \"npv\": 0.9998591606011864, \"accuracy\": 0.9998590069483057, \"f1\": 0.5786679874957361, \"f2\": 0.46212134216286777, \"f0_5\": 0.7738264100388291, \"p4\": 0.7330902199204783, \"phi\": 0.637696658534029}, {\"truth_threshold\": 4.759999893605709, \"match_probability\": 0.9644075523154256, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123801.0, \"tn\": 1278737580.0, \"fp\": 212.0, \"fn\": 180160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40729238290438574, \"tn_rate\": 0.999999834211516, \"fp_rate\": 1.6578848402409617e-07, \"fn_rate\": 0.5927076170956143, \"precision\": 0.9982905018022304, \"recall\": 0.40729238290438574, \"specificity\": 0.999999834211516, \"npv\": 0.999859130892969, \"accuracy\": 0.9998589788022346, \"f1\": 0.5785444910204826, \"f2\": 0.4619933321242491, \"f0_5\": 0.7737436766652542, \"p4\": 0.7329911068227424, \"phi\": 0.6376037773679284}, {\"truth_threshold\": 4.779999893158674, \"match_probability\": 0.9648803550114816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123696.0, \"tn\": 1278737580.0, \"fp\": 212.0, \"fn\": 180265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40694694385134933, \"tn_rate\": 0.999999834211516, \"fp_rate\": 1.6578848402409617e-07, \"fn_rate\": 0.5930530561486507, \"precision\": 0.9982890531684798, \"recall\": 0.40694694385134933, \"specificity\": 0.999999834211516, \"npv\": 0.9998590488038737, \"accuracy\": 0.9998588967095275, \"f1\": 0.5781956626911507, \"f2\": 0.4616376762266449, \"f0_5\": 0.7734935148256675, \"p4\": 0.7327110676953222, \"phi\": 0.6373328440675355}, {\"truth_threshold\": 4.799999892711639, \"match_probability\": 0.9653471027682606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123672.0, \"tn\": 1278737583.0, \"fp\": 209.0, \"fn\": 180289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40686798635351246, \"tn_rate\": 0.9999998365575794, \"fp_rate\": 1.6344242057092499e-07, \"fn_rate\": 0.5931320136464875, \"precision\": 0.9983128970544313, \"recall\": 0.40686798635351246, \"specificity\": 0.9999998365575794, \"npv\": 0.9998590300409845, \"accuracy\": 0.9998588802909861, \"f1\": 0.5781199601722131, \"f2\": 0.4615574091697923, \"f0_5\": 0.7734479070901893, \"p4\": 0.7326502776094331, \"phi\": 0.6372786194972188}, {\"truth_threshold\": 4.819999892264605, \"match_probability\": 0.9658078671652934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123635.0, \"tn\": 1278737585.0, \"fp\": 207.0, \"fn\": 180326.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4067462602110139, \"tn_rate\": 0.9999998381216217, \"fp_rate\": 1.6187837826881087e-07, \"fn_rate\": 0.5932537397889861, \"precision\": 0.9983285153663539, \"recall\": 0.4067462602110139, \"specificity\": 0.9999998381216217, \"npv\": 0.9998590011145758, \"accuracy\": 0.9998588529267504, \"f1\": 0.577999686771715, \"f2\": 0.46143275364525715, \"f0_5\": 0.7733674119167452, \"p4\": 0.7325536843736324, \"phi\": 0.6371882592554273}, {\"truth_threshold\": 4.83999989181757, \"match_probability\": 0.9662627190938445, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123607.0, \"tn\": 1278737585.0, \"fp\": 207.0, \"fn\": 180354.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4066541431302042, \"tn_rate\": 0.9999998381216217, \"fp_rate\": 1.6187837826881087e-07, \"fn_rate\": 0.5933458568697958, \"precision\": 0.9983281373673414, \"recall\": 0.4066541431302042, \"specificity\": 0.9999998381216217, \"npv\": 0.9998589792241549, \"accuracy\": 0.9998588310353619, \"f1\": 0.5779066097831804, \"f2\": 0.46133789370122824, \"f0_5\": 0.7733006179798477, \"p4\": 0.7324789227515411, \"phi\": 0.6371159745259983}, {\"truth_threshold\": 4.859999891370535, \"match_probability\": 0.9667117287592163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123574.0, \"tn\": 1278737585.0, \"fp\": 207.0, \"fn\": 180387.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40654557657067847, \"tn_rate\": 0.9999998381216217, \"fp_rate\": 1.6187837826881087e-07, \"fn_rate\": 0.5934544234293215, \"precision\": 0.9983276916489606, \"recall\": 0.40654557657067847, \"specificity\": 0.9999998381216217, \"npv\": 0.9998589534247314, \"accuracy\": 0.9998588052347968, \"f1\": 0.5777968962598949, \"f2\": 0.4612260893906877, \"f0_5\": 0.773221872516691, \"p4\": 0.7323907869497503, \"phi\": 0.6370307712833031}, {\"truth_threshold\": 4.8799998909235, \"match_probability\": 0.9671549656831816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123534.0, \"tn\": 1278737585.0, \"fp\": 207.0, \"fn\": 180427.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4064139807409503, \"tn_rate\": 0.9999998381216217, \"fp_rate\": 1.6187837826881087e-07, \"fn_rate\": 0.5935860192590496, \"precision\": 0.998327151065532, \"recall\": 0.4064139807409503, \"specificity\": 0.9999998381216217, \"npv\": 0.9998589221527048, \"accuracy\": 0.9998587739613846, \"f1\": 0.5776638874730536, \"f2\": 0.4610905616291613, \"f0_5\": 0.7731263885846607, \"p4\": 0.7322839210050841, \"phi\": 0.6369274793507175}, {\"truth_threshold\": 4.899999890476465, \"match_probability\": 0.9675924987065404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123429.0, \"tn\": 1278737585.0, \"fp\": 207.0, \"fn\": 180532.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4060685416879139, \"tn_rate\": 0.9999998381216217, \"fp_rate\": 1.6187837826881087e-07, \"fn_rate\": 0.593931458312086, \"precision\": 0.9983257303697952, \"recall\": 0.4060685416879139, \"specificity\": 0.9999998381216217, \"npv\": 0.9998588400636442, \"accuracy\": 0.9998586918686774, \"f1\": 0.5773146210099697, \"f2\": 0.4607347627437513, \"f0_5\": 0.7728755612050019, \"p4\": 0.7320032169876071, \"phi\": 0.6366562583268809}, {\"truth_threshold\": 4.91999989002943, \"match_probability\": 0.968024395991795, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123386.0, \"tn\": 1278737586.0, \"fp\": 206.0, \"fn\": 180575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40592707617095614, \"tn_rate\": 0.9999998389036429, \"fp_rate\": 1.610963571177538e-07, \"fn_rate\": 0.5940729238290439, \"precision\": 0.9983332254514855, \"recall\": 0.40592707617095614, \"specificity\": 0.9999998389036429, \"npv\": 0.9998588064463336, \"accuracy\": 0.9998586590315945, \"f1\": 0.5771728885073897, \"f2\": 0.46058938239677, \"f0_5\": 0.7727766372009535, \"p4\": 0.7318892717656656, \"phi\": 0.6365477296796584}, {\"truth_threshold\": 4.9399998895823956, \"match_probability\": 0.9684507250259401, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123337.0, \"tn\": 1278737587.0, \"fp\": 205.0, \"fn\": 180624.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40576587127953917, \"tn_rate\": 0.9999998396856641, \"fp_rate\": 1.6031433596669677e-07, \"fn_rate\": 0.5942341287204609, \"precision\": 0.9983406452866231, \"recall\": 0.40576587127953917, \"specificity\": 0.9999998396856641, \"npv\": 0.999858768138223, \"accuracy\": 0.9998586215034999, \"f1\": 0.5770111554772716, \"f2\": 0.46042365680991143, \"f0_5\": 0.7726633163310693, \"p4\": 0.7317592221823924, \"phi\": 0.6364236754500744}, {\"truth_threshold\": 4.959999889135361, \"match_probability\": 0.9688715526233621, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123299.0, \"tn\": 1278737588.0, \"fp\": 204.0, \"fn\": 180662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4056408552412974, \"tn_rate\": 0.9999998404676852, \"fp_rate\": 1.595323148156397e-07, \"fn_rate\": 0.5943591447587026, \"precision\": 0.9983482182619046, \"recall\": 0.4056408552412974, \"specificity\": 0.9999998404676852, \"npv\": 0.9998587384299192, \"accuracy\": 0.9998585925755936, \"f1\": 0.5768860067748395, \"f2\": 0.46029520355815184, \"f0_5\": 0.7725762651117268, \"p4\": 0.7316585717784788, \"phi\": 0.6363280320510936}, {\"truth_threshold\": 4.979999888688326, \"match_probability\": 0.9692869449288442, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123269.0, \"tn\": 1278737589.0, \"fp\": 203.0, \"fn\": 180692.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40554215836900126, \"tn_rate\": 0.9999998412497063, \"fp_rate\": 1.5875029366458265e-07, \"fn_rate\": 0.5944578416309987, \"precision\": 0.9983559025528055, \"recall\": 0.40554215836900126, \"specificity\": 0.9999998412497063, \"npv\": 0.9998587149760196, \"accuracy\": 0.9998585699023698, \"f1\": 0.5767874731244429, \"f2\": 0.46019386014950914, \"f0_5\": 0.7725083317770656, \"p4\": 0.7315793152100496, \"phi\": 0.6362530566066171}, {\"truth_threshold\": 4.999999888241291, \"match_probability\": 0.9696969674206727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123206.0, \"tn\": 1278737595.0, \"fp\": 197.0, \"fn\": 180755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40533489493717945, \"tn_rate\": 0.9999998459418332, \"fp_rate\": 1.540581667582403e-07, \"fn_rate\": 0.5946651050628206, \"precision\": 0.9984036044504591, \"recall\": 0.40533489493717945, \"specificity\": 0.9999998459418332, \"npv\": 0.9998586657232653, \"accuracy\": 0.9998585253377573, \"f1\": 0.5765857676360199, \"f2\": 0.45998236322351294, \"f0_5\": 0.7723807099788985, \"p4\": 0.7314170406528334, \"phi\": 0.6361056347888779}, {\"truth_threshold\": 5.019999887794256, \"match_probability\": 0.970101684913839, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123168.0, \"tn\": 1278737595.0, \"fp\": 197.0, \"fn\": 180793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40520987889893767, \"tn_rate\": 0.9999998459418332, \"fp_rate\": 1.540581667582403e-07, \"fn_rate\": 0.5947901211010623, \"precision\": 0.998403112714303, \"recall\": 0.40520987889893767, \"specificity\": 0.9999998459418332, \"npv\": 0.9998586360148572, \"accuracy\": 0.9998584956280157, \"f1\": 0.5764591904073236, \"f2\": 0.45985354041079474, \"f0_5\": 0.772289668819858, \"p4\": 0.7313151862721716, \"phi\": 0.6360073651472992}, {\"truth_threshold\": 5.039999887347221, \"match_probability\": 0.9705011615633362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123139.0, \"tn\": 1278737596.0, \"fp\": 196.0, \"fn\": 180822.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40511447192238476, \"tn_rate\": 0.9999998467238544, \"fp_rate\": 1.5327614560718323e-07, \"fn_rate\": 0.5948855280776152, \"precision\": 0.9984108322860502, \"recall\": 0.40511447192238476, \"specificity\": 0.9999998467238544, \"npv\": 0.9998586133427629, \"accuracy\": 0.9998584737366271, \"f1\": 0.5763639257095784, \"f2\": 0.45975556665688455, \"f0_5\": 0.7722240408578441, \"p4\": 0.7312385177884524, \"phi\": 0.6359349387250833}, {\"truth_threshold\": 5.0599998869001865, \"match_probability\": 0.9708954608675425, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123111.0, \"tn\": 1278737596.0, \"fp\": 196.0, \"fn\": 180850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40502235484157506, \"tn_rate\": 0.9999998467238544, \"fp_rate\": 1.5327614560718323e-07, \"fn_rate\": 0.5949776451584249, \"precision\": 0.99841047142498, \"recall\": 0.40502235484157506, \"specificity\": 0.9999998467238544, \"npv\": 0.9998585914523591, \"accuracy\": 0.9998584518452386, \"f1\": 0.5762706310793225, \"f2\": 0.45966063573114607, \"f0_5\": 0.772156916364877, \"p4\": 0.7311634257626687, \"phi\": 0.6358625115551616}, {\"truth_threshold\": 5.079999886453152, \"match_probability\": 0.9712846456716904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123073.0, \"tn\": 1278737597.0, \"fp\": 195.0, \"fn\": 180888.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40489733880333334, \"tn_rate\": 0.9999998475058756, \"fp_rate\": 1.524941244561262e-07, \"fn_rate\": 0.5951026611966667, \"precision\": 0.9984180809293571, \"recall\": 0.40489733880333334, \"specificity\": 0.9999998475058756, \"npv\": 0.9998585617440661, \"accuracy\": 0.9998584229173323, \"f1\": 0.576145345938595, \"f2\": 0.45953213771514256, \"f0_5\": 0.7720696633640013, \"p4\": 0.7310625709369277, \"phi\": 0.6357667841092932}, {\"truth_threshold\": 5.099999886006117, \"match_probability\": 0.9716687781714157, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 123006.0, \"tn\": 1278737597.0, \"fp\": 195.0, \"fn\": 180955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40467691578853865, \"tn_rate\": 0.9999998475058756, \"fp_rate\": 1.524941244561262e-07, \"fn_rate\": 0.5953230842114613, \"precision\": 0.9984172206394428, \"recall\": 0.40467691578853865, \"specificity\": 0.9999998475058756, \"npv\": 0.9998585093634641, \"accuracy\": 0.9998583705343668, \"f1\": 0.5759220155350897, \"f2\": 0.45930495241011315, \"f0_5\": 0.7719089066412305, \"p4\": 0.7308827495754692, \"phi\": 0.6355934166532446}, {\"truth_threshold\": 5.119999885559082, \"match_probability\": 0.9720479199163852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122982.0, \"tn\": 1278737599.0, \"fp\": 193.0, \"fn\": 180979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4045979582907018, \"tn_rate\": 0.9999998490699179, \"fp_rate\": 1.5093008215401208e-07, \"fn_rate\": 0.5954020417092982, \"precision\": 0.9984331236046275, \"recall\": 0.4045979582907018, \"specificity\": 0.9999998490699179, \"npv\": 0.999858490600486, \"accuracy\": 0.99985835333399, \"f1\": 0.575844695834582, \"f2\": 0.4592242529792333, \"f0_5\": 0.771859046696148, \"p4\": 0.7308204814830087, \"phi\": 0.635536464897084}, {\"truth_threshold\": 5.139999885112047, \"match_probability\": 0.972422131813996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122913.0, \"tn\": 1278737599.0, \"fp\": 193.0, \"fn\": 181048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4043709554844207, \"tn_rate\": 0.9999998490699179, \"fp_rate\": 1.5093008215401208e-07, \"fn_rate\": 0.5956290445155793, \"precision\": 0.9984322453820285, \"recall\": 0.4043709554844207, \"specificity\": 0.9999998490699179, \"npv\": 0.9998584366562918, \"accuracy\": 0.9998582993873539, \"f1\": 0.5756145991144247, \"f2\": 0.4589902535568916, \"f0_5\": 0.7716933392768573, \"p4\": 0.7306351405237704, \"phi\": 0.6353578568609465}, {\"truth_threshold\": 5.159999884665012, \"match_probability\": 0.9727914741331464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122863.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4042064606972605, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5957935393027395, \"precision\": 0.9984478359094381, \"recall\": 0.4042064606972605, \"specificity\": 0.9999998506339601, \"npv\": 0.9998583975665212, \"accuracy\": 0.9998582618592593, \"f1\": 0.5754505111061672, \"f2\": 0.45882135905797156, \"f0_5\": 0.7715809424286308, \"p4\": 0.7305029360830778, \"phi\": 0.6352335635121006}, {\"truth_threshold\": 5.1799998842179775, \"match_probability\": 0.9731560065080713, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122798.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40399261747395226, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5960073825260478, \"precision\": 0.9984470155867597, \"recall\": 0.40399261747395226, \"specificity\": 0.9999998506339601, \"npv\": 0.999858346749536, \"accuracy\": 0.9998582110399644, \"f1\": 0.5752336339149783, \"f2\": 0.4586008859954901, \"f0_5\": 0.7714246586013366, \"p4\": 0.7303281573888583, \"phi\": 0.6350652307091011}, {\"truth_threshold\": 5.199999883770943, \"match_probability\": 0.973515787942243, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122755.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4038511519569945, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5961488480430055, \"precision\": 0.9984464724350528, \"recall\": 0.4038511519569945, \"specificity\": 0.9999998506339601, \"npv\": 0.9998583131321487, \"accuracy\": 0.9998581774210462, \"f1\": 0.5750901250155186, \"f2\": 0.45845502281911277, \"f0_5\": 0.7713212147107428, \"p4\": 0.7302124788527622, \"phi\": 0.6349538475689885}, {\"truth_threshold\": 5.219999883323908, \"match_probability\": 0.9738708768123288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122730.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181231.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4037689045634144, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5962310954365856, \"precision\": 0.9984461564744836, \"recall\": 0.4037689045634144, \"specificity\": 0.9999998506339601, \"npv\": 0.999858293587157, \"accuracy\": 0.9998581578751636, \"f1\": 0.5750066763180457, \"f2\": 0.4583702143393351, \"f0_5\": 0.7712610523537508, \"p4\": 0.7301452034852762, \"phi\": 0.6348890809498838}, {\"truth_threshold\": 5.239999882876873, \"match_probability\": 0.9742213308722075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122695.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181266.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40365375821240224, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5963462417875978, \"precision\": 0.9984457139137086, \"recall\": 0.40365375821240224, \"specificity\": 0.9999998506339601, \"npv\": 0.9998582662241701, \"accuracy\": 0.9998581305109279, \"f1\": 0.5748898317195623, \"f2\": 0.45825147714625053, \"f0_5\": 0.7711767996429941, \"p4\": 0.7300509927534784, \"phi\": 0.6347983965861461}, {\"truth_threshold\": 5.259999882429838, \"match_probability\": 0.9745672072570385, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122659.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4035353219656469, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5964646780343531, \"precision\": 0.9984452584452584, \"recall\": 0.4035353219656469, \"specificity\": 0.9999998506339601, \"npv\": 0.9998582380793851, \"accuracy\": 0.9998581023648568, \"f1\": 0.5747696287115375, \"f2\": 0.45812934098457153, \"f0_5\": 0.7710901087682197, \"p4\": 0.7299540595802562, \"phi\": 0.6347051077286705}, {\"truth_threshold\": 5.279999881982803, \"match_probability\": 0.9749085624873802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122577.0, \"tn\": 1278737601.0, \"fp\": 191.0, \"fn\": 181384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4032655505147042, \"tn_rate\": 0.9999998506339601, \"fp_rate\": 1.4936603985189796e-07, \"fn_rate\": 0.5967344494852959, \"precision\": 0.9984442199921804, \"recall\": 0.4032655505147042, \"specificity\": 0.9999998506339601, \"npv\": 0.9998581739718251, \"accuracy\": 0.9998580382543618, \"f1\": 0.5744957572604628, \"f2\": 0.45785111742611, \"f0_5\": 0.7708925289893627, \"p4\": 0.7297331510313643, \"phi\": 0.6344925652594888}, {\"truth_threshold\": 5.2999998815357685, \"match_probability\": 0.9752454524733574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122550.0, \"tn\": 1278737609.0, \"fp\": 183.0, \"fn\": 181411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40317672332963767, \"tn_rate\": 0.9999998568901294, \"fp_rate\": 1.431098706434415e-07, \"fn_rate\": 0.5968232766703623, \"precision\": 0.9985089584708269, \"recall\": 0.40317672332963767, \"specificity\": 0.9999998568901294, \"npv\": 0.9998581528641274, \"accuracy\": 0.999858023399491, \"f1\": 0.5744163264540866, \"f2\": 0.45776223556806966, \"f0_5\": 0.7708584677434573, \"p4\": 0.72966906715258, \"phi\": 0.6344432502217313}, {\"truth_threshold\": 5.319999881088734, \"match_probability\": 0.9755779325188714, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122511.0, \"tn\": 1278737609.0, \"fp\": 183.0, \"fn\": 181450.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4030484173956527, \"tn_rate\": 0.9999998568901294, \"fp_rate\": 1.431098706434415e-07, \"fn_rate\": 0.5969515826043472, \"precision\": 0.9985084845224705, \"recall\": 0.4030484173956527, \"specificity\": 0.9999998568901294, \"npv\": 0.9998581223739508, \"accuracy\": 0.9998579929079141, \"f1\": 0.57428601563324, \"f2\": 0.45762989171768004, \"f0_5\": 0.7707644164044206, \"p4\": 0.7295639190314374, \"phi\": 0.6343421300955459}, {\"truth_threshold\": 5.339999880641699, \"match_probability\": 0.9759060573258537, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122455.0, \"tn\": 1278737609.0, \"fp\": 183.0, \"fn\": 181506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40286418323403334, \"tn_rate\": 0.9999998568901294, \"fp_rate\": 1.431098706434415e-07, \"fn_rate\": 0.5971358167659667, \"precision\": 0.9985078034540681, \"recall\": 0.40286418323403334, \"specificity\": 0.9999998568901294, \"npv\": 0.9998580785931876, \"accuracy\": 0.9998579491251369, \"f1\": 0.5740988609912353, \"f2\": 0.45743984603453763, \"f0_5\": 0.7706293037370062, \"p4\": 0.7294128730397621, \"phi\": 0.634196903779639}, {\"truth_threshold\": 5.359999880194664, \"match_probability\": 0.9762298809985563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122408.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181553.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40270955813410275, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5972904418658973, \"precision\": 0.9985398125412972, \"recall\": 0.40270955813410275, \"specificity\": 0.999999860018214, \"npv\": 0.9998580418490656, \"accuracy\": 0.9998579155062188, \"f1\": 0.5739471290452657, \"f2\": 0.45728169774908084, \"f0_5\": 0.7705313675156645, \"p4\": 0.7292903893587778, \"phi\": 0.6340853404913761}, {\"truth_threshold\": 5.379999879747629, \"match_probability\": 0.9765494570478808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122390.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181571.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4026503400107251, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5973496599892749, \"precision\": 0.9985395981039251, \"recall\": 0.4026503400107251, \"specificity\": 0.999999860018214, \"npv\": 0.9998580277766793, \"accuracy\": 0.9998579014331833, \"f1\": 0.5738869481630835, \"f2\": 0.45722060380465523, \"f0_5\": 0.7704879022256581, \"p4\": 0.7292418024695818, \"phi\": 0.6340386453279037}, {\"truth_threshold\": 5.399999879300594, \"match_probability\": 0.9768648383957381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122353.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4025286138682265, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5974713861317735, \"precision\": 0.9985391571181406, \"recall\": 0.4025286138682265, \"specificity\": 0.999999860018214, \"npv\": 0.9998579988501087, \"accuracy\": 0.999857872505277, \"f1\": 0.5737632270635157, \"f2\": 0.4570950166470409, \"f0_5\": 0.7703985321544562, \"p4\": 0.7291419048698877, \"phi\": 0.6339426500279516}, {\"truth_threshold\": 5.4199998788535595, \"match_probability\": 0.9771760773794429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122285.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40230490095768867, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5976950990423113, \"precision\": 0.9985383459628953, \"recall\": 0.40230490095768867, \"specificity\": 0.999999860018214, \"npv\": 0.9998579456877673, \"accuracy\": 0.9998578193404762, \"f1\": 0.5735357917570499, \"f2\": 0.4568641897081987, \"f0_5\": 0.7702341975543482, \"p4\": 0.7289582230988945, \"phi\": 0.6337661883311126}, {\"truth_threshold\": 5.439999878406525, \"match_probability\": 0.9774832257561331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122258.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181703.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40221607377262214, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5977839262273779, \"precision\": 0.9985380236366458, \"recall\": 0.40221607377262214, \"specificity\": 0.999999860018214, \"npv\": 0.9998579245791921, \"accuracy\": 0.9998577982309229, \"f1\": 0.5734454664421503, \"f2\": 0.45677253132936957, \"f0_5\": 0.7701689158117143, \"p4\": 0.7288852596522531, \"phi\": 0.6336961090338338}, {\"truth_threshold\": 5.45999987795949, \"match_probability\": 0.9777863347072188, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122223.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40210092742161, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.59789907257839, \"precision\": 0.9985376055946799, \"recall\": 0.40210092742161, \"specificity\": 0.999999860018214, \"npv\": 0.9998578972162256, \"accuracy\": 0.9998577708666873, \"f1\": 0.5733283610444622, \"f2\": 0.4566537094076874, \"f0_5\": 0.770084264884339, \"p4\": 0.7287906511832286, \"phi\": 0.6336052539686235}, {\"truth_threshold\": 5.479999877512455, \"match_probability\": 0.9780854548428534, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122188.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181773.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40198578107059785, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5980142189294021, \"precision\": 0.9985371873135731, \"recall\": 0.40198578107059785, \"specificity\": 0.999999860018214, \"npv\": 0.9998578698532606, \"accuracy\": 0.9998577435024516, \"f1\": 0.5732112364189075, \"f2\": 0.45653488127059183, \"f0_5\": 0.769999584083768, \"p4\": 0.7286960130943175, \"phi\": 0.6335143858785771}, {\"truth_threshold\": 5.49999987706542, \"match_probability\": 0.9783806362064269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122145.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181816.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4018443155536401, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5981556844463599, \"precision\": 0.998536673097675, \"recall\": 0.4018443155536401, \"specificity\": 0.999999860018214, \"npv\": 0.9998578362359056, \"accuracy\": 0.9998577098835334, \"f1\": 0.5730673141208347, \"f2\": 0.45638888390695337, \"f0_5\": 0.7698955067525405, \"p4\": 0.7285797028727068, \"phi\": 0.633402730100383}, {\"truth_threshold\": 5.519999876618385, \"match_probability\": 0.9786719282790798, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122106.0, \"tn\": 1278737613.0, \"fp\": 179.0, \"fn\": 181855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40171600961965515, \"tn_rate\": 0.999999860018214, \"fp_rate\": 1.3998178603921326e-07, \"fn_rate\": 0.5982839903803449, \"precision\": 0.9985362064030748, \"recall\": 0.40171600961965515, \"specificity\": 0.999999860018214, \"npv\": 0.9998578057457485, \"accuracy\": 0.9998576793919565, \"f1\": 0.5729367548317169, \"f2\": 0.4562564595790092, \"f0_5\": 0.7698010719946136, \"p4\": 0.7284741735037767, \"phi\": 0.633301443888774}, {\"truth_threshold\": 5.5399998761713505, \"match_probability\": 0.9789593799842328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122074.0, \"tn\": 1278737620.0, \"fp\": 172.0, \"fn\": 181887.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40161073295587263, \"tn_rate\": 0.999999865492362, \"fp_rate\": 1.3450763798181387e-07, \"fn_rate\": 0.5983892670441274, \"precision\": 0.9985930009979876, \"recall\": 0.40161073295587263, \"specificity\": 0.999999865492362, \"npv\": 0.9998577807289635, \"accuracy\": 0.9998576598460739, \"f1\": 0.5728390195374548, \"f2\": 0.456150184217803, \"f0_5\": 0.7697507393324884, \"p4\": 0.7283951643116287, \"phi\": 0.6332364613400498}, {\"truth_threshold\": 5.559999875724316, \"match_probability\": 0.9792430396921339, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122040.0, \"tn\": 1278737620.0, \"fp\": 172.0, \"fn\": 181921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4014988765006037, \"tn_rate\": 0.999999865492362, \"fp_rate\": 1.3450763798181387e-07, \"fn_rate\": 0.5985011234993963, \"precision\": 0.998592609563709, \"recall\": 0.4014988765006037, \"specificity\": 0.999999865492362, \"npv\": 0.9998577541478038, \"accuracy\": 0.9998576332636735, \"f1\": 0.5727251609088329, \"f2\": 0.4560347250040357, \"f0_5\": 0.7696683564389405, \"p4\": 0.7283031081312882, \"phi\": 0.6331481382524877}, {\"truth_threshold\": 5.579999875277281, \"match_probability\": 0.9795229552244182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 122001.0, \"tn\": 1278737624.0, \"fp\": 168.0, \"fn\": 181960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40137057056661873, \"tn_rate\": 0.9999998686204467, \"fp_rate\": 1.3137955337758563e-07, \"fn_rate\": 0.5986294294333813, \"precision\": 0.9986248557326327, \"recall\": 0.40137057056661873, \"specificity\": 0.9999998686204467, \"npv\": 0.9998577236580967, \"accuracy\": 0.9998576058994377, \"f1\": 0.572599910825335, \"f2\": 0.4559036421918173, \"f0_5\": 0.7695893580541913, \"p4\": 0.7282018266654802, \"phi\": 0.6330571786266158}, {\"truth_threshold\": 5.599999874830246, \"match_probability\": 0.9797991738586788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121952.0, \"tn\": 1278737626.0, \"fp\": 166.0, \"fn\": 182009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40120936567520177, \"tn_rate\": 0.9999998701844889, \"fp_rate\": 1.298155110754715e-07, \"fn_rate\": 0.5987906343247983, \"precision\": 0.9986406590347041, \"recall\": 0.40120936567520177, \"specificity\": 0.9999998701844889, \"npv\": 0.9998576853501823, \"accuracy\": 0.9998575691531784, \"f1\": 0.5724384445138109, \"f2\": 0.45573790585980767, \"f0_5\": 0.769478302897532, \"p4\": 0.7280712355297521, \"phi\": 0.6329350343896494}, {\"truth_threshold\": 5.619999874383211, \"match_probability\": 0.9800717423330486, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121914.0, \"tn\": 1278737626.0, \"fp\": 166.0, \"fn\": 182047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40108434963696, \"tn_rate\": 0.9999998701844889, \"fp_rate\": 1.298155110754715e-07, \"fn_rate\": 0.59891565036304, \"precision\": 0.9986402359108781, \"recall\": 0.40108434963696, \"specificity\": 0.9999998701844889, \"npv\": 0.9998576556418333, \"accuracy\": 0.9998575394434368, \"f1\": 0.5723111155968557, \"f2\": 0.45560883876812136, \"f0_5\": 0.7693861142700633, \"p4\": 0.7279682351132298, \"phi\": 0.6328362725277218}, {\"truth_threshold\": 5.639999873936176, \"match_probability\": 0.9803407068507896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121848.0, \"tn\": 1278737626.0, \"fp\": 166.0, \"fn\": 182113.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4008672165179085, \"tn_rate\": 0.9999998701844889, \"fp_rate\": 1.298155110754715e-07, \"fn_rate\": 0.5991327834820914, \"precision\": 0.9986395003852017, \"recall\": 0.4008672165179085, \"specificity\": 0.9999998701844889, \"npv\": 0.999857604043126, \"accuracy\": 0.9998574878423065, \"f1\": 0.5720899113797758, \"f2\": 0.4553846521828176, \"f0_5\": 0.7692259130801485, \"p4\": 0.7277892563121703, \"phi\": 0.6326647021392637}, {\"truth_threshold\": 5.6599998734891415, \"match_probability\": 0.9806061130848882, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121821.0, \"tn\": 1278737626.0, \"fp\": 166.0, \"fn\": 182140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40077838933284204, \"tn_rate\": 0.9999998701844889, \"fp_rate\": 1.298155110754715e-07, \"fn_rate\": 0.599221610667158, \"precision\": 0.9986391992589374, \"recall\": 0.40077838933284204, \"specificity\": 0.9999998701844889, \"npv\": 0.9998575829345654, \"accuracy\": 0.9998574667327533, \"f1\": 0.5719993989876698, \"f2\": 0.4552929331133753, \"f0_5\": 0.7691603454437316, \"p4\": 0.7277160072059764, \"phi\": 0.6325945008464487}, {\"truth_threshold\": 5.679999873042107, \"match_probability\": 0.9808680061826558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121787.0, \"tn\": 1278737626.0, \"fp\": 166.0, \"fn\": 182174.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4006665328775731, \"tn_rate\": 0.9999998701844889, \"fp_rate\": 1.298155110754715e-07, \"fn_rate\": 0.5993334671224269, \"precision\": 0.9986388198732299, \"recall\": 0.4006665328775731, \"specificity\": 0.9999998701844889, \"npv\": 0.9998575563534163, \"accuracy\": 0.9998574401503529, \"f1\": 0.5718854040956625, \"f2\": 0.4551774297595226, \"f0_5\": 0.7690777533459716, \"p4\": 0.7276237423797158, \"phi\": 0.6325060881392635}, {\"truth_threshold\": 5.699999872595072, \"match_probability\": 0.9811264307703318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121743.0, \"tn\": 1278737626.0, \"fp\": 166.0, \"fn\": 182218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40052177746487216, \"tn_rate\": 0.9999998701844889, \"fp_rate\": 1.298155110754715e-07, \"fn_rate\": 0.5994782225351278, \"precision\": 0.9986383285893576, \"recall\": 0.40052177746487216, \"specificity\": 0.9999998701844889, \"npv\": 0.9998575219542845, \"accuracy\": 0.9998574057495995, \"f1\": 0.5717378542747786, \"f2\": 0.45502794611561326, \"f0_5\": 0.7689708273275416, \"p4\": 0.7275042991016356, \"phi\": 0.6323916533531967}, {\"truth_threshold\": 5.719999872148037, \"match_probability\": 0.9813814309576883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121707.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40040334121811677, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5995966587818832, \"precision\": 0.9986461205198898, \"recall\": 0.40040334121811677, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574938096533, \"accuracy\": 0.9998573783853638, \"f1\": 0.5716184513647369, \"f2\": 0.45490597406325406, \"f0_5\": 0.7688871929840078, \"p4\": 0.7274076247184453, \"phi\": 0.63230060458259}, {\"truth_threshold\": 5.739999871701002, \"match_probability\": 0.9816330503426346, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121677.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182284.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.4003046443458207, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5996953556541793, \"precision\": 0.9986457871669867, \"recall\": 0.4003046443458207, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574703557024, \"accuracy\": 0.9998573549303046, \"f1\": 0.5715178145762242, \"f2\": 0.4548040422042243, \"f0_5\": 0.7688142352927796, \"p4\": 0.7273261328377273, \"phi\": 0.6322225577598473}, {\"truth_threshold\": 5.759999871253967, \"match_probability\": 0.9818813320158202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121647.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40020594747352456, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5997940525264754, \"precision\": 0.9986454536498867, \"recall\": 0.40020594747352456, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574469017526, \"accuracy\": 0.9998573314752455, \"f1\": 0.5714171636059591, \"f2\": 0.4547021057730837, \"f0_5\": 0.7687412554710575, \"p4\": 0.72724461903489, \"phi\": 0.6321445013048973}, {\"truth_threshold\": 5.7799998708069324, \"match_probability\": 0.9821263185652349, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121593.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.40002829310339155, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.5999717068966084, \"precision\": 0.9986448529049425, \"recall\": 0.40002829310339155, \"specificity\": 0.9999998709665101, \"npv\": 0.9998574046846457, \"accuracy\": 0.9998572892561389, \"f1\": 0.5712359561118954, \"f2\": 0.45451860867432914, \"f0_5\": 0.7686098359909632, \"p4\": 0.727097838917796, \"phi\": 0.6320039754014329}, {\"truth_threshold\": 5.799999870359898, \"match_probability\": 0.9823680520808044, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121561.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182400.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39992301643960904, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.600076983560391, \"precision\": 0.9986444966564251, \"recall\": 0.39992301643960904, \"specificity\": 0.9999998709665101, \"npv\": 0.9998573796671025, \"accuracy\": 0.9998572642374092, \"f1\": 0.571128552199151, \"f2\": 0.45440986266139344, \"f0_5\": 0.7685319239061028, \"p4\": 0.727010824556595, \"phi\": 0.631920686051448}, {\"truth_threshold\": 5.819999869912863, \"match_probability\": 0.9826065741589802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121530.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3998210296715697, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.6001789703284303, \"precision\": 0.9986441513620116, \"recall\": 0.3998210296715697, \"specificity\": 0.9999998709665101, \"npv\": 0.9998573554313588, \"accuracy\": 0.9998572400005147, \"f1\": 0.5710244892589321, \"f2\": 0.4543045099993346, \"f0_5\": 0.7684564225201425, \"p4\": 0.7269265055716393, \"phi\": 0.6318399890277642}, {\"truth_threshold\": 5.839999869465828, \"match_probability\": 0.9828419259073232, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121512.0, \"tn\": 1278737627.0, \"fp\": 165.0, \"fn\": 182449.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.399761811548192, \"tn_rate\": 0.9999998709665101, \"fp_rate\": 1.2903348992441448e-07, \"fn_rate\": 0.600238188451808, \"precision\": 0.9986439507877413, \"recall\": 0.399761811548192, \"specificity\": 0.9999998709665101, \"npv\": 0.999857341358992, \"accuracy\": 0.9998572259274792, \"f1\": 0.570964058660176, \"f2\": 0.4542433352448298, \"f0_5\": 0.7684125721382778, \"p4\": 0.7268775353985424, \"phi\": 0.6317931279633249}, {\"truth_threshold\": 5.859999869018793, \"match_probability\": 0.9830741479490782, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121456.0, \"tn\": 1278737629.0, \"fp\": 163.0, \"fn\": 182505.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3995775773865726, \"tn_rate\": 0.9999998725305523, \"fp_rate\": 1.2746944762230036e-07, \"fn_rate\": 0.6004224226134274, \"precision\": 0.9986597488879204, \"recall\": 0.3995775773865726, \"specificity\": 0.9999998725305523, \"npv\": 0.999857297578521, \"accuracy\": 0.9998571837083726, \"f1\": 0.5707787020066732, \"f2\": 0.45405368223270476, \"f0_5\": 0.7682838733510704, \"p4\": 0.7267273075310023, \"phi\": 0.6316525113746007}, {\"truth_threshold\": 5.879999868571758, \"match_probability\": 0.9833032804277396, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121416.0, \"tn\": 1278737629.0, \"fp\": 163.0, \"fn\": 182545.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39944598155684446, \"tn_rate\": 0.9999998725305523, \"fp_rate\": 1.2746944762230036e-07, \"fn_rate\": 0.6005540184431556, \"precision\": 0.9986593079396935, \"recall\": 0.39944598155684446, \"specificity\": 0.9999998725305523, \"npv\": 0.9998572663065991, \"accuracy\": 0.9998571524349604, \"f1\": 0.5706443577572026, \"f2\": 0.45391772087065946, \"f0_5\": 0.7681863447879668, \"p4\": 0.726618401949424, \"phi\": 0.6315483400502546}, {\"truth_threshold\": 5.899999868124723, \"match_probability\": 0.9835293630116069, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121394.0, \"tn\": 1278737629.0, \"fp\": 163.0, \"fn\": 182567.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.399373603850494, \"tn_rate\": 0.9999998725305523, \"fp_rate\": 1.2746944762230036e-07, \"fn_rate\": 0.600626396149506, \"precision\": 0.9986590652944709, \"recall\": 0.399373603850494, \"specificity\": 0.9999998725305523, \"npv\": 0.9998572491070428, \"accuracy\": 0.9998571352345837, \"f1\": 0.5705704576539653, \"f2\": 0.45384293865489855, \"f0_5\": 0.7681326872431785, \"p4\": 0.7265584872103135, \"phi\": 0.6314910384999318}, {\"truth_threshold\": 5.919999867677689, \"match_probability\": 0.983752434898328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121346.0, \"tn\": 1278737629.0, \"fp\": 163.0, \"fn\": 182615.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39921568885482017, \"tn_rate\": 0.9999998725305523, \"fp_rate\": 1.2746944762230036e-07, \"fn_rate\": 0.6007843111451798, \"precision\": 0.9986585355817265, \"recall\": 0.39921568885482017, \"specificity\": 0.9999998725305523, \"npv\": 0.9998572115807403, \"accuracy\": 0.999857097706489, \"f1\": 0.5704091945378053, \"f2\": 0.4536797689166585, \"f0_5\": 0.7680155747426889, \"p4\": 0.7264277230608187, \"phi\": 0.6313659988909752}, {\"truth_threshold\": 5.939999867230654, \"match_probability\": 0.9839725348194305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121286.0, \"tn\": 1278737633.0, \"fp\": 159.0, \"fn\": 182675.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39901829511022796, \"tn_rate\": 0.999999875658637, \"fp_rate\": 1.2434136301807212e-07, \"fn_rate\": 0.6009817048897721, \"precision\": 0.9986907653670386, \"recall\": 0.39901829511022796, \"specificity\": 0.999999875658637, \"npv\": 0.9998571646733129, \"accuracy\": 0.9998570539237119, \"f1\": 0.5702129260048048, \"f2\": 0.45347714667510164, \"f0_5\": 0.767884660920479, \"p4\": 0.7262685379276851, \"phi\": 0.6312200634245854}, {\"truth_threshold\": 5.959999866783619, \"match_probability\": 0.9841897010448389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121270.0, \"tn\": 1278737633.0, \"fp\": 159.0, \"fn\": 182691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3989656567783367, \"tn_rate\": 0.999999875658637, \"fp_rate\": 1.2434136301807212e-07, \"fn_rate\": 0.6010343432216633, \"precision\": 0.9986905928567311, \"recall\": 0.3989656567783367, \"specificity\": 0.999999875658637, \"npv\": 0.9998571521645472, \"accuracy\": 0.9998570414143471, \"f1\": 0.5701591480758833, \"f2\": 0.4534227491320022, \"f0_5\": 0.7678455874996992, \"p4\": 0.726224913903826, \"phi\": 0.6311783684158969}, {\"truth_threshold\": 5.979999866336584, \"match_probability\": 0.9844039713873779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121239.0, \"tn\": 1278737633.0, \"fp\": 159.0, \"fn\": 182722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3988636700102974, \"tn_rate\": 0.999999875658637, \"fp_rate\": 1.2434136301807212e-07, \"fn_rate\": 0.6011363299897027, \"precision\": 0.9986902584886077, \"recall\": 0.3988636700102974, \"specificity\": 0.999999875658637, \"npv\": 0.9998571279288146, \"accuracy\": 0.9998570171774526, \"f1\": 0.5700549418256108, \"f2\": 0.4533173501879241, \"f0_5\": 0.7677698647209243, \"p4\": 0.7261403745140347, \"phi\": 0.6310975765005762}, {\"truth_threshold\": 5.999999865889549, \"match_probability\": 0.9846153832072593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121174.0, \"tn\": 1278737635.0, \"fp\": 157.0, \"fn\": 182787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3986498267869891, \"tn_rate\": 0.9999998772226792, \"fp_rate\": 1.22777320715958e-07, \"fn_rate\": 0.6013501732130109, \"precision\": 0.9987060190717953, \"recall\": 0.3986498267869891, \"specificity\": 0.9999998772226792, \"npv\": 0.9998570771121833, \"accuracy\": 0.9998569679218283, \"f1\": 0.5698390752706376, \"f2\": 0.4530970142277563, \"f0_5\": 0.7676187942251531, \"p4\": 0.7259652129084542, \"phi\": 0.6309333425400192}, {\"truth_threshold\": 6.019999865442514, \"match_probability\": 0.9848239734165524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121154.0, \"tn\": 1278737638.0, \"fp\": 154.0, \"fn\": 182807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.398584028872125, \"tn_rate\": 0.9999998795687427, \"fp_rate\": 1.2043125726278684e-07, \"fn_rate\": 0.6014159711278749, \"precision\": 0.9987305041712006, \"recall\": 0.398584028872125, \"specificity\": 0.9999998795687427, \"npv\": 0.9998570614765643, \"accuracy\": 0.9998569546306281, \"f1\": 0.5697758360002728, \"f2\": 0.4530300220169435, \"f0_5\": 0.7675815674999652, \"p4\": 0.7259138893997813, \"phi\": 0.6308890035785517}, {\"truth_threshold\": 6.03999986499548, \"match_probability\": 0.9850297784836395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121124.0, \"tn\": 1278737644.0, \"fp\": 148.0, \"fn\": 182837.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39848533199982894, \"tn_rate\": 0.9999998842608696, \"fp_rate\": 1.1573913035644448e-07, \"fn_rate\": 0.6015146680001711, \"precision\": 0.9987796028761792, \"recall\": 0.39848533199982894, \"specificity\": 0.9999998842608696, \"npv\": 0.9998570380233046, \"accuracy\": 0.9998569358665808, \"f1\": 0.5696829738049493, \"f2\": 0.45293003748365884, \"f0_5\": 0.767531547470436, \"p4\": 0.7258385172251514, \"phi\": 0.6308263927695863}, {\"truth_threshold\": 6.059999864548445, \"match_probability\": 0.9852328344376492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121093.0, \"tn\": 1278737644.0, \"fp\": 148.0, \"fn\": 182868.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3983833452317896, \"tn_rate\": 0.9999998842608696, \"fp_rate\": 1.1573913035644448e-07, \"fn_rate\": 0.6016166547682104, \"precision\": 0.9987792908339588, \"recall\": 0.3983833452317896, \"specificity\": 0.9999998842608696, \"npv\": 0.9998570137875777, \"accuracy\": 0.9998569116296863, \"f1\": 0.5695786943617387, \"f2\": 0.4528246147402746, \"f0_5\": 0.7674557150552967, \"p4\": 0.7257538671239366, \"phi\": 0.6307455557701083}, {\"truth_threshold\": 6.07999986410141, \"match_probability\": 0.9854331768728747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121065.0, \"tn\": 1278737645.0, \"fp\": 147.0, \"fn\": 182896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3982912281509799, \"tn_rate\": 0.9999998850428908, \"fp_rate\": 1.1495710920538744e-07, \"fn_rate\": 0.60170877184902, \"precision\": 0.9987872487872488, \"recall\": 0.3982912281509799, \"specificity\": 0.9999998850428908, \"npv\": 0.9998569918973567, \"accuracy\": 0.999856890520133, \"f1\": 0.5694858328256969, \"f2\": 0.45272972859775507, \"f0_5\": 0.7673910921401759, \"p4\": 0.7256784762421665, \"phi\": 0.6306751353168437}, {\"truth_threshold\": 6.099999863654375, \"match_probability\": 0.98563084095317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 121008.0, \"tn\": 1278737645.0, \"fp\": 147.0, \"fn\": 182953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3981037040936173, \"tn_rate\": 0.9999998850428908, \"fp_rate\": 1.1495710920538744e-07, \"fn_rate\": 0.6018962959063827, \"precision\": 0.9987866782221122, \"recall\": 0.3981037040936173, \"specificity\": 0.9999998850428908, \"npv\": 0.9998569473348963, \"accuracy\": 0.9998568459555206, \"f1\": 0.5692940279829506, \"f2\": 0.452535865771029, \"f0_5\": 0.7672515569104505, \"p4\": 0.7255227285411506, \"phi\": 0.6305264559100912}, {\"truth_threshold\": 6.11999986320734, \"match_probability\": 0.9858258614163268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120962.0, \"tn\": 1278737645.0, \"fp\": 147.0, \"fn\": 182999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3979523688894299, \"tn_rate\": 0.9999998850428908, \"fp_rate\": 1.1495710920538744e-07, \"fn_rate\": 0.6020476311105701, \"precision\": 0.9987862173744313, \"recall\": 0.3979523688894299, \"specificity\": 0.9999998850428908, \"npv\": 0.9998569113722118, \"accuracy\": 0.9998568099910965, \"f1\": 0.5691392006022538, \"f2\": 0.4523794030156632, \"f0_5\": 0.7671388906857839, \"p4\": 0.7253969791893685, \"phi\": 0.6304064434622725}, {\"truth_threshold\": 6.139999862760305, \"match_probability\": 0.98601827257843, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120928.0, \"tn\": 1278737646.0, \"fp\": 146.0, \"fn\": 183033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39784051243416096, \"tn_rate\": 0.999999885824912, \"fp_rate\": 1.1417508805433038e-07, \"fn_rate\": 0.602159487565839, \"precision\": 0.9987941259064704, \"recall\": 0.39784051243416096, \"specificity\": 0.999999885824912, \"npv\": 0.9998568847912107, \"accuracy\": 0.9998567841905315, \"f1\": 0.5690260802051595, \"f2\": 0.4522640879994136, \"f0_5\": 0.7670594742577611, \"p4\": 0.7253050882346364, \"phi\": 0.6303203279426987}, {\"truth_threshold\": 6.159999862313271, \"match_probability\": 0.9862081083381921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120894.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.397728655978892, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.6022713440211079, \"precision\": 0.9988433002296875, \"recall\": 0.397728655978892, \"specificity\": 0.9999998905170389, \"npv\": 0.9998568582107707, \"accuracy\": 0.9998567622991429, \"f1\": 0.5689196343486393, \"f2\": 0.45215045800738735, \"f0_5\": 0.7669994937171439, \"p4\": 0.725218607415671, \"phi\": 0.6302472232400389}, {\"truth_threshold\": 6.179999861866236, \"match_probability\": 0.9863954021812639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120853.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3975937702534207, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.6024062297465793, \"precision\": 0.9988429082674204, \"recall\": 0.3975937702534207, \"specificity\": 0.9999998905170389, \"npv\": 0.9998568261570795, \"accuracy\": 0.9998567302438953, \"f1\": 0.5687815622396777, \"f2\": 0.4520109781521607, \"f0_5\": 0.7668989622214072, \"p4\": 0.7251064142162055, \"phi\": 0.6301402093346549}, {\"truth_threshold\": 6.199999861419201, \"match_probability\": 0.9865801871845239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120809.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3974490148407197, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.6025509851592803, \"precision\": 0.9988424873293702, \"recall\": 0.3974490148407197, \"specificity\": 0.9999998905170389, \"npv\": 0.9998567917579985, \"accuracy\": 0.9998566958431419, \"f1\": 0.5686333576522087, \"f2\": 0.45186128293610156, \"f0_5\": 0.7667910281977818, \"p4\": 0.72498596569835, \"phi\": 0.6300253449305491}, {\"truth_threshold\": 6.219999860972166, \"match_probability\": 0.986762496020343, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120791.0, \"tn\": 1278737652.0, \"fp\": 140.0, \"fn\": 183170.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39738979671734204, \"tn_rate\": 0.9999998905170389, \"fp_rate\": 1.0948296114798803e-07, \"fn_rate\": 0.602610203282658, \"precision\": 0.9988423150391545, \"recall\": 0.39738979671734204, \"specificity\": 0.9999998905170389, \"npv\": 0.9998567776856478, \"accuracy\": 0.9998566817701063, \"f1\": 0.5685727196558185, \"f2\": 0.45180004114379757, \"f0_5\": 0.7667468594679345, \"p4\": 0.7249366775542347, \"phi\": 0.6299783489130156}, {\"truth_threshold\": 6.239999860525131, \"match_probability\": 0.9869423609608258, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120752.0, \"tn\": 1278737659.0, \"fp\": 133.0, \"fn\": 183209.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3972614907833571, \"tn_rate\": 0.9999998959911869, \"fp_rate\": 1.0400881309058862e-07, \"fn_rate\": 0.602738509216643, \"precision\": 0.9988997807833891, \"recall\": 0.3972614907833571, \"specificity\": 0.9999998959911869, \"npv\": 0.9998567471963402, \"accuracy\": 0.9998566567513766, \"f1\": 0.5684506856602157, \"f2\": 0.4516697101656357, \"f0_5\": 0.7666783915195028, \"p4\": 0.7248374740244673, \"phi\": 0.6298947557769916}, {\"truth_threshold\": 6.259999860078096, \"match_probability\": 0.9871198138820265, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120706.0, \"tn\": 1278737660.0, \"fp\": 132.0, \"fn\": 183255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3971101555791697, \"tn_rate\": 0.9999998967732081, \"fp_rate\": 1.0322679193953158e-07, \"fn_rate\": 0.6028898444208303, \"precision\": 0.9989076283950413, \"recall\": 0.3971101555791697, \"specificity\": 0.9999998967732081, \"npv\": 0.9998567112337826, \"accuracy\": 0.9998566215687879, \"f1\": 0.568297006348885, \"f2\": 0.4515135237850139, \"f0_5\": 0.7665693313840874, \"p4\": 0.7247125230307461, \"phi\": 0.6297772298183623}, {\"truth_threshold\": 6.2799998596310616, \"match_probability\": 0.9872948862681414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120667.0, \"tn\": 1278737661.0, \"fp\": 131.0, \"fn\": 183294.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39698184964518474, \"tn_rate\": 0.9999998975552292, \"fp_rate\": 1.0244477078847452e-07, \"fn_rate\": 0.6030181503548152, \"precision\": 0.9989155449593536, \"recall\": 0.39698184964518474, \"specificity\": 0.9999998975552292, \"npv\": 0.9998566807438072, \"accuracy\": 0.9998565918590462, \"f1\": 0.5681668899305253, \"f2\": 0.45138114768202703, \"f0_5\": 0.766477419256485, \"p4\": 0.7246067110253357, \"phi\": 0.6296779678652311}, {\"truth_threshold\": 6.299999859184027, \"match_probability\": 0.9874676092156737, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120649.0, \"tn\": 1278737662.0, \"fp\": 130.0, \"fn\": 183312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39692263152180707, \"tn_rate\": 0.9999998983372503, \"fp_rate\": 1.0166274963741746e-07, \"fn_rate\": 0.6030773684781929, \"precision\": 0.9989236539464642, \"recall\": 0.39692263152180707, \"specificity\": 0.9999998983372503, \"npv\": 0.9998566666715718, \"accuracy\": 0.999856578567846, \"f1\": 0.5681075481471017, \"f2\": 0.45132023016213246, \"f0_5\": 0.7664370830299958, \"p4\": 0.7245584478828653, \"phi\": 0.6296335534524438}, {\"truth_threshold\": 6.319999858736992, \"match_probability\": 0.9876380134375741, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120580.0, \"tn\": 1278737662.0, \"fp\": 130.0, \"fn\": 183381.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.396695628715526, \"tn_rate\": 0.9999998983372503, \"fp_rate\": 1.0166274963741746e-07, \"fn_rate\": 0.603304371284474, \"precision\": 0.9989230386877641, \"recall\": 0.396695628715526, \"specificity\": 0.9999998983372503, \"npv\": 0.9998566127275771, \"accuracy\": 0.9998565246212099, \"f1\": 0.5678748960960367, \"f2\": 0.45108540320854973, \"f0_5\": 0.7662674551760864, \"p4\": 0.7243691946509234, \"phi\": 0.6294532708849776}, {\"truth_threshold\": 6.339999858289957, \"match_probability\": 0.9878061292673542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120558.0, \"tn\": 1278737662.0, \"fp\": 130.0, \"fn\": 183403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3966232510091755, \"tn_rate\": 0.9999998983372503, \"fp_rate\": 1.0166274963741746e-07, \"fn_rate\": 0.6033767489908245, \"precision\": 0.9989228423704096, \"recall\": 0.3966232510091755, \"specificity\": 0.9999998983372503, \"npv\": 0.9998565955280437, \"accuracy\": 0.9998565074208332, \"f1\": 0.5678007012850613, \"f2\": 0.4510105257487288, \"f0_5\": 0.7662133459088638, \"p4\": 0.7243088282993251, \"phi\": 0.629395778633554}, {\"truth_threshold\": 6.359999857842922, \"match_probability\": 0.9879719866631735, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120527.0, \"tn\": 1278737667.0, \"fp\": 125.0, \"fn\": 183434.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3965212642411362, \"tn_rate\": 0.9999999022473561, \"fp_rate\": 9.775264388213217e-08, \"fn_rate\": 0.6034787357588638, \"precision\": 0.9989639624705765, \"recall\": 0.3965212642411362, \"specificity\": 0.9999999022473561, \"npv\": 0.9998565712928995, \"accuracy\": 0.9998564870931153, \"f1\": 0.5677028258673191, \"f2\": 0.4509066993092385, \"f0_5\": 0.7661565609628653, \"p4\": 0.7242291865126793, \"phi\": 0.6293278026279722}, {\"truth_threshold\": 6.379999857395887, \"match_probability\": 0.9881356152118985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120471.0, \"tn\": 1278737667.0, \"fp\": 125.0, \"fn\": 183490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39633703007951676, \"tn_rate\": 0.9999999022473561, \"fp_rate\": 9.775264388213217e-08, \"fn_rate\": 0.6036629699204832, \"precision\": 0.9989634813758334, \"recall\": 0.39633703007951676, \"specificity\": 0.9999999022473561, \"npv\": 0.9998565275122742, \"accuracy\": 0.9998564433103381, \"f1\": 0.5675139027268423, \"f2\": 0.450716081530035, \"f0_5\": 0.7660187322358507, \"p4\": 0.7240754299540894, \"phi\": 0.6291814192022938}, {\"truth_threshold\": 6.3999998569488525, \"match_probability\": 0.9882970441331357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120454.0, \"tn\": 1278737667.0, \"fp\": 125.0, \"fn\": 183507.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3962811018518823, \"tn_rate\": 0.9999999022473561, \"fp_rate\": 9.775264388213217e-08, \"fn_rate\": 0.6037188981481176, \"precision\": 0.9989633352407965, \"recall\": 0.3962811018518823, \"specificity\": 0.9999999022473561, \"npv\": 0.9998565142217279, \"accuracy\": 0.9998564300191379, \"f1\": 0.5674565411975314, \"f2\": 0.45065821225764596, \"f0_5\": 0.7659768758338347, \"p4\": 0.72402873849597, \"phi\": 0.6291369746400695}, {\"truth_threshold\": 6.419999856501818, \"match_probability\": 0.9884563022832351, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120415.0, \"tn\": 1278737667.0, \"fp\": 125.0, \"fn\": 183546.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39615279591789737, \"tn_rate\": 0.9999999022473561, \"fp_rate\": 9.775264388213217e-08, \"fn_rate\": 0.6038472040821027, \"precision\": 0.99896299983408, \"recall\": 0.39615279591789737, \"specificity\": 0.9999999022473561, \"npv\": 0.9998564837316527, \"accuracy\": 0.999856399527561, \"f1\": 0.5673249297410371, \"f2\": 0.4505254477754897, \"f0_5\": 0.7658808249620606, \"p4\": 0.7239215957527025, \"phi\": 0.6290350017245384}, {\"truth_threshold\": 6.439999856054783, \"match_probability\": 0.9886134181592674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120364.0, \"tn\": 1278737667.0, \"fp\": 125.0, \"fn\": 183597.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39598501123499397, \"tn_rate\": 0.9999999022473561, \"fp_rate\": 9.775264388213217e-08, \"fn_rate\": 0.604014988765006, \"precision\": 0.9989625608976753, \"recall\": 0.39598501123499397, \"specificity\": 0.9999999022473561, \"npv\": 0.9998564438600186, \"accuracy\": 0.9998563596539604, \"f1\": 0.567152785958299, \"f2\": 0.4503518209907261, \"f0_5\": 0.7657551624408175, \"p4\": 0.7237814291445144, \"phi\": 0.6289016275885303}, {\"truth_threshold\": 6.459999855607748, \"match_probability\": 0.9887684199029713, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120334.0, \"tn\": 1278737671.0, \"fp\": 121.0, \"fn\": 183627.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39588631436269783, \"tn_rate\": 0.9999999053754407, \"fp_rate\": 9.462455927790394e-08, \"fn_rate\": 0.6041136856373022, \"precision\": 0.9989954754887718, \"recall\": 0.39588631436269783, \"specificity\": 0.9999999053754407, \"npv\": 0.9998564204065667, \"accuracy\": 0.9998563393262425, \"f1\": 0.5670568498831335, \"f2\": 0.45025102914841664, \"f0_5\": 0.7656968035623157, \"p4\": 0.7237033008992364, \"phi\": 0.6288336037015502}, {\"truth_threshold\": 6.479999855160713, \"match_probability\": 0.9889213353046725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120293.0, \"tn\": 1278737679.0, \"fp\": 113.0, \"fn\": 183668.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3957514286372265, \"tn_rate\": 0.99999991163161, \"fp_rate\": 8.836839006944748e-08, \"fn_rate\": 0.6042485713627735, \"precision\": 0.9990615085626963, \"recall\": 0.3957514286372265, \"specificity\": 0.99999991163161, \"npv\": 0.9998563883538023, \"accuracy\": 0.9998563135256774, \"f1\": 0.5669290967488047, \"f2\": 0.45011412535079515, \"f0_5\": 0.7656268895154567, \"p4\": 0.7235992468510459, \"phi\": 0.6287472437500078}, {\"truth_threshold\": 6.499999854713678, \"match_probability\": 0.9890721918071752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120236.0, \"tn\": 1278737680.0, \"fp\": 112.0, \"fn\": 183725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39556390457986385, \"tn_rate\": 0.9999999124136311, \"fp_rate\": 8.758636891839043e-08, \"fn_rate\": 0.6044360954201361, \"precision\": 0.9990693655066972, \"recall\": 0.39556390457986385, \"specificity\": 0.9999999124136311, \"npv\": 0.9998563437915092, \"accuracy\": 0.9998562697429002, \"f1\": 0.5667379197707331, \"f2\": 0.4499203707251652, \"f0_5\": 0.7654901681154844, \"p4\": 0.723443502147563, \"phi\": 0.6286007210168733}, {\"truth_threshold\": 6.5199998542666435, \"match_probability\": 0.9892210165096217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120193.0, \"tn\": 1278737680.0, \"fp\": 112.0, \"fn\": 183768.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3954224390629061, \"tn_rate\": 0.9999999124136311, \"fp_rate\": 8.758636891839043e-08, \"fn_rate\": 0.6045775609370939, \"precision\": 0.9990690328747767, \"recall\": 0.3954224390629061, \"specificity\": 0.9999999124136311, \"npv\": 0.9998563101742587, \"accuracy\": 0.9998562361239821, \"f1\": 0.5665926564938034, \"f2\": 0.44977393988245323, \"f0_5\": 0.7653840324714938, \"p4\": 0.7233251361542863, \"phi\": 0.6284881924888932}, {\"truth_threshold\": 6.539999853819609, \"match_probability\": 0.9893678361713254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120159.0, \"tn\": 1278737683.0, \"fp\": 109.0, \"fn\": 183802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3953105826076372, \"tn_rate\": 0.9999999147596945, \"fp_rate\": 8.524030546521925e-08, \"fn_rate\": 0.6046894173923628, \"precision\": 0.9990936907573087, \"recall\": 0.3953105826076372, \"specificity\": 0.9999999147596945, \"npv\": 0.9998562835935155, \"accuracy\": 0.9998562118870876, \"f1\": 0.5664817822449667, \"f2\": 0.44965916030991415, \"f0_5\": 0.7653117767023807, \"p4\": 0.7232347770529389, \"phi\": 0.6284070426130722}, {\"truth_threshold\": 6.559999853372574, \"match_probability\": 0.9895126772155729, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120134.0, \"tn\": 1278737683.0, \"fp\": 109.0, \"fn\": 183827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3952283352140571, \"tn_rate\": 0.9999999147596945, \"fp_rate\": 8.524030546521925e-08, \"fn_rate\": 0.6047716647859429, \"precision\": 0.9990935023244596, \"recall\": 0.3952283352140571, \"specificity\": 0.9999999147596945, \"npv\": 0.9998562640486045, \"accuracy\": 0.999856192341205, \"f1\": 0.5663972994125468, \"f2\": 0.449574017260852, \"f0_5\": 0.7652500277093713, \"p4\": 0.7231659174169824, \"phi\": 0.6283416013406355}, {\"truth_threshold\": 6.579999852925539, \"match_probability\": 0.9896555657333964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120088.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 183873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39507700000986967, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6049229999901303, \"precision\": 0.9991097799409293, \"recall\": 0.39507700000986967, \"specificity\": 0.9999999163237369, \"npv\": 0.9998562280861951, \"accuracy\": 0.9998561579404516, \"f1\": 0.5662444949499712, \"f2\": 0.44941801848598734, \"f0_5\": 0.7651441685855588, \"p4\": 0.7230413519549439, \"phi\": 0.6282264002518909}, {\"truth_threshold\": 6.599999852478504, \"match_probability\": 0.9897965274873167, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120037.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 183924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39490921532696627, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6050907846730337, \"precision\": 0.9991094020508723, \"recall\": 0.39490921532696627, \"specificity\": 0.9999999163237369, \"npv\": 0.999856188214582, \"accuracy\": 0.9998561180668509, \"f1\": 0.566072081206305, \"f2\": 0.44924430458956216, \"f0_5\": 0.7650180934742402, \"p4\": 0.722900771779028, \"phi\": 0.6280928544416523}, {\"truth_threshold\": 6.619999852031469, \"match_probability\": 0.9899355879150558, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119997.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 183964.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3947776194972381, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6052223805027619, \"precision\": 0.9991091054419503, \"recall\": 0.3947776194972381, \"specificity\": 0.9999999163237369, \"npv\": 0.9998561569427308, \"accuracy\": 0.9998560867934387, \"f1\": 0.5659368257224718, \"f2\": 0.44910804911568414, \"f0_5\": 0.7649191651463518, \"p4\": 0.7227904674927005, \"phi\": 0.6279880927652833}, {\"truth_threshold\": 6.6399998515844345, \"match_probability\": 0.9900727721332194, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119939.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3945868055441323, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6054131944558677, \"precision\": 0.9991086750079137, \"recall\": 0.3945868055441323, \"specificity\": 0.9999999163237369, \"npv\": 0.9998561115985499, \"accuracy\": 0.999856041446991, \"f1\": 0.5657406599419349, \"f2\": 0.4489104641849254, \"f0_5\": 0.7647756473611386, \"p4\": 0.7226304554534116, \"phi\": 0.6278361572962168}, {\"truth_threshold\": 6.6599998511374, \"match_probability\": 0.99020810494095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119856.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184105.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39431374419744636, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6056862558025536, \"precision\": 0.9991080583179813, \"recall\": 0.39431374419744636, \"specificity\": 0.9999999163237369, \"npv\": 0.9998560467094708, \"accuracy\": 0.9998559765546606, \"f1\": 0.5654598465762731, \"f2\": 0.4486276834902048, \"f0_5\": 0.7645701206792946, \"p4\": 0.7224013267657975, \"phi\": 0.6276186684465674}, {\"truth_threshold\": 6.679999850690365, \"match_probability\": 0.9903416108235482, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119835.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184126.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3942446563868391, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6057553436131609, \"precision\": 0.9991079021527072, \"recall\": 0.3942446563868391, \"specificity\": 0.9999999163237369, \"npv\": 0.9998560302917533, \"accuracy\": 0.9998559601361192, \"f1\": 0.5653887799803257, \"f2\": 0.44855613099703096, \"f0_5\": 0.7645180923507998, \"p4\": 0.7223433271918225, \"phi\": 0.6275636292041175}, {\"truth_threshold\": 6.69999985024333, \"match_probability\": 0.9904733139560644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119722.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39387289816785703, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6061271018321429, \"precision\": 0.9991070608951088, \"recall\": 0.39387289816785703, \"specificity\": 0.9999999163237369, \"npv\": 0.9998559419488066, \"accuracy\": 0.9998558717887296, \"f1\": 0.5650062530970528, \"f2\": 0.4481710718117384, \"f0_5\": 0.7642379388134721, \"p4\": 0.7220310450947242, \"phi\": 0.6272673827827389}, {\"truth_threshold\": 6.719999849796295, \"match_probability\": 0.9906032382068604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119644.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39361628629988715, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6063837137001128, \"precision\": 0.9991064792778348, \"recall\": 0.39361628629988715, \"specificity\": 0.9999999163237369, \"npv\": 0.9998558809687286, \"accuracy\": 0.9998558108055758, \"f1\": 0.5647420889660901, \"f2\": 0.44790524073540255, \"f0_5\": 0.7640443697994164, \"p4\": 0.721815301259027, \"phi\": 0.6270628124870625}, {\"truth_threshold\": 6.73999984934926, \"match_probability\": 0.9907314071411394, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119617.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184344.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3935274591148207, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6064725408851793, \"precision\": 0.9991062777722094, \"recall\": 0.3935274591148207, \"specificity\": 0.9999999163237369, \"npv\": 0.9998558598602417, \"accuracy\": 0.9998557896960225, \"f1\": 0.564650624874612, \"f2\": 0.44781321505157357, \"f0_5\": 0.7639773291929433, \"p4\": 0.7217405852172065, \"phi\": 0.626991984147317}, {\"truth_threshold\": 6.7599998489022255, \"match_probability\": 0.9908578440244462, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119575.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184386.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3933892834936061, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6066107165063939, \"precision\": 0.9991059641382998, \"recall\": 0.3933892834936061, \"specificity\": 0.9999999163237369, \"npv\": 0.9998558270248196, \"accuracy\": 0.9998557568589397, \"f1\": 0.5645083242258222, \"f2\": 0.44767005659193454, \"f0_5\": 0.7638730070308897, \"p4\": 0.7216243239673004, \"phi\": 0.6268817908296261}, {\"truth_threshold\": 6.779999848455191, \"match_probability\": 0.9909825718261368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119539.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184422.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39327084724685074, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6067291527531492, \"precision\": 0.9991056951339786, \"recall\": 0.39327084724685074, \"specificity\": 0.9999999163237369, \"npv\": 0.9998557988801737, \"accuracy\": 0.9998557287128687, \"f1\": 0.5643863297820858, \"f2\": 0.4475473421740335, \"f0_5\": 0.763783552383569, \"p4\": 0.7215246362819037, \"phi\": 0.6267873240011804}, {\"truth_threshold\": 6.799999848008156, \"match_probability\": 0.9911056132228164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119499.0, \"tn\": 1278737685.0, \"fp\": 107.0, \"fn\": 184462.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3931392514171226, \"tn_rate\": 0.9999999163237369, \"fp_rate\": 8.367626316310514e-08, \"fn_rate\": 0.6068607485828774, \"precision\": 0.9991053960503654, \"recall\": 0.3931392514171226, \"specificity\": 0.9999999163237369, \"npv\": 0.9998557676083468, \"accuracy\": 0.9998556974394565, \"f1\": 0.5642507560787313, \"f2\": 0.4474109850612153, \"f0_5\": 0.763684119710884, \"p4\": 0.7214138340741255, \"phi\": 0.6266823441634738}, {\"truth_threshold\": 6.819999847561121, \"match_probability\": 0.991226990601748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119448.0, \"tn\": 1278737688.0, \"fp\": 104.0, \"fn\": 184513.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3929714667342192, \"tn_rate\": 0.9999999186698003, \"fp_rate\": 8.133019970993396e-08, \"fn_rate\": 0.6070285332657808, \"precision\": 0.9991300856531049, \"recall\": 0.3929714667342192, \"specificity\": 0.9999999186698003, \"npv\": 0.9998557277371088, \"accuracy\": 0.9998556599113618, \"f1\": 0.5640818581720042, \"f2\": 0.4472381226243002, \"f0_5\": 0.7635689985156661, \"p4\": 0.7212757698493539, \"phi\": 0.626556333530285}, {\"truth_threshold\": 6.839999847114086, \"match_probability\": 0.9913467260642292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119434.0, \"tn\": 1278737688.0, \"fp\": 104.0, \"fn\": 184527.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39292540819381433, \"tn_rate\": 0.9999999186698003, \"fp_rate\": 8.133019970993396e-08, \"fn_rate\": 0.6070745918061856, \"precision\": 0.9991299837708512, \"recall\": 0.39292540819381433, \"specificity\": 0.9999999186698003, \"npv\": 0.9998557167919708, \"accuracy\": 0.9998556489656675, \"f1\": 0.5640343896915931, \"f2\": 0.44719039196274923, \"f0_5\": 0.7635341696148766, \"p4\": 0.7212369617056735, \"phi\": 0.6265195790442019}, {\"truth_threshold\": 6.859999846667051, \"match_probability\": 0.9914648414289392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119389.0, \"tn\": 1278737688.0, \"fp\": 104.0, \"fn\": 184572.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3927773628853702, \"tn_rate\": 0.9999999186698003, \"fp_rate\": 8.133019970993396e-08, \"fn_rate\": 0.6072226371146299, \"precision\": 0.9991296561304847, \"recall\": 0.3927773628853702, \"specificity\": 0.9999999186698003, \"npv\": 0.9998556816111716, \"accuracy\": 0.9998556137830787, \"f1\": 0.5638817911744841, \"f2\": 0.44703696520054487, \"f0_5\": 0.7634221857882965, \"p4\": 0.721112187906033, \"phi\": 0.6264014250236357}, {\"truth_threshold\": 6.8799998462200165, \"match_probability\": 0.9915813582352545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119365.0, \"tn\": 1278737688.0, \"fp\": 104.0, \"fn\": 184596.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39269840538753326, \"tn_rate\": 0.9999999186698003, \"fp_rate\": 8.133019970993396e-08, \"fn_rate\": 0.6073015946124667, \"precision\": 0.9991294812880329, \"recall\": 0.39269840538753326, \"specificity\": 0.9999999186698003, \"npv\": 0.9998556628480797, \"accuracy\": 0.9998555950190314, \"f1\": 0.5638003920364641, \"f2\": 0.4469551333657352, \"f0_5\": 0.7633624399970838, \"p4\": 0.7210456210779855, \"phi\": 0.6263384004357591}, {\"truth_threshold\": 6.899999845772982, \"match_probability\": 0.9916962977465344, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119322.0, \"tn\": 1278737688.0, \"fp\": 104.0, \"fn\": 184639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3925569398705755, \"tn_rate\": 0.9999999186698003, \"fp_rate\": 8.133019970993396e-08, \"fn_rate\": 0.6074430601294245, \"precision\": 0.9991291678528964, \"recall\": 0.3925569398705755, \"specificity\": 0.9999999186698003, \"npv\": 0.9998556292308751, \"accuracy\": 0.9998555614001132, \"f1\": 0.5636545288353209, \"f2\": 0.44680851063829785, \"f0_5\": 0.7632553587534302, \"p4\": 0.7209263193034897, \"phi\": 0.6262254655256364}, {\"truth_threshold\": 6.919999845325947, \"match_probability\": 0.991809680953376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119276.0, \"tn\": 1278737688.0, \"fp\": 104.0, \"fn\": 184685.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39240560466638813, \"tn_rate\": 0.9999999186698003, \"fp_rate\": 8.133019970993396e-08, \"fn_rate\": 0.6075943953336119, \"precision\": 0.9991288323002178, \"recall\": 0.39240560466638813, \"specificity\": 0.9999999186698003, \"npv\": 0.9998555932682867, \"accuracy\": 0.9998555254356892, \"f1\": 0.5634984563271689, \"f2\": 0.4466516479631882, \"f0_5\": 0.7631407545416972, \"p4\": 0.7207986426708128, \"phi\": 0.6261046288919373}, {\"truth_threshold\": 6.939999844878912, \"match_probability\": 0.9919215285768376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119216.0, \"tn\": 1278737689.0, \"fp\": 103.0, \"fn\": 184745.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39220821092179586, \"tn_rate\": 0.9999999194518214, \"fp_rate\": 8.05481785588769e-08, \"fn_rate\": 0.6077917890782041, \"precision\": 0.9991367678240682, \"recall\": 0.39220821092179586, \"specificity\": 0.9999999194518214, \"npv\": 0.9998555463606794, \"accuracy\": 0.9998554793074061, \"f1\": 0.5632961632961633, \"f2\": 0.446447362606663, \"f0_5\": 0.7629950962384014, \"p4\": 0.720633117021909, \"phi\": 0.6259496048437232}, {\"truth_threshold\": 6.959999844431877, \"match_probability\": 0.9920318610716337, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119180.0, \"tn\": 1278737689.0, \"fp\": 103.0, \"fn\": 184781.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3920897746750405, \"tn_rate\": 0.9999999194518214, \"fp_rate\": 8.05481785588769e-08, \"fn_rate\": 0.6079102253249594, \"precision\": 0.9991365072977708, \"recall\": 0.3920897746750405, \"specificity\": 0.9999999194518214, \"npv\": 0.9998555182160495, \"accuracy\": 0.9998554511613351, \"f1\": 0.5631739611193544, \"f2\": 0.4463245818562579, \"f0_5\": 0.7629053134517912, \"p4\": 0.7205331046765392, \"phi\": 0.6258549973587237}, {\"truth_threshold\": 6.979999843984842, \"match_probability\": 0.9921406986292971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119152.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184809.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39199765759423083, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6080023424057691, \"precision\": 0.9991530611389231, \"recall\": 0.39199765759423083, \"specificity\": 0.9999999210158638, \"npv\": 0.9998554963260088, \"accuracy\": 0.9998554308336172, \"f1\": 0.56308156157405, \"f2\": 0.4462297495987183, \"f0_5\": 0.762843273711127, \"p4\": 0.7204574730557599, \"phi\": 0.6257866533707928}, {\"truth_threshold\": 6.9999998435378075, \"match_probability\": 0.992248061181313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119122.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184839.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3918989607219347, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6081010392780652, \"precision\": 0.9991528480242906, \"recall\": 0.3918989607219347, \"specificity\": 0.9999999210158638, \"npv\": 0.9998554728721528, \"accuracy\": 0.999855407378558, \"f1\": 0.5629796967749253, \"f2\": 0.4461274228184803, \"f0_5\": 0.7627684083944097, \"p4\": 0.7203740833613543, \"phi\": 0.6257077942666783}, {\"truth_threshold\": 7.019999843090773, \"match_probability\": 0.9923539684022208, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119095.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184866.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3918101335368682, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.6081898664631318, \"precision\": 0.9991526561294003, \"recall\": 0.3918101335368682, \"specificity\": 0.9999999210158638, \"npv\": 0.9998554517636833, \"accuracy\": 0.9998553862690048, \"f1\": 0.5628880061064806, \"f2\": 0.4460353247842761, \"f0_5\": 0.7627010099328205, \"p4\": 0.7202990132325167, \"phi\": 0.6256368125775613}, {\"truth_threshold\": 7.039999842643738, \"match_probability\": 0.9924584397126871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119040.0, \"tn\": 1278737691.0, \"fp\": 101.0, \"fn\": 184921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.391629189270992, \"tn_rate\": 0.9999999210158638, \"fp_rate\": 7.89841362567628e-08, \"fn_rate\": 0.608370810729008, \"precision\": 0.9991522649633627, \"recall\": 0.391629189270992, \"specificity\": 0.9999999210158638, \"npv\": 0.9998554087649519, \"accuracy\": 0.9998553432680629, \"f1\": 0.5627011926202192, \"f2\": 0.4458477061540017, \"f0_5\": 0.7625636590756222, \"p4\": 0.7201460357082511, \"phi\": 0.6254921953405664}, {\"truth_threshold\": 7.059999842196703, \"match_probability\": 0.9925614942825483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118997.0, \"tn\": 1278737692.0, \"fp\": 100.0, \"fn\": 184964.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39148772375403423, \"tn_rate\": 0.9999999217978849, \"fp_rate\": 7.820211510570574e-08, \"fn_rate\": 0.6085122762459657, \"precision\": 0.9991603482875303, \"recall\": 0.39148772375403423, \"specificity\": 0.9999999217978849, \"npv\": 0.9998553751478776, \"accuracy\": 0.9998553104309801, \"f1\": 0.562556434342336, \"f2\": 0.4457013456025397, \"f0_5\": 0.762460130018748, \"p4\": 0.7200274711965822, \"phi\": 0.625381734172877}, {\"truth_threshold\": 7.079999841749668, \"match_probability\": 0.9926631510338226, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118961.0, \"tn\": 1278737692.0, \"fp\": 100.0, \"fn\": 185000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3913692875072789, \"tn_rate\": 0.9999999217978849, \"fp_rate\": 7.820211510570574e-08, \"fn_rate\": 0.6086307124927212, \"precision\": 0.9991600944053889, \"recall\": 0.3913692875072789, \"specificity\": 0.9999999217978849, \"npv\": 0.9998553470032573, \"accuracy\": 0.9998552822849092, \"f1\": 0.5624341050820052, \"f2\": 0.4455785243144643, \"f0_5\": 0.7623701463077012, \"p4\": 0.7199272600326553, \"phi\": 0.625287040796266}, {\"truth_threshold\": 7.099999841302633, \"match_probability\": 0.9927634286436933, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118943.0, \"tn\": 1278737693.0, \"fp\": 99.0, \"fn\": 185018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3913100693839012, \"tn_rate\": 0.999999922579906, \"fp_rate\": 7.742009395464868e-08, \"fn_rate\": 0.6086899306160988, \"precision\": 0.9991683607466273, \"recall\": 0.3913100693839012, \"specificity\": 0.999999922579906, \"npv\": 0.9998553329310609, \"accuracy\": 0.9998552689937089, \"f1\": 0.5623742621210724, \"f2\": 0.44551744493537276, \"f0_5\": 0.7623290507082803, \"p4\": 0.719878231498247, \"phi\": 0.6252423158621537}, {\"truth_threshold\": 7.1199998408555984, \"match_probability\": 0.9928623455474604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118913.0, \"tn\": 1278737697.0, \"fp\": 95.0, \"fn\": 185048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3912113725116051, \"tn_rate\": 0.9999999257079907, \"fp_rate\": 7.429200935042045e-08, \"fn_rate\": 0.6087886274883949, \"precision\": 0.9992017343371874, \"recall\": 0.3912113725116051, \"specificity\": 0.9999999257079907, \"npv\": 0.9998553094776651, \"accuracy\": 0.999855248665991, \"f1\": 0.5622776137258286, \"f2\": 0.4454164206968263, \"f0_5\": 0.7622696613943971, \"p4\": 0.719799040982421, \"phi\": 0.6251738982924991}, {\"truth_threshold\": 7.139999840408564, \"match_probability\": 0.9929599199414655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118874.0, \"tn\": 1278737697.0, \"fp\": 95.0, \"fn\": 185087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39108306657762015, \"tn_rate\": 0.9999999257079907, \"fp_rate\": 7.429200935042045e-08, \"fn_rate\": 0.6089169334223798, \"precision\": 0.9992014726525398, \"recall\": 0.39108306657762015, \"specificity\": 0.9999999257079907, \"npv\": 0.999855278987664, \"accuracy\": 0.999855218174414, \"f1\": 0.5621450358215307, \"f2\": 0.44528334680588216, \"f0_5\": 0.7621720949377883, \"p4\": 0.719690394732558, \"phi\": 0.625071279051112}, {\"truth_threshold\": 7.159999839961529, \"match_probability\": 0.9930561697859839, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118846.0, \"tn\": 1278737697.0, \"fp\": 95.0, \"fn\": 185115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39099094949681046, \"tn_rate\": 0.9999999257079907, \"fp_rate\": 7.429200935042045e-08, \"fn_rate\": 0.6090090505031895, \"precision\": 0.9992012846705509, \"recall\": 0.39099094949681046, \"specificity\": 0.9999999257079907, \"npv\": 0.999855257097408, \"accuracy\": 0.9998551962830254, \"f1\": 0.5620498366051709, \"f2\": 0.44518780178081113, \"f0_5\": 0.7621020231491872, \"p4\": 0.7196123685646387, \"phi\": 0.6249975933113153}, {\"truth_threshold\": 7.179999839514494, \"match_probability\": 0.9931511128080894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118821.0, \"tn\": 1278737697.0, \"fp\": 95.0, \"fn\": 185140.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39090870210323037, \"tn_rate\": 0.9999999257079907, \"fp_rate\": 7.429200935042045e-08, \"fn_rate\": 0.6090912978967696, \"precision\": 0.9992011167546839, \"recall\": 0.39090870210323037, \"specificity\": 0.9999999257079907, \"npv\": 0.9998552375525374, \"accuracy\": 0.9998551767371429, \"f1\": 0.5619648266517214, \"f2\": 0.44510249033534116, \"f0_5\": 0.7620394420394421, \"p4\": 0.7195426855745192, \"phi\": 0.6249317951331305}, {\"truth_threshold\": 7.199999839067459, \"match_probability\": 0.99324476650449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118794.0, \"tn\": 1278737698.0, \"fp\": 94.0, \"fn\": 185167.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39081987491816383, \"tn_rate\": 0.9999999264900118, \"fp_rate\": 7.350998819936339e-08, \"fn_rate\": 0.6091801250818362, \"precision\": 0.999209339882915, \"recall\": 0.39081987491816383, \"specificity\": 0.9999999264900118, \"npv\": 0.9998552164441911, \"accuracy\": 0.9998551564094249, \"f1\": 0.5618743333908794, \"f2\": 0.4450106837927015, \"f0_5\": 0.7619757463955059, \"p4\": 0.7194684996238334, \"phi\": 0.6248633542605189}, {\"truth_threshold\": 7.219999838620424, \"match_probability\": 0.9933371481443325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118755.0, \"tn\": 1278737698.0, \"fp\": 94.0, \"fn\": 185206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3906915689841789, \"tn_rate\": 0.9999999264900118, \"fp_rate\": 7.350998819936339e-08, \"fn_rate\": 0.6093084310158211, \"precision\": 0.9992090804297891, \"recall\": 0.3906915689841789, \"specificity\": 0.9999999264900118, \"npv\": 0.9998551859541958, \"accuracy\": 0.999855125917848, \"f1\": 0.5617416806603439, \"f2\": 0.4448775860815933, \"f0_5\": 0.7618780610169665, \"p4\": 0.719359735911491, \"phi\": 0.6247606840290002}, {\"truth_threshold\": 7.239999838173389, \"match_probability\": 0.9934282747719803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118730.0, \"tn\": 1278737699.0, \"fp\": 93.0, \"fn\": 185231.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3906093215905988, \"tn_rate\": 0.9999999272720329, \"fp_rate\": 7.272796704830633e-08, \"fn_rate\": 0.6093906784094012, \"precision\": 0.9992173232454996, \"recall\": 0.3906093215905988, \"specificity\": 0.9999999272720329, \"npv\": 0.999855166409441, \"accuracy\": 0.9998551071538007, \"f1\": 0.5616579624583712, \"f2\": 0.4447925962056453, \"f0_5\": 0.7618193321039508, \"p4\": 0.7192910848131954, \"phi\": 0.6246974905851918}, {\"truth_threshold\": 7.259999837726355, \"match_probability\": 0.993518163209761, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118700.0, \"tn\": 1278737699.0, \"fp\": 93.0, \"fn\": 185261.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39051062471830267, \"tn_rate\": 0.9999999272720329, \"fp_rate\": 7.272796704830633e-08, \"fn_rate\": 0.6094893752816973, \"precision\": 0.9992171255882081, \"recall\": 0.39051062471830267, \"specificity\": 0.9999999272720329, \"npv\": 0.9998551429556007, \"accuracy\": 0.9998550836987414, \"f1\": 0.5615558930252582, \"f2\": 0.4446902041528895, \"f0_5\": 0.7617441438111336, \"p4\": 0.7192073751972479, \"phi\": 0.6246184940163713}, {\"truth_threshold\": 7.27999983727932, \"match_probability\": 0.9936068300606864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118648.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185313.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3903395501396561, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.609660449860344, \"precision\": 0.9992251979114031, \"recall\": 0.3903395501396561, \"specificity\": 0.9999999280540541, \"npv\": 0.9998551023023933, \"accuracy\": 0.9998550438251409, \"f1\": 0.5613802664294619, \"f2\": 0.4445130467621371, \"f0_5\": 0.7616176736793591, \"p4\": 0.7190633140179346, \"phi\": 0.6244841735857432}, {\"truth_threshold\": 7.299999836832285, \"match_probability\": 0.9936942917111425, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118583.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.39012570691634785, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6098742930836522, \"precision\": 0.9992247735411839, \"recall\": 0.39012570691634785, \"specificity\": 0.9999999280540541, \"npv\": 0.9998550514857469, \"accuracy\": 0.999854993005846, \"f1\": 0.5611590115371147, \"f2\": 0.44429116408233976, \"f0_5\": 0.7614545996267952, \"p4\": 0.7188817791195014, \"phi\": 0.6243129432622309}, {\"truth_threshold\": 7.31999983638525, \"match_probability\": 0.993780564333553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118538.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185423.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38997766160790365, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6100223383920964, \"precision\": 0.9992244794739947, \"recall\": 0.38997766160790365, \"specificity\": 0.9999999280540541, \"npv\": 0.9998550163049948, \"accuracy\": 0.9998549578232573, \"f1\": 0.5610057952015068, \"f2\": 0.4441375403342441, \"f0_5\": 0.761341638395799, \"p4\": 0.7187560382469309, \"phi\": 0.6241943716860754}, {\"truth_threshold\": 7.339999835938215, \"match_probability\": 0.9938656638890125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118507.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38987567483986435, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6101243251601357, \"precision\": 0.9992242767645596, \"recall\": 0.38987567483986435, \"specificity\": 0.9999999280540541, \"npv\": 0.9998549920693671, \"accuracy\": 0.9998549335863628, \"f1\": 0.5609002271866718, \"f2\": 0.4440317046138351, \"f0_5\": 0.7612637902659063, \"p4\": 0.7186693868160892, \"phi\": 0.6241126759451713}, {\"truth_threshold\": 7.35999983549118, \"match_probability\": 0.9939496061298939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118449.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185512.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3896848608867585, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6103151391132415, \"precision\": 0.9992238972169967, \"recall\": 0.3896848608867585, \"specificity\": 0.9999999280540541, \"npv\": 0.9998549467252925, \"accuracy\": 0.999854888239915, \"f1\": 0.5607026712299586, \"f2\": 0.4438336761879068, \"f0_5\": 0.7611180722891566, \"p4\": 0.7185071991437464, \"phi\": 0.6239597971319002}, {\"truth_threshold\": 7.379999835044146, \"match_probability\": 0.9940324066024261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118397.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3895137863081119, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6104862136918882, \"precision\": 0.99922355661707, \"recall\": 0.3895137863081119, \"specificity\": 0.9999999280540541, \"npv\": 0.9998549060719878, \"accuracy\": 0.9998548475844792, \"f1\": 0.5605255059770387, \"f2\": 0.443656118824911, \"f0_5\": 0.7609873546920816, \"p4\": 0.7183617167237784, \"phi\": 0.6238227015276516}, {\"truth_threshold\": 7.399999834597111, \"match_probability\": 0.9941140806492453, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118332.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38929994308480365, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6107000569151964, \"precision\": 0.9992231304465311, \"recall\": 0.38929994308480365, \"specificity\": 0.9999999280540541, \"npv\": 0.9998548552553614, \"accuracy\": 0.9998547967651843, \"f1\": 0.560303988067758, \"f2\": 0.44343415265898606, \"f0_5\": 0.7608238593621609, \"p4\": 0.7181797668538276, \"phi\": 0.6236512896574626}, {\"truth_threshold\": 7.419999834150076, \"match_probability\": 0.9941946434119178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118298.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185663.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3891880866295347, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6108119133704653, \"precision\": 0.999222907340147, \"recall\": 0.3891880866295347, \"specificity\": 0.9999999280540541, \"npv\": 0.9998548286743589, \"accuracy\": 0.9998547701827839, \"f1\": 0.5601880900009708, \"f2\": 0.4433180386648819, \"f0_5\": 0.7607382951714488, \"p4\": 0.7180845501822939, \"phi\": 0.6235616093010058}, {\"truth_threshold\": 7.439999833703041, \"match_probability\": 0.994274109833436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118248.0, \"tn\": 1278737700.0, \"fp\": 92.0, \"fn\": 185713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3890235918423745, \"tn_rate\": 0.9999999280540541, \"fp_rate\": 7.194594589724928e-08, \"fn_rate\": 0.6109764081576254, \"precision\": 0.9992225790096333, \"recall\": 0.3890235918423745, \"specificity\": 0.9999999280540541, \"npv\": 0.999854789584652, \"accuracy\": 0.9998547310910185, \"f1\": 0.5600176177655274, \"f2\": 0.4431472720404382, \"f0_5\": 0.7606124110888551, \"p4\": 0.7179444721078329, \"phi\": 0.6234297029973872}, {\"truth_threshold\": 7.459999833256006, \"match_probability\": 0.9943524946606879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118205.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185756.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38888212632541674, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6111178736745833, \"precision\": 0.9992307432203963, \"recall\": 0.38888212632541674, \"specificity\": 0.9999999288360752, \"npv\": 0.9998547559676201, \"accuracy\": 0.9998546982539357, \"f1\": 0.5598723052548567, \"f2\": 0.44300073455559386, \"f0_5\": 0.7605080133051104, \"p4\": 0.7178250438253798, \"phi\": 0.6233188768249209}, {\"truth_threshold\": 7.479999832808971, \"match_probability\": 0.9944298124468978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118164.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185797.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38874724059994537, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6112527594000546, \"precision\": 0.999230476512621, \"recall\": 0.38874724059994537, \"specificity\": 0.9999999288360752, \"npv\": 0.9998547239140648, \"accuracy\": 0.9998546661986882, \"f1\": 0.5597324592151884, \"f2\": 0.4428606872503465, \"f0_5\": 0.7604046945806912, \"p4\": 0.7177100872132106, \"phi\": 0.6232106736018675}, {\"truth_threshold\": 7.499999832361937, \"match_probability\": 0.9945060775540423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118113.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.388579455917042, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.611420544082958, \"precision\": 0.9992301444959562, \"recall\": 0.388579455917042, \"specificity\": 0.9999999288360752, \"npv\": 0.9998546840425722, \"accuracy\": 0.9998546263250876, \"f1\": 0.5595584664763777, \"f2\": 0.4426864700520521, \"f0_5\": 0.7602761152814772, \"p4\": 0.7175670324634905, \"phi\": 0.623076053134507}, {\"truth_threshold\": 7.519999831914902, \"match_probability\": 0.9945813041552386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118077.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3884610196702866, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6115389803297133, \"precision\": 0.9992299099587029, \"recall\": 0.3884610196702866, \"specificity\": 0.9999999288360752, \"npv\": 0.9998546558979909, \"accuracy\": 0.9998545981790166, \"f1\": 0.5594356227598672, \"f2\": 0.44256348518604033, \"f0_5\": 0.7601853127539004, \"p4\": 0.717466012606078, \"phi\": 0.6229810094142181}, {\"truth_threshold\": 7.539999831467867, \"match_probability\": 0.9946555062371064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118054.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38838535206819297, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6116146479318071, \"precision\": 0.999229760040628, \"recall\": 0.38838535206819297, \"specificity\": 0.9999999288360752, \"npv\": 0.9998546379167316, \"accuracy\": 0.9998545801968046, \"f1\": 0.5593571283042648, \"f2\": 0.4424849080464682, \"f0_5\": 0.7601272823971947, \"p4\": 0.7174014547873782, \"phi\": 0.6229202794481336}, {\"truth_threshold\": 7.559999831020832, \"match_probability\": 0.9947286976021039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118009.0, \"tn\": 1278737701.0, \"fp\": 91.0, \"fn\": 185952.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38823730675974877, \"tn_rate\": 0.9999999288360752, \"fp_rate\": 7.116392474619222e-08, \"fn_rate\": 0.6117626932402512, \"precision\": 0.999229466553768, \"recall\": 0.38823730675974877, \"specificity\": 0.9999999288360752, \"npv\": 0.9998546027360087, \"accuracy\": 0.9998545450142158, \"f1\": 0.5592035274521929, \"f2\": 0.44233116232765396, \"f0_5\": 0.7600137049645719, \"p4\": 0.7172751068597387, \"phi\": 0.6228014428282016}, {\"truth_threshold\": 7.579999830573797, \"match_probability\": 0.9948008918708379, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117978.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 185983.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38813531999170947, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6118646800082905, \"precision\": 0.9992885094272501, \"recall\": 0.38813531999170947, \"specificity\": 0.9999999343102233, \"npv\": 0.9998545785011969, \"accuracy\": 0.9998545262501685, \"f1\": 0.5591069681036341, \"f2\": 0.44222756326157914, \"f0_5\": 0.759962845058483, \"p4\": 0.7171956674266698, \"phi\": 0.6227380320143665}, {\"truth_threshold\": 7.599999830126762, \"match_probability\": 0.9948721024843478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117927.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38796753530880607, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.612032464691194, \"precision\": 0.9992882019472761, \"recall\": 0.38796753530880607, \"specificity\": 0.9999999343102233, \"npv\": 0.9998545386297161, \"accuracy\": 0.9998544863765679, \"f1\": 0.5589328201871214, \"f2\": 0.4420532966476866, \"f0_5\": 0.7598340216880046, \"p4\": 0.71705237018052, \"phi\": 0.6226033093791568}, {\"truth_threshold\": 7.6199998296797276, \"match_probability\": 0.9949423427063642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117878.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3878063304173891, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6121936695826109, \"precision\": 0.999287906274902, \"recall\": 0.3878063304173891, \"specificity\": 0.9999999343102233, \"npv\": 0.9998545003218257, \"accuracy\": 0.9998544480666379, \"f1\": 0.5587654619444781, \"f2\": 0.4418858514656554, \"f0_5\": 0.7597101863989719, \"p4\": 0.7169146296372733, \"phi\": 0.6224738425293342}, {\"truth_threshold\": 7.639999829232693, \"match_probability\": 0.9950116256255418, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117819.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186142.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38761222656854005, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.61238777343146, \"precision\": 0.9992875499351161, \"recall\": 0.38761222656854005, \"specificity\": 0.9999999343102233, \"npv\": 0.9998544541960024, \"accuracy\": 0.9998544019383548, \"f1\": 0.5585638973697684, \"f2\": 0.44168421747152947, \"f0_5\": 0.7595609955478079, \"p4\": 0.7167486970581706, \"phi\": 0.6223179181463452}, {\"truth_threshold\": 7.659999828785658, \"match_probability\": 0.9950799641576676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117758.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186203.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3874115429282046, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6125884570717954, \"precision\": 0.9992871811408496, \"recall\": 0.3874115429282046, \"specificity\": 0.9999999343102233, \"npv\": 0.9998544065065963, \"accuracy\": 0.9998543542464012, \"f1\": 0.5583554408100464, \"f2\": 0.44147572966950244, \"f0_5\": 0.7594066518858446, \"p4\": 0.7165770456944555, \"phi\": 0.6221566671191792}, {\"truth_threshold\": 7.679999828338623, \"match_probability\": 0.9951473710478438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117723.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186238.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38729639657719245, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6127036034228075, \"precision\": 0.999286969365148, \"recall\": 0.38729639657719245, \"specificity\": 0.9999999343102233, \"npv\": 0.9998543791438244, \"accuracy\": 0.9998543268821655, \"f1\": 0.5582358073632898, \"f2\": 0.44135609690991123, \"f0_5\": 0.7593180501787306, \"p4\": 0.7164785140513208, \"phi\": 0.6220641271729385}, {\"truth_threshold\": 7.699999827891588, \"match_probability\": 0.9952138588726456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117648.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186313.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38704965439645217, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6129503456035478, \"precision\": 0.9992865151360718, \"recall\": 0.38704965439645217, \"specificity\": 0.9999999343102233, \"npv\": 0.9998543205093182, \"accuracy\": 0.9998542682445176, \"f1\": 0.557979383105719, \"f2\": 0.4410997198509871, \"f0_5\": 0.7591280815703927, \"p4\": 0.7162672687704924, \"phi\": 0.6218657809339506}, {\"truth_threshold\": 7.719999827444553, \"match_probability\": 0.995279440042255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117611.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3869279282539536, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6130720717460464, \"precision\": 0.9992862908364841, \"recall\": 0.3869279282539536, \"specificity\": 0.9999999343102233, \"npv\": 0.9998542915829643, \"accuracy\": 0.9998542393166112, \"f1\": 0.5578528468704347, \"f2\": 0.4409732298792911, \"f0_5\": 0.7590343095305399, \"p4\": 0.7161630011291914, \"phi\": 0.6217679068243102}, {\"truth_threshold\": 7.7399998269975185, \"match_probability\": 0.9953441268025699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117584.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38683910106888714, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6131608989311129, \"precision\": 0.9992861270693817, \"recall\": 0.38683910106888714, \"specificity\": 0.9999999343102233, \"npv\": 0.999854270474545, \"accuracy\": 0.999854218207058, \"f1\": 0.5577604956015834, \"f2\": 0.44088092195645784, \"f0_5\": 0.7589658586711384, \"p4\": 0.7160868916907398, \"phi\": 0.6216964754558236}, {\"truth_threshold\": 7.759999826550484, \"match_probability\": 0.9954079312372888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117551.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3867305345093614, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6132694654906387, \"precision\": 0.9992859268074977, \"recall\": 0.3867305345093614, \"specificity\": 0.9999999343102233, \"npv\": 0.9998542446753671, \"accuracy\": 0.999854192406493, \"f1\": 0.5576476057647606, \"f2\": 0.44076809608550266, \"f0_5\": 0.7588821705846732, \"p4\": 0.7159938435482626, \"phi\": 0.6216091593067533}, {\"truth_threshold\": 7.779999826103449, \"match_probability\": 0.9954708652699722, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117469.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186492.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3864607630584187, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6135392369415813, \"precision\": 0.9992854287002458, \"recall\": 0.3864607630584187, \"specificity\": 0.9999999343102233, \"npv\": 0.9998541805683245, \"accuracy\": 0.9998541282959978, \"f1\": 0.5573670150932116, \"f2\": 0.44048771671152703, \"f0_5\": 0.7586740948082664, \"p4\": 0.7157625115081618, \"phi\": 0.6213921388033198}, {\"truth_threshold\": 7.799999825656414, \"match_probability\": 0.9955329406660792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117425.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186536.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3863160076457177, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6136839923542823, \"precision\": 0.9992851611365938, \"recall\": 0.3863160076457177, \"specificity\": 0.9999999343102233, \"npv\": 0.999854146169427, \"accuracy\": 0.9998540938952444, \"f1\": 0.5572164092343465, \"f2\": 0.44033725502548837, \"f0_5\": 0.7585623716887792, \"p4\": 0.7156383106351968, \"phi\": 0.6212756575362759}, {\"truth_threshold\": 7.819999825209379, \"match_probability\": 0.9955941690349815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117380.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186581.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3861679623372735, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6138320376627264, \"precision\": 0.9992848872846148, \"recall\": 0.3861679623372735, \"specificity\": 0.9999999343102233, \"npv\": 0.9998541109887389, \"accuracy\": 0.9998540587126556, \"f1\": 0.5570623479859999, \"f2\": 0.4401833634839062, \"f0_5\": 0.7584480568403124, \"p4\": 0.7155112353333655, \"phi\": 0.6211565063828182}, {\"truth_threshold\": 7.839999824762344, \"match_probability\": 0.9956545618319536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117326.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186635.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3859903079671405, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6140096920328595, \"precision\": 0.9992845583851461, \"recall\": 0.3859903079671405, \"specificity\": 0.9999999343102233, \"npv\": 0.9998540687719164, \"accuracy\": 0.9998540164935491, \"f1\": 0.5568774310524455, \"f2\": 0.4399986799214553, \"f0_5\": 0.7583108088019535, \"p4\": 0.7153586759396223, \"phi\": 0.6210134948332662}, {\"truth_threshold\": 7.8599998243153095, \"match_probability\": 0.9957141303601397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117249.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3857369859949138, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6142630140050862, \"precision\": 0.9992840888752524, \"recall\": 0.3857369859949138, \"specificity\": 0.9999999343102233, \"npv\": 0.9998540085738609, \"accuracy\": 0.9998539562922306, \"f1\": 0.5566136712129771, \"f2\": 0.43973530896497615, \"f0_5\": 0.7581149706514866, \"p4\": 0.7151410071890865, \"phi\": 0.6208095139972929}, {\"truth_threshold\": 7.879999823868275, \"match_probability\": 0.9957728857724977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117174.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3854902438141735, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6145097561858265, \"precision\": 0.9992836309676099, \"recall\": 0.3854902438141735, \"specificity\": 0.9999999343102233, \"npv\": 0.9998539499393981, \"accuracy\": 0.9998538976545827, \"f1\": 0.5563566695709358, \"f2\": 0.43947874956304916, \"f0_5\": 0.757924069170096, \"p4\": 0.7149288447096005, \"phi\": 0.6206107669341723}, {\"truth_threshold\": 7.89999982342124, \"match_probability\": 0.9958308390737213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117137.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38536851767167496, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.614631482328325, \"precision\": 0.9992834048506667, \"recall\": 0.38536851767167496, \"specificity\": 0.9999999343102233, \"npv\": 0.9998539210130657, \"accuracy\": 0.9998538687266764, \"f1\": 0.5562298483790855, \"f2\": 0.43935216962413687, \"f0_5\": 0.757829836513143, \"p4\": 0.7148241242360192, \"phi\": 0.6205126949430124}, {\"truth_threshold\": 7.919999822974205, \"match_probability\": 0.9958880011221378, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117090.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186871.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3852138925717444, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6147861074282556, \"precision\": 0.9992831174151262, \"recall\": 0.3852138925717444, \"specificity\": 0.9999999343102233, \"npv\": 0.9998538842688081, \"accuracy\": 0.999853831980417, \"f1\": 0.5560687190568345, \"f2\": 0.43919136875871145, \"f0_5\": 0.7577100835170069, \"p4\": 0.7146910497816829, \"phi\": 0.6203880946617555}, {\"truth_threshold\": 7.93999982252717, \"match_probability\": 0.9959443826315856, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117010.0, \"tn\": 1278737708.0, \"fp\": 84.0, \"fn\": 186951.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3849507009122881, \"tn_rate\": 0.9999999343102233, \"fp_rate\": 6.568977668879282e-08, \"fn_rate\": 0.6150492990877119, \"precision\": 0.9992826276325004, \"recall\": 0.3849507009122881, \"specificity\": 0.9999999343102233, \"npv\": 0.9998538217253968, \"accuracy\": 0.9998537694335925, \"f1\": 0.5557943736566482, \"f2\": 0.4389176390799872, \"f0_5\": 0.7575061145588001, \"p4\": 0.7144644083409392, \"phi\": 0.6201759515285055}, {\"truth_threshold\": 7.959999822080135, \"match_probability\": 0.9959999941732675, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116969.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 186992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38481581518681673, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6151841848131833, \"precision\": 0.9992909134401804, \"recall\": 0.38481581518681673, \"specificity\": 0.9999999350922445, \"npv\": 0.999853789672016, \"accuracy\": 0.9998537381601803, \"f1\": 0.5556550510316783, \"f2\": 0.43877766907545673, \"f0_5\": 0.7574054384467649, \"p4\": 0.7143492809911567, \"phi\": 0.6200698497471634}, {\"truth_threshold\": 7.9799998216331005, \"match_probability\": 0.9960548461775844, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116927.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3846776395656022, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6153223604343978, \"precision\": 0.9992906589180411, \"recall\": 0.3846776395656022, \"specificity\": 0.9999999350922445, \"npv\": 0.9998537568367305, \"accuracy\": 0.9998537053230975, \"f1\": 0.5555109496853703, \"f2\": 0.4386339389010349, \"f0_5\": 0.7572982418416556, \"p4\": 0.7142301830535667, \"phi\": 0.619958426497678}, {\"truth_threshold\": 7.999999821186066, \"match_probability\": 0.9961089489359451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116878.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38451643467418517, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6154835653258148, \"precision\": 0.9992903617445131, \"recall\": 0.38451643467418517, \"specificity\": 0.9999999350922445, \"npv\": 0.9998537185289, \"accuracy\": 0.9998536670131675, \"f1\": 0.5553427951021804, \"f2\": 0.43846624224849096, \"f0_5\": 0.7571731201534067, \"p4\": 0.7140911775229771, \"phi\": 0.6198284074002667}, {\"truth_threshold\": 8.01999982073903, \"match_probability\": 0.9961623126025559, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116832.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3843650994699978, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6156349005300022, \"precision\": 0.9992900825385964, \"recall\": 0.3843650994699978, \"specificity\": 0.9999999350922445, \"npv\": 0.9998536825664496, \"accuracy\": 0.9998536310487434, \"f1\": 0.5551849000655775, \"f2\": 0.4383088015162531, \"f0_5\": 0.7570556011306069, \"p4\": 0.7139606257190826, \"phi\": 0.6197063238399702}, {\"truth_threshold\": 8.039999820291996, \"match_probability\": 0.9962149471961885, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116764.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187197.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38414138655945995, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.61585861344054, \"precision\": 0.9992896693967325, \"recall\": 0.38414138655945995, \"specificity\": 0.9999999350922445, \"npv\": 0.9998536294045711, \"accuracy\": 0.9998535778839426, \"f1\": 0.5549514267789586, \"f2\": 0.4380760431337797, \"f0_5\": 0.7568817746571267, \"p4\": 0.7137675352339774, \"phi\": 0.6195258084381768}, {\"truth_threshold\": 8.059999819844961, \"match_probability\": 0.9962668626019269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116705.0, \"tn\": 1278737709.0, \"fp\": 83.0, \"fn\": 187256.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3839472827106109, \"tn_rate\": 0.9999999350922445, \"fp_rate\": 6.490775553773576e-08, \"fn_rate\": 0.6160527172893892, \"precision\": 0.999289310545604, \"recall\": 0.3839472827106109, \"specificity\": 0.9999999350922445, \"npv\": 0.9998535832788282, \"accuracy\": 0.9998535317556596, \"f1\": 0.5547487932235133, \"f2\": 0.4378740717617467, \"f0_5\": 0.7567308552702392, \"p4\": 0.7135999032730516, \"phi\": 0.6193691421691789}, {\"truth_threshold\": 8.079999819397926, \"match_probability\": 0.9963180685728933, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116649.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38376304854899146, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6162369514510085, \"precision\": 0.9993060909791828, \"recall\": 0.38376304854899146, \"specificity\": 0.9999999366562867, \"npv\": 0.999853539498695, \"accuracy\": 0.9998534895365531, \"f1\": 0.5545590469014074, \"f2\": 0.43768301047446523, \"f0_5\": 0.7565953759399959, \"p4\": 0.7134428929974631, \"phi\": 0.6192257120701571}, {\"truth_threshold\": 8.099999818950891, \"match_probability\": 0.9963685747319533, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116590.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187371.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38356894470014247, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6164310552998575, \"precision\": 0.9993057400725116, \"recall\": 0.38356894470014247, \"specificity\": 0.9999999366562867, \"npv\": 0.9998534933729605, \"accuracy\": 0.99985344340827, \"f1\": 0.5543563019456437, \"f2\": 0.4374810039661842, \"f0_5\": 0.7564442771963744, \"p4\": 0.7132750841942754, \"phi\": 0.6190689698810844}, {\"truth_threshold\": 8.119999818503857, \"match_probability\": 0.9964183905734008, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116507.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38329588335345655, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6167041166465435, \"precision\": 0.9993052458228977, \"recall\": 0.38329588335345655, \"specificity\": 0.9999999366562867, \"npv\": 0.9998534284842225, \"accuracy\": 0.9998533785159397, \"f1\": 0.5540709881607138, \"f2\": 0.4371967950334426, \"f0_5\": 0.7562315578213012, \"p4\": 0.7130388603210579, \"phi\": 0.6188484009742578}, {\"truth_threshold\": 8.139999818056822, \"match_probability\": 0.9964675254646224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116452.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3831149390875803, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6168850609124197, \"precision\": 0.9993049179202458, \"recall\": 0.3831149390875803, \"specificity\": 0.9999999366562867, \"npv\": 0.9998533854856658, \"accuracy\": 0.9998533355149979, \"f1\": 0.5538818627614187, \"f2\": 0.43700844430667896, \"f0_5\": 0.7560904981606118, \"p4\": 0.712882227254844, \"phi\": 0.6187021975537252}, {\"truth_threshold\": 8.159999817609787, \"match_probability\": 0.9965159886477419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116396.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3829307049259609, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6170692950740391, \"precision\": 0.9993045837375619, \"recall\": 0.3829307049259609, \"specificity\": 0.9999999366562867, \"npv\": 0.999853341705321, \"accuracy\": 0.9998532917322207, \"f1\": 0.5536892478795923, \"f2\": 0.4368166530438235, \"f0_5\": 0.7559467909475508, \"p4\": 0.7127226650213045, \"phi\": 0.6185533003968459}, {\"truth_threshold\": 8.179999817162752, \"match_probability\": 0.9965637892412448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116339.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38274318086859827, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6172568191314017, \"precision\": 0.9993042432571723, \"recall\": 0.38274318086859827, \"specificity\": 0.9999999366562867, \"npv\": 0.9998532971431883, \"accuracy\": 0.9998532471676083, \"f1\": 0.5534931407461327, \"f2\": 0.4366214203791441, \"f0_5\": 0.7558004316298118, \"p4\": 0.7125601691611895, \"phi\": 0.6184017075585498}, {\"truth_threshold\": 8.199999816715717, \"match_probability\": 0.9966109362415831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116292.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3825885557686677, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6174114442313323, \"precision\": 0.999303962259287, \"recall\": 0.3825885557686677, \"specificity\": 0.9999999366562867, \"npv\": 0.9998532603989765, \"accuracy\": 0.9998532104213489, \"f1\": 0.553331398364158, \"f2\": 0.4364604264920805, \"f0_5\": 0.7556796841392521, \"p4\": 0.7124261173246433, \"phi\": 0.6182766820059847}, {\"truth_threshold\": 8.219999816268682, \"match_probability\": 0.9966574385247609, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116225.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38236813275387305, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.617631867246127, \"precision\": 0.999303561295204, \"recall\": 0.38236813275387305, \"specificity\": 0.9999999366562867, \"npv\": 0.9998532080189346, \"accuracy\": 0.9998531580383835, \"f1\": 0.5531007668934272, \"f2\": 0.4362309049281237, \"f0_5\": 0.7555074526934352, \"p4\": 0.7122349220337405, \"phi\": 0.6180984103852231}, {\"truth_threshold\": 8.239999815821648, \"match_probability\": 0.9967033048478998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116178.0, \"tn\": 1278737711.0, \"fp\": 81.0, \"fn\": 187783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38221350765394246, \"tn_rate\": 0.9999999366562867, \"fp_rate\": 6.334371323562165e-08, \"fn_rate\": 0.6177864923460575, \"precision\": 0.9993032797460841, \"recall\": 0.38221350765394246, \"specificity\": 0.9999999366562867, \"npv\": 0.9998531712747295, \"accuracy\": 0.9998531212921241, \"f1\": 0.552938936747418, \"f2\": 0.43606988348498577, \"f0_5\": 0.7553865619761846, \"p4\": 0.7121007296788255, \"phi\": 0.617973323493377}, {\"truth_threshold\": 8.259999815374613, \"match_probability\": 0.9967485438507871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116148.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38211481078164633, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6178851892183537, \"precision\": 0.9993116976976288, \"recall\": 0.38211481078164633, \"specificity\": 0.999999937438308, \"npv\": 0.9998531478210977, \"accuracy\": 0.9998530986189003, \"f1\": 0.5528369376637656, \"f2\": 0.43596742518422427, \"f0_5\": 0.7553132962140692, \"p4\": 0.7120161359684855, \"phi\": 0.617896126687664}, {\"truth_threshold\": 8.279999814927578, \"match_probability\": 0.9967931640574029, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116094.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3819371564115133, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6180628435884867, \"precision\": 0.9993113777609448, \"recall\": 0.3819371564115133, \"specificity\": 0.999999937438308, \"npv\": 0.9998531056043567, \"accuracy\": 0.9998530563997937, \"f1\": 0.5526509336284766, \"f2\": 0.4357823993369459, \"f0_5\": 0.7551742844988076, \"p4\": 0.7118618433950391, \"phi\": 0.6177523606223624}, {\"truth_threshold\": 8.299999814480543, \"match_probability\": 0.9968371738774299, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116029.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38172331318820507, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6182766868117949, \"precision\": 0.9993109922572755, \"recall\": 0.38172331318820507, \"specificity\": 0.999999937438308, \"npv\": 0.9998530547879139, \"accuracy\": 0.9998530055804988, \"f1\": 0.5524269764563049, \"f2\": 0.435559663141267, \"f0_5\": 0.7550068519268035, \"p4\": 0.7116760191886083, \"phi\": 0.6175792645055627}, {\"truth_threshold\": 8.319999814033508, \"match_probability\": 0.9968805816077441, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115985.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 187976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3815785577755041, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6184214422244959, \"precision\": 0.9993107310558739, \"recall\": 0.3815785577755041, \"specificity\": 0.999999937438308, \"npv\": 0.999853020389094, \"accuracy\": 0.9998529711797454, \"f1\": 0.552275335336384, \"f2\": 0.4354088755312863, \"f0_5\": 0.7548934486300166, \"p4\": 0.7115501674119241, \"phi\": 0.6174620642181656}, {\"truth_threshold\": 8.339999813586473, \"match_probability\": 0.9969233954338881, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115908.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3813252358032774, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6186747641967226, \"precision\": 0.9993102734765665, \"recall\": 0.3813252358032774, \"specificity\": 0.999999937438308, \"npv\": 0.9998529601911648, \"accuracy\": 0.9998529109784269, \"f1\": 0.5520098869148397, \"f2\": 0.4351449732398681, \"f0_5\": 0.7546948677779904, \"p4\": 0.7113298041487519, \"phi\": 0.6172569101881081}, {\"truth_threshold\": 8.359999813139439, \"match_probability\": 0.9969656234315248, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115861.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188100.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3811706107033468, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6188293892966532, \"precision\": 0.9993099938761957, \"recall\": 0.3811706107033468, \"specificity\": 0.999999937438308, \"npv\": 0.9998529234469778, \"accuracy\": 0.9998528742321675, \"f1\": 0.5518478121085396, \"f2\": 0.4349838750248726, \"f0_5\": 0.7545735777785014, \"p4\": 0.7111952199201443, \"phi\": 0.6171316527928938}, {\"truth_threshold\": 8.379999812692404, \"match_probability\": 0.9970072735678748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115804.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3809830866459842, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6190169133540158, \"precision\": 0.9993096544820683, \"recall\": 0.3809830866459842, \"specificity\": 0.999999937438308, \"npv\": 0.9998528788848824, \"accuracy\": 0.9998528296675551, \"f1\": 0.5516512046112255, \"f2\": 0.43478848533634495, \"f0_5\": 0.7544264016667166, \"p4\": 0.7110319225844514, \"phi\": 0.6169797107797494}, {\"truth_threshold\": 8.399999812245369, \"match_probability\": 0.9970483537031342, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115722.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3807133151950415, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6192866848049585, \"precision\": 0.9993091656448075, \"recall\": 0.3807133151950415, \"specificity\": 0.999999937438308, \"npv\": 0.9998528147780152, \"accuracy\": 0.9998527655570599, \"f1\": 0.5513682720963973, \"f2\": 0.43450736907556514, \"f0_5\": 0.7542145211811218, \"p4\": 0.7107968531909042, \"phi\": 0.6167610618986512}, {\"truth_threshold\": 8.419999811798334, \"match_probability\": 0.997088871591877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115677.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188284.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3805652698865973, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6194347301134027, \"precision\": 0.9993088970861373, \"recall\": 0.3805652698865973, \"specificity\": 0.999999937438308, \"npv\": 0.9998527795974209, \"accuracy\": 0.9998527303744712, \"f1\": 0.5512129572713107, \"f2\": 0.434353083243404, \"f0_5\": 0.7540981682918529, \"p4\": 0.7106677762096498, \"phi\": 0.6166410387236468}, {\"truth_threshold\": 8.4399998113513, \"match_probability\": 0.9971288348844387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115624.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3803909054122075, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6196090945877926, \"precision\": 0.999308580515799, \"recall\": 0.3803909054122075, \"specificity\": 0.999999937438308, \"npv\": 0.9998527381625019, \"accuracy\": 0.9998526889372, \"f1\": 0.5510299882048777, \"f2\": 0.4341713554449408, \"f0_5\": 0.753961060386527, \"p4\": 0.7105156835492599, \"phi\": 0.6164996481391302}, {\"truth_threshold\": 8.459999810904264, \"match_probability\": 0.997168251128283, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115585.0, \"tn\": 1278737712.0, \"fp\": 80.0, \"fn\": 188376.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38026259947822255, \"tn_rate\": 0.999999937438308, \"fp_rate\": 6.256169208456459e-08, \"fn_rate\": 0.6197374005217775, \"precision\": 0.9993083473825272, \"recall\": 0.38026259947822255, \"specificity\": 0.999999937438308, \"npv\": 0.999852707672658, \"accuracy\": 0.9998526584456231, \"f1\": 0.5508953210716209, \"f2\": 0.43403762197626905, \"f0_5\": 0.7538601212333083, \"p4\": 0.7104037188483433, \"phi\": 0.6163955853049905}, {\"truth_threshold\": 8.47999981045723, \"match_probability\": 0.9972071277693515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115531.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.38008494510808954, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6199150548919105, \"precision\": 0.9993166681082951, \"recall\": 0.38008494510808954, \"specificity\": 0.9999999382203291, \"npv\": 0.9998526654560692, \"accuracy\": 0.9998526170083519, \"f1\": 0.5507101301090876, \"f2\": 0.4338527654729341, \"f0_5\": 0.7537242253076392, \"p4\": 0.7102497160248971, \"phi\": 0.616254135542428}, {\"truth_threshold\": 8.499999810010195, \"match_probability\": 0.9972454721533973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115479.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188482.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3799138705294429, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6200861294705571, \"precision\": 0.9993163606154485, \"recall\": 0.3799138705294429, \"specificity\": 0.9999999382203291, \"npv\": 0.9998526248029505, \"accuracy\": 0.999852576352916, \"f1\": 0.5505304884880065, \"f2\": 0.43367442740810064, \"f0_5\": 0.7535895002956174, \"p4\": 0.7101002927699878, \"phi\": 0.6161153259211698}, {\"truth_threshold\": 8.51999980956316, \"match_probability\": 0.9972832915273011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115421.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188540.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3797230565763371, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6202769434236629, \"precision\": 0.9993160173160173, \"recall\": 0.3797230565763371, \"specificity\": 0.9999999382203291, \"npv\": 0.999852579459091, \"accuracy\": 0.9998525310064682, \"f1\": 0.5503300664424107, \"f2\": 0.4334754954391953, \"f0_5\": 0.7534391437684164, \"p4\": 0.7099335438015231, \"phi\": 0.6159604629148098}, {\"truth_threshold\": 8.539999809116125, \"match_probability\": 0.9973205930403709, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115383.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37959804053809537, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6204019594619047, \"precision\": 0.999315792208692, \"recall\": 0.37959804053809537, \"specificity\": 0.9999999382203291, \"npv\": 0.9998525497510474, \"accuracy\": 0.9998525012967266, \"f1\": 0.5501987253917883, \"f2\": 0.4333451513025555, \"f0_5\": 0.7533405849239171, \"p4\": 0.7098242460890318, \"phi\": 0.6158589798381796}, {\"truth_threshold\": 8.55999980866909, \"match_probability\": 0.9973573837456264, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115333.0, \"tn\": 1278737713.0, \"fp\": 79.0, \"fn\": 188628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37943354575093513, \"tn_rate\": 0.9999999382203291, \"fp_rate\": 6.177967093350753e-08, \"fn_rate\": 0.6205664542490649, \"precision\": 0.9993154957889994, \"recall\": 0.37943354575093513, \"specificity\": 0.9999999382203291, \"npv\": 0.999852510661519, \"accuracy\": 0.9998524622049614, \"f1\": 0.5500258719564683, \"f2\": 0.43317363452258617, \"f0_5\": 0.7532108426102619, \"p4\": 0.7096803749069995, \"phi\": 0.6157254240001324}, {\"truth_threshold\": 8.579999808222055, \"match_probability\": 0.9973936706010663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115288.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188673.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.379285500442491, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.620714499557509, \"precision\": 0.9993238909210685, \"recall\": 0.379285500442491, \"specificity\": 0.9999999390023502, \"npv\": 0.9998524754810615, \"accuracy\": 0.9998524278042079, \"f1\": 0.5498715799364219, \"f2\": 0.4330195836870216, \"f0_5\": 0.7530979521181044, \"p4\": 0.709551925914506, \"phi\": 0.615607868057038}, {\"truth_threshold\": 8.59999980777502, \"match_probability\": 0.9974294604709201, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115242.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3791341652383036, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6208658347616964, \"precision\": 0.9993236212278876, \"recall\": 0.3791341652383036, \"specificity\": 0.9999999390023502, \"npv\": 0.9998524395187006, \"accuracy\": 0.9998523918397838, \"f1\": 0.5497124839904504, \"f2\": 0.432861766093434, \"f0_5\": 0.752978473448234, \"p4\": 0.7094194507828755, \"phi\": 0.6154849476387403}, {\"truth_threshold\": 8.619999807327986, \"match_probability\": 0.9974647601268845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115213.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3790387582617507, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6209612417382493, \"precision\": 0.9993234510933203, \"recall\": 0.3790387582617507, \"specificity\": 0.9999999390023502, \"npv\": 0.9998524168467788, \"accuracy\": 0.99985236916656, \"f1\": 0.5496121664297368, \"f2\": 0.4327622667873657, \"f0_5\": 0.7529031204051626, \"p4\": 0.7093359049300898, \"phi\": 0.6154074417178773}, {\"truth_threshold\": 8.639999806880951, \"match_probability\": 0.9974995762493434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115175.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188786.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37891374222350893, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6210862577764911, \"precision\": 0.9993232280287715, \"recall\": 0.37891374222350893, \"specificity\": 0.9999999390023502, \"npv\": 0.9998523871387449, \"accuracy\": 0.9998523394568184, \"f1\": 0.5494806948241232, \"f2\": 0.432631881823789, \"f0_5\": 0.7528043473429781, \"p4\": 0.7092263971810235, \"phi\": 0.615305867462871}, {\"truth_threshold\": 8.659999806433916, \"match_probability\": 0.9975339154285738, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115115.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188846.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3787163484789167, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6212836515210833, \"precision\": 0.9993228755219501, \"recall\": 0.3787163484789167, \"specificity\": 0.9999999390023502, \"npv\": 0.9998523402313265, \"accuracy\": 0.9998522925467, \"f1\": 0.5492730595437476, \"f2\": 0.43242599567104445, \"f0_5\": 0.7526483099330094, \"p4\": 0.7090534119330413, \"phi\": 0.6151454529242452}, {\"truth_threshold\": 8.679999805986881, \"match_probability\": 0.9975677841659352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115063.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188898.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3785452739002701, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6214547260997298, \"precision\": 0.9993225697188665, \"recall\": 0.3785452739002701, \"specificity\": 0.9999999390023502, \"npv\": 0.9998522995782341, \"accuracy\": 0.9998522518912641, \"f1\": 0.5490930608777815, \"f2\": 0.43224754599037557, \"f0_5\": 0.7525129982668978, \"p4\": 0.70890341380076, \"phi\": 0.6150063931578426}, {\"truth_threshold\": 8.699999805539846, \"match_probability\": 0.9976011888750448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114977.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 188984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3782623428663546, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6217376571336455, \"precision\": 0.9993220633610013, \"recall\": 0.3782623428663546, \"specificity\": 0.9999999390023502, \"npv\": 0.9998522323442809, \"accuracy\": 0.9998521846534278, \"f1\": 0.5487952727342154, \"f2\": 0.43195238707069433, \"f0_5\": 0.7522890519392657, \"p4\": 0.7086551817231127, \"phi\": 0.6147763406947571}, {\"truth_threshold\": 8.719999805092812, \"match_probability\": 0.9976341358829378, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114936.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3781274571408832, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6218725428591168, \"precision\": 0.9993218216912724, \"recall\": 0.3781274571408832, \"specificity\": 0.9999999390023502, \"npv\": 0.9998522002908878, \"accuracy\": 0.9998521525981803, \"f1\": 0.5486532609344233, \"f2\": 0.4318116583437151, \"f0_5\": 0.752182215840747, \"p4\": 0.7085367690376431, \"phi\": 0.614666634222223}, {\"truth_threshold\": 8.739999804645777, \"match_probability\": 0.9976666314312127, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114904.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3780221804771007, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6219778195228993, \"precision\": 0.9993216329512445, \"recall\": 0.3780221804771007, \"specificity\": 0.9999999390023502, \"npv\": 0.9998521752736068, \"accuracy\": 0.9998521275794505, \"f1\": 0.5485424031431484, \"f2\": 0.4317018152636032, \"f0_5\": 0.75209879969472, \"p4\": 0.7084443181846366, \"phi\": 0.6145809960562666}, {\"truth_threshold\": 8.759999804198742, \"match_probability\": 0.997698681677162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114818.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37773924944318515, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6222607505568148, \"precision\": 0.9993211251914775, \"recall\": 0.37773924944318515, \"specificity\": 0.9999999390023502, \"npv\": 0.9998521080396703, \"accuracy\": 0.9998520603416142, \"f1\": 0.5482443888964491, \"f2\": 0.4314065858093993, \"f0_5\": 0.7518744802205501, \"p4\": 0.7081957208962776, \"phi\": 0.6143507843547003}, {\"truth_threshold\": 8.779999803751707, \"match_probability\": 0.9977302926948894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114764.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189197.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37756159507305215, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6224384049269479, \"precision\": 0.9993208059769074, \"recall\": 0.37756159507305215, \"specificity\": 0.9999999390023502, \"npv\": 0.9998520658230171, \"accuracy\": 0.9998520181225077, \"f1\": 0.5480572011184256, \"f2\": 0.43122118967209394, \"f0_5\": 0.7517335251248152, \"p4\": 0.7080395238100022, \"phi\": 0.6142061887373855}, {\"truth_threshold\": 8.799999803304672, \"match_probability\": 0.9977614704764116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114701.0, \"tn\": 1278737714.0, \"fp\": 78.0, \"fn\": 189260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3773543316412303, \"tn_rate\": 0.9999999390023502, \"fp_rate\": 6.099764978245047e-08, \"fn_rate\": 0.6226456683587697, \"precision\": 0.9993204331802856, \"recall\": 0.3773543316412303, \"specificity\": 0.9999999390023502, \"npv\": 0.9998520165702596, \"accuracy\": 0.9998519688668834, \"f1\": 0.5478387543583131, \"f2\": 0.4310048751599814, \"f0_5\": 0.7515689766563531, \"p4\": 0.7078571951967249, \"phi\": 0.6140374508307914}, {\"truth_threshold\": 8.819999802857637, \"match_probability\": 0.997792220932747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114625.0, \"tn\": 1278737718.0, \"fp\": 74.0, \"fn\": 189336.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3771042995647468, \"tn_rate\": 0.9999999421304349, \"fp_rate\": 5.786956517822224e-08, \"fn_rate\": 0.6228957004352532, \"precision\": 0.9993548330848568, \"recall\": 0.3771042995647468, \"specificity\": 0.9999999421304349, \"npv\": 0.9998519571547041, \"accuracy\": 0.9998519125747414, \"f1\": 0.5475803754836861, \"f2\": 0.43074519200055916, \"f0_5\": 0.7513860901964846, \"p4\": 0.7076414706810285, \"phi\": 0.6138445397085209}, {\"truth_threshold\": 8.839999802410603, \"match_probability\": 0.9978225498949904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114567.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189394.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37691348561164095, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.623086514388359, \"precision\": 0.9993632240055826, \"recall\": 0.37691348561164095, \"specificity\": 0.999999942912456, \"npv\": 0.9998519118110213, \"accuracy\": 0.999851868010129, \"f1\": 0.5473804410405135, \"f2\": 0.4305463275018715, \"f0_5\": 0.7512383265510064, \"p4\": 0.7074744927617425, \"phi\": 0.6136917814944302}, {\"truth_threshold\": 8.859999801963568, \"match_probability\": 0.9978524631153733, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114498.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189463.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3766864828053599, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.6233135171946401, \"precision\": 0.9993628405093785, \"recall\": 0.3766864828053599, \"specificity\": 0.999999942912456, \"npv\": 0.9998518578675419, \"accuracy\": 0.9998518140634929, \"f1\": 0.5471409593531678, \"f2\": 0.4303093395669772, \"f0_5\": 0.7510577307820976, \"p4\": 0.7072744295632661, \"phi\": 0.6135068159819479}, {\"truth_threshold\": 8.879999801516533, \"match_probability\": 0.997881966268312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114445.0, \"tn\": 1278737719.0, \"fp\": 73.0, \"fn\": 189516.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3765121183309701, \"tn_rate\": 0.999999942912456, \"fp_rate\": 5.708754402716519e-08, \"fn_rate\": 0.6234878816690299, \"precision\": 0.9993625456260151, \"recall\": 0.3765121183309701, \"specificity\": 0.999999942912456, \"npv\": 0.9998518164326996, \"accuracy\": 0.9998517726262217, \"f1\": 0.5469569560240777, \"f2\": 0.430127288662785, \"f0_5\": 0.7509189234586954, \"p4\": 0.7071206709565333, \"phi\": 0.6133647031601686}, {\"truth_threshold\": 8.899999801069498, \"match_probability\": 0.9979110649514407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114386.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37631801448212104, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6236819855178789, \"precision\": 0.9994320713667858, \"recall\": 0.37631801448212104, \"specificity\": 0.9999999491686252, \"npv\": 0.9998517703080515, \"accuracy\": 0.9998517327526211, \"f1\": 0.546762521151401, \"f2\": 0.42992719659925055, \"f0_5\": 0.7507958491135718, \"p4\": 0.7069581561858675, \"phi\": 0.6132279025029516}, {\"truth_threshold\": 8.919999800622463, \"match_probability\": 0.9979397646866325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114324.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3761140409460424, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6238859590539576, \"precision\": 0.9994317635436973, \"recall\": 0.3761140409460424, \"specificity\": 0.9999999491686252, \"npv\": 0.9998517218371129, \"accuracy\": 0.9998516842788321, \"f1\": 0.5465471495159555, \"f2\": 0.4297141929271037, \"f0_5\": 0.7506332754226104, \"p4\": 0.7067780935775435, \"phi\": 0.6130615784260735}, {\"truth_threshold\": 8.939999800175428, \"match_probability\": 0.9979680709210076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114253.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37588045834827494, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.624119541651725, \"precision\": 0.999431410626498, \"recall\": 0.37588045834827494, \"specificity\": 0.9999999491686252, \"npv\": 0.999851666330076, \"accuracy\": 0.9998516287685254, \"f1\": 0.5463004358334987, \"f2\": 0.4294702449776794, \"f0_5\": 0.7504469722148146, \"p4\": 0.7065717656528624, \"phi\": 0.61287105510962}, {\"truth_threshold\": 8.959999799728394, \"match_probability\": 0.9979959890279272, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114213.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3757488625185468, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6242511374814532, \"precision\": 0.9994312116067835, \"recall\": 0.3757488625185468, \"specificity\": 0.9999999491686252, \"npv\": 0.9998516350585087, \"accuracy\": 0.9998515974951132, \"f1\": 0.5461614053208811, \"f2\": 0.4293327980440892, \"f0_5\": 0.7503419514291008, \"p4\": 0.7064554647143992, \"phi\": 0.6127636919513574}, {\"truth_threshold\": 8.979999799281359, \"match_probability\": 0.9980235243079757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114130.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37547580117186086, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6245241988281391, \"precision\": 0.9994307981960682, \"recall\": 0.37547580117186086, \"specificity\": 0.9999999491686252, \"npv\": 0.9998515701700127, \"accuracy\": 0.9998515326027828, \"f1\": 0.5458728321487675, \"f2\": 0.429047569281803, \"f0_5\": 0.7501238923628409, \"p4\": 0.706214002519102, \"phi\": 0.6125408533838965}, {\"truth_threshold\": 8.999999798834324, \"match_probability\": 0.9980506819899304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114075.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189886.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37529485690598463, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6247051430940154, \"precision\": 0.9994305239179955, \"recall\": 0.37529485690598463, \"specificity\": 0.9999999491686252, \"npv\": 0.9998515271716164, \"accuracy\": 0.999851489601841, \"f1\": 0.5456815458465777, \"f2\": 0.4288585426591598, \"f0_5\": 0.749979290512688, \"p4\": 0.7060538949549576, \"phi\": 0.6123931446199526}, {\"truth_threshold\": 9.019999798387289, \"match_probability\": 0.9980774672317183, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113999.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 189962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37504482482950113, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6249551751704988, \"precision\": 0.9994301444802918, \"recall\": 0.37504482482950113, \"specificity\": 0.9999999491686252, \"npv\": 0.9998514677556567, \"accuracy\": 0.9998514301823578, \"f1\": 0.5454171401231984, \"f2\": 0.42859731650610416, \"f0_5\": 0.7497793393202205, \"p4\": 0.7058325208328471, \"phi\": 0.6121889793368667}, {\"truth_threshold\": 9.039999797940254, \"match_probability\": 0.99810388512136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113932.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190029.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3748244018147065, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6251755981852936, \"precision\": 0.9994298095563918, \"recall\": 0.3748244018147065, \"specificity\": 0.9999999491686252, \"npv\": 0.9998514153758032, \"accuracy\": 0.9998513777993923, \"f1\": 0.5451839658530283, \"f2\": 0.4283670002654453, \"f0_5\": 0.7496029338810893, \"p4\": 0.7056372324382628, \"phi\": 0.6120089350532708}, {\"truth_threshold\": 9.05999979749322, \"match_probability\": 0.9981299406779027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113872.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190089.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37462700807011423, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6253729919298857, \"precision\": 0.9994295092902218, \"recall\": 0.37462700807011423, \"specificity\": 0.9999999491686252, \"npv\": 0.9998513684684766, \"accuracy\": 0.9998513308892739, \"f1\": 0.5449750896151693, \"f2\": 0.4281607272174892, \"f0_5\": 0.749444853226696, \"p4\": 0.705462244114437, \"phi\": 0.6118476564158744}, {\"truth_threshold\": 9.079999797046185, \"match_probability\": 0.9981556388523408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113777.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190184.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3743144679745099, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6256855320254902, \"precision\": 0.9994290332214824, \"recall\": 0.3743144679745099, \"specificity\": 0.9999999491686252, \"npv\": 0.9998512941985516, \"accuracy\": 0.9998512566149199, \"f1\": 0.5446442462117314, \"f2\": 0.42783409015361523, \"f0_5\": 0.7491943544892925, \"p4\": 0.7051849796483031, \"phi\": 0.6115922116253862}, {\"truth_threshold\": 9.09999979659915, \"match_probability\": 0.9981809845285239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113729.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190232.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3741565529788361, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6258434470211639, \"precision\": 0.9994287923792116, \"recall\": 0.3741565529788361, \"specificity\": 0.9999999491686252, \"npv\": 0.9998512566726989, \"accuracy\": 0.9998512190868253, \"f1\": 0.5444770260080669, \"f2\": 0.42766903472975354, \"f0_5\": 0.749067691338981, \"p4\": 0.705044794988636, \"phi\": 0.6114631042172589}, {\"truth_threshold\": 9.119999796152115, \"match_probability\": 0.9982059825240535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113689.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190272.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37402495714910794, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.625975042850892, \"precision\": 0.9994285915220563, \"recall\": 0.37402495714910794, \"specificity\": 0.9999999491686252, \"npv\": 0.9998512254011572, \"accuracy\": 0.999851187813413, \"f1\": 0.5443376464814527, \"f2\": 0.4275314794396502, \"f0_5\": 0.7489620897602958, \"p4\": 0.7049279266341926, \"phi\": 0.611355493890344}, {\"truth_threshold\": 9.13999979570508, \"match_probability\": 0.9982306375911687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113620.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37379795434282687, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6262020456571731, \"precision\": 0.9994282447112636, \"recall\": 0.37379795434282687, \"specificity\": 0.9999999491686252, \"npv\": 0.9998511714577524, \"accuracy\": 0.9998511338667769, \"f1\": 0.544097154049123, \"f2\": 0.4272941771108415, \"f0_5\": 0.7487798223542608, \"p4\": 0.704726226506325, \"phi\": 0.611169821560363}, {\"truth_threshold\": 9.159999795258045, \"match_probability\": 0.9982549544176195, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113555.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3735841111195186, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6264158888804814, \"precision\": 0.9994279176201373, \"recall\": 0.3735841111195186, \"specificity\": 0.9999999491686252, \"npv\": 0.9998511206415067, \"accuracy\": 0.999851083047482, \"f1\": 0.5438705305078536, \"f2\": 0.42707060890704823, \"f0_5\": 0.7486079998312327, \"p4\": 0.7045361006677197, \"phi\": 0.6109948612505808}, {\"truth_threshold\": 9.17999979481101, \"match_probability\": 0.9982789376275292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113496.0, \"tn\": 1278737727.0, \"fp\": 65.0, \"fn\": 190465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37339000727066957, \"tn_rate\": 0.9999999491686252, \"fp_rate\": 5.083137481870873e-08, \"fn_rate\": 0.6266099927293304, \"precision\": 0.9994276203978478, \"recall\": 0.37339000727066957, \"specificity\": 0.9999999491686252, \"npv\": 0.999851074515996, \"accuracy\": 0.999851036919199, \"f1\": 0.5436647649704687, \"f2\": 0.42686765883985694, \"f0_5\": 0.7484519358221061, \"p4\": 0.7043634253062746, \"phi\": 0.6108360077505218}, {\"truth_threshold\": 9.199999794363976, \"match_probability\": 0.9983025917822457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113444.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190517.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.373218932692023, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.626781067307977, \"precision\": 0.9994361630898263, \"recall\": 0.373218932692023, \"specificity\": 0.9999999499506463, \"npv\": 0.9998510338631235, \"accuracy\": 0.9998509970455984, \"f1\": 0.5434846659272904, \"f2\": 0.4266890936335899, \"f0_5\": 0.7483182562371948, \"p4\": 0.7042122511655791, \"phi\": 0.6106986581661245}, {\"truth_threshold\": 9.21999979391694, \"match_probability\": 0.9983259213811816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113380.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190581.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37300837936445796, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.626991620635542, \"precision\": 0.9994358449984133, \"recall\": 0.37300837936445796, \"specificity\": 0.9999999499506463, \"npv\": 0.99985098382868, \"accuracy\": 0.9998509470081388, \"f1\": 0.5432613409039183, \"f2\": 0.426468906662815, \"f0_5\": 0.7481487640170666, \"p4\": 0.704024744304373, \"phi\": 0.6105262570335388}, {\"truth_threshold\": 9.239999793469906, \"match_probability\": 0.9983489308626438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113329.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37284059468155456, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6271594053184455, \"precision\": 0.9994355912622472, \"recall\": 0.37284059468155456, \"specificity\": 0.9999999499506463, \"npv\": 0.9998509439574864, \"accuracy\": 0.9998509071345383, \"f1\": 0.5430833297392621, \"f2\": 0.4262934299902877, \"f0_5\": 0.7480136178885937, \"p4\": 0.7038752447351667, \"phi\": 0.6103888400314594}, {\"truth_threshold\": 9.259999793022871, \"match_probability\": 0.9983716246046509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113275.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190686.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37266294031142155, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6273370596885784, \"precision\": 0.9994353223515294, \"recall\": 0.37266294031142155, \"specificity\": 0.9999999499506463, \"npv\": 0.999850901740932, \"accuracy\": 0.9998508649154317, \"f1\": 0.5428947999041457, \"f2\": 0.4261076164832081, \"f0_5\": 0.7478704426283842, \"p4\": 0.7037168736346862, \"phi\": 0.6102433059603072}, {\"truth_threshold\": 9.279999792575836, \"match_probability\": 0.9983940069257424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113225.0, \"tn\": 1278737728.0, \"fp\": 64.0, \"fn\": 190736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3724984455242613, \"tn_rate\": 0.9999999499506463, \"fp_rate\": 5.004935366765167e-08, \"fn_rate\": 0.6275015544757386, \"precision\": 0.9994350731315486, \"recall\": 0.3724984455242613, \"specificity\": 0.9999999499506463, \"npv\": 0.999850862651533, \"accuracy\": 0.9998508258236665, \"f1\": 0.5427201917315758, \"f2\": 0.425935553477342, \"f0_5\": 0.7477378001022299, \"p4\": 0.7035701626556627, \"phi\": 0.6101085212483428}, {\"truth_threshold\": 9.299999792128801, \"match_probability\": 0.9984160820857753, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113153.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37226157303075064, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6277384269692493, \"precision\": 0.9994523693856822, \"recall\": 0.37226157303075064, \"specificity\": 0.9999999515146887, \"npv\": 0.999850806363037, \"accuracy\": 0.999850771095195, \"f1\": 0.5424712831035342, \"f2\": 0.42568840059019203, \"f0_5\": 0.7475545736706566, \"p4\": 0.7033609649302552, \"phi\": 0.6099197682378538}, {\"truth_threshold\": 9.319999791681767, \"match_probability\": 0.9984378542867104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113097.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190864.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37207733886913125, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6279226611308688, \"precision\": 0.999452098374853, \"recall\": 0.37207733886913125, \"specificity\": 0.9999999515146887, \"npv\": 0.9998507625829187, \"accuracy\": 0.999850727312418, \"f1\": 0.5422756041426927, \"f2\": 0.42549565350868285, \"f0_5\": 0.7474058184211674, \"p4\": 0.7031964571092445, \"phi\": 0.6097687272876224}, {\"truth_threshold\": 9.339999791234732, \"match_probability\": 0.9984593276733903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113028.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3718503360628502, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6281496639371499, \"precision\": 0.9994517640817049, \"recall\": 0.3718503360628502, \"specificity\": 0.9999999515146887, \"npv\": 0.9998507086395639, \"accuracy\": 0.9998506733657818, \"f1\": 0.5420344274441256, \"f2\": 0.4252581392303907, \"f0_5\": 0.7472224095324604, \"p4\": 0.702993641786663, \"phi\": 0.6095825718131624}, {\"truth_threshold\": 9.359999790787697, \"match_probability\": 0.9984805063343047, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112971.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 190990.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37166281200548756, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6283371879945124, \"precision\": 0.99945148761866, \"recall\": 0.37166281200548756, \"specificity\": 0.9999999515146887, \"npv\": 0.9998506640776665, \"accuracy\": 0.9998506288011694, \"f1\": 0.5418351343184794, \"f2\": 0.42506191317932357, \"f0_5\": 0.7470707968464196, \"p4\": 0.7028260001975656, \"phi\": 0.6094287483300366}, {\"truth_threshold\": 9.379999790340662, \"match_probability\": 0.9985013943023475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112926.0, \"tn\": 1278737730.0, \"fp\": 62.0, \"fn\": 191035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37151476669704336, \"tn_rate\": 0.9999999515146887, \"fp_rate\": 4.8485311365537555e-08, \"fn_rate\": 0.6284852333029566, \"precision\": 0.9994512691613269, \"recall\": 0.37151476669704336, \"specificity\": 0.9999999515146887, \"npv\": 0.999850628897224, \"accuracy\": 0.9998505936185806, \"f1\": 0.5416777591503997, \"f2\": 0.4249069859846843, \"f0_5\": 0.7469510380162796, \"p4\": 0.7026935885754436, \"phi\": 0.6093072813168011}, {\"truth_threshold\": 9.399999789893627, \"match_probability\": 0.9985219955555633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112883.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3713733011800856, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6286266988199144, \"precision\": 0.9994599093355999, \"recall\": 0.3713733011800856, \"specificity\": 0.9999999522967098, \"npv\": 0.9998505952804758, \"accuracy\": 0.9998505607814978, \"f1\": 0.5415286456147084, \"f2\": 0.42475925429790157, \"f0_5\": 0.746840501391357, \"p4\": 0.702568103208967, \"phi\": 0.6091938881282463}, {\"truth_threshold\": 9.419999789446592, \"match_probability\": 0.998542314017884, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112820.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37116603774826373, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6288339622517363, \"precision\": 0.9994596079056706, \"recall\": 0.37116603774826373, \"specificity\": 0.9999999522967098, \"npv\": 0.9998505460278638, \"accuracy\": 0.9998505115258736, \"f1\": 0.5413082175020751, \"f2\": 0.4245423244087377, \"f0_5\": 0.7466726672270131, \"p4\": 0.7023825590418366, \"phi\": 0.6090237619721707}, {\"truth_threshold\": 9.439999788999557, \"match_probability\": 0.9985623535598561, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112759.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191202.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3709653541079283, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6290346458920717, \"precision\": 0.9994593157241624, \"recall\": 0.3709653541079283, \"specificity\": 0.9999999522967098, \"npv\": 0.9998504983388314, \"accuracy\": 0.9998504638339198, \"f1\": 0.541094723607842, \"f2\": 0.4243322615800533, \"f0_5\": 0.7465100544064742, \"p4\": 0.7022028011227526, \"phi\": 0.6088589913658502}, {\"truth_threshold\": 9.459999788552523, \"match_probability\": 0.9985821179993586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112691.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191270.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37074164119739045, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6292583588026095, \"precision\": 0.999458989640982, \"recall\": 0.37074164119739045, \"specificity\": 0.9999999522967098, \"npv\": 0.9998504451772925, \"accuracy\": 0.9998504106691191, \"f1\": 0.5408566567397706, \"f2\": 0.42409807044428854, \"f0_5\": 0.7463286572031435, \"p4\": 0.7020022944784584, \"phi\": 0.6086752601003393}, {\"truth_threshold\": 9.479999788105488, \"match_probability\": 0.9986016111023109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112657.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191304.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37062978474212155, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6293702152578785, \"precision\": 0.9994588264518532, \"recall\": 0.37062978474212155, \"specificity\": 0.9999999522967098, \"npv\": 0.9998504185965251, \"accuracy\": 0.9998503840867187, \"f1\": 0.5407375941672127, \"f2\": 0.4239809658864246, \"f0_5\": 0.7462379095773503, \"p4\": 0.7019019933747378, \"phi\": 0.6085833736742678}, {\"truth_threshold\": 9.499999787658453, \"match_probability\": 0.998620836583372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112596.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191365.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37042910110178606, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6295708988982139, \"precision\": 0.9994585334244654, \"recall\": 0.37042910110178606, \"specificity\": 0.9999999522967098, \"npv\": 0.999850370907505, \"accuracy\": 0.9998503363947651, \"f1\": 0.5405239331953973, \"f2\": 0.42377085150857996, \"f0_5\": 0.7460750156707824, \"p4\": 0.7017219614910739, \"phi\": 0.608418483845108}, {\"truth_threshold\": 9.519999787211418, \"match_probability\": 0.99863979810663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112537.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.37023499725293707, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6297650027470629, \"precision\": 0.9994582497024814, \"recall\": 0.37023499725293707, \"specificity\": 0.9999999522967098, \"npv\": 0.9998503247820635, \"accuracy\": 0.999850290266482, \"f1\": 0.5403172179691232, \"f2\": 0.42356760776910096, \"f0_5\": 0.7459173622959012, \"p4\": 0.7015477346003428, \"phi\": 0.6082589577300239}, {\"truth_threshold\": 9.539999786764383, \"match_probability\": 0.9986584992862828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112473.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191488.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.370024443925372, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.629975556074628, \"precision\": 0.999457941599872, \"recall\": 0.370024443925372, \"specificity\": 0.9999999522967098, \"npv\": 0.9998502747476911, \"accuracy\": 0.9998502402290225, \"f1\": 0.5400929182823323, \"f2\": 0.42334711956988147, \"f0_5\": 0.7457462368899491, \"p4\": 0.7013586340053827, \"phi\": 0.6080858651488066}, {\"truth_threshold\": 9.559999786317348, \"match_probability\": 0.9986769436873105, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112421.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191540.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3698533693467254, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6301466306532746, \"precision\": 0.9994576910083391, \"recall\": 0.3698533693467254, \"specificity\": 0.9999999522967098, \"npv\": 0.9998502340947673, \"accuracy\": 0.9998501995735866, \"f1\": 0.5399106240229755, \"f2\": 0.4231679572635031, \"f0_5\": 0.7456071119223122, \"p4\": 0.7012049064009609, \"phi\": 0.607945191151302}, {\"truth_threshold\": 9.579999785870314, \"match_probability\": 0.9986951348261374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112350.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3696197867489579, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6303802132510421, \"precision\": 0.9994573484801309, \"recall\": 0.3696197867489579, \"specificity\": 0.9999999522967098, \"npv\": 0.9998501785878957, \"accuracy\": 0.9998501440632799, \"f1\": 0.5396616487179734, \"f2\": 0.4229233091537393, \"f0_5\": 0.7454170288148301, \"p4\": 0.700994888286525, \"phi\": 0.6077530644770585}, {\"truth_threshold\": 9.599999785423279, \"match_probability\": 0.9987130761712866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112307.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191654.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36947832123200014, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6305216787679998, \"precision\": 0.9994571408230101, \"recall\": 0.36947832123200014, \"specificity\": 0.9999999522967098, \"npv\": 0.9998501449710611, \"accuracy\": 0.9998501104443617, \"f1\": 0.539510819568178, \"f2\": 0.42277512927153194, \"f0_5\": 0.7453018383850986, \"p4\": 0.7008676263524617, \"phi\": 0.6076366765426974}, {\"truth_threshold\": 9.619999784976244, \"match_probability\": 0.998730771144026, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112230.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191731.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3692249992597735, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6307750007402265, \"precision\": 0.9994567685745073, \"recall\": 0.3692249992597735, \"specificity\": 0.9999999522967098, \"npv\": 0.9998500847734791, \"accuracy\": 0.9998500502430432, \"f1\": 0.5392406522971661, \"f2\": 0.4225097599265135, \"f0_5\": 0.7450954356846473, \"p4\": 0.7006396106673557, \"phi\": 0.6074282052370238}, {\"truth_threshold\": 9.63999978452921, \"match_probability\": 0.9987482231190045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112184.0, \"tn\": 1278737731.0, \"fp\": 61.0, \"fn\": 191777.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36907366405558606, \"tn_rate\": 0.9999999522967098, \"fp_rate\": 4.77032902144805e-08, \"fn_rate\": 0.6309263359444139, \"precision\": 0.9994565459485946, \"recall\": 0.36907366405558606, \"specificity\": 0.9999999522967098, \"npv\": 0.9998500488112907, \"accuracy\": 0.9998500142786191, \"f1\": 0.5390792059701206, \"f2\": 0.42235121290817107, \"f0_5\": 0.7449720496028241, \"p4\": 0.7005033150427667, \"phi\": 0.6073036298036832}, {\"truth_threshold\": 9.659999784082174, \"match_probability\": 0.9987654354248814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112154.0, \"tn\": 1278737732.0, \"fp\": 60.0, \"fn\": 191807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36897496718329, \"tn_rate\": 0.9999999530787309, \"fp_rate\": 4.692126906342344e-08, \"fn_rate\": 0.6310250328167101, \"precision\": 0.9994653073591531, \"recall\": 0.36897496718329, \"specificity\": 0.9999999530787309, \"npv\": 0.9998500253578082, \"accuracy\": 0.9998499916053952, \"f1\": 0.5389751907250556, \"f2\": 0.4222481247053969, \"f0_5\": 0.7448955058134978, \"p4\": 0.7004154885908721, \"phi\": 0.6072250778795748}, {\"truth_threshold\": 9.67999978363514, \"match_probability\": 0.9987824113449463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112082.0, \"tn\": 1278737732.0, \"fp\": 60.0, \"fn\": 191879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3687380946897793, \"tn_rate\": 0.9999999530787309, \"fp_rate\": 4.692126906342344e-08, \"fn_rate\": 0.6312619053102208, \"precision\": 0.9994649640634196, \"recall\": 0.3687380946897793, \"specificity\": 0.9999999530787309, \"npv\": 0.9998499690691734, \"accuracy\": 0.9998499353132532, \"f1\": 0.538722383640589, \"f2\": 0.42199993072216124, \"f0_5\": 0.7447021975232848, \"p4\": 0.700201978420953, \"phi\": 0.6070300137136809}, {\"truth_threshold\": 9.699999783188105, \"match_probability\": 0.9987991541177315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 112031.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 191930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3685703100068759, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6314296899931241, \"precision\": 0.9994825540418775, \"recall\": 0.3685703100068759, \"specificity\": 0.9999999546427732, \"npv\": 0.9998499291982956, \"accuracy\": 0.9998498970033233, \"f1\": 0.5385458478548252, \"f2\": 0.42182474567617495, \"f0_5\": 0.7445730988399837, \"p4\": 0.7000528422844478, \"phi\": 0.606897221793626}, {\"truth_threshold\": 9.71999978274107, \"match_probability\": 0.9988156669376159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111956.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192005.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36832356782613557, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6316764321738644, \"precision\": 0.9994822075811952, \"recall\": 0.36832356782613557, \"specificity\": 0.9999999546427732, \"npv\": 0.9998498705643125, \"accuracy\": 0.9998498383656753, \"f1\": 0.5382823486988401, \"f2\": 0.4215661614419614, \"f0_5\": 0.7443714703258038, \"p4\": 0.6998301762821746, \"phi\": 0.6066939188245818}, {\"truth_threshold\": 9.739999782294035, \"match_probability\": 0.9988319529554216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111907.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192054.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3681623629347186, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6318376370652814, \"precision\": 0.9994819809761979, \"recall\": 0.3681623629347186, \"specificity\": 0.9999999546427732, \"npv\": 0.9998498322567806, \"accuracy\": 0.9998498000557453, \"f1\": 0.5381101445930285, \"f2\": 0.42139720396532937, \"f0_5\": 0.7442396527896933, \"p4\": 0.6996846165745646, \"phi\": 0.6065610574284922}, {\"truth_threshold\": 9.759999781847, \"match_probability\": 0.9988480152790014, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111839.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36793865002418075, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6320613499758193, \"precision\": 0.9994816661751432, \"recall\": 0.36793865002418075, \"specificity\": 0.9999999546427732, \"npv\": 0.9998497790953126, \"accuracy\": 0.9998497468909445, \"f1\": 0.537871100231329, \"f2\": 0.4211627117035627, \"f0_5\": 0.7440566084180805, \"p4\": 0.6994825044896539, \"phi\": 0.6063766301339639}, {\"truth_threshold\": 9.779999781399965, \"match_probability\": 0.9988638569738193, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111774.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192187.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3677248068008725, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6322751931991275, \"precision\": 0.9994813649044996, \"recall\": 0.3677248068008725, \"specificity\": 0.9999999546427732, \"npv\": 0.9998497282792088, \"accuracy\": 0.9998496960716496, \"f1\": 0.5376425288545021, \"f2\": 0.42093854223470184, \"f0_5\": 0.7438815156351284, \"p4\": 0.6992891885530215, \"phi\": 0.6062002869054062}, {\"truth_threshold\": 9.79999978095293, \"match_probability\": 0.9988794810635239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111712.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192249.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36752083326479384, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6324791667352062, \"precision\": 0.9994810772121321, \"recall\": 0.36752083326479384, \"specificity\": 0.9999999546427732, \"npv\": 0.9998496798084685, \"accuracy\": 0.9998496475978607, \"f1\": 0.5374244403231897, \"f2\": 0.42072469859462164, \"f0_5\": 0.7437143910918312, \"p4\": 0.6991046849807306, \"phi\": 0.6060320347972347}, {\"truth_threshold\": 9.819999780505896, \"match_probability\": 0.998894890530513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111659.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36734646879040406, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.632653531209596, \"precision\": 0.9994808310284021, \"recall\": 0.36734646879040406, \"specificity\": 0.9999999546427732, \"npv\": 0.999849638373807, \"accuracy\": 0.9998496061605895, \"f1\": 0.5372379582272817, \"f2\": 0.42054188093805106, \"f0_5\": 0.7435714390360522, \"p4\": 0.6989468790357738, \"phi\": 0.6058881693536355}, {\"truth_threshold\": 9.83999978005886, \"match_probability\": 0.9989100883164911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111582.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36709314681817734, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6329068531818227, \"precision\": 0.9994804729487639, \"recall\": 0.36709314681817734, \"specificity\": 0.9999999546427732, \"npv\": 0.9998495781762862, \"accuracy\": 0.999849545959271, \"f1\": 0.5369669466627848, \"f2\": 0.42027625191716056, \"f0_5\": 0.7433636100788652, \"p4\": 0.6987174738256657, \"phi\": 0.6056790964286493}, {\"truth_threshold\": 9.859999779611826, \"match_probability\": 0.9989250773230202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111542.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192419.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3669615509884492, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6330384490115508, \"precision\": 0.9994802867383512, \"recall\": 0.3669615509884492, \"specificity\": 0.9999999546427732, \"npv\": 0.9998495469048496, \"accuracy\": 0.9998495146858587, \"f1\": 0.5368261217968, \"f2\": 0.42013825065313487, \"f0_5\": 0.743255579647663, \"p4\": 0.698598236795484, \"phi\": 0.6055704586387186}, {\"truth_threshold\": 9.879999779164791, \"match_probability\": 0.9989398604120622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111486.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36677731682682974, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6332226831731702, \"precision\": 0.9994800258194075, \"recall\": 0.36677731682682974, \"specificity\": 0.9999999546427732, \"npv\": 0.9998495031248418, \"accuracy\": 0.9998494709030816, \"f1\": 0.536628921432955, \"f2\": 0.41994503491066665, \"f0_5\": 0.7431042596219091, \"p4\": 0.6984312296597043, \"phi\": 0.6054183329939516}, {\"truth_threshold\": 9.899999778717756, \"match_probability\": 0.9989544404065152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111428.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192533.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3665865028737239, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.633413497126276, \"precision\": 0.999479755305599, \"recall\": 0.3665865028737239, \"specificity\": 0.9999999546427732, \"npv\": 0.9998494577812662, \"accuracy\": 0.9998494255566339, \"f1\": 0.5364246221539691, \"f2\": 0.4197449014186374, \"f0_5\": 0.7429474400090678, \"p4\": 0.6982581653120176, \"phi\": 0.6052607339967319}, {\"truth_threshold\": 9.919999778270721, \"match_probability\": 0.9989688200907413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111349.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192612.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3663266011100108, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6336733988899892, \"precision\": 0.9994793863940327, \"recall\": 0.3663266011100108, \"specificity\": 0.9999999546427732, \"npv\": 0.9998493960201957, \"accuracy\": 0.9998493637916447, \"f1\": 0.5361462606652414, \"f2\": 0.4194722776626275, \"f0_5\": 0.7427336847258964, \"p4\": 0.6980222879061801, \"phi\": 0.6050460072807916}, {\"truth_threshold\": 9.939999777823687, \"match_probability\": 0.9989830022110892, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111277.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192684.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36608972861650013, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6339102713834999, \"precision\": 0.9994790497148246, \"recall\": 0.36608972861650013, \"specificity\": 0.9999999546427732, \"npv\": 0.9998493397316319, \"accuracy\": 0.9998493074995027, \"f1\": 0.5358924718754816, \"f2\": 0.419223782172563, \"f0_5\": 0.7425387127469468, \"p4\": 0.6978071583638394, \"phi\": 0.604850240608742}, {\"truth_threshold\": 9.959999777376652, \"match_probability\": 0.9989969894764078, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111229.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192732.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36593181362082633, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6340681863791736, \"precision\": 0.9994788250199933, \"recall\": 0.36593181362082633, \"specificity\": 0.9999999546427732, \"npv\": 0.9998493022059262, \"accuracy\": 0.999849269971408, \"f1\": 0.5357232304550533, \"f2\": 0.4190581035331101, \"f0_5\": 0.7424086481406578, \"p4\": 0.6976636577105019, \"phi\": 0.604719694297558}, {\"truth_threshold\": 9.979999776929617, \"match_probability\": 0.9990107845585551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111148.0, \"tn\": 1278737734.0, \"fp\": 58.0, \"fn\": 192813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36566533206562685, \"tn_rate\": 0.9999999546427732, \"fp_rate\": 4.535722676130933e-08, \"fn_rate\": 0.6343346679343732, \"precision\": 0.9994784454076219, \"recall\": 0.36566533206562685, \"specificity\": 0.9999999546427732, \"npv\": 0.9998492388813042, \"accuracy\": 0.9998492066427482, \"f1\": 0.5354375468185092, \"f2\": 0.4187784936513319, \"f0_5\": 0.742189012867512, \"p4\": 0.6974213533553867, \"phi\": 0.6044993334910731}, {\"truth_threshold\": 9.999999776482582, \"match_probability\": 0.9990243900928982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111096.0, \"tn\": 1278737735.0, \"fp\": 57.0, \"fn\": 192865.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3654942574869802, \"tn_rate\": 0.9999999554247944, \"fp_rate\": 4.457520561025227e-08, \"fn_rate\": 0.6345057425130197, \"precision\": 0.9994871933281153, \"recall\": 0.3654942574869802, \"specificity\": 0.9999999554247944, \"npv\": 0.9998491982285825, \"accuracy\": 0.9998491667691477, \"f1\": 0.5352553756317542, \"f2\": 0.41859928846862504, \"f0_5\": 0.7420518773720132, \"p4\": 0.6972667967103703, \"phi\": 0.604360544597435}, {\"truth_threshold\": 10.019999776035547, \"match_probability\": 0.9990378086788084, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 111032.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 192929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3652837041594152, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6347162958405849, \"precision\": 0.9995048925616858, \"recall\": 0.3652837041594152, \"specificity\": 0.9999999569888367, \"npv\": 0.999849148194559, \"accuracy\": 0.9998491182953587, \"f1\": 0.5350320926736185, \"f2\": 0.41837895112858164, \"f0_5\": 0.7418860390560584, \"p4\": 0.6970773102662402, \"phi\": 0.6041917765004258}, {\"truth_threshold\": 10.039999775588512, \"match_probability\": 0.9990510428801486, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110950.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 193011.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3650139327084725, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6349860672915275, \"precision\": 0.9995045268231161, \"recall\": 0.3650139327084725, \"specificity\": 0.9999999569888367, \"npv\": 0.9998490840881714, \"accuracy\": 0.9998490541848637, \"f1\": 0.5347426054182752, \"f2\": 0.4180958044208497, \"f0_5\": 0.741663224065852, \"p4\": 0.6968315581017219, \"phi\": 0.6039684997595325}, {\"truth_threshold\": 10.059999775141478, \"match_probability\": 0.9990640952257547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110862.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 193099.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3647244218830705, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6352755781169295, \"precision\": 0.9995041337216116, \"recall\": 0.3647244218830705, \"specificity\": 0.9999999569888367, \"npv\": 0.9998490152910817, \"accuracy\": 0.9998489853833568, \"f1\": 0.5344318088691133, \"f2\": 0.4177919007266569, \"f0_5\": 0.7414238880514266, \"p4\": 0.6965676128005017, \"phi\": 0.6037287938696805}, {\"truth_threshold\": 10.079999774694443, \"match_probability\": 0.9990769682099103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110807.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 193154.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3645434776171943, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6354565223828057, \"precision\": 0.9995038877162599, \"recall\": 0.3645434776171943, \"specificity\": 0.9999999569888367, \"npv\": 0.9998489722929056, \"accuracy\": 0.999848942382415, \"f1\": 0.5342374940637332, \"f2\": 0.4176019404449818, \"f0_5\": 0.7412741885634238, \"p4\": 0.6964025357968063, \"phi\": 0.603578929363096}, {\"truth_threshold\": 10.099999774247408, \"match_probability\": 0.9990896642928159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110750.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 193211.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3643559535598317, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6356440464401684, \"precision\": 0.9995036325075584, \"recall\": 0.3643559535598317, \"specificity\": 0.9999999569888367, \"npv\": 0.9998489277311632, \"accuracy\": 0.9998488978178025, \"f1\": 0.5340360588862154, \"f2\": 0.417405055896473, \"f0_5\": 0.741118952435889, \"p4\": 0.6962313656548789, \"phi\": 0.6034235759770431}, {\"truth_threshold\": 10.119999773800373, \"match_probability\": 0.9991021859010499, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110713.0, \"tn\": 1278737737.0, \"fp\": 55.0, \"fn\": 193248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36423422741733313, \"tn_rate\": 0.9999999569888367, \"fp_rate\": 4.3011163308138155e-08, \"fn_rate\": 0.6357657725826669, \"precision\": 0.9995034667051856, \"recall\": 0.36423422741733313, \"specificity\": 0.9999999569888367, \"npv\": 0.999848898805122, \"accuracy\": 0.9998488688898962, \"f1\": 0.5339052730819402, \"f2\": 0.41727724458997806, \"f0_5\": 0.7410181344063783, \"p4\": 0.6961202059611392, \"phi\": 0.603322711147213}, {\"truth_threshold\": 10.139999773353338, \"match_probability\": 0.9991145354280261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110655.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193306.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3640434134642273, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6359565865357727, \"precision\": 0.9995573782338488, \"recall\": 0.3640434134642273, \"specificity\": 0.9999999616809636, \"npv\": 0.9998488534623104, \"accuracy\": 0.9998488282344603, \"f1\": 0.5337079329096982, \"f2\": 0.4170787638291264, \"f0_5\": 0.7408838247562526, \"p4\": 0.695952443730033, \"phi\": 0.6031809162496825}, {\"truth_threshold\": 10.159999772906303, \"match_probability\": 0.9991267152344423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110608.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193353.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3638887883642967, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6361112116357033, \"precision\": 0.9995571902364966, \"recall\": 0.3638887883642967, \"specificity\": 0.9999999616809636, \"npv\": 0.9998488167184263, \"accuracy\": 0.9998487914882009, \"f1\": 0.5335417179186625, \"f2\": 0.4169163837795825, \"f0_5\": 0.7407556232411675, \"p4\": 0.6958111077454833, \"phi\": 0.6030527362167852}, {\"truth_threshold\": 10.179999772459269, \"match_probability\": 0.9991387276487257, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110554.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193407.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3637111339941637, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6362888660058362, \"precision\": 0.9995569740422954, \"recall\": 0.3637111339941637, \"specificity\": 0.9999999616809636, \"npv\": 0.999848774502052, \"accuracy\": 0.9998487492690944, \"f1\": 0.5333507009774124, \"f2\": 0.4167298052617255, \"f0_5\": 0.740608248154743, \"p4\": 0.6956486443226441, \"phi\": 0.6029054319104161}, {\"truth_threshold\": 10.199999772012234, \"match_probability\": 0.9991505749674697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110513.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3635762482686924, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6364237517313076, \"precision\": 0.9995568097538033, \"recall\": 0.3635762482686924, \"specificity\": 0.9999999616809636, \"npv\": 0.9998487424488813, \"accuracy\": 0.9998487172138469, \"f1\": 0.5332056363579343, \"f2\": 0.4165881336483701, \"f0_5\": 0.7404962952738442, \"p4\": 0.6955252371533351, \"phi\": 0.6027935657192228}, {\"truth_threshold\": 10.219999771565199, \"match_probability\": 0.9991622594558669, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110461.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193500.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36340517369004577, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6365948263099542, \"precision\": 0.99955660121256, \"recall\": 0.36340517369004577, \"specificity\": 0.9999999616809636, \"npv\": 0.9998487017960824, \"accuracy\": 0.999848676558411, \"f1\": 0.5330216106796374, \"f2\": 0.41640843997907045, \"f0_5\": 0.7403542354500865, \"p4\": 0.695368652021848, \"phi\": 0.602651656788862}, {\"truth_threshold\": 10.239999771118164, \"match_probability\": 0.999173783348135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110385.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36315514161356227, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6368448583864378, \"precision\": 0.9995562960682398, \"recall\": 0.36315514161356227, \"specificity\": 0.9999999616809636, \"npv\": 0.9998486423804592, \"accuracy\": 0.9998486171389278, \"f1\": 0.5327525669952582, \"f2\": 0.41614578542356884, \"f0_5\": 0.7401464669966488, \"p4\": 0.6951396584802768, \"phi\": 0.6024441913201558}, {\"truth_threshold\": 10.25999977067113, \"match_probability\": 0.9991851488479381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110322.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3629478781817404, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6370521218182595, \"precision\": 0.9995560428010981, \"recall\": 0.3629478781817404, \"specificity\": 0.9999999616809636, \"npv\": 0.9998485931280401, \"accuracy\": 0.9998485678833035, \"f1\": 0.5325294691213809, \"f2\": 0.4159280358011333, \"f0_5\": 0.7399741094245719, \"p4\": 0.6949497102341585, \"phi\": 0.6022721592098151}, {\"truth_threshold\": 10.279999770224094, \"match_probability\": 0.9991963581288007, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110264.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3627570642286346, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6372429357713654, \"precision\": 0.9995558093787676, \"recall\": 0.3627570642286346, \"specificity\": 0.9999999616809636, \"npv\": 0.9998485477845473, \"accuracy\": 0.9998485225368557, \"f1\": 0.5323240174377345, \"f2\": 0.41572754960385533, \"f0_5\": 0.7398153279666351, \"p4\": 0.6947747372541915, \"phi\": 0.6021137370012896}, {\"truth_threshold\": 10.29999976977706, \"match_probability\": 0.9992074133345185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110200.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36254651090106954, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6374534890989304, \"precision\": 0.9995555515242769, \"recall\": 0.36254651090106954, \"specificity\": 0.9999999616809636, \"npv\": 0.9998484977503533, \"accuracy\": 0.9998484724993962, \"f1\": 0.5320972453586346, \"f2\": 0.4155063031024219, \"f0_5\": 0.7396400060674643, \"p4\": 0.6945815522765417, \"phi\": 0.6019388779176151}, {\"truth_threshold\": 10.319999769330025, \"match_probability\": 0.9992183165795613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110132.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3623227979905317, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6376772020094683, \"precision\": 0.999555277225656, \"recall\": 0.3623227979905317, \"specificity\": 0.9999999616809636, \"npv\": 0.9998484445890277, \"accuracy\": 0.9998484193345955, \"f1\": 0.5318562232277818, \"f2\": 0.41527120529401784, \"f0_5\": 0.7394535944728308, \"p4\": 0.6943761651221404, \"phi\": 0.6017530344866235}, {\"truth_threshold\": 10.33999976888299, \"match_probability\": 0.9992290699494722, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110072.0, \"tn\": 1278737743.0, \"fp\": 49.0, \"fn\": 193889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3621254042459394, \"tn_rate\": 0.9999999616809636, \"fp_rate\": 3.831903640179581e-08, \"fn_rate\": 0.6378745957540606, \"precision\": 0.9995550349161377, \"recall\": 0.3621254042459394, \"specificity\": 0.9999999616809636, \"npv\": 0.9998483976819802, \"accuracy\": 0.9998483724244771, \"f1\": 0.5316434909027681, \"f2\": 0.41506374602647883, \"f0_5\": 0.7392890005305967, \"p4\": 0.6941948314451482, \"phi\": 0.601589007328256}, {\"truth_threshold\": 10.359999768435955, \"match_probability\": 0.9992396755012607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 110012.0, \"tn\": 1278737744.0, \"fp\": 48.0, \"fn\": 193949.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3619280105013472, \"tn_rate\": 0.9999999624629847, \"fp_rate\": 3.7537015250738755e-08, \"fn_rate\": 0.6380719894986527, \"precision\": 0.9995638742504088, \"recall\": 0.3619280105013472, \"specificity\": 0.9999999624629847, \"npv\": 0.9998483507750558, \"accuracy\": 0.999848326296194, \"f1\": 0.5314319805034045, \"f2\": 0.41485658086859983, \"f0_5\": 0.7391282731412616, \"p4\": 0.6940144894627841, \"phi\": 0.6014276687676077}, {\"truth_threshold\": 10.37999976798892, \"match_probability\": 0.9992501352637905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109976.0, \"tn\": 1278737744.0, \"fp\": 48.0, \"fn\": 193985.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36180957425459187, \"tn_rate\": 0.9999999624629847, \"fp_rate\": 3.7537015250738755e-08, \"fn_rate\": 0.6381904257454081, \"precision\": 0.9995637315494801, \"recall\": 0.36180957425459187, \"specificity\": 0.9999999624629847, \"npv\": 0.9998483226308321, \"accuracy\": 0.999848298150123, \"f1\": 0.5313042743094557, \"f2\": 0.4147320849435992, \"f0_5\": 0.7390294023172956, \"p4\": 0.6939055780472371, \"phi\": 0.6013292046067116}, {\"truth_threshold\": 10.399999767541885, \"match_probability\": 0.9992604512381623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109939.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3616878481120933, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6383121518879067, \"precision\": 0.9996362942016203, \"recall\": 0.3616878481120933, \"specificity\": 0.999999968719154, \"npv\": 0.9998482937057751, \"accuracy\": 0.9998482754768991, \"f1\": 0.5311832632748708, \"f2\": 0.41460662546961397, \"f0_5\": 0.738959532288268, \"p4\": 0.6938023601703314, \"phi\": 0.6012498636646039}, {\"truth_threshold\": 10.41999976709485, \"match_probability\": 0.9992706253980917, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109878.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194083.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3614871644717579, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6385128355282421, \"precision\": 0.9996360923597591, \"recall\": 0.3614871644717579, \"specificity\": 0.999999968719154, \"npv\": 0.9998482460169583, \"accuracy\": 0.9998482277849455, \"f1\": 0.530966780145888, \"f2\": 0.4143956456739596, \"f0_5\": 0.7387918502809854, \"p4\": 0.6936176666147056, \"phi\": 0.6010829627838531}, {\"truth_threshold\": 10.439999766647816, \"match_probability\": 0.9992806596902816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109794.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194167.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36121081322932874, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6387891867706712, \"precision\": 0.9996358140466522, \"recall\": 0.36121081322932874, \"specificity\": 0.999999968719154, \"npv\": 0.9998481803471198, \"accuracy\": 0.9998481621107799, \"f1\": 0.5306685677690643, \"f2\": 0.41410508434174814, \"f0_5\": 0.7385607637323977, \"p4\": 0.6933631598442078, \"phi\": 0.6008530562125546}, {\"truth_threshold\": 10.45999976620078, \"match_probability\": 0.9992905560347891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109711.0, \"tn\": 1278737752.0, \"fp\": 40.0, \"fn\": 194250.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3609377518826428, \"tn_rate\": 0.999999968719154, \"fp_rate\": 3.1280846042282294e-08, \"fn_rate\": 0.6390622481173571, \"precision\": 0.9996355386283496, \"recall\": 0.3609377518826428, \"specificity\": 0.999999968719154, \"npv\": 0.9998481154590735, \"accuracy\": 0.9998480972184495, \"f1\": 0.530373786595506, \"f2\": 0.41381794590353765, \"f0_5\": 0.7383322229176341, \"p4\": 0.6931114839348305, \"phi\": 0.6006258002159658}, {\"truth_threshold\": 10.479999765753746, \"match_probability\": 0.9993003163253892, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109669.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3607995762614283, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6392004237385718, \"precision\": 0.999644510883436, \"recall\": 0.3607995762614283, \"specificity\": 0.9999999695011751, \"npv\": 0.9998480826242805, \"accuracy\": 0.9998480651632019, \"f1\": 0.5302258569049167, \"f2\": 0.41367294530882226, \"f0_5\": 0.738220473267788, \"p4\": 0.6929851492337632, \"phi\": 0.6005135083665233}, {\"truth_threshold\": 10.499999765306711, \"match_probability\": 0.9993099424299317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109611.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.36060876230832245, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6393912376916776, \"precision\": 0.9996443228454173, \"recall\": 0.36060876230832245, \"specificity\": 0.9999999695011751, \"npv\": 0.9998480372808345, \"accuracy\": 0.9998480198167542, \"f1\": 0.5300197528595709, \"f2\": 0.4134722601535729, \"f0_5\": 0.7380605768414985, \"p4\": 0.692809091746973, \"phi\": 0.6003546222345666}, {\"truth_threshold\": 10.519999764859676, \"match_probability\": 0.9993194361906943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109559.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194402.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3604376877296758, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6395623122703241, \"precision\": 0.9996441540904031, \"recall\": 0.3604376877296758, \"specificity\": 0.9999999695011751, \"npv\": 0.9998479966280932, \"accuracy\": 0.9998479791613183, \"f1\": 0.529834920773094, \"f2\": 0.41329232059946797, \"f0_5\": 0.7379171364566453, \"p4\": 0.6926511647782032, \"phi\": 0.6002121368529626}, {\"truth_threshold\": 10.539999764412642, \"match_probability\": 0.9993287994247311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109479.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194482.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3601744960702195, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6398255039297804, \"precision\": 0.9996438941543856, \"recall\": 0.3601744960702195, \"specificity\": 0.9999999695011751, \"npv\": 0.9998479340854208, \"accuracy\": 0.9998479166144938, \"f1\": 0.5295504729381662, \"f2\": 0.41301546294521796, \"f0_5\": 0.7376963019164916, \"p4\": 0.6924080480884484, \"phi\": 0.5999928625235874}, {\"truth_threshold\": 10.559999763965607, \"match_probability\": 0.9993380339242153, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109388.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194573.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.359875115557588, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.640124884442412, \"precision\": 0.9996435980151152, \"recall\": 0.359875115557588, \"specificity\": 0.9999999695011751, \"npv\": 0.9998478629431405, \"accuracy\": 0.999847845467481, \"f1\": 0.5292267796839772, \"f2\": 0.4127004967285936, \"f0_5\": 0.7374448709599565, \"p4\": 0.6921312784521322, \"phi\": 0.5997433405448198}, {\"truth_threshold\": 10.579999763518572, \"match_probability\": 0.9993471414567788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109312.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194649.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3596250834811045, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6403749165188956, \"precision\": 0.9996433503122971, \"recall\": 0.3596250834811045, \"specificity\": 0.9999999695011751, \"npv\": 0.9998478035276176, \"accuracy\": 0.9998477860479977, \"f1\": 0.5289563332301022, \"f2\": 0.412437414871019, \"f0_5\": 0.7372346954604008, \"p4\": 0.6918999469413026, \"phi\": 0.5995348690067985}, {\"truth_threshold\": 10.599999763071537, \"match_probability\": 0.9993561237658463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109264.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3594671684854307, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6405328315145693, \"precision\": 0.9996431936909326, \"recall\": 0.3594671684854307, \"specificity\": 0.9999999695011751, \"npv\": 0.9998477660020277, \"accuracy\": 0.9998477485199031, \"f1\": 0.5287854736923613, \"f2\": 0.41227124236028156, \"f0_5\": 0.737101864207142, \"p4\": 0.6917537568083464, \"phi\": 0.5994031654273393}, {\"truth_threshold\": 10.619999762624502, \"match_probability\": 0.9993649825709646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109189.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194772.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3592204263046904, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6407795736953096, \"precision\": 0.9996429486944739, \"recall\": 0.3592204263046904, \"specificity\": 0.9999999695011751, \"npv\": 0.9998477073682992, \"accuracy\": 0.9998476898822551, \"f1\": 0.528518426192372, \"f2\": 0.41201157371071156, \"f0_5\": 0.7368941775445994, \"p4\": 0.6915252012759178, \"phi\": 0.59919732065083}, {\"truth_threshold\": 10.639999762177467, \"match_probability\": 0.9993737195681286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109124.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194837.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35900658308138217, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6409934169186179, \"precision\": 0.9996427360918992, \"recall\": 0.35900658308138217, \"specificity\": 0.9999999695011751, \"npv\": 0.9998476565524067, \"accuracy\": 0.9998476390629603, \"f1\": 0.5282869065946302, \"f2\": 0.41178650376941406, \"f0_5\": 0.7367140463372909, \"p4\": 0.6913269880554562, \"phi\": 0.5990188646466978}, {\"truth_threshold\": 10.659999761730433, \"match_probability\": 0.9993823364301017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109077.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3588519579814516, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6411480420185485, \"precision\": 0.9996425822060926, \"recall\": 0.3588519579814516, \"specificity\": 0.9999999695011751, \"npv\": 0.9998476198086108, \"accuracy\": 0.9998476023167009, \"f1\": 0.5281194547263586, \"f2\": 0.4116237471319889, \"f0_5\": 0.7365837188101428, \"p4\": 0.6911835883646235, \"phi\": 0.598889794113221}, {\"truth_threshold\": 10.679999761283398, \"match_probability\": 0.9993908348067326, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 109022.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 194939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35867101371557536, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6413289862844247, \"precision\": 0.9996424019585369, \"recall\": 0.35867101371557536, \"specificity\": 0.9999999695011751, \"npv\": 0.9998475768105551, \"accuracy\": 0.9998475593157591, \"f1\": 0.527923452019505, \"f2\": 0.41143327257426004, \"f0_5\": 0.7364311238102959, \"p4\": 0.6910156988517705, \"phi\": 0.5987387188084626}, {\"truth_threshold\": 10.699999760836363, \"match_probability\": 0.999399216325268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108936.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35838808268165984, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6416119173183402, \"precision\": 0.9996421197522367, \"recall\": 0.35838808268165984, \"specificity\": 0.9999999695011751, \"npv\": 0.9998475095772391, \"accuracy\": 0.9998474920779228, \"f1\": 0.5276168704109111, \"f2\": 0.41113540793119663, \"f0_5\": 0.7361923388312129, \"p4\": 0.6907530046790686, \"phi\": 0.5985024155609855}, {\"truth_threshold\": 10.719999760389328, \"match_probability\": 0.99940748259066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108905.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3582860959136205, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6417139040863795, \"precision\": 0.9996420179174622, \"recall\": 0.3582860959136205, \"specificity\": 0.9999999695011751, \"npv\": 0.9998474853419762, \"accuracy\": 0.9998474678410283, \"f1\": 0.5275063271212507, \"f2\": 0.41102802863552507, \"f0_5\": 0.7361062107208373, \"p4\": 0.69065825989966, \"phi\": 0.5984172136112168}, {\"truth_threshold\": 10.739999759942293, \"match_probability\": 0.9994156351858707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108851.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195110.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3581084415434875, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6418915584565125, \"precision\": 0.9996418403893838, \"recall\": 0.3581084415434875, \"specificity\": 0.9999999695011751, \"npv\": 0.9998474431257147, \"accuracy\": 0.9998474256219219, \"f1\": 0.52731372819734, \"f2\": 0.41084096882845916, \"f0_5\": 0.7359561121320423, \"p4\": 0.6904931538676535, \"phi\": 0.5982687683439277}, {\"truth_threshold\": 10.759999759495258, \"match_probability\": 0.9994236756721719, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108804.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3579538164435569, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.642046183556443, \"precision\": 0.9996416857308233, \"recall\": 0.3579538164435569, \"specificity\": 0.9999999695011751, \"npv\": 0.9998474063819345, \"accuracy\": 0.9998473888756625, \"f1\": 0.5271460547862908, \"f2\": 0.4106781451014466, \"f0_5\": 0.7358253993802522, \"p4\": 0.6903493814044352, \"phi\": 0.5981395360049565}, {\"truth_threshold\": 10.779999759048223, \"match_probability\": 0.9994316055894407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108722.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3576840449926142, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6423159550073858, \"precision\": 0.9996414155809528, \"recall\": 0.3576840449926142, \"specificity\": 0.9999999695011751, \"npv\": 0.9998473422757711, \"accuracy\": 0.9998473247651674, \"f1\": 0.5268534267618397, \"f2\": 0.41039404199742563, \"f0_5\": 0.7355971881110412, \"p4\": 0.6900983903055631, \"phi\": 0.5979139999628742}, {\"truth_threshold\": 10.799999758601189, \"match_probability\": 0.9994394264564512, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108641.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195320.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35741756343741465, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6425824365625853, \"precision\": 0.9996411483253589, \"recall\": 0.35741756343741465, \"specificity\": 0.9999999695011751, \"npv\": 0.9998472789513982, \"accuracy\": 0.9998472614365076, \"f1\": 0.526564253188607, \"f2\": 0.4101133690291758, \"f0_5\": 0.7353715609309025, \"p4\": 0.6898502676211818, \"phi\": 0.5976911308342543}, {\"truth_threshold\": 10.819999758154154, \"match_probability\": 0.9994471397711634, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108558.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35714450209072873, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6428554979092712, \"precision\": 0.9996408740572944, \"recall\": 0.35714450209072873, \"specificity\": 0.9999999695011751, \"npv\": 0.999847214063469, \"accuracy\": 0.9998471965441772, \"f1\": 0.52626782173658, \"f2\": 0.40982573025147967, \"f0_5\": 0.7351401572968881, \"p4\": 0.6895958198038791, \"phi\": 0.5974626725530996}, {\"truth_threshold\": 10.839999757707119, \"match_probability\": 0.9994547470110056, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108479.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195482.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35688460032701563, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6431153996729844, \"precision\": 0.9996406126172617, \"recall\": 0.35688460032701563, \"specificity\": 0.9999999695011751, \"npv\": 0.9998471523026767, \"accuracy\": 0.9998471347791881, \"f1\": 0.5259855653257499, \"f2\": 0.40955192009435487, \"f0_5\": 0.7349197122621888, \"p4\": 0.6893534475478984, \"phi\": 0.5972451431631671}, {\"truth_threshold\": 10.859999757260084, \"match_probability\": 0.9994622496331557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108417.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195544.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.356680626790937, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.643319373209063, \"precision\": 0.9996404071697278, \"recall\": 0.356680626790937, \"specificity\": 0.9999999695011751, \"npv\": 0.9998471038321868, \"accuracy\": 0.9998470863053991, \"f1\": 0.5257639719022251, \"f2\": 0.4093370082307634, \"f0_5\": 0.7347465725109619, \"p4\": 0.6891631034863467, \"phi\": 0.5970743684087284}, {\"truth_threshold\": 10.87999975681305, \"match_probability\": 0.9994696490748174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108354.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35647336335911517, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6435266366408848, \"precision\": 0.9996401981677784, \"recall\": 0.35647336335911517, \"specificity\": 0.9999999695011751, \"npv\": 0.9998470545799196, \"accuracy\": 0.9998470370497748, \"f1\": 0.5255387361344864, \"f2\": 0.40911860943320566, \"f0_5\": 0.7345705209122846, \"p4\": 0.6889695740673273, \"phi\": 0.5969007891922637}, {\"truth_threshold\": 10.899999756366014, \"match_probability\": 0.9994769467534924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108240.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195721.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3560983152443899, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.64390168475561, \"precision\": 0.9996398193555537, \"recall\": 0.3560983152443899, \"specificity\": 0.9999999695011751, \"npv\": 0.9998469654567819, \"accuracy\": 0.9998469479205501, \"f1\": 0.5251309916553464, \"f2\": 0.40872335878162375, \"f0_5\": 0.7342516453504858, \"p4\": 0.6886190822279218, \"phi\": 0.5965865651332859}, {\"truth_threshold\": 10.91999975591898, \"match_probability\": 0.9994841440672497, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108151.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35580551452324477, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6441944854767553, \"precision\": 0.9996395230612811, \"recall\": 0.35580551452324477, \"specificity\": 0.9999999695011751, \"npv\": 0.9998468958782029, \"accuracy\": 0.9998468783372078, \"f1\": 0.5248125080371029, \"f2\": 0.40841473859432614, \"f0_5\": 0.7340024242555866, \"p4\": 0.6883451874907002, \"phi\": 0.5963411348100994}, {\"truth_threshold\": 10.939999755471945, \"match_probability\": 0.9994912423949907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108086.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3555916712999365, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6444083287000635, \"precision\": 0.9996393063583815, \"recall\": 0.3555916712999365, \"specificity\": 0.9999999695011751, \"npv\": 0.9998468450623929, \"accuracy\": 0.999846827517913, \"f1\": 0.5245798207170348, \"f2\": 0.408189315610864, \"f0_5\": 0.7338202566055773, \"p4\": 0.688145004918123, \"phi\": 0.5961618241230324}, {\"truth_threshold\": 10.95999975502491, \"match_probability\": 0.9994982430967109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 108028.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 195933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3554008573468307, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6445991426531693, \"precision\": 0.9996391127726318, \"recall\": 0.3554008573468307, \"specificity\": 0.9999999695011751, \"npv\": 0.9998467997190591, \"accuracy\": 0.9998467821714652, \"f1\": 0.5243721300494141, \"f2\": 0.4079881502608559, \"f0_5\": 0.7336575983831117, \"p4\": 0.6879662755331736, \"phi\": 0.5960017782880186}, {\"truth_threshold\": 10.979999754577875, \"match_probability\": 0.9995051475137581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107961.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.355180434332036, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.644819565667964, \"precision\": 0.9996388888888889, \"recall\": 0.355180434332036, \"specificity\": 0.9999999695011751, \"npv\": 0.9998467473396959, \"accuracy\": 0.9998467297884998, \"f1\": 0.5241321387218693, \"f2\": 0.40775574765606826, \"f0_5\": 0.733469572436583, \"p4\": 0.6877596889765926, \"phi\": 0.5958168442576651}, {\"truth_threshold\": 10.99999975413084, \"match_probability\": 0.9995119569690871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107864.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196097.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35486131444494523, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6451386855550547, \"precision\": 0.9996385642660538, \"recall\": 0.35486131444494523, \"specificity\": 0.9999999695011751, \"npv\": 0.9998466715068961, \"accuracy\": 0.9998466539504751, \"f1\": 0.523784550239885, \"f2\": 0.40741924249875544, \"f0_5\": 0.7331971129989817, \"p4\": 0.6874603665215141, \"phi\": 0.5955490022253247}, {\"truth_threshold\": 11.019999753683805, \"match_probability\": 0.9995186727675113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107792.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196169.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35462444195143455, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6453755580485654, \"precision\": 0.9996383229312535, \"recall\": 0.35462444195143455, \"specificity\": 0.9999999695011751, \"npv\": 0.9998466152186399, \"accuracy\": 0.9998465976583331, \"f1\": 0.5235264405330846, \"f2\": 0.40716943358452795, \"f0_5\": 0.7329946891341452, \"p4\": 0.6872380094923016, \"phi\": 0.5953501137542127}, {\"truth_threshold\": 11.03999975323677, \"match_probability\": 0.9995252961959493, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107744.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196217.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35446652695576075, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6455334730442392, \"precision\": 0.9996381618622603, \"recall\": 0.35446652695576075, \"specificity\": 0.9999999695011751, \"npv\": 0.9998465776931392, \"accuracy\": 0.9998465601302384, \"f1\": 0.5233543172456672, \"f2\": 0.4070028792099285, \"f0_5\": 0.7328596517719527, \"p4\": 0.6870896863967876, \"phi\": 0.59521748453181}, {\"truth_threshold\": 11.059999752789736, \"match_probability\": 0.9995318285236707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107678.0, \"tn\": 1278737753.0, \"fp\": 39.0, \"fn\": 196283.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35424939383670934, \"tn_rate\": 0.9999999695011751, \"fp_rate\": 3.0498824891225234e-08, \"fn_rate\": 0.6457506061632907, \"precision\": 0.9996379401580067, \"recall\": 0.35424939383670934, \"specificity\": 0.9999999695011751, \"npv\": 0.9998465260955804, \"accuracy\": 0.9998465085291082, \"f1\": 0.5231175821880207, \"f2\": 0.40677384721973525, \"f0_5\": 0.7326738601769935, \"p4\": 0.686885630910979, \"phi\": 0.5950350710978627}, {\"truth_threshold\": 11.079999752342701, \"match_probability\": 0.9995382710025367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107606.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196355.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35401252134319866, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6459874786568014, \"precision\": 0.9996655580535478, \"recall\": 0.35401252134319866, \"specificity\": 0.9999999718472385, \"npv\": 0.9998464698077006, \"accuracy\": 0.9998464545824721, \"f1\": 0.5228630500749508, \"f2\": 0.4065248895719335, \"f0_5\": 0.7324829925026786, \"p4\": 0.6866661645368615, \"phi\": 0.5948443031222459}, {\"truth_threshold\": 11.099999751895666, \"match_probability\": 0.9995446248672375, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107545.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3538118377028632, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6461881622971368, \"precision\": 0.9996653684200741, \"recall\": 0.3538118377028632, \"specificity\": 0.9999999718472385, \"npv\": 0.999846422119058, \"accuracy\": 0.9998464068905184, \"f1\": 0.5226441043684484, \"f2\": 0.4063131647052156, \"f0_5\": 0.7323110236488557, \"p4\": 0.6864773231409973, \"phi\": 0.5946756050800408}, {\"truth_threshold\": 11.119999751448631, \"match_probability\": 0.9995508913355277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107482.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196479.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35360457427104136, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6463954257289587, \"precision\": 0.9996651723432356, \"recall\": 0.35360457427104136, \"specificity\": 0.9999999718472385, \"npv\": 0.9998463728668582, \"accuracy\": 0.9998463576348942, \"f1\": 0.5224179119712064, \"f2\": 0.4060944775503604, \"f0_5\": 0.7321332964594235, \"p4\": 0.6862821744148254, \"phi\": 0.5945013257209741}, {\"truth_threshold\": 11.139999751001596, \"match_probability\": 0.9995570716084575, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107428.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196533.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35342691990090835, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6465730800990916, \"precision\": 0.9996650040943944, \"recall\": 0.35342691990090835, \"specificity\": 0.9999999718472385, \"npv\": 0.9998463306506907, \"accuracy\": 0.9998463154157877, \"f1\": 0.5222239776386948, \"f2\": 0.40590701484461666, \"f0_5\": 0.731980861713479, \"p4\": 0.6861148103369397, \"phi\": 0.5943519027529036}, {\"truth_threshold\": 11.159999750554562, \"match_probability\": 0.9995631668706008, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107333.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35311437980530397, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.646885620194696, \"precision\": 0.9996647076903017, \"recall\": 0.35311437980530397, \"specificity\": 0.9999999718472385, \"npv\": 0.9998462563815158, \"accuracy\": 0.9998462411414336, \"f1\": 0.5218826732793621, \"f2\": 0.4055771822072486, \"f0_5\": 0.7317124715551574, \"p4\": 0.6858201632998868, \"phi\": 0.5940889378265072}, {\"truth_threshold\": 11.179999750107527, \"match_probability\": 0.9995691782902804, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107273.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35291698606071176, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6470830139392882, \"precision\": 0.9996645202173163, \"recall\": 0.35291698606071176, \"specificity\": 0.9999999718472385, \"npv\": 0.9998462094746742, \"accuracy\": 0.9998461942313153, \"f1\": 0.5216670313905707, \"f2\": 0.40536884245434956, \"f0_5\": 0.7315428186421931, \"p4\": 0.6856339321702141, \"phi\": 0.5939227947462977}, {\"truth_threshold\": 11.199999749660492, \"match_probability\": 0.9995751070197908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107227.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196734.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35276565085652434, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6472343491434757, \"precision\": 0.9996643763459907, \"recall\": 0.35276565085652434, \"specificity\": 0.9999999718472385, \"npv\": 0.9998461735127653, \"accuracy\": 0.9998461582668913, \"f1\": 0.5215016633270432, \"f2\": 0.4052091025140068, \"f0_5\": 0.7314126761735468, \"p4\": 0.6854910824088793, \"phi\": 0.5937953869136274}, {\"truth_threshold\": 11.219999749213457, \"match_probability\": 0.9995809541956164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107180.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196781.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35261102575659375, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6473889742434062, \"precision\": 0.9996642292195195, \"recall\": 0.35261102575659375, \"specificity\": 0.9999999718472385, \"npv\": 0.9998461367690784, \"accuracy\": 0.9998461215206319, \"f1\": 0.5213326620895624, \"f2\": 0.4050458784937947, \"f0_5\": 0.7312796370211169, \"p4\": 0.6853450621234289, \"phi\": 0.5936651811135727}, {\"truth_threshold\": 11.239999748766422, \"match_probability\": 0.9995867209386486, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107087.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3523050654524758, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6476949345475241, \"precision\": 0.9996639377164568, \"recall\": 0.3523050654524758, \"specificity\": 0.9999999718472385, \"npv\": 0.9998460640634932, \"accuracy\": 0.9998460488099484, \"f1\": 0.520998141499061, \"f2\": 0.40472286912674316, \"f0_5\": 0.7310161880694052, \"p4\": 0.6850559342954867, \"phi\": 0.5934074556816108}, {\"truth_threshold\": 11.259999748319387, \"match_probability\": 0.9995924083543983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107026.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3521043818121404, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6478956181878597, \"precision\": 0.9996637462404961, \"recall\": 0.3521043818121404, \"specificity\": 0.9999999718472385, \"npv\": 0.9998460163748893, \"accuracy\": 0.9998460011179948, \"f1\": 0.5207786425577158, \"f2\": 0.4045109781042644, \"f0_5\": 0.7308432428445977, \"p4\": 0.6848661511527611, \"phi\": 0.5932383491834707}, {\"truth_threshold\": 11.279999747872353, \"match_probability\": 0.9995980175332065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106987.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 196974.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35197607587815544, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6480239241218446, \"precision\": 0.9996636237070536, \"recall\": 0.35197607587815544, \"specificity\": 0.9999999718472385, \"npv\": 0.9998459858854564, \"accuracy\": 0.9998459706264179, \"f1\": 0.5206382730227941, \"f2\": 0.40437549655407534, \"f0_5\": 0.7307326108901951, \"p4\": 0.6847447561473317, \"phi\": 0.5931302066561128}, {\"truth_threshold\": 11.299999747425318, \"match_probability\": 0.9996035495504519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106926.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35177539223782, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.64822460776218, \"precision\": 0.9996634318730017, \"recall\": 0.35177539223782, \"specificity\": 0.9999999718472385, \"npv\": 0.99984593819686, \"accuracy\": 0.9998459229344642, \"f1\": 0.5204186672442283, \"f2\": 0.40416357349452603, \"f0_5\": 0.7305594765847373, \"p4\": 0.684554790741106, \"phi\": 0.5929610211158513}, {\"truth_threshold\": 11.319999746978283, \"match_probability\": 0.9996090054667556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106832.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35146614203795884, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6485338579620412, \"precision\": 0.9996631358311188, \"recall\": 0.35146614203795884, \"specificity\": 0.9999999718472385, \"npv\": 0.9998458647095235, \"accuracy\": 0.9998458494419454, \"f1\": 0.5200801306626358, \"f2\": 0.4038369652653034, \"f0_5\": 0.7302924533074117, \"p4\": 0.6842618392068155, \"phi\": 0.592700214453561}, {\"truth_threshold\": 11.339999746531248, \"match_probability\": 0.9996143863281827, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106706.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3510516151743151, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6489483848256848, \"precision\": 0.9996627381911525, \"recall\": 0.3510516151743151, \"specificity\": 0.9999999718472385, \"npv\": 0.9998457662052384, \"accuracy\": 0.9998457509306969, \"f1\": 0.5196261045086108, \"f2\": 0.40339909843291855, \"f0_5\": 0.7299340975662478, \"p4\": 0.6838687442577918, \"phi\": 0.5923504424830731}, {\"truth_threshold\": 11.359999746084213, \"match_probability\": 0.9996196931664414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106673.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197288.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3509430486147894, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6490569513852106, \"precision\": 0.999662633892174, \"recall\": 0.3509430486147894, \"specificity\": 0.9999999718472385, \"npv\": 0.9998457404065003, \"accuracy\": 0.9998457251301318, \"f1\": 0.5195071468575742, \"f2\": 0.4032844052374461, \"f0_5\": 0.7298401608107313, \"p4\": 0.6837657121255112, \"phi\": 0.5922588014149456}, {\"truth_threshold\": 11.379999745637178, \"match_probability\": 0.9996249269990801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106594.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35068314685107627, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6493168531489237, \"precision\": 0.9996623839444809, \"recall\": 0.35068314685107627, \"specificity\": 0.9999999718472385, \"npv\": 0.9998456786458901, \"accuracy\": 0.9998456633651427, \"f1\": 0.5192222917696686, \"f2\": 0.4030098134254435, \"f0_5\": 0.7296151439941627, \"p4\": 0.6835189265931153, \"phi\": 0.5920393606453053}, {\"truth_threshold\": 11.399999745190144, \"match_probability\": 0.9996300888296803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106495.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197466.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3503574471724991, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6496425528275009, \"precision\": 0.99966207019553, \"recall\": 0.3503574471724991, \"specificity\": 0.9999999718472385, \"npv\": 0.9998456012496933, \"accuracy\": 0.9998455859634474, \"f1\": 0.5188651666780352, \"f2\": 0.40266565837980905, \"f0_5\": 0.7293328858968476, \"p4\": 0.6832093988490282, \"phi\": 0.5917642504054941}, {\"truth_threshold\": 11.419999744743109, \"match_probability\": 0.9996351796480484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106448.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197513.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.35020282207256853, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6497971779274315, \"precision\": 0.9996619210397806, \"recall\": 0.35020282207256853, \"specificity\": 0.9999999718472385, \"npv\": 0.9998455645060486, \"accuracy\": 0.999845549217188, \"f1\": 0.5186955621337817, \"f2\": 0.4025022536012245, \"f0_5\": 0.7291987773617373, \"p4\": 0.6830623480854178, \"phi\": 0.5916335977460294}, {\"truth_threshold\": 11.439999744296074, \"match_probability\": 0.9996402004304035, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106378.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34997252937054424, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6500274706294558, \"precision\": 0.999661698648674, \"recall\": 0.34997252937054424, \"specificity\": 0.9999999718472385, \"npv\": 0.9998455097814761, \"accuracy\": 0.9998454944887166, \"f1\": 0.5184428876028023, \"f2\": 0.4022588632475659, \"f0_5\": 0.7289989131283947, \"p4\": 0.682843212951246, \"phi\": 0.5914389551927599}, {\"truth_threshold\": 11.459999743849039, \"match_probability\": 0.9996451521395642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106336.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197625.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3498343537493297, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6501656462506703, \"precision\": 0.9996615650735156, \"recall\": 0.3498343537493297, \"specificity\": 0.9999999718472385, \"npv\": 0.9998454769467356, \"accuracy\": 0.9998454616516338, \"f1\": 0.5182912415038518, \"f2\": 0.40211281666535575, \"f0_5\": 0.7288789209389553, \"p4\": 0.6827116609643841, \"phi\": 0.591322138917676}, {\"truth_threshold\": 11.479999743402004, \"match_probability\": 0.9996500357251314, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106292.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3496895983366287, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6503104016633713, \"precision\": 0.9996614250244527, \"recall\": 0.3496895983366287, \"specificity\": 0.9999999718472385, \"npv\": 0.9998454425484383, \"accuracy\": 0.9998454272508803, \"f1\": 0.5181323408621727, \"f2\": 0.4019598055321093, \"f0_5\": 0.7287531555398321, \"p4\": 0.6825737875157183, \"phi\": 0.5911997352142402}, {\"truth_threshold\": 11.49999974295497, \"match_probability\": 0.9996548521236697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106208.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3494132470941996, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6505867529058004, \"precision\": 0.9996611573359436, \"recall\": 0.3494132470941996, \"specificity\": 0.9999999718472385, \"npv\": 0.9998453768789681, \"accuracy\": 0.9998453615767147, \"f1\": 0.5178288904328323, \"f2\": 0.4016676650873467, \"f0_5\": 0.7285128893169094, \"p4\": 0.682310412241946, \"phi\": 0.5909659850389302}, {\"truth_threshold\": 11.519999742507935, \"match_probability\": 0.9996596022588853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106132.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3491632150177161, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6508367849822839, \"precision\": 0.9996609147765805, \"recall\": 0.3491632150177161, \"specificity\": 0.9999999718472385, \"npv\": 0.9998453174637407, \"accuracy\": 0.9998453021572314, \"f1\": 0.5175542329364663, \"f2\": 0.40140331555235503, \"f0_5\": 0.72829531465086, \"p4\": 0.6820719365637158, \"phi\": 0.5907544171146027}, {\"truth_threshold\": 11.5399997420609, \"match_probability\": 0.9996642870418024, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106060.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 197901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3489263425242054, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6510736574757946, \"precision\": 0.9996606846629468, \"recall\": 0.3489263425242054, \"specificity\": 0.9999999718472385, \"npv\": 0.9998452611756371, \"accuracy\": 0.9998452458650895, \"f1\": 0.5172939371843427, \"f2\": 0.4011528511127585, \"f0_5\": 0.728089023745615, \"p4\": 0.6818458510216435, \"phi\": 0.5905539144513404}, {\"truth_threshold\": 11.559999741613865, \"match_probability\": 0.9996689073709372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105961.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 198000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3486006428456282, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6513993571543718, \"precision\": 0.999660367746257, \"recall\": 0.3486006428456282, \"specificity\": 0.9999999718472385, \"npv\": 0.9998451837795048, \"accuracy\": 0.9998451684633942, \"f1\": 0.5169358812366145, \"f2\": 0.4008084179564713, \"f0_5\": 0.7278051072259183, \"p4\": 0.6815347269761397, \"phi\": 0.5902781121224244}, {\"truth_threshold\": 11.57999974116683, \"match_probability\": 0.9996734641324683, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105874.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 198087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3483144219159695, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6516855780840305, \"precision\": 0.999660088754603, \"recall\": 0.3483144219159695, \"specificity\": 0.9999999718472385, \"npv\": 0.9998451157647319, \"accuracy\": 0.9998451004437225, \"f1\": 0.5166210832188665, \"f2\": 0.40050569167938965, \"f0_5\": 0.7275553497040274, \"p4\": 0.6812610695206651, \"phi\": 0.5900356339877477}, {\"truth_threshold\": 11.599999740719795, \"match_probability\": 0.9996779582004064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105810.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 198151.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3481038685884044, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6518961314115955, \"precision\": 0.9996598832265745, \"recall\": 0.3481038685884044, \"specificity\": 0.9999999718472385, \"npv\": 0.9998450657308818, \"accuracy\": 0.999845050406263, \"f1\": 0.5163894223378322, \"f2\": 0.4002829710446474, \"f0_5\": 0.7273714674604211, \"p4\": 0.681059611548364, \"phi\": 0.5898571956554585}, {\"truth_threshold\": 11.61999974027276, \"match_probability\": 0.9996823904367605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105757.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 198204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34792950411401463, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6520704958859854, \"precision\": 0.9996597128354427, \"recall\": 0.34792950411401463, \"specificity\": 0.9999999718472385, \"npv\": 0.9998450242966036, \"accuracy\": 0.9998450089689918, \"f1\": 0.516197523392084, \"f2\": 0.400098514191113, \"f0_5\": 0.7272190919680444, \"p4\": 0.6808926849146988, \"phi\": 0.5897093855545653}, {\"truth_threshold\": 11.639999739825726, \"match_probability\": 0.9996867616917028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105666.0, \"tn\": 1278737756.0, \"fp\": 36.0, \"fn\": 198295.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34763012360138307, \"tn_rate\": 0.9999999718472385, \"fp_rate\": 2.8152761438054064e-08, \"fn_rate\": 0.6523698763986169, \"precision\": 0.9996594198785265, \"recall\": 0.34763012360138307, \"specificity\": 0.9999999718472385, \"npv\": 0.9998449531547375, \"accuracy\": 0.999844937821979, \"f1\": 0.5158679207055555, \"f2\": 0.3997817707442647, \"f0_5\": 0.7269572587713565, \"p4\": 0.6806058756635519, \"phi\": 0.589455511975983}, {\"truth_threshold\": 11.65999973937869, \"match_probability\": 0.9996910728037302, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105613.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198348.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3474557591269933, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6525442408730068, \"precision\": 0.9996687111918825, \"recall\": 0.3474557591269933, \"specificity\": 0.9999999726292597, \"npv\": 0.9998449117205899, \"accuracy\": 0.9998448971665431, \"f1\": 0.5156771457658401, \"f2\": 0.39959757607310525, \"f0_5\": 0.7268086430033321, \"p4\": 0.6804398127526757, \"phi\": 0.5893103912620212}, {\"truth_threshold\": 11.679999738931656, \"match_probability\": 0.9996953245998244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105567.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198394.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34730442392280586, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6526955760771941, \"precision\": 0.9996685668832029, \"recall\": 0.34730442392280586, \"specificity\": 0.9999999726292597, \"npv\": 0.9998448757587743, \"accuracy\": 0.999844861202119, \"f1\": 0.5155104342921601, \"f2\": 0.3994374344468105, \"f0_5\": 0.72667611090231, \"p4\": 0.6802946619686955, \"phi\": 0.589181986352646}, {\"truth_threshold\": 11.699999738484621, \"match_probability\": 0.99969951789561, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105507.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34710703017821365, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6528929698217864, \"precision\": 0.999668378465445, \"recall\": 0.34710703017821365, \"specificity\": 0.9999999726292597, \"npv\": 0.9998448288520623, \"accuracy\": 0.9998448142920007, \"f1\": 0.5152929282569358, \"f2\": 0.3992285373085533, \"f0_5\": 0.7265031420036936, \"p4\": 0.680105237839242, \"phi\": 0.5890144596344513}, {\"truth_threshold\": 11.719999738037586, \"match_probability\": 0.9997036534955098, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105466.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34697214445274227, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6530278555472577, \"precision\": 0.9996682495900513, \"recall\": 0.34697214445274227, \"specificity\": 0.9999999726292597, \"npv\": 0.999844796799145, \"accuracy\": 0.9998447822367531, \"f1\": 0.5151442624712428, \"f2\": 0.39908578001960127, \"f0_5\": 0.7263848808138134, \"p4\": 0.679975734802816, \"phi\": 0.588899955643351}, {\"truth_threshold\": 11.739999737590551, \"match_probability\": 0.9997077321928985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105382.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3466957932103132, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6533042067896868, \"precision\": 0.9996679852395723, \"recall\": 0.3466957932103132, \"specificity\": 0.9999999726292597, \"npv\": 0.9998447311297597, \"accuracy\": 0.9998447165625874, \"f1\": 0.5148395859083781, \"f2\": 0.3987932740011247, \"f0_5\": 0.7261424226429759, \"p4\": 0.679710251076966, \"phi\": 0.5886652925628089}, {\"truth_threshold\": 11.759999737143517, \"match_probability\": 0.9997117547702536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105300.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198661.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34642602175937043, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6535739782406296, \"precision\": 0.9996677267764751, \"recall\": 0.34642602175937043, \"specificity\": 0.9999999726292597, \"npv\": 0.9998446670239396, \"accuracy\": 0.9998446524520924, \"f1\": 0.5145420429224815, \"f2\": 0.39850769653468604, \"f0_5\": 0.725905520604549, \"p4\": 0.6794508802032345, \"phi\": 0.5884361264623958}, {\"truth_threshold\": 11.779999736696482, \"match_probability\": 0.9997157219993051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105228.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198733.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34618914926585975, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6538108507341402, \"precision\": 0.9996674995012492, \"recall\": 0.34618914926585975, \"specificity\": 0.9999999726292597, \"npv\": 0.9998446107359091, \"accuracy\": 0.9998445961599504, \"f1\": 0.5142806873497155, \"f2\": 0.3982569163587809, \"f0_5\": 0.7256973323236963, \"p4\": 0.6792229701428416, \"phi\": 0.5882348338602023}, {\"truth_threshold\": 11.799999736249447, \"match_probability\": 0.999719634641183, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105177.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34602136458295635, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6539786354170436, \"precision\": 0.9996673383264266, \"recall\": 0.34602136458295635, \"specificity\": 0.9999999726292597, \"npv\": 0.9998445708652248, \"accuracy\": 0.9998445562863498, \"f1\": 0.514095504835363, \"f2\": 0.39807926386163794, \"f0_5\": 0.7255497655244347, \"p4\": 0.6790614377016471, \"phi\": 0.5880922099280267}, {\"truth_threshold\": 11.819999735802412, \"match_probability\": 0.9997234934465619, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105149.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34592924750214665, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.6540707524978533, \"precision\": 0.9996672497718284, \"recall\": 0.34592924750214665, \"specificity\": 0.9999999726292597, \"npv\": 0.9998445489754386, \"accuracy\": 0.9998445343949612, \"f1\": 0.5139938163731684, \"f2\": 0.3979817233245624, \"f0_5\": 0.7254687131311431, \"p4\": 0.6789727192952525, \"phi\": 0.5880138918875824}, {\"truth_threshold\": 11.839999735355377, \"match_probability\": 0.9997272991558049, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105087.0, \"tn\": 1278737757.0, \"fp\": 35.0, \"fn\": 198874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.345725273966068, \"tn_rate\": 0.9999999726292597, \"fp_rate\": 2.7370740286997008e-08, \"fn_rate\": 0.654274726033932, \"precision\": 0.9996670535187687, \"recall\": 0.345725273966068, \"specificity\": 0.9999999726292597, \"npv\": 0.9998445005052014, \"accuracy\": 0.9998444859211723, \"f1\": 0.5137685995262575, \"f2\": 0.39776572599143356, \"f0_5\": 0.7252891507890825, \"p4\": 0.6787761857477947, \"phi\": 0.5878404362493416}, {\"truth_threshold\": 11.859999734908342, \"match_probability\": 0.9997310524991047, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105036.0, \"tn\": 1278737759.0, \"fp\": 33.0, \"fn\": 198925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3455574892831646, \"tn_rate\": 0.999999974193302, \"fp_rate\": 2.5806697984882894e-08, \"fn_rate\": 0.6544425107168353, \"precision\": 0.9996859206806955, \"recall\": 0.3455574892831646, \"specificity\": 0.999999974193302, \"npv\": 0.999844460634769, \"accuracy\": 0.9998444476112422, \"f1\": 0.5135858005525267, \"f2\": 0.39758863755599344, \"f0_5\": 0.7251493640893796, \"p4\": 0.6786166249149092, \"phi\": 0.5877033122546081}, {\"truth_threshold\": 11.879999734461308, \"match_probability\": 0.9997347541966228, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104962.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 198999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34531403699816754, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6546859630018325, \"precision\": 0.999695220679277, \"recall\": 0.34531403699816754, \"specificity\": 0.9999999749753231, \"npv\": 0.999844402783328, \"accuracy\": 0.9998443905372649, \"f1\": 0.5133180912325317, \"f2\": 0.3973310882939467, \"f0_5\": 0.7249387722964844, \"p4\": 0.6783828782101721, \"phi\": 0.5874989680878974}, {\"truth_threshold\": 11.899999734014273, \"match_probability\": 0.9997384049586276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104868.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199093.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3450047867983064, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6549952132016936, \"precision\": 0.9996949475691135, \"recall\": 0.3450047867983064, \"specificity\": 0.9999999749753231, \"npv\": 0.9998443292962174, \"accuracy\": 0.9998443170447462, \"f1\": 0.5129762926764841, \"f2\": 0.39700350711417204, \"f0_5\": 0.7246659231218929, \"p4\": 0.6780843212220458, \"phi\": 0.5872357363940902}, {\"truth_threshold\": 11.919999733567238, \"match_probability\": 0.9997420054856294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104773.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199188.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.344692246702702, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.655307753297298, \"precision\": 0.9996946710557703, \"recall\": 0.344692246702702, \"specificity\": 0.9999999749753231, \"npv\": 0.9998442550273401, \"accuracy\": 0.9998442427703922, \"f1\": 0.5126306982478973, \"f2\": 0.3966723936488802, \"f0_5\": 0.7243898830306659, \"p4\": 0.6777823114185221, \"phi\": 0.5869695844635007}, {\"truth_threshold\": 11.939999733120203, \"match_probability\": 0.9997455564685144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104728.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34454420139425784, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6554557986057422, \"precision\": 0.9996945399007254, \"recall\": 0.34454420139425784, \"specificity\": 0.9999999749753231, \"npv\": 0.9998442198473494, \"accuracy\": 0.9998442075878035, \"f1\": 0.5124669395504513, \"f2\": 0.3965155338012001, \"f0_5\": 0.724259025921126, \"p4\": 0.6776391569531912, \"phi\": 0.5868434703793448}, {\"truth_threshold\": 11.959999732673168, \"match_probability\": 0.9997490585886768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104658.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34431390869223355, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6556860913077664, \"precision\": 0.999694335657656, \"recall\": 0.34431390869223355, \"specificity\": 0.9999999749753231, \"npv\": 0.9998441651229244, \"accuracy\": 0.999844152859332, \"f1\": 0.5122121321127319, \"f2\": 0.3962715083443516, \"f0_5\": 0.7240553408576754, \"p4\": 0.6774163479155376, \"phi\": 0.586647239044904}, {\"truth_threshold\": 11.979999732226133, \"match_probability\": 0.9997525125181488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104592.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199369.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3440967755731821, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6559032244268179, \"precision\": 0.9996941428352959, \"recall\": 0.3440967755731821, \"specificity\": 0.9999999749753231, \"npv\": 0.9998441135256149, \"accuracy\": 0.9998441012582019, \"f1\": 0.511971805132347, \"f2\": 0.3960414035023946, \"f0_5\": 0.7238631503328226, \"p4\": 0.6772061320872954, \"phi\": 0.5864621608106599}, {\"truth_threshold\": 11.999999731779099, \"match_probability\": 0.9997559189197288, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104512.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199449.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34383358391372576, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6561664160862742, \"precision\": 0.9996939087848179, \"recall\": 0.34383358391372576, \"specificity\": 0.9999999749753231, \"npv\": 0.9998440509834287, \"accuracy\": 0.9998440387113774, \"f1\": 0.5116803955887933, \"f2\": 0.39576245770182705, \"f0_5\": 0.7236300037250549, \"p4\": 0.6769511443039253, \"phi\": 0.5862377452465981}, {\"truth_threshold\": 12.019999731332064, \"match_probability\": 0.9997592784471085, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104438.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199523.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3435901316287287, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6564098683712714, \"precision\": 0.9996936919689863, \"recall\": 0.3435901316287287, \"specificity\": 0.9999999749753231, \"npv\": 0.9998439931319134, \"accuracy\": 0.9998439808555648, \"f1\": 0.511410740125015, \"f2\": 0.3955044027405602, \"f0_5\": 0.7234141590738127, \"p4\": 0.6767151040911357, \"phi\": 0.5860300843630686}, {\"truth_threshold\": 12.039999730885029, \"match_probability\": 0.9997625917449974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104391.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199570.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3434355065287981, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6565644934712019, \"precision\": 0.9996935541020656, \"recall\": 0.3434355065287981, \"specificity\": 0.9999999749753231, \"npv\": 0.9998439563883869, \"accuracy\": 0.9998439441093054, \"f1\": 0.5112394217207334, \"f2\": 0.39534048794675625, \"f0_5\": 0.723276976607871, \"p4\": 0.6765650984864127, \"phi\": 0.5858981534334438}, {\"truth_threshold\": 12.059999730437994, \"match_probability\": 0.9997658594492459, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104274.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34305058872684324, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6569494112731568, \"precision\": 0.99969321036182, \"recall\": 0.34305058872684324, \"specificity\": 0.9999999749753231, \"npv\": 0.999843864920471, \"accuracy\": 0.9998438526345746, \"f1\": 0.5108127769327425, \"f2\": 0.3949323940461311, \"f0_5\": 0.7229351692006906, \"p4\": 0.6761913824403067, \"phi\": 0.5855696005743508}, {\"truth_threshold\": 12.07999972999096, \"match_probability\": 0.9997690821869673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104216.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199745.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3428597747737374, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6571402252262626, \"precision\": 0.9996930396746221, \"recall\": 0.3428597747737374, \"specificity\": 0.9999999749753231, \"npv\": 0.9998438195774078, \"accuracy\": 0.9998438072881269, \"f1\": 0.5106011871369813, \"f2\": 0.39473006426824797, \"f0_5\": 0.7227655616940355, \"p4\": 0.6760059637745989, \"phi\": 0.5854066598768013}, {\"truth_threshold\": 12.099999729543924, \"match_probability\": 0.9997722605766569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104133.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199828.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3425867134270515, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6574132865729485, \"precision\": 0.9996927950847213, \"recall\": 0.3425867134270515, \"specificity\": 0.9999999749753231, \"npv\": 0.9998437546899278, \"accuracy\": 0.9998437423957965, \"f1\": 0.5102982902338984, \"f2\": 0.39444049245118784, \"f0_5\": 0.722522657541204, \"p4\": 0.6757404411901842, \"phi\": 0.5851734072259541}, {\"truth_threshold\": 12.11999972909689, \"match_probability\": 0.999775395228311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 104061.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3423498409335408, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6576501590664592, \"precision\": 0.9996925825944107, \"recall\": 0.3423498409335408, \"specificity\": 0.9999999749753231, \"npv\": 0.9998436984020003, \"accuracy\": 0.9998436861036545, \"f1\": 0.5100354364863474, \"f2\": 0.3941892681241605, \"f0_5\": 0.7223117641424175, \"p4\": 0.6755099345339756, \"phi\": 0.5849709922665841}, {\"truth_threshold\": 12.139999728649855, \"match_probability\": 0.9997784867435432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103983.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 199978.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34209322906557094, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6579067709344291, \"precision\": 0.999692352064606, \"recall\": 0.34209322906557094, \"specificity\": 0.9999999749753231, \"npv\": 0.9998436374234193, \"accuracy\": 0.9998436251205006, \"f1\": 0.5097505735631508, \"f2\": 0.3939170775060063, \"f0_5\": 0.7220831059094109, \"p4\": 0.675260036560794, \"phi\": 0.5847516303509926}, {\"truth_threshold\": 12.15999972820282, \"match_probability\": 0.9997815357156987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103909.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200052.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3418497767805738, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6581502232194262, \"precision\": 0.9996921330370114, \"recall\": 0.3418497767805738, \"specificity\": 0.9999999749753231, \"npv\": 0.9998435795719518, \"accuracy\": 0.999843567264688, \"f1\": 0.5094802182877259, \"f2\": 0.39365881564042626, \"f0_5\": 0.7218659904824759, \"p4\": 0.6750227782955939, \"phi\": 0.5845434416931967}, {\"truth_threshold\": 12.179999727755785, \"match_probability\": 0.9997845427299689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103836.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3416096143913199, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.65839038560868, \"precision\": 0.9996919166634575, \"recall\": 0.3416096143913199, \"specificity\": 0.9999999749753231, \"npv\": 0.9998435225022676, \"accuracy\": 0.9998435101907107, \"f1\": 0.5092134203305797, \"f2\": 0.3934040154215465, \"f0_5\": 0.7216516339951045, \"p4\": 0.674788558536743, \"phi\": 0.5843379937423294}, {\"truth_threshold\": 12.19999972730875, \"match_probability\": 0.9997875083635023, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103741.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34129707429571554, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6587029257042845, \"precision\": 0.999691634625577, \"recall\": 0.34129707429571554, \"specificity\": 0.9999999749753231, \"npv\": 0.9998434482335101, \"accuracy\": 0.9998434359163567, \"f1\": 0.5088660744504996, \"f2\": 0.3930723838810806, \"f0_5\": 0.7213724162196667, \"p4\": 0.6744835023102925, \"phi\": 0.5840705217888416}, {\"truth_threshold\": 12.219999726861715, \"match_probability\": 0.9997904331855156, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103677.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200284.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3410865209681505, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6589134790318495, \"precision\": 0.9996914443298074, \"recall\": 0.3410865209681505, \"specificity\": 0.9999999749753231, \"npv\": 0.9998433981998271, \"accuracy\": 0.9998433858788971, \"f1\": 0.5086319817499448, \"f2\": 0.3928489420280959, \"f0_5\": 0.721184145175898, \"p4\": 0.6742778313655843, \"phi\": 0.5838902611037838}, {\"truth_threshold\": 12.23999972641468, \"match_probability\": 0.9997933177574019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103607.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200354.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34085622826612627, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6591437717338737, \"precision\": 0.9996912359247001, \"recall\": 0.34085622826612627, \"specificity\": 0.9999999749753231, \"npv\": 0.9998433434754921, \"accuracy\": 0.9998433311504257, \"f1\": 0.5083758586849852, \"f2\": 0.3926045276824332, \"f0_5\": 0.7209780701082925, \"p4\": 0.6740527316913637, \"phi\": 0.5836930372575028}, {\"truth_threshold\": 12.259999725967646, \"match_probability\": 0.9997961626328384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103527.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200434.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.34059303660666995, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.65940696339333, \"precision\": 0.9996909974024469, \"recall\": 0.34059303660666995, \"specificity\": 0.9999999749753231, \"npv\": 0.9998432809334021, \"accuracy\": 0.9998432686036013, \"f1\": 0.508083038869258, \"f2\": 0.39232516524519045, \"f0_5\": 0.7207423589906391, \"p4\": 0.6737952865641998, \"phi\": 0.5834675569711147}, {\"truth_threshold\": 12.27999972552061, \"match_probability\": 0.9997989683578922, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103469.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200492.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3404022226535641, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6595977773464359, \"precision\": 0.9996908242432441, \"recall\": 0.3404022226535641, \"specificity\": 0.9999999749753231, \"npv\": 0.9998432355903919, \"accuracy\": 0.9998432232571535, \"f1\": 0.5078706726025985, \"f2\": 0.39212260629327433, \"f0_5\": 0.7205713370428921, \"p4\": 0.6736085130855328, \"phi\": 0.5833040292782945}, {\"truth_threshold\": 12.299999725073576, \"match_probability\": 0.9998017354711247, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103385.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.340125871411135, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6598741285888651, \"precision\": 0.9996905731166056, \"recall\": 0.340125871411135, \"specificity\": 0.9999999749753231, \"npv\": 0.9998431699212119, \"accuracy\": 0.9998431575829878, \"f1\": 0.5075630004565784, \"f2\": 0.3918292134763326, \"f0_5\": 0.7203234540410156, \"p4\": 0.6733378259448061, \"phi\": 0.5830671147840206}, {\"truth_threshold\": 12.319999724626541, \"match_probability\": 0.9998044645036945, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103325.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200636.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33992847766654277, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6600715223334572, \"precision\": 0.9996903934905231, \"recall\": 0.33992847766654277, \"specificity\": 0.9999999749753231, \"npv\": 0.99984312301466, \"accuracy\": 0.9998431106728695, \"f1\": 0.5073431569437148, \"f2\": 0.39161962430289243, \"f0_5\": 0.7201462525909932, \"p4\": 0.6731443419512615, \"phi\": 0.5828978312099727}, {\"truth_threshold\": 12.339999724179506, \"match_probability\": 0.9998071559794593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103231.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200730.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3396192274666816, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6603807725333184, \"precision\": 0.9996901116566437, \"recall\": 0.3396192274666816, \"specificity\": 0.9999999749753231, \"npv\": 0.9998430495277376, \"accuracy\": 0.9998430371803507, \"f1\": 0.5069986051902639, \"f2\": 0.39129122959699253, \"f0_5\": 0.7198683984809201, \"p4\": 0.6728409888397651, \"phi\": 0.5826325214196126}, {\"truth_threshold\": 12.359999723732471, \"match_probability\": 0.9998098104150758, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103161.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200800.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3393889347646573, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6606110652353427, \"precision\": 0.9996899014468036, \"recall\": 0.3393889347646573, \"specificity\": 0.9999999749753231, \"npv\": 0.9998429948034407, \"accuracy\": 0.9998429824518793, \"f1\": 0.5067419207474322, \"f2\": 0.3910466499423443, \"f0_5\": 0.719661296466048, \"p4\": 0.6726149064265984, \"phi\": 0.5824348718162533}, {\"truth_threshold\": 12.379999723285437, \"match_probability\": 0.9998124283200986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103114.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200847.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33923430966472673, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6607656903352733, \"precision\": 0.9996897601458127, \"recall\": 0.33923430966472673, \"specificity\": 0.9999999749753231, \"npv\": 0.9998429580599876, \"accuracy\": 0.9998429457056199, \"f1\": 0.5065695259477239, \"f2\": 0.3908824176074117, \"f0_5\": 0.7195221514350111, \"p4\": 0.6724630213684706, \"phi\": 0.5823021265931194}, {\"truth_threshold\": 12.399999722838402, \"match_probability\": 0.999815010197078, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 103037.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3389809876925, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6610190123074999, \"precision\": 0.9996895283741959, \"recall\": 0.3389809876925, \"specificity\": 0.9999999749753231, \"npv\": 0.9998428978632724, \"accuracy\": 0.9998428855043014, \"f1\": 0.5062870058718031, \"f2\": 0.39061333082621824, \"f0_5\": 0.7192940325618475, \"p4\": 0.6722140374301703, \"phi\": 0.582084584973423}, {\"truth_threshold\": 12.419999722391367, \"match_probability\": 0.9998175565416553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102971.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 200990.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33876385457344854, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6612361454265514, \"precision\": 0.9996893294370067, \"recall\": 0.33876385457344854, \"specificity\": 0.9999999749753231, \"npv\": 0.9998428462660937, \"accuracy\": 0.9998428339031713, \"f1\": 0.5060447607159355, \"f2\": 0.3903826600052925, \"f0_5\": 0.7190983458873449, \"p4\": 0.6720004732556858, \"phi\": 0.5818980560187481}, {\"truth_threshold\": 12.439999721944332, \"match_probability\": 0.9998200678426586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102881.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201080.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3384677639565602, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6615322360434398, \"precision\": 0.9996890577478064, \"recall\": 0.3384677639565602, \"specificity\": 0.9999999749753231, \"npv\": 0.9998427759063131, \"accuracy\": 0.9998427635379937, \"f1\": 0.5057142997586477, \"f2\": 0.39006807167658636, \"f0_5\": 0.7188312677382888, \"p4\": 0.6717090269242041, \"phi\": 0.5816436019826481}, {\"truth_threshold\": 12.459999721497297, \"match_probability\": 0.9998225445821961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102838.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33832629843960244, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6616737015603975, \"precision\": 0.9996889277729173, \"recall\": 0.33832629843960244, \"specificity\": 0.9999999749753231, \"npv\": 0.9998427422899769, \"accuracy\": 0.9998427299190756, \"f1\": 0.5055563612409084, \"f2\": 0.3899177532050164, \"f0_5\": 0.7187035688477457, \"p4\": 0.6715696896404215, \"phi\": 0.5815219902055089}, {\"truth_threshold\": 12.479999721050262, \"match_probability\": 0.9998249872357476, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102772.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.338109165320551, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.661890834679449, \"precision\": 0.9996887280650558, \"recall\": 0.338109165320551, \"specificity\": 0.9999999749753231, \"npv\": 0.9998426906928143, \"accuracy\": 0.9998426783179454, \"f1\": 0.5053138790210564, \"f2\": 0.38968701275852236, \"f0_5\": 0.7185074464083716, \"p4\": 0.6713557089039294, \"phi\": 0.5813352807932259}, {\"truth_threshold\": 12.499999720603228, \"match_probability\": 0.9998273962722566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102698.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201263.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3378657130355539, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6621342869644461, \"precision\": 0.9996885038450307, \"recall\": 0.3378657130355539, \"specificity\": 0.9999999749753231, \"npv\": 0.9998426328414565, \"accuracy\": 0.9998426204621328, \"f1\": 0.5050419114266114, \"f2\": 0.38942827630455323, \"f0_5\": 0.7182873792980929, \"p4\": 0.6711156264914125, \"phi\": 0.5811258686247532}, {\"truth_threshold\": 12.519999720156193, \"match_probability\": 0.9998297721542191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102640.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3376748990824481, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6623251009175519, \"precision\": 0.9996883278790712, \"recall\": 0.3376748990824481, \"specificity\": 0.9999999749753231, \"npv\": 0.999842587498505, \"accuracy\": 0.9998425751156851, \"f1\": 0.5048286784397725, \"f2\": 0.3892254625654903, \"f0_5\": 0.7181147668295905, \"p4\": 0.6709273320202451, \"phi\": 0.5809616820126537}, {\"truth_threshold\": 12.539999719709158, \"match_probability\": 0.9998321153377727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102574.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201387.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3374577659633966, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6625422340366034, \"precision\": 0.9996881273999572, \"recall\": 0.3374577659633966, \"specificity\": 0.9999999749753231, \"npv\": 0.9998425359013583, \"accuracy\": 0.9998425235145549, \"f1\": 0.5045859600016726, \"f2\": 0.3889946528120141, \"f0_5\": 0.7179182093688977, \"p4\": 0.6707129356041186, \"phi\": 0.5807747925286031}, {\"truth_threshold\": 12.559999719262123, \"match_probability\": 0.9998344262727838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102502.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33722089346988593, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6627791065301141, \"precision\": 0.9996879084011158, \"recall\": 0.33722089346988593, \"specificity\": 0.9999999749753231, \"npv\": 0.999842479613568, \"accuracy\": 0.9998424672224129, \"f1\": 0.5043210863602259, \"f2\": 0.38874283399753334, \"f0_5\": 0.7177036172956895, \"p4\": 0.6704788902660288, \"phi\": 0.5805708445002112}, {\"truth_threshold\": 12.579999718815088, \"match_probability\": 0.9998367054029336, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102410.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201551.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3369182230615112, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6630817769384888, \"precision\": 0.9996876281212784, \"recall\": 0.3369182230615112, \"specificity\": 0.9999999749753231, \"npv\": 0.9998424076902895, \"accuracy\": 0.9998423952935648, \"f1\": 0.5039825001291821, \"f2\": 0.38842102548308943, \"f0_5\": 0.7174291642906482, \"p4\": 0.6701795916223654, \"phi\": 0.5803101399676952}, {\"truth_threshold\": 12.599999718368053, \"match_probability\": 0.9998389531658027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102320.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201641.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33662213244462286, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6633778675553772, \"precision\": 0.9996873534469283, \"recall\": 0.33662213244462286, \"specificity\": 0.9999999749753231, \"npv\": 0.9998423373305707, \"accuracy\": 0.9998423249283872, \"f1\": 0.5036511261022906, \"f2\": 0.38810616934052294, \"f0_5\": 0.7171604036620599, \"p4\": 0.6698865378209752, \"phi\": 0.5800549895814435}, {\"truth_threshold\": 12.619999717921019, \"match_probability\": 0.9998411699929557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102267.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201694.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.336447767970233, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.663552232029767, \"precision\": 0.9996871914681473, \"recall\": 0.336447767970233, \"specificity\": 0.9999999749753231, \"npv\": 0.9998422958965186, \"accuracy\": 0.999842283491116, \"f1\": 0.5034559149313248, \"f2\": 0.3879207339416133, \"f0_5\": 0.7170020065707832, \"p4\": 0.6697138404887144, \"phi\": 0.5799046818498457}, {\"truth_threshold\": 12.639999717473984, \"match_probability\": 0.9998433563100231, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102182.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201779.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3361681268320607, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6638318731679393, \"precision\": 0.9996869313401295, \"recall\": 0.3361681268320607, \"specificity\": 0.9999999749753231, \"npv\": 0.9998422294456877, \"accuracy\": 0.999842217035115, \"f1\": 0.503142734043208, \"f2\": 0.38762330640988485, \"f0_5\": 0.7167477767786122, \"p4\": 0.6694366852705423, \"phi\": 0.5796635409291286}, {\"truth_threshold\": 12.659999717026949, \"match_probability\": 0.9998455125367829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102118.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3359575735044956, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6640424264955044, \"precision\": 0.9996867351933432, \"recall\": 0.3359575735044956, \"specificity\": 0.9999999749753231, \"npv\": 0.9998421794121266, \"accuracy\": 0.9998421669976555, \"f1\": 0.5029068407405857, \"f2\": 0.38739933565706675, \"f0_5\": 0.7165561965922917, \"p4\": 0.6692278508705714, \"phi\": 0.5794819098000799}, {\"truth_threshold\": 12.679999716579914, \"match_probability\": 0.9998476390872413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 102046.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 201915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33572070101098495, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.664279298989015, \"precision\": 0.9996865142342131, \"recall\": 0.33572070101098495, \"specificity\": 0.9999999749753231, \"npv\": 0.9998421231243765, \"accuracy\": 0.9998421107055134, \"f1\": 0.5026413718879221, \"f2\": 0.3871473425589678, \"f0_5\": 0.7163405042729403, \"p4\": 0.6689927550734789, \"phi\": 0.5792775067285965}, {\"truth_threshold\": 12.69999971613288, \"match_probability\": 0.9998497363697118, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101959.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202002.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3354344800813262, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6645655199186737, \"precision\": 0.9996862468257003, \"recall\": 0.3354344800813262, \"specificity\": 0.9999999749753231, \"npv\": 0.9998420551100201, \"accuracy\": 0.9998420426858419, \"f1\": 0.5023204713857796, \"f2\": 0.38684281416110516, \"f0_5\": 0.7160796432208449, \"p4\": 0.6687084588132997, \"phi\": 0.5790304234438001}, {\"truth_threshold\": 12.719999715685844, \"match_probability\": 0.999851804786893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101906.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202055.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3352601156069364, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6647398843930635, \"precision\": 0.999686083697934, \"recall\": 0.3352601156069364, \"specificity\": 0.9999999749753231, \"npv\": 0.9998420136759915, \"accuracy\": 0.9998420012485707, \"f1\": 0.5021249128477774, \"f2\": 0.3866572771520631, \"f0_5\": 0.7159206028272632, \"p4\": 0.668535147541656, \"phi\": 0.5788798497659906}, {\"truth_threshold\": 12.73999971523881, \"match_probability\": 0.9998538447359463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101851.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202110.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3350791713410602, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6649208286589398, \"precision\": 0.9996859142349558, \"recall\": 0.3350791713410602, \"specificity\": 0.9999999749753231, \"npv\": 0.9998419706784182, \"accuracy\": 0.9998419582476289, \"f1\": 0.5019219207380176, \"f2\": 0.38646472296613793, \"f0_5\": 0.7157554607002459, \"p4\": 0.6683552006284122, \"phi\": 0.5787235526537637}, {\"truth_threshold\": 12.759999714791775, \"match_probability\": 0.9998558566085717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101796.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202165.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33489822707518396, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.665101772924816, \"precision\": 0.9996857445889147, \"recall\": 0.33489822707518396, \"specificity\": 0.9999999749753231, \"npv\": 0.9998419276808487, \"accuracy\": 0.999841915246687, \"f1\": 0.501718873601798, \"f2\": 0.38627215270568094, \"f0_5\": 0.7155902164147944, \"p4\": 0.6681751562731687, \"phi\": 0.5785672133321005}, {\"truth_threshold\": 12.77999971434474, \"match_probability\": 0.9998578407910829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101704.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202257.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33459555666680924, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6654044433331908, \"precision\": 0.9996854604073288, \"recall\": 0.33459555666680924, \"specificity\": 0.9999999749753231, \"npv\": 0.9998418557576496, \"accuracy\": 0.9998418433178389, \"f1\": 0.5013791080535474, \"f2\": 0.3859499992410328, \"f0_5\": 0.7153135791702127, \"p4\": 0.6678737731340241, \"phi\": 0.57830560583748}, {\"truth_threshold\": 12.799999713897705, \"match_probability\": 0.9998597976644809, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101612.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33429288625843445, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6657071137415655, \"precision\": 0.9996851757113061, \"recall\": 0.33429288625843445, \"specificity\": 0.9999999749753231, \"npv\": 0.999841783834461, \"accuracy\": 0.9998417713889908, \"f1\": 0.5010391883729244, \"f2\": 0.3856278007845233, \"f0_5\": 0.7150366553747377, \"p4\": 0.6675721167578631, \"phi\": 0.5780438799838925}, {\"truth_threshold\": 12.81999971345067, \"match_probability\": 0.9998617276045275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101552.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33409549251384224, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6659045074861578, \"precision\": 0.9996849897621672, \"recall\": 0.33409549251384224, \"specificity\": 0.9999999749753231, \"npv\": 0.9998417369280392, \"accuracy\": 0.9998417244788724, \"f1\": 0.500817418535551, \"f2\": 0.38541764711240384, \"f0_5\": 0.7148558983073278, \"p4\": 0.6673752369544896, \"phi\": 0.5778731253670478}, {\"truth_threshold\": 12.839999713003635, \"match_probability\": 0.9998636309818171, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101463.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3338026917926971, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6661973082073029, \"precision\": 0.9996847135326863, \"recall\": 0.3338026917926971, \"specificity\": 0.9999999749753231, \"npv\": 0.9998416673501883, \"accuracy\": 0.9998416548955302, \"f1\": 0.5004883390552859, \"f2\": 0.3851058839068759, \"f0_5\": 0.7145875502330475, \"p4\": 0.6670829840198523, \"phi\": 0.5776197464108126}, {\"truth_threshold\": 12.8599997125566, \"match_probability\": 0.9998655081618473, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101400.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202561.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33359542836087525, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6664045716391248, \"precision\": 0.9996845177064437, \"recall\": 0.33359542836087525, \"specificity\": 0.9999999749753231, \"npv\": 0.999841618098457, \"accuracy\": 0.999841605639906, \"f1\": 0.5002553078124191, \"f2\": 0.38488517212793677, \"f0_5\": 0.7143974332418849, \"p4\": 0.6668759532477262, \"phi\": 0.5774403210886019}, {\"truth_threshold\": 12.879999712109566, \"match_probability\": 0.9998673595050896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101311.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202650.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3333026276397301, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6666973723602699, \"precision\": 0.999684240648096, \"recall\": 0.3333026276397301, \"specificity\": 0.9999999749753231, \"npv\": 0.9998415485206227, \"accuracy\": 0.9998415360565638, \"f1\": 0.4999259814855022, \"f2\": 0.38457333696734025, \"f0_5\": 0.7141286250604441, \"p4\": 0.6665832618354418, \"phi\": 0.5771867521962012}, {\"truth_threshold\": 12.899999711662531, \"match_probability\": 0.9998691853670579, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101217.0, \"tn\": 1278737760.0, \"fp\": 32.0, \"fn\": 202744.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33299337743986895, \"tn_rate\": 0.9999999749753231, \"fp_rate\": 2.5024676833825834e-08, \"fn_rate\": 0.6670066225601311, \"precision\": 0.9996839474957777, \"recall\": 0.33299337743986895, \"specificity\": 0.9999999749753231, \"npv\": 0.9998414750339317, \"accuracy\": 0.999841462564045, \"f1\": 0.4995779965943585, \"f2\": 0.3842439372162786, \"f0_5\": 0.7138444221581844, \"p4\": 0.6662738478001279, \"phi\": 0.5769188168818723}, {\"truth_threshold\": 12.919999711215496, \"match_probability\": 0.999870986098377, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101146.0, \"tn\": 1278737762.0, \"fp\": 30.0, \"fn\": 202815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33275979484210144, \"tn_rate\": 0.9999999765393655, \"fp_rate\": 2.346063453171172e-08, \"fn_rate\": 0.6672402051578985, \"precision\": 0.9997034869929627, \"recall\": 0.33275979484210144, \"specificity\": 0.9999999765393655, \"npv\": 0.999841419528282, \"accuracy\": 0.9998414086174089, \"f1\": 0.4993175148159758, \"f2\": 0.3839956872332994, \"f0_5\": 0.7136376143876162, \"p4\": 0.6660421441112974, \"phi\": 0.5767220600770523}, {\"truth_threshold\": 12.939999710768461, \"match_probability\": 0.9998727620448491, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 101072.0, \"tn\": 1278737762.0, \"fp\": 30.0, \"fn\": 202889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3325163425571044, \"tn_rate\": 0.9999999765393655, \"fp_rate\": 2.346063453171172e-08, \"fn_rate\": 0.6674836574428956, \"precision\": 0.9997032699649858, \"recall\": 0.3325163425571044, \"specificity\": 0.9999999765393655, \"npv\": 0.9998413616770713, \"accuracy\": 0.9998413507615963, \"f1\": 0.49904335868741406, \"f2\": 0.38373631113196743, \"f0_5\": 0.7134134892972448, \"p4\": 0.6657981897290602, \"phi\": 0.5765109727370795}, {\"truth_threshold\": 12.959999710321426, \"match_probability\": 0.999874513547521, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100983.0, \"tn\": 1278737762.0, \"fp\": 30.0, \"fn\": 202978.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3322235418359592, \"tn_rate\": 0.9999999765393655, \"fp_rate\": 2.346063453171172e-08, \"fn_rate\": 0.6677764581640407, \"precision\": 0.9997030085236553, \"recall\": 0.3322235418359592, \"specificity\": 0.9999999765393655, \"npv\": 0.9998412920992727, \"accuracy\": 0.9998412811782541, \"f1\": 0.4987134976566397, \"f2\": 0.3834243201805511, \"f0_5\": 0.7131436852148195, \"p4\": 0.6655045487561245, \"phi\": 0.5762569950334246}, {\"truth_threshold\": 12.979999709874392, \"match_probability\": 0.9998762409427487, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100904.0, \"tn\": 1278737762.0, \"fp\": 30.0, \"fn\": 203057.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3319636400722461, \"tn_rate\": 0.9999999765393655, \"fp_rate\": 2.346063453171172e-08, \"fn_rate\": 0.6680363599277539, \"precision\": 0.9997027760714923, \"recall\": 0.3319636400722461, \"specificity\": 0.9999999765393655, \"npv\": 0.9998412303392125, \"accuracy\": 0.9998412194132649, \"f1\": 0.49842057817458846, \"f2\": 0.3831473490595985, \"f0_5\": 0.7129039687889026, \"p4\": 0.6652436846372375, \"phi\": 0.5760314603652803}, {\"truth_threshold\": 12.999999709427357, \"match_probability\": 0.9998779445622623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100818.0, \"tn\": 1278737762.0, \"fp\": 30.0, \"fn\": 203143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3316807090383306, \"tn_rate\": 0.9999999765393655, \"fp_rate\": 2.346063453171172e-08, \"fn_rate\": 0.6683192909616694, \"precision\": 0.9997025226082817, \"recall\": 0.3316807090383306, \"specificity\": 0.9999999765393655, \"npv\": 0.9998411631067504, \"accuracy\": 0.9998411521754287, \"f1\": 0.4981015738286451, \"f2\": 0.38284579840995464, \"f0_5\": 0.7126427681793955, \"p4\": 0.6649594741957342, \"phi\": 0.5757858412142652}, {\"truth_threshold\": 13.019999708980322, \"match_probability\": 0.9998796247332291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100766.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203195.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33150963445968396, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.668490365540316, \"precision\": 0.999712287315839, \"recall\": 0.33150963445968396, \"specificity\": 0.9999999773213866, \"npv\": 0.9998411224546927, \"accuracy\": 0.999841112301828, \"f1\": 0.4979098518613683, \"f2\": 0.3826637369848531, \"f0_5\": 0.7124887398694179, \"p4\": 0.6647886052281017, \"phi\": 0.5756401330931282}, {\"truth_threshold\": 13.039999708533287, \"match_probability\": 0.9998812817783169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100717.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203244.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.331348429568267, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6686515704317331, \"precision\": 0.9997121473805411, \"recall\": 0.331348429568267, \"specificity\": 0.9999999773213866, \"npv\": 0.999841084147832, \"accuracy\": 0.999841073991898, \"f1\": 0.4977279859256203, \"f2\": 0.38249189193294797, \"f0_5\": 0.7123397152536619, \"p4\": 0.6646264798017136, \"phi\": 0.575500105011573}, {\"truth_threshold\": 13.059999708086252, \"match_probability\": 0.9998829160157551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100637.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203324.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33108523790881067, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6689147620911894, \"precision\": 0.9997119186219776, \"recall\": 0.33108523790881067, \"specificity\": 0.9999999773213866, \"npv\": 0.999841021606025, \"accuracy\": 0.9998410114450736, \"f1\": 0.4974309672859201, \"f2\": 0.3822113010915223, \"f0_5\": 0.7120962320891562, \"p4\": 0.6643616161715724, \"phi\": 0.5752714145074174}, {\"truth_threshold\": 13.079999707639217, \"match_probability\": 0.9998845277593964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100547.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203414.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3307891472919223, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6692108527080777, \"precision\": 0.9997116608335985, \"recall\": 0.3307891472919223, \"specificity\": 0.9999999773213866, \"npv\": 0.9998409512465013, \"accuracy\": 0.9998409410798961, \"f1\": 0.4970966808969266, \"f2\": 0.38189559563057385, \"f0_5\": 0.7118220497971725, \"p4\": 0.6640633936797437, \"phi\": 0.5750140290070518}, {\"truth_threshold\": 13.099999707192183, \"match_probability\": 0.9998861173187764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100502.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3306411019834781, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6693588980165218, \"precision\": 0.9997115317663209, \"recall\": 0.3306411019834781, \"specificity\": 0.9999999773213866, \"npv\": 0.9998409160667432, \"accuracy\": 0.9998409058973073, \"f1\": 0.4969294819180602, \"f2\": 0.3817377267116133, \"f0_5\": 0.711684853806553, \"p4\": 0.6639141827024952, \"phi\": 0.5748852930570966}, {\"truth_threshold\": 13.119999706745148, \"match_probability\": 0.9998876849991732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100406.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203555.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3303252719921306, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6696747280078694, \"precision\": 0.9997112560362423, \"recall\": 0.3303252719921306, \"specificity\": 0.9999999773213866, \"npv\": 0.9998408410166009, \"accuracy\": 0.999840830841118, \"f1\": 0.4965726663963046, \"f2\": 0.38140090360782175, \"f0_5\": 0.711391935111329, \"p4\": 0.66359564348038, \"phi\": 0.5746105599976643}, {\"truth_threshold\": 13.139999706298113, \"match_probability\": 0.9998892311016662, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100342.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203619.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.33011471866456554, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6698852813354345, \"precision\": 0.9997110719231651, \"recall\": 0.33011471866456554, \"specificity\": 0.9999999773213866, \"npv\": 0.9998407909831789, \"accuracy\": 0.9998407808036585, \"f1\": 0.4963346952504378, \"f2\": 0.38117632757566206, \"f0_5\": 0.7111964788183345, \"p4\": 0.6633831155285731, \"phi\": 0.5744273316491129}, {\"truth_threshold\": 13.159999705851078, \"match_probability\": 0.9998907559231927, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100250.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32981204825619076, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6701879517438092, \"precision\": 0.9997108068488916, \"recall\": 0.32981204825619076, \"specificity\": 0.9999999773213866, \"npv\": 0.9998407190601436, \"accuracy\": 0.9998407088748102, \"f1\": 0.4959924797150208, \"f2\": 0.38085346126463865, \"f0_5\": 0.7109152617373705, \"p4\": 0.663077370180863, \"phi\": 0.5741638384896921}, {\"truth_threshold\": 13.179999705404043, \"match_probability\": 0.9998922597566062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100201.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3296508433647738, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6703491566352262, \"precision\": 0.9997106654694203, \"recall\": 0.3296508433647738, \"specificity\": 0.9999999773213866, \"npv\": 0.9998406807533139, \"accuracy\": 0.9998406705648804, \"f1\": 0.49581014916215355, \"f2\": 0.3806814814364542, \"f0_5\": 0.7107653632315242, \"p4\": 0.6629144136239737, \"phi\": 0.5740234503922995}, {\"truth_threshold\": 13.199999704957008, \"match_probability\": 0.9998937428907317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100128.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203833.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3294106809755199, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6705893190244802, \"precision\": 0.9997104545862995, \"recall\": 0.3294106809755199, \"specificity\": 0.9999999773213866, \"npv\": 0.9998406236839606, \"accuracy\": 0.999840613490903, \"f1\": 0.49553843184416435, \"f2\": 0.38042524283796136, \"f0_5\": 0.7105418903786462, \"p4\": 0.6626714945990418, \"phi\": 0.5738142370962829}, {\"truth_threshold\": 13.219999704509974, \"match_probability\": 0.9998952056104213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100066.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32920670743944125, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6707932925605588, \"precision\": 0.9997102752385234, \"recall\": 0.32920670743944125, \"specificity\": 0.9999999773213866, \"npv\": 0.9998405752141041, \"accuracy\": 0.999840565017114, \"f1\": 0.4953075811273685, \"f2\": 0.38020759320910774, \"f0_5\": 0.7103519460034273, \"p4\": 0.662465041520668, \"phi\": 0.5736364891875129}, {\"truth_threshold\": 13.239999704062939, \"match_probability\": 0.9998966481966088, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 100016.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 203945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32904221265228106, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6709577873477189, \"precision\": 0.9997101304413014, \"recall\": 0.32904221265228106, \"specificity\": 0.9999999773213866, \"npv\": 0.9998405361255136, \"accuracy\": 0.9998405259253488, \"f1\": 0.49512135958376857, \"f2\": 0.38003205437540705, \"f0_5\": 0.7101986675964047, \"p4\": 0.6622984544937818, \"phi\": 0.5734931039836346}, {\"truth_threshold\": 13.259999703615904, \"match_probability\": 0.9998980709263633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99953.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204008.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3288349492204592, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6711650507795408, \"precision\": 0.9997099477906023, \"recall\": 0.3288349492204592, \"specificity\": 0.9999999773213866, \"npv\": 0.9998404868738938, \"accuracy\": 0.9998404766697245, \"f1\": 0.49488665480030597, \"f2\": 0.37981085645062496, \"f0_5\": 0.7100054127852545, \"p4\": 0.662088437008552, \"phi\": 0.5733123875844387}, {\"truth_threshold\": 13.279999703168869, \"match_probability\": 0.9998994740729429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99896.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204065.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3286474251630966, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6713525748369035, \"precision\": 0.9997097823367526, \"recall\": 0.3286474251630966, \"specificity\": 0.9999999773213866, \"npv\": 0.9998404423129087, \"accuracy\": 0.9998404321051121, \"f1\": 0.49467423976072455, \"f2\": 0.3796107067425969, \"f0_5\": 0.7098304439211496, \"p4\": 0.6618983078794953, \"phi\": 0.5731488331872384}, {\"truth_threshold\": 13.299999702721834, \"match_probability\": 0.9999008579058464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99833.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204128.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3284401617312747, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6715598382687252, \"precision\": 0.9997095992469608, \"recall\": 0.3284401617312747, \"specificity\": 0.9999999773213866, \"npv\": 0.9998403930612982, \"accuracy\": 0.9998403828494878, \"f1\": 0.4944393954777217, \"f2\": 0.3793894684678796, \"f0_5\": 0.7096369253165654, \"p4\": 0.6616880398076124, \"phi\": 0.5729680082376425}, {\"truth_threshold\": 13.3199997022748, \"match_probability\": 0.9999022226908654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99761.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204200.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32820328923776404, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.6717967107622359, \"precision\": 0.9997093897184086, \"recall\": 0.32820328923776404, \"specificity\": 0.9999999773213866, \"npv\": 0.9998403367737493, \"accuracy\": 0.9998403265573458, \"f1\": 0.49417091227018634, \"f2\": 0.3791365987805119, \"f0_5\": 0.7094155913420307, \"p4\": 0.6614475721211955, \"phi\": 0.5727612812708552}, {\"truth_threshold\": 13.339999701827765, \"match_probability\": 0.9999035686901352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99702.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204259.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32800918538891505, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.671990814611085, \"precision\": 0.9997092177958709, \"recall\": 0.32800918538891505, \"specificity\": 0.9999999773213866, \"npv\": 0.9998402906492347, \"accuracy\": 0.9998402804290627, \"f1\": 0.4939508338039892, \"f2\": 0.3789293654865743, \"f0_5\": 0.7092340852344267, \"p4\": 0.6612503938128963, \"phi\": 0.5725918243850262}, {\"truth_threshold\": 13.35999970138073, \"match_probability\": 0.999904896162185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99643.0, \"tn\": 1278737763.0, \"fp\": 29.0, \"fn\": 204318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.327815081540066, \"tn_rate\": 0.9999999773213866, \"fp_rate\": 2.2678613380654664e-08, \"fn_rate\": 0.672184918459934, \"precision\": 0.9997090456697969, \"recall\": 0.327815081540066, \"specificity\": 0.9999999773213866, \"npv\": 0.9998402445247245, \"accuracy\": 0.9998402343007797, \"f1\": 0.4937306909990016, \"f2\": 0.37872211360409147, \"f0_5\": 0.7090524572012484, \"p4\": 0.661053099738498, \"phi\": 0.5724223173497345}, {\"truth_threshold\": 13.379999700933695, \"match_probability\": 0.9999062053619875, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99582.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32761439789973057, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6723856021002694, \"precision\": 0.9997490136235405, \"recall\": 0.32761439789973057, \"specificity\": 0.9999999804494712, \"npv\": 0.9998401968371757, \"accuracy\": 0.9998401897361673, \"f1\": 0.49350790944772627, \"f2\": 0.37850896764683745, \"f0_5\": 0.7088806914686876, \"p4\": 0.6608533818181231, \"phi\": 0.5722585060876395}, {\"truth_threshold\": 13.39999970048666, \"match_probability\": 0.9999074965410077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99528.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204433.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32743674352959756, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6725632564704025, \"precision\": 0.9997488774823461, \"recall\": 0.32743674352959756, \"specificity\": 0.9999999804494712, \"npv\": 0.9998401546215302, \"accuracy\": 0.9998401475170607, \"f1\": 0.49330630411832055, \"f2\": 0.37831924506441783, \"f0_5\": 0.7087142342414191, \"p4\": 0.6606725962688972, \"phi\": 0.5721032756395487}, {\"truth_threshold\": 13.419999700039625, \"match_probability\": 0.9999087699472513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99449.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204512.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32717684176588446, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6728231582341155, \"precision\": 0.9997486780465247, \"recall\": 0.32717684176588446, \"specificity\": 0.9999999804494712, \"npv\": 0.9998400928616107, \"accuracy\": 0.9998400857520716, \"f1\": 0.4930112657553261, \"f2\": 0.37804165988757094, \"f0_5\": 0.7084705288969121, \"p4\": 0.6604079385153171, \"phi\": 0.5718761033544564}, {\"truth_threshold\": 13.43999969959259, \"match_probability\": 0.999910025825312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99377.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204584.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32693996927237373, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6730600307276262, \"precision\": 0.9997484960061166, \"recall\": 0.32693996927237373, \"specificity\": 0.9999999804494712, \"npv\": 0.9998400365740957, \"accuracy\": 0.9998400294599296, \"f1\": 0.49274226937026944, \"f2\": 0.3777886418206176, \"f0_5\": 0.7082482264752291, \"p4\": 0.6601665499868646, \"phi\": 0.5716689816531132}, {\"truth_threshold\": 13.459999699145555, \"match_probability\": 0.9999112644164184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99309.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204652.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3267162563618359, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6732837436381641, \"precision\": 0.9997483238367528, \"recall\": 0.3267162563618359, \"specificity\": 0.9999999804494712, \"npv\": 0.9998399834136708, \"accuracy\": 0.9998399762951288, \"f1\": 0.49248812903705724, \"f2\": 0.3775496548756138, \"f0_5\": 0.708038106536888, \"p4\": 0.6599384128627714, \"phi\": 0.5714732978061556}, {\"truth_threshold\": 13.47999969869852, \"match_probability\": 0.999912485958481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99204.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32637081730879947, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6736291826912005, \"precision\": 0.9997480575235063, \"recall\": 0.32637081730879947, \"specificity\": 0.9999999804494712, \"npv\": 0.9998399013277316, \"accuracy\": 0.9998398942024217, \"f1\": 0.4920955380837818, \"f2\": 0.3771805823707125, \"f0_5\": 0.7077133362915319, \"p4\": 0.6595858384141333, \"phi\": 0.5711710072822674}, {\"truth_threshold\": 13.499999698251486, \"match_probability\": 0.9999136906861367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99088.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3259891894025878, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6740108105974122, \"precision\": 0.9997477626547476, \"recall\": 0.3259891894025878, \"specificity\": 0.9999999804494712, \"npv\": 0.9998398106423287, \"accuracy\": 0.9998398035095263, \"f1\": 0.49166158075192146, \"f2\": 0.37677277660029945, \"f0_5\": 0.7073540896585301, \"p4\": 0.6591958981015648, \"phi\": 0.5708368621712757}, {\"truth_threshold\": 13.519999697804451, \"match_probability\": 0.9999148788307943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99002.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 204959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3257062583686723, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6742937416313277, \"precision\": 0.9997475435992205, \"recall\": 0.3257062583686723, \"specificity\": 0.9999999804494712, \"npv\": 0.9998397434100579, \"accuracy\": 0.99983973627169, \"f1\": 0.49133969249704706, \"f2\": 0.3764703913920073, \"f0_5\": 0.7070874442376395, \"p4\": 0.6589065129334517, \"phi\": 0.5705890076247738}, {\"truth_threshold\": 13.539999697357416, \"match_probability\": 0.9999160506206793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98882.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205079.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3253114708794878, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6746885291205121, \"precision\": 0.9997472373037297, \"recall\": 0.3253114708794878, \"specificity\": 0.9999999804494712, \"npv\": 0.9998396495976021, \"accuracy\": 0.9998396424514533, \"f1\": 0.49089031643118836, \"f2\": 0.376048392433244, \"f0_5\": 0.7067149426306016, \"p4\": 0.6585023042268873, \"phi\": 0.5702429840929815}, {\"truth_threshold\": 13.559999696910381, \"match_probability\": 0.9999172062808771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98825.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3251239468221252, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6748760531778748, \"precision\": 0.9997470915528579, \"recall\": 0.3251239468221252, \"specificity\": 0.9999999804494712, \"npv\": 0.9998396050366918, \"accuracy\": 0.9998395978868408, \"f1\": 0.49067676900581164, \"f2\": 0.3758479159408957, \"f0_5\": 0.7065378252433293, \"p4\": 0.6583101353109256, \"phi\": 0.5700785493628365}, {\"truth_threshold\": 13.579999696463346, \"match_probability\": 0.9999183460333761, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98761.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205200.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32491339349456017, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6750866065054398, \"precision\": 0.999746927702306, \"recall\": 0.32491339349456017, \"specificity\": 0.9999999804494712, \"npv\": 0.9998395550033937, \"accuracy\": 0.9998395478493812, \"f1\": 0.4904369244215351, \"f2\": 0.37562279881031163, \"f0_5\": 0.7063388189184744, \"p4\": 0.6580942362284915, \"phi\": 0.5698938643684067}, {\"truth_threshold\": 13.599999696016312, \"match_probability\": 0.9999194700971109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98681.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205280.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32465020183510385, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6753497981648962, \"precision\": 0.9997467225903187, \"recall\": 0.32465020183510385, \"specificity\": 0.9999999804494712, \"npv\": 0.9998394924617781, \"accuracy\": 0.9998394853025568, \"f1\": 0.4901370114759839, \"f2\": 0.37534137157202085, \"f0_5\": 0.7060898559642809, \"p4\": 0.6578241680852835, \"phi\": 0.5696629239522366}, {\"truth_threshold\": 13.619999695569277, \"match_probability\": 0.9999205786880038, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98608.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205353.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32441003944584995, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.67558996055415, \"precision\": 0.9997465351352995, \"recall\": 0.32441003944584995, \"specificity\": 0.9999999804494712, \"npv\": 0.9998394353925607, \"accuracy\": 0.9998394282285795, \"f1\": 0.4898632369086474, \"f2\": 0.37508453932628716, \"f0_5\": 0.70586247822097, \"p4\": 0.657577542329762, \"phi\": 0.569452109124224}, {\"truth_threshold\": 13.639999695122242, \"match_probability\": 0.9999216720190062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98530.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32415342757788007, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.67584657242212, \"precision\": 0.9997463345340165, \"recall\": 0.32415342757788007, \"specificity\": 0.9999999804494712, \"npv\": 0.9998393744145, \"accuracy\": 0.9998393672454257, \"f1\": 0.4895706009202119, \"f2\": 0.3748100843046898, \"f0_5\": 0.7056193164809699, \"p4\": 0.6573138253122888, \"phi\": 0.569226768670534}, {\"truth_threshold\": 13.659999694675207, \"match_probability\": 0.9999227503001397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98471.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.323959323729031, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.676040676270969, \"precision\": 0.9997461825860948, \"recall\": 0.323959323729031, \"specificity\": 0.9999999804494712, \"npv\": 0.9998393282900744, \"accuracy\": 0.9998393211171426, \"f1\": 0.4893491727066494, \"f2\": 0.37460246207221876, \"f0_5\": 0.7054352420319653, \"p4\": 0.6571142102825999, \"phi\": 0.5690562595827907}, {\"truth_threshold\": 13.679999694228172, \"match_probability\": 0.9999238137385363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98396.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32371258154829075, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6762874184517093, \"precision\": 0.9997459891689782, \"recall\": 0.32371258154829075, \"specificity\": 0.9999999804494712, \"npv\": 0.9998392696573362, \"accuracy\": 0.9998392624794947, \"f1\": 0.489067602427544, \"f2\": 0.3743385085960594, \"f0_5\": 0.705201069311756, \"p4\": 0.6568602921263896, \"phi\": 0.568839436985396}, {\"truth_threshold\": 13.699999693781137, \"match_probability\": 0.999924862538478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98291.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32336714249525433, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6766328575047457, \"precision\": 0.999745717889255, \"recall\": 0.32336714249525433, \"specificity\": 0.9999999804494712, \"npv\": 0.9998391875715141, \"accuracy\": 0.9998391803867875, \"f1\": 0.4886732276515933, \"f2\": 0.37396892311438484, \"f0_5\": 0.7048728889526337, \"p4\": 0.6565044861769608, \"phi\": 0.5685357464731874}, {\"truth_threshold\": 13.719999693334103, \"match_probability\": 0.9999258969014363, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98198.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205763.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3230611821911364, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6769388178088637, \"precision\": 0.9997454771285748, \"recall\": 0.3230611821911364, \"specificity\": 0.9999999804494712, \"npv\": 0.9998391148669402, \"accuracy\": 0.9998391076761042, \"f1\": 0.48832375231237446, \"f2\": 0.3736415266497066, \"f0_5\": 0.7045818845581493, \"p4\": 0.6561890310487859, \"phi\": 0.5682666279553186}, {\"truth_threshold\": 13.739999692887068, \"match_probability\": 0.9999269170261104, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98131.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3228407591763417, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6771592408236583, \"precision\": 0.9997453033945963, \"recall\": 0.3228407591763417, \"specificity\": 0.9999999804494712, \"npv\": 0.9998390624883827, \"accuracy\": 0.9998390552931387, \"f1\": 0.48807187957733694, \"f2\": 0.3734056316590563, \"f0_5\": 0.704372043612768, \"p4\": 0.655961585382549, \"phi\": 0.5680726678868296}, {\"truth_threshold\": 13.759999692440033, \"match_probability\": 0.9999279231084656, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98076.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32265981491046547, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6773401850895345, \"precision\": 0.99974516059979, \"recall\": 0.32265981491046547, \"specificity\": 0.9999999804494712, \"npv\": 0.9998390194910636, \"accuracy\": 0.9998390122921968, \"f1\": 0.48786505563818516, \"f2\": 0.3732119685374959, \"f0_5\": 0.704199665405355, \"p4\": 0.6557747620265097, \"phi\": 0.5679133974411459}, {\"truth_threshold\": 13.779999691992998, \"match_probability\": 0.9999289153417709, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97983.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 205978.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3223538546063475, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6776461453936524, \"precision\": 0.9997449187821402, \"recall\": 0.3223538546063475, \"specificity\": 0.9999999804494712, \"npv\": 0.9998389467865141, \"accuracy\": 0.9998389395815134, \"f1\": 0.4875152063965132, \"f2\": 0.37288446491690086, \"f0_5\": 0.703907941602861, \"p4\": 0.6554586261524931, \"phi\": 0.5676439839599955}, {\"truth_threshold\": 13.799999691545963, \"match_probability\": 0.9999298939166361, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97867.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32197222670013587, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6780277732998641, \"precision\": 0.9997446165161606, \"recall\": 0.32197222670013587, \"specificity\": 0.9999999804494712, \"npv\": 0.9998388561012843, \"accuracy\": 0.999838848888618, \"f1\": 0.4870786083468333, \"f2\": 0.37247590078980863, \"f0_5\": 0.703543633694641, \"p4\": 0.6550638924293619, \"phi\": 0.5673077620735569}, {\"truth_threshold\": 13.819999691098928, \"match_probability\": 0.9999308590210483, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97779.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3216827158747339, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.678317284125266, \"precision\": 0.999744386732649, \"recall\": 0.3216827158747339, \"specificity\": 0.9999999804494712, \"npv\": 0.9998387873056038, \"accuracy\": 0.999838780087111, \"f1\": 0.48674722785708063, \"f2\": 0.37216590745770556, \"f0_5\": 0.7032669377726823, \"p4\": 0.6547641324638074, \"phi\": 0.5670525642521443}, {\"truth_threshold\": 13.839999690651894, \"match_probability\": 0.9999318108404078, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97719.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206242.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3214853221301417, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6785146778698583, \"precision\": 0.9997442298248486, \"recall\": 0.3214853221301417, \"specificity\": 0.9999999804494712, \"npv\": 0.9998387403994634, \"accuracy\": 0.9998387331769927, \"f1\": 0.4865212033706327, \"f2\": 0.371954524554122, \"f0_5\": 0.7030781207505141, \"p4\": 0.6545595987103024, \"phi\": 0.5668784998886367}, {\"truth_threshold\": 13.859999690204859, \"match_probability\": 0.9999327495575641, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97621.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206340.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3211629123473077, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6788370876526922, \"precision\": 0.9997439731274195, \"recall\": 0.3211629123473077, \"specificity\": 0.9999999804494712, \"npv\": 0.9998386637861102, \"accuracy\": 0.9998386565571328, \"f1\": 0.48615188480280475, \"f2\": 0.37160922428035237, \"f0_5\": 0.7027694389852349, \"p4\": 0.6542252616156439, \"phi\": 0.5665940797966226}, {\"truth_threshold\": 13.879999689757824, \"match_probability\": 0.9999336753528504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97538.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206423.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3208898510006218, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6791101489993782, \"precision\": 0.9997437553170772, \"recall\": 0.3208898510006218, \"specificity\": 0.9999999804494712, \"npv\": 0.9998385988992999, \"accuracy\": 0.9998385916648024, \"f1\": 0.48583895358683415, \"f2\": 0.37131673578715507, \"f0_5\": 0.7025077317768466, \"p4\": 0.6539418408554767, \"phi\": 0.5663530817122658}, {\"truth_threshold\": 13.899999689310789, \"match_probability\": 0.9999345884041188, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97445.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206516.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32058389069650384, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6794161093034962, \"precision\": 0.9997435108238433, \"recall\": 0.32058389069650384, \"specificity\": 0.9999999804494712, \"npv\": 0.9998385261948116, \"accuracy\": 0.9998385189541189, \"f1\": 0.48548816608582795, \"f2\": 0.37098896379692897, \"f0_5\": 0.7022141960477977, \"p4\": 0.6536239918454214, \"phi\": 0.5660829258645942}, {\"truth_threshold\": 13.919999688863754, \"match_probability\": 0.999935488886774, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97372.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32034372830724994, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.67965627169275, \"precision\": 0.9997433185827079, \"recall\": 0.32034372830724994, \"specificity\": 0.9999999804494712, \"npv\": 0.9998384691257045, \"accuracy\": 0.9998384618801416, \"f1\": 0.48521270287374363, \"f2\": 0.3707316478848894, \"f0_5\": 0.7019835656889419, \"p4\": 0.6533742890366818, \"phi\": 0.5658707777224288}, {\"truth_threshold\": 13.93999968841672, \"match_probability\": 0.9999363769738071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97294.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206667.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.32008711643928006, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.67991288356072, \"precision\": 0.9997431128556602, \"recall\": 0.32008711643928006, \"specificity\": 0.9999999804494712, \"npv\": 0.9998384081477616, \"accuracy\": 0.9998384008969877, \"f1\": 0.4849182615629984, \"f2\": 0.3704566759800573, \"f0_5\": 0.7017369240245399, \"p4\": 0.6531072804703204, \"phi\": 0.5656440109836113}, {\"truth_threshold\": 13.959999687969685, \"match_probability\": 0.9999372528358289, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97221.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31984695405002617, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6801530459499738, \"precision\": 0.9997429200172758, \"recall\": 0.31984695405002617, \"specificity\": 0.9999999804494712, \"npv\": 0.999838351078668, \"accuracy\": 0.9998383438230104, \"f1\": 0.4846425909817127, \"f2\": 0.3701993008856971, \"f0_5\": 0.7015058915209721, \"p4\": 0.6528571977996521, \"phi\": 0.5654316982122144}, {\"truth_threshold\": 13.97999968752265, \"match_probability\": 0.9999381166411027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97174.0, \"tn\": 1278737767.0, \"fp\": 25.0, \"fn\": 206787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3196923289500956, \"tn_rate\": 0.9999999804494712, \"fp_rate\": 1.9550528776426434e-08, \"fn_rate\": 0.6803076710499044, \"precision\": 0.9997427957077748, \"recall\": 0.3196923289500956, \"specificity\": 0.9999999804494712, \"npv\": 0.9998383143355564, \"accuracy\": 0.999838307076751, \"f1\": 0.48446505135108187, \"f2\": 0.3700335784890518, \"f0_5\": 0.7013570415022873, \"p4\": 0.6526960883378466, \"phi\": 0.5652949615041116}, {\"truth_threshold\": 13.999999687075615, \"match_probability\": 0.999938968555576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97065.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31933373031408635, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6806662696859137, \"precision\": 0.9997631015161503, \"recall\": 0.31933373031408635, \"specificity\": 0.9999999820135135, \"npv\": 0.9998382291230715, \"accuracy\": 0.9998382234203733, \"f1\": 0.4840555642826687, \"f2\": 0.36964976099295316, \"f0_5\": 0.7010196255162043, \"p4\": 0.6523243498470602, \"phi\": 0.5649835429113235}, {\"truth_threshold\": 14.01999968662858, \"match_probability\": 0.9999398087429128, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 97006.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 206955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3191396264652373, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6808603735347627, \"precision\": 0.9997629574663245, \"recall\": 0.3191396264652373, \"specificity\": 0.9999999820135135, \"npv\": 0.9998381829987517, \"accuracy\": 0.9998381772920903, \"f1\": 0.4838325145265468, \"f2\": 0.36944167486116325, \"f0_5\": 0.7008324218258951, \"p4\": 0.6521217755679464, \"phi\": 0.564811753244333}, {\"truth_threshold\": 14.039999686181545, \"match_probability\": 0.9999406373645255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96932.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207029.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31889617418024024, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6811038258197598, \"precision\": 0.9997627765458202, \"recall\": 0.31889617418024024, \"specificity\": 0.9999999820135135, \"npv\": 0.9998381251479159, \"accuracy\": 0.9998381194362777, \"f1\": 0.4835526643985274, \"f2\": 0.36918065903462755, \"f0_5\": 0.7005974434105591, \"p4\": 0.6518675289179724, \"phi\": 0.5645962143673501}, {\"truth_threshold\": 14.05999968573451, \"match_probability\": 0.999941454579605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96853.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31863627241652714, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6813637275834729, \"precision\": 0.9997625830959165, \"recall\": 0.31863627241652714, \"specificity\": 0.9999999820135135, \"npv\": 0.9998380633882472, \"accuracy\": 0.9998380576712885, \"f1\": 0.48325379144140884, \"f2\": 0.3689019745261747, \"f0_5\": 0.7003463660488962, \"p4\": 0.6515958939038607, \"phi\": 0.5643660212322861}, {\"truth_threshold\": 14.079999685287476, \"match_probability\": 0.9999422605451516, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96774.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207187.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.318376370652814, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.681623629347186, \"precision\": 0.9997623893302479, \"recall\": 0.318376370652814, \"specificity\": 0.9999999820135135, \"npv\": 0.9998380016285862, \"accuracy\": 0.9998379959062994, \"f1\": 0.482954800652763, \"f2\": 0.3686232564730189, \"f0_5\": 0.7000950590972425, \"p4\": 0.6513240422522922, \"phi\": 0.5641357341963976}, {\"truth_threshold\": 14.09999968484044, \"match_probability\": 0.9999430554160051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96703.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207258.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31814278805504653, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6818572119449534, \"precision\": 0.9997622149163616, \"recall\": 0.31814278805504653, \"specificity\": 0.9999999820135135, \"npv\": 0.9998379461230744, \"accuracy\": 0.9998379403959927, \"f1\": 0.4826859868176407, \"f2\": 0.36837273440654594, \"f0_5\": 0.6998690047983325, \"p4\": 0.6510795348268514, \"phi\": 0.5639286871529634}, {\"truth_threshold\": 14.119999684393406, \"match_probability\": 0.9999438393448746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96640.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31793552462322466, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6820644753767753, \"precision\": 0.9997620599402046, \"recall\": 0.31793552462322466, \"specificity\": 0.9999999820135135, \"npv\": 0.9998378968717101, \"accuracy\": 0.9998378911403685, \"f1\": 0.48244738208394905, \"f2\": 0.3681504174834877, \"f0_5\": 0.6996682657291421, \"p4\": 0.6508624306873169, \"phi\": 0.5637449057003155}, {\"truth_threshold\": 14.139999683946371, \"match_probability\": 0.9999446124823679, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96517.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207444.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3175308674468106, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6824691325531894, \"precision\": 0.9997617567847524, \"recall\": 0.3175308674468106, \"specificity\": 0.9999999820135135, \"npv\": 0.9998378007142985, \"accuracy\": 0.9998377949746258, \"f1\": 0.4819813183987056, \"f2\": 0.3677163086413733, \"f0_5\": 0.6992759240770822, \"p4\": 0.6504381622263846, \"phi\": 0.5633859215607343}, {\"truth_threshold\": 14.159999683499336, \"match_probability\": 0.99994537497702, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96418.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31720516776823343, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6827948322317666, \"precision\": 0.9997615122199065, \"recall\": 0.31720516776823343, \"specificity\": 0.9999999820135135, \"npv\": 0.9998377233193221, \"accuracy\": 0.9998377175729306, \"f1\": 0.481605985984086, \"f2\": 0.3673668448545857, \"f0_5\": 0.6989597303273044, \"p4\": 0.6500962945050515, \"phi\": 0.5630968169248879}, {\"truth_threshold\": 14.179999683052301, \"match_probability\": 0.9999461269753221, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96328.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3169090771513451, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6830909228486549, \"precision\": 0.9997612894521074, \"recall\": 0.3169090771513451, \"specificity\": 0.9999999820135135, \"npv\": 0.999837652960263, \"accuracy\": 0.999837647207753, \"f1\": 0.4812646136013909, \"f2\": 0.3670491047443406, \"f0_5\": 0.6986719662297912, \"p4\": 0.6497852085029073, \"phi\": 0.5628338657029195}, {\"truth_threshold\": 14.199999682605267, \"match_probability\": 0.9999468686217494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96272.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31672484298972564, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6832751570102743, \"precision\": 0.9997611506308739, \"recall\": 0.31672484298972564, \"specificity\": 0.9999999820135135, \"npv\": 0.9998376091812978, \"accuracy\": 0.999837603424976, \"f1\": 0.4810521266389511, \"f2\": 0.36685137778848126, \"f0_5\": 0.698492761278171, \"p4\": 0.6495915008675869, \"phi\": 0.5626701896092995}, {\"truth_threshold\": 14.219999682158232, \"match_probability\": 0.999947600058789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96168.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31638269383243245, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6836173061675676, \"precision\": 0.99976089239118, \"recall\": 0.31638269383243245, \"specificity\": 0.9999999820135135, \"npv\": 0.9998375278775157, \"accuracy\": 0.9998375221141041, \"f1\": 0.48065735020692135, \"f2\": 0.36648412580457074, \"f0_5\": 0.6981596428182512, \"p4\": 0.6492314666866937, \"phi\": 0.5623660933733384}, {\"truth_threshold\": 14.239999681711197, \"match_probability\": 0.999948321426967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96086.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31611292238148975, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6838870776185103, \"precision\": 0.9997606883850628, \"recall\": 0.31611292238148975, \"specificity\": 0.9999999820135135, \"npv\": 0.9998374637726198, \"accuracy\": 0.999837458003609, \"f1\": 0.4803459394605944, \"f2\": 0.36619452068786, \"f0_5\": 0.6978967078589825, \"p4\": 0.6489473261346272, \"phi\": 0.5621262092328052}, {\"truth_threshold\": 14.259999681264162, \"match_probability\": 0.9999490328648757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 96040.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3159615871773023, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6840384128226976, \"precision\": 0.999760573790117, \"recall\": 0.3159615871773023, \"specificity\": 0.9999999820135135, \"npv\": 0.9998374278113404, \"accuracy\": 0.999837422039185, \"f1\": 0.4801711897286163, \"f2\": 0.36603204342990775, \"f0_5\": 0.6977490980263378, \"p4\": 0.648787826846149, \"phi\": 0.5619915952627762}, {\"truth_threshold\": 14.279999680817127, \"match_probability\": 0.9999497345092002, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95998.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 207963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3158234115560878, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6841765884439122, \"precision\": 0.9997604690640589, \"recall\": 0.3158234115560878, \"specificity\": 0.9999999820135135, \"npv\": 0.9998373949771311, \"accuracy\": 0.9998373892021022, \"f1\": 0.4800116005220235, \"f2\": 0.3658836846779204, \"f0_5\": 0.6976142548815848, \"p4\": 0.648642132118577, \"phi\": 0.5618686586973984}, {\"truth_threshold\": 14.299999680370092, \"match_probability\": 0.9999504264947446, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95929.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208032.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3155964087498067, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6844035912501932, \"precision\": 0.9997602968150742, \"recall\": 0.3155964087498067, \"specificity\": 0.9999999820135135, \"npv\": 0.9998373410352203, \"accuracy\": 0.999837335255466, \"f1\": 0.4797493454826425, \"f2\": 0.36563993181866694, \"f0_5\": 0.6973925838471928, \"p4\": 0.6484026418112537, \"phi\": 0.5616666330850475}, {\"truth_threshold\": 14.319999679923058, \"match_probability\": 0.9999511089544578, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95855.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31535295646480965, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6846470435351903, \"precision\": 0.999760111808757, \"recall\": 0.31535295646480965, \"specificity\": 0.9999999820135135, \"npv\": 0.999837283184482, \"accuracy\": 0.9998372773996534, \"f1\": 0.4794679858643104, \"f2\": 0.36537848720994237, \"f0_5\": 0.6971546518917834, \"p4\": 0.6481456108748507, \"phi\": 0.5614498871728402}, {\"truth_threshold\": 14.339999679476023, \"match_probability\": 0.9999517820194591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95769.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208192.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3150700254308941, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6849299745691059, \"precision\": 0.9997598964422917, \"recall\": 0.3150700254308941, \"specificity\": 0.9999999820135135, \"npv\": 0.9998372159525512, \"accuracy\": 0.9998372101618171, \"f1\": 0.47914086948690815, \"f2\": 0.365074609114114, \"f0_5\": 0.6968778788262466, \"p4\": 0.6478466567681189, \"phi\": 0.5611978881318527}, {\"truth_threshold\": 14.359999679028988, \"match_probability\": 0.9999524458190633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95710.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3148759215820451, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.685124078417955, \"precision\": 0.9997597484670908, \"recall\": 0.3148759215820451, \"specificity\": 0.9999999820135135, \"npv\": 0.9998371698283247, \"accuracy\": 0.9998371640335341, \"f1\": 0.4789163710238332, \"f2\": 0.36486611155883336, \"f0_5\": 0.6966878392995707, \"p4\": 0.6476414094227664, \"phi\": 0.5610249396235472}, {\"truth_threshold\": 14.379999678581953, \"match_probability\": 0.9999531004808055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95632.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31461930971407515, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6853806902859249, \"precision\": 0.9997595525586744, \"recall\": 0.31461930971407515, \"specificity\": 0.9999999820135135, \"npv\": 0.9998371088505404, \"accuracy\": 0.9998371030503802, \"f1\": 0.47861947469570787, \"f2\": 0.3645904419294258, \"f0_5\": 0.6964364000751551, \"p4\": 0.6473698767438264, \"phi\": 0.5607962139902778}, {\"truth_threshold\": 14.399999678134918, \"match_probability\": 0.9999537461304658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95584.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3144613947184014, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6855386052815986, \"precision\": 0.9997594318407648, \"recall\": 0.3144613947184014, \"specificity\": 0.9999999820135135, \"npv\": 0.9998370713257538, \"accuracy\": 0.9998370655222856, \"f1\": 0.4784367116485805, \"f2\": 0.36442078278181955, \"f0_5\": 0.6962815546286435, \"p4\": 0.6472026727934875, \"phi\": 0.5606554133887868}, {\"truth_threshold\": 14.419999677687883, \"match_probability\": 0.9999543828920934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95476.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31410608597813533, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6858939140218646, \"precision\": 0.9997591597817779, \"recall\": 0.31410608597813533, \"specificity\": 0.9999999820135135, \"npv\": 0.9998369868949942, \"accuracy\": 0.9998369810840726, \"f1\": 0.4780253342011716, \"f2\": 0.3640390042879704, \"f0_5\": 0.6959328354401223, \"p4\": 0.6468261657104548, \"phi\": 0.5603384827157996}, {\"truth_threshold\": 14.439999677240849, \"match_probability\": 0.9999550108880298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95409.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3138856629633407, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6861143370366594, \"precision\": 0.9997589906949451, \"recall\": 0.3138856629633407, \"specificity\": 0.9999999820135135, \"npv\": 0.9998369345166598, \"accuracy\": 0.9998369287011071, \"f1\": 0.47777001599927893, \"f2\": 0.3638021286136557, \"f0_5\": 0.6957162795378079, \"p4\": 0.6465923841144894, \"phi\": 0.5601417782144802}, {\"truth_threshold\": 14.459999676793814, \"match_probability\": 0.9999556302389335, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95301.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208660.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3135303542230747, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6864696457769254, \"precision\": 0.9997587176366917, \"recall\": 0.3135303542230747, \"specificity\": 0.9999999820135135, \"npv\": 0.9998368500859234, \"accuracy\": 0.9998368442628941, \"f1\": 0.4773582779217852, \"f2\": 0.3634202482061795, \"f0_5\": 0.6953668477666044, \"p4\": 0.646215206764327, \"phi\": 0.5598245568467631}, {\"truth_threshold\": 14.479999676346779, \"match_probability\": 0.999956241063802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95203.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3132079444402407, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6867920555597593, \"precision\": 0.9997584693256043, \"recall\": 0.3132079444402407, \"specificity\": 0.9999999820135135, \"npv\": 0.9998367734728599, \"accuracy\": 0.9998367676430341, \"f1\": 0.4769844709371798, \"f2\": 0.36307367264905765, \"f0_5\": 0.6950493892957006, \"p4\": 0.6458725945155086, \"phi\": 0.5595365522376031}, {\"truth_threshold\": 14.499999675899744, \"match_probability\": 0.9999568434799949, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95129.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208832.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3129644921552436, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6870355078447564, \"precision\": 0.9997582814864637, \"recall\": 0.3129644921552436, \"specificity\": 0.9999999820135135, \"npv\": 0.9998367156221872, \"accuracy\": 0.9998367097872215, \"f1\": 0.4767020868776512, \"f2\": 0.3628119384040836, \"f0_5\": 0.6948094348414842, \"p4\": 0.645613660816733, \"phi\": 0.5593189811295781}, {\"truth_threshold\": 14.51999967545271, \"match_probability\": 0.9999574376032573, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95036.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 208925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31265853185112563, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6873414681488743, \"precision\": 0.9997580450036293, \"recall\": 0.31265853185112563, \"specificity\": 0.9999999820135135, \"npv\": 0.9998366429179729, \"accuracy\": 0.999836637076538, \"f1\": 0.47634705027316926, \"f2\": 0.3624829602190246, \"f0_5\": 0.6945075760343877, \"p4\": 0.6452879673993274, \"phi\": 0.5590454271278461}, {\"truth_threshold\": 14.539999675005674, \"match_probability\": 0.9999580235477409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94934.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3123229624853188, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6876770375146811, \"precision\": 0.9997577851027307, \"recall\": 0.3123229624853188, \"specificity\": 0.9999999820135135, \"npv\": 0.9998365631778791, \"accuracy\": 0.9998365573293369, \"f1\": 0.47595746494266994, \"f2\": 0.362122091759161, \"f0_5\": 0.6941761274311228, \"p4\": 0.6449304003647739, \"phi\": 0.5587452462074209}, {\"truth_threshold\": 14.55999967455864, \"match_probability\": 0.9999586014260262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94853.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31205648093011934, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6879435190698807, \"precision\": 0.999757578312745, \"recall\": 0.31205648093011934, \"specificity\": 0.9999999820135135, \"npv\": 0.9998364998548724, \"accuracy\": 0.9998364940006771, \"f1\": 0.47564794640417013, \"f2\": 0.3618354797363281, \"f0_5\": 0.6939126363456798, \"p4\": 0.6446461852121813, \"phi\": 0.5585067523426981}, {\"truth_threshold\": 14.579999674111605, \"match_probability\": 0.9999591713491449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94770.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209191.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3117834195834334, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6882165804165666, \"precision\": 0.9997573660502358, \"recall\": 0.3117834195834334, \"specificity\": 0.9999999820135135, \"npv\": 0.9998364349683431, \"accuracy\": 0.9998364291083467, \"f1\": 0.47533065499029475, \"f2\": 0.36154175412413964, \"f0_5\": 0.6936423800343418, \"p4\": 0.6443547088495128, \"phi\": 0.5582622640809553}, {\"truth_threshold\": 14.59999967366457, \"match_probability\": 0.9999597334266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94694.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3115333875069499, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6884666124930501, \"precision\": 0.9997571713631133, \"recall\": 0.3115333875069499, \"specificity\": 0.9999999820135135, \"npv\": 0.9998363755541789, \"accuracy\": 0.9998363696888635, \"f1\": 0.4750400072238749, \"f2\": 0.3612727679215237, \"f0_5\": 0.6933946859316168, \"p4\": 0.644087598353621, \"phi\": 0.5580383013934218}, {\"truth_threshold\": 14.619999673217535, \"match_probability\": 0.9999602877663878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94649.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3113853421985057, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6886146578014942, \"precision\": 0.9997570559405103, \"recall\": 0.3113853421985057, \"specificity\": 0.9999999820135135, \"npv\": 0.999836340374743, \"accuracy\": 0.9998363345062747, \"f1\": 0.4748678609146759, \"f2\": 0.36111348507000296, \"f0_5\": 0.6932479209667047, \"p4\": 0.6439293431779544, \"phi\": 0.5579056495428404}, {\"truth_threshold\": 14.6399996727705, \"match_probability\": 0.9999608344750182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94581.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209380.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31116162928796787, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6888383707120321, \"precision\": 0.9997568813158006, \"recall\": 0.31116162928796787, \"specificity\": 0.9999999820135135, \"npv\": 0.9998362872147112, \"accuracy\": 0.999836281341474, \"f1\": 0.47460765496217683, \"f2\": 0.36087277022819675, \"f0_5\": 0.6930259958937655, \"p4\": 0.64369006409347, \"phi\": 0.5577051380128277}, {\"truth_threshold\": 14.659999672323465, \"match_probability\": 0.9999613736575348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94515.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3109444961689164, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6890555038310836, \"precision\": 0.9997567115868751, \"recall\": 0.3109444961689164, \"specificity\": 0.9999999820135135, \"npv\": 0.9998362356182151, \"accuracy\": 0.9998362297403437, \"f1\": 0.4743550172020507, \"f2\": 0.36063911134310456, \"f0_5\": 0.6928104287705996, \"p4\": 0.6434576637315124, \"phi\": 0.5575104549365186}, {\"truth_threshold\": 14.67999967187643, \"match_probability\": 0.999961905417536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94402.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209559.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.31057273794993434, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6894272620500657, \"precision\": 0.9997564204395023, \"recall\": 0.31057273794993434, \"specificity\": 0.9999999820135135, \"npv\": 0.999836147278772, \"accuracy\": 0.9998361413929542, \"f1\": 0.47392227638521434, \"f2\": 0.3602390043571206, \"f0_5\": 0.6924409640569139, \"p4\": 0.643059402270776, \"phi\": 0.5571769760242354}, {\"truth_threshold\": 14.699999671429396, \"match_probability\": 0.9999624298571944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94310.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3102700675415596, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6897299324584404, \"precision\": 0.9997561828840384, \"recall\": 0.3102700675415596, \"specificity\": 0.9999999820135135, \"npv\": 0.9998360753564052, \"accuracy\": 0.9998360694641061, \"f1\": 0.4735697750907621, \"f2\": 0.3599132025672867, \"f0_5\": 0.6921397988824192, \"p4\": 0.6427348142520253, \"phi\": 0.5569053236404998}, {\"truth_threshold\": 14.71999967098236, \"match_probability\": 0.999962947077276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94222.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30998055671615765, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6900194432838423, \"precision\": 0.9997559552230888, \"recall\": 0.30998055671615765, \"specificity\": 0.9999999820135135, \"npv\": 0.9998360065611074, \"accuracy\": 0.9998360006625991, \"f1\": 0.4732324475271593, \"f2\": 0.35960152325529027, \"f0_5\": 0.69185142325106, \"p4\": 0.6424240529816349, \"phi\": 0.556645358216265}, {\"truth_threshold\": 14.739999670535326, \"match_probability\": 0.99996345717716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94166.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30979632255453826, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6902036774454617, \"precision\": 0.9997558101264479, \"recall\": 0.30979632255453826, \"specificity\": 0.9999999820135135, \"npv\": 0.9998359627822865, \"accuracy\": 0.9998359568798221, \"f1\": 0.47301770689438655, \"f2\": 0.3594031600730669, \"f0_5\": 0.69166775620412, \"p4\": 0.6422261501488851, \"phi\": 0.556479862460227}, {\"truth_threshold\": 14.759999670088291, \"match_probability\": 0.999963960254858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94073.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209888.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30949036225042026, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6905096377495797, \"precision\": 0.9997555687808196, \"recall\": 0.30949036225042026, \"specificity\": 0.9999999820135135, \"npv\": 0.9998358900781816, \"accuracy\": 0.9998358841691386, \"f1\": 0.47266095056738106, \"f2\": 0.3590736980319709, \"f0_5\": 0.6913624705112847, \"p4\": 0.641897239483641, \"phi\": 0.5562049125327465}, {\"truth_threshold\": 14.779999669641256, \"match_probability\": 0.9999644564070327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93994.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 209967.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30923046048670716, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6907695395132928, \"precision\": 0.999755363391727, \"recall\": 0.30923046048670716, \"specificity\": 0.9999999820135135, \"npv\": 0.9998358283187891, \"accuracy\": 0.9998358224041495, \"f1\": 0.47235776851986794, \"f2\": 0.35879379567755665, \"f0_5\": 0.691102879436024, \"p4\": 0.6416175962261562, \"phi\": 0.555971246137753}, {\"truth_threshold\": 14.799999669194221, \"match_probability\": 0.9999649457290162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93893.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210068.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30889818101664357, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6911018189833564, \"precision\": 0.9997551003023979, \"recall\": 0.30889818101664357, \"specificity\": 0.9999999820135135, \"npv\": 0.9998357493605894, \"accuracy\": 0.9998357434387836, \"f1\": 0.47196998067241885, \"f2\": 0.3584358966528219, \"f0_5\": 0.6907706455766047, \"p4\": 0.6412597480018639, \"phi\": 0.5556723650161584}, {\"truth_threshold\": 14.819999668747187, \"match_probability\": 0.9999654283148285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93831.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210130.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3086942074805649, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.691305792519435, \"precision\": 0.9997549385215334, \"recall\": 0.3086942074805649, \"specificity\": 0.9999999820135135, \"npv\": 0.9998357008912058, \"accuracy\": 0.9998356949649946, \"f1\": 0.4717318351495042, \"f2\": 0.3582161689183308, \"f0_5\": 0.6905665043120388, \"p4\": 0.6410398953314782, \"phi\": 0.5554888138022072}, {\"truth_threshold\": 14.839999668300152, \"match_probability\": 0.9999659042571957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93744.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210217.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3084079865509062, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6915920134490938, \"precision\": 0.9997547111457122, \"recall\": 0.3084079865509062, \"specificity\": 0.9999999820135135, \"npv\": 0.9998356328777236, \"accuracy\": 0.999835626945323, \"f1\": 0.4713975380159305, \"f2\": 0.35790780621115736, \"f0_5\": 0.6902797965918981, \"p4\": 0.640731156760057, \"phi\": 0.5552311477185671}, {\"truth_threshold\": 14.859999667853117, \"match_probability\": 0.9999663736475676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93658.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30812505551699065, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6918749444830093, \"precision\": 0.9997544859683394, \"recall\": 0.30812505551699065, \"specificity\": 0.9999999820135135, \"npv\": 0.9998355656460147, \"accuracy\": 0.9998355597074867, \"f1\": 0.47106693960899504, \"f2\": 0.35760294763368394, \"f0_5\": 0.6899960953903505, \"p4\": 0.6404256961418826, \"phi\": 0.5549763257732635}, {\"truth_threshold\": 14.879999667406082, \"match_probability\": 0.9999668365761353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93598.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30792766177239844, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6920723382276016, \"precision\": 0.9997543286228517, \"recall\": 0.30792766177239844, \"specificity\": 0.9999999820135135, \"npv\": 0.9998355187401767, \"accuracy\": 0.9998355127973684, \"f1\": 0.47083620485836886, \"f2\": 0.3573902318885957, \"f0_5\": 0.6897979939420292, \"p4\": 0.6402124244681453, \"phi\": 0.5547984737279085}, {\"truth_threshold\": 14.899999666959047, \"match_probability\": 0.9999672931318484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93530.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3077039488618606, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6922960511381394, \"precision\": 0.99975415005398, \"recall\": 0.3077039488618606, \"specificity\": 0.9999999820135135, \"npv\": 0.9998354655802323, \"accuracy\": 0.9998354596325676, \"f1\": 0.47057462127120053, \"f2\": 0.3571491304776168, \"f0_5\": 0.689573309465284, \"p4\": 0.6399705578028808, \"phi\": 0.5545968391479088}, {\"truth_threshold\": 14.919999666512012, \"match_probability\": 0.9999677434024328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93443.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30741772793220185, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6925822720677982, \"precision\": 0.9997539212119916, \"recall\": 0.30741772793220185, \"specificity\": 0.9999999820135135, \"npv\": 0.9998353975667822, \"accuracy\": 0.999835391612896, \"f1\": 0.47023981762688494, \"f2\": 0.35684062597856886, \"f0_5\": 0.6892855825618707, \"p4\": 0.639660864496443, \"phi\": 0.5543387585810398}, {\"truth_threshold\": 14.939999666064978, \"match_probability\": 0.9999681874744061, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93363.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3071545362727455, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6928454637272545, \"precision\": 0.9997537104062707, \"recall\": 0.3071545362727455, \"specificity\": 0.9999999820135135, \"npv\": 0.9998353350256868, \"accuracy\": 0.9998353290660715, \"f1\": 0.46993182281481927, \"f2\": 0.3565569074952453, \"f0_5\": 0.6890207452343525, \"p4\": 0.6393758447809683, \"phi\": 0.5541013370619804}, {\"truth_threshold\": 14.959999665617943, \"match_probability\": 0.9999686254330958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93273.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3068584456558572, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6931415543441428, \"precision\": 0.9997534728176986, \"recall\": 0.3068584456558572, \"specificity\": 0.9999999820135135, \"npv\": 0.9998352646669638, \"accuracy\": 0.9998352587008941, \"f1\": 0.46958518037441754, \"f2\": 0.35623768275356343, \"f0_5\": 0.6887225040427087, \"p4\": 0.6390549175012558, \"phi\": 0.5538341162302615}, {\"truth_threshold\": 14.979999665170908, \"match_probability\": 0.9999690573626547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93213.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3066610519112649, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6933389480887351, \"precision\": 0.9997533141704921, \"recall\": 0.3066610519112649, \"specificity\": 0.9999999820135135, \"npv\": 0.999835217761154, \"accuracy\": 0.9998352117907757, \"f1\": 0.4693539981419799, \"f2\": 0.3560248418736823, \"f0_5\": 0.6885235003434751, \"p4\": 0.6388408010220502, \"phi\": 0.5536558973780646}, {\"truth_threshold\": 14.999999664723873, \"match_probability\": 0.9999694833460775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93117.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30634522191991737, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6936547780800827, \"precision\": 0.9997530599098132, \"recall\": 0.30634522191991737, \"specificity\": 0.9999999820135135, \"npv\": 0.9998351427118675, \"accuracy\": 0.9998351367345863, \"f1\": 0.46898396125922626, \"f2\": 0.3556842558808969, \"f0_5\": 0.6882048007378928, \"p4\": 0.6384979398155941, \"phi\": 0.55337062786309}, {\"truth_threshold\": 15.019999664276838, \"match_probability\": 0.999969903465216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 93037.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30608203026046105, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.693917969739539, \"precision\": 0.999752847625188, \"recall\": 0.30608203026046105, \"specificity\": 0.9999999820135135, \"npv\": 0.999835080170804, \"accuracy\": 0.9998350741877619, \"f1\": 0.46867546049201425, \"f2\": 0.35540039605654805, \"f0_5\": 0.687938941231971, \"p4\": 0.6382119634334577, \"phi\": 0.553132790914234}, {\"truth_threshold\": 15.039999663829803, \"match_probability\": 0.9999703178007961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92969.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 210992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3058583173499232, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6941416826500768, \"precision\": 0.9997526668960771, \"recall\": 0.3058583173499232, \"specificity\": 0.9999999820135135, \"npv\": 0.9998350270109062, \"accuracy\": 0.9998350210229611, \"f1\": 0.4684131370716432, \"f2\": 0.3551590879223982, \"f0_5\": 0.6877127627309969, \"p4\": 0.6379686983574898, \"phi\": 0.5529305490954622}, {\"truth_threshold\": 15.059999663382769, \"match_probability\": 0.9999707264324323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92876.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211085.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30555235704580525, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6944476429541948, \"precision\": 0.9997524192940721, \"recall\": 0.30555235704580525, \"specificity\": 0.9999999820135135, \"npv\": 0.9998349543069375, \"accuracy\": 0.9998349483122777, \"f1\": 0.46805422567152144, \"f2\": 0.3548290229632556, \"f0_5\": 0.6874031354867168, \"p4\": 0.6376357217861172, \"phi\": 0.5526538338760979}, {\"truth_threshold\": 15.079999662935734, \"match_probability\": 0.9999711294386433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92799.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211162.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30529903507357853, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6947009649264215, \"precision\": 0.9997522139148047, \"recall\": 0.30529903507357853, \"specificity\": 0.9999999820135135, \"npv\": 0.9998348941111864, \"accuracy\": 0.9998348881109591, \"f1\": 0.4677569351509515, \"f2\": 0.3545557078735139, \"f0_5\": 0.6871465192839975, \"p4\": 0.6373597900904964, \"phi\": 0.5524246207160429}, {\"truth_threshold\": 15.099999662488699, \"match_probability\": 0.999971526896867, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92743.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3051148009119591, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6948851990880409, \"precision\": 0.9997520643339154, \"recall\": 0.3051148009119591, \"specificity\": 0.9999999820135135, \"npv\": 0.9998348503324629, \"accuracy\": 0.999834844328182, \"f1\": 0.4675406513799162, \"f2\": 0.3543569130604229, \"f0_5\": 0.6869597422317691, \"p4\": 0.637158974971825, \"phi\": 0.5522578604995813}, {\"truth_threshold\": 15.119999662041664, \"match_probability\": 0.9999719188834754, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92623.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211338.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3047200134227746, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6952799865772253, \"precision\": 0.9997517431945254, \"recall\": 0.3047200134227746, \"specificity\": 0.9999999820135135, \"npv\": 0.9998347565209255, \"accuracy\": 0.9998347505079453, \"f1\": 0.4670769804869808, \"f2\": 0.3539308668770873, \"f0_5\": 0.6865590879778221, \"p4\": 0.6367282663863606, \"phi\": 0.5519003475551247}, {\"truth_threshold\": 15.13999966159463, \"match_probability\": 0.9999723054737893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92556.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211405.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30449959040797997, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.69550040959202, \"precision\": 0.9997515635295261, \"recall\": 0.30449959040797997, \"specificity\": 0.9999999820135135, \"npv\": 0.9998347041428247, \"accuracy\": 0.9998346981249798, \"f1\": 0.46681797548797094, \"f2\": 0.3536929570941507, \"f0_5\": 0.6863351411956807, \"p4\": 0.6364875554952245, \"phi\": 0.5517006354035016}, {\"truth_threshold\": 15.159999661147594, \"match_probability\": 0.9999726867420932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92510.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211451.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3043482552037926, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6956517447962074, \"precision\": 0.9997514400268013, \"recall\": 0.3043482552037926, \"specificity\": 0.9999999820135135, \"npv\": 0.9998346681817437, \"accuracy\": 0.9998346621605557, \"f1\": 0.46664010048071347, \"f2\": 0.35352960194194794, \"f0_5\": 0.6861812835914333, \"p4\": 0.6363221949627246, \"phi\": 0.5515634777432041}, {\"truth_threshold\": 15.17999966070056, \"match_probability\": 0.9999730627616485, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92476.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30423639874852365, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6957636012514763, \"precision\": 0.9997513486632288, \"recall\": 0.30423639874852365, \"specificity\": 0.9999999820135135, \"npv\": 0.999834641601816, \"accuracy\": 0.9998346355781553, \"f1\": 0.4665086011199112, \"f2\": 0.353408853794456, \"f0_5\": 0.6860675087579772, \"p4\": 0.6361999215103225, \"phi\": 0.5514620784230536}, {\"truth_threshold\": 15.199999660253525, \"match_probability\": 0.9999734336047086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92404.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.303999526255013, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.696000473744987, \"precision\": 0.9997511549655403, \"recall\": 0.303999526255013, \"specificity\": 0.9999999820135135, \"npv\": 0.999834585314915, \"accuracy\": 0.9998345792860134, \"f1\": 0.46623005741848894, \"f2\": 0.35315313111732966, \"f0_5\": 0.6858264221746881, \"p4\": 0.6359408478253004, \"phi\": 0.5512472888980856}, {\"truth_threshold\": 15.21999965980649, \"match_probability\": 0.9999737993425322, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92310.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3036902760551518, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6963097239448481, \"precision\": 0.9997509016278037, \"recall\": 0.3036902760551518, \"specificity\": 0.9999999820135135, \"npv\": 0.9998345118292481, \"accuracy\": 0.9998345057934946, \"f1\": 0.46586625081378974, \"f2\": 0.3528192285906265, \"f0_5\": 0.6855113598388815, \"p4\": 0.6356023227897872, \"phi\": 0.5509667432562927}, {\"truth_threshold\": 15.239999659359455, \"match_probability\": 0.9999741600453972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92229.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211732.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30342379449995227, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6965762055000477, \"precision\": 0.9997506829120236, \"recall\": 0.30342379449995227, \"specificity\": 0.9999999820135135, \"npv\": 0.9998344485065013, \"accuracy\": 0.9998344424648349, \"f1\": 0.4655526194244005, \"f2\": 0.35253146558050785, \"f0_5\": 0.6852395875590109, \"p4\": 0.635310351316603, \"phi\": 0.5507248818799799}, {\"truth_threshold\": 15.25999965891242, \"match_probability\": 0.9999745157826142, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92164.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211797.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.303209951276644, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6967900487233559, \"precision\": 0.9997505071213946, \"recall\": 0.303209951276644, \"specificity\": 0.9999999820135135, \"npv\": 0.9998343976919571, \"accuracy\": 0.99983439164554, \"f1\": 0.4653008471581328, \"f2\": 0.35230051887149466, \"f0_5\": 0.6850213093625922, \"p4\": 0.6350758764377337, \"phi\": 0.5505307187671773}, {\"truth_threshold\": 15.279999658465385, \"match_probability\": 0.99997486662254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92082.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3029401798257013, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6970598201742987, \"precision\": 0.9997502850008143, \"recall\": 0.3029401798257013, \"specificity\": 0.9999999820135135, \"npv\": 0.9998343335874627, \"accuracy\": 0.9998343275350449, \"f1\": 0.4649831088757934, \"f2\": 0.35200913797097594, \"f0_5\": 0.6847457022134772, \"p4\": 0.6347798525488456, \"phi\": 0.5502856768326089}, {\"truth_threshold\": 15.29999965801835, \"match_probability\": 0.9999752126325899, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 92008.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 211953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30269672754070426, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6973032724592958, \"precision\": 0.9997500842107551, \"recall\": 0.30269672754070426, \"specificity\": 0.9999999820135135, \"npv\": 0.9998342757370723, \"accuracy\": 0.9998342696792323, \"f1\": 0.4646962564900301, \"f2\": 0.3517461531109624, \"f0_5\": 0.6844967526428949, \"p4\": 0.6345124934939739, \"phi\": 0.5500644477495943}, {\"truth_threshold\": 15.319999657571316, \"match_probability\": 0.999975553879252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91885.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212076.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3022920703642902, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6977079296357098, \"precision\": 0.9997497497497497, \"recall\": 0.3022920703642902, \"specificity\": 0.9999999820135135, \"npv\": 0.9998341795803571, \"accuracy\": 0.9998341735134897, \"f1\": 0.4642192240362342, \"f2\": 0.3513089637790651, \"f0_5\": 0.6840824725689517, \"p4\": 0.6340676463034481, \"phi\": 0.5496965322076058}, {\"truth_threshold\": 15.339999657124281, \"match_probability\": 0.9999758904280986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91776.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212185.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30193347172828094, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6980665282717191, \"precision\": 0.9997494526084162, \"recall\": 0.30193347172828094, \"specificity\": 0.9999999820135135, \"npv\": 0.9998340943683243, \"accuracy\": 0.9998340882934413, \"f1\": 0.46379624014554277, \"f2\": 0.35092146709767114, \"f0_5\": 0.6837148387039098, \"p4\": 0.6336729585269121, \"phi\": 0.549370287367419}, {\"truth_threshold\": 15.359999656677246, \"match_probability\": 0.9999762223437998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91699.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212262.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30168014975605423, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6983198502439457, \"precision\": 0.9997492422755718, \"recall\": 0.30168014975605423, \"specificity\": 0.9999999820135135, \"npv\": 0.9998340341726768, \"accuracy\": 0.9998340280921229, \"f1\": 0.4634972945514465, \"f2\": 0.3506476919711892, \"f0_5\": 0.6834548460234717, \"p4\": 0.6333938737360323, \"phi\": 0.5491397040403871}, {\"truth_threshold\": 15.379999656230211, \"match_probability\": 0.9999765496901353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91593.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3013314208072746, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6986685791927254, \"precision\": 0.9997489521480964, \"recall\": 0.3013314208072746, \"specificity\": 0.9999999820135135, \"npv\": 0.9998339513059531, \"accuracy\": 0.9998339452175804, \"f1\": 0.4630855686756308, \"f2\": 0.3502707539810013, \"f0_5\": 0.6830965432374986, \"p4\": 0.6330093146662068, \"phi\": 0.5488221192093894}, {\"truth_threshold\": 15.399999655783176, \"match_probability\": 0.9999768725300071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91532.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212429.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30113073716693917, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6988692628330608, \"precision\": 0.9997487848834035, \"recall\": 0.30113073716693917, \"specificity\": 0.9999999820135135, \"npv\": 0.9998339036185051, \"accuracy\": 0.9998338975256268, \"f1\": 0.46284853204421567, \"f2\": 0.3500538091278944, \"f0_5\": 0.6828901446027267, \"p4\": 0.6327878201839442, \"phi\": 0.548639274814436}, {\"truth_threshold\": 15.419999655336142, \"match_probability\": 0.9999771909254513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91459.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212502.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.30089057477768527, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6991094252223147, \"precision\": 0.999748584420979, \"recall\": 0.30089057477768527, \"specificity\": 0.9999999820135135, \"npv\": 0.9998338465499258, \"accuracy\": 0.9998338404516495, \"f1\": 0.4625647691323402, \"f2\": 0.3497941599876389, \"f0_5\": 0.6826429453237776, \"p4\": 0.6325225687844466, \"phi\": 0.5484203809246476}, {\"truth_threshold\": 15.439999654889107, \"match_probability\": 0.99997750493765, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91406.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212555.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3007162103032955, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6992837896967045, \"precision\": 0.9997484386791937, \"recall\": 0.3007162103032955, \"specificity\": 0.9999999820135135, \"npv\": 0.9998338051165778, \"accuracy\": 0.9998337990143782, \"f1\": 0.462358683831154, \"f2\": 0.34960562942858914, \"f0_5\": 0.6824633368026676, \"p4\": 0.6323298631071179, \"phi\": 0.5482614032209059}, {\"truth_threshold\": 15.459999654442072, \"match_probability\": 0.9999778146269432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91359.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212602.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3005615852033649, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.699438414796635, \"precision\": 0.9997483092950472, \"recall\": 0.3005615852033649, \"specificity\": 0.9999999820135135, \"npv\": 0.9998337683738003, \"accuracy\": 0.9998337622681188, \"f1\": 0.4621758827145036, \"f2\": 0.3494384291622107, \"f0_5\": 0.6823039661592648, \"p4\": 0.6321588844825542, \"phi\": 0.5481203844285052}, {\"truth_threshold\": 15.479999653995037, \"match_probability\": 0.9999781200528404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91283.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212678.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3003115531268814, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6996884468731186, \"precision\": 0.9997480997962894, \"recall\": 0.3003115531268814, \"specificity\": 0.9999999820135135, \"npv\": 0.9998337089599532, \"accuracy\": 0.9998337028486356, \"f1\": 0.46188019743616343, \"f2\": 0.34916803733312934, \"f0_5\": 0.6820460709669225, \"p4\": 0.6318822318602129, \"phi\": 0.5478922772644271}, {\"truth_threshold\": 15.499999653548002, \"match_probability\": 0.9999784212740318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91208.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.3000648109461411, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.6999351890538589, \"precision\": 0.9997478927119071, \"recall\": 0.3000648109461411, \"specificity\": 0.9999999820135135, \"npv\": 0.9998336503278741, \"accuracy\": 0.9998336442109876, \"f1\": 0.4615882912609567, \"f2\": 0.3489011724652373, \"f0_5\": 0.681791339318418, \"p4\": 0.6316090052973091, \"phi\": 0.5476670783957386}, {\"truth_threshold\": 15.519999653100967, \"match_probability\": 0.9999787183483999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91120.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29977530012073916, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.7002246998792608, \"precision\": 0.9997476492983554, \"recall\": 0.29977530012073916, \"specificity\": 0.9999999820135135, \"npv\": 0.99983358153291, \"accuracy\": 0.9998335754094808, \"f1\": 0.4612456467158014, \"f2\": 0.3485880119695146, \"f0_5\": 0.6814921626905478, \"p4\": 0.6312881479438576, \"phi\": 0.5474027269648427}, {\"truth_threshold\": 15.539999652653933, \"match_probability\": 0.9999790113330304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91047.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29953513773148527, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.7004648622685147, \"precision\": 0.9997474470187767, \"recall\": 0.29953513773148527, \"specificity\": 0.9999999820135135, \"npv\": 0.9998335244643675, \"accuracy\": 0.9998335183355035, \"f1\": 0.4609612916454658, \"f2\": 0.34832819910108853, \"f0_5\": 0.681243742901139, \"p4\": 0.6310217594375723, \"phi\": 0.5471833385511897}, {\"truth_threshold\": 15.559999652206898, \"match_probability\": 0.9999793002842231, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90993.0, \"tn\": 1278737769.0, \"fp\": 23.0, \"fn\": 212968.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29935748336135226, \"tn_rate\": 0.9999999820135135, \"fp_rate\": 1.798648647431232e-08, \"fn_rate\": 0.7006425166386477, \"precision\": 0.9997472971785181, \"recall\": 0.29935748336135226, \"specificity\": 0.9999999820135135, \"npv\": 0.9998334822492854, \"accuracy\": 0.999833476116397, \"f1\": 0.4607508791651159, \"f2\": 0.3481359900830999, \"f0_5\": 0.6810598405748288, \"p4\": 0.6308245748054288, \"phi\": 0.5470209946308643}, {\"truth_threshold\": 15.579999651759863, \"match_probability\": 0.999979585257503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90886.0, \"tn\": 1278737770.0, \"fp\": 22.0, \"fn\": 213075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29900546451682947, \"tn_rate\": 0.9999999827955347, \"fp_rate\": 1.720446532325526e-08, \"fn_rate\": 0.7009945354831706, \"precision\": 0.9997579970959651, \"recall\": 0.29900546451682947, \"specificity\": 0.9999999827955347, \"npv\": 0.9998333986010228, \"accuracy\": 0.9998333932418546, \"f1\": 0.4603349465265696, \"f2\": 0.34775535067097657, \"f0_5\": 0.6806991685053618, \"p4\": 0.6304346231880202, \"phi\": 0.54670217888716}, {\"truth_threshold\": 15.599999651312828, \"match_probability\": 0.9999798663076307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90814.0, \"tn\": 1278737770.0, \"fp\": 22.0, \"fn\": 213147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2987685920233188, \"tn_rate\": 0.9999999827955347, \"fp_rate\": 1.720446532325526e-08, \"fn_rate\": 0.7012314079766813, \"precision\": 0.9997578052754414, \"recall\": 0.2987685920233188, \"specificity\": 0.9999999827955347, \"npv\": 0.9998333423142618, \"accuracy\": 0.9998333369497125, \"f1\": 0.46005415441353403, \"f2\": 0.3474990051121927, \"f0_5\": 0.6804534658064902, \"p4\": 0.6301712449628366, \"phi\": 0.5464855190825442}, {\"truth_threshold\": 15.619999650865793, \"match_probability\": 0.9999801434886131, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90740.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2985251397383217, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7014748602616783, \"precision\": 0.999779638607316, \"recall\": 0.2985251397383217, \"specificity\": 0.9999999843595769, \"npv\": 0.9998332844642469, \"accuracy\": 0.9998332806575705, \"f1\": 0.4597677853471186, \"f2\": 0.3472360409121662, \"f0_5\": 0.6802088752490626, \"p4\": 0.6299025314047644, \"phi\": 0.5462687725925779}, {\"truth_threshold\": 15.639999650418758, \"match_probability\": 0.9999804168537135, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90641.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213320.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2981994400597445, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7018005599402555, \"precision\": 0.9997793979770795, \"recall\": 0.2981994400597445, \"specificity\": 0.9999999843595769, \"npv\": 0.9998332070699698, \"accuracy\": 0.9998332032558752, \"f1\": 0.4593813826902707, \"f2\": 0.3468834792059732, \"f0_5\": 0.6798703880108911, \"p4\": 0.6295397843431281, \"phi\": 0.5459706067796404}, {\"truth_threshold\": 15.659999649971724, \"match_probability\": 0.9999806864554623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90584.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29801191600238186, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7019880839976181, \"precision\": 0.9997792591938546, \"recall\": 0.29801191600238186, \"specificity\": 0.9999999843595769, \"npv\": 0.9998331625096339, \"accuracy\": 0.9998331586912629, \"f1\": 0.4591588204731793, \"f2\": 0.34668046489412513, \"f0_5\": 0.6796753189260734, \"p4\": 0.6293307602080686, \"phi\": 0.5457988616855814}, {\"truth_threshold\": 15.679999649524689, \"match_probability\": 0.9999809523456668, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90461.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213500.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2976072588259678, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7023927411740322, \"precision\": 0.999778959118489, \"recall\": 0.2976072588259678, \"specificity\": 0.9999999843595769, \"npv\": 0.9998330663531331, \"accuracy\": 0.9998330625255202, \"f1\": 0.45867833547137477, \"f2\": 0.34624232101506136, \"f0_5\": 0.6792539252273291, \"p4\": 0.6288792848148906, \"phi\": 0.5454280696441356}, {\"truth_threshold\": 15.699999649077654, \"match_probability\": 0.9999812145754207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90412.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213549.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2974460539345508, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7025539460654492, \"precision\": 0.999778839348903, \"recall\": 0.2974460539345508, \"specificity\": 0.9999999843595769, \"npv\": 0.99983302804689, \"accuracy\": 0.9998330242155903, \"f1\": 0.45848683926945966, \"f2\": 0.3460677529097985, \"f0_5\": 0.679085879442202, \"p4\": 0.6286992674298506, \"phi\": 0.5452802855309127}, {\"truth_threshold\": 15.719999648630619, \"match_probability\": 0.9999814731951148, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90313.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213648.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2971203542559736, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7028796457440264, \"precision\": 0.9997785969689925, \"recall\": 0.2971203542559736, \"specificity\": 0.9999999843595769, \"npv\": 0.9998329506526527, \"accuracy\": 0.999832946813895, \"f1\": 0.458099793555063, \"f2\": 0.34571501412136335, \"f0_5\": 0.6787460562489008, \"p4\": 0.6283352779610994, \"phi\": 0.5449815790587401}, {\"truth_threshold\": 15.739999648183584, \"match_probability\": 0.9999817282544463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90258.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213703.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29693940999009744, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7030605900099026, \"precision\": 0.9997784620837856, \"recall\": 0.29693940999009744, \"specificity\": 0.9999999843595769, \"npv\": 0.9998329076558593, \"accuracy\": 0.9998329038129532, \"f1\": 0.45788468416366723, \"f2\": 0.34551902502216486, \"f0_5\": 0.6785570907253791, \"p4\": 0.6281328990501364, \"phi\": 0.5448155602729594}, {\"truth_threshold\": 15.75999964773655, \"match_probability\": 0.9999819798024282, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90179.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213782.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2966795082263843, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7033204917736157, \"precision\": 0.9997782680517522, \"recall\": 0.2966795082263843, \"specificity\": 0.9999999843595769, \"npv\": 0.9998328458968353, \"accuracy\": 0.999832842047964, \"f1\": 0.45757560381570933, \"f2\": 0.3452374845238633, \"f0_5\": 0.6782854486677087, \"p4\": 0.6278420059489784, \"phi\": 0.5445770083923435}, {\"truth_threshold\": 15.779999647289515, \"match_probability\": 0.9999822278873987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90089.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29638341760949594, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7036165823905041, \"precision\": 0.9997780465880212, \"recall\": 0.29638341760949594, \"specificity\": 0.9999999843595769, \"npv\": 0.9998327755384628, \"accuracy\": 0.9998327716827865, \"f1\": 0.4572233359555409, \"f2\": 0.34491670067758945, \"f0_5\": 0.6779756681622584, \"p4\": 0.627510316167843, \"phi\": 0.5443051130633894}, {\"truth_threshold\": 15.79999964684248, \"match_probability\": 0.9999824725570307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 90017.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29614654511598526, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7038534548840147, \"precision\": 0.9997778690982596, \"recall\": 0.29614654511598526, \"specificity\": 0.9999999843595769, \"npv\": 0.999832719251772, \"accuracy\": 0.9998327153906444, \"f1\": 0.45694140579393805, \"f2\": 0.3446600417649081, \"f0_5\": 0.6777276019448615, \"p4\": 0.627244739693367, \"phi\": 0.5440874989989081}, {\"truth_threshold\": 15.819999646395445, \"match_probability\": 0.9999827138583409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89962.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 213999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29596560085010903, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.704034399149891, \"precision\": 0.9997777333244426, \"recall\": 0.29596560085010903, \"specificity\": 0.9999999843595769, \"npv\": 0.9998326762549985, \"accuracy\": 0.9998326723897026, \"f1\": 0.45672597304686213, \"f2\": 0.34446396380528493, \"f0_5\": 0.6775379619183327, \"p4\": 0.6270417340910865, \"phi\": 0.5439212073939325}, {\"truth_threshold\": 15.83999964594841, \"match_probability\": 0.9999829518376988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89886.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29571556877362554, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7042844312263744, \"precision\": 0.9997775454363447, \"recall\": 0.29571556877362554, \"specificity\": 0.9999999843595769, \"npv\": 0.9998326168412813, \"accuracy\": 0.9998326129702194, \"f1\": 0.4564281851487939, \"f2\": 0.344192992533027, \"f0_5\": 0.6772757069554013, \"p4\": 0.6267610250841376, \"phi\": 0.5436913389557521}, {\"truth_threshold\": 15.859999645501375, \"match_probability\": 0.9999831865408356, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89811.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29546882659288526, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7045311734071147, \"precision\": 0.9997773597087865, \"recall\": 0.29546882659288526, \"specificity\": 0.9999999843595769, \"npv\": 0.9998325582093304, \"accuracy\": 0.9998325543325715, \"f1\": 0.45613420282788886, \"f2\": 0.3439255557470274, \"f0_5\": 0.6770166670435785, \"p4\": 0.6264837907814493, \"phi\": 0.5434643998124941}, {\"truth_threshold\": 15.87999964505434, \"match_probability\": 0.999983418012853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89742.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214219.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2952418237866042, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7047581762133958, \"precision\": 0.9997771885653172, \"recall\": 0.2952418237866042, \"specificity\": 0.9999999843595769, \"npv\": 0.9998325042679417, \"accuracy\": 0.9998325003859354, \"f1\": 0.4558636401734214, \"f2\": 0.3436794867670645, \"f0_5\": 0.6767781432831228, \"p4\": 0.6262285430065256, \"phi\": 0.5432555320956614}, {\"truth_threshold\": 15.899999644607306, \"match_probability\": 0.9999836462982317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89624.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29485361608890615, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7051463839110939, \"precision\": 0.9997768952746419, \"recall\": 0.29485361608890615, \"specificity\": 0.9999999843595769, \"npv\": 0.9998324120203629, \"accuracy\": 0.9998324081293694, \"f1\": 0.45540071899493145, \"f2\": 0.3432586128712022, \"f0_5\": 0.6763697725560988, \"p4\": 0.6257916048564013, \"phi\": 0.542898151864368}, {\"truth_threshold\": 15.91999964416027, \"match_probability\": 0.9999838714408402, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89514.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214447.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2944917275571537, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7055082724428463, \"precision\": 0.9997766211718453, \"recall\": 0.2944917275571537, \"specificity\": 0.9999999843595769, \"npv\": 0.9998323260268724, \"accuracy\": 0.9998323221274857, \"f1\": 0.45496893226089274, \"f2\": 0.3428662042718661, \"f0_5\": 0.6759885636092596, \"p4\": 0.625383803025769, \"phi\": 0.5425647888573596}, {\"truth_threshold\": 15.939999643713236, \"match_probability\": 0.9999840934839433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89447.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29427130454235906, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7057286954576409, \"precision\": 0.9997764538880257, \"recall\": 0.29427130454235906, \"specificity\": 0.9999999843595769, \"npv\": 0.9998322736490265, \"accuracy\": 0.9998322697445202, \"f1\": 0.45470581656618236, \"f2\": 0.34262715935129634, \"f0_5\": 0.6757561243160998, \"p4\": 0.6251351841920991, \"phi\": 0.5423616400981476}, {\"truth_threshold\": 15.959999643266201, \"match_probability\": 0.9999843124702101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89371.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214590.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29402127246587556, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7059787275341245, \"precision\": 0.999776263829692, \"recall\": 0.29402127246587556, \"specificity\": 0.9999999843595769, \"npv\": 0.9998322142353571, \"accuracy\": 0.999832210325037, \"f1\": 0.45440724846956415, \"f2\": 0.34235597421154046, \"f0_5\": 0.6754922338535958, \"p4\": 0.6248529573298258, \"phi\": 0.5421311105757199}, {\"truth_threshold\": 15.979999642819166, \"match_probability\": 0.9999845284417223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89322.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29386006757445854, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7061399324255414, \"precision\": 0.9997761411206375, \"recall\": 0.29386006757445854, \"specificity\": 0.9999999843595769, \"npv\": 0.9998321759291793, \"accuracy\": 0.999832172015107, \"f1\": 0.45421468943791427, \"f2\": 0.34218111441587634, \"f0_5\": 0.675321965315297, \"p4\": 0.6246708759739926, \"phi\": 0.5419824277243249}, {\"truth_threshold\": 15.999999642372131, \"match_probability\": 0.9999847414399821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89223.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2935343678958814, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7064656321041186, \"precision\": 0.9997758927871093, \"recall\": 0.2935343678958814, \"specificity\": 0.9999999843595769, \"npv\": 0.9998320985350738, \"accuracy\": 0.9998320946134117, \"f1\": 0.45382549516281623, \"f2\": 0.34182778619356413, \"f0_5\": 0.6749776452378683, \"p4\": 0.6243027115959638, \"phi\": 0.5416819031887044}, {\"truth_threshold\": 16.019999641925097, \"match_probability\": 0.9999849515059211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89156.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214805.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2933139448810867, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7066860551189132, \"precision\": 0.9997757244101552, \"recall\": 0.2933139448810867, \"specificity\": 0.9999999843595769, \"npv\": 0.9998320461572517, \"accuracy\": 0.9998320422304462, \"f1\": 0.4535619898406917, \"f2\": 0.3415886346569401, \"f0_5\": 0.6747443863380079, \"p4\": 0.624053332716563, \"phi\": 0.5414784232863079}, {\"truth_threshold\": 16.03999964147806, \"match_probability\": 0.9999851586799067, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 89056.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2929849553067663, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7070150446932336, \"precision\": 0.9997754726301136, \"recall\": 0.2929849553067663, \"specificity\": 0.9999999843595769, \"npv\": 0.9998319679814079, \"accuracy\": 0.9998319640469157, \"f1\": 0.4531685312069856, \"f2\": 0.3412316463844527, \"f0_5\": 0.6743958865001174, \"p4\": 0.6236807989535309, \"phi\": 0.5411745796668526}, {\"truth_threshold\": 16.059999641031027, \"match_probability\": 0.9999853630017509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88969.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 214992.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2926987343771076, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7073012656228924, \"precision\": 0.9997752531211723, \"recall\": 0.2926987343771076, \"specificity\": 0.9999999843595769, \"npv\": 0.9998318999684339, \"accuracy\": 0.9998318960272441, \"f1\": 0.4528260592950757, \"f2\": 0.3409210220771547, \"f0_5\": 0.674092347977094, \"p4\": 0.6233563761007276, \"phi\": 0.5409100969193981}, {\"truth_threshold\": 16.079999640583992, \"match_probability\": 0.9999855645107176, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88918.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2925309496942042, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7074690503057958, \"precision\": 0.9997751242438553, \"recall\": 0.2925309496942042, \"specificity\": 0.9999999843595769, \"npv\": 0.9998318600987637, \"accuracy\": 0.9998318561536435, \"f1\": 0.452625229384651, \"f2\": 0.34073891270725687, \"f0_5\": 0.6739142627172725, \"p4\": 0.6231660592400476, \"phi\": 0.5407549951839833}, {\"truth_threshold\": 16.099999640136957, \"match_probability\": 0.9999857632455306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88820.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2922085399113702, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7077914600886298, \"precision\": 0.9997748761819001, \"recall\": 0.2922085399113702, \"specificity\": 0.9999999843595769, \"npv\": 0.9998317834864652, \"accuracy\": 0.9998317795337835, \"f1\": 0.452239174543853, \"f2\": 0.3403889370912803, \"f0_5\": 0.6735717503310223, \"p4\": 0.6228000657723521, \"phi\": 0.5404568316462509}, {\"truth_threshold\": 16.119999639689922, \"match_probability\": 0.99998595924438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88770.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215191.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29204404512421, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.70795595487579, \"precision\": 0.9997747494087172, \"recall\": 0.29204404512421, \"specificity\": 0.9999999843595769, \"npv\": 0.9998317443985624, \"accuracy\": 0.9998317404420183, \"f1\": 0.4520421335655415, \"f2\": 0.34021035784748827, \"f0_5\": 0.6733968421579649, \"p4\": 0.6226131890369431, \"phi\": 0.5403046440200548}, {\"truth_threshold\": 16.139999639242887, \"match_probability\": 0.9999861525449308, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88699.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215262.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29181046252644255, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7081895374735575, \"precision\": 0.999774569145279, \"recall\": 0.29181046252644255, \"specificity\": 0.9999999843595769, \"npv\": 0.9998316888937455, \"accuracy\": 0.9998316849317115, \"f1\": 0.45176224915962104, \"f2\": 0.33995675180117785, \"f0_5\": 0.6731482900929973, \"p4\": 0.6223476551063952, \"phi\": 0.540088463928299}, {\"truth_threshold\": 16.159999638795853, \"match_probability\": 0.999986343184329, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88597.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215364.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.29147489316063574, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7085251068393643, \"precision\": 0.9997743096697022, \"recall\": 0.29147489316063574, \"specificity\": 0.9999999843595769, \"npv\": 0.999831609154442, \"accuracy\": 0.9998316051845103, \"f1\": 0.4513599845126319, \"f2\": 0.33959236803553344, \"f0_5\": 0.672790840014641, \"p4\": 0.6219658363599638, \"phi\": 0.5397777438518072}, {\"truth_threshold\": 16.179999638348818, \"match_probability\": 0.9999865311992094, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88520.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215441.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.291221571188409, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7087784288115909, \"precision\": 0.9997741133950757, \"recall\": 0.291221571188409, \"specificity\": 0.9999999843595769, \"npv\": 0.999831548959094, \"accuracy\": 0.9998315449831918, \"f1\": 0.45105617565305567, \"f2\": 0.33931725626809284, \"f0_5\": 0.6725207066785591, \"p4\": 0.6216773288822925, \"phi\": 0.5395430621603396}, {\"truth_threshold\": 16.199999637901783, \"match_probability\": 0.9999867166257028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88428.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215533.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2909189007800343, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7090810992199658, \"precision\": 0.9997738784370478, \"recall\": 0.2909189007800343, \"specificity\": 0.9999999843595769, \"npv\": 0.9998314770373888, \"accuracy\": 0.9998314730543437, \"f1\": 0.45069302691834284, \"f2\": 0.3389885087081727, \"f0_5\": 0.6721976182548768, \"p4\": 0.6213323116538297, \"phi\": 0.5392625293808275}, {\"truth_threshold\": 16.219999637454748, \"match_probability\": 0.9999868994994422, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88348.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.290655709120578, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7093442908794221, \"precision\": 0.9997736737280464, \"recall\": 0.290655709120578, \"specificity\": 0.9999999843595769, \"npv\": 0.999831414496784, \"accuracy\": 0.9998314105075192, \"f1\": 0.450377106968896, \"f2\": 0.3387026035644512, \"f0_5\": 0.6719163777905885, \"p4\": 0.6210320246245441, \"phi\": 0.5390184691866129}, {\"truth_threshold\": 16.239999637007713, \"match_probability\": 0.9999870798555704, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88281.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215680.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2904352861057833, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7095647138942167, \"precision\": 0.9997735019988448, \"recall\": 0.2904352861057833, \"specificity\": 0.9999999843595769, \"npv\": 0.9998313621190336, \"accuracy\": 0.9998313581245537, \"f1\": 0.45011242485889535, \"f2\": 0.33846313101687314, \"f0_5\": 0.671680628152747, \"p4\": 0.6207803392681532, \"phi\": 0.5388139837351716}, {\"truth_threshold\": 16.25999963656068, \"match_probability\": 0.9999872577287463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88199.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215762.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2901655146548406, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7098344853451594, \"precision\": 0.9997732914678243, \"recall\": 0.2901655146548406, \"specificity\": 0.9999999843595769, \"npv\": 0.9998312980149285, \"accuracy\": 0.9998312940140587, \"f1\": 0.4497883624866133, \"f2\": 0.33817001172489364, \"f0_5\": 0.6713918369397582, \"p4\": 0.6204720642859145, \"phi\": 0.5385636123285391}, {\"truth_threshold\": 16.279999636113644, \"match_probability\": 0.9999874331531516, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88120.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2899056128911275, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7100943871088725, \"precision\": 0.9997730882686635, \"recall\": 0.2899056128911275, \"specificity\": 0.9999999843595769, \"npv\": 0.9998312362561034, \"accuracy\": 0.9998312322490696, \"f1\": 0.44947602786016866, \"f2\": 0.3378875814427171, \"f0_5\": 0.67111333833952, \"p4\": 0.6201748152655732, \"phi\": 0.5383222907475962}, {\"truth_threshold\": 16.29999963566661, \"match_probability\": 0.9999876061624977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88062.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28971479893802166, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7102852010619783, \"precision\": 0.999772938852433, \"recall\": 0.28971479893802166, \"specificity\": 0.9999999843595769, \"npv\": 0.9998311909141859, \"accuracy\": 0.9998311869026217, \"f1\": 0.4492466387615644, \"f2\": 0.3376802057785488, \"f0_5\": 0.6709087002829546, \"p4\": 0.619956423947788, \"phi\": 0.538145049070156}, {\"truth_threshold\": 16.319999635219574, \"match_probability\": 0.9999877767900316, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88016.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 215945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2895634637338343, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7104365362661658, \"precision\": 0.9997728202099141, \"recall\": 0.2895634637338343, \"specificity\": 0.9999999843595769, \"npv\": 0.9998311549533578, \"accuracy\": 0.9998311509381977, \"f1\": 0.4490646612091419, \"f2\": 0.3375157223057337, \"f0_5\": 0.6707462982297041, \"p4\": 0.6197831219070165, \"phi\": 0.5380044365766492}, {\"truth_threshold\": 16.33999963477254, \"match_probability\": 0.9999879450685429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87948.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216013.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2893397508232964, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7106602491767036, \"precision\": 0.9997726445980356, \"recall\": 0.2893397508232964, \"specificity\": 0.9999999843595769, \"npv\": 0.9998311017938776, \"accuracy\": 0.999831097773397, \"f1\": 0.4487955726674985, \"f2\": 0.33727255156418257, \"f0_5\": 0.6705060587070184, \"p4\": 0.6195267819868829, \"phi\": 0.5377965073044304}, {\"truth_threshold\": 16.359999634325504, \"match_probability\": 0.9999881110303698, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87885.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216076.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28913248739147457, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7108675126085254, \"precision\": 0.9997724816563336, \"recall\": 0.28913248739147457, \"specificity\": 0.9999999843595769, \"npv\": 0.9998310525431876, \"accuracy\": 0.9998310485177727, \"f1\": 0.44854618670668034, \"f2\": 0.3370472383871435, \"f0_5\": 0.6702833059530401, \"p4\": 0.6192891261701415, \"phi\": 0.5376037952006982}, {\"truth_threshold\": 16.37999963387847, \"match_probability\": 0.9999882747074051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87804.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28886600583627503, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7111339941637249, \"precision\": 0.99977227181636, \"recall\": 0.28886600583627503, \"specificity\": 0.9999999843595769, \"npv\": 0.9998309892208791, \"accuracy\": 0.999830985189113, \"f1\": 0.4482254297637735, \"f2\": 0.3367575180183912, \"f0_5\": 0.6699966577999167, \"p4\": 0.6189833360552923, \"phi\": 0.5373559209709379}, {\"truth_threshold\": 16.399999633431435, \"match_probability\": 0.9999884361311029, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87713.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28856662532364347, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7114333746763565, \"precision\": 0.9997720356080381, \"recall\": 0.28856662532364347, \"specificity\": 0.9999999843595769, \"npv\": 0.9998309180810112, \"accuracy\": 0.9998309140421001, \"f1\": 0.4478649149591263, \"f2\": 0.33643198675644015, \"f0_5\": 0.6696742826690772, \"p4\": 0.6186394815102613, \"phi\": 0.5370773085649608}, {\"truth_threshold\": 16.4199996329844, \"match_probability\": 0.999988595332484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87618.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216343.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28825408522803914, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7117459147719609, \"precision\": 0.9997717884935758, \"recall\": 0.28825408522803914, \"specificity\": 0.9999999843595769, \"npv\": 0.999830843814127, \"accuracy\": 0.999830839767746, \"f1\": 0.44748837458726914, \"f2\": 0.336092097934609, \"f0_5\": 0.6693373546438344, \"p4\": 0.618280159118272, \"phi\": 0.5367862952173694}, {\"truth_threshold\": 16.439999632537365, \"match_probability\": 0.9999887523421424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87526.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216435.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28795141481966435, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7120485851803356, \"precision\": 0.9997715486715555, \"recall\": 0.28795141481966435, \"specificity\": 0.9999999843595769, \"npv\": 0.9998307718925232, \"accuracy\": 0.9998307678388979, \"f1\": 0.4471235507921953, \"f2\": 0.33576289521938946, \"f0_5\": 0.6690106933478052, \"p4\": 0.6179318392002345, \"phi\": 0.5365043213518816}, {\"truth_threshold\": 16.45999963209033, \"match_probability\": 0.9999889071902507, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87433.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2876454545155464, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7123545454844536, \"precision\": 0.9997713057299349, \"recall\": 0.2876454545155464, \"specificity\": 0.9999999843595769, \"npv\": 0.9998306991891736, \"accuracy\": 0.9998306951282144, \"f1\": 0.4467545872145605, \"f2\": 0.3354300669762917, \"f0_5\": 0.6686801076214527, \"p4\": 0.6175793881160004, \"phi\": 0.5362191318905082}, {\"truth_threshold\": 16.479999631643295, \"match_probability\": 0.9999890599065664, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87355.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216606.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2873888426475765, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7126111573524235, \"precision\": 0.9997711015736767, \"recall\": 0.2873888426475765, \"specificity\": 0.9999999843595769, \"npv\": 0.9998306382121787, \"accuracy\": 0.9998306341450607, \"f1\": 0.4464449986712186, \"f2\": 0.3351508840801124, \"f0_5\": 0.6684025519503076, \"p4\": 0.6172835160880882, \"phi\": 0.535979823753998}, {\"truth_threshold\": 16.49999963119626, \"match_probability\": 0.9999892105204371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87260.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28707630255197214, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7129236974480279, \"precision\": 0.9997708524289642, \"recall\": 0.28707630255197214, \"specificity\": 0.9999999843595769, \"npv\": 0.999830563945336, \"accuracy\": 0.9998305598707066, \"f1\": 0.44606776897104344, \"f2\": 0.3348108084879106, \"f0_5\": 0.6680641451826037, \"p4\": 0.6169228285696273, \"phi\": 0.5356882143600505}, {\"truth_threshold\": 16.519999630749226, \"match_probability\": 0.9999893590608068, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87207.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2869019380775823, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7130980619224176, \"precision\": 0.9997707131966019, \"recall\": 0.2869019380775823, \"specificity\": 0.9999999843595769, \"npv\": 0.9998305225122601, \"accuracy\": 0.9998305184334354, \"f1\": 0.4458572348845057, \"f2\": 0.33462106055617846, \"f0_5\": 0.6678751786346112, \"p4\": 0.6167214449439097, \"phi\": 0.5355254580273776}, {\"truth_threshold\": 16.53999963030219, \"match_probability\": 0.9999895055562203, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87123.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2866255868351532, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7133744131648468, \"precision\": 0.999770492179521, \"recall\": 0.2866255868351532, \"specificity\": 0.9999999843595769, \"npv\": 0.9998304568447507, \"accuracy\": 0.9998304527592697, \"f1\": 0.44552344133529703, \"f2\": 0.33432029636519783, \"f0_5\": 0.6675754329666086, \"p4\": 0.6164020388694468, \"phi\": 0.5352674032489521}, {\"truth_threshold\": 16.559999629855156, \"match_probability\": 0.9999896500348305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 87042.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 216919.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2863591052799537, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7136408947200463, \"precision\": 0.9997702786519951, \"recall\": 0.2863591052799537, \"specificity\": 0.9999999843595769, \"npv\": 0.9998303935225177, \"accuracy\": 0.99983038943061, \"f1\": 0.4452014331637781, \"f2\": 0.33403023702400636, \"f0_5\": 0.6672861000078196, \"p4\": 0.6160937703756232, \"phi\": 0.5350184468660463}, {\"truth_threshold\": 16.57999962940812, \"match_probability\": 0.9999897925244019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86954.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217007.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2860695944545517, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7139304055454483, \"precision\": 0.9997700462207096, \"recall\": 0.2860695944545517, \"specificity\": 0.9999999843595769, \"npv\": 0.9998303247280019, \"accuracy\": 0.999830320629103, \"f1\": 0.44485144589253967, \"f2\": 0.33371506994837347, \"f0_5\": 0.6669714369869465, \"p4\": 0.6157585607925621, \"phi\": 0.5347478444086939}, {\"truth_threshold\": 16.599999628961086, \"match_probability\": 0.999989933052317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86869.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217092.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2857899533163794, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7142100466836206, \"precision\": 0.9997698212662132, \"recall\": 0.2857899533163794, \"specificity\": 0.9999999843595769, \"npv\": 0.9998302582787628, \"accuracy\": 0.999830254173102, \"f1\": 0.44451324037354484, \"f2\": 0.33341060677821166, \"f0_5\": 0.666667178293122, \"p4\": 0.6154344811811375, \"phi\": 0.5344863369947259}, {\"truth_threshold\": 16.61999962851405, \"match_probability\": 0.9999900716455815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86817.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217144.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2856188787377328, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7143811212622672, \"precision\": 0.9997696834298744, \"recall\": 0.2856188787377328, \"specificity\": 0.9999999843595769, \"npv\": 0.9998302176274679, \"accuracy\": 0.9998302135176661, \"f1\": 0.4443062656410729, \"f2\": 0.3332243273679435, \"f0_5\": 0.6664808869522761, \"p4\": 0.6152360763514525, \"phi\": 0.5343262929074157}, {\"truth_threshold\": 16.639999628067017, \"match_probability\": 0.9999902083308292, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86721.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217240.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28530304874638523, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7146969512536148, \"precision\": 0.9997694285286082, \"recall\": 0.28530304874638523, \"specificity\": 0.9999999843595769, \"npv\": 0.9998301425789322, \"accuracy\": 0.9998301384614768, \"f1\": 0.4439240136984198, \"f2\": 0.3328803878441714, \"f0_5\": 0.6661366516879825, \"p4\": 0.6148695022428028, \"phi\": 0.5340307009230838}, {\"truth_threshold\": 16.65999962761998, \"match_probability\": 0.9999903431343274, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86648.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217313.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28506288635713134, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7149371136428686, \"precision\": 0.999769234319472, \"recall\": 0.28506288635713134, \"specificity\": 0.9999999843595769, \"npv\": 0.9998300855107825, \"accuracy\": 0.9998300813874995, \"f1\": 0.4436332171958559, \"f2\": 0.3326188165636862, \"f0_5\": 0.6658746174878926, \"p4\": 0.6145905025786146, \"phi\": 0.5338058183246801}, {\"truth_threshold\": 16.679999627172947, \"match_probability\": 0.9999904760819817, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86592.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217369.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28487865219551195, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7151213478044881, \"precision\": 0.9997690851152266, \"recall\": 0.28487865219551195, \"specificity\": 0.9999999843595769, \"npv\": 0.9998300417324801, \"accuracy\": 0.9998300376047223, \"f1\": 0.44341006674808553, \"f2\": 0.33241813926919606, \"f0_5\": 0.665673445478153, \"p4\": 0.6143763285216043, \"phi\": 0.5336332414290099}, {\"truth_threshold\": 16.699999626725912, \"match_probability\": 0.999990607199341, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86504.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217457.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28458914137011, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7154108586298901, \"precision\": 0.9997688502611992, \"recall\": 0.28458914137011, \"specificity\": 0.9999999843595769, \"npv\": 0.9998299729380128, \"accuracy\": 0.9998299688032154, \"f1\": 0.44305927244324367, \"f2\": 0.3321027543674292, \"f0_5\": 0.66535703792129, \"p4\": 0.6140395112759053, \"phi\": 0.5333619363759357}, {\"truth_threshold\": 16.719999626278877, \"match_probability\": 0.9999907365116024, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86389.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217572.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28421080335964155, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7157891966403584, \"precision\": 0.9997685426286613, \"recall\": 0.28421080335964155, \"specificity\": 0.9999999843595769, \"npv\": 0.9998298830361664, \"accuracy\": 0.9998298788921552, \"f1\": 0.4426006096779978, \"f2\": 0.33169053939595455, \"f0_5\": 0.6649430339117945, \"p4\": 0.6135988763943312, \"phi\": 0.5330071819038571}, {\"truth_threshold\": 16.739999625831842, \"match_probability\": 0.9999908640436167, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86328.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2840101197193061, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7159898802806939, \"precision\": 0.9997683791170612, \"recall\": 0.2840101197193061, \"specificity\": 0.9999999843595769, \"npv\": 0.9998298353491066, \"accuracy\": 0.9998298312002016, \"f1\": 0.44235720928802563, \"f2\": 0.3314718566847285, \"f0_5\": 0.6647231937020388, \"p4\": 0.6133649291225604, \"phi\": 0.5328189119462653}, {\"truth_threshold\": 16.759999625384808, \"match_probability\": 0.9999909898198919, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86251.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217710.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2837567977470794, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7162432022529206, \"precision\": 0.999768172387013, \"recall\": 0.2837567977470794, \"specificity\": 0.9999999843595769, \"npv\": 0.9998297751539721, \"accuracy\": 0.9998297709988831, \"f1\": 0.4420498575206544, \"f2\": 0.3311957853185011, \"f0_5\": 0.6644454544754216, \"p4\": 0.6130694013811115, \"phi\": 0.5325811647013516}, {\"truth_threshold\": 16.779999624937773, \"match_probability\": 0.9999911138645989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86176.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217785.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2835100555663391, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7164899444336609, \"precision\": 0.9997679706714929, \"recall\": 0.2835100555663391, \"specificity\": 0.9999999843595769, \"npv\": 0.9998297165223545, \"accuracy\": 0.9998297123612352, \"f1\": 0.4417503722860284, \"f2\": 0.330926853245676, \"f0_5\": 0.6641746757200441, \"p4\": 0.6127813163446615, \"phi\": 0.5323494906602062}, {\"truth_threshold\": 16.799999624490738, \"match_probability\": 0.999991236201576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86065.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28314487713884345, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7168551228611565, \"precision\": 0.9997676714874834, \"recall\": 0.28314487713884345, \"specificity\": 0.9999999843595769, \"npv\": 0.9998296297475731, \"accuracy\": 0.9998296255775162, \"f1\": 0.4413069227732114, \"f2\": 0.33052877691487015, \"f0_5\": 0.6637734632524089, \"p4\": 0.6123545273061405, \"phi\": 0.5320064279803346}, {\"truth_threshold\": 16.819999624043703, \"match_probability\": 0.9999913568543333, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 86009.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 217952.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28296064297722406, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.717039357022776, \"precision\": 0.9997675202547978, \"recall\": 0.28296064297722406, \"specificity\": 0.9999999843595769, \"npv\": 0.9998295859693107, \"accuracy\": 0.9998295817947391, \"f1\": 0.4410831046949922, \"f2\": 0.330327919850861, \"f0_5\": 0.663570841119188, \"p4\": 0.6121390183765603, \"phi\": 0.5318332673509854}, {\"truth_threshold\": 16.83999962359667, \"match_probability\": 0.9999914758460567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85943.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2827435098581726, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7172564901418274, \"precision\": 0.9997673417633168, \"recall\": 0.2827435098581726, \"specificity\": 0.9999999843595769, \"npv\": 0.9998295343735064, \"accuracy\": 0.999829530193609, \"f1\": 0.4408192365691776, \"f2\": 0.3300911732691559, \"f0_5\": 0.6633318565697199, \"p4\": 0.6118848602475039, \"phi\": 0.5316291127920596}, {\"truth_threshold\": 16.859999623149633, \"match_probability\": 0.9999915931996138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85859.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28246715861574345, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7175328413842565, \"precision\": 0.9997671141955542, \"recall\": 0.28246715861574345, \"specificity\": 0.9999999843595769, \"npv\": 0.9998294687061268, \"accuracy\": 0.9998294645194432, \"f1\": 0.44048327518982144, \"f2\": 0.32978982471693286, \"f0_5\": 0.6630274125567395, \"p4\": 0.6115611270603564, \"phi\": 0.5313691663054331}, {\"truth_threshold\": 16.8799996227026, \"match_probability\": 0.9999917089375568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85797.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2822631850796648, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7177368149203351, \"precision\": 0.9997669459431116, \"recall\": 0.2822631850796648, \"specificity\": 0.9999999843595769, \"npv\": 0.9998294202373521, \"accuracy\": 0.9998294160456543, \"f1\": 0.44023521081230854, \"f2\": 0.32956737583748763, \"f0_5\": 0.6628025011240226, \"p4\": 0.6113219947095695, \"phi\": 0.5311772194645085}, {\"truth_threshold\": 16.899999622255564, \"match_probability\": 0.9999918230821278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85694.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28192432581811483, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7180756741818852, \"precision\": 0.9997666658888863, \"recall\": 0.28192432581811483, \"specificity\": 0.9999999843595769, \"npv\": 0.9998293397166562, \"accuracy\": 0.9998293355166178, \"f1\": 0.43982292936421374, \"f2\": 0.32919777681824397, \"f0_5\": 0.6624284766788752, \"p4\": 0.6109243759694533, \"phi\": 0.5308581866531953}, {\"truth_threshold\": 16.91999962180853, \"match_probability\": 0.9999919356552621, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85612.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2816545543671721, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7183454456328279, \"precision\": 0.99976644245142, \"recall\": 0.2816545543671721, \"specificity\": 0.9999999843595769, \"npv\": 0.9998292756128105, \"accuracy\": 0.9998292714061228, \"f1\": 0.43949454944005667, \"f2\": 0.3289034911131669, \"f0_5\": 0.6621303688075125, \"p4\": 0.6106075118706109, \"phi\": 0.5306040622579272}, {\"truth_threshold\": 16.939999621361494, \"match_probability\": 0.9999920466785936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85572.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28152295853744397, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7184770414625561, \"precision\": 0.9997663333021778, \"recall\": 0.28152295853744397, \"specificity\": 0.9999999843595769, \"npv\": 0.9998292443426449, \"accuracy\": 0.9998292401327105, \"f1\": 0.439334313944444, \"f2\": 0.3287599236535642, \"f0_5\": 0.6619848405378684, \"p4\": 0.6104528431252589, \"phi\": 0.5304800549741885}, {\"truth_threshold\": 16.95999962091446, \"match_probability\": 0.9999921561734584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85506.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2813058254183925, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7186941745816076, \"precision\": 0.9997661529827188, \"recall\": 0.2813058254183925, \"specificity\": 0.9999999843595769, \"npv\": 0.9998291927468758, \"accuracy\": 0.9998291885315803, \"f1\": 0.4390698534225789, \"f2\": 0.3285230180502086, \"f0_5\": 0.661744561305751, \"p4\": 0.6101974949100735, \"phi\": 0.5302753795724944}, {\"truth_threshold\": 16.979999620467424, \"match_probability\": 0.9999922641608986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85424.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2810360539674498, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7189639460325502, \"precision\": 0.9997659285613969, \"recall\": 0.2810360539674498, \"specificity\": 0.9999999843595769, \"npv\": 0.9998291286430488, \"accuracy\": 0.9998291244210853, \"f1\": 0.43874115637960476, \"f2\": 0.32822864730943496, \"f0_5\": 0.661445758877066, \"p4\": 0.6098799926844557, \"phi\": 0.5300209758188964}, {\"truth_threshold\": 16.99999962002039, \"match_probability\": 0.9999923706616665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85343.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218618.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.28076957241225026, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7192304275877498, \"precision\": 0.9997657064536157, \"recall\": 0.28076957241225026, \"specificity\": 0.9999999843595769, \"npv\": 0.999829065320984, \"accuracy\": 0.9998290610924255, \"f1\": 0.43841633189836743, \"f2\": 0.32793783003011817, \"f0_5\": 0.6611503022095929, \"p4\": 0.6095660885845531, \"phi\": 0.5297695546391754}, {\"truth_threshold\": 17.019999619573355, \"match_probability\": 0.9999924756962293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85252.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218709.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2804701918996187, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7195298081003813, \"precision\": 0.9997654564218031, \"recall\": 0.2804701918996187, \"specificity\": 0.9999999843595769, \"npv\": 0.9998289941813899, \"accuracy\": 0.9998289899454127, \"f1\": 0.4380512443703386, \"f2\": 0.32761106619240715, \"f0_5\": 0.6608180153755762, \"p4\": 0.6092131058010168, \"phi\": 0.5294869514429902}, {\"truth_threshold\": 17.03999961912632, \"match_probability\": 0.9999925792847717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85167.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218794.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2801905507614464, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7198094492385536, \"precision\": 0.9997652223930882, \"recall\": 0.2801905507614464, \"specificity\": 0.9999999843595769, \"npv\": 0.9998289277323277, \"accuracy\": 0.9998289234894117, \"f1\": 0.43771007431619846, \"f2\": 0.32730580593390934, \"f0_5\": 0.6605072986417128, \"p4\": 0.6088830854611338, \"phi\": 0.5292228451488888}, {\"truth_threshold\": 17.059999618679285, \"match_probability\": 0.9999926814472012, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85088.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2799306489977333, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7200693510022668, \"precision\": 0.9997650044649151, \"recall\": 0.2799306489977333, \"specificity\": 0.9999999843595769, \"npv\": 0.9998288659737954, \"accuracy\": 0.9998288617244225, \"f1\": 0.43739285319570564, \"f2\": 0.32702205769313547, \"f0_5\": 0.660218220868321, \"p4\": 0.6085760908398722, \"phi\": 0.5289772634546719}, {\"truth_threshold\": 17.07999961823225, \"match_probability\": 0.9999927822031508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85015.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 218946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2796904866084794, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7203095133915206, \"precision\": 0.9997648027282884, \"recall\": 0.2796904866084794, \"specificity\": 0.9999999843595769, \"npv\": 0.9998288089057913, \"accuracy\": 0.9998288046504452, \"f1\": 0.4370996102787689, \"f2\": 0.32675982931540903, \"f0_5\": 0.6599508462182173, \"p4\": 0.608292180875319, \"phi\": 0.5287502321650518}, {\"truth_threshold\": 17.099999617785215, \"match_probability\": 0.9999928815719834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84935.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219026.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2794272949490231, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7205727050509769, \"precision\": 0.9997645812488964, \"recall\": 0.2794272949490231, \"specificity\": 0.9999999843595769, \"npv\": 0.9998287463655203, \"accuracy\": 0.9998287421036207, \"f1\": 0.4367781217537977, \"f2\": 0.3264724219498939, \"f0_5\": 0.6596575543546641, \"p4\": 0.6079807911027626, \"phi\": 0.5285013187782284}, {\"truth_threshold\": 17.11999961733818, \"match_probability\": 0.9999929795727952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84836.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219125.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27910159527044587, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7208984047295541, \"precision\": 0.9997643065899877, \"recall\": 0.27910159527044587, \"specificity\": 0.9999999843595769, \"npv\": 0.9998286689719458, \"accuracy\": 0.9998286647019254, \"f1\": 0.4363800965492764, \"f2\": 0.3261167063888675, \"f0_5\": 0.6592942017609985, \"p4\": 0.6075950757530836, \"phi\": 0.52819312610674}, {\"truth_threshold\": 17.139999616891146, \"match_probability\": 0.9999930762244198, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84762.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219199.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2788581429854488, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7211418570145512, \"precision\": 0.9997641008704677, \"recall\": 0.2788581429854488, \"specificity\": 0.9999999843595769, \"npv\": 0.9998286111222111, \"accuracy\": 0.9998286068461129, \"f1\": 0.43608245035923476, \"f2\": 0.3258507826231369, \"f0_5\": 0.6590223126192487, \"p4\": 0.6073064952446167, \"phi\": 0.5279626424038107}, {\"truth_threshold\": 17.15999961644411, \"match_probability\": 0.9999931715454312, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84670.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.278555472577074, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.721444527422926, \"precision\": 0.9997638446097532, \"recall\": 0.278555472577074, \"specificity\": 0.9999999843595769, \"npv\": 0.9998285392009286, \"accuracy\": 0.9998285349172648, \"f1\": 0.43571224569086403, \"f2\": 0.32552013249941947, \"f0_5\": 0.6586839390653176, \"p4\": 0.6069473992845481, \"phi\": 0.5276759547513803}, {\"truth_threshold\": 17.179999615997076, \"match_probability\": 0.9999932655541479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84576.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219385.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27824622237721286, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7217537776227871, \"precision\": 0.9997635822024682, \"recall\": 0.27824622237721286, \"specificity\": 0.9999999843595769, \"npv\": 0.9998284657161507, \"accuracy\": 0.999828461424746, \"f1\": 0.435333812027579, \"f2\": 0.3251822460090431, \"f0_5\": 0.6583378091212666, \"p4\": 0.6065801298082768, \"phi\": 0.527382873837988}, {\"truth_threshold\": 17.19999961555004, \"match_probability\": 0.9999933582686362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84493.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219468.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27797316103052694, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7220268389694731, \"precision\": 0.9997633500171571, \"recall\": 0.27797316103052694, \"specificity\": 0.9999999843595769, \"npv\": 0.9998284008306642, \"accuracy\": 0.9998283965324156, \"f1\": 0.43499951090677885, \"f2\": 0.3248838588172325, \"f0_5\": 0.6580318467071539, \"p4\": 0.6062555297860936, \"phi\": 0.5271239541978433}, {\"truth_threshold\": 17.219999615103006, \"match_probability\": 0.9999934497067136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84387.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2776244320817473, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7223755679182526, \"precision\": 0.9997630528273721, \"recall\": 0.2776244320817473, \"specificity\": 0.9999999843595769, \"npv\": 0.9998283179648745, \"accuracy\": 0.9998283136578732, \"f1\": 0.43457236435545665, \"f2\": 0.32450273062662516, \"f0_5\": 0.6576406391007327, \"p4\": 0.6058405584889347, \"phi\": 0.5267931007482738}, {\"truth_threshold\": 17.23999961465597, \"match_probability\": 0.9999935398859523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84326.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219635.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2774237484414119, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7225762515585881, \"precision\": 0.999762881464444, \"recall\": 0.2774237484414119, \"specificity\": 0.9999999843595769, \"npv\": 0.999828270277964, \"accuracy\": 0.9998282659659196, \"f1\": 0.43432644788788255, \"f2\": 0.32428337396842, \"f0_5\": 0.6574152757096414, \"p4\": 0.6056015394475687, \"phi\": 0.5266026097459247}, {\"truth_threshold\": 17.259999614208937, \"match_probability\": 0.9999936288236828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84247.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219714.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2771638466776988, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7228361533223012, \"precision\": 0.9997626591666964, \"recall\": 0.2771638466776988, \"specificity\": 0.9999999843595769, \"npv\": 0.9998282085195129, \"accuracy\": 0.9998282042009304, \"f1\": 0.4340078510565956, \"f2\": 0.323999258524849, \"f0_5\": 0.657123156674659, \"p4\": 0.6052917566756008, \"phi\": 0.526355805855492}, {\"truth_threshold\": 17.279999613761902, \"match_probability\": 0.9999937165369968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84157.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27686775606081043, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7231322439391895, \"precision\": 0.9997624054076529, \"recall\": 0.27686775606081043, \"specificity\": 0.9999999843595769, \"npv\": 0.9998281381617931, \"accuracy\": 0.9998281338357529, \"f1\": 0.43364473460470243, \"f2\": 0.3236755406258822, \"f0_5\": 0.6567900116909043, \"p4\": 0.6049385180502821, \"phi\": 0.5260744958118188}, {\"truth_threshold\": 17.299999613314867, \"match_probability\": 0.9999938030427508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84091.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27665062294175896, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.723349377058241, \"precision\": 0.9997622189725481, \"recall\": 0.27665062294175896, \"specificity\": 0.9999999843595769, \"npv\": 0.9998280865661382, \"accuracy\": 0.9998280822346227, \"f1\": 0.4333783421633099, \"f2\": 0.32343811901181196, \"f0_5\": 0.6565454673214607, \"p4\": 0.6046792584557351, \"phi\": 0.5258681061633284}, {\"truth_threshold\": 17.319999612867832, \"match_probability\": 0.9999938883575692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84028.0, \"tn\": 1278737772.0, \"fp\": 20.0, \"fn\": 219933.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27644335950993715, \"tn_rate\": 0.9999999843595769, \"fp_rate\": 1.5640423021141147e-08, \"fn_rate\": 0.7235566404900629, \"precision\": 0.9997620407386255, \"recall\": 0.27644335950993715, \"specificity\": 0.9999999843595769, \"npv\": 0.9998280373157453, \"accuracy\": 0.9998280329789985, \"f1\": 0.4331239739284398, \"f2\": 0.3232114667987802, \"f0_5\": 0.6563118504482522, \"p4\": 0.6044316111603097, \"phi\": 0.5256710222906897}, {\"truth_threshold\": 17.339999612420797, \"match_probability\": 0.9999939724978475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83914.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2760683113952119, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7239316886047881, \"precision\": 0.9997736289659609, \"recall\": 0.2760683113952119, \"specificity\": 0.9999999851415982, \"npv\": 0.9998279481961336, \"accuracy\": 0.999827944631609, \"f1\": 0.4326645939354566, \"f2\": 0.32280152672343027, \"f0_5\": 0.6558927485528214, \"p4\": 0.6039841461954081, \"phi\": 0.5253173370665088}, {\"truth_threshold\": 17.359999611973763, \"match_probability\": 0.9999940554797557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83816.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220145.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2757459016123779, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7242540983876221, \"precision\": 0.9997733643466332, \"recall\": 0.2757459016123779, \"specificity\": 0.9999999851415982, \"npv\": 0.9998278715844348, \"accuracy\": 0.9998278680117489, \"f1\": 0.4322685123105963, \"f2\": 0.32244885083162844, \"f0_5\": 0.6555284599898952, \"p4\": 0.6035981073507921, \"phi\": 0.5250104086608024}, {\"truth_threshold\": 17.379999611526728, \"match_probability\": 0.9999941373192409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83738.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.275489289744408, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.724510710255592, \"precision\": 0.9997731532886803, \"recall\": 0.275489289744408, \"specificity\": 0.9999999851415982, \"npv\": 0.9998278106077848, \"accuracy\": 0.9998278070285951, \"f1\": 0.43195312056701, \"f2\": 0.3221681115973287, \"f0_5\": 0.6552381965886737, \"p4\": 0.6032905597470247, \"phi\": 0.5247659904368708}, {\"truth_threshold\": 17.399999611079693, \"match_probability\": 0.9999942180320309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83638.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220323.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27516030017008763, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7248396998299124, \"precision\": 0.9997728821258233, \"recall\": 0.27516030017008763, \"specificity\": 0.9999999851415982, \"npv\": 0.9998277324326035, \"accuracy\": 0.9998277288450645, \"f1\": 0.4315485864949512, \"f2\": 0.3218081402015081, \"f0_5\": 0.6548656491107739, \"p4\": 0.6028958885136865, \"phi\": 0.5244524671499154}, {\"truth_threshold\": 17.419999610632658, \"match_probability\": 0.9999942976336369, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83530.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27480499142982157, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7251950085701784, \"precision\": 0.9997725885408563, \"recall\": 0.27480499142982157, \"specificity\": 0.9999999851415982, \"npv\": 0.9998276480034214, \"accuracy\": 0.9998276444068515, \"f1\": 0.4311114551882532, \"f2\": 0.32141930886190706, \"f0_5\": 0.6544627732673934, \"p4\": 0.6024691639870067, \"phi\": 0.5241136514004723}, {\"truth_threshold\": 17.439999610185623, \"match_probability\": 0.9999943761393564, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83465.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220496.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2745911482065133, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7254088517934867, \"precision\": 0.999772411480044, \"recall\": 0.2745911482065133, \"specificity\": 0.9999999851415982, \"npv\": 0.9998275971895687, \"accuracy\": 0.9998275935875567, \"f1\": 0.4308482494289512, \"f2\": 0.32118525884149346, \"f0_5\": 0.6542200386582787, \"p4\": 0.6022120986108208, \"phi\": 0.5239096289202662}, {\"truth_threshold\": 17.45999960973859, \"match_probability\": 0.9999944535642766, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83408.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220553.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2744036241491507, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7255963758508492, \"precision\": 0.9997722559842737, \"recall\": 0.2744036241491507, \"specificity\": 0.9999999851415982, \"npv\": 0.9998275526297329, \"accuracy\": 0.9998275490229442, \"f1\": 0.4306173655353289, \"f2\": 0.32097999570528396, \"f0_5\": 0.6540070161792403, \"p4\": 0.6019865231814242, \"phi\": 0.5237306515089843}, {\"truth_threshold\": 17.479999609291553, \"match_probability\": 0.9999945299232769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83309.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220652.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27407792447057355, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7259220755294264, \"precision\": 0.999771985407066, \"recall\": 0.27407792447057355, \"specificity\": 0.9999999851415982, \"npv\": 0.9998274752363432, \"accuracy\": 0.999827471621249, \"f1\": 0.43021619514109616, \"f2\": 0.32062344323923236, \"f0_5\": 0.6536366674878741, \"p4\": 0.6015944032623565, \"phi\": 0.5234196505888941}, {\"truth_threshold\": 17.49999960884452, \"match_probability\": 0.9999946052310316, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83217.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220744.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27377525406219877, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7262247459378013, \"precision\": 0.9997717333845932, \"recall\": 0.27377525406219877, \"specificity\": 0.9999999851415982, \"npv\": 0.9998274033152241, \"accuracy\": 0.9998273996924009, \"f1\": 0.4298432064298019, \"f2\": 0.3202920528373926, \"f0_5\": 0.6532920922272553, \"p4\": 0.6012296318626009, \"phi\": 0.5231304739335125}, {\"truth_threshold\": 17.519999608397484, \"match_probability\": 0.9999946795020134, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83164.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220797.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.273600889587809, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7263991104121911, \"precision\": 0.9997715879446522, \"recall\": 0.273600889587809, \"specificity\": 0.9999999851415982, \"npv\": 0.9998273618824103, \"accuracy\": 0.9998273582551296, \"f1\": 0.4296282520199202, \"f2\": 0.32010112183965383, \"f0_5\": 0.6530934060842509, \"p4\": 0.601019326662915, \"phi\": 0.522963810460419}, {\"truth_threshold\": 17.53999960795045, \"match_probability\": 0.9999947527504954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83078.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2733179585538934, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7266820414461066, \"precision\": 0.9997713515530043, \"recall\": 0.2733179585538934, \"specificity\": 0.9999999851415982, \"npv\": 0.999827294651814, \"accuracy\": 0.9998272910172933, \"f1\": 0.4292793328131701, \"f2\": 0.31979127612416575, \"f0_5\": 0.6527707280124586, \"p4\": 0.6006778194974841, \"phi\": 0.5226932623456114}, {\"truth_threshold\": 17.559999607503414, \"match_probability\": 0.9999948249905545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82975.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 220986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27297909929234343, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7270209007076566, \"precision\": 0.9997710677880328, \"recall\": 0.27297909929234343, \"specificity\": 0.9999999851415982, \"npv\": 0.9998272141314605, \"accuracy\": 0.9998272104882568, \"f1\": 0.4288612370947526, \"f2\": 0.31942012783734386, \"f0_5\": 0.6523838053140484, \"p4\": 0.6002683856727773, \"phi\": 0.52236904942782}, {\"truth_threshold\": 17.57999960705638, \"match_probability\": 0.9999948962360736, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82909.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221052.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27276196617329196, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.727238033826708, \"precision\": 0.9997708855874976, \"recall\": 0.27276196617329196, \"specificity\": 0.9999999851415982, \"npv\": 0.999827162535901, \"accuracy\": 0.9998271588871267, \"f1\": 0.42859321407432105, \"f2\": 0.31918227371701885, \"f0_5\": 0.6521356106048235, \"p4\": 0.600005789365439, \"phi\": 0.5221611955485524}, {\"truth_threshold\": 17.599999606609344, \"match_probability\": 0.9999949665007445, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82829.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27249877451383564, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7275012254861644, \"precision\": 0.9997706643491696, \"recall\": 0.27249877451383564, \"specificity\": 0.9999999851415982, \"npv\": 0.9998270999958361, \"accuracy\": 0.9998270963403022, \"f1\": 0.4282682150622142, \"f2\": 0.3188939332805623, \"f0_5\": 0.6518344920068057, \"p4\": 0.5996872384689712, \"phi\": 0.5219091405008717}, {\"truth_threshold\": 17.61999960616231, \"match_probability\": 0.9999950357980707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82743.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2722158434799201, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7277841565200799, \"precision\": 0.9997704260409367, \"recall\": 0.2722158434799201, \"specificity\": 0.9999999851415982, \"npv\": 0.999827032765275, \"accuracy\": 0.9998270291024659, \"f1\": 0.42791869115620224, \"f2\": 0.31858392768861377, \"f0_5\": 0.6515104510329774, \"p4\": 0.5993444874387588, \"phi\": 0.521638045522848}, {\"truth_threshold\": 17.639999605715275, \"match_probability\": 0.9999951041413695, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82638.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221323.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2718704044268837, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7281295955731163, \"precision\": 0.9997701344108787, \"recall\": 0.2718704044268837, \"specificity\": 0.9999999851415982, \"npv\": 0.9998269506814627, \"accuracy\": 0.9998269470097588, \"f1\": 0.427491736028845, \"f2\": 0.3182053768152662, \"f0_5\": 0.6511143432993638, \"p4\": 0.5989255778775613, \"phi\": 0.5213068663806124}, {\"truth_threshold\": 17.65999960526824, \"match_probability\": 0.999995171543775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82576.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221385.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27166643089080506, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7283335691091949, \"precision\": 0.9997699618620982, \"recall\": 0.27166643089080506, \"specificity\": 0.9999999851415982, \"npv\": 0.9998269022129321, \"accuracy\": 0.9998268985359698, \"f1\": 0.4272395202764929, \"f2\": 0.31798182278874865, \"f0_5\": 0.6508802048109771, \"p4\": 0.5986779971408146, \"phi\": 0.5211112141764873}, {\"truth_threshold\": 17.679999604821205, \"match_probability\": 0.9999952380182406, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82499.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221462.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2714131089185784, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7285868910814216, \"precision\": 0.9997697472066701, \"recall\": 0.2714131089185784, \"specificity\": 0.9999999851415982, \"npv\": 0.9998268420181508, \"accuracy\": 0.9998268383346512, \"f1\": 0.4269261719265471, \"f2\": 0.31770415338711394, \"f0_5\": 0.6505891649172835, \"p4\": 0.5983702853445757, \"phi\": 0.5208681244744278}, {\"truth_threshold\": 17.69999960437417, \"match_probability\": 0.9999953035775414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82433.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2711959757995269, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7288040242004731, \"precision\": 0.9997695628972008, \"recall\": 0.2711959757995269, \"specificity\": 0.9999999851415982, \"npv\": 0.9998267904226297, \"accuracy\": 0.9998267867335211, \"f1\": 0.4266574882315036, \"f2\": 0.3174661248282364, \"f0_5\": 0.6503394770018729, \"p4\": 0.5981063271322482, \"phi\": 0.5206596715627357}, {\"truth_threshold\": 17.719999603927135, \"match_probability\": 0.9999953682342764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82349.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221612.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2709196245570978, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7290803754429022, \"precision\": 0.9997693278943279, \"recall\": 0.2709196245570978, \"specificity\": 0.9999999851415982, \"npv\": 0.9998267247556106, \"accuracy\": 0.9998267210593554, \"f1\": 0.42631539439182664, \"f2\": 0.31716314438627896, \"f0_5\": 0.650021391370516, \"p4\": 0.597770105971126, \"phi\": 0.5203942471245031}, {\"truth_threshold\": 17.7399996034801, \"match_probability\": 0.999995432000871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82228.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221733.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27052154717217014, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7294784528278299, \"precision\": 0.9997689885345362, \"recall\": 0.27052154717217014, \"specificity\": 0.9999999851415982, \"npv\": 0.9998266301638482, \"accuracy\": 0.9998266264572835, \"f1\": 0.425822354793272, \"f2\": 0.3167266393496296, \"f0_5\": 0.6495626029901304, \"p4\": 0.5972852465060053, \"phi\": 0.5200116714694163}, {\"truth_threshold\": 17.759999603033066, \"match_probability\": 0.9999954948895802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82145.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221816.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.27024848582548416, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7297515141745158, \"precision\": 0.9997687551725817, \"recall\": 0.27024848582548416, \"specificity\": 0.9999999851415982, \"npv\": 0.9998265652786, \"accuracy\": 0.9998265615649531, \"f1\": 0.42548397539656846, \"f2\": 0.3164271714812235, \"f0_5\": 0.6492474909779535, \"p4\": 0.5969522871636167, \"phi\": 0.5197490807474147}, {\"truth_threshold\": 17.77999960258603, \"match_probability\": 0.9999955569124898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82044.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2699162063554206, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7300837936445794, \"precision\": 0.9997684705652974, \"recall\": 0.2699162063554206, \"specificity\": 0.9999999851415982, \"npv\": 0.9998264863218637, \"accuracy\": 0.9998264825995872, \"f1\": 0.4250720162476944, \"f2\": 0.31606270711229695, \"f0_5\": 0.6488635950225636, \"p4\": 0.5965467132246206, \"phi\": 0.5194293636314847}, {\"truth_threshold\": 17.799999602138996, \"match_probability\": 0.999995618081519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81963.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 221998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2696497248002211, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7303502751997789, \"precision\": 0.9997682418091777, \"recall\": 0.2696497248002211, \"specificity\": 0.9999999851415982, \"npv\": 0.9998264230001336, \"accuracy\": 0.9998264192709274, \"f1\": 0.42474147736841966, \"f2\": 0.3157703729159379, \"f0_5\": 0.6485553633628691, \"p4\": 0.5962211279921519, \"phi\": 0.5191728146053304}, {\"truth_threshold\": 17.81999960169196, \"match_probability\": 0.9999956784084236, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81891.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2694128523067104, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7305871476932896, \"precision\": 0.9997680380905872, \"recall\": 0.2694128523067104, \"specificity\": 0.9999999851415982, \"npv\": 0.999826366714158, \"accuracy\": 0.9998263629787855, \"f1\": 0.424447548533059, \"f2\": 0.3155104896613688, \"f0_5\": 0.6482811141844297, \"p4\": 0.5959314772258777, \"phi\": 0.5189446645798562}, {\"truth_threshold\": 17.839999601244926, \"match_probability\": 0.999995737904797, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81800.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26911347179407885, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7308865282059211, \"precision\": 0.9997677800999768, \"recall\": 0.26911347179407885, \"specificity\": 0.9999999851415982, \"npv\": 0.9998262955749481, \"accuracy\": 0.9998262918317726, \"f1\": 0.42407589818031, \"f2\": 0.31518198484506377, \"f0_5\": 0.6479341356732891, \"p4\": 0.5955650649984274, \"phi\": 0.5186561647539744}, {\"truth_threshold\": 17.85999960079789, \"match_probability\": 0.9999957965820732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81699.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222262.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26878119232401526, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7312188076759848, \"precision\": 0.9997674930859786, \"recall\": 0.26878119232401526, \"specificity\": 0.9999999851415982, \"npv\": 0.9998262166182542, \"accuracy\": 0.9998262128664067, \"f1\": 0.4236632017817926, \"f2\": 0.3148173266479752, \"f0_5\": 0.6475485588103349, \"p4\": 0.5951579610849125, \"phi\": 0.5183357736849004}, {\"truth_threshold\": 17.879999600350857, \"match_probability\": 0.9999958544515287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81647.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222314.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26861011774536864, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7313898822546313, \"precision\": 0.9997673450395513, \"recall\": 0.26861011774536864, \"specificity\": 0.9999999851415982, \"npv\": 0.9998261759672881, \"accuracy\": 0.9998261722109708, \"f1\": 0.4234506401263397, \"f2\": 0.3146295596951083, \"f0_5\": 0.6473498513379584, \"p4\": 0.5949481877723497, \"phi\": 0.518170742634889}, {\"truth_threshold\": 17.899999599903822, \"match_probability\": 0.9999959115242849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81571.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26836008566888514, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7316399143311149, \"precision\": 0.9997671283245496, \"recall\": 0.26836008566888514, \"specificity\": 0.9999999851415982, \"npv\": 0.9998261165543434, \"accuracy\": 0.9998261127914876, \"f1\": 0.4231398699523539, \"f2\": 0.31435510399758293, \"f0_5\": 0.6470591968219368, \"p4\": 0.5946413814470773, \"phi\": 0.5179294488416164}, {\"truth_threshold\": 17.919999599456787, \"match_probability\": 0.9999959678113101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81465.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222496.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26801135672010556, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7319886432798944, \"precision\": 0.9997668253890334, \"recall\": 0.26801135672010556, \"specificity\": 0.9999999851415982, \"npv\": 0.9998260336889324, \"accuracy\": 0.9998260299169451, \"f1\": 0.42270622267768426, \"f2\": 0.3139722568232552, \"f0_5\": 0.6466533417368237, \"p4\": 0.5942130413127582, \"phi\": 0.5175927196907453}, {\"truth_threshold\": 17.939999599009752, \"match_probability\": 0.9999960233234213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81355.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222606.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2676494681883531, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7323505318116469, \"precision\": 0.9997665101875292, \"recall\": 0.2676494681883531, \"specificity\": 0.9999999851415982, \"npv\": 0.9998259476965392, \"accuracy\": 0.9998259439150615, \"f1\": 0.42225595910052294, \"f2\": 0.3135748964322111, \"f0_5\": 0.6462315932621291, \"p4\": 0.5937680118395823, \"phi\": 0.5172430520610336}, {\"truth_threshold\": 17.959999598562717, \"match_probability\": 0.999996078071287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81272.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2673764068416672, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7326235931583328, \"precision\": 0.9997662717890049, \"recall\": 0.2673764068416672, \"specificity\": 0.9999999851415982, \"npv\": 0.9998258828113796, \"accuracy\": 0.9998258790227311, \"f1\": 0.42191604456303927, \"f2\": 0.3132750253443165, \"f0_5\": 0.6459129743691635, \"p4\": 0.5934318619603487, \"phi\": 0.5169790554285822}, {\"truth_threshold\": 17.979999598115683, \"match_probability\": 0.9999961320654285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81154.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26698819914396915, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7330118008560309, \"precision\": 0.9997659320217314, \"recall\": 0.26698819914396915, \"specificity\": 0.9999999851415982, \"npv\": 0.9998257905650227, \"accuracy\": 0.9998257867661651, \"f1\": 0.4214325403625751, \"f2\": 0.3128486365251959, \"f0_5\": 0.6454594187890617, \"p4\": 0.5929534357460987, \"phi\": 0.5166035027371765}, {\"truth_threshold\": 17.999999597668648, \"match_probability\": 0.9999961853162226, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81039.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222922.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26660986113350066, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7333901388664993, \"precision\": 0.9997655999407832, \"recall\": 0.26660986113350066, \"specificity\": 0.9999999851415982, \"npv\": 0.9998257006639285, \"accuracy\": 0.9998256968551049, \"f1\": 0.4209610434809711, \"f2\": 0.31243301344280444, \"f0_5\": 0.6450167384864206, \"p4\": 0.5924865772042661, \"phi\": 0.5162372351856733}, {\"truth_threshold\": 18.019999597221613, \"match_probability\": 0.9999962378339025, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80967.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 222994.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26637298863999, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.73362701136001, \"precision\": 0.9997653915491567, \"recall\": 0.26637298863999, \"specificity\": 0.9999999851415982, \"npv\": 0.9998256443780343, \"accuracy\": 0.999825640562963, \"f1\": 0.4206657020317083, \"f2\": 0.3121727597294942, \"f0_5\": 0.6447392519569043, \"p4\": 0.5921939833284537, \"phi\": 0.5160077875433123}, {\"truth_threshold\": 18.039999596774578, \"match_probability\": 0.9999962896285616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80886.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2661065070847905, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7338934929152096, \"precision\": 0.9997651566652247, \"recall\": 0.2661065070847905, \"specificity\": 0.9999999851415982, \"npv\": 0.9998255810564108, \"accuracy\": 0.9998255772343032, \"f1\": 0.4203333108146732, \"f2\": 0.31187993975703854, \"f0_5\": 0.6444267751891788, \"p4\": 0.5918645388302851, \"phi\": 0.5157495369625575}, {\"truth_threshold\": 18.059999596327543, \"match_probability\": 0.9999963407101535, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80809.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2658531851125638, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7341468148874363, \"precision\": 0.9997649329440293, \"recall\": 0.2658531851125638, \"specificity\": 0.9999999851415982, \"npv\": 0.9998255208617887, \"accuracy\": 0.9998255170329846, \"f1\": 0.4200172042340088, \"f2\": 0.3116015461118926, \"f0_5\": 0.6441294300886535, \"p4\": 0.5915510915282346, \"phi\": 0.5155039195777982}, {\"truth_threshold\": 18.07999959588051, \"match_probability\": 0.9999963910884953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80722.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223239.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26556696418290504, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.734433035817095, \"precision\": 0.9997646796546984, \"recall\": 0.26556696418290504, \"specificity\": 0.9999999851415982, \"npv\": 0.9998254528496917, \"accuracy\": 0.999825449013313, \"f1\": 0.4196598925921882, \"f2\": 0.3112869576618579, \"f0_5\": 0.643793117199027, \"p4\": 0.5911966177496984, \"phi\": 0.5152262629797386}, {\"truth_threshold\": 18.099999595433474, \"match_probability\": 0.9999964407732684, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80632.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2652708735660167, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7347291264339834, \"precision\": 0.9997644170562051, \"recall\": 0.2652708735660167, \"specificity\": 0.9999999851415982, \"npv\": 0.9998253824923597, \"accuracy\": 0.9998253786481355, \"f1\": 0.4192900897527898, \"f2\": 0.3109614769050401, \"f0_5\": 0.6434448141852801, \"p4\": 0.5908295640429322, \"phi\": 0.514938874509995}, {\"truth_threshold\": 18.11999959498644, \"match_probability\": 0.9999964897740216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80600.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223361.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2651655969022342, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7348344030977658, \"precision\": 0.9997643235465585, \"recall\": 0.2651655969022342, \"specificity\": 0.9999999851415982, \"npv\": 0.999825357476422, \"accuracy\": 0.9998253536294057, \"f1\": 0.4191585625877581, \"f2\": 0.31084573952361155, \"f0_5\": 0.6433208766404284, \"p4\": 0.5906989685419741, \"phi\": 0.5148366532925441}, {\"truth_threshold\": 18.139999594539404, \"match_probability\": 0.9999965381001715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80493.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223468.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26481357805771133, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7351864219422887, \"precision\": 0.9997640103338633, \"recall\": 0.26481357805771133, \"specificity\": 0.9999999851415982, \"npv\": 0.9998252738293889, \"accuracy\": 0.999825269973028, \"f1\": 0.41871860962928475, \"f2\": 0.31045870115924945, \"f0_5\": 0.6429060924044223, \"p4\": 0.5902619560062746, \"phi\": 0.5144947036414641}, {\"truth_threshold\": 18.15999959409237, \"match_probability\": 0.9999965857610057, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80422.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223539.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2645799954599439, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7354200045400561, \"precision\": 0.9997638020412476, \"recall\": 0.2645799954599439, \"specificity\": 0.9999999851415982, \"npv\": 0.9998252183252905, \"accuracy\": 0.9998252144627213, \"f1\": 0.41842654304608196, \"f2\": 0.3102018460446584, \"f0_5\": 0.6426305485636662, \"p4\": 0.5899716917337386, \"phi\": 0.5142676770108083}, {\"truth_threshold\": 18.179999593645334, \"match_probability\": 0.9999966327656835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80357.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223604.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2643661522366356, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7356338477633644, \"precision\": 0.9997636110281676, \"recall\": 0.2643661522366356, \"specificity\": 0.9999999851415982, \"npv\": 0.9998251675116847, \"accuracy\": 0.9998251636434264, \"f1\": 0.4181590635301832, \"f2\": 0.3099666723241425, \"f0_5\": 0.6423780707153878, \"p4\": 0.5897057579246675, \"phi\": 0.5140597478398863}, {\"truth_threshold\": 18.1999995931983, \"match_probability\": 0.9999966791232384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80247.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223714.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26400426370488317, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7359957362951168, \"precision\": 0.9997632870704907, \"recall\": 0.26400426370488317, \"specificity\": 0.9999999851415982, \"npv\": 0.9998250815194406, \"accuracy\": 0.9998250776415428, \"f1\": 0.41770619972047773, \"f2\": 0.30956863229201226, \"f0_5\": 0.6419503219871205, \"p4\": 0.5892552823566232, \"phi\": 0.5137076760233046}, {\"truth_threshold\": 18.219999592751265, \"match_probability\": 0.9999967248425794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80163.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223798.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2637279124624541, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7362720875375459, \"precision\": 0.9997630390860792, \"recall\": 0.2637279124624541, \"specificity\": 0.9999999851415982, \"npv\": 0.9998250158526459, \"accuracy\": 0.9998250119673772, \"f1\": 0.41736020179985056, \"f2\": 0.3092646289503451, \"f0_5\": 0.6416232717400179, \"p4\": 0.5889109151295645, \"phi\": 0.5134386586527293}, {\"truth_threshold\": 18.23999959230423, \"match_probability\": 0.9999967699324929, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80110.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26355354798806424, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7364464520119357, \"precision\": 0.9997628823522071, \"recall\": 0.26355354798806424, \"specificity\": 0.9999999851415982, \"npv\": 0.9998249744200299, \"accuracy\": 0.9998249705301059, \"f1\": 0.41714181572027387, \"f2\": 0.30907279704129637, \"f0_5\": 0.6414167375259617, \"p4\": 0.5886934717477279, \"phi\": 0.5132688489727678}, {\"truth_threshold\": 18.259999591857195, \"match_probability\": 0.999996814401644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80029.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 223932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26328706643286476, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7367129335671353, \"precision\": 0.9997626424145513, \"recall\": 0.26328706643286476, \"specificity\": 0.9999999851415982, \"npv\": 0.9998249110984914, \"accuracy\": 0.9998249072014461, \"f1\": 0.4168079393972537, \"f2\": 0.3087795896571628, \"f0_5\": 0.6411008198310351, \"p4\": 0.5883609070794807, \"phi\": 0.5130092199512399}, {\"truth_threshold\": 18.27999959141016, \"match_probability\": 0.9999968582585792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79951.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 224010.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2630304545648948, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.7369695454351052, \"precision\": 0.999762410904089, \"recall\": 0.2630304545648948, \"specificity\": 0.9999999851415982, \"npv\": 0.9998248501222026, \"accuracy\": 0.9998248462182923, \"f1\": 0.41648629571459456, \"f2\": 0.3084972071609043, \"f0_5\": 0.6407962926450811, \"p4\": 0.5880403787369123, \"phi\": 0.5127590826038623}, {\"truth_threshold\": 18.299999590963125, \"match_probability\": 0.9999969015117268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79898.0, \"tn\": 1278737773.0, \"fp\": 19.0, \"fn\": 224063.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26285609009050503, \"tn_rate\": 0.9999999851415982, \"fp_rate\": 1.485840187008409e-08, \"fn_rate\": 0.737143909909495, \"precision\": 0.999762253337838, \"recall\": 0.26285609009050503, \"specificity\": 0.9999999851415982, \"npv\": 0.9998248086896003, \"accuracy\": 0.9998248047810211, \"f1\": 0.41626766837380624, \"f2\": 0.3083053124766064, \"f0_5\": 0.6405891964613576, \"p4\": 0.587822426406344, \"phi\": 0.5125890478515136}, {\"truth_threshold\": 18.31999959051609, \"match_probability\": 0.9999969441693992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79817.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224144.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2625896085353055, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7374103914646944, \"precision\": 0.9997870581456523, \"recall\": 0.2625896085353055, \"specificity\": 0.9999999867056404, \"npv\": 0.9998247453683569, \"accuracy\": 0.999824743016032, \"f1\": 0.4159355906147813, \"f2\": 0.308012484583361, \"f0_5\": 0.6402806366788224, \"p4\": 0.5874912452830969, \"phi\": 0.5123354944592612}, {\"truth_threshold\": 18.339999590069056, \"match_probability\": 0.9999969862397944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79731.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224230.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26230667750139, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.73769332249861, \"precision\": 0.9997868285098059, \"recall\": 0.26230667750139, \"specificity\": 0.9999999867056404, \"npv\": 0.9998246781381125, \"accuracy\": 0.9998246757781957, \"f1\": 0.4155805571409584, \"f2\": 0.30770103551117944, \"f0_5\": 0.6399439444067209, \"p4\": 0.5871369984639094, \"phi\": 0.5120593323158745}, {\"truth_threshold\": 18.35999958962202, \"match_probability\": 0.9999970277309974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79632.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2619809778228128, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7380190221771872, \"precision\": 0.9997865635475649, \"recall\": 0.2619809778228128, \"specificity\": 0.9999999867056404, \"npv\": 0.999824600745168, \"accuracy\": 0.9998245983765004, \"f1\": 0.4151716587158833, \"f2\": 0.3073424557292089, \"f0_5\": 0.6395558960866234, \"p4\": 0.586728785812892, \"phi\": 0.5117412402521614}, {\"truth_threshold\": 18.379999589174986, \"match_probability\": 0.9999970686509823, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79552.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2617177861633565, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7382822138366435, \"precision\": 0.9997863489549951, \"recall\": 0.2617177861633565, \"specificity\": 0.9999999867056404, \"npv\": 0.9998245382054236, \"accuracy\": 0.9998245358296759, \"f1\": 0.41484108153208354, \"f2\": 0.30705265425003453, \"f0_5\": 0.6392419608605724, \"p4\": 0.5863985905683001, \"phi\": 0.5114840516802327}, {\"truth_threshold\": 18.39999958872795, \"match_probability\": 0.9999971090076128, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79461.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224500.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26141840565072494, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7385815943492751, \"precision\": 0.9997861043307582, \"recall\": 0.26141840565072494, \"specificity\": 0.9999999867056404, \"npv\": 0.9998244670664739, \"accuracy\": 0.9998244646826631, \"f1\": 0.41446488228896905, \"f2\": 0.30672296154932904, \"f0_5\": 0.6388844667641143, \"p4\": 0.5860226382225117, \"phi\": 0.5111913424121072}, {\"truth_threshold\": 18.419999588280916, \"match_probability\": 0.999997148808645, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79382.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26115850388701184, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7388414961129882, \"precision\": 0.9997858915099687, \"recall\": 0.26115850388701184, \"specificity\": 0.9999999867056404, \"npv\": 0.9998244053084928, \"accuracy\": 0.9998244029176739, \"f1\": 0.4141381469115192, \"f2\": 0.30643670724335126, \"f0_5\": 0.6385737752128928, \"p4\": 0.5856959549813507, \"phi\": 0.5109370962241658}, {\"truth_threshold\": 18.43999958783388, \"match_probability\": 0.9999971880617277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79315.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224646.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26093808087221715, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7390619191277829, \"precision\": 0.9997857106842132, \"recall\": 0.26093808087221715, \"specificity\": 0.9999999867056404, \"npv\": 0.9998243529314768, \"accuracy\": 0.9998243505347084, \"f1\": 0.41386093667246726, \"f2\": 0.30619390723731754, \"f0_5\": 0.6383100296319426, \"p4\": 0.5854186705871604, \"phi\": 0.5107213705448964}, {\"truth_threshold\": 18.459999587386847, \"match_probability\": 0.9999972267744046, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79247.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224714.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2607143679616793, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7392856320383207, \"precision\": 0.9997855268469923, \"recall\": 0.2607143679616793, \"specificity\": 0.9999999867056404, \"npv\": 0.9998242997727199, \"accuracy\": 0.9998242973699076, \"f1\": 0.4135794898558288, \"f2\": 0.3059474576637624, \"f0_5\": 0.6380421147891282, \"p4\": 0.5851370372276576, \"phi\": 0.5105023318911184}, {\"truth_threshold\": 18.47999958693981, \"match_probability\": 0.9999972649541156, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79157.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26041827734479095, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.739581722655209, \"precision\": 0.9997852830474651, \"recall\": 0.26041827734479095, \"specificity\": 0.9999999867056404, \"npv\": 0.9998242294155504, \"accuracy\": 0.9998242270047302, \"f1\": 0.41320683310060424, \"f2\": 0.305621234608322, \"f0_5\": 0.6376871605411685, \"p4\": 0.5847639608849672, \"phi\": 0.5102122832350438}, {\"truth_threshold\": 18.499999586492777, \"match_probability\": 0.9999973026081981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79100.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.26023075328742834, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7397692467125717, \"precision\": 0.9997851283542096, \"recall\": 0.26023075328742834, \"specificity\": 0.9999999867056404, \"npv\": 0.9998241848560149, \"accuracy\": 0.9998241824401177, \"f1\": 0.41297072658831885, \"f2\": 0.30541460321971087, \"f0_5\": 0.6374621431299955, \"p4\": 0.584527486698208, \"phi\": 0.5100285004591998}, {\"truth_threshold\": 18.519999586045742, \"match_probability\": 0.9999973397438885, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 79024.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 224937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25998072121094484, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7400192787890552, \"precision\": 0.9997849217494718, \"recall\": 0.25998072121094484, \"specificity\": 0.9999999867056404, \"npv\": 0.9998241254433069, \"accuracy\": 0.9998241230206345, \"f1\": 0.41265580858585593, \"f2\": 0.30513906640358024, \"f0_5\": 0.6371618625277162, \"p4\": 0.5842119552694607, \"phi\": 0.5097833537190106}, {\"truth_threshold\": 18.539999585598707, \"match_probability\": 0.9999973763683236, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78912.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.259612252887706, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.740387747112294, \"precision\": 0.9997846165541182, \"recall\": 0.259612252887706, \"specificity\": 0.9999999867056404, \"npv\": 0.9998240378877502, \"accuracy\": 0.9998240354550803, \"f1\": 0.412191491028755, \"f2\": 0.304732953189478, \"f0_5\": 0.6367188067331851, \"p4\": 0.5837464765780171, \"phi\": 0.5094218698647959}, {\"truth_threshold\": 18.559999585151672, \"match_probability\": 0.999997412488542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78804.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25925694414744, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7407430558525601, \"precision\": 0.9997843214371804, \"recall\": 0.25925694414744, \"specificity\": 0.9999999867056404, \"npv\": 0.9998239534591922, \"accuracy\": 0.9998239510168673, \"f1\": 0.4117434989106071, \"f2\": 0.30434127747332324, \"f0_5\": 0.636290967226219, \"p4\": 0.583297073934856, \"phi\": 0.5090730531121991}, {\"truth_threshold\": 18.579999584704638, \"match_probability\": 0.9999974481114852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78742.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225219.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25905297061136134, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7409470293886387, \"precision\": 0.9997841516525096, \"recall\": 0.25905297061136134, \"specificity\": 0.9999999867056404, \"npv\": 0.9998239049909524, \"accuracy\": 0.9998239025430783, \"f1\": 0.41148620401337793, \"f2\": 0.3041163970730795, \"f0_5\": 0.6360450858404807, \"p4\": 0.5830388399688676, \"phi\": 0.5088726984535423}, {\"truth_threshold\": 18.599999584257603, \"match_probability\": 0.9999974832439992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78682.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225279.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2588555768667691, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7411444231332309, \"precision\": 0.999783987090052, \"recall\": 0.2588555768667691, \"specificity\": 0.9999999867056404, \"npv\": 0.9998238580862087, \"accuracy\": 0.99982385563296, \"f1\": 0.4112371295667172, \"f2\": 0.3038987503698216, \"f0_5\": 0.6358069484466439, \"p4\": 0.5827887667631343, \"phi\": 0.5086787317300604}, {\"truth_threshold\": 18.619999583810568, \"match_probability\": 0.9999975178928361, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78563.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225398.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2584640792733278, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7415359207266722, \"precision\": 0.9997836599643676, \"recall\": 0.2584640792733278, \"specificity\": 0.9999999867056404, \"npv\": 0.9998237650584799, \"accuracy\": 0.9998237625945585, \"f1\": 0.4107429007609642, \"f2\": 0.3034670247152401, \"f0_5\": 0.6353340956620048, \"p4\": 0.5822922947227838, \"phi\": 0.5082938121344502}, {\"truth_threshold\": 18.639999583363533, \"match_probability\": 0.9999975520646545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78464.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225497.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25813837959475067, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7418616204052494, \"precision\": 0.9997833870618367, \"recall\": 0.25813837959475067, \"specificity\": 0.9999999867056404, \"npv\": 0.9998236876656768, \"accuracy\": 0.9998236851928632, \"f1\": 0.41033150124724793, \"f2\": 0.3031077975006277, \"f0_5\": 0.6349401587674082, \"p4\": 0.5818787625622331, \"phi\": 0.5079733626997317}, {\"truth_threshold\": 18.659999582916498, \"match_probability\": 0.9999975857660216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78389.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225572.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25789163741401033, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7421083625859897, \"precision\": 0.9997831798586843, \"recall\": 0.25789163741401033, \"specificity\": 0.9999999867056404, \"npv\": 0.9998236290347733, \"accuracy\": 0.9998236265552154, \"f1\": 0.4100196931220529, \"f2\": 0.3028356190844118, \"f0_5\": 0.6346413853963422, \"p4\": 0.5815651773101271, \"phi\": 0.5077304633627917}, {\"truth_threshold\": 18.679999582469463, \"match_probability\": 0.9999976190034143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78289.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225672.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25756264783968996, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.74243735216031, \"precision\": 0.9997829029703982, \"recall\": 0.25756264783968996, \"specificity\": 0.9999999867056404, \"npv\": 0.999823550860246, \"accuracy\": 0.9998235483716847, \"f1\": 0.40960375862943965, \"f2\": 0.30247266545609086, \"f0_5\": 0.6342425690838241, \"p4\": 0.5811466562795131, \"phi\": 0.5074064167480895}, {\"truth_threshold\": 18.69999958202243, \"match_probability\": 0.9999976517832202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78222.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25734222482489527, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7426577751751047, \"precision\": 0.9997827170592671, \"recall\": 0.25734222482489527, \"specificity\": 0.9999999867056404, \"npv\": 0.9998234984833195, \"accuracy\": 0.9998234959887193, \"f1\": 0.4093249607535322, \"f2\": 0.30222945514314, \"f0_5\": 0.6339750728217897, \"p4\": 0.5808659863828582, \"phi\": 0.5071891897185887}, {\"truth_threshold\": 18.719999581575394, \"match_probability\": 0.999997684111739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78132.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2570461342080069, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7429538657919931, \"precision\": 0.999782466826191, \"recall\": 0.2570461342080069, \"specificity\": 0.9999999867056404, \"npv\": 0.9998234281262628, \"accuracy\": 0.9998234256235418, \"f1\": 0.40895030226898016, \"f2\": 0.30190271508423927, \"f0_5\": 0.6336153834925238, \"p4\": 0.5804886372886258, \"phi\": 0.5068972457411296}, {\"truth_threshold\": 18.73999958112836, \"match_probability\": 0.9999977159951835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 78032.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 225929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25671714463368656, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7432828553663134, \"precision\": 0.9997821881125959, \"recall\": 0.25671714463368656, \"specificity\": 0.9999999867056404, \"npv\": 0.9998233499517669, \"accuracy\": 0.9998233474400112, \"f1\": 0.408533808015497, \"f2\": 0.30153961726356043, \"f0_5\": 0.6332152357272578, \"p4\": 0.5800689163734887, \"phi\": 0.506572666261009}, {\"truth_threshold\": 18.759999580681324, \"match_probability\": 0.9999977474396812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77933.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25639144495510935, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7436085550448907, \"precision\": 0.999781911481719, \"recall\": 0.25639144495510935, \"specificity\": 0.9999999867056404, \"npv\": 0.999823272559028, \"accuracy\": 0.999823270038316, \"f1\": 0.40812126385466774, \"f2\": 0.30118009513106414, \"f0_5\": 0.6328185773376359, \"p4\": 0.5796529313946599, \"phi\": 0.5062511276350053}, {\"truth_threshold\": 18.77999958023429, \"match_probability\": 0.9999977784512751, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77829.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25604929579781616, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7439507042021838, \"precision\": 0.9997816201217788, \"recall\": 0.25604929579781616, \"specificity\": 0.9999999867056404, \"npv\": 0.9998231912575778, \"accuracy\": 0.9998231887274441, \"f1\": 0.40768765370985866, \"f2\": 0.30080235605129513, \"f0_5\": 0.6324013358359944, \"p4\": 0.5792154419278631, \"phi\": 0.5059131296385649}, {\"truth_threshold\": 18.799999579787254, \"match_probability\": 0.9999978090359253, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77740.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25575649507667103, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.744243504923329, \"precision\": 0.9997813701660301, \"recall\": 0.25575649507667103, \"specificity\": 0.9999999867056404, \"npv\": 0.9998231216823089, \"accuracy\": 0.9998231191441019, \"f1\": 0.40731639587339347, \"f2\": 0.3004790503408702, \"f0_5\": 0.6320438251741088, \"p4\": 0.5788406483894668, \"phi\": 0.5056237019849112}, {\"truth_threshold\": 18.81999957934022, \"match_probability\": 0.9999978391995092, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77646.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226315.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25544724487680986, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7445527551231902, \"precision\": 0.9997811055457554, \"recall\": 0.25544724487680986, \"specificity\": 0.9999999867056404, \"npv\": 0.9998230481983275, \"accuracy\": 0.9998230456515832, \"f1\": 0.40692409282435066, \"f2\": 0.3001375330786768, \"f0_5\": 0.6316657799298094, \"p4\": 0.578444394285036, \"phi\": 0.5053178343896483}, {\"truth_threshold\": 18.839999578893185, \"match_probability\": 0.999997868947824, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77577.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2552202420705288, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7447797579294713, \"precision\": 0.9997809108951723, \"recall\": 0.2552202420705288, \"specificity\": 0.9999999867056404, \"npv\": 0.999822994257965, \"accuracy\": 0.9998229917049472, \"f1\": 0.4066360026732712, \"f2\": 0.29988681328366723, \"f0_5\": 0.6313879841194654, \"p4\": 0.5781532619048326, \"phi\": 0.5050931967060494}, {\"truth_threshold\": 18.85999957844615, \"match_probability\": 0.9999978982865868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77500.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2549669200983021, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7450330799016979, \"precision\": 0.9997806932672834, \"recall\": 0.2549669200983021, \"specificity\": 0.9999999867056404, \"npv\": 0.9998229340636543, \"accuracy\": 0.9998229315036286, \"f1\": 0.40631438772353845, \"f2\": 0.2996069929431922, \"f0_5\": 0.6310776852559081, \"p4\": 0.5778281098023786, \"phi\": 0.5048423960906712}, {\"truth_threshold\": 18.879999577999115, \"match_probability\": 0.9999979272214359, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77451.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2548057152068851, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7451942847931149, \"precision\": 0.9997805545515568, \"recall\": 0.2548057152068851, \"specificity\": 0.9999999867056404, \"npv\": 0.9998228957581876, \"accuracy\": 0.9998228931936985, \"f1\": 0.40610965605656624, \"f2\": 0.2994289081057007, \"f0_5\": 0.6308800602118165, \"p4\": 0.577621049000035, \"phi\": 0.5046827308224017}, {\"truth_threshold\": 18.89999957755208, \"match_probability\": 0.9999979557579319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77344.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25445369636236226, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7455463036376377, \"precision\": 0.9997802510308812, \"recall\": 0.25445369636236226, \"specificity\": 0.9999999867056404, \"npv\": 0.9998228121115665, \"accuracy\": 0.9998228095373208, \"f1\": 0.4056624060505295, \"f2\": 0.29903998206007554, \"f0_5\": 0.6304480726436856, \"p4\": 0.5771685010451241, \"phi\": 0.5043338983477643}, {\"truth_threshold\": 18.919999577105045, \"match_probability\": 0.9999979839015591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77242.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2541181269965555, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7458818730034446, \"precision\": 0.999779960910703, \"recall\": 0.2541181269965555, \"specificity\": 0.9999999867056404, \"npv\": 0.9998227323736791, \"accuracy\": 0.9998227297901197, \"f1\": 0.4052358218351608, \"f2\": 0.29866917020531236, \"f0_5\": 0.6300357097995586, \"p4\": 0.5767365952808771, \"phi\": 0.5040011417338872}, {\"truth_threshold\": 18.93999957665801, \"match_probability\": 0.9999980116577264, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77178.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2539075736689904, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7460924263310096, \"precision\": 0.9997797784830623, \"recall\": 0.2539075736689904, \"specificity\": 0.9999999867056404, \"npv\": 0.9998226823420701, \"accuracy\": 0.9998226797526601, \"f1\": 0.4049680445801719, \"f2\": 0.29843647407386786, \"f0_5\": 0.6297766919465158, \"p4\": 0.5764653435747563, \"phi\": 0.5037922410801767}, {\"truth_threshold\": 18.959999576210976, \"match_probability\": 0.9999980390317678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77107.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226854.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25367399107122296, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7463260089287771, \"precision\": 0.9997795757481458, \"recall\": 0.25367399107122296, \"specificity\": 0.9999999867056404, \"npv\": 0.9998226268382595, \"accuracy\": 0.9998226242423534, \"f1\": 0.40467087395200546, \"f2\": 0.2981782998496483, \"f0_5\": 0.6294890906626914, \"p4\": 0.5761641960463824, \"phi\": 0.5035603905437832}, {\"truth_threshold\": 18.97999957576394, \"match_probability\": 0.999998066028944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77051.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226910.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2534897569096035, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7465102430903965, \"precision\": 0.9997794155810453, \"recall\": 0.2534897569096035, \"specificity\": 0.9999999867056404, \"npv\": 0.9998225830606104, \"accuracy\": 0.9998225804595763, \"f1\": 0.4044364077274958, \"f2\": 0.2979746494734367, \"f0_5\": 0.629262061992738, \"p4\": 0.5759265021272036, \"phi\": 0.5033774472033474}, {\"truth_threshold\": 18.999999575316906, \"match_probability\": 0.9999980926544437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76985.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 226976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2532726237905521, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.746727376209448, \"precision\": 0.9997792265135971, \"recall\": 0.2532726237905521, \"specificity\": 0.9999999867056404, \"npv\": 0.999822531465529, \"accuracy\": 0.9998225288584461, \"f1\": 0.4041599840404449, \"f2\": 0.2977346103093485, \"f0_5\": 0.6289942791219817, \"p4\": 0.5756461711988254, \"phi\": 0.5031617500366622}, {\"truth_threshold\": 19.01999957486987, \"match_probability\": 0.9999981189133836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76915.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2530423310885278, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7469576689114722, \"precision\": 0.9997790256330266, \"recall\": 0.2530423310885278, \"specificity\": 0.9999999867056404, \"npv\": 0.9998224767434788, \"accuracy\": 0.9998224741299747, \"f1\": 0.40386670272228686, \"f2\": 0.2974799965345891, \"f0_5\": 0.6287100144027439, \"p4\": 0.5753486236629383, \"phi\": 0.5029328792511817}, {\"truth_threshold\": 19.039999574422836, \"match_probability\": 0.9999981448108103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76844.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227117.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25280874849076035, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7471912515092397, \"precision\": 0.9997788215089577, \"recall\": 0.25280874849076035, \"specificity\": 0.9999999867056404, \"npv\": 0.9998224212396911, \"accuracy\": 0.999822418619668, \"f1\": 0.40356912153184427, \"f2\": 0.2972217172518092, \"f0_5\": 0.6284214227884953, \"p4\": 0.5750465866163692, \"phi\": 0.5027006324643288}, {\"truth_threshold\": 19.0599995739758, \"match_probability\": 0.9999981703517008, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76762.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227199.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2525389770398176, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7474610229601824, \"precision\": 0.9997785852902487, \"recall\": 0.2525389770398176, \"specificity\": 0.9999999867056404, \"npv\": 0.9998223571367326, \"accuracy\": 0.9998223545091729, \"f1\": 0.4032252981036928, \"f2\": 0.29692338756157055, \"f0_5\": 0.6280877859909635, \"p4\": 0.5746974554140996, \"phi\": 0.5024322702210648}, {\"truth_threshold\": 19.079999573528767, \"match_probability\": 0.9999981955409636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76684.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227277.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2522823651718477, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7477176348281523, \"precision\": 0.9997783601256829, \"recall\": 0.2522823651718477, \"specificity\": 0.9999999867056404, \"npv\": 0.9998222961607555, \"accuracy\": 0.999822293526019, \"f1\": 0.40289810908364904, \"f2\": 0.296639575411301, \"f0_5\": 0.627770091606428, \"p4\": 0.5743650565081447, \"phi\": 0.502176865761679}, {\"truth_threshold\": 19.099999573081732, \"match_probability\": 0.9999982203834397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76605.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227356.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2520224634081346, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7479775365918654, \"precision\": 0.9997781316071103, \"recall\": 0.2520224634081346, \"specificity\": 0.9999999867056404, \"npv\": 0.9998222344030425, \"accuracy\": 0.9998222317610299, \"f1\": 0.4025665886284989, \"f2\": 0.2963520897261514, \"f0_5\": 0.627447993198449, \"p4\": 0.5740280990268924, \"phi\": 0.5019180544436562}, {\"truth_threshold\": 19.119999572634697, \"match_probability\": 0.9999982448839032, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76502.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2516836041465846, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7483163958534154, \"precision\": 0.9997778329565206, \"recall\": 0.2516836041465846, \"specificity\": 0.9999999867056404, \"npv\": 0.9998221538835043, \"accuracy\": 0.9998221512319935, \"f1\": 0.40213414634146344, \"f2\": 0.2959772138323366, \"f0_5\": 0.6270275409524341, \"p4\": 0.5735883250942196, \"phi\": 0.5015804163877756}, {\"truth_threshold\": 19.139999572187662, \"match_probability\": 0.9999982690470628, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76414.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227547.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2513940933211827, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7486059066788173, \"precision\": 0.9997775771610996, \"recall\": 0.2513940933211827, \"specificity\": 0.9999999867056404, \"npv\": 0.9998220850901226, \"accuracy\": 0.9998220824304865, \"f1\": 0.4017644955729879, \"f2\": 0.2956568841771295, \"f0_5\": 0.6266678694735807, \"p4\": 0.573212192157729, \"phi\": 0.5012917688200845}, {\"truth_threshold\": 19.159999571740627, \"match_probability\": 0.9999982928775621, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76323.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2510947128085511, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7489052871914489, \"precision\": 0.9997773120251506, \"recall\": 0.2510947128085511, \"specificity\": 0.9999999867056404, \"npv\": 0.9998220139515219, \"accuracy\": 0.9998220112834737, \"f1\": 0.40138206315523756, \"f2\": 0.29532558830630934, \"f0_5\": 0.6262954994165637, \"p4\": 0.5728228446021322, \"phi\": 0.5009931061309137}, {\"truth_threshold\": 19.179999571293592, \"match_probability\": 0.9999983163799812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76219.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227742.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25075256365125786, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7492474363487421, \"precision\": 0.9997770082375781, \"recall\": 0.25075256365125786, \"specificity\": 0.9999999867056404, \"npv\": 0.9998219326502764, \"accuracy\": 0.9998219299726019, \"f1\": 0.40094477336749107, \"f2\": 0.2949469073122407, \"f0_5\": 0.6258693884924578, \"p4\": 0.5723773872625131, \"phi\": 0.5006515592322509}, {\"truth_threshold\": 19.199999570846558, \"match_probability\": 0.9999983395588364, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76157.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.25054859011517927, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7494514098848207, \"precision\": 0.9997768267387822, \"recall\": 0.25054859011517927, \"specificity\": 0.9999999867056404, \"npv\": 0.9998218841822325, \"accuracy\": 0.999821881498813, \"f1\": 0.4006839675378484, \"f2\": 0.29472112617626073, \"f0_5\": 0.6256150837006721, \"p4\": 0.5721115777818468, \"phi\": 0.5004478338580218}, {\"truth_threshold\": 19.219999570399523, \"match_probability\": 0.9999983624185826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76093.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227868.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2503380367876142, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7496619632123858, \"precision\": 0.999776639075023, \"recall\": 0.2503380367876142, \"specificity\": 0.9999999867056404, \"npv\": 0.9998218341507084, \"accuracy\": 0.9998218314613534, \"f1\": 0.4004146593662763, \"f2\": 0.2944880390478299, \"f0_5\": 0.6253523580664726, \"p4\": 0.5718369989429397, \"phi\": 0.5002374496918485}, {\"truth_threshold\": 19.239999569952488, \"match_probability\": 0.999998384963613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75981.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 227980.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24996956846437537, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7500304315356247, \"precision\": 0.9997763099028922, \"recall\": 0.24996956846437537, \"specificity\": 0.9999999867056404, \"npv\": 0.9998217465955529, \"accuracy\": 0.9998217438957991, \"f1\": 0.39994315176111106, \"f2\": 0.2940800810006177, \"f0_5\": 0.6248920558003661, \"p4\": 0.5713560090137759, \"phi\": 0.49986906438759404}, {\"truth_threshold\": 19.259999569505453, \"match_probability\": 0.9999984071982604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75862.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228099.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2495780708709341, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7504219291290659, \"precision\": 0.9997759590927661, \"recall\": 0.2495780708709341, \"specificity\": 0.9999999867056404, \"npv\": 0.9998216535682171, \"accuracy\": 0.9998216508573978, \"f1\": 0.39944187026116257, \"f2\": 0.29364654806022655, \"f0_5\": 0.6244022407432709, \"p4\": 0.5708442909694608, \"phi\": 0.49947735737079146}, {\"truth_threshold\": 19.27999956905842, \"match_probability\": 0.9999984291267976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75777.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228184.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24929842973276176, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7507015702672383, \"precision\": 0.9997757078396707, \"recall\": 0.24929842973276176, \"specificity\": 0.9999999867056404, \"npv\": 0.9998215871201307, \"accuracy\": 0.9998215844013968, \"f1\": 0.39908361970217643, \"f2\": 0.2933368327658369, \"f0_5\": 0.6240519026183546, \"p4\": 0.5704783570651538, \"phi\": 0.49919737850833}, {\"truth_threshold\": 19.299999568611383, \"match_probability\": 0.9999984507534392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75698.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228263.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24903852796904866, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7509614720309513, \"precision\": 0.9997754738162847, \"recall\": 0.24903852796904866, \"specificity\": 0.9999999867056404, \"npv\": 0.9998215253625053, \"accuracy\": 0.9998215226364077, \"f1\": 0.3987505135958027, \"f2\": 0.29304894317642477, \"f0_5\": 0.6237259422465603, \"p4\": 0.5701379387145522, \"phi\": 0.49893702202659035}, {\"truth_threshold\": 19.31999956816435, \"match_probability\": 0.9999984720823414, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75574.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228387.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24863058089689138, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7513694191031086, \"precision\": 0.9997751055019778, \"recall\": 0.24863058089689138, \"specificity\": 0.9999999867056404, \"npv\": 0.9998214284265012, \"accuracy\": 0.9998214256888297, \"f1\": 0.3982273838630807, \"f2\": 0.2925969948158444, \"f0_5\": 0.6232136230569414, \"p4\": 0.5696029980264997, \"phi\": 0.49852808707650687}, {\"truth_threshold\": 19.339999567717314, \"match_probability\": 0.9999984931176031, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75486.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24834107007148942, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7516589299285106, \"precision\": 0.9997748433837066, \"recall\": 0.24834107007148942, \"specificity\": 0.9999999867056404, \"npv\": 0.9998213596332194, \"accuracy\": 0.9998213568873228, \"f1\": 0.39785592309151857, \"f2\": 0.29227620461425163, \"f0_5\": 0.6228495328999807, \"p4\": 0.5692229075206702, \"phi\": 0.4982376716062625}, {\"truth_threshold\": 19.35999956727028, \"match_probability\": 0.9999985138632671, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75419.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228542.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24812064705669476, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7518793529433052, \"precision\": 0.9997746434063312, \"recall\": 0.24812064705669476, \"specificity\": 0.9999999867056404, \"npv\": 0.9998213072565225, \"accuracy\": 0.9998213045043574, \"f1\": 0.39757299082491426, \"f2\": 0.2920319373025215, \"f0_5\": 0.6225720441469031, \"p4\": 0.5689332666523607, \"phi\": 0.49801644629944825}, {\"truth_threshold\": 19.379999566823244, \"match_probability\": 0.9999985343233202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75351.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2478969341461569, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7521030658538431, \"precision\": 0.9997744400806708, \"recall\": 0.2478969341461569, \"specificity\": 0.9999999867056404, \"npv\": 0.9998212540980895, \"accuracy\": 0.9998212513395566, \"f1\": 0.39728573349256185, \"f2\": 0.2917839982899787, \"f0_5\": 0.6222901625778575, \"p4\": 0.5686390781708373, \"phi\": 0.4977918186186165}, {\"truth_threshold\": 19.39999956637621, \"match_probability\": 0.9999985545016946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75255.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228706.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24758110415480933, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7524188958451906, \"precision\": 0.9997741524072696, \"recall\": 0.24758110415480933, \"specificity\": 0.9999999867056404, \"npv\": 0.9998211790508996, \"accuracy\": 0.9998211762833672, \"f1\": 0.3968800183528332, \"f2\": 0.2914339222811893, \"f0_5\": 0.6218917806656982, \"p4\": 0.568223367529401, \"phi\": 0.49747452455520413}, {\"truth_threshold\": 19.419999565929174, \"match_probability\": 0.9999985744022681, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75196.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228765.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2473870003059603, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7526129996940397, \"precision\": 0.9997739752436414, \"recall\": 0.2473870003059603, \"specificity\": 0.9999999867056404, \"npv\": 0.9998211329281531, \"accuracy\": 0.9998211301550841, \"f1\": 0.3966305706614905, \"f2\": 0.29121874557048993, \"f0_5\": 0.6216466907953367, \"p4\": 0.5679676543630855, \"phi\": 0.4972794204892812}, {\"truth_threshold\": 19.43999956548214, \"match_probability\": 0.9999985940288653, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75106.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24709090968907196, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.752909090310928, \"precision\": 0.9997737044580222, \"recall\": 0.24709090968907196, \"specificity\": 0.9999999867056404, \"npv\": 0.9998210625714292, \"accuracy\": 0.9998210597899067, \"f1\": 0.3962499076721782, \"f2\": 0.29089047202600843, \"f0_5\": 0.6212724562538361, \"p4\": 0.5675772540159222, \"phi\": 0.4969816566200113}, {\"truth_threshold\": 19.459999565035105, \"match_probability\": 0.9999986133852581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75003.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 228958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24675205042752196, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7532479495724781, \"precision\": 0.9997733937616635, \"recall\": 0.24675205042752196, \"specificity\": 0.9999999867056404, \"npv\": 0.9998209820520797, \"accuracy\": 0.9998209792608701, \"f1\": 0.39581403817077904, \"f2\": 0.29051472502138104, \"f0_5\": 0.6208436182312128, \"p4\": 0.5671299734836466, \"phi\": 0.4966406633964773}, {\"truth_threshold\": 19.47999956458807, \"match_probability\": 0.9999986324751665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74892.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24638687200002632, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7536131279999737, \"precision\": 0.9997730579770121, \"recall\": 0.24638687200002632, \"specificity\": 0.9999999867056404, \"npv\": 0.9998208952788146, \"accuracy\": 0.9998208924771512, \"f1\": 0.3953440494100879, \"f2\": 0.29010972664793344, \"f0_5\": 0.6203808170020726, \"p4\": 0.5666473673587678, \"phi\": 0.4962729230210754}, {\"truth_threshold\": 19.499999564141035, \"match_probability\": 0.9999986513022592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74810.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229151.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2461171005490836, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7538828994509164, \"precision\": 0.9997728092800727, \"recall\": 0.2461171005490836, \"specificity\": 0.9999999867056404, \"npv\": 0.9998208311760518, \"accuracy\": 0.9998208283666561, \"f1\": 0.39499667360106444, \"f2\": 0.28981049392137886, \"f0_5\": 0.6200384902920588, \"p4\": 0.5662904568717055, \"phi\": 0.4960010838974117}, {\"truth_threshold\": 19.519999563694, \"match_probability\": 0.9999986698701544, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74706.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2457749513917904, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7542250486082096, \"precision\": 0.9997724930744215, \"recall\": 0.2457749513917904, \"specificity\": 0.9999999867056404, \"npv\": 0.9998207498749987, \"accuracy\": 0.9998207470557844, \"f1\": 0.3945558830053554, \"f2\": 0.28943092454711766, \"f0_5\": 0.6196037840070465, \"p4\": 0.5658373116219001, \"phi\": 0.4956560979232515}, {\"truth_threshold\": 19.539999563246965, \"match_probability\": 0.9999986881824207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74636.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229325.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24554465868976613, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7544553413102338, \"precision\": 0.9997722797476324, \"recall\": 0.24554465868976613, \"specificity\": 0.9999999867056404, \"npv\": 0.9998206951531435, \"accuracy\": 0.999820692327313, \"f1\": 0.3942590606792142, \"f2\": 0.2891754107138568, \"f0_5\": 0.6193108552822646, \"p4\": 0.565532008416361, \"phi\": 0.4954237605946555}, {\"truth_threshold\": 19.55999956279993, \"match_probability\": 0.9999987062425771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74579.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229382.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2453571346324035, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7546428653675965, \"precision\": 0.9997721057429353, \"recall\": 0.2453571346324035, \"specificity\": 0.9999999867056404, \"npv\": 0.999820650593923, \"accuracy\": 0.9998206477627005, \"f1\": 0.39401728141336706, \"f2\": 0.28896732897306343, \"f0_5\": 0.6190721264391669, \"p4\": 0.5652832248936477, \"phi\": 0.4952344911303859}, {\"truth_threshold\": 19.579999562352896, \"match_probability\": 0.9999987240540947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74511.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229450.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24513342172186564, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7548665782781344, \"precision\": 0.999771897810219, \"recall\": 0.24513342172186564, \"specificity\": 0.9999999867056404, \"npv\": 0.9998205974355597, \"accuracy\": 0.9998205945978997, \"f1\": 0.3937287477311098, \"f2\": 0.2887190670597316, \"f0_5\": 0.6187870906019702, \"p4\": 0.5649862195327651, \"phi\": 0.4950086013375459}, {\"truth_threshold\": 19.59999956190586, \"match_probability\": 0.9999987416203966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74453.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229508.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2449426077687598, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7550573922312402, \"precision\": 0.9997717201557674, \"recall\": 0.2449426077687598, \"specificity\": 0.9999999867056404, \"npv\": 0.9998205520946074, \"accuracy\": 0.999820549251452, \"f1\": 0.39348256353205735, \"f2\": 0.28850729357350224, \"f0_5\": 0.618543768204559, \"p4\": 0.5647327098463184, \"phi\": 0.4948158491616531}, {\"truth_threshold\": 19.619999561458826, \"match_probability\": 0.9999987589448586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74337.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229624.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24456097986254816, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7554390201374518, \"precision\": 0.9997713640153859, \"recall\": 0.24456097986254816, \"specificity\": 0.9999999867056404, \"npv\": 0.9998204614127151, \"accuracy\": 0.9998204585585565, \"f1\": 0.39298996867689623, \"f2\": 0.28808368948021934, \"f0_5\": 0.618056560194354, \"p4\": 0.5642251882633278, \"phi\": 0.49443011943080123}, {\"truth_threshold\": 19.63999956101179, \"match_probability\": 0.9999987760308101, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74272.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2443471366392399, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7556528633607601, \"precision\": 0.9997711639677476, \"recall\": 0.2443471366392399, \"specificity\": 0.9999999867056404, \"npv\": 0.9998204105995928, \"accuracy\": 0.9998204077392616, \"f1\": 0.39271381361533375, \"f2\": 0.2878462918164251, \"f0_5\": 0.6177832268926016, \"p4\": 0.5639405080390039, \"phi\": 0.494213846189389}, {\"truth_threshold\": 19.659999560564756, \"match_probability\": 0.9999987928815349, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74205.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229756.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24412671362444524, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7558732863755547, \"precision\": 0.9997709573980761, \"recall\": 0.24412671362444524, \"specificity\": 0.9999999867056404, \"npv\": 0.9998203582229954, \"accuracy\": 0.9998203553562962, \"f1\": 0.3924290621207193, \"f2\": 0.28760156457111496, \"f0_5\": 0.6175012357514118, \"p4\": 0.5636468477594742, \"phi\": 0.4939908193085995}, {\"truth_threshold\": 19.67999956011772, \"match_probability\": 0.9999988095002714, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74154.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24395892894154184, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7560410710584582, \"precision\": 0.99977079990832, \"recall\": 0.24395892894154184, \"specificity\": 0.9999999867056404, \"npv\": 0.9998203183542458, \"accuracy\": 0.9998203154826956, \"f1\": 0.3922122433435943, \"f2\": 0.2874152626132254, \"f0_5\": 0.6172864171016158, \"p4\": 0.5634231649981878, \"phi\": 0.4938209850764646}, {\"truth_threshold\": 19.699999559670687, \"match_probability\": 0.9999988258902134, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74054.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 229907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24362993936722147, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7563700606327786, \"precision\": 0.9997704904753547, \"recall\": 0.24362993936722147, \"specificity\": 0.9999999867056404, \"npv\": 0.9998202401802362, \"accuracy\": 0.999820237299165, \"f1\": 0.3917869386718585, \"f2\": 0.2870499218940783, \"f0_5\": 0.6168647802147457, \"p4\": 0.5629841937317995, \"phi\": 0.49348780715711676}, {\"truth_threshold\": 19.719999559223652, \"match_probability\": 0.9999988420545107, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73960.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230001.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2433206891673603, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7566793108326397, \"precision\": 0.9997701988455872, \"recall\": 0.2433206891673603, \"specificity\": 0.9999999867056404, \"npv\": 0.9998201666966784, \"accuracy\": 0.9998201638066463, \"f1\": 0.3913869470653917, \"f2\": 0.2867064499647626, \"f0_5\": 0.6164679288311281, \"p4\": 0.5625711040628741, \"phi\": 0.4931744147255451}, {\"truth_threshold\": 19.739999558776617, \"match_probability\": 0.9999988579962699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73883.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24306736719513358, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7569326328048664, \"precision\": 0.9997699594046008, \"recall\": 0.24306736719513358, \"specificity\": 0.9999999867056404, \"npv\": 0.9998201065027081, \"accuracy\": 0.9998201036053277, \"f1\": 0.39105914608811176, \"f2\": 0.2864250579960054, \"f0_5\": 0.616142477579429, \"p4\": 0.5622323918528696, \"phi\": 0.4929175512249385}, {\"truth_threshold\": 19.759999558329582, \"match_probability\": 0.9999988737185547, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73826.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24287984313777097, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.757120156862229, \"precision\": 0.9997697818344325, \"recall\": 0.24287984313777097, \"specificity\": 0.9999999867056404, \"npv\": 0.9998200619435401, \"accuracy\": 0.9998200590407154, \"f1\": 0.3908164021556151, \"f2\": 0.28621673320735963, \"f0_5\": 0.6159013436603691, \"p4\": 0.5619814650189329, \"phi\": 0.49272731928521696}, {\"truth_threshold\": 19.779999557882547, \"match_probability\": 0.9999988892243865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73753.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230208.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24263968074851708, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.757360319251483, \"precision\": 0.999769554019249, \"recall\": 0.24263968074851708, \"specificity\": 0.9999999867056404, \"npv\": 0.9998200048765411, \"accuracy\": 0.999820001966738, \"f1\": 0.3905054125819697, \"f2\": 0.2859499043899958, \"f0_5\": 0.6155922549541684, \"p4\": 0.5616598639680739, \"phi\": 0.49248358161579614}, {\"truth_threshold\": 19.799999557435513, \"match_probability\": 0.9999989045167456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73690.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230271.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24243241731669524, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7575675826833048, \"precision\": 0.9997693570488556, \"recall\": 0.24243241731669524, \"specificity\": 0.9999999867056404, \"npv\": 0.9998199556269446, \"accuracy\": 0.9998199527111137, \"f1\": 0.3902369276719235, \"f2\": 0.2857196031797114, \"f0_5\": 0.6153252648261741, \"p4\": 0.561382102186251, \"phi\": 0.4922731356747272}, {\"truth_threshold\": 19.819999556988478, \"match_probability\": 0.9999989195985707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73585.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230376.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24208697826365883, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7579130217363412, \"precision\": 0.999769028015543, \"recall\": 0.24208697826365883, \"specificity\": 0.9999999867056404, \"npv\": 0.9998198735442944, \"accuracy\": 0.9998198706184066, \"f1\": 0.38978925371394973, \"f2\": 0.28533571781990097, \"f0_5\": 0.6148797815394849, \"p4\": 0.560918721246065, \"phi\": 0.4919221924203224}, {\"truth_threshold\": 19.839999556541443, \"match_probability\": 0.9999989344727602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73497.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2417974674382569, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7582025325617431, \"precision\": 0.9997687515303207, \"recall\": 0.2417974674382569, \"specificity\": 0.9999999867056404, \"npv\": 0.9998198047512266, \"accuracy\": 0.9998198018168997, \"f1\": 0.3894138684681105, \"f2\": 0.28501393716873047, \"f0_5\": 0.6145059421387686, \"p4\": 0.560529935157858, \"phi\": 0.49162787563384963}, {\"truth_threshold\": 19.859999556094408, \"match_probability\": 0.9999989491421728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73362.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230599.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24135333151292435, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7586466684870756, \"precision\": 0.9997683260878453, \"recall\": 0.24135333151292435, \"specificity\": 0.9999999867056404, \"npv\": 0.9998196992164249, \"accuracy\": 0.9998196962691335, \"f1\": 0.38883765304499923, \"f2\": 0.28452021101081815, \"f0_5\": 0.6139315823035866, \"p4\": 0.5599327405838456, \"phi\": 0.4911760242099855}, {\"truth_threshold\": 19.879999555647373, \"match_probability\": 0.9999989636096278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73286.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230675.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24110329943644085, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7588967005635592, \"precision\": 0.9997680858900727, \"recall\": 0.24110329943644085, \"specificity\": 0.9999999867056404, \"npv\": 0.99981963980425, \"accuracy\": 0.9998196368496503, \"f1\": 0.3885130836761525, \"f2\": 0.2842422159769212, \"f0_5\": 0.613607781999521, \"p4\": 0.5595961359040227, \"phi\": 0.49092146566654693}, {\"truth_threshold\": 19.89999955520034, \"match_probability\": 0.9999989778779054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73185.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230776.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24077101996637726, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7592289800336227, \"precision\": 0.9997677659080353, \"recall\": 0.24077101996637726, \"specificity\": 0.9999999867056404, \"npv\": 0.9998195608486076, \"accuracy\": 0.9998195578842843, \"f1\": 0.38808154564472125, \"f2\": 0.28387272447996426, \"f0_5\": 0.6131769579183906, \"p4\": 0.5591483522983038, \"phi\": 0.49058296639792537}, {\"truth_threshold\": 19.919999554753304, \"match_probability\": 0.9999989919497478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73116.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.24054401716009619, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7594559828399038, \"precision\": 0.999767546798299, \"recall\": 0.24054401716009619, \"specificity\": 0.9999999867056404, \"npv\": 0.9998195069086214, \"accuracy\": 0.9998195039376482, \"f1\": 0.38778659962767903, \"f2\": 0.28362026630420867, \"f0_5\": 0.6128822970261176, \"p4\": 0.5588421426093308, \"phi\": 0.4903515801045386}, {\"truth_threshold\": 19.93999955430627, \"match_probability\": 0.9999990058278594, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 73066.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230895.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.240379522372936, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.759620477627064, \"precision\": 0.9997673877645964, \"recall\": 0.240379522372936, \"specificity\": 0.9999999867056404, \"npv\": 0.9998194678216785, \"accuracy\": 0.9998194648458829, \"f1\": 0.38757280317416537, \"f2\": 0.28343730870716494, \"f0_5\": 0.6126686041929051, \"p4\": 0.558620100120946, \"phi\": 0.4901838406426987}, {\"truth_threshold\": 19.959999553859234, \"match_probability\": 0.9999990195149073, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72988.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 230973.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2401229105049661, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7598770894950339, \"precision\": 0.9997671392370385, \"recall\": 0.2401229105049661, \"specificity\": 0.9999999867056404, \"npv\": 0.9998194068460537, \"accuracy\": 0.999819403862729, \"f1\": 0.38723916745807313, \"f2\": 0.28315186651035146, \"f0_5\": 0.6123349569868838, \"p4\": 0.5582734594894606, \"phi\": 0.48992205243101233}, {\"truth_threshold\": 19.9799995534122, \"match_probability\": 0.999999033013522, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72927.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23992222686463066, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7600777731353694, \"precision\": 0.999766944505374, \"recall\": 0.23992222686463066, \"specificity\": 0.9999999867056404, \"npv\": 0.9998193591599934, \"accuracy\": 0.9998193561707754, \"f1\": 0.3869781509929558, \"f2\": 0.28292861199824954, \"f0_5\": 0.6120737842370039, \"p4\": 0.5580021524962486, \"phi\": 0.4897172231297569}, {\"truth_threshold\": 19.999999552965164, \"match_probability\": 0.9999990463262975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72820.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23957020802010784, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7604297919798921, \"precision\": 0.9997666021390228, \"recall\": 0.23957020802010784, \"specificity\": 0.9999999867056404, \"npv\": 0.9998192755139641, \"accuracy\": 0.9998192725143977, \"f1\": 0.38652009830200795, \"f2\": 0.2825369505719414, \"f0_5\": 0.6116151444039986, \"p4\": 0.5575257942482625, \"phi\": 0.489357725344593}, {\"truth_threshold\": 20.01999955251813, \"match_probability\": 0.9999990594557926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72767.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23939584354571802, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7606041564542819, \"precision\": 0.9997664321828973, \"recall\": 0.23939584354571802, \"specificity\": 0.9999999867056404, \"npv\": 0.9998192340818239, \"accuracy\": 0.9998192310771266, \"f1\": 0.3862931160333913, \"f2\": 0.2823429259646694, \"f0_5\": 0.6113877233459419, \"p4\": 0.5572896242484747, \"phi\": 0.4891795585291768}, {\"truth_threshold\": 20.039999552071095, \"match_probability\": 0.9999990724045303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72674.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231287.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23908988324160008, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7609101167583999, \"precision\": 0.9997661333590128, \"recall\": 0.23908988324160008, \"specificity\": 0.9999999867056404, \"npv\": 0.9998191613801523, \"accuracy\": 0.9998191583664431, \"f1\": 0.3858946720049276, \"f2\": 0.28200242911523554, \"f0_5\": 0.6109882718903695, \"p4\": 0.5568748650205408, \"phi\": 0.48886676929441736}, {\"truth_threshold\": 20.05999955162406, \"match_probability\": 0.9999990851749994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72564.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23872799470984765, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7612720052901524, \"precision\": 0.9997657789228586, \"recall\": 0.23872799470984765, \"specificity\": 0.9999999867056404, \"npv\": 0.9998190753889414, \"accuracy\": 0.9998190723645595, \"f1\": 0.3854231400481221, \"f2\": 0.2815996274521218, \"f0_5\": 0.6105151568691789, \"p4\": 0.55638371689897, \"phi\": 0.4884965450475067}, {\"truth_threshold\": 20.079999551177025, \"match_probability\": 0.9999990977696538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72484.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231477.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23846480305039133, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7615351969496087, \"precision\": 0.9997655204755796, \"recall\": 0.23846480305039133, \"specificity\": 0.9999999867056404, \"npv\": 0.9998190128498883, \"accuracy\": 0.999819009817735, \"f1\": 0.38508003463829016, \"f2\": 0.28130663758542934, \"f0_5\": 0.6101706329497529, \"p4\": 0.5560261278005831, \"phi\": 0.48822711475586733}, {\"truth_threshold\": 20.09999955072999, \"match_probability\": 0.9999991101909143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72387.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23814568316330056, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7618543168366995, \"precision\": 0.999765206342191, \"recall\": 0.23814568316330056, \"specificity\": 0.9999999867056404, \"npv\": 0.9998189370212969, \"accuracy\": 0.9998189339797103, \"f1\": 0.38466382368179824, \"f2\": 0.2809513385621402, \"f0_5\": 0.6097523994359619, \"p4\": 0.5555921092449858, \"phi\": 0.48790023100186103}, {\"truth_threshold\": 20.119999550282955, \"match_probability\": 0.9999991224411678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72299.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2378561723378986, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7621438276621014, \"precision\": 0.9997649206261409, \"recall\": 0.2378561723378986, \"specificity\": 0.9999999867056404, \"npv\": 0.9998188682283579, \"accuracy\": 0.9998188651782034, \"f1\": 0.3842860445894912, \"f2\": 0.2806289591355111, \"f0_5\": 0.6093724977875173, \"p4\": 0.5551979409138493, \"phi\": 0.48760348712772655}, {\"truth_threshold\": 20.13999954983592, \"match_probability\": 0.9999991345227689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72234.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231727.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23764232911459035, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7623576708854096, \"precision\": 0.9997647091389739, \"recall\": 0.23764232911459035, \"specificity\": 0.9999999867056404, \"npv\": 0.9998188174153976, \"accuracy\": 0.9998188143589086, \"f1\": 0.38400688973238495, \"f2\": 0.2803908096840683, \"f0_5\": 0.6090915989982545, \"p4\": 0.5549065371975185, \"phi\": 0.4873841853262516}, {\"truth_threshold\": 20.159999549388885, \"match_probability\": 0.9999991464380393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72166.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2374186162040525, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7625813837959475, \"precision\": 0.9997644874832025, \"recall\": 0.2374186162040525, \"specificity\": 0.9999999867056404, \"npv\": 0.9998187642572294, \"accuracy\": 0.9998187611941078, \"f1\": 0.383714747543494, \"f2\": 0.2801416429935087, \"f0_5\": 0.6087974718783586, \"p4\": 0.5546014503803769, \"phi\": 0.4871546562644569}, {\"truth_threshold\": 20.17999954894185, \"match_probability\": 0.9999991581892689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72086.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23715542454459618, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7628445754554039, \"precision\": 0.999764226176442, \"recall\": 0.23715542454459618, \"specificity\": 0.9999999867056404, \"npv\": 0.9998187017182151, \"accuracy\": 0.9998186986472833, \"f1\": 0.38337091558883596, \"f2\": 0.2798484720256346, \"f0_5\": 0.6084510941585791, \"p4\": 0.554242218389696, \"phi\": 0.48688448357241065}, {\"truth_threshold\": 20.199999548494816, \"match_probability\": 0.9999991697787161, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 72005.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 231956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23688894298939667, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7631110570106033, \"precision\": 0.999763961011913, \"recall\": 0.23688894298939667, \"specificity\": 0.9999999867056404, \"npv\": 0.9998186383974712, \"accuracy\": 0.9998186353186236, \"f1\": 0.38302263666176395, \"f2\": 0.2795515993123508, \"f0_5\": 0.6081000052360531, \"p4\": 0.5538781581577229, \"phi\": 0.48661078092852816}, {\"truth_threshold\": 20.21999954804778, \"match_probability\": 0.9999991812086082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71919.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232042.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23660601195548114, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7633939880445189, \"precision\": 0.9997636788256228, \"recall\": 0.23660601195548114, \"specificity\": 0.9999999867056404, \"npv\": 0.9998185711680482, \"accuracy\": 0.9998185680807873, \"f1\": 0.3826526947541481, \"f2\": 0.2792363602478684, \"f0_5\": 0.6077268233325728, \"p4\": 0.5534912524780684, \"phi\": 0.4863200145004145}, {\"truth_threshold\": 20.239999547600746, \"match_probability\": 0.9999991924811419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71833.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232128.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2363230809215656, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7636769190784344, \"precision\": 0.9997633959638135, \"recall\": 0.2363230809215656, \"specificity\": 0.9999999867056404, \"npv\": 0.9998185039386341, \"accuracy\": 0.999818500842951, \"f1\": 0.38228258353267996, \"f2\": 0.27892107907624014, \"f0_5\": 0.6073532072625689, \"p4\": 0.5531039624883282, \"phi\": 0.486029074160772}, {\"truth_threshold\": 20.25999954715371, \"match_probability\": 0.9999992035984836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71733.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232228.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2359940913472452, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7640059086527548, \"precision\": 0.9997630662020905, \"recall\": 0.2359940913472452, \"specificity\": 0.9999999867056404, \"npv\": 0.9998184257649083, \"accuracy\": 0.9998184226594204, \"f1\": 0.3818520085917101, \"f2\": 0.2785544201044739, \"f0_5\": 0.6069182230299461, \"p4\": 0.5526531412858724, \"phi\": 0.4856905523432382}, {\"truth_threshold\": 20.279999546706676, \"match_probability\": 0.9999992145627697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71670.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23578682791542335, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7642131720845766, \"precision\": 0.999762857979829, \"recall\": 0.23578682791542335, \"specificity\": 0.9999999867056404, \"npv\": 0.9998183765154672, \"accuracy\": 0.9998183734037962, \"f1\": 0.38158062867365194, \"f2\": 0.2783233957085305, \"f0_5\": 0.606643880489378, \"p4\": 0.5523688563260392, \"phi\": 0.48547716242541883}, {\"truth_threshold\": 20.29999954625964, \"match_probability\": 0.9999992253761075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71587.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232374.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23551376656873743, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7644862334312625, \"precision\": 0.9997625830959165, \"recall\": 0.23551376656873743, \"specificity\": 0.9999999867056404, \"npv\": 0.9998183116312904, \"accuracy\": 0.9998183085114658, \"f1\": 0.38122295741083434, \"f2\": 0.278018995718662, \"f0_5\": 0.6062820875474485, \"p4\": 0.5519940059375059, \"phi\": 0.48519588644027606}, {\"truth_threshold\": 20.319999545812607, \"match_probability\": 0.9999992360405752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71488.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23518806689016025, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7648119331098397, \"precision\": 0.9997622543878051, \"recall\": 0.23518806689016025, \"specificity\": 0.9999999867056404, \"npv\": 0.9998182342393316, \"accuracy\": 0.9998182311097705, \"f1\": 0.38079613067494794, \"f2\": 0.2776558648820172, \"f0_5\": 0.6058500188989137, \"p4\": 0.5515464243631184, \"phi\": 0.48486017523875435}, {\"truth_threshold\": 20.339999545365572, \"match_probability\": 0.9999992465582223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71381.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232580.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23483604804563743, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7651639519543626, \"precision\": 0.9997618980923836, \"recall\": 0.23483604804563743, \"specificity\": 0.9999999867056404, \"npv\": 0.9998181505934906, \"accuracy\": 0.9998181474533928, \"f1\": 0.380334559714833, \"f2\": 0.27726332733083603, \"f0_5\": 0.6053823829240119, \"p4\": 0.551062097586302, \"phi\": 0.48449707434604794}, {\"truth_threshold\": 20.359999544918537, \"match_probability\": 0.9999992569310698, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71318.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232643.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2346287846138156, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7653712153861845, \"precision\": 0.9997616878110325, \"recall\": 0.2346287846138156, \"specificity\": 0.9999999867056404, \"npv\": 0.9998181013440766, \"accuracy\": 0.9998180981977686, \"f1\": 0.38006267053206005, \"f2\": 0.27703217656596324, \"f0_5\": 0.6051067281406276, \"p4\": 0.5507766524293883, \"phi\": 0.4842831586636316}, {\"truth_threshold\": 20.379999544471502, \"match_probability\": 0.9999992671611116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71239.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2343688828501025, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7656311171498975, \"precision\": 0.9997614235994162, \"recall\": 0.2343688828501025, \"specificity\": 0.9999999867056404, \"npv\": 0.9998180395868819, \"accuracy\": 0.9998180364327793, \"f1\": 0.3797216011001634, \"f2\": 0.2767422888664439, \"f0_5\": 0.604760732446497, \"p4\": 0.5504184187283065, \"phi\": 0.4840147816111705}, {\"truth_threshold\": 20.399999544024467, \"match_probability\": 0.9999992772503137, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71171.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2341451699395646, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7658548300604354, \"precision\": 0.9997611957071416, \"recall\": 0.2341451699395646, \"specificity\": 0.9999999867056404, \"npv\": 0.9998179864287964, \"accuracy\": 0.9998179832679785, \"f1\": 0.3794279073114949, \"f2\": 0.27649273677732955, \"f0_5\": 0.6044626159096198, \"p4\": 0.5501098028979767, \"phi\": 0.483783654313067}, {\"truth_threshold\": 20.419999543577433, \"match_probability\": 0.9999992872006149, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71069.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232892.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23380960057375783, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7661903994262422, \"precision\": 0.9997608530512337, \"recall\": 0.23380960057375783, \"specificity\": 0.9999999867056404, \"npv\": 0.9998179066916787, \"accuracy\": 0.9998179035207774, \"f1\": 0.3789871669417433, \"f2\": 0.2761183591959159, \"f0_5\": 0.6040149242314786, \"p4\": 0.5496464226665219, \"phi\": 0.48343675622437227}, {\"truth_threshold\": 20.439999543130398, \"match_probability\": 0.9999992970139275, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70995.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 232966.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23356614828876074, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7664338517112392, \"precision\": 0.9997606038416043, \"recall\": 0.23356614828876074, \"specificity\": 0.9999999867056404, \"npv\": 0.9998178488431895, \"accuracy\": 0.9998178456649648, \"f1\": 0.3786672640430111, \"f2\": 0.2758467147839385, \"f0_5\": 0.6036897394427636, \"p4\": 0.5493099015013749, \"phi\": 0.48318492921165407}, {\"truth_threshold\": 20.459999542683363, \"match_probability\": 0.9999993066921377, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70923.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233038.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23332927579525004, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7666707242047499, \"precision\": 0.9997603608683394, \"recall\": 0.23332927579525004, \"specificity\": 0.9999999867056404, \"npv\": 0.9998177925581794, \"accuracy\": 0.9998177893728227, \"f1\": 0.3783558859538918, \"f2\": 0.2755823821247389, \"f0_5\": 0.603373029039289, \"p4\": 0.5489821979772171, \"phi\": 0.4829397823238541}, {\"truth_threshold\": 20.479999542236328, \"match_probability\": 0.9999993162371051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70824.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233137.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23300357611667286, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7669964238833271, \"precision\": 0.9997600259736593, \"recall\": 0.23300357611667286, \"specificity\": 0.9999999867056404, \"npv\": 0.9998177151663008, \"accuracy\": 0.9998177119711275, \"f1\": 0.37792754574415294, \"f2\": 0.27521887641497333, \"f0_5\": 0.6029370450772571, \"p4\": 0.5485311580555552, \"phi\": 0.48260250206923994}, {\"truth_threshold\": 20.499999541789293, \"match_probability\": 0.9999993256506644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70741.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233220.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23273051476998693, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.767269485230013, \"precision\": 0.9997597444811894, \"recall\": 0.23273051476998693, \"specificity\": 0.9999999867056404, \"npv\": 0.9998176502822099, \"accuracy\": 0.9998176470787972, \"f1\": 0.37756825781452236, \"f2\": 0.27491407599242035, \"f0_5\": 0.6025710698424002, \"p4\": 0.5481526135064683, \"phi\": 0.48231955003605964}, {\"truth_threshold\": 20.51999954134226, \"match_probability\": 0.9999993349346246, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70629.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2323620464467481, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7676379535532519, \"precision\": 0.9997593635874643, \"recall\": 0.2323620464467481, \"specificity\": 0.9999999867056404, \"npv\": 0.9998175627277872, \"accuracy\": 0.9998175595132429, \"f1\": 0.3770831831759684, \"f2\": 0.27450271669426113, \"f0_5\": 0.6020765670153185, \"p4\": 0.5476412271479106, \"phi\": 0.48193747197206727}, {\"truth_threshold\": 20.539999540895224, \"match_probability\": 0.99999934409077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70533.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23204621645540052, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7679537835445994, \"precision\": 0.9997590361445783, \"recall\": 0.23204621645540052, \"specificity\": 0.9999999867056404, \"npv\": 0.9998174876811515, \"accuracy\": 0.9998174844570535, \"f1\": 0.37666717399488936, \"f2\": 0.27415006599844216, \"f0_5\": 0.6016521058207557, \"p4\": 0.5472023654809768, \"phi\": 0.4816097352864375}, {\"truth_threshold\": 20.55999954044819, \"match_probability\": 0.9999993531208601, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70466.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23182579344060586, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7681742065593942, \"precision\": 0.9997588070882341, \"recall\": 0.23182579344060586, \"specificity\": 0.9999999867056404, \"npv\": 0.9998174353048603, \"accuracy\": 0.999817432074088, \"f1\": 0.3763767078655286, \"f2\": 0.27390391401253333, \"f0_5\": 0.6013555376152301, \"p4\": 0.546895785999679, \"phi\": 0.48138087021446174}, {\"truth_threshold\": 20.579999540001154, \"match_probability\": 0.9999993620266305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70404.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23162181990452724, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7683781800954728, \"precision\": 0.9997585947373653, \"recall\": 0.23162181990452724, \"specificity\": 0.9999999867056404, \"npv\": 0.9998173868372524, \"accuracy\": 0.999817383600299, \"f1\": 0.3761078256967482, \"f2\": 0.27367610873342585, \"f0_5\": 0.6010808595650949, \"p4\": 0.5466118724772069, \"phi\": 0.48116898767111393}, {\"truth_threshold\": 20.59999953955412, \"match_probability\": 0.9999993708097926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70320.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233641.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2313454686620981, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7686545313379018, \"precision\": 0.9997583064390008, \"recall\": 0.2313454686620981, \"specificity\": 0.9999999867056404, \"npv\": 0.9998173211714686, \"accuracy\": 0.9998173179261334, \"f1\": 0.37574339162912973, \"f2\": 0.27336743428802013, \"f0_5\": 0.6007083437978914, \"p4\": 0.5462268882665954, \"phi\": 0.4808817721062393}, {\"truth_threshold\": 20.619999539107084, \"match_probability\": 0.9999993794720347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70259.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233702.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23114478502176267, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7688552149782374, \"precision\": 0.9997580966475041, \"recall\": 0.23114478502176267, \"specificity\": 0.9999999867056404, \"npv\": 0.9998172734856072, \"accuracy\": 0.9998172702341798, \"f1\": 0.37547864054061997, \"f2\": 0.2731432525736323, \"f0_5\": 0.6004375582200269, \"p4\": 0.5459470801469203, \"phi\": 0.4806730913560197}, {\"truth_threshold\": 20.63999953866005, \"match_probability\": 0.9999993880150211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70177.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23087501357081994, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.76912498642918, \"precision\": 0.9997578140581816, \"recall\": 0.23087501357081994, \"specificity\": 0.9999999867056404, \"npv\": 0.9998172093833089, \"accuracy\": 0.9998172061236847, \"f1\": 0.3751226096136628, \"f2\": 0.27284186003835037, \"f0_5\": 0.6000731952997672, \"p4\": 0.5455706310224339, \"phi\": 0.48039242689013845}, {\"truth_threshold\": 20.659999538213015, \"match_probability\": 0.9999993964403938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 70078.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 233883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23054931389224276, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7694506861077572, \"precision\": 0.9997574720022826, \"recall\": 0.23054931389224276, \"specificity\": 0.9999999867056404, \"npv\": 0.9998171319915207, \"accuracy\": 0.9998171287219895, \"f1\": 0.37469255940287016, \"f2\": 0.2724779324680253, \"f0_5\": 0.5996327486861268, \"p4\": 0.545115657635489, \"phi\": 0.48005335729080933}, {\"truth_threshold\": 20.67999953776598, \"match_probability\": 0.9999994047497722, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69953.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234008.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.23013807692434227, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7698619230756577, \"precision\": 0.9997570387308846, \"recall\": 0.23013807692434227, \"specificity\": 0.9999999867056404, \"npv\": 0.9998170342746334, \"accuracy\": 0.9998170309925762, \"f1\": 0.37414924143759143, \"f2\": 0.27201834791035095, \"f0_5\": 0.5990757757677175, \"p4\": 0.5445404450132062, \"phi\": 0.4796248967852116}, {\"truth_threshold\": 20.699999537318945, \"match_probability\": 0.9999994129447529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69860.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2298321166202243, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7701678833797757, \"precision\": 0.9997567153712953, \"recall\": 0.2298321166202243, \"specificity\": 0.9999999867056404, \"npv\": 0.9998169615732817, \"accuracy\": 0.9998169582818928, \"f1\": 0.37374477714946047, \"f2\": 0.27167635902345844, \"f0_5\": 0.5986607686098148, \"p4\": 0.5441119418379787, \"phi\": 0.4793058737396617}, {\"truth_threshold\": 20.71999953687191, \"match_probability\": 0.9999994210269112, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69797.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22962485318840245, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7703751468115976, \"precision\": 0.9997564958317816, \"recall\": 0.22962485318840245, \"specificity\": 0.9999999867056404, \"npv\": 0.999816912323985, \"accuracy\": 0.9998169090262685, \"f1\": 0.37347067085813657, \"f2\": 0.27144466102182696, \"f0_5\": 0.5983793339357392, \"p4\": 0.5438214008737117, \"phi\": 0.47908964068335963}, {\"truth_threshold\": 20.739999536424875, \"match_probability\": 0.9999994289978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69701.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22930902319705487, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7706909768029451, \"precision\": 0.9997561605324307, \"recall\": 0.22930902319705487, \"specificity\": 0.9999999867056404, \"npv\": 0.9998168372774469, \"accuracy\": 0.9998168339700791, \"f1\": 0.37305280735604623, \"f2\": 0.27109155373291993, \"f0_5\": 0.5979500131255436, \"p4\": 0.5433782601951682, \"phi\": 0.4787599549390613}, {\"truth_threshold\": 20.75999953597784, \"match_probability\": 0.9999994368589514, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69611.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22901293258016653, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7709870674198335, \"precision\": 0.999755845349572, \"recall\": 0.22901293258016653, \"specificity\": 0.9999999867056404, \"npv\": 0.9998167669213276, \"accuracy\": 0.9998167636049017, \"f1\": 0.372660865282436, \"f2\": 0.27076046775036716, \"f0_5\": 0.5975470107627306, \"p4\": 0.5429623637613369, \"phi\": 0.4784506682765724}, {\"truth_threshold\": 20.779999535530806, \"match_probability\": 0.9999994446118762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69523.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234438.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2287234217547646, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7712765782452354, \"precision\": 0.9997555363819385, \"recall\": 0.2287234217547646, \"specificity\": 0.9999999867056404, \"npv\": 0.9998166981286872, \"accuracy\": 0.9998166948033947, \"f1\": 0.3722774503950458, \"f2\": 0.2704366944041625, \"f0_5\": 0.5971524820441111, \"p4\": 0.5425552858007168, \"phi\": 0.47814806125263504}, {\"truth_threshold\": 20.79999953508377, \"match_probability\": 0.9999994522580643, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69439.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22844707051233545, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7715529294876645, \"precision\": 0.9997552407279429, \"recall\": 0.22844707051233545, \"specificity\": 0.9999999867056404, \"npv\": 0.9998166324629938, \"accuracy\": 0.9998166291292291, \"f1\": 0.3719112948794511, \"f2\": 0.2701275966700381, \"f0_5\": 0.5967754410993752, \"p4\": 0.5421663200039811, \"phi\": 0.4778590303722733}, {\"truth_threshold\": 20.819999534636736, \"match_probability\": 0.9999994597989851, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69342.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234619.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22812795062524469, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7718720493747553, \"precision\": 0.9997548984270246, \"recall\": 0.22812795062524469, \"specificity\": 0.9999999867056404, \"npv\": 0.9998165566347634, \"accuracy\": 0.9998165532912044, \"f1\": 0.3714882674381228, \"f2\": 0.26977061211341713, \"f0_5\": 0.5963395063958018, \"p4\": 0.5417166807709572, \"phi\": 0.47752505092201947}, {\"truth_threshold\": 20.8399995341897, \"match_probability\": 0.999999467236088, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69260.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22785817917430196, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.772141820825698, \"precision\": 0.9997546083115608, \"recall\": 0.22785817917430196, \"specificity\": 0.9999999867056404, \"npv\": 0.999816492532557, \"accuracy\": 0.9998164891807093, \"f1\": 0.37113048510601815, \"f2\": 0.26946878932022744, \"f0_5\": 0.5959705301779995, \"p4\": 0.5413361745271202, \"phi\": 0.4772425355151567}, {\"truth_threshold\": 20.859999533742666, \"match_probability\": 0.9999994745708022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69201.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22766407532545294, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.772335924674547, \"precision\": 0.9997543991447312, \"recall\": 0.22766407532545294, \"specificity\": 0.9999999867056404, \"npv\": 0.9998164464102429, \"accuracy\": 0.9998164430524263, \"f1\": 0.3708729590893378, \"f2\": 0.26925160031189155, \"f0_5\": 0.5957047895005966, \"p4\": 0.5410621692734353, \"phi\": 0.4770391587562808}, {\"truth_threshold\": 20.87999953329563, \"match_probability\": 0.9999994818045373, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 69103.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22734166554261895, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7726583344573811, \"precision\": 0.999754050925926, \"recall\": 0.22734166554261895, \"specificity\": 0.9999999867056404, \"npv\": 0.9998163698003067, \"accuracy\": 0.9998163664325663, \"f1\": 0.37044502400283047, \"f2\": 0.26889080161000617, \"f0_5\": 0.5952629121650607, \"p4\": 0.5406066226424645, \"phi\": 0.4767011547986742}, {\"truth_threshold\": 20.899999532848597, \"match_probability\": 0.9999994889386836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68990.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 234971.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22696990732363692, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7730300926763631, \"precision\": 0.9997536481806194, \"recall\": 0.22696990732363692, \"specificity\": 0.9999999867056404, \"npv\": 0.9998162814643745, \"accuracy\": 0.9998162780851768, \"f1\": 0.3699513094957208, \"f2\": 0.2684747102971473, \"f0_5\": 0.5947526591021554, \"p4\": 0.5400806987470387, \"phi\": 0.47631111786979785}, {\"truth_threshold\": 20.91999953240156, \"match_probability\": 0.999999495974612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68892.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22664749754080293, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7733525024591971, \"precision\": 0.9997532978275697, \"recall\": 0.22664749754080293, \"specificity\": 0.9999999867056404, \"npv\": 0.9998162048544637, \"accuracy\": 0.9998162014653168, \"f1\": 0.3695228900152868, \"f2\": 0.2681137930792923, \"f0_5\": 0.5943094943555608, \"p4\": 0.5396240223755486, \"phi\": 0.4759725970183067}, {\"truth_threshold\": 20.939999531954527, \"match_probability\": 0.9999995029136749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68825.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235136.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22642707452600827, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7735729254739917, \"precision\": 0.999753057726388, \"recall\": 0.22642707452600827, \"specificity\": 0.9999999867056404, \"npv\": 0.9998161524783069, \"accuracy\": 0.9998161490823514, \"f1\": 0.36922986134768226, \"f2\": 0.26786701186126416, \"f0_5\": 0.5940061692060988, \"p4\": 0.5393115020940729, \"phi\": 0.4757410206869796}, {\"truth_threshold\": 20.959999531507492, \"match_probability\": 0.9999995097572058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68746.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235215.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22616717276229517, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7738328272377049, \"precision\": 0.9997527740209124, \"recall\": 0.22616717276229517, \"specificity\": 0.9999999867056404, \"npv\": 0.9998160907213529, \"accuracy\": 0.9998160873173622, \"f1\": 0.3688842145931037, \"f2\": 0.26757599795112436, \"f0_5\": 0.5936481564317209, \"p4\": 0.5389426916971047, \"phi\": 0.47546782312933356}, {\"truth_threshold\": 20.979999531060457, \"match_probability\": 0.9999995165065197, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68690.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235271.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22598293860067575, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7740170613993242, \"precision\": 0.999752572518084, \"recall\": 0.22598293860067575, \"specificity\": 0.9999999867056404, \"npv\": 0.9998160469442763, \"accuracy\": 0.9998160435345851, \"f1\": 0.36863911041463177, \"f2\": 0.2673696879298681, \"f0_5\": 0.5933941384511454, \"p4\": 0.5386810488906016, \"phi\": 0.4752740690070311}, {\"truth_threshold\": 20.999999530613422, \"match_probability\": 0.9999995231629142, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68609.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235352.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22571645704547622, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7742835429545237, \"precision\": 0.9997522804767872, \"recall\": 0.22571645704547622, \"specificity\": 0.9999999867056404, \"npv\": 0.9998159836238686, \"accuracy\": 0.9998159802059253, \"f1\": 0.36828445436904667, \"f2\": 0.2670712433922162, \"f0_5\": 0.5930263715177236, \"p4\": 0.5383022961623187, \"phi\": 0.47499367770453216}, {\"truth_threshold\": 21.019999530166388, \"match_probability\": 0.9999995297276678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68537.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22547958455196554, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7745204154480344, \"precision\": 0.9997520203051609, \"recall\": 0.22547958455196554, \"specificity\": 0.9999999867056404, \"npv\": 0.9998159273390685, \"accuracy\": 0.9998159239137833, \"f1\": 0.3679690750708025, \"f2\": 0.2668059277575954, \"f0_5\": 0.5926991215492834, \"p4\": 0.537965323827376, \"phi\": 0.4747443019959966}, {\"truth_threshold\": 21.039999529719353, \"match_probability\": 0.9999995362020428, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68450.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235511.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2251933636223068, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7748066363776932, \"precision\": 0.9997517052010457, \"recall\": 0.2251933636223068, \"specificity\": 0.9999999867056404, \"npv\": 0.9998158593282769, \"accuracy\": 0.9998158558941117, \"f1\": 0.3675878290568915, \"f2\": 0.26648529834284684, \"f0_5\": 0.5923032592687456, \"p4\": 0.5375577675961739, \"phi\": 0.4744427981701322}, {\"truth_threshold\": 21.059999529272318, \"match_probability\": 0.9999995425872834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68368.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2249235921713641, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.775076407828636, \"precision\": 0.9997514074723989, \"recall\": 0.2249235921713641, \"specificity\": 0.9999999867056404, \"npv\": 0.9998157952261598, \"accuracy\": 0.9998157917836166, \"f1\": 0.367228330638707, \"f2\": 0.26618305613718424, \"f0_5\": 0.5919297109442234, \"p4\": 0.5371732515786652, \"phi\": 0.4741584466811027}, {\"truth_threshold\": 21.079999528825283, \"match_probability\": 0.9999995488846164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68282.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235679.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22464066113744854, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7753593388625515, \"precision\": 0.9997510944523346, \"recall\": 0.22464066113744854, \"specificity\": 0.9999999867056404, \"npv\": 0.9998157279971192, \"accuracy\": 0.9998157245457804, \"f1\": 0.3668511255574061, \"f2\": 0.2658660289391446, \"f0_5\": 0.5915374846012437, \"p4\": 0.5367695792370543, \"phi\": 0.47386004110655205}, {\"truth_threshold\": 21.099999528378248, \"match_probability\": 0.9999995550952523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68189.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235772.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2243347008333306, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7756652991666694, \"precision\": 0.9997507550655368, \"recall\": 0.2243347008333306, \"specificity\": 0.9999999867056404, \"npv\": 0.9998156552959574, \"accuracy\": 0.9998156518350969, \"f1\": 0.3664430215467787, \"f2\": 0.2655231494100697, \"f0_5\": 0.5911128063316488, \"p4\": 0.5363325888945529, \"phi\": 0.4735371351255324}, {\"truth_threshold\": 21.119999527931213, \"match_probability\": 0.9999995612203846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68116.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2240945384440767, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7759054615559233, \"precision\": 0.9997504880160862, \"recall\": 0.2240945384440767, \"specificity\": 0.9999999867056404, \"npv\": 0.9998155982294615, \"accuracy\": 0.9998155947611196, \"f1\": 0.3661225389283353, \"f2\": 0.2652539726178896, \"f0_5\": 0.590779072772783, \"p4\": 0.535989238927388, \"phi\": 0.47328351698845084}, {\"truth_threshold\": 21.13999952748418, \"match_probability\": 0.9999995672611905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68046.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 235915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22386424574205244, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7761357542579476, \"precision\": 0.9997502314032587, \"recall\": 0.22386424574205244, \"specificity\": 0.9999999867056404, \"npv\": 0.9998155435081703, \"accuracy\": 0.9998155400326482, \"f1\": 0.36581510870266437, \"f2\": 0.26499582913715714, \"f0_5\": 0.5904587366130233, \"p4\": 0.5356597212602585, \"phi\": 0.4730401938329664}, {\"truth_threshold\": 21.159999527037144, \"match_probability\": 0.9999995732188309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67940.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236021.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22351551679327283, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7764844832067271, \"precision\": 0.9997498418117339, \"recall\": 0.22351551679327283, \"specificity\": 0.9999999867056404, \"npv\": 0.9998154606445119, \"accuracy\": 0.9998154571581057, \"f1\": 0.3653493512010712, \"f2\": 0.2646048725620248, \"f0_5\": 0.5899730630491378, \"p4\": 0.5351602185345721, \"phi\": 0.472671494654111}, {\"truth_threshold\": 21.17999952659011, \"match_probability\": 0.9999995790944508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67829.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2231503383657772, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7768496616342229, \"precision\": 0.9997494325383958, \"recall\": 0.2231503383657772, \"specificity\": 0.9999999867056404, \"npv\": 0.9998153738722052, \"accuracy\": 0.9998153703743868, \"f1\": 0.36486133935079224, \"f2\": 0.2641954054327758, \"f0_5\": 0.5894637130765019, \"p4\": 0.5346364833552283, \"phi\": 0.4722850955519073}, {\"truth_threshold\": 21.199999526143074, \"match_probability\": 0.9999995848891793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67735.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236226.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22284108816591602, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.777158911834084, \"precision\": 0.9997490848978627, \"recall\": 0.22284108816591602, \"specificity\": 0.9999999867056404, \"npv\": 0.9998153003893626, \"accuracy\": 0.9998152968818681, \"f1\": 0.3644478401347276, \"f2\": 0.26384859410593364, \"f0_5\": 0.589031756494698, \"p4\": 0.5341924220678372, \"phi\": 0.4719576273572998}, {\"truth_threshold\": 21.21999952569604, \"match_probability\": 0.9999995906041301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67650.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236311.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2225614470277437, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7774385529722563, \"precision\": 0.9997487697104941, \"recall\": 0.2225614470277437, \"specificity\": 0.9999999867056404, \"npv\": 0.9998152339421207, \"accuracy\": 0.9998152304258671, \"f1\": 0.3640737511705254, \"f2\": 0.2635349443830244, \"f0_5\": 0.5886406707632229, \"p4\": 0.5337904519257974, \"phi\": 0.4716613167954391}, {\"truth_threshold\": 21.239999525249004, \"match_probability\": 0.9999995962404017, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67561.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236400.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22226864630659854, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7777313536934014, \"precision\": 0.9997484388410429, \"recall\": 0.22226864630659854, \"specificity\": 0.9999999867056404, \"npv\": 0.9998151643679591, \"accuracy\": 0.9998151608425249, \"f1\": 0.36368187458113416, \"f2\": 0.2632064901489923, \"f0_5\": 0.5882306847091888, \"p4\": 0.5333691319175763, \"phi\": 0.4713508626215221}, {\"truth_threshold\": 21.25999952480197, \"match_probability\": 0.9999996017990771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67486.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22202190412585826, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7779780958741418, \"precision\": 0.9997481593410663, \"recall\": 0.22202190412585826, \"specificity\": 0.9999999867056404, \"npv\": 0.9998151057380553, \"accuracy\": 0.999815102204877, \"f1\": 0.36335149570348674, \"f2\": 0.26292966750224217, \"f0_5\": 0.5878847959747235, \"p4\": 0.5330137420459129, \"phi\": 0.47108908511933617}, {\"truth_threshold\": 21.279999524354935, \"match_probability\": 0.9999996072812246, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67409.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22176858215363154, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7782314178463684, \"precision\": 0.9997478717408714, \"recall\": 0.22176858215363154, \"specificity\": 0.9999999867056404, \"npv\": 0.9998150455446945, \"accuracy\": 0.9998150420035584, \"f1\": 0.36301216790033036, \"f2\": 0.26264542925495027, \"f0_5\": 0.5875293071740476, \"p4\": 0.5326485464345304, \"phi\": 0.470820175492957}, {\"truth_threshold\": 21.2999995239079, \"match_probability\": 0.9999996126878977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67341.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2215448692430937, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7784551307569063, \"precision\": 0.9997476172095371, \"recall\": 0.2215448692430937, \"specificity\": 0.9999999867056404, \"npv\": 0.9998149923869274, \"accuracy\": 0.9998149888387576, \"f1\": 0.36271238476889145, \"f2\": 0.26239438529553416, \"f0_5\": 0.5872150514568542, \"p4\": 0.5323257587707731, \"phi\": 0.4705825691149104}, {\"truth_threshold\": 21.319999523460865, \"match_probability\": 0.9999996180201358, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67238.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236723.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2212060099815437, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7787939900184563, \"precision\": 0.999747230689168, \"recall\": 0.2212060099815437, \"specificity\": 0.9999999867056404, \"npv\": 0.9998149118685555, \"accuracy\": 0.9998149083097212, \"f1\": 0.36225809232360673, \"f2\": 0.26201407685611167, \"f0_5\": 0.5867384782392435, \"p4\": 0.5318363344084305, \"phi\": 0.4702224367203871}, {\"truth_threshold\": 21.33999952301383, \"match_probability\": 0.9999996232789633, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67174.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22099545665397863, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7790045433460213, \"precision\": 0.9997469899242458, \"recall\": 0.22099545665397863, \"specificity\": 0.9999999867056404, \"npv\": 0.999814861837729, \"accuracy\": 0.9998148582722616, \"f1\": 0.3619756865111868, \"f2\": 0.26177773794167736, \"f0_5\": 0.5864420096905146, \"p4\": 0.5315319246685314, \"phi\": 0.46999852616311416}, {\"truth_threshold\": 21.359999522566795, \"match_probability\": 0.9999996284653911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67079.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22068291655837427, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7793170834416258, \"precision\": 0.9997466316919041, \"recall\": 0.22068291655837427, \"specificity\": 0.9999999867056404, \"npv\": 0.9998147875732303, \"accuracy\": 0.9998147839979076, \"f1\": 0.3615563107554904, \"f2\": 0.26142687888755517, \"f0_5\": 0.586001450174283, \"p4\": 0.5310796398418706, \"phi\": 0.4696659621413169}, {\"truth_threshold\": 21.37999952211976, \"match_probability\": 0.9999996335804159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 67015.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 236946.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2204723632308092, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7795276367691908, \"precision\": 0.9997463897839838, \"recall\": 0.2204723632308092, \"specificity\": 0.9999999867056404, \"npv\": 0.9998147375424162, \"accuracy\": 0.999814733960448, \"f1\": 0.3612736628453906, \"f2\": 0.2611904813871333, \"f0_5\": 0.5857043222295831, \"p4\": 0.5307746549082564, \"phi\": 0.4694417862171817}, {\"truth_threshold\": 21.399999521672726, \"match_probability\": 0.9999996386250206, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66927.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237034.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.22018285240540728, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7798171475945928, \"precision\": 0.9997460564053537, \"recall\": 0.22018285240540728, \"specificity\": 0.9999999867056404, \"npv\": 0.9998146687500551, \"accuracy\": 0.999814665158941, \"f1\": 0.36088486270069153, \"f2\": 0.2608653963086652, \"f0_5\": 0.5852953368419396, \"p4\": 0.5303549217828049, \"phi\": 0.4691333694469149}, {\"truth_threshold\": 21.41999952122569, \"match_probability\": 0.9999996436001749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66883.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2200380969927063, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7799619030072937, \"precision\": 0.999745889387145, \"recall\": 0.2200380969927063, \"specificity\": 0.9999999867056404, \"npv\": 0.9998146343538781, \"accuracy\": 0.9998146307581877, \"f1\": 0.36069039343581555, \"f2\": 0.2607028370430889, \"f0_5\": 0.585090655240648, \"p4\": 0.5301448905313244, \"phi\": 0.4689790850181813}, {\"truth_threshold\": 21.439999520778656, \"match_probability\": 0.9999996485068348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66834.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237127.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2198768921012893, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7801231078987106, \"precision\": 0.9997457031308432, \"recall\": 0.2198768921012893, \"specificity\": 0.9999999867056404, \"npv\": 0.9998145960490474, \"accuracy\": 0.9998145924482577, \"f1\": 0.3604737710753697, \"f2\": 0.26052179200823267, \"f0_5\": 0.5848625659604632, \"p4\": 0.5299108627370624, \"phi\": 0.46880720852285884}, {\"truth_threshold\": 21.45999952033162, \"match_probability\": 0.9999996533459433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66739.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237222.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21956435200568494, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7804356479943151, \"precision\": 0.9997453412427347, \"recall\": 0.21956435200568494, \"specificity\": 0.9999999867056404, \"npv\": 0.9998145217845881, \"accuracy\": 0.9998145181739035, \"f1\": 0.36005362581160294, \"f2\": 0.2601707469203181, \"f0_5\": 0.5844199059519952, \"p4\": 0.5294567466256171, \"phi\": 0.46847379897703684}, {\"truth_threshold\": 21.479999519884586, \"match_probability\": 0.9999996581184304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66659.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21930116034622862, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7806988396537714, \"precision\": 0.9997450356950027, \"recall\": 0.21930116034622862, \"specificity\": 0.9999999867056404, \"npv\": 0.9998144592461046, \"accuracy\": 0.9998144556270792, \"f1\": 0.35969965222036654, \"f2\": 0.2598750896672177, \"f0_5\": 0.5840466823793293, \"p4\": 0.5290739346786255, \"phi\": 0.46819284892784485}, {\"truth_threshold\": 21.49999951943755, \"match_probability\": 0.9999996628252132, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66548.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237413.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.218935981918733, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.781064018081267, \"precision\": 0.9997446105310599, \"recall\": 0.218935981918733, \"specificity\": 0.9999999867056404, \"npv\": 0.9998143724739718, \"accuracy\": 0.9998143688433602, \"f1\": 0.3592082606888585, \"f2\": 0.25946480413035156, \"f0_5\": 0.5835281408436378, \"p4\": 0.5285421787855318, \"phi\": 0.46780275131875854}, {\"truth_threshold\": 21.519999518990517, \"match_probability\": 0.9999996674671966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66468.0, \"tn\": 1278737775.0, \"fp\": 17.0, \"fn\": 237493.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2186727902592767, \"tn_rate\": 0.9999999867056404, \"fp_rate\": 1.3294359567969975e-08, \"fn_rate\": 0.7813272097407233, \"precision\": 0.9997443032262916, \"recall\": 0.2186727902592767, \"specificity\": 0.9999999867056404, \"npv\": 0.9998143099355069, \"accuracy\": 0.9998143062965358, \"f1\": 0.35885392202912164, \"f2\": 0.25916905879848307, \"f0_5\": 0.583153916206499, \"p4\": 0.5281584950480068, \"phi\": 0.46752139809776816}, {\"truth_threshold\": 21.539999518543482, \"match_probability\": 0.9999996720452723, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66382.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21838985922536114, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7816101407746389, \"precision\": 0.9997740861785924, \"recall\": 0.21838985922536114, \"specificity\": 0.9999999882696827, \"npv\": 0.9998142427069564, \"accuracy\": 0.99981424062237, \"f1\": 0.3584747730574201, \"f2\": 0.25885149515574685, \"f0_5\": 0.5827593411629202, \"p4\": 0.5277477247151375, \"phi\": 0.46722579413292326}, {\"truth_threshold\": 21.559999518096447, \"match_probability\": 0.9999996765603204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66306.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21813982714887764, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7818601728511223, \"precision\": 0.9997738272945221, \"recall\": 0.21813982714887764, \"specificity\": 0.9999999882696827, \"npv\": 0.9998141832954301, \"accuracy\": 0.9998141812028868, \"f1\": 0.35813785169141354, \"f2\": 0.25857046479977225, \"f0_5\": 0.5824030074923803, \"p4\": 0.5273825112798499, \"phi\": 0.4669581824154045}, {\"truth_threshold\": 21.579999517649412, \"match_probability\": 0.9999996810132086, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66252.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237709.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21796217277874463, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7820378272212554, \"precision\": 0.9997736429897234, \"recall\": 0.21796217277874463, \"specificity\": 0.9999999882696827, \"npv\": 0.9998141410819816, \"accuracy\": 0.9998141389837804, \"f1\": 0.3578983761357866, \"f2\": 0.25837076508976214, \"f0_5\": 0.5821495916728321, \"p4\": 0.5271228162196991, \"phi\": 0.4667679440298762}, {\"truth_threshold\": 21.599999517202377, \"match_probability\": 0.9999996854047924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66190.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237771.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.217758199242666, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.782241800757334, \"precision\": 0.9997734310097425, \"recall\": 0.217758199242666, \"specificity\": 0.9999999882696827, \"npv\": 0.9998140926146932, \"accuracy\": 0.9998140905099914, \"f1\": 0.3576233365571122, \"f2\": 0.2581414594917979, \"f0_5\": 0.5818583954105359, \"p4\": 0.5268244413451874, \"phi\": 0.4665494265395834}, {\"truth_threshold\": 21.619999516755342, \"match_probability\": 0.9999996897359162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66131.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21756409539381696, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7824359046061831, \"precision\": 0.9997732289178484, \"recall\": 0.21756409539381696, \"specificity\": 0.9999999882696827, \"npv\": 0.9998140464926005, \"accuracy\": 0.9998140443817083, \"f1\": 0.3573615197767132, \"f2\": 0.2579232287303333, \"f0_5\": 0.5815810533906727, \"p4\": 0.526540298799845, \"phi\": 0.4663413874152375}, {\"truth_threshold\": 21.639999516308308, \"match_probability\": 0.9999996940074122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 66067.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21735354206625193, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7826464579337481, \"precision\": 0.9997730092914864, \"recall\": 0.21735354206625193, \"specificity\": 0.9999999882696827, \"npv\": 0.9998139964618608, \"accuracy\": 0.9998139943442488, \"f1\": 0.3570774207321852, \"f2\": 0.25768648112293535, \"f0_5\": 0.5812799473507317, \"p4\": 0.5262318498975943, \"phi\": 0.46611561288849385}, {\"truth_threshold\": 21.659999515861273, \"match_probability\": 0.9999996982201012, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65982.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 237979.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2170739009280796, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7829260990719205, \"precision\": 0.9997727169416791, \"recall\": 0.2170739009280796, \"specificity\": 0.9999999882696827, \"npv\": 0.9998139300147922, \"accuracy\": 0.9998139278882477, \"f1\": 0.35669994972402275, \"f2\": 0.2573720141577622, \"f0_5\": 0.5808796212335967, \"p4\": 0.5258218263697979, \"phi\": 0.46581558694937625}, {\"truth_threshold\": 21.679999515414238, \"match_probability\": 0.9999997023747929, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65886.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21675807093673202, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.783241929063268, \"precision\": 0.9997723858515045, \"recall\": 0.21675807093673202, \"specificity\": 0.9999999882696827, \"npv\": 0.9998138549687019, \"accuracy\": 0.9998138528320584, \"f1\": 0.35627342089752395, \"f2\": 0.25701680131383386, \"f0_5\": 0.5804269114550756, \"p4\": 0.5253582397051412, \"phi\": 0.46547650162991455}, {\"truth_threshold\": 21.699999514967203, \"match_probability\": 0.9999997064722858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65781.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238180.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2164126318836956, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7835873681163044, \"precision\": 0.9997720226153566, \"recall\": 0.2164126318836956, \"specificity\": 0.9999999882696827, \"npv\": 0.9998137728870535, \"accuracy\": 0.9998137707393513, \"f1\": 0.3558066513953759, \"f2\": 0.25662822633500826, \"f0_5\": 0.5799310581949942, \"p4\": 0.5248505819046041, \"phi\": 0.46510534405957493}, {\"truth_threshold\": 21.71999951452017, \"match_probability\": 0.9999997105133673, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65719.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238242.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21620865834761696, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7837913416523831, \"precision\": 0.9997718075881583, \"recall\": 0.21620865834761696, \"specificity\": 0.9999999882696827, \"npv\": 0.9998137244198009, \"accuracy\": 0.9998137222655623, \"f1\": 0.3555309106155074, \"f2\": 0.2563987521633486, \"f0_5\": 0.5796379236439777, \"p4\": 0.5245505223825265, \"phi\": 0.4648860452343933}, {\"truth_threshold\": 21.739999514073133, \"match_probability\": 0.9999997144988141, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65657.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238304.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2160046848115383, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7839953151884617, \"precision\": 0.9997715921549519, \"recall\": 0.2160046848115383, \"specificity\": 0.9999999882696827, \"npv\": 0.9998136759525529, \"accuracy\": 0.9998136737917734, \"f1\": 0.3552550773334632, \"f2\": 0.25616925578767646, \"f0_5\": 0.5793445325060135, \"p4\": 0.5242502400399064, \"phi\": 0.46466664293272253}, {\"truth_threshold\": 21.7599995136261, \"match_probability\": 0.9999997184293921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65577.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21574149315208202, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.784258506847918, \"precision\": 0.9997713135748262, \"recall\": 0.21574149315208202, \"specificity\": 0.9999999882696827, \"npv\": 0.9998136134141753, \"accuracy\": 0.9998136112449489, \"f1\": 0.35489902666194023, \"f2\": 0.2558730986174885, \"f0_5\": 0.5789655836095273, \"p4\": 0.5238624493044464, \"phi\": 0.464383390051231}, {\"truth_threshold\": 21.779999513179064, \"match_probability\": 0.9999997223058567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65467.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2153796046203296, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7846203953796704, \"precision\": 0.9997709294157173, \"recall\": 0.2153796046203296, \"specificity\": 0.9999999882696827, \"npv\": 0.9998135274239188, \"accuracy\": 0.9998135252430653, \"f1\": 0.3544092052089226, \"f2\": 0.2554658221248925, \"f0_5\": 0.5784438290901572, \"p4\": 0.523328629643759, \"phi\": 0.4639936350568884}, {\"truth_threshold\": 21.79999951273203, \"match_probability\": 0.9999997261289529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65395.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238566.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2151427321268189, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7848572678731811, \"precision\": 0.9997706772664731, \"recall\": 0.2151427321268189, \"specificity\": 0.9999999882696827, \"npv\": 0.9998134711393954, \"accuracy\": 0.9998134689509233, \"f1\": 0.35408843682909596, \"f2\": 0.2551992032805361, \"f0_5\": 0.5781018774719281, \"p4\": 0.5229788389820738, \"phi\": 0.4637383453557178}, {\"truth_threshold\": 21.819999512284994, \"match_probability\": 0.9999997298994154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65267.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238694.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2147216254716888, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7852783745283112, \"precision\": 0.9997702276278301, \"recall\": 0.2147216254716888, \"specificity\": 0.9999999882696827, \"npv\": 0.999813371078036, \"accuracy\": 0.9998133688760041, \"f1\": 0.3535178730537884, \"f2\": 0.2547251402282055, \"f0_5\": 0.5774931028563642, \"p4\": 0.5223562423692493, \"phi\": 0.46328414972188625}, {\"truth_threshold\": 21.83999951183796, \"match_probability\": 0.9999997336179689, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65165.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21438605610588202, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.785613943894118, \"precision\": 0.9997698680576864, \"recall\": 0.21438605610588202, \"specificity\": 0.9999999882696827, \"npv\": 0.9998132913416546, \"accuracy\": 0.999813289128803, \"f1\": 0.3530629217561853, \"f2\": 0.2543473034072742, \"f0_5\": 0.5770071952128724, \"p4\": 0.5218594253114565, \"phi\": 0.46292189359335156}, {\"truth_threshold\": 21.859999511390924, \"match_probability\": 0.999999737285328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 65078.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 238883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21409983517622327, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7859001648237768, \"precision\": 0.9997695604750126, \"recall\": 0.21409983517622327, \"specificity\": 0.9999999882696827, \"npv\": 0.9998132233312217, \"accuracy\": 0.9998132211091314, \"f1\": 0.3526746763346285, \"f2\": 0.2540249832739627, \"f0_5\": 0.5765921893633723, \"p4\": 0.5214351882896257, \"phi\": 0.46261268630732777}, {\"truth_threshold\": 21.87999951094389, \"match_probability\": 0.9999997409021976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64957.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2137017577912956, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7862982422087044, \"precision\": 0.9997691313181063, \"recall\": 0.2137017577912956, \"specificity\": 0.9999999882696827, \"npv\": 0.9998131287420142, \"accuracy\": 0.9998131265070593, \"f1\": 0.35213439838669897, \"f2\": 0.2535766261508288, \"f0_5\": 0.5760141456311885, \"p4\": 0.5208444194338308, \"phi\": 0.46218229553545936}, {\"truth_threshold\": 21.899999510496855, \"match_probability\": 0.9999997444692725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64860.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2133826379042048, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7866173620957951, \"precision\": 0.9997687861271676, \"recall\": 0.2133826379042048, \"specificity\": 0.9999999882696827, \"npv\": 0.9998130529143154, \"accuracy\": 0.9998130506690347, \"f1\": 0.35170102701471656, \"f2\": 0.2532171381856598, \"f0_5\": 0.5755500380682957, \"p4\": 0.5203702066240131, \"phi\": 0.46183698194319156}, {\"truth_threshold\": 21.91999951004982, \"match_probability\": 0.9999997479872386, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64785.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21313589572346453, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7868641042765355, \"precision\": 0.9997685185185186, \"recall\": 0.21313589572346453, \"specificity\": 0.9999999882696827, \"npv\": 0.9998129942846593, \"accuracy\": 0.9998129920313868, \"f1\": 0.35136578976627136, \"f2\": 0.252939146242047, \"f0_5\": 0.5751907536210782, \"p4\": 0.520003167577708, \"phi\": 0.46156980983867735}, {\"truth_threshold\": 21.939999509602785, \"match_probability\": 0.9999997514567718, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64696.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21284309500231938, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7871569049976807, \"precision\": 0.9997682001514425, \"recall\": 0.21284309500231938, \"specificity\": 0.9999999882696827, \"npv\": 0.9998129247108096, \"accuracy\": 0.9998129224480445, \"f1\": 0.3509677979342071, \"f2\": 0.25260922022091986, \"f0_5\": 0.5747639057933032, \"p4\": 0.5195671843288237, \"phi\": 0.4612525648667743}, {\"truth_threshold\": 21.95999950915575, \"match_probability\": 0.999999754878539, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64575.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239386.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2124450176173917, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7875549823826083, \"precision\": 0.9997677659080353, \"recall\": 0.2124450176173917, \"specificity\": 0.9999999882696827, \"npv\": 0.9998128301216587, \"accuracy\": 0.9998128278459726, \"f1\": 0.35042639960276867, \"f2\": 0.25216059554807196, \"f0_5\": 0.5741827177003882, \"p4\": 0.5189736927587869, \"phi\": 0.46082090404856174}, {\"truth_threshold\": 21.979999508708715, \"match_probability\": 0.9999997582531976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64450.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239511.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21203378064949122, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7879662193505088, \"precision\": 0.9997673155976111, \"recall\": 0.21203378064949122, \"specificity\": 0.9999999882696827, \"npv\": 0.9998127324056125, \"accuracy\": 0.9998127301165594, \"f1\": 0.3498667303610494, \"f2\": 0.25169705125871955, \"f0_5\": 0.5735812652072457, \"p4\": 0.5183596718207042, \"phi\": 0.460374548508638}, {\"truth_threshold\": 21.99999950826168, \"match_probability\": 0.9999997615813965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64372.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2117771687815213, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7882228312184787, \"precision\": 0.9997670337179866, \"recall\": 0.2117771687815213, \"specificity\": 0.9999999882696827, \"npv\": 0.9998126714308093, \"accuracy\": 0.9998126691334055, \"f1\": 0.34951730428833605, \"f2\": 0.2514077537569392, \"f0_5\": 0.5732054161197773, \"p4\": 0.5179760533526012, \"phi\": 0.46009580328719885}, {\"truth_threshold\": 22.019999507814646, \"match_probability\": 0.999999764863775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64280.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239681.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21147449837314655, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7885255016268534, \"precision\": 0.9997667003655027, \"recall\": 0.21147449837314655, \"specificity\": 0.9999999882696827, \"npv\": 0.9998125995118203, \"accuracy\": 0.9998125972045574, \"f1\": 0.3491049704553354, \"f2\": 0.25106648574881324, \"f0_5\": 0.5727615697302461, \"p4\": 0.5175231158101203, \"phi\": 0.4597668096985206}, {\"truth_threshold\": 22.03999950736761, \"match_probability\": 0.999999768100964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64222.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21128368442004072, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7887163155799592, \"precision\": 0.9997664897177639, \"recall\": 0.21128368442004072, \"specificity\": 0.9999999882696827, \"npv\": 0.9998125541715934, \"accuracy\": 0.9998125518581097, \"f1\": 0.3488449149642312, \"f2\": 0.2508513133153293, \"f0_5\": 0.5724814542109327, \"p4\": 0.5172373095000684, \"phi\": 0.45955927967632826}, {\"truth_threshold\": 22.059999506920576, \"match_probability\": 0.9999997712935859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64103.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21089218682659946, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7891078131734005, \"precision\": 0.9997660563336349, \"recall\": 0.21089218682659946, \"specificity\": 0.9999999882696827, \"npv\": 0.9998124611459683, \"accuracy\": 0.9998124588197083, \"f1\": 0.34831109625922696, \"f2\": 0.2504097777902782, \"f0_5\": 0.5719060083899413, \"p4\": 0.5166502863846884, \"phi\": 0.45913319171106615}, {\"truth_threshold\": 22.07999950647354, \"match_probability\": 0.9999997744422539, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64017.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 239944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21060925579268394, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.789390744207316, \"precision\": 0.9997657421289355, \"recall\": 0.21060925579268394, \"specificity\": 0.9999999882696827, \"npv\": 0.9998123939173762, \"accuracy\": 0.999812391581872, \"f1\": 0.34792509640129027, \"f2\": 0.25009063378014745, \"f0_5\": 0.5714895311280885, \"p4\": 0.51622552520627, \"phi\": 0.4588250163340957}, {\"truth_threshold\": 22.099999506026506, \"match_probability\": 0.9999997775475732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63943.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.21036580350768685, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7896341964923131, \"precision\": 0.999765471090403, \"recall\": 0.21036580350768685, \"specificity\": 0.9999999882696827, \"npv\": 0.9998123360695249, \"accuracy\": 0.9998123337260594, \"f1\": 0.3475928125484142, \"f2\": 0.2498159871605139, \"f0_5\": 0.5711307572620594, \"p4\": 0.5158596791902531, \"phi\": 0.4585596764285812}, {\"truth_threshold\": 22.11999950557947, \"match_probability\": 0.9999997806101408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63832.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240129.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2100006250801912, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7899993749198088, \"precision\": 0.999765063354582, \"recall\": 0.2100006250801912, \"specificity\": 0.9999999882696827, \"npv\": 0.9998122492977607, \"accuracy\": 0.9998122469423404, \"f1\": 0.34709413607099354, \"f2\": 0.24940395767415727, \"f0_5\": 0.5705918844942961, \"p4\": 0.5153102954692546, \"phi\": 0.4581613784984617}, {\"truth_threshold\": 22.139999505132437, \"match_probability\": 0.9999997836305451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63760.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240201.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20976375258668054, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7902362474133194, \"precision\": 0.9997647981183849, \"recall\": 0.20976375258668054, \"specificity\": 0.9999999882696827, \"npv\": 0.9998121930133812, \"accuracy\": 0.9998121906501984, \"f1\": 0.34677050927839537, \"f2\": 0.24913665708308488, \"f0_5\": 0.5702418877367585, \"p4\": 0.5149535434351417, \"phi\": 0.4579028378747473}, {\"truth_threshold\": 22.159999504685402, \"match_probability\": 0.9999997866093666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63685.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240276.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20951701040594023, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7904829895940597, \"precision\": 0.9997645211930927, \"recall\": 0.20951701040594023, \"specificity\": 0.9999999882696827, \"npv\": 0.9998121343838259, \"accuracy\": 0.9998121320125505, \"f1\": 0.34643326325065754, \"f2\": 0.2488581869791113, \"f0_5\": 0.569876924123194, \"p4\": 0.5145815956787191, \"phi\": 0.4576333694374711}, {\"truth_threshold\": 22.179999504238367, \"match_probability\": 0.9999997895471778, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63588.0, \"tn\": 1278737777.0, \"fp\": 15.0, \"fn\": 240373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20919789051884946, \"tn_rate\": 0.9999999882696827, \"fp_rate\": 1.173031726585586e-08, \"fn_rate\": 0.7908021094811506, \"precision\": 0.999764162067827, \"recall\": 0.20919789051884946, \"specificity\": 0.9999999882696827, \"npv\": 0.9998120585562779, \"accuracy\": 0.9998120561745258, \"f1\": 0.3459968876168504, \"f2\": 0.24849798389460448, \"f0_5\": 0.5694043229167599, \"p4\": 0.5141000415254232, \"phi\": 0.4572846214799057}, {\"truth_threshold\": 22.199999503791332, \"match_probability\": 0.9999997924445434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63502.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2089149594849339, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7910850405150661, \"precision\": 0.9997795830971724, \"recall\": 0.2089149594849339, \"specificity\": 0.9999999890517038, \"npv\": 0.9998119913278869, \"accuracy\": 0.9998119897185248, \"f1\": 0.345610745706534, \"f2\": 0.24817877688844422, \"f0_5\": 0.568988844585816, \"p4\": 0.5136736614297911, \"phi\": 0.45697879855488704}, {\"truth_threshold\": 22.219999503344297, \"match_probability\": 0.99999979530202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63446.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240515.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2087307253233145, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7912692746766855, \"precision\": 0.9997793885912386, \"recall\": 0.2087307253233145, \"specificity\": 0.9999999890517038, \"npv\": 0.9998119475511693, \"accuracy\": 0.9998119459357477, \"f1\": 0.3453585940923355, \"f2\": 0.24797077160706135, \"f0_5\": 0.5687153662327604, \"p4\": 0.5133951020590559, \"phi\": 0.4567772035424753}, {\"truth_threshold\": 22.239999502897263, \"match_probability\": 0.9999997981201569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63349.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240612.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20841160543622372, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7915883945637763, \"precision\": 0.9997790508656471, \"recall\": 0.20841160543622372, \"specificity\": 0.9999999890517038, \"npv\": 0.9998118717236497, \"accuracy\": 0.9998118700977231, \"f1\": 0.34492164955189425, \"f2\": 0.24761043365147314, \"f0_5\": 0.5682411425639516, \"p4\": 0.5129121491378172, \"phi\": 0.4564278015332699}, {\"truth_threshold\": 22.259999502450228, \"match_probability\": 0.9999998008994958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63285.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20820105210865866, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7917989478913413, \"precision\": 0.9997788274696283, \"recall\": 0.20820105210865866, \"specificity\": 0.9999999890517038, \"npv\": 0.9998118216931275, \"accuracy\": 0.9998118200602635, \"f1\": 0.34463322986440126, \"f2\": 0.2473726549728998, \"f0_5\": 0.5679278910612269, \"p4\": 0.5125931881280379, \"phi\": 0.4561971217465631}, {\"truth_threshold\": 22.279999502003193, \"match_probability\": 0.9999998036405707, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63206.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20794115034494556, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7920588496550545, \"precision\": 0.9997785510914268, \"recall\": 0.20794115034494556, \"specificity\": 0.9999999890517038, \"npv\": 0.9998117599367088, \"accuracy\": 0.9998117582952744, \"f1\": 0.3442770731601036, \"f2\": 0.24707911410218722, \"f0_5\": 0.5675408240413332, \"p4\": 0.5121991284386984, \"phi\": 0.4559122154593379}, {\"truth_threshold\": 22.299999501556158, \"match_probability\": 0.9999998063439084, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63121.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240840.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20766150920677323, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7923384907932267, \"precision\": 0.9997782529500278, \"recall\": 0.20766150920677323, \"specificity\": 0.9999999890517038, \"npv\": 0.9998116934899376, \"accuracy\": 0.9998116918392733, \"f1\": 0.3438936953821344, \"f2\": 0.24676323848945136, \"f0_5\": 0.5671238686004159, \"p4\": 0.5117747173289351, \"phi\": 0.45560547178653826}, {\"truth_threshold\": 22.319999501109123, \"match_probability\": 0.9999998090100285, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63065.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20747727504515381, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7925227249548462, \"precision\": 0.9997780560883971, \"recall\": 0.20747727504515381, \"specificity\": 0.9999999890517038, \"npv\": 0.9998116497132461, \"accuracy\": 0.9998116480564962, \"f1\": 0.3436410200523104, \"f2\": 0.2465551092599007, \"f0_5\": 0.5668488900314053, \"p4\": 0.5114948654769339, \"phi\": 0.4554032689596198}, {\"truth_threshold\": 22.33999950066209, \"match_probability\": 0.9999998116394433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63000.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 240961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20726343182184556, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7927365681781544, \"precision\": 0.9997778271495223, \"recall\": 0.20726343182184556, \"specificity\": 0.9999999890517038, \"npv\": 0.9998115989010198, \"accuracy\": 0.9998115972372014, \"f1\": 0.34334763948497854, \"f2\": 0.24631350783276956, \"f0_5\": 0.5665294406465989, \"p4\": 0.5111697982497672, \"phi\": 0.4551684566314578}, {\"truth_threshold\": 22.359999500215054, \"match_probability\": 0.9999998142326582, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62951.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241010.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20710222693042857, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7928977730695714, \"precision\": 0.9997776542523624, \"recall\": 0.20710222693042857, \"specificity\": 0.9999999890517038, \"npv\": 0.9998115605964217, \"accuracy\": 0.9998115589272714, \"f1\": 0.3431264069594414, \"f2\": 0.24613136129007537, \"f0_5\": 0.5662884273893933, \"p4\": 0.5109245775176448, \"phi\": 0.4549913641675225}, {\"truth_threshold\": 22.37999949976802, \"match_probability\": 0.9999998167901716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62841.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241120.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20674033839867614, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7932596616013239, \"precision\": 0.9997772651340386, \"recall\": 0.20674033839867614, \"specificity\": 0.9999999890517038, \"npv\": 0.9998114746065185, \"accuracy\": 0.9998114729253877, \"f1\": 0.3426295472389427, \"f2\": 0.24572241004333312, \"f0_5\": 0.5657467576312477, \"p4\": 0.5103735488263674, \"phi\": 0.45459355843398774}, {\"truth_threshold\": 22.399999499320984, \"match_probability\": 0.9999998193124748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62747.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20643108819881498, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.793568911801185, \"precision\": 0.9997769315339143, \"recall\": 0.20643108819881498, \"specificity\": 0.9999999890517038, \"npv\": 0.9998114011242493, \"accuracy\": 0.999811399432869, \"f1\": 0.342204721832887, \"f2\": 0.24537288685716074, \"f0_5\": 0.5652831956468861, \"p4\": 0.5099020842947531, \"phi\": 0.4542533393577583}, {\"truth_threshold\": 22.41999949887395, \"match_probability\": 0.999999821800053, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62683.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241278.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20622053487124992, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7937794651287501, \"precision\": 0.9997767038295293, \"recall\": 0.20622053487124992, \"specificity\": 0.9999999890517038, \"npv\": 0.9998113510937743, \"accuracy\": 0.9998113493954095, \"f1\": 0.3419153543629213, \"f2\": 0.24513488421568022, \"f0_5\": 0.5649672194091382, \"p4\": 0.5095807779298439, \"phi\": 0.4540215549876569}, {\"truth_threshold\": 22.439999498426914, \"match_probability\": 0.9999998242533837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62593.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20592444425436157, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7940755557456384, \"precision\": 0.9997763828325906, \"recall\": 0.20592444425436157, \"specificity\": 0.9999999890517038, \"npv\": 0.9998112807384273, \"accuracy\": 0.9998112790302319, \"f1\": 0.34150826040461796, \"f2\": 0.24480015268477243, \"f0_5\": 0.5645223841021376, \"p4\": 0.5091285163575708, \"phi\": 0.45369540791217616}, {\"truth_threshold\": 22.45999949797988, \"match_probability\": 0.999999826672939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62539.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241422.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20574678988422856, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7942532101157714, \"precision\": 0.9997761897910572, \"recall\": 0.20574678988422856, \"specificity\": 0.9999999890517038, \"npv\": 0.9998112385252239, \"accuracy\": 0.9998112368111254, \"f1\": 0.3412639080635392, \"f2\": 0.24459929114351803, \"f0_5\": 0.5642552055044183, \"p4\": 0.5088569209527388, \"phi\": 0.45349960710118276}, {\"truth_threshold\": 22.479999497532845, \"match_probability\": 0.9999998290591833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62447.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2054441194758538, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7945558805241462, \"precision\": 0.9997758601367254, \"recall\": 0.2054441194758538, \"specificity\": 0.9999999890517038, \"npv\": 0.999811166606441, \"accuracy\": 0.9998111648822773, \"f1\": 0.3408474381996714, \"f2\": 0.2442570435068313, \"f0_5\": 0.5637995323263604, \"p4\": 0.5083937903517111, \"phi\": 0.4531658257249345}, {\"truth_threshold\": 22.49999949708581, \"match_probability\": 0.9999998314125756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62369.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241592.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2051875076078839, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.794812492392116, \"precision\": 0.9997755798855458, \"recall\": 0.2051875076078839, \"specificity\": 0.9999999890517038, \"npv\": 0.999811105631829, \"accuracy\": 0.9998111038991234, \"f1\": 0.3404941803332387, \"f2\": 0.24396683844105937, \"f0_5\": 0.5634127260868701, \"p4\": 0.5080007283675162, \"phi\": 0.45288264450690174}, {\"truth_threshold\": 22.519999496638775, \"match_probability\": 0.999999833733568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62302.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241659.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20496708459308924, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7950329154069108, \"precision\": 0.9997753385968291, \"recall\": 0.20496708459308924, \"specificity\": 0.9999999890517038, \"npv\": 0.9998110532562065, \"accuracy\": 0.999811051516158, \"f1\": 0.34019062075969825, \"f2\": 0.24371753145146147, \"f0_5\": 0.5630801211080483, \"p4\": 0.507662799007704, \"phi\": 0.45263925768019087}, {\"truth_threshold\": 22.53999949619174, \"match_probability\": 0.9999998360226068, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62215.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241746.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2046808636634305, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7953191363365695, \"precision\": 0.9997750245062591, \"recall\": 0.2046808636634305, \"specificity\": 0.9999999890517038, \"npv\": 0.9998109852460781, \"accuracy\": 0.9998109834964863, \"f1\": 0.33979628061935063, \"f2\": 0.2433937654578416, \"f0_5\": 0.5626477498611807, \"p4\": 0.5072235820070917, \"phi\": 0.4523230226709967}, {\"truth_threshold\": 22.559999495744705, \"match_probability\": 0.9999998382801315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62151.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241810.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20447031033586546, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7955296896641345, \"precision\": 0.9997747928898898, \"recall\": 0.20447031033586546, \"specificity\": 0.9999999890517038, \"npv\": 0.9998109352156448, \"accuracy\": 0.9998109334590268, \"f1\": 0.3395060716802412, \"f2\": 0.24315556463217394, \"f0_5\": 0.562329336018718, \"p4\": 0.5069001814027548, \"phi\": 0.45209024883233223}, {\"truth_threshold\": 22.57999949529767, \"match_probability\": 0.9999998405065764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62064.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241897.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20418408940620672, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7958159105937933, \"precision\": 0.9997744772705306, \"recall\": 0.20418408940620672, \"specificity\": 0.9999999890517038, \"npv\": 0.9998108672055324, \"accuracy\": 0.9998108654393552, \"f1\": 0.33911140616163854, \"f2\": 0.24283172212388549, \"f0_5\": 0.5618960188167809, \"p4\": 0.5064601524193318, \"phi\": 0.4517736295999115}, {\"truth_threshold\": 22.599999494850636, \"match_probability\": 0.9999998427023691, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61984.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 241977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2039208977467504, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7960791022532496, \"precision\": 0.999774186264073, \"recall\": 0.2039208977467504, \"specificity\": 0.9999999890517038, \"npv\": 0.9998108046675063, \"accuracy\": 0.9998108028925308, \"f1\": 0.33874832973092617, \"f2\": 0.24253389699195987, \"f0_5\": 0.5614970839908471, \"p4\": 0.506055114298669, \"phi\": 0.45148228955429975}, {\"truth_threshold\": 22.6199994944036, \"match_probability\": 0.9999998448679317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61900.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2036445465043213, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7963554534956787, \"precision\": 0.9997738798979229, \"recall\": 0.2036445465043213, \"specificity\": 0.9999999890517038, \"npv\": 0.9998107390025872, \"accuracy\": 0.9998107372183651, \"f1\": 0.3383669285958319, \"f2\": 0.2422211404663481, \"f0_5\": 0.5610777042766992, \"p4\": 0.5056293969639571, \"phi\": 0.4511761800726417}, {\"truth_threshold\": 22.639999493956566, \"match_probability\": 0.9999998470036803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61803.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2033254266172305, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7966745733827695, \"precision\": 0.9997735250820972, \"recall\": 0.2033254266172305, \"specificity\": 0.9999999890517038, \"npv\": 0.9998106631752509, \"accuracy\": 0.9998106613803404, \"f1\": 0.33792628315535655, \"f2\": 0.241859929981427, \"f0_5\": 0.5605927844870281, \"p4\": 0.5051372493440682, \"phi\": 0.4508224379659021}, {\"truth_threshold\": 22.65999949350953, \"match_probability\": 0.9999998491100255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61719.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242242.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20304907537480138, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7969509246251987, \"precision\": 0.9997732169180179, \"recall\": 0.20304907537480138, \"specificity\": 0.9999999890517038, \"npv\": 0.9998105975103505, \"accuracy\": 0.9998105957061747, \"f1\": 0.3375445044217296, \"f2\": 0.24154708483324291, \"f0_5\": 0.560172302062288, \"p4\": 0.5047105865280946, \"phi\": 0.4505158802257226}, {\"truth_threshold\": 22.679999493062496, \"match_probability\": 0.999999851187372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61595.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20264112830264408, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7973588716973559, \"precision\": 0.9997727604733074, \"recall\": 0.20264112830264408, \"specificity\": 0.9999999890517038, \"npv\": 0.9998105005764656, \"accuracy\": 0.9998104987585968, \"f1\": 0.3369806056295648, \"f2\": 0.24108519060975236, \"f0_5\": 0.5595506516205575, \"p4\": 0.5040799468335636, \"phi\": 0.4500629610485947}, {\"truth_threshold\": 22.69999949261546, \"match_probability\": 0.9999998532361191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61505.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242456.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20234503768575574, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7976549623142443, \"precision\": 0.9997724280303646, \"recall\": 0.20234503768575574, \"specificity\": 0.9999999890517038, \"npv\": 0.9998104302212383, \"accuracy\": 0.9998104283934193, \"f1\": 0.33657108460107255, \"f2\": 0.2407498886377639, \"f0_5\": 0.5590987515385328, \"p4\": 0.5036216229126896, \"phi\": 0.449733943770344}, {\"truth_threshold\": 22.719999492168427, \"match_probability\": 0.9999998552566605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61390.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242571.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2019666996752873, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7980333003247128, \"precision\": 0.9997720018239854, \"recall\": 0.2019666996752873, \"specificity\": 0.9999999890517038, \"npv\": 0.9998103403229067, \"accuracy\": 0.9998103384823591, \"f1\": 0.3360475141297059, \"f2\": 0.24032137846369694, \"f0_5\": 0.5585204621008522, \"p4\": 0.503035248967096, \"phi\": 0.44931318226085704}, {\"truth_threshold\": 22.73999949172139, \"match_probability\": 0.9999998572493844, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61285.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242676.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.2016212606222509, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7983787393777492, \"precision\": 0.9997716112824027, \"recall\": 0.2016212606222509, \"specificity\": 0.9999999890517038, \"npv\": 0.9998102582418354, \"accuracy\": 0.999810256389652, \"f1\": 0.33556918359524723, \"f2\": 0.239930062647644, \"f0_5\": 0.5579916125989471, \"p4\": 0.5024991397234614, \"phi\": 0.44892866436094825}, {\"truth_threshold\": 22.759999491274357, \"match_probability\": 0.999999859214674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61223.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20141728708617224, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7985827129138278, \"precision\": 0.9997713800480101, \"recall\": 0.20141728708617224, \"specificity\": 0.9999999890517038, \"npv\": 0.9998102097749236, \"accuracy\": 0.9998102079158631, \"f1\": 0.33528661164628504, \"f2\": 0.23969896975994476, \"f0_5\": 0.5576789595360979, \"p4\": 0.5021822547503746, \"phi\": 0.44870146099573055}, {\"truth_threshold\": 22.779999490827322, \"match_probability\": 0.999999861152907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61182.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242779.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20128240136070089, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7987175986392991, \"precision\": 0.9997712268775737, \"recall\": 0.20128240136070089, \"specificity\": 0.9999999890517038, \"npv\": 0.9998101777242263, \"accuracy\": 0.9998101758606156, \"f1\": 0.33509969684272795, \"f2\": 0.23954613794399549, \"f0_5\": 0.5574720498592243, \"p4\": 0.5019725689659633, \"phi\": 0.44855115040543536}, {\"truth_threshold\": 22.799999490380287, \"match_probability\": 0.9999998630644555, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61118.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20107184803313582, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7989281519668642, \"precision\": 0.9997709873715893, \"recall\": 0.20107184803313582, \"specificity\": 0.9999999890517038, \"npv\": 0.9998101276938738, \"accuracy\": 0.999810125823156, \"f1\": 0.3348078434809761, \"f2\": 0.23930755159063288, \"f0_5\": 0.5571488215807427, \"p4\": 0.5016450430015523, \"phi\": 0.4483164185277238}, {\"truth_threshold\": 22.819999489933252, \"match_probability\": 0.9999998649496874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61045.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20083168564388196, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.799168314356118, \"precision\": 0.9997707135721188, \"recall\": 0.20083168564388196, \"specificity\": 0.9999999890517038, \"npv\": 0.999810070628009, \"accuracy\": 0.9998100687491787, \"f1\": 0.33447482329735356, \"f2\": 0.23903538483346035, \"f0_5\": 0.5567797707758342, \"p4\": 0.5012711434865464, \"phi\": 0.44804852737671025}, {\"truth_threshold\": 22.839999489486217, \"match_probability\": 0.9999998668089647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60970.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 242991.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20058494346314165, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7994150565368583, \"precision\": 0.9997704315886135, \"recall\": 0.20058494346314165, \"specificity\": 0.9999999890517038, \"npv\": 0.9998100119987027, \"accuracy\": 0.9998100101115307, \"f1\": 0.33413254051980434, \"f2\": 0.2387557290410298, \"f0_5\": 0.556400199307534, \"p4\": 0.5008866498420169, \"phi\": 0.44777312985497597}, {\"truth_threshold\": 22.859999489039183, \"match_probability\": 0.9999998686426447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60893.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243068.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20033162149091496, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.799668378509085, \"precision\": 0.9997701413630617, \"recall\": 0.20033162149091496, \"specificity\": 0.9999999890517038, \"npv\": 0.9998099518059553, \"accuracy\": 0.9998099499102122, \"f1\": 0.3337809838078428, \"f2\": 0.23846858157933692, \"f0_5\": 0.5560100732483669, \"p4\": 0.5004915331523209, \"phi\": 0.4474902121062428}, {\"truth_threshold\": 22.879999488592148, \"match_probability\": 0.99999987045108, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60833.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243128.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.20013422774632272, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.7998657722536773, \"precision\": 0.9997699147040938, \"recall\": 0.20013422774632272, \"specificity\": 0.9999999890517038, \"npv\": 0.9998099049025209, \"accuracy\": 0.9998099030000939, \"f1\": 0.3335069406372667, \"f2\": 0.23824480630003658, \"f0_5\": 0.5557057745606551, \"p4\": 0.5001833899013274, \"phi\": 0.44726963268713266}, {\"truth_threshold\": 22.899999488145113, \"match_probability\": 0.999999872234618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60711.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243250.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19973286046565183, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8002671395343481, \"precision\": 0.9997694524495677, \"recall\": 0.19973286046565183, \"specificity\": 0.9999999890517038, \"npv\": 0.9998098095322177, \"accuracy\": 0.9998098076161865, \"f1\": 0.33294944143729127, \"f2\": 0.23778973169487902, \"f0_5\": 0.5550862102069813, \"p4\": 0.49955612820438555, \"phi\": 0.4468207854543893}, {\"truth_threshold\": 22.919999487698078, \"match_probability\": 0.9999998739936015, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60631.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243330.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19946966880619554, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8005303311938045, \"precision\": 0.999769148322203, \"recall\": 0.19946966880619554, \"specificity\": 0.9999999890517038, \"npv\": 0.9998097469943239, \"accuracy\": 0.999809745069362, \"f1\": 0.33258366565552955, \"f2\": 0.23749127489543584, \"f0_5\": 0.5546793378721816, \"p4\": 0.49914429604085214, \"phi\": 0.4465262145168688}, {\"truth_threshold\": 22.939999487251043, \"match_probability\": 0.9999998757283686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60538.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243423.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19916370850207757, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8008362914979225, \"precision\": 0.9997687937640375, \"recall\": 0.19916370850207757, \"specificity\": 0.9999999890517038, \"npv\": 0.9998096742940321, \"accuracy\": 0.9998096723586787, \"f1\": 0.3321582495000178, \"f2\": 0.23714427184040063, \"f0_5\": 0.5542057495024434, \"p4\": 0.49866502945578056, \"phi\": 0.4461835314011372}, {\"truth_threshold\": 22.95999948680401, \"match_probability\": 0.9999998774392526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60432.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243529.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19881497955329797, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.801185020446702, \"precision\": 0.9997683883135361, \"recall\": 0.19881497955329797, \"specificity\": 0.9999999890517038, \"npv\": 0.9998095914313468, \"accuracy\": 0.9998095894841362, \"f1\": 0.33167310177905474, \"f2\": 0.2367487013139647, \"f0_5\": 0.5536651732952202, \"p4\": 0.4981180965855644, \"phi\": 0.44579262517591073}, {\"truth_threshold\": 22.979999486356974, \"match_probability\": 0.9999998791265824, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60360.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243601.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19857810705978726, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8014218929402127, \"precision\": 0.9997681121012356, \"recall\": 0.19857810705978726, \"specificity\": 0.9999999890517038, \"npv\": 0.9998095351472666, \"accuracy\": 0.9998095331919943, \"f1\": 0.33134340648029975, \"f2\": 0.2364799744244322, \"f0_5\": 0.5532975101612043, \"p4\": 0.4977461860254714, \"phi\": 0.44552690839747416}, {\"truth_threshold\": 22.99999948590994, \"match_probability\": 0.9999998807906821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60284.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243677.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1983280749833038, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8016719250166963, \"precision\": 0.9997678198281866, \"recall\": 0.1983280749833038, \"specificity\": 0.9999999890517038, \"npv\": 0.9998094757362999, \"accuracy\": 0.9998094737725111, \"f1\": 0.33099525337740454, \"f2\": 0.23619628536636206, \"f0_5\": 0.5529089998587553, \"p4\": 0.4973532542539946, \"phi\": 0.4452462575728776}, {\"truth_threshold\": 23.019999485462904, \"match_probability\": 0.9999998824318719, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60201.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19805501363661784, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8019449863633822, \"precision\": 0.9997674997924105, \"recall\": 0.19805501363661784, \"specificity\": 0.9999999890517038, \"npv\": 0.9998094108532785, \"accuracy\": 0.9998094088801807, \"f1\": 0.3306148675365757, \"f2\": 0.2358864284488413, \"f0_5\": 0.5524842104103916, \"p4\": 0.4969237089866209, \"phi\": 0.4449395551365559}, {\"truth_threshold\": 23.03999948501587, \"match_probability\": 0.9999998840504668, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60109.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1977523432282431, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8022476567717569, \"precision\": 0.9997671440214227, \"recall\": 0.1977523432282431, \"specificity\": 0.9999999890517038, \"npv\": 0.9998093389347585, \"accuracy\": 0.9998093369513325, \"f1\": 0.33019303237714376, \"f2\": 0.23554292548318256, \"f0_5\": 0.5520127540852929, \"p4\": 0.4964470703889127, \"phi\": 0.4445993486238723}, {\"truth_threshold\": 23.059999484568834, \"match_probability\": 0.9999998856467781, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60022.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 243939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19746612229858435, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8025338777014156, \"precision\": 0.999766806582717, \"recall\": 0.19746612229858435, \"specificity\": 0.9999999890517038, \"npv\": 0.9998092709248634, \"accuracy\": 0.9998092689316609, \"f1\": 0.32979392687302367, \"f2\": 0.2352180455842242, \"f0_5\": 0.5515663337039726, \"p4\": 0.49599583601394936, \"phi\": 0.44427739197960125}, {\"truth_threshold\": 23.0799994841218, \"match_probability\": 0.9999998872211124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59942.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244019.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19720293063912805, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8027970693608719, \"precision\": 0.999766495429982, \"recall\": 0.19720293063912805, \"specificity\": 0.9999999890517038, \"npv\": 0.9998092083870369, \"accuracy\": 0.9998092063848364, \"f1\": 0.3294267648941929, \"f2\": 0.23491926634268695, \"f0_5\": 0.5511553279329147, \"p4\": 0.49558047817458434, \"phi\": 0.44398113388378835}, {\"truth_threshold\": 23.099999483674765, \"match_probability\": 0.9999998887737725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59874.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19697921772859017, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8030207822714098, \"precision\": 0.9997662302965535, \"recall\": 0.19697921772859017, \"specificity\": 0.9999999890517038, \"npv\": 0.9998091552298907, \"accuracy\": 0.9998091532200356, \"f1\": 0.32911455026673153, \"f2\": 0.23466527452474345, \"f0_5\": 0.5508055925065269, \"p4\": 0.49522709986526436, \"phi\": 0.44372915901268606}, {\"truth_threshold\": 23.11999948322773, \"match_probability\": 0.9999998903050566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59817.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244144.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19679169367122756, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8032083063287725, \"precision\": 0.9997660075880397, \"recall\": 0.19679169367122756, \"specificity\": 0.9999999890517038, \"npv\": 0.9998091106716988, \"accuracy\": 0.9998091086554233, \"f1\": 0.32885275102256234, \"f2\": 0.23445234875654067, \"f0_5\": 0.5505121621248515, \"p4\": 0.4949306559170336, \"phi\": 0.4435178345121052}, {\"truth_threshold\": 23.139999482780695, \"match_probability\": 0.9999998918152592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59737.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244224.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19652850201177124, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8034714979882287, \"precision\": 0.9997656942980033, \"recall\": 0.19652850201177124, \"specificity\": 0.9999999890517038, \"npv\": 0.9998090481338924, \"accuracy\": 0.9998090461085988, \"f1\": 0.3284851750835826, \"f2\": 0.23415347347708323, \"f0_5\": 0.5500999143591208, \"p4\": 0.4945142403316556, \"phi\": 0.44322106880799594}, {\"truth_threshold\": 23.15999948233366, \"match_probability\": 0.9999998933046703, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59659.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244302.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19627189014380134, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8037281098561987, \"precision\": 0.999765388031438, \"recall\": 0.19627189014380134, \"specificity\": 0.9999999890517038, \"npv\": 0.9998089871595386, \"accuracy\": 0.9998089851254449, \"f1\": 0.32812663282311333, \"f2\": 0.23386203398308295, \"f0_5\": 0.5496975046668866, \"p4\": 0.4941078366565387, \"phi\": 0.4429315308424159}, {\"truth_threshold\": 23.179999481886625, \"match_probability\": 0.9999998947735762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59579.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244382.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19600869848434502, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.803991301515655, \"precision\": 0.9997650730790529, \"recall\": 0.19600869848434502, \"specificity\": 0.9999999890517038, \"npv\": 0.9998089246217476, \"accuracy\": 0.9998089225786204, \"f1\": 0.3277587373540107, \"f2\": 0.23356308465255438, \"f0_5\": 0.5492842958108763, \"p4\": 0.49369060307301316, \"phi\": 0.4426343721227437}, {\"truth_threshold\": 23.19999948143959, \"match_probability\": 0.9999998962222593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59486.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19570273818022707, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8042972618197729, \"precision\": 0.9997647058823529, \"recall\": 0.19570273818022707, \"specificity\": 0.9999999890517038, \"npv\": 0.9998088519215755, \"accuracy\": 0.999808849867937, \"f1\": 0.3273308553049708, \"f2\": 0.23321550891367349, \"f0_5\": 0.5488033271766788, \"p4\": 0.4932050472340093, \"phi\": 0.44228867420628465}, {\"truth_threshold\": 23.219999480992556, \"match_probability\": 0.999999897650998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59418.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244543.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19547902526968922, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8045209747303108, \"precision\": 0.9997644366671153, \"recall\": 0.19547902526968922, \"specificity\": 0.9999999890517038, \"npv\": 0.999808798764467, \"accuracy\": 0.9998087967031363, \"f1\": 0.32701785670059685, \"f2\": 0.23296133542856606, \"f0_5\": 0.5484512330876203, \"p4\": 0.49284966156046106, \"phi\": 0.44203573475931957}, {\"truth_threshold\": 23.23999948054552, \"match_probability\": 0.9999998990600667, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59368.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244593.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.195314530482529, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.804685469517471, \"precision\": 0.9997642383213768, \"recall\": 0.195314530482529, \"specificity\": 0.9999999890517038, \"npv\": 0.9998087596783615, \"accuracy\": 0.999808757611371, \"f1\": 0.3267876359252827, \"f2\": 0.23277442586647387, \"f0_5\": 0.5481921147059312, \"p4\": 0.49258815667796013, \"phi\": 0.44184965751227145}, {\"truth_threshold\": 23.259999480098486, \"match_probability\": 0.9999999004497364, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59297.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244664.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19508094788476152, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8049190521152385, \"precision\": 0.9997639560958338, \"recall\": 0.19508094788476152, \"specificity\": 0.9999999890517038, \"npv\": 0.9998087041760969, \"accuracy\": 0.9998087021010642, \"f1\": 0.32646061353476186, \"f2\": 0.2325089891032855, \"f0_5\": 0.5478238375476945, \"p4\": 0.4922165400086725, \"phi\": 0.44158529312231803}, {\"truth_threshold\": 23.27999947965145, \"match_probability\": 0.9999999018202742, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59215.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244746.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19481117643381882, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8051888235661812, \"precision\": 0.9997636293032129, \"recall\": 0.19481117643381882, \"specificity\": 0.9999999890517038, \"npv\": 0.9998086400748976, \"accuracy\": 0.9998086379905692, \"f1\": 0.3260827665959966, \"f2\": 0.23220239154934658, \"f0_5\": 0.5473980221011432, \"p4\": 0.4917869398922341, \"phi\": 0.44127977382218475}, {\"truth_threshold\": 23.299999479204416, \"match_probability\": 0.9999999031719433, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59157.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.194620362480713, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.805379637519287, \"precision\": 0.9997633976103159, \"recall\": 0.194620362480713, \"specificity\": 0.9999999890517038, \"npv\": 0.9998085947350298, \"accuracy\": 0.9998085926441215, \"f1\": 0.32581540596807773, \"f2\": 0.23198550605286997, \"f0_5\": 0.5470965235968149, \"p4\": 0.4914828113131436, \"phi\": 0.4410635470453317}, {\"truth_threshold\": 23.31999947875738, \"match_probability\": 0.9999999045050036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59062.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1943078223851086, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8056921776148914, \"precision\": 0.999763017130476, \"recall\": 0.1943078223851086, \"specificity\": 0.9999999890517038, \"npv\": 0.9998085204714622, \"accuracy\": 0.9998085183697674, \"f1\": 0.3253773031399003, \"f2\": 0.2316302199353685, \"f0_5\": 0.5466021304359897, \"p4\": 0.4909841944762027, \"phi\": 0.44070915334941946}, {\"truth_threshold\": 23.339999478310347, \"match_probability\": 0.9999999058197113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58972.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 244989.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19401173176822026, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8059882682317797, \"precision\": 0.9997626555453837, \"recall\": 0.19401173176822026, \"specificity\": 0.9999999890517038, \"npv\": 0.9998084501165135, \"accuracy\": 0.9998084480045899, \"f1\": 0.3249620468002215, \"f2\": 0.2312935842426049, \"f0_5\": 0.5461331160111501, \"p4\": 0.49051127546008544, \"phi\": 0.4403731489218421}, {\"truth_threshold\": 23.35999947786331, \"match_probability\": 0.999999907116319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58863.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245098.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19365313313221105, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.806346866867789, \"precision\": 0.9997622161455237, \"recall\": 0.19365313313221105, \"specificity\": 0.9999999890517038, \"npv\": 0.9998083649088668, \"accuracy\": 0.9998083627845415, \"f1\": 0.3244588494038662, \"f2\": 0.23088581736709446, \"f0_5\": 0.5455642492895793, \"p4\": 0.4899378064534612, \"phi\": 0.43996586670373955}, {\"truth_threshold\": 23.379999477416277, \"match_probability\": 0.999999908395076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58790.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245171.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19341297074295716, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8065870292570428, \"precision\": 0.999761920957758, \"recall\": 0.19341297074295716, \"specificity\": 0.9999999890517038, \"npv\": 0.9998083078432033, \"accuracy\": 0.9998083057105642, \"f1\": 0.3241216765674748, \"f2\": 0.23061268679666858, \"f0_5\": 0.5451827507478991, \"p4\": 0.4895533034924306, \"phi\": 0.43969288881561464}, {\"truth_threshold\": 23.399999476969242, \"match_probability\": 0.9999999096562279, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58730.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245231.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19321557699836492, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8067844230016351, \"precision\": 0.9997616777883699, \"recall\": 0.19321557699836492, \"specificity\": 0.9999999890517038, \"npv\": 0.9998082609399231, \"accuracy\": 0.9998082588004459, \"f1\": 0.3238444465888256, \"f2\": 0.23038817249181695, \"f0_5\": 0.5448688807782728, \"p4\": 0.4892370110516855, \"phi\": 0.4394683964951515}, {\"truth_threshold\": 23.419999476522207, \"match_probability\": 0.9999999109000172, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58667.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245294.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19300831356654308, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.806991686433457, \"precision\": 0.999761421925325, \"recall\": 0.19300831356654308, \"specificity\": 0.9999999890517038, \"npv\": 0.9998082116914836, \"accuracy\": 0.9998082095448216, \"f1\": 0.32355325637956994, \"f2\": 0.2301524097212687, \"f0_5\": 0.5445390163082321, \"p4\": 0.48890464866858246, \"phi\": 0.43923255609428963}, {\"truth_threshold\": 23.439999476075172, \"match_probability\": 0.9999999121266828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58560.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19265629472202025, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8073437052779797, \"precision\": 0.9997609861030491, \"recall\": 0.19265629472202025, \"specificity\": 0.9999999890517038, \"npv\": 0.9998081280473197, \"accuracy\": 0.9998081258884439, \"f1\": 0.3230584633207828, \"f2\": 0.2297519338239102, \"f0_5\": 0.5439780625240359, \"p4\": 0.4883395599755833, \"phi\": 0.4388317113737378}, {\"truth_threshold\": 23.459999475628138, \"match_probability\": 0.9999999133364607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58436.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245525.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19224834764986298, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.807751652350137, \"precision\": 0.9997604790419161, \"recall\": 0.19224834764986298, \"specificity\": 0.9999999890517038, \"npv\": 0.9998080311139136, \"accuracy\": 0.9998080289408661, \"f1\": 0.32248469279354103, \"f2\": 0.22928774678370925, \"f0_5\": 0.5433268682556005, \"p4\": 0.4876837439531744, \"phi\": 0.43836672261557624}, {\"truth_threshold\": 23.479999475181103, \"match_probability\": 0.999999914529583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58388.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245573.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19209043265418918, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8079095673458108, \"precision\": 0.9997602821821171, \"recall\": 0.19209043265418918, \"specificity\": 0.9999999890517038, \"npv\": 0.9998079935913099, \"accuracy\": 0.9998079914127713, \"f1\": 0.3222624826486148, \"f2\": 0.22910803722358164, \"f0_5\": 0.5430744704400737, \"p4\": 0.4874296062915885, \"phi\": 0.4381865945201313}, {\"truth_threshold\": 23.499999474734068, \"match_probability\": 0.9999999157062794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58306.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19182066120324648, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8081793387967535, \"precision\": 0.9997599451303155, \"recall\": 0.19182066120324648, \"specificity\": 0.9999999890517038, \"npv\": 0.9998079294902016, \"accuracy\": 0.9998079273022763, \"f1\": 0.32188273743309753, \"f2\": 0.22880100206880746, \"f0_5\": 0.5426428734962522, \"p4\": 0.48699510088876946, \"phi\": 0.437878704304818}, {\"truth_threshold\": 23.519999474287033, \"match_probability\": 0.9999999168667758, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58270.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19170222495649114, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8082977750435089, \"precision\": 0.9997597968567703, \"recall\": 0.19170222495649114, \"specificity\": 0.9999999890517038, \"npv\": 0.9998079013482543, \"accuracy\": 0.9998078991562053, \"f1\": 0.3217159657138125, \"f2\": 0.228666193663431, \"f0_5\": 0.5424532253950404, \"p4\": 0.48680420137764724, \"phi\": 0.43774346459653574}, {\"truth_threshold\": 23.53999947384, \"match_probability\": 0.9999999180112954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58168.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19136665559068433, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8086333444093157, \"precision\": 0.9997593757519507, \"recall\": 0.19136665559068433, \"specificity\": 0.9999999890517038, \"npv\": 0.9998078216127453, \"accuracy\": 0.9998078194090041, \"f1\": 0.3212432657817492, \"f2\": 0.22828419514201437, \"f0_5\": 0.5419153364425208, \"p4\": 0.4862628514350943, \"phi\": 0.43736005836641934}, {\"truth_threshold\": 23.559999473392963, \"match_probability\": 0.999999919140058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58089.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19110675382697123, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8088932461730288, \"precision\": 0.9997590485861315, \"recall\": 0.19110675382697123, \"specificity\": 0.9999999890517038, \"npv\": 0.9998077598568207, \"accuracy\": 0.999807757644015, \"f1\": 0.32087697202704496, \"f2\": 0.22798829150663252, \"f0_5\": 0.5414981738454396, \"p4\": 0.4858430945414416, \"phi\": 0.4370628753979971}, {\"truth_threshold\": 23.57999947294593, \"match_probability\": 0.9999999202532805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57990.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 245971.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19078105414839402, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8092189458516059, \"precision\": 0.9997586373353562, \"recall\": 0.19078105414839402, \"specificity\": 0.9999999890517038, \"npv\": 0.9998076824664955, \"accuracy\": 0.9998076802423197, \"f1\": 0.32041771994529855, \"f2\": 0.22761742374286414, \"f0_5\": 0.5409747060041755, \"p4\": 0.48531648236034447, \"phi\": 0.43669017076123884}, {\"truth_threshold\": 23.599999472498894, \"match_probability\": 0.9999999213511771, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57894.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19046522415704648, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8095347758429535, \"precision\": 0.9997582372038406, \"recall\": 0.19046522415704648, \"specificity\": 0.9999999890517038, \"npv\": 0.9998076074213431, \"accuracy\": 0.9998076051861303, \"f1\": 0.31997214461586926, \"f2\": 0.2272577393401541, \"f0_5\": 0.5404663615842626, \"p4\": 0.4848052027102968, \"phi\": 0.43632845622617855}, {\"truth_threshold\": 23.61999947205186, \"match_probability\": 0.9999999224339586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57842.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19029414957839985, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8097058504216001, \"precision\": 0.9997580199115044, \"recall\": 0.19029414957839985, \"specificity\": 0.9999999890517038, \"npv\": 0.9998075667718903, \"accuracy\": 0.9998075645306944, \"f1\": 0.3197306925876894, \"f2\": 0.2270628876501531, \"f0_5\": 0.5401907038859886, \"p4\": 0.4845280020529208, \"phi\": 0.4361324022842271}, {\"truth_threshold\": 23.639999471604824, \"match_probability\": 0.9999999235018331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57770.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246191.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.19005727708488918, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8099427229151108, \"precision\": 0.999757718399557, \"recall\": 0.19005727708488918, \"specificity\": 0.9999999890517038, \"npv\": 0.9998075104880381, \"accuracy\": 0.9998075082385524, \"f1\": 0.31939625979626535, \"f2\": 0.22679306673534189, \"f0_5\": 0.53980867020372, \"p4\": 0.4841438866077733, \"phi\": 0.4358607974199724}, {\"truth_threshold\": 23.65999947115779, \"match_probability\": 0.9999999245550059, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57677.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246284.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18975131678077123, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8102486832192288, \"precision\": 0.9997573278327642, \"recall\": 0.18975131678077123, \"specificity\": 0.9999999890517038, \"npv\": 0.9998074377880715, \"accuracy\": 0.999807435527869, \"f1\": 0.31896408702288387, \"f2\": 0.2264445028994099, \"f0_5\": 0.5393146009631119, \"p4\": 0.48364722262475357, \"phi\": 0.43550972381875186}, {\"truth_threshold\": 23.679999470710754, \"match_probability\": 0.9999999255936793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57604.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18951115439151733, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8104888456084827, \"precision\": 0.9997570203755771, \"recall\": 0.18951115439151733, \"specificity\": 0.9999999890517038, \"npv\": 0.9998073807225138, \"accuracy\": 0.9998073784538917, \"f1\": 0.3186246988901457, \"f2\": 0.22617086336302145, \"f0_5\": 0.5389263013324401, \"p4\": 0.4832569608997575, \"phi\": 0.43523395156770317}, {\"truth_threshold\": 23.69999947026372, \"match_probability\": 0.999999926618053, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57508.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246453.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18919532440016976, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8108046755998303, \"precision\": 0.9997566148604012, \"recall\": 0.18919532440016976, \"specificity\": 0.9999999890517038, \"npv\": 0.9998073056774067, \"accuracy\": 0.9998073033977023, \"f1\": 0.31817817158759887, \"f2\": 0.22581096087063735, \"f0_5\": 0.5384150143526156, \"p4\": 0.4827431939273387, \"phi\": 0.43487102600809624}, {\"truth_threshold\": 23.719999469816685, \"match_probability\": 0.9999999276283239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57430.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246531.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18893871253219985, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8110612874678002, \"precision\": 0.9997562843813105, \"recall\": 0.18893871253219985, \"specificity\": 0.9999999890517038, \"npv\": 0.9998072447032655, \"accuracy\": 0.9998072424145484, \"f1\": 0.3178151934809978, \"f2\": 0.22551850013508334, \"f0_5\": 0.537999051967542, \"p4\": 0.4823253007397355, \"phi\": 0.43457592585860577}, {\"truth_threshold\": 23.73999946936965, \"match_probability\": 0.999999928624686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57344.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18865578149828433, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8113442185017157, \"precision\": 0.9997559189650964, \"recall\": 0.18865578149828433, \"specificity\": 0.9999999890517038, \"npv\": 0.999807177475375, \"accuracy\": 0.9998071751767121, \"f1\": 0.3174148051998373, \"f2\": 0.22519600189129454, \"f0_5\": 0.5375398627278574, \"p4\": 0.4818640704765872, \"phi\": 0.43425032662314633}, {\"truth_threshold\": 23.759999468922615, \"match_probability\": 0.999999929607331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57267.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246694.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1884024595260576, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8115975404739424, \"precision\": 0.9997555908590982, \"recall\": 0.1884024595260576, \"specificity\": 0.9999999890517038, \"npv\": 0.9998071172829689, \"accuracy\": 0.9998071149753937, \"f1\": 0.3170561562608999, \"f2\": 0.22490721649484535, \"f0_5\": 0.5371282253299192, \"p4\": 0.4814506840555573, \"phi\": 0.4339585944776112}, {\"truth_threshold\": 23.77999946847558, \"match_probability\": 0.9999999305764475, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57202.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246759.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18818861630274936, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8118113836972506, \"precision\": 0.9997553131991052, \"recall\": 0.18818861630274936, \"specificity\": 0.9999999890517038, \"npv\": 0.9998070664712032, \"accuracy\": 0.9998070641560988, \"f1\": 0.3167532816319976, \"f2\": 0.22466340942296514, \"f0_5\": 0.536780368789002, \"p4\": 0.48110140890949515, \"phi\": 0.4337121743679025}, {\"truth_threshold\": 23.799999468028545, \"match_probability\": 0.999999931532222, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57115.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246846.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1879023953730906, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8120976046269094, \"precision\": 0.999754940573089, \"recall\": 0.1879023953730906, \"specificity\": 0.9999999890517038, \"npv\": 0.9998069984616171, \"accuracy\": 0.9998069961364271, \"f1\": 0.3163477249439198, \"f2\": 0.2243370440692772, \"f0_5\": 0.53631424455892, \"p4\": 0.48063346906930104, \"phi\": 0.43338213129395675}, {\"truth_threshold\": 23.81999946758151, \"match_probability\": 0.9999999324748381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57037.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 246924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18764578350512073, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8123542164948793, \"precision\": 0.9997546055283869, \"recall\": 0.18764578350512073, \"specificity\": 0.9999999890517038, \"npv\": 0.9998069374875135, \"accuracy\": 0.9998069351532733, \"f1\": 0.3159839562119819, \"f2\": 0.22404440271978443, \"f0_5\": 0.5358958217845969, \"p4\": 0.48021349967983323, \"phi\": 0.4330860168111068}, {\"truth_threshold\": 23.839999467134476, \"match_probability\": 0.9999999334044769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56940.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247021.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18732666361802994, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.81267333638197, \"precision\": 0.9997541875899849, \"recall\": 0.18732666361802994, \"specificity\": 0.9999999890517038, \"npv\": 0.9998068616607538, \"accuracy\": 0.9998068593152486, \"f1\": 0.3155313577989277, \"f2\": 0.22368042690199072, \"f0_5\": 0.5353747905607049, \"p4\": 0.4796906525580751, \"phi\": 0.4327174892411767}, {\"truth_threshold\": 23.85999946668744, \"match_probability\": 0.9999999343213171, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56859.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18706018206283043, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8129398179371695, \"precision\": 0.9997538374975823, \"recall\": 0.18706018206283043, \"specificity\": 0.9999999890517038, \"npv\": 0.9998067983415098, \"accuracy\": 0.9998067959865888, \"f1\": 0.31515322835431253, \"f2\": 0.22337644582416988, \"f0_5\": 0.5349391197340122, \"p4\": 0.47925355696043515, \"phi\": 0.4324095091223287}, {\"truth_threshold\": 23.879999466240406, \"match_probability\": 0.9999999352255348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56801.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1868693681097246, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8131306318902753, \"precision\": 0.9997535862008272, \"recall\": 0.1868693681097246, \"specificity\": 0.9999999890517038, \"npv\": 0.999806753001809, \"accuracy\": 0.9998067506401411, \"f1\": 0.3148823646805774, \"f2\": 0.22315875658758552, \"f0_5\": 0.5346268313940902, \"p4\": 0.47894029980110214, \"phi\": 0.43218884533367596}, {\"truth_threshold\": 23.89999946579337, \"match_probability\": 0.9999999361173039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56726.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247235.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18662262592898432, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8133773740710157, \"precision\": 0.9997532604864293, \"recall\": 0.18662262592898432, \"specificity\": 0.9999999890517038, \"npv\": 0.9998066943728917, \"accuracy\": 0.9998066920024932, \"f1\": 0.3145319807818664, \"f2\": 0.22287723246559757, \"f0_5\": 0.5342226056230588, \"p4\": 0.478534885017107, \"phi\": 0.43190333710892437}, {\"truth_threshold\": 23.919999465346336, \"match_probability\": 0.9999999369967958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56661.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18640878270567607, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8135912172943239, \"precision\": 0.9997529775033084, \"recall\": 0.18640878270567607, \"specificity\": 0.9999999890517038, \"npv\": 0.9998066435611691, \"accuracy\": 0.9998066411831983, \"f1\": 0.31422819685222775, \"f2\": 0.22263321805018235, \"f0_5\": 0.5338719069236292, \"p4\": 0.47818321417779297, \"phi\": 0.4316557439220534}, {\"truth_threshold\": 23.9399994648993, \"match_probability\": 0.9999999378641794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56583.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18615217083770616, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8138478291622938, \"precision\": 0.9997526370655688, \"recall\": 0.18615217083770616, \"specificity\": 0.9999999890517038, \"npv\": 0.9998065825871086, \"accuracy\": 0.9998065802000445, \"f1\": 0.3138635115570865, \"f2\": 0.22234036784416725, \"f0_5\": 0.5334506145952947, \"p4\": 0.4777608270054915, \"phi\": 0.4313584445397112}, {\"truth_threshold\": 23.959999464452267, \"match_probability\": 0.9999999387196216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56478.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247483.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18580673178466975, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8141932682153302, \"precision\": 0.9997521772994407, \"recall\": 0.18580673178466975, \"specificity\": 0.9999999890517038, \"npv\": 0.9998065005066544, \"accuracy\": 0.9998064981073373, \"f1\": 0.3133723398057444, \"f2\": 0.22194608971215152, \"f0_5\": 0.532882706928664, \"p4\": 0.4771915694981985, \"phi\": 0.4309579100175467}, {\"truth_threshold\": 23.979999464005232, \"match_probability\": 0.9999999395632866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56415.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247546.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1855994683528479, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8144005316471521, \"precision\": 0.9997519006184763, \"recall\": 0.1855994683528479, \"specificity\": 0.9999999890517038, \"npv\": 0.9998064512583883, \"accuracy\": 0.9998064488517131, \"f1\": 0.31307749937567636, \"f2\": 0.22170949159496428, \"f0_5\": 0.5325415300267899, \"p4\": 0.4768496512219676, \"phi\": 0.43071741055190016}, {\"truth_threshold\": 23.999999463558197, \"match_probability\": 0.9999999403953366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56347.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18537575544231003, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.81462424455769, \"precision\": 0.9997516012845762, \"recall\": 0.18537575544231003, \"specificity\": 0.9999999890517038, \"npv\": 0.9998063981015352, \"accuracy\": 0.9998063956869123, \"f1\": 0.3127591432107948, \"f2\": 0.22145408955317736, \"f0_5\": 0.5321729110983084, \"p4\": 0.47648028994854025, \"phi\": 0.4304576730657121}, {\"truth_threshold\": 24.019999463111162, \"match_probability\": 0.9999999412159316, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56289.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247672.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1851849414892042, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8148150585107958, \"precision\": 0.9997513453990018, \"recall\": 0.1851849414892042, \"specificity\": 0.9999999890517038, \"npv\": 0.9998063527618708, \"accuracy\": 0.9998063503404646, \"f1\": 0.3124875091599494, \"f2\": 0.2212362250588965, \"f0_5\": 0.5318582013821567, \"p4\": 0.4761649946559915, \"phi\": 0.4302360083786005}, {\"truth_threshold\": 24.039999462664127, \"match_probability\": 0.9999999420252291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56206.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18491188014251828, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8150881198574818, \"precision\": 0.9997509782995375, \"recall\": 0.18491188014251828, \"specificity\": 0.9999999890517038, \"npv\": 0.9998062878792547, \"accuracy\": 0.9998062854481342, \"f1\": 0.31209863929524323, \"f2\": 0.2209244188971624, \"f0_5\": 0.5314073606244599, \"p4\": 0.47571339236793847, \"phi\": 0.42991859980208713}, {\"truth_threshold\": 24.059999462217093, \"match_probability\": 0.9999999428233849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56117.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18461907942137315, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8153809205786269, \"precision\": 0.999750583456557, \"recall\": 0.18461907942137315, \"specificity\": 0.9999999890517038, \"npv\": 0.9998062183063384, \"accuracy\": 0.999806215864792, \"f1\": 0.31168145918265333, \"f2\": 0.22059002731971933, \"f0_5\": 0.5309232996206137, \"p4\": 0.47522861510453784, \"phi\": 0.4295779855013451}, {\"truth_threshold\": 24.079999461770058, \"match_probability\": 0.9999999436105522, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56041.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 247920.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18436904734488965, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8156309526551103, \"precision\": 0.9997502452947997, \"recall\": 0.18436904734488965, \"specificity\": 0.9999999890517038, \"npv\": 0.9998061588957659, \"accuracy\": 0.9998061564453088, \"f1\": 0.3113250522199013, \"f2\": 0.22030444241248714, \"f0_5\": 0.5305094276393888, \"p4\": 0.47481421395226886, \"phi\": 0.4292869099619257}, {\"truth_threshold\": 24.099999461323023, \"match_probability\": 0.9999999443868823, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55943.0, \"tn\": 1278737778.0, \"fp\": 14.0, \"fn\": 248018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18404663756205566, \"tn_rate\": 0.9999999890517038, \"fp_rate\": 1.0948296114798804e-08, \"fn_rate\": 0.8159533624379444, \"precision\": 0.9997498078881999, \"recall\": 0.18404663756205566, \"specificity\": 0.9999999890517038, \"npv\": 0.9998060822874064, \"accuracy\": 0.9998060798254488, \"f1\": 0.31086525264087933, \"f2\": 0.21993613780772306, \"f0_5\": 0.5299750468463723, \"p4\": 0.4742792633584024, \"phi\": 0.42891128418209495}, {\"truth_threshold\": 24.119999460875988, \"match_probability\": 0.9999999451525244, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55847.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248114.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1837308075707081, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.816269192429292, \"precision\": 0.9997851733829821, \"recall\": 0.1837308075707081, \"specificity\": 0.9999999906157462, \"npv\": 0.9998060072427977, \"accuracy\": 0.99980600633293, \"f1\": 0.3104163192707465, \"f2\": 0.219575639909633, \"f0_5\": 0.5294588327199434, \"p4\": 0.473756592843208, \"phi\": 0.428550680172736}, {\"truth_threshold\": 24.139999460428953, \"match_probability\": 0.9999999459076259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55765.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248196.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18346103611976536, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8165389638802346, \"precision\": 0.9997848575577747, \"recall\": 0.18346103611976536, \"specificity\": 0.9999999906157462, \"npv\": 0.9998059431419442, \"accuracy\": 0.999805942222435, \"f1\": 0.3100311893655939, \"f2\": 0.2192673760499394, \"f0_5\": 0.5290104331690917, \"p4\": 0.47330791994857424, \"phi\": 0.42823586329468316}, {\"truth_threshold\": 24.15999945998192, \"match_probability\": 0.9999999466523315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55699.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248262.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18324390300071391, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8167560969992861, \"precision\": 0.9997846026816967, \"recall\": 0.18324390300071391, \"specificity\": 0.9999999906157462, \"npv\": 0.9998058915485803, \"accuracy\": 0.9998058906213049, \"f1\": 0.30972107920549835, \"f2\": 0.2190192323572319, \"f0_5\": 0.5286491206423629, \"p4\": 0.4729464526081846, \"phi\": 0.42798230592485664}, {\"truth_threshold\": 24.179999459534883, \"match_probability\": 0.9999999473867845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55615.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248346.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18296755175828477, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8170324482417152, \"precision\": 0.9997842774192388, \"recall\": 0.18296755175828477, \"specificity\": 0.9999999906157462, \"npv\": 0.9998058258843068, \"accuracy\": 0.9998058249471392, \"f1\": 0.30932622890641515, \"f2\": 0.21870337585363725, \"f0_5\": 0.5281887442565469, \"p4\": 0.47248596355628497, \"phi\": 0.42765937915922464}, {\"truth_threshold\": 24.19999945908785, \"match_probability\": 0.9999999481111261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55541.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248420.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1827240994732877, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8172759005267123, \"precision\": 0.9997839900635429, \"recall\": 0.1827240994732877, \"specificity\": 0.9999999906157462, \"npv\": 0.9998057680372158, \"accuracy\": 0.9998057670913265, \"f1\": 0.3089782317239384, \"f2\": 0.21842508673529984, \"f0_5\": 0.5277826874431033, \"p4\": 0.4720798860243478, \"phi\": 0.42737469392943545}, {\"truth_threshold\": 24.219999458640814, \"match_probability\": 0.9999999488254956, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55441.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1823951098989673, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8176048901010327, \"precision\": 0.999783600526572, \"recall\": 0.1823951098989673, \"specificity\": 0.9999999906157462, \"npv\": 0.9998056898654818, \"accuracy\": 0.999805688907796, \"f1\": 0.3085077375950853, \"f2\": 0.21804896888767927, \"f0_5\": 0.5272332356359113, \"p4\": 0.471530523516822, \"phi\": 0.4269896826557871}, {\"truth_threshold\": 24.23999945819378, \"match_probability\": 0.99999994953003, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55333.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18203980115870128, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8179601988412987, \"precision\": 0.9997831782455506, \"recall\": 0.18203980115870128, \"specificity\": 0.9999999906157462, \"npv\": 0.9998056054400228, \"accuracy\": 0.9998056044695829, \"f1\": 0.3079993097805213, \"f2\": 0.21764269514604043, \"f0_5\": 0.5266388878842504, \"p4\": 0.47093642424206644, \"phi\": 0.4265734802378073}, {\"truth_threshold\": 24.259999457746744, \"match_probability\": 0.999999950224865, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55233.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248728.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1817108115843809, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8182891884156192, \"precision\": 0.999782785772468, \"recall\": 0.1817108115843809, \"specificity\": 0.9999999906157462, \"npv\": 0.9998055272683143, \"accuracy\": 0.9998055262860523, \"f1\": 0.30752827068590166, \"f2\": 0.21726645419793578, \"f0_5\": 0.5260876936646214, \"p4\": 0.47038560147235664, \"phi\": 0.4261877452866428}, {\"truth_threshold\": 24.27999945729971, \"match_probability\": 0.9999999509101339, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55137.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18139498159303333, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8186050184069666, \"precision\": 0.9997824076592504, \"recall\": 0.18139498159303333, \"specificity\": 0.9999999906157462, \"npv\": 0.9998054522234855, \"accuracy\": 0.999805451229863, \"f1\": 0.30707582634847264, \"f2\": 0.2169052071883952, \"f0_5\": 0.5255577563544095, \"p4\": 0.4698561491918534, \"phi\": 0.4258171110508152}, {\"truth_threshold\": 24.299999456852674, \"match_probability\": 0.9999999515859685, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55065.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18115810909952262, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8188418909004773, \"precision\": 0.9997821232093251, \"recall\": 0.18115810909952262, \"specificity\": 0.9999999906157462, \"npv\": 0.9998053959398714, \"accuracy\": 0.999805394937721, \"f1\": 0.3067363343155878, \"f2\": 0.2166342361169577, \"f0_5\": 0.5251597939225855, \"p4\": 0.4694586334092264, \"phi\": 0.4255389235641886}, {\"truth_threshold\": 24.31999945640564, \"match_probability\": 0.9999999522524988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54975.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 248986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18086201848263428, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8191379815173657, \"precision\": 0.999781766599378, \"recall\": 0.18086201848263428, \"specificity\": 0.9999999906157462, \"npv\": 0.9998053255853626, \"accuracy\": 0.9998053245725435, \"f1\": 0.3063117777505377, \"f2\": 0.21629547909989605, \"f0_5\": 0.5246617256050192, \"p4\": 0.4689612236602438, \"phi\": 0.4251909333009586}, {\"truth_threshold\": 24.339999455958605, \"match_probability\": 0.9999999529098527, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54922.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 249039.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1806876540082445, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8193123459917555, \"precision\": 0.999781556049077, \"recall\": 0.1806876540082445, \"specificity\": 0.9999999906157462, \"npv\": 0.9998052841543787, \"accuracy\": 0.9998052831352723, \"f1\": 0.30606166148873626, \"f2\": 0.21609596640797998, \"f0_5\": 0.5243680983469449, \"p4\": 0.4686680364985062, \"phi\": 0.42498587241636604}, {\"truth_threshold\": 24.35999945551157, \"match_probability\": 0.9999999535581566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54812.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 249149.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.18032576547649204, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.819674234523508, \"precision\": 0.9997811177586459, \"recall\": 0.18032576547649204, \"specificity\": 0.9999999906157462, \"npv\": 0.9998051981655552, \"accuracy\": 0.9998051971333887, \"f1\": 0.3055423164290592, \"f2\": 0.21568183034435431, \"f0_5\": 0.5237579239264836, \"p4\": 0.46805889958737557, \"phi\": 0.42455995830799503}, {\"truth_threshold\": 24.379999455064535, \"match_probability\": 0.9999999541975352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54707.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 249254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17998032642345563, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8200196735765444, \"precision\": 0.9997806977466693, \"recall\": 0.17998032642345563, \"specificity\": 0.9999999906157462, \"npv\": 0.9998051160853285, \"accuracy\": 0.9998051150406816, \"f1\": 0.3050462808074049, \"f2\": 0.21528645175406494, \"f0_5\": 0.5231745266689236, \"p4\": 0.46747664951808654, \"phi\": 0.4241530050363566}, {\"truth_threshold\": 24.3999994546175, \"match_probability\": 0.9999999548281112, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54632.0, \"tn\": 1278737780.0, \"fp\": 12.0, \"fn\": 249329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17973358424271535, \"tn_rate\": 0.9999999906157462, \"fp_rate\": 9.384253812684689e-09, \"fn_rate\": 0.8202664157572847, \"precision\": 0.9997803967498718, \"recall\": 0.17973358424271535, \"specificity\": 0.9999999906157462, \"npv\": 0.9998050574566033, \"accuracy\": 0.9998050564030336, \"f1\": 0.30469179180435296, \"f2\": 0.2150039984635825, \"f0_5\": 0.5227572401571563, \"p4\": 0.4670602765977958, \"phi\": 0.4238620849534065}, {\"truth_threshold\": 24.419999454170465, \"match_probability\": 0.9999999554500059, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54568.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1795230309151503, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8204769690848497, \"precision\": 0.9998167759903258, \"recall\": 0.1795230309151503, \"specificity\": 0.9999999921797885, \"npv\": 0.9998050074270682, \"accuracy\": 0.9998050079292446, \"f1\": 0.3043908751907045, \"f2\": 0.21476328338142758, \"f0_5\": 0.5224087785506814, \"p4\": 0.4667066507895848, \"phi\": 0.42362144009793073}, {\"truth_threshold\": 24.43999945372343, \"match_probability\": 0.9999999560633388, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54458.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249503.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17916114238339786, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8208388576166021, \"precision\": 0.9998164059631344, \"recall\": 0.17916114238339786, \"specificity\": 0.9999999921797885, \"npv\": 0.9998049214382925, \"accuracy\": 0.999804921927361, \"f1\": 0.3038705015498188, \"f2\": 0.21434891585689186, \"f0_5\": 0.5217952869979476, \"p4\": 0.46609474207856866, \"phi\": 0.42319415302057045}, {\"truth_threshold\": 24.459999453276396, \"match_probability\": 0.9999999566682277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54372.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17887821134948234, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8211217886505177, \"precision\": 0.9998161156264941, \"recall\": 0.17887821134948234, \"specificity\": 0.9999999921797885, \"npv\": 0.9998048542107145, \"accuracy\": 0.9998048546895247, \"f1\": 0.3034634414513469, \"f2\": 0.21402490580416397, \"f0_5\": 0.5213149270646169, \"p4\": 0.465615738475644, \"phi\": 0.42285979153221376}, {\"truth_threshold\": 24.47999945282936, \"match_probability\": 0.9999999572647891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54282.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249679.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.178582120732594, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8214178792674061, \"precision\": 0.9998158108008547, \"recall\": 0.178582120732594, \"specificity\": 0.9999999921797885, \"npv\": 0.999804783856282, \"accuracy\": 0.9998047843243473, \"f1\": 0.30303723904614893, \"f2\": 0.213685778530803, \"f0_5\": 0.520811545701736, \"p4\": 0.4651138886486701, \"phi\": 0.4225095950444246}, {\"truth_threshold\": 24.499999452382326, \"match_probability\": 0.9999999578531372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54204.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1783255088646241, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8216744911353759, \"precision\": 0.9998155457999779, \"recall\": 0.1783255088646241, \"specificity\": 0.9999999921797885, \"npv\": 0.9998047228824487, \"accuracy\": 0.9998047233411934, \"f1\": 0.3026676903748168, \"f2\": 0.21339182934952577, \"f0_5\": 0.5203747189511863, \"p4\": 0.46467848231323633, \"phi\": 0.4222058565047908}, {\"truth_threshold\": 24.51999945193529, \"match_probability\": 0.9999999584333855, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54104.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1779965192903037, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8220034807096963, \"precision\": 0.999815204937724, \"recall\": 0.1779965192903037, \"specificity\": 0.9999999921797885, \"npv\": 0.9998046447108783, \"accuracy\": 0.9998046451576628, \"f1\": 0.3021936745095301, \"f2\": 0.21301491860360736, \"f0_5\": 0.5198139184538553, \"p4\": 0.4641196297774253, \"phi\": 0.42181612822853193}, {\"truth_threshold\": 24.539999451488256, \"match_probability\": 0.9999999590056454, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54003.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 249958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1776642398202401, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.82233576017976, \"precision\": 0.9998148593857035, \"recall\": 0.1776642398202401, \"specificity\": 0.9999999921797885, \"npv\": 0.9998045657576046, \"accuracy\": 0.999804566192297, \"f1\": 0.3017146496672943, \"f2\": 0.2126341784941139, \"f0_5\": 0.5192466342187599, \"p4\": 0.46355445829810604, \"phi\": 0.42142213688936164}, {\"truth_threshold\": 24.55999945104122, \"match_probability\": 0.9999999595700267, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53912.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17736485930760854, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8226351406923914, \"precision\": 0.99981454693817, \"recall\": 0.17736485930760854, \"specificity\": 0.9999999921797885, \"npv\": 0.9998044946214973, \"accuracy\": 0.9998044950452841, \"f1\": 0.30128282148076324, \"f2\": 0.21229108355397766, \"f0_5\": 0.5187347613485256, \"p4\": 0.46304461457607204, \"phi\": 0.42106683893439595}, {\"truth_threshold\": 24.579999450594187, \"match_probability\": 0.999999960126638, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53841.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250120.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17713127670984108, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8228687232901589, \"precision\": 0.9998143024270673, \"recall\": 0.17713127670984108, \"specificity\": 0.9999999921797885, \"npv\": 0.9998044391197064, \"accuracy\": 0.9998044395349774, \"f1\": 0.3009457480464601, \"f2\": 0.21202335994077318, \"f0_5\": 0.5183348897211018, \"p4\": 0.4626464091027726, \"phi\": 0.4207894201332}, {\"truth_threshold\": 24.599999450147152, \"match_probability\": 0.9999999606755864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53764.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250197.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17687795473761436, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8231220452623856, \"precision\": 0.9998140365232269, \"recall\": 0.17687795473761436, \"specificity\": 0.9999999921797885, \"npv\": 0.9998043789276303, \"accuracy\": 0.9998043793336588, \"f1\": 0.30058003829650437, \"f2\": 0.2117329779508482, \"f0_5\": 0.517900731518889, \"p4\": 0.46221414033946256, \"phi\": 0.42048835064217305}, {\"truth_threshold\": 24.619999449700117, \"match_probability\": 0.9999999612169772, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53714.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17671345995045418, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8232865400495458, \"precision\": 0.999813863450227, \"recall\": 0.17671345995045418, \"specificity\": 0.9999999921797885, \"npv\": 0.9998043398418704, \"accuracy\": 0.9998043402418936, \"f1\": 0.30034248011518516, \"f2\": 0.21154439935474115, \"f0_5\": 0.5176185345866009, \"p4\": 0.46193321640355933, \"phi\": 0.4202927355022654}, {\"truth_threshold\": 24.639999449253082, \"match_probability\": 0.9999999617509145, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53611.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17637460068890418, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8236253993110958, \"precision\": 0.9998135059025381, \"recall\": 0.17637460068890418, \"specificity\": 0.9999999921797885, \"npv\": 0.9998042593252148, \"accuracy\": 0.9998042597128571, \"f1\": 0.29985290087308647, \"f2\": 0.21115588062687826, \"f0_5\": 0.5170365226783941, \"p4\": 0.46135394161441595, \"phi\": 0.4198894811332588}, {\"truth_threshold\": 24.659999448806047, \"match_probability\": 0.999999962277501, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53515.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1760587706975566, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8239412293024434, \"precision\": 0.9998131714152265, \"recall\": 0.1760587706975566, \"specificity\": 0.9999999921797885, \"npv\": 0.9998041842805765, \"accuracy\": 0.9998041846566678, \"f1\": 0.2993963399965313, \"f2\": 0.21079370931541577, \"f0_5\": 0.5164932314920444, \"p4\": 0.4608133411170811, \"phi\": 0.4195132834542025}, {\"truth_threshold\": 24.679999448359013, \"match_probability\": 0.9999999627968377, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53459.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250502.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17587453653593718, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8241254634640628, \"precision\": 0.9998129757429539, \"recall\": 0.17587453653593718, \"specificity\": 0.9999999921797885, \"npv\": 0.9998041405045427, \"accuracy\": 0.9998041408738906, \"f1\": 0.29912989956075314, \"f2\": 0.21058241741792608, \"f0_5\": 0.5161759395330964, \"p4\": 0.4604976811437092, \"phi\": 0.4192936789604647}, {\"truth_threshold\": 24.699999447911978, \"match_probability\": 0.9999999633090246, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53363.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1755587065445896, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8244412934554104, \"precision\": 0.9998126393494838, \"recall\": 0.1755587065445896, \"specificity\": 0.9999999921797885, \"npv\": 0.9998040654599223, \"accuracy\": 0.9998040658177013, \"f1\": 0.29867295023703316, \"f2\": 0.21022015935809243, \"f0_5\": 0.515631371351601, \"p4\": 0.45995601802400116, \"phi\": 0.4189169463264647}, {\"truth_threshold\": 24.719999447464943, \"match_probability\": 0.9999999638141601, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53291.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17532183405107893, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8246781659489211, \"precision\": 0.9998123862591696, \"recall\": 0.17532183405107893, \"specificity\": 0.9999999921797885, \"npv\": 0.9998040091764644, \"accuracy\": 0.9998040095255593, \"f1\": 0.298330077086284, \"f2\": 0.20994842984844128, \"f0_5\": 0.5152224145098759, \"p4\": 0.4595493292637791, \"phi\": 0.418634174403013}, {\"truth_threshold\": 24.739999447017908, \"match_probability\": 0.9999999643123412, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53208.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.175048772704393, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.824951227295607, \"precision\": 0.9998120936525235, \"recall\": 0.175048772704393, \"specificity\": 0.9999999921797885, \"npv\": 0.9998039442941528, \"accuracy\": 0.9998039446332289, \"f1\": 0.29793464901351985, \"f2\": 0.20963514784935644, \"f0_5\": 0.5147504126091019, \"p4\": 0.4590800372522768, \"phi\": 0.4183079640659316}, {\"truth_threshold\": 24.759999446570873, \"match_probability\": 0.9999999648036637, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53159.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.174887567812976, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.825112432187024, \"precision\": 0.9998119204799789, \"recall\": 0.174887567812976, \"specificity\": 0.9999999921797885, \"npv\": 0.9998039059901414, \"accuracy\": 0.9998039063232989, \"f1\": 0.29770111724022064, \"f2\": 0.20945017899737828, \"f0_5\": 0.5144714761041118, \"p4\": 0.4588027486089157, \"phi\": 0.41811526260292153}, {\"truth_threshold\": 24.77999944612384, \"match_probability\": 0.999999965288222, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53108.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250853.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1747197831300726, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8252802168699274, \"precision\": 0.9998117398998456, \"recall\": 0.1747197831300726, \"specificity\": 0.9999999921797885, \"npv\": 0.999803866122704, \"accuracy\": 0.9998038664496983, \"f1\": 0.2974579854878052, \"f2\": 0.2092576452249949, \"f0_5\": 0.5141809295687921, \"p4\": 0.45851395517725735, \"phi\": 0.41791460142054204}, {\"truth_threshold\": 24.799999445676804, \"match_probability\": 0.9999999657661093, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 53043.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17450593990676436, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8254940600932357, \"precision\": 0.9998115092454715, \"recall\": 0.17450593990676436, \"specificity\": 0.9999999921797885, \"npv\": 0.9998038153112689, \"accuracy\": 0.9998038156304034, \"f1\": 0.29714801100236965, \"f2\": 0.2090122366117975, \"f0_5\": 0.513810292285726, \"p4\": 0.45814560852606406, \"phi\": 0.41765871706427493}, {\"truth_threshold\": 24.81999944522977, \"match_probability\": 0.9999999662374174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52966.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 250995.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17425261793453767, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8257473820654624, \"precision\": 0.9998112352763515, \"recall\": 0.17425261793453767, \"specificity\": 0.9999999921797885, \"npv\": 0.999803755119268, \"accuracy\": 0.9998037554290848, \"f1\": 0.2967806643749457, \"f2\": 0.20872148925773554, \"f0_5\": 0.5133707462223643, \"p4\": 0.4577088578204518, \"phi\": 0.41735538954929496}, {\"truth_threshold\": 24.839999444782734, \"match_probability\": 0.9999999667022368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52888.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251073.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17399600606656776, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8260039939334323, \"precision\": 0.99981095693599, \"recall\": 0.17399600606656776, \"specificity\": 0.9999999921797885, \"npv\": 0.99980369414556, \"accuracy\": 0.9998036944459311, \"f1\": 0.29640838538470377, \"f2\": 0.2084269299826127, \"f0_5\": 0.5129249563090507, \"p4\": 0.4572659903396657, \"phi\": 0.41704789782064294}, {\"truth_threshold\": 24.8599994443357, \"match_probability\": 0.999999967160657, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52842.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17384467086238037, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8261553291376196, \"precision\": 0.9998107924014228, \"recall\": 0.17384467086238037, \"specificity\": 0.9999999921797885, \"npv\": 0.9998036581867101, \"accuracy\": 0.999803658481507, \"f1\": 0.2961887599386794, \"f2\": 0.20825319855978106, \"f0_5\": 0.5126618015441363, \"p4\": 0.45700460200665005, \"phi\": 0.41686645023865465}, {\"truth_threshold\": 24.879999443888664, \"match_probability\": 0.9999999676127659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52770.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251191.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1736077983688697, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8263922016311304, \"precision\": 0.9998105342932929, \"recall\": 0.1736077983688697, \"specificity\": 0.9999999921797885, \"npv\": 0.9998036019032981, \"accuracy\": 0.9998036021893649, \"f1\": 0.2958448846642242, \"f2\": 0.2079812458222452, \"f0_5\": 0.5122495296856222, \"p4\": 0.4565951591409965, \"phi\": 0.4165822866929121}, {\"truth_threshold\": 24.89999944344163, \"match_probability\": 0.9999999680586504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52698.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251263.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17337092587535902, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.826629074124641, \"precision\": 0.999810275480003, \"recall\": 0.17337092587535902, \"specificity\": 0.9999999921797885, \"npv\": 0.9998035456198923, \"accuracy\": 0.999803545897223, \"f1\": 0.2955008705550524, \"f2\": 0.2077092622139258, \"f0_5\": 0.5118367965376375, \"p4\": 0.456185333470324, \"phi\": 0.4162979292102026}, {\"truth_threshold\": 24.919999442994595, \"match_probability\": 0.9999999684983965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52633.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251328.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17315708265205076, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8268429173479492, \"precision\": 0.999810041221055, \"recall\": 0.17315708265205076, \"specificity\": 0.9999999921797885, \"npv\": 0.9998034948084898, \"accuracy\": 0.9998034950779281, \"f1\": 0.295190182948032, \"f2\": 0.2074636949373545, \"f0_5\": 0.5114637933815712, \"p4\": 0.45581502272725416, \"phi\": 0.4160410506923414}, {\"truth_threshold\": 24.93999944254756, \"match_probability\": 0.9999999689320883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52564.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1729300798457697, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8270699201542303, \"precision\": 0.9998097919123521, \"recall\": 0.1729300798457697, \"specificity\": 0.9999999921797885, \"npv\": 0.9998034408702374, \"accuracy\": 0.9998034411312919, \"f1\": 0.29486025214915784, \"f2\": 0.2072029882893494, \"f0_5\": 0.5110674234867002, \"p4\": 0.4554215813308858, \"phi\": 0.4157681906336682}, {\"truth_threshold\": 24.959999442100525, \"match_probability\": 0.9999999693598094, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52524.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251437.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17279848401604153, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8272015159839584, \"precision\": 0.9998096470856969, \"recall\": 0.17279848401604153, \"specificity\": 0.9999999921797885, \"npv\": 0.999803409601688, \"accuracy\": 0.9998034098578797, \"f1\": 0.29466892943800055, \"f2\": 0.20705184101269494, \"f0_5\": 0.5108374489639115, \"p4\": 0.4551933377660964, \"phi\": 0.4156099288768688}, {\"truth_threshold\": 24.97999944165349, \"match_probability\": 0.999999969781642, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52460.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251501.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17258793068847647, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8274120693115236, \"precision\": 0.9998094149037545, \"recall\": 0.17258793068847647, \"specificity\": 0.9999999921797885, \"npv\": 0.9998033595720129, \"accuracy\": 0.9998033598204202, \"f1\": 0.2943627237810404, \"f2\": 0.20680998553985844, \"f0_5\": 0.5104691918317145, \"p4\": 0.4548279010917346, \"phi\": 0.41535658465871955}, {\"truth_threshold\": 24.999999441206455, \"match_probability\": 0.999999970197667, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52415.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251546.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1724398853800323, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8275601146199677, \"precision\": 0.9998092513113972, \"recall\": 0.1724398853800323, \"specificity\": 0.9999999921797885, \"npv\": 0.9998033243949006, \"accuracy\": 0.9998033246378314, \"f1\": 0.2941473570791221, \"f2\": 0.20663991629536005, \"f0_5\": 0.5102100412528886, \"p4\": 0.4545707712537802, \"phi\": 0.41517835945777704}, {\"truth_threshold\": 25.01999944075942, \"match_probability\": 0.9999999706079644, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52352.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17223262194821046, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8277673780517896, \"precision\": 0.9998090218097093, \"recall\": 0.17223262194821046, \"specificity\": 0.9999999921797885, \"npv\": 0.9998032751469477, \"accuracy\": 0.9998032753822071, \"f1\": 0.29384575230900056, \"f2\": 0.20640179907680614, \"f0_5\": 0.5098469251610315, \"p4\": 0.45421053649085213, \"phi\": 0.41492871558779654}, {\"truth_threshold\": 25.039999440312386, \"match_probability\": 0.9999999710126133, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52269.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251692.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17195956060152454, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8280404393984755, \"precision\": 0.9998087186059412, \"recall\": 0.17195956060152454, \"specificity\": 0.9999999921797885, \"npv\": 0.9998032102647312, \"accuracy\": 0.9998032104898767, \"f1\": 0.29344823714349877, \"f2\": 0.20608805297277946, \"f0_5\": 0.5093679896000015, \"p4\": 0.45373549034772515, \"phi\": 0.4145995902596462}, {\"truth_threshold\": 25.05999943986535, \"match_probability\": 0.9999999714116912, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52154.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1715812225910561, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8284187774089439, \"precision\": 0.9998082969097462, \"recall\": 0.1715812225910561, \"specificity\": 0.9999999921797885, \"npv\": 0.9998031203676984, \"accuracy\": 0.9998031205788166, \"f1\": 0.2928971568971569, \"f2\": 0.20565327663547864, \"f0_5\": 0.5087033789359308, \"p4\": 0.45307644474403164, \"phi\": 0.4141431410457857}, {\"truth_threshold\": 25.079999439418316, \"match_probability\": 0.9999999718052749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 52103.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251858.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1714134379081527, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8285865620918473, \"precision\": 0.9998081093009422, \"recall\": 0.1714134379081527, \"specificity\": 0.9999999921797885, \"npv\": 0.9998030805003236, \"accuracy\": 0.9998030807052161, \"f1\": 0.2926526508534743, \"f2\": 0.20546043753849697, \"f0_5\": 0.508408256621124, \"p4\": 0.4527838561188309, \"phi\": 0.41394055466712004}, {\"truth_threshold\": 25.09999943897128, \"match_probability\": 0.99999997219344, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51998.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 251963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.17106799885511628, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8289320011448837, \"precision\": 0.9998077218889402, \"recall\": 0.17106799885511628, \"specificity\": 0.9999999921797885, \"npv\": 0.9998029984204447, \"accuracy\": 0.999802998612509, \"f1\": 0.29214903544971615, \"f2\": 0.20506336701760142, \"f0_5\": 0.5077999113269127, \"p4\": 0.4521808548558674, \"phi\": 0.41352315260488204}, {\"truth_threshold\": 25.119999438524246, \"match_probability\": 0.999999972576261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51952.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1709166636509289, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.829083336349071, \"precision\": 0.999807551672376, \"recall\": 0.1709166636509289, \"specificity\": 0.9999999921797885, \"npv\": 0.9998029624616449, \"accuracy\": 0.9998029626480849, \"f1\": 0.29192831033678635, \"f2\": 0.20488939159461306, \"f0_5\": 0.5075330836308076, \"p4\": 0.4519164226217219, \"phi\": 0.4133401579921928}, {\"truth_threshold\": 25.13999943807721, \"match_probability\": 0.9999999729538117, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51874.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.170660051782959, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.829339948217041, \"precision\": 0.999807262354483, \"recall\": 0.170660051782959, \"specificity\": 0.9999999921797885, \"npv\": 0.9998029014880336, \"accuracy\": 0.999802901664931, \"f1\": 0.29155390689766614, \"f2\": 0.20459436093546882, \"f0_5\": 0.5070801979288246, \"p4\": 0.4514676745974356, \"phi\": 0.41302967751358144}, {\"truth_threshold\": 25.159999437630177, \"match_probability\": 0.9999999733261646, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51775.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252186.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1703343521043818, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8296656478956181, \"precision\": 0.9998068938881916, \"recall\": 0.1703343521043818, \"specificity\": 0.9999999921797885, \"npv\": 0.9998028240984608, \"accuracy\": 0.9998028242632357, \"f1\": 0.291078466096597, \"f2\": 0.20421984665860438, \"f0_5\": 0.5065045851994029, \"p4\": 0.45089745130746256, \"phi\": 0.4126352697641597}, {\"truth_threshold\": 25.17999943718314, \"match_probability\": 0.9999999736933911, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51693.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252268.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1700645806534391, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8299354193465609, \"precision\": 0.9998065876254763, \"recall\": 0.1700645806534391, \"specificity\": 0.9999999921797885, \"npv\": 0.9998027599980156, \"accuracy\": 0.9998027601527407, \"f1\": 0.2906844662377975, \"f2\": 0.20390959861843388, \"f0_5\": 0.5060271392575567, \"p4\": 0.45042458646230293, \"phi\": 0.41230830297689913}, {\"truth_threshold\": 25.199999436736107, \"match_probability\": 0.999999974055562, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51649.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252312.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16991982524073812, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8300801747592619, \"precision\": 0.9998064228885577, \"recall\": 0.16991982524073812, \"specificity\": 0.9999999921797885, \"npv\": 0.9998027256026581, \"accuracy\": 0.9998027257519873, \"f1\": 0.2904729767729599, \"f2\": 0.2037431075113826, \"f0_5\": 0.5057706958716953, \"p4\": 0.4501706451109402, \"phi\": 0.4121327504621727}, {\"truth_threshold\": 25.219999436289072, \"match_probability\": 0.9999999744127467, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51577.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252384.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16968295274722744, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8303170472527726, \"precision\": 0.9998061527128927, \"recall\": 0.16968295274722744, \"specificity\": 0.9999999921797885, \"npv\": 0.9998026693193511, \"accuracy\": 0.9998026694598452, \"f1\": 0.2901267901942916, \"f2\": 0.20347064258330433, \"f0_5\": 0.5053506796862294, \"p4\": 0.44975478945980646, \"phi\": 0.4118453213251992}, {\"truth_threshold\": 25.239999435842037, \"match_probability\": 0.999999974765014, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51529.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252432.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16952503775155364, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8304749622484463, \"precision\": 0.9998059721764101, \"recall\": 0.16952503775155364, \"specificity\": 0.9999999921797885, \"npv\": 0.9998026317971499, \"accuracy\": 0.9998026319317506, \"f1\": 0.28989592123769337, \"f2\": 0.20328898209933383, \"f0_5\": 0.5050704054167965, \"p4\": 0.4494773347064522, \"phi\": 0.4116535904231189}, {\"truth_threshold\": 25.259999435395002, \"match_probability\": 0.9999999751124314, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51471.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1693342237984478, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8306657762015521, \"precision\": 0.9998057535789903, \"recall\": 0.1693342237984478, \"specificity\": 0.9999999921797885, \"npv\": 0.9998025864578273, \"accuracy\": 0.9998025865853029, \"f1\": 0.2896168713882996, \"f2\": 0.20306945732152368, \"f0_5\": 0.5047314590544927, \"p4\": 0.4491418442949072, \"phi\": 0.41142179639080956}, {\"truth_threshold\": 25.279999434947968, \"match_probability\": 0.999999975455066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51406.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252555.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16912038057513956, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8308796194248604, \"precision\": 0.9998055080130699, \"recall\": 0.16912038057513956, \"specificity\": 0.9999999921797885, \"npv\": 0.9998025356465222, \"accuracy\": 0.999802535766008, \"f1\": 0.2893040348700113, \"f2\": 0.20282341429540898, \"f0_5\": 0.5043512386558744, \"p4\": 0.4487655608643073, \"phi\": 0.4111618719586419}, {\"truth_threshold\": 25.299999434500933, \"match_probability\": 0.9999999757929833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51339.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1688999575603449, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8311000424396551, \"precision\": 0.9998052542405889, \"recall\": 0.1688999575603449, \"specificity\": 0.9999999921797885, \"npv\": 0.9998024832717979, \"accuracy\": 0.9998024833830425, \"f1\": 0.28898145281585097, \"f2\": 0.20256977429641737, \"f0_5\": 0.5039589129039161, \"p4\": 0.44837736411369855, \"phi\": 0.41089377778896896}, {\"truth_threshold\": 25.319999434053898, \"match_probability\": 0.9999999761262485, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51272.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16867953454555026, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8313204654544497, \"precision\": 0.9998049998049998, \"recall\": 0.16867953454555026, \"specificity\": 0.9999999921797885, \"npv\": 0.999802430897079, \"accuracy\": 0.9998024310000769, \"f1\": 0.28865874908161454, \"f2\": 0.2023161074747105, \"f0_5\": 0.5035661740874385, \"p4\": 0.44798882646944227, \"phi\": 0.4106255086108978}, {\"truth_threshold\": 25.339999433606863, \"match_probability\": 0.9999999764549254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51204.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16845582163501238, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8315441783649876, \"precision\": 0.9998047408911626, \"recall\": 0.16845582163501238, \"specificity\": 0.9999999921797885, \"npv\": 0.9998023777406535, \"accuracy\": 0.9998023778352761, \"f1\": 0.28833110438516224, \"f2\": 0.20205862715045406, \"f0_5\": 0.503167150468636, \"p4\": 0.44759414073065157, \"phi\": 0.41035305611654793}, {\"truth_threshold\": 25.359999433159828, \"match_probability\": 0.9999999767790774, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51119.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16817618049684005, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.83182381950316, \"precision\": 0.9998044162803889, \"recall\": 0.16817618049684005, \"specificity\": 0.9999999921797885, \"npv\": 0.9998023112951295, \"accuracy\": 0.9998023113792752, \"f1\": 0.2879213720465234, \"f2\": 0.20173673787839205, \"f0_5\": 0.5026677706169601, \"p4\": 0.4471002883911454, \"phi\": 0.4100122359460263}, {\"truth_threshold\": 25.379999432712793, \"match_probability\": 0.9999999770987668, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 51047.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16793930800332937, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8320606919966707, \"precision\": 0.9998041404704546, \"recall\": 0.16793930800332937, \"specificity\": 0.9999999921797885, \"npv\": 0.9998022550118691, \"accuracy\": 0.9998022550871332, \"f1\": 0.28757415116979984, \"f2\": 0.20146404494115958, \"f0_5\": 0.5022442437754457, \"p4\": 0.44668153537348676, \"phi\": 0.4097233194679922}, {\"truth_threshold\": 25.39999943226576, \"match_probability\": 0.9999999774140548, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50975.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 252986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1677024355098187, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8322975644901813, \"precision\": 0.9998038638815337, \"recall\": 0.1677024355098187, \"specificity\": 0.9999999921797885, \"npv\": 0.9998021987286151, \"accuracy\": 0.9998021987949912, \"f1\": 0.28722678942712415, \"f2\": 0.2011913210070183, \"f0_5\": 0.5018202366209162, \"p4\": 0.4462623864162521, \"phi\": 0.4094341991492301}, {\"truth_threshold\": 25.419999431818724, \"match_probability\": 0.9999999777250022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50889.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253072.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16741950447590315, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8325804955240969, \"precision\": 0.9998035324859035, \"recall\": 0.16741950447590315, \"specificity\": 0.9999999921797885, \"npv\": 0.9998021315014032, \"accuracy\": 0.9998021315571549, \"f1\": 0.28681170038888576, \"f2\": 0.20086552678799094, \"f0_5\": 0.5013131530054753, \"p4\": 0.44576121658182116, \"phi\": 0.40908859323981805}, {\"truth_threshold\": 25.43999943137169, \"match_probability\": 0.9999999780316686, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50805.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16714315323347403, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8328568467665259, \"precision\": 0.9998032077142576, \"recall\": 0.16714315323347403, \"specificity\": 0.9999999921797885, \"npv\": 0.9998020658376237, \"accuracy\": 0.9998020658829893, \"f1\": 0.2864060703091528, \"f2\": 0.20054726647029705, \"f0_5\": 0.5008171980261069, \"p4\": 0.4452711548334284, \"phi\": 0.4087507426209109}, {\"truth_threshold\": 25.459999430924654, \"match_probability\": 0.999999978334113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50727.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16688654136550413, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8331134586344958, \"precision\": 0.999802905177681, \"recall\": 0.16688654136550413, \"specificity\": 0.9999999921797885, \"npv\": 0.9998020048641217, \"accuracy\": 0.9998020048998354, \"f1\": 0.28602924177751216, \"f2\": 0.20025170123347816, \"f0_5\": 0.5003560796908321, \"p4\": 0.44481561265667524, \"phi\": 0.4084367739953523}, {\"truth_threshold\": 25.47999943047762, \"match_probability\": 0.9999999786323938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50683.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253278.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16674178595280315, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8332582140471968, \"precision\": 0.9998027341053005, \"recall\": 0.16674178595280315, \"specificity\": 0.9999999921797885, \"npv\": 0.9998019704688162, \"accuracy\": 0.9998019704990819, \"f1\": 0.28581659871311194, \"f2\": 0.20008495606523932, \"f0_5\": 0.5000957111536055, \"p4\": 0.44455843389925553, \"phi\": 0.4082595569859844}, {\"truth_threshold\": 25.499999430030584, \"match_probability\": 0.9999999789265679, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50614.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253347.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1665147831465221, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8334852168534779, \"precision\": 0.9998024652338812, \"recall\": 0.1665147831465221, \"specificity\": 0.9999999921797885, \"npv\": 0.9998019165307284, \"accuracy\": 0.9998019165524458, \"f1\": 0.28548302945697085, \"f2\": 0.1998234459931084, \"f0_5\": 0.49968704154548166, \"p4\": 0.44415483089756647, \"phi\": 0.4079814935076462}, {\"truth_threshold\": 25.51999942958355, \"match_probability\": 0.999999979216692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50560.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16633712877638906, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8336628712236109, \"precision\": 0.9998022543009689, \"recall\": 0.16633712877638906, \"specificity\": 0.9999999921797885, \"npv\": 0.9998018743183158, \"accuracy\": 0.9998018743333393, \"f1\": 0.28522188468709364, \"f2\": 0.19961876605912443, \"f0_5\": 0.49936690232517716, \"p4\": 0.44383871188040874, \"phi\": 0.40776374636600593}, {\"truth_threshold\": 25.539999429136515, \"match_probability\": 0.9999999795028219, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50492.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253469.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1661134158658512, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8338865841341487, \"precision\": 0.9998019880400776, \"recall\": 0.1661134158658512, \"specificity\": 0.9999999921797885, \"npv\": 0.9998018211619495, \"accuracy\": 0.9998018211685386, \"f1\": 0.28489292253352255, \"f2\": 0.19936099612586133, \"f0_5\": 0.4989633752265455, \"p4\": 0.443440316181309, \"phi\": 0.40748938077200497}, {\"truth_threshold\": 25.55999942868948, \"match_probability\": 0.9999999797850126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50438.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253523.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1659357614957182, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8340642385042818, \"precision\": 0.9998017760862671, \"recall\": 0.1659357614957182, \"specificity\": 0.9999999921797885, \"npv\": 0.9998017789495449, \"accuracy\": 0.999801778949432, \"f1\": 0.2846315979560338, \"f2\": 0.19915627675133382, \"f0_5\": 0.4986426180368678, \"p4\": 0.44312368879349995, \"phi\": 0.4072713705646191}, {\"truth_threshold\": 25.579999428242445, \"match_probability\": 0.9999999800633184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50361.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253600.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1656824395234915, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8343175604765085, \"precision\": 0.9998014730698219, \"recall\": 0.1656824395234915, \"specificity\": 0.9999999921797885, \"npv\": 0.9998017187577891, \"accuracy\": 0.9998017187481134, \"f1\": 0.2842588307011503, \"f2\": 0.1988643318867649, \"f0_5\": 0.49818476787781063, \"p4\": 0.44267181166836733, \"phi\": 0.4069603021921903}, {\"truth_threshold\": 25.59999942779541, \"match_probability\": 0.9999999803377925, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50322.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253639.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16555413358950655, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8344458664104935, \"precision\": 0.9998013192402447, \"recall\": 0.16555413358950655, \"specificity\": 0.9999999921797885, \"npv\": 0.9998016882710584, \"accuracy\": 0.9998016882565365, \"f1\": 0.28406996469024226, \"f2\": 0.19871645016174685, \"f0_5\": 0.4979526567964076, \"p4\": 0.44244276376253516, \"phi\": 0.4068026573473824}, {\"truth_threshold\": 25.619999427348375, \"match_probability\": 0.9999999806084879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50279.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16541266807254879, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8345873319274513, \"precision\": 0.9998011493567182, \"recall\": 0.16541266807254879, \"specificity\": 0.9999999921797885, \"npv\": 0.9998016546574856, \"accuracy\": 0.9998016546376184, \"f1\": 0.28386167960479886, \"f2\": 0.19855339052058513, \"f0_5\": 0.4976965732691634, \"p4\": 0.44219008716648583, \"phi\": 0.4066287729707345}, {\"truth_threshold\": 25.63999942690134, \"match_probability\": 0.9999999808754566, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50201.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16515605620457888, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8348439437954212, \"precision\": 0.9998008404532871, \"recall\": 0.16515605620457888, \"specificity\": 0.9999999921797885, \"npv\": 0.9998015936840339, \"accuracy\": 0.9998015936544645, \"f1\": 0.2834837310685204, \"f2\": 0.19825757964701377, \"f0_5\": 0.4972316042828419, \"p4\": 0.44173137755923486, \"phi\": 0.40631316490794983}, {\"truth_threshold\": 25.659999426454306, \"match_probability\": 0.9999999811387498, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50120.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16488957464937937, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8351104253506206, \"precision\": 0.9998005186515061, \"recall\": 0.16488957464937937, \"specificity\": 0.9999999921797885, \"npv\": 0.9998015303654573, \"accuracy\": 0.9998015303258048, \"f1\": 0.2830910698097382, \"f2\": 0.19795035285084844, \"f0_5\": 0.49674814314116883, \"p4\": 0.44125452514894364, \"phi\": 0.4059851584281816}, {\"truth_threshold\": 25.67999942600727, \"match_probability\": 0.9999999813984182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 50021.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 253940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1645638749708022, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8354361250291978, \"precision\": 0.9998001239231676, \"recall\": 0.1645638749708022, \"specificity\": 0.9999999921797885, \"npv\": 0.9998014529760968, \"accuracy\": 0.9998014529241095, \"f1\": 0.282610906461163, \"f2\": 0.19757480003949837, \"f0_5\": 0.4961564021940744, \"p4\": 0.44067101235860506, \"phi\": 0.40558390143640005}, {\"truth_threshold\": 25.699999425560236, \"match_probability\": 0.9999999816545116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49926.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254035.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1642513348751978, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8357486651248022, \"precision\": 0.9997997436719, \"recall\": 0.1642513348751978, \"specificity\": 0.9999999921797885, \"npv\": 0.9998013787135903, \"accuracy\": 0.9998013786497555, \"f1\": 0.2821498910700006, \"f2\": 0.1972143658455656, \"f0_5\": 0.49558769517872564, \"p4\": 0.44011035763299544, \"phi\": 0.4051984833109208}, {\"truth_threshold\": 25.7199994251132, \"match_probability\": 0.9999999819070794, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49858.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254103.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16402762196465995, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8359723780353401, \"precision\": 0.9997994706023903, \"recall\": 0.16402762196465995, \"specificity\": 0.9999999921797885, \"npv\": 0.9998013255572767, \"accuracy\": 0.9998013254849547, \"f1\": 0.2818197490878362, \"f2\": 0.19695633761866838, \"f0_5\": 0.4951800934781788, \"p4\": 0.43970861419443685, \"phi\": 0.40492237983465584}, {\"truth_threshold\": 25.739999424666166, \"match_probability\": 0.99999998215617, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49807.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254154.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16385983728175654, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8361401627182434, \"precision\": 0.9997992653110384, \"recall\": 0.16385983728175654, \"specificity\": 0.9999999921797885, \"npv\": 0.9998012856900452, \"accuracy\": 0.9998012856113541, \"f1\": 0.2815720593140331, \"f2\": 0.19676279825324475, \"f0_5\": 0.4948741030425512, \"p4\": 0.43940706936365453, \"phi\": 0.4047151786339426}, {\"truth_threshold\": 25.75999942421913, \"match_probability\": 0.9999999824018313, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49760.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254201.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16370521218182596, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.836294787818174, \"precision\": 0.9997990757484428, \"recall\": 0.16370521218182596, \"specificity\": 0.9999999921797885, \"npv\": 0.9998012489496582, \"accuracy\": 0.9998012488650947, \"f1\": 0.28134373294961423, \"f2\": 0.19658442463499928, \"f0_5\": 0.49459189211217375, \"p4\": 0.4391289948503237, \"phi\": 0.40452413455149844}, {\"truth_threshold\": 25.779999423772097, \"match_probability\": 0.9999999826441105, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49694.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1634880790627745, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8365119209372255, \"precision\": 0.999798808948978, \"recall\": 0.1634880790627745, \"specificity\": 0.9999999921797885, \"npv\": 0.9998011973567789, \"accuracy\": 0.9998011972639645, \"f1\": 0.28102300199341185, \"f2\": 0.19633392016738993, \"f0_5\": 0.49419523963904477, \"p4\": 0.4387382150472886, \"phi\": 0.4042557074983382}, {\"truth_threshold\": 25.799999423325062, \"match_probability\": 0.9999999828830541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49594.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16315908948845412, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8368409105115459, \"precision\": 0.9997984033545682, \"recall\": 0.16315908948845412, \"specificity\": 0.9999999921797885, \"npv\": 0.9998011191857598, \"accuracy\": 0.999801119080434, \"f1\": 0.2805368178411325, \"f2\": 0.1959543181545192, \"f0_5\": 0.4935934567068158, \"p4\": 0.438145473166001, \"phi\": 0.4038486599379694}, {\"truth_threshold\": 25.819999422878027, \"match_probability\": 0.9999999831187082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49517.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254444.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1629057675162274, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8370942324837726, \"precision\": 0.9997980899307448, \"recall\": 0.1629057675162274, \"specificity\": 0.9999999921797885, \"npv\": 0.9998010589940833, \"accuracy\": 0.9998010588791154, \"f1\": 0.28016226859186166, \"f2\": 0.19566198371860902, \"f0_5\": 0.49312943041693474, \"p4\": 0.43768852634706856, \"phi\": 0.40353495356299696}, {\"truth_threshold\": 25.839999422430992, \"match_probability\": 0.9999999833511178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49447.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254514.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16267547481420314, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8373245251857968, \"precision\": 0.9997978041531027, \"recall\": 0.16267547481420314, \"specificity\": 0.9999999921797885, \"npv\": 0.9998010042743838, \"accuracy\": 0.999801004150644, \"f1\": 0.2798216276477146, \"f2\": 0.19539619426523808, \"f0_5\": 0.492707094017605, \"p4\": 0.43727271512581634, \"phi\": 0.40324955420629904}, {\"truth_threshold\": 25.859999421983957, \"match_probability\": 0.9999999835803279, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49366.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254595.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16240899325900363, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8375910067409964, \"precision\": 0.999797472456254, \"recall\": 0.16240899325900363, \"specificity\": 0.9999999921797885, \"npv\": 0.9998009409558819, \"accuracy\": 0.9998009408219842, \"f1\": 0.2794272889620957, \"f2\": 0.1950886011918876, \"f0_5\": 0.49221780184060704, \"p4\": 0.43679107999130273, \"phi\": 0.4029190541144602}, {\"truth_threshold\": 25.879999421536922, \"match_probability\": 0.9999999838063824, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49299.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16218857024420896, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.837811429755791, \"precision\": 0.9997971972662192, \"recall\": 0.16218857024420896, \"specificity\": 0.9999999921797885, \"npv\": 0.9998008885813245, \"accuracy\": 0.9998008884390188, \"f1\": 0.27910097092875136, \"f2\": 0.1948341425898686, \"f0_5\": 0.491812600634082, \"p4\": 0.4363922989779228, \"phi\": 0.402645472525636}, {\"truth_threshold\": 25.899999421089888, \"match_probability\": 0.9999999840293248, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49200.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16186287056563178, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8381371294343682, \"precision\": 0.9997967892704734, \"recall\": 0.16186287056563178, \"specificity\": 0.9999999921797885, \"npv\": 0.9998008111920634, \"accuracy\": 0.9998008110373235, \"f1\": 0.2786185728726311, \"f2\": 0.1944581021837803, \"f0_5\": 0.4912130766512048, \"p4\": 0.43580240555510436, \"phi\": 0.4022408845509356}, {\"truth_threshold\": 25.919999420642853, \"match_probability\": 0.9999999842491977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49131.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1616358677593507, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8383641322406493, \"precision\": 0.9997965039376489, \"recall\": 0.1616358677593507, \"specificity\": 0.9999999921797885, \"npv\": 0.9998007572541006, \"accuracy\": 0.9998007570906874, \"f1\": 0.27828219607931987, \"f2\": 0.194195978608442, \"f0_5\": 0.49079466560111884, \"p4\": 0.43539080862622265, \"phi\": 0.4019586582044685}, {\"truth_threshold\": 25.939999420195818, \"match_probability\": 0.9999999844660437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49087.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254874.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16149111234664973, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8385088876533503, \"precision\": 0.9997963215675092, \"recall\": 0.16149111234664973, \"specificity\": 0.9999999921797885, \"npv\": 0.9998007228588809, \"accuracy\": 0.9998007226899339, \"f1\": 0.2780676262823672, \"f2\": 0.19402881241101363, \"f0_5\": 0.49052761172701453, \"p4\": 0.43512814383110815, \"phi\": 0.4017785842796762}, {\"truth_threshold\": 25.959999419748783, \"match_probability\": 0.9999999846799043, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 49031.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1613068781850303, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8386931218149697, \"precision\": 0.9997960889867662, \"recall\": 0.1613068781850303, \"specificity\": 0.9999999921797885, \"npv\": 0.9998006790831503, \"accuracy\": 0.9998006789071568, \"f1\": 0.2777944600880448, \"f2\": 0.19381603861220587, \"f0_5\": 0.4901874531367158, \"p4\": 0.4347936208385103, \"phi\": 0.40154928250981325}, {\"truth_threshold\": 25.97999941930175, \"match_probability\": 0.9999999848908205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48970.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 254991.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16110619454469488, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8388938054553051, \"precision\": 0.999795835034708, \"recall\": 0.16110619454469488, \"specificity\": 0.9999999921797885, \"npv\": 0.9998006313988765, \"accuracy\": 0.9998006312152031, \"f1\": 0.2774968054150694, \"f2\": 0.19358424571323757, \"f0_5\": 0.4898165763451702, \"p4\": 0.4344289460481642, \"phi\": 0.40129935829799535}, {\"truth_threshold\": 25.999999418854713, \"match_probability\": 0.999999985098833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48902.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255059.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16088248163415703, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.839117518365843, \"precision\": 0.999795551193981, \"recall\": 0.16088248163415703, \"specificity\": 0.9999999921797885, \"npv\": 0.9998005782426425, \"accuracy\": 0.9998005780504023, \"f1\": 0.2771648723478419, \"f2\": 0.1933258272741936, \"f0_5\": 0.4894027129215046, \"p4\": 0.4340220742421177, \"phi\": 0.4010205706925878}, {\"truth_threshold\": 26.01999941840768, \"match_probability\": 0.9999999853039818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48830.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16064560914064632, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8393543908593537, \"precision\": 0.9997952497952498, \"recall\": 0.16064560914064632, \"specificity\": 0.9999999921797885, \"npv\": 0.9998005219595771, \"accuracy\": 0.9998005217582604, \"f1\": 0.27681327433879155, \"f2\": 0.19305217746093095, \"f0_5\": 0.4889640131298303, \"p4\": 0.43359086712153033, \"phi\": 0.40072517244480443}, {\"truth_threshold\": 26.039999417960644, \"match_probability\": 0.9999999855063062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48746.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255215.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1603692578982172, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8396307421017828, \"precision\": 0.9997948970383133, \"recall\": 0.1603692578982172, \"specificity\": 0.9999999921797885, \"npv\": 0.999800456296009, \"accuracy\": 0.9998004560840947, \"f1\": 0.2764028952389593, \"f2\": 0.19273287996204333, \"f0_5\": 0.4884515566600198, \"p4\": 0.4330872691854671, \"phi\": 0.40038026574206226}, {\"truth_threshold\": 26.05999941751361, \"match_probability\": 0.9999999857058451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48680.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255281.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.16015212477916574, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8398478752208343, \"precision\": 0.9997946190182789, \"recall\": 0.16015212477916574, \"specificity\": 0.9999999921797885, \"npv\": 0.9998004047032114, \"accuracy\": 0.9998004044829645, \"f1\": 0.27608031736759575, \"f2\": 0.19248197359659763, \"f0_5\": 0.4880484278785132, \"p4\": 0.4326911894131268, \"phi\": 0.40010905907093974}, {\"truth_threshold\": 26.079999417066574, \"match_probability\": 0.9999999859026371, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48610.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255351.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15992183207714147, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8400781679228585, \"precision\": 0.9997943233237351, \"recall\": 0.15992183207714147, \"specificity\": 0.9999999921797885, \"npv\": 0.9998003499835836, \"accuracy\": 0.9998003497544932, \"f1\": 0.2757380573541966, \"f2\": 0.1922158321628769, \"f0_5\": 0.4876204004084736, \"p4\": 0.43227072375574455, \"phi\": 0.3998212146357623}, {\"truth_threshold\": 26.09999941661954, \"match_probability\": 0.9999999860967196, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48546.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1597112787495764, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8402887212504235, \"precision\": 0.9997940522283549, \"recall\": 0.1597112787495764, \"specificity\": 0.9999999921797885, \"npv\": 0.9998002999542147, \"accuracy\": 0.9998002997170335, \"f1\": 0.2754250149638173, \"f2\": 0.1919724770642202, \"f0_5\": 0.4872286399630659, \"p4\": 0.4318859542882047, \"phi\": 0.3995578611426553}, {\"truth_threshold\": 26.119999416172504, \"match_probability\": 0.9999999862881301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48501.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255460.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15956323344113224, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8404367665588678, \"precision\": 0.9997938611861228, \"recall\": 0.15956323344113224, \"specificity\": 0.9999999921797885, \"npv\": 0.9998002647773178, \"accuracy\": 0.9998002645344448, \"f1\": 0.27520483896593206, \"f2\": 0.19180135325917166, \"f0_5\": 0.4869529422395357, \"p4\": 0.43161521643044193, \"phi\": 0.3993725867538376}, {\"truth_threshold\": 26.13999941572547, \"match_probability\": 0.9999999864769055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48413.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255548.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1592737226157303, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8407262773842696, \"precision\": 0.9997934865663012, \"recall\": 0.1592737226157303, \"specificity\": 0.9999999921797885, \"npv\": 0.9998001959869486, \"accuracy\": 0.9998001957329379, \"f1\": 0.27477411006175084, \"f2\": 0.19146667594740668, \"f0_5\": 0.486413223671916, \"p4\": 0.4310853032371745, \"phi\": 0.399010023816932}, {\"truth_threshold\": 26.159999415278435, \"match_probability\": 0.9999999866630819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48337.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255624.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1590236905392468, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8409763094607532, \"precision\": 0.9997931619335223, \"recall\": 0.1590236905392468, \"specificity\": 0.9999999921797885, \"npv\": 0.999800136577092, \"accuracy\": 0.9998001363134547, \"f1\": 0.2744019437537609, \"f2\": 0.19117759895458836, \"f0_5\": 0.4859464882808652, \"p4\": 0.4306271494259471, \"phi\": 0.39869663599085686}, {\"truth_threshold\": 26.1799994148314, \"match_probability\": 0.9999999868466952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48274.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15881642710742497, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8411835728925751, \"precision\": 0.9997928920553393, \"recall\": 0.15881642710742497, \"specificity\": 0.9999999921797885, \"npv\": 0.999800087329453, \"accuracy\": 0.9998000870578304, \"f1\": 0.27409331573194795, \"f2\": 0.19093794299311462, \"f0_5\": 0.4855591564624208, \"p4\": 0.43024701114391944, \"phi\": 0.39843666715116727}, {\"truth_threshold\": 26.199999414384365, \"match_probability\": 0.9999999870277806, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48203.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15858284450965748, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8414171554903425, \"precision\": 0.9997925870615809, \"recall\": 0.15858284450965748, \"specificity\": 0.9999999921797885, \"npv\": 0.9998000318281514, \"accuracy\": 0.9998000315475237, \"f1\": 0.2737453645073174, \"f2\": 0.19066782589709166, \"f0_5\": 0.4851221687033149, \"p4\": 0.42981821740438586, \"phi\": 0.3981434829773885}, {\"truth_threshold\": 26.21999941393733, \"match_probability\": 0.999999987206373, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48123.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255838.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15831965285020116, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8416803471497988, \"precision\": 0.999792242328548, \"recall\": 0.15831965285020116, \"specificity\": 0.9999999921797885, \"npv\": 0.999799969291481, \"accuracy\": 0.9997999690006992, \"f1\": 0.273353138650474, \"f2\": 0.19036343224599814, \"f0_5\": 0.4846291891325759, \"p4\": 0.42933458135231606, \"phi\": 0.39781287575746627}, {\"truth_threshold\": 26.239999413490295, \"match_probability\": 0.9999999873825066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48058.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1581058096268929, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8418941903731071, \"precision\": 0.9997919613880336, \"recall\": 0.1581058096268929, \"specificity\": 0.9999999921797885, \"npv\": 0.9997999184804419, \"accuracy\": 0.9997999181814043, \"f1\": 0.27303432387672605, \"f2\": 0.19011608403116673, \"f0_5\": 0.4842281750709848, \"p4\": 0.42894124562645686, \"phi\": 0.39754405497511003}, {\"truth_threshold\": 26.25999941304326, \"match_probability\": 0.9999999875562154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47967.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 255994.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15780642911426138, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8421935708857387, \"precision\": 0.9997915667924213, \"recall\": 0.15780642911426138, \"specificity\": 0.9999999921797885, \"npv\": 0.9997998473449959, \"accuracy\": 0.9997998470343915, \"f1\": 0.2725877853485557, \"f2\": 0.18976975378633526, \"f0_5\": 0.4836660488959786, \"p4\": 0.42839000018413875, \"phi\": 0.39716740024992525}, {\"truth_threshold\": 26.279999412596226, \"match_probability\": 0.9999999877275326, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47903.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256058.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15759587578669632, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8424041242133037, \"precision\": 0.9997912883768497, \"recall\": 0.15759587578669632, \"specificity\": 0.9999999921797885, \"npv\": 0.9997997973156775, \"accuracy\": 0.999799796996932, \"f1\": 0.27227359793562467, \"f2\": 0.18952615099263545, \"f0_5\": 0.4832702128475242, \"p4\": 0.42800190838791274, \"phi\": 0.3969022861628221}, {\"truth_threshold\": 26.29999941214919, \"match_probability\": 0.9999999878964914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47812.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256149.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15729649527406475, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8427035047259352, \"precision\": 0.9997908912216135, \"recall\": 0.15729649527406475, \"specificity\": 0.9999999921797885, \"npv\": 0.9997997261802488, \"accuracy\": 0.9997997258499192, \"f1\": 0.27182666587072146, \"f2\": 0.18917973578461397, \"f0_5\": 0.482706678862552, \"p4\": 0.42744951684017124, \"phi\": 0.39652502192061156}, {\"truth_threshold\": 26.319999411702156, \"match_probability\": 0.999999988063124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47736.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15704646319758128, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8429535368024187, \"precision\": 0.9997905583713819, \"recall\": 0.15704646319758128, \"specificity\": 0.9999999921797885, \"npv\": 0.999799666770448, \"accuracy\": 0.9997996664304359, \"f1\": 0.2714532266915359, \"f2\": 0.1888903837478929, \"f0_5\": 0.4822353998929174, \"p4\": 0.4269876619736035, \"phi\": 0.39620966884768394}, {\"truth_threshold\": 26.33999941125512, \"match_probability\": 0.9999999882274624, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47644.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256317.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1567437927892065, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8432562072107935, \"precision\": 0.9997901540269443, \"recall\": 0.1567437927892065, \"specificity\": 0.9999999921797885, \"npv\": 0.9997995948533301, \"accuracy\": 0.9997995945015877, \"f1\": 0.27100095274661207, \"f2\": 0.18854006891977668, \"f0_5\": 0.48166412914470347, \"p4\": 0.4264279439769723, \"phi\": 0.39582758955851144}, {\"truth_threshold\": 26.359999410808086, \"match_probability\": 0.9999999883895384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47594.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1565792980020463, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8434207019979537, \"precision\": 0.9997899336190236, \"recall\": 0.1565792980020463, \"specificity\": 0.9999999921797885, \"npv\": 0.9997995557679443, \"accuracy\": 0.9997995554098225, \"f1\": 0.2707550524085162, \"f2\": 0.18834965902830983, \"f0_5\": 0.4813532992028351, \"p4\": 0.4261234593454804, \"phi\": 0.39561978302586703}, {\"truth_threshold\": 26.37999941036105, \"match_probability\": 0.9999999885493831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47496.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15625688821921233, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8437431117807876, \"precision\": 0.9997895002736497, \"recall\": 0.15625688821921233, \"specificity\": 0.9999999921797885, \"npv\": 0.9997994791605971, \"accuracy\": 0.9997994787899626, \"f1\": 0.270272884794305, \"f2\": 0.18797641192068706, \"f0_5\": 0.4807433424091825, \"p4\": 0.42552607595604997, \"phi\": 0.3952121653082258}, {\"truth_threshold\": 26.399999409914017, \"match_probability\": 0.9999999887070271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47399.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256562.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15593776833212156, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8440622316678784, \"precision\": 0.9997890695859436, \"recall\": 0.15593776833212156, \"specificity\": 0.9999999921797885, \"npv\": 0.999799403334969, \"accuracy\": 0.9997994029519379, \"f1\": 0.26979537239946494, \"f2\": 0.1876069164292505, \"f0_5\": 0.48013865562391994, \"p4\": 0.4249340130280542, \"phi\": 0.394808292593769}, {\"truth_threshold\": 26.419999409466982, \"match_probability\": 0.9999999888625007, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47364.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256597.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1558226219811094, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8441773780188906, \"precision\": 0.9997889137501583, \"recall\": 0.1558226219811094, \"specificity\": 0.9999999921797885, \"npv\": 0.9997993759752091, \"accuracy\": 0.9997993755877022, \"f1\": 0.2696230093785134, \"f2\": 0.18747357938218107, \"f0_5\": 0.4799202362110579, \"p4\": 0.4247201924172935, \"phi\": 0.39466246387213944}, {\"truth_threshold\": 26.439999409019947, \"match_probability\": 0.999999989015834, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47293.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256668.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15558903938334195, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8444109606166581, \"precision\": 0.999788596917743, \"recall\": 0.15558903938334195, \"specificity\": 0.9999999921797885, \"npv\": 0.9997993204739865, \"accuracy\": 0.9997993200773955, \"f1\": 0.2692732531657101, \"f2\": 0.18720307295983762, \"f0_5\": 0.47947677589811283, \"p4\": 0.42428613266076554, \"phi\": 0.39436647427131233}, {\"truth_threshold\": 26.459999408572912, \"match_probability\": 0.9999999891670562, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47225.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256736.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15536532647280407, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8446346735271959, \"precision\": 0.999788292579655, \"recall\": 0.15536532647280407, \"specificity\": 0.9999999921797885, \"npv\": 0.9997992673178917, \"accuracy\": 0.9997992669125947, \"f1\": 0.2689381428034488, \"f2\": 0.18694396787532688, \"f0_5\": 0.4790515742512188, \"p4\": 0.42387002445452326, \"phi\": 0.3940827828827971}, {\"truth_threshold\": 26.479999408125877, \"match_probability\": 0.9999999893161966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47168.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15517780241544146, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8448221975845586, \"precision\": 0.999788036796812, \"recall\": 0.15517780241544146, \"specificity\": 0.9999999921797885, \"npv\": 0.9997992227605813, \"accuracy\": 0.9997992223479822, \"f1\": 0.26865714147388925, \"f2\": 0.1867267553534301, \"f0_5\": 0.47869479350400773, \"p4\": 0.4235209342490932, \"phi\": 0.39384482533557047}, {\"truth_threshold\": 26.499999407678843, \"match_probability\": 0.9999999894632836, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47095.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256866.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15493764002618757, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8450623599738124, \"precision\": 0.9997877083112197, \"recall\": 0.15493764002618757, \"specificity\": 0.9999999921797885, \"npv\": 0.9997991656959615, \"accuracy\": 0.9997991652740049, \"f1\": 0.2682971293147158, \"f2\": 0.18644854226100974, \"f0_5\": 0.47823738121495346, \"p4\": 0.4230734622065118, \"phi\": 0.3935398625842698}, {\"truth_threshold\": 26.519999407231808, \"match_probability\": 0.9999999896083457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47026.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 256935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1547106372199065, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8452893627800935, \"precision\": 0.9997873968874904, \"recall\": 0.1547106372199065, \"specificity\": 0.9999999921797885, \"npv\": 0.9997991117581763, \"accuracy\": 0.9997991113273689, \"f1\": 0.2679567061826739, \"f2\": 0.186185544153047, \"f0_5\": 0.47780453358531205, \"p4\": 0.42265010432392447, \"phi\": 0.39325139274008264}, {\"truth_threshold\": 26.539999406784773, \"match_probability\": 0.9999999897514107, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46955.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15447705462213904, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.845522945377861, \"precision\": 0.9997870754817417, \"recall\": 0.15447705462213904, \"specificity\": 0.9999999921797885, \"npv\": 0.999799056256983, \"accuracy\": 0.9997990558170622, \"f1\": 0.267606275967013, \"f2\": 0.18591489290937901, \"f0_5\": 0.47735863251060856, \"p4\": 0.4222140638848064, \"phi\": 0.3929543404203097}, {\"truth_threshold\": 26.559999406337738, \"match_probability\": 0.999999989892506, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46909.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257052.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15432571941795165, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8456742805820484, \"precision\": 0.9997868667277648, \"recall\": 0.15432571941795165, \"specificity\": 0.9999999921797885, \"npv\": 0.9997990202984667, \"accuracy\": 0.9997990198526381, \"f1\": 0.26737916096671227, \"f2\": 0.1857395251523841, \"f0_5\": 0.4770694638523952, \"p4\": 0.4219313358269203, \"phi\": 0.39276176407382307}, {\"truth_threshold\": 26.579999405890703, \"match_probability\": 0.999999990031659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46855.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257106.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15414806504781864, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8458519349521814, \"precision\": 0.9997866211458445, \"recall\": 0.15414806504781864, \"specificity\": 0.9999999921797885, \"npv\": 0.9997989780862987, \"accuracy\": 0.9997989776335315, \"f1\": 0.26711247170962243, \"f2\": 0.18553364235148398, \"f0_5\": 0.47672972868477337, \"p4\": 0.4215992136833814, \"phi\": 0.39253557565439634}, {\"truth_threshold\": 26.59999940544367, \"match_probability\": 0.999999990168896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46779.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15389803297133514, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8461019670286649, \"precision\": 0.9997862745517109, \"recall\": 0.15389803297133514, \"specificity\": 0.9999999921797885, \"npv\": 0.9997989186765868, \"accuracy\": 0.9997989182140483, \"f1\": 0.26673699215965785, \"f2\": 0.18524385153880818, \"f0_5\": 0.4762510766273617, \"p4\": 0.42113137221512187, \"phi\": 0.39221701544953314}, {\"truth_threshold\": 26.619999404996634, \"match_probability\": 0.9999999903042437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46693.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257268.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1536151019374196, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8463848980625804, \"precision\": 0.9997858809926558, \"recall\": 0.1536151019374196, \"specificity\": 0.9999999921797885, \"npv\": 0.9997988514498161, \"accuracy\": 0.999798850976212, \"f1\": 0.2663119111171948, \"f2\": 0.18491588827980265, \"f0_5\": 0.47570872888280324, \"p4\": 0.42060139323709944, \"phi\": 0.3918562271449499}, {\"truth_threshold\": 26.6399994045496, \"match_probability\": 0.999999990437728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46580.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257381.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15324334371843756, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8467566562815625, \"precision\": 0.9997853616655935, \"recall\": 0.15324334371843756, \"specificity\": 0.9999999921797885, \"npv\": 0.9997987631169798, \"accuracy\": 0.9997987626288225, \"f1\": 0.2657530573297466, \"f2\": 0.18448489188345688, \"f0_5\": 0.47499495228635935, \"p4\": 0.4199040885530539, \"phi\": 0.3913816625655706}, {\"truth_threshold\": 26.659999404102564, \"match_probability\": 0.9999999905693747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46516.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257445.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1530327903908725, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8469672096091275, \"precision\": 0.999785066414478, \"recall\": 0.1530327903908725, \"specificity\": 0.9999999921797885, \"npv\": 0.9997987130877698, \"accuracy\": 0.9997987125913629, \"f1\": 0.26543637852473845, \"f2\": 0.18424075350333102, \"f0_5\": 0.4745901053941824, \"p4\": 0.41950868208758235, \"phi\": 0.3911126272440293}, {\"truth_threshold\": 26.67999940365553, \"match_probability\": 0.9999999906992089, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46427.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257534.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15273998966972738, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8472600103302727, \"precision\": 0.9997846544781102, \"recall\": 0.15273998966972738, \"specificity\": 0.9999999921797885, \"npv\": 0.999798643515908, \"accuracy\": 0.9997986430080207, \"f1\": 0.26499580477057516, \"f2\": 0.18390120741736588, \"f0_5\": 0.47402641160362585, \"p4\": 0.4189582505645189, \"phi\": 0.3907381921346895}, {\"truth_threshold\": 26.699999403208494, \"match_probability\": 0.9999999908272557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46328.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15241428999115017, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8475857100088499, \"precision\": 0.9997841943976865, \"recall\": 0.15241428999115017, \"specificity\": 0.9999999921797885, \"npv\": 0.9997985661269942, \"accuracy\": 0.9997985656063254, \"f1\": 0.26450546533104574, \"f2\": 0.18352345382837024, \"f0_5\": 0.4733984177816653, \"p4\": 0.418345193197108, \"phi\": 0.3903212637249149}, {\"truth_threshold\": 26.71999940276146, \"match_probability\": 0.9999999909535395, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46257.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257704.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1521807073933827, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8478192926066173, \"precision\": 0.9997838632286511, \"recall\": 0.1521807073933827, \"specificity\": 0.9999999921797885, \"npv\": 0.9997985106258616, \"accuracy\": 0.9997985100960187, \"f1\": 0.26415363705928707, \"f2\": 0.18325250314750446, \"f0_5\": 0.47294741211666386, \"p4\": 0.41790501932555035, \"phi\": 0.39002198006547134}, {\"truth_threshold\": 26.739999402314425, \"match_probability\": 0.9999999910780848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46159.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15185829761054873, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8481417023894513, \"precision\": 0.9997834044488726, \"recall\": 0.15185829761054873, \"specificity\": 0.9999999921797885, \"npv\": 0.9997984340186744, \"accuracy\": 0.9997984334761588, \"f1\": 0.2636677805386571, \"f2\": 0.18287846480186812, \"f0_5\": 0.47232403604311585, \"p4\": 0.4172967591727414, \"phi\": 0.38960850670277053}, {\"truth_threshold\": 26.75999940186739, \"match_probability\": 0.9999999912009154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46105.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15168064324041572, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8483193567595843, \"precision\": 0.9997831508186057, \"recall\": 0.15168064324041572, \"specificity\": 0.9999999921797885, \"npv\": 0.9997983918065559, \"accuracy\": 0.9997983912570523, \"f1\": 0.26339994743998446, \"f2\": 0.1826723372153929, \"f0_5\": 0.47198011551509866, \"p4\": 0.41696124985312116, \"phi\": 0.3893804868501919}, {\"truth_threshold\": 26.779999401420355, \"match_probability\": 0.999999991322055, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 46005.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 257956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15135165366609532, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8486483463339046, \"precision\": 0.9997826795610127, \"recall\": 0.15135165366609532, \"specificity\": 0.9999999921797885, \"npv\": 0.9997983136359755, \"accuracy\": 0.9997983130735217, \"f1\": 0.262903741970878, \"f2\": 0.18229057287700132, \"f0_5\": 0.4713424217400481, \"p4\": 0.4163392868395487, \"phi\": 0.38895787493844025}, {\"truth_threshold\": 26.79999940097332, \"match_probability\": 0.9999999914415268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45896.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258065.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1509930550300861, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8490069449699139, \"precision\": 0.9997821635516054, \"recall\": 0.1509930550300861, \"specificity\": 0.9999999921797885, \"npv\": 0.9997982284300568, \"accuracy\": 0.9997982278534734, \"f1\": 0.26236255491372434, \"f2\": 0.18187438082028928, \"f0_5\": 0.470646143749295, \"p4\": 0.41566038470332184, \"phi\": 0.38849670438312867}, {\"truth_threshold\": 26.819999400526285, \"match_probability\": 0.9999999915593538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45820.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258141.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1507430229536026, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8492569770463974, \"precision\": 0.9997818023128955, \"recall\": 0.1507430229536026, \"specificity\": 0.9999999921797885, \"npv\": 0.9997981690204341, \"accuracy\": 0.9997981684339902, \"f1\": 0.26198501390830525, \"f2\": 0.18158414931273847, \"f0_5\": 0.4701599282549494, \"p4\": 0.41518642658862515, \"phi\": 0.38817483012907306}, {\"truth_threshold\": 26.83999940007925, \"match_probability\": 0.9999999916755588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45732.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258229.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.15045351212820066, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8495464878717993, \"precision\": 0.999781382536837, \"recall\": 0.15045351212820066, \"specificity\": 0.9999999921797885, \"npv\": 0.9997981002303533, \"accuracy\": 0.9997980996324832, \"f1\": 0.2615476561539363, \"f2\": 0.1812480480918463, \"f0_5\": 0.46959618342715265, \"p4\": 0.41463702094392296, \"phi\": 0.38780179991419717}, {\"truth_threshold\": 26.859999399632215, \"match_probability\": 0.9999999917901637, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45642.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258319.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1501574215113123, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8498425784886877, \"precision\": 0.999780951546482, \"recall\": 0.1501574215113123, \"specificity\": 0.9999999921797885, \"npv\": 0.9997980298768714, \"accuracy\": 0.9997980292673057, \"f1\": 0.26110013071596305, \"f2\": 0.18090425970435103, \"f0_5\": 0.4690187825364953, \"p4\": 0.41407444825026607, \"phi\": 0.3874199202809733}, {\"truth_threshold\": 26.87999939918518, \"match_probability\": 0.999999991903191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45572.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14992712880928805, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.850072871190712, \"precision\": 0.9997806151551051, \"recall\": 0.14992712880928805, \"specificity\": 0.9999999921797885, \"npv\": 0.9997979751575035, \"accuracy\": 0.9997979745388343, \"f1\": 0.2607518960471244, \"f2\": 0.18063683482027484, \"f0_5\": 0.46856910191264867, \"p4\": 0.4136364151122475, \"phi\": 0.3871226423859615}, {\"truth_threshold\": 26.899999398738146, \"match_probability\": 0.9999999920146622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45518.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258443.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.149749474439155, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.850250525560845, \"precision\": 0.9997803549464066, \"recall\": 0.149749474439155, \"specificity\": 0.9999999921797885, \"npv\": 0.9997979329454236, \"accuracy\": 0.9997979323197278, \"f1\": 0.26048316256019505, \"f2\": 0.18043051534361, \"f0_5\": 0.46822185145029654, \"p4\": 0.41329821848124054, \"phi\": 0.3868931576749301}, {\"truth_threshold\": 26.91999939829111, \"match_probability\": 0.9999999921245987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45443.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14950273225841473, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8504972677415853, \"precision\": 0.9997799925197457, \"recall\": 0.14950273225841473, \"specificity\": 0.9999999921797885, \"npv\": 0.9997978743175411, \"accuracy\": 0.9997978736820798, \"f1\": 0.26010978380946387, \"f2\": 0.18014393120732072, \"f0_5\": 0.4677390468387498, \"p4\": 0.41282808807453686, \"phi\": 0.3865742029420767}, {\"truth_threshold\": 26.939999397844076, \"match_probability\": 0.9999999922330216, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45372.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14926914966064725, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8507308503393527, \"precision\": 0.9997796483187167, \"recall\": 0.14926914966064725, \"specificity\": 0.9999999921797885, \"npv\": 0.9997978188164851, \"accuracy\": 0.9997978181717732, \"f1\": 0.25975617086931757, \"f2\": 0.17987260015254997, \"f0_5\": 0.46728144201001465, \"p4\": 0.41238258833554337, \"phi\": 0.3862720164887795}, {\"truth_threshold\": 26.95999939739704, \"match_probability\": 0.999999992339952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45294.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258667.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14901253779267734, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8509874622073227, \"precision\": 0.999779268938725, \"recall\": 0.14901253779267734, \"specificity\": 0.9999999921797885, \"npv\": 0.9997977578435012, \"accuracy\": 0.9997977571886193, \"f1\": 0.25936752895365983, \"f2\": 0.1795744829314244, \"f0_5\": 0.4667781036611381, \"p4\": 0.4118926687036274, \"phi\": 0.38593976429382704}, {\"truth_threshold\": 26.979999396950006, \"match_probability\": 0.99999999244541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45208.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258753.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14872960675876182, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8512703932412382, \"precision\": 0.9997788491308771, \"recall\": 0.14872960675876182, \"specificity\": 0.9999999921797885, \"npv\": 0.9997976906168866, \"accuracy\": 0.999797689950783, \"f1\": 0.25893882507252725, \"f2\": 0.17924574683877556, \"f0_5\": 0.4662223899775799, \"p4\": 0.41135189633133845, \"phi\": 0.3855731031400775}, {\"truth_threshold\": 26.99999939650297, \"match_probability\": 0.9999999925494163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45149.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1485355029099128, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8514644970900872, \"precision\": 0.99977856019841, \"recall\": 0.1485355029099128, \"specificity\": 0.9999999921797885, \"npv\": 0.9997976444963074, \"accuracy\": 0.9997976438225, \"f1\": 0.25864459211732355, \"f2\": 0.1790201926561634, \"f0_5\": 0.4658406882419825, \"p4\": 0.41098053406026464, \"phi\": 0.3853213547731484}, {\"truth_threshold\": 27.019999396055937, \"match_probability\": 0.9999999926519907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45060.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14824270218876764, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8517572978112323, \"precision\": 0.9997781229199024, \"recall\": 0.14824270218876764, \"specificity\": 0.9999999921797885, \"npv\": 0.9997975749245942, \"accuracy\": 0.9997975742391578, \"f1\": 0.2582005609816893, \"f2\": 0.17867990997006933, \"f0_5\": 0.4652641969597783, \"p4\": 0.4104197771295852, \"phi\": 0.3849412873072956}, {\"truth_threshold\": 27.039999395608902, \"match_probability\": 0.999999992753153, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44976.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 258985.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1479663509463385, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8520336490536615, \"precision\": 0.9997777086204597, \"recall\": 0.1479663509463385, \"specificity\": 0.9999999921797885, \"npv\": 0.9997975092614132, \"accuracy\": 0.999797508564992, \"f1\": 0.25778126764236403, \"f2\": 0.1783587002212828, \"f0_5\": 0.46471931474152983, \"p4\": 0.40988989754111926, \"phi\": 0.3845822274488024}, {\"truth_threshold\": 27.059999395161867, \"match_probability\": 0.9999999928529224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44896.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259065.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14770315928688219, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8522968407131178, \"precision\": 0.9997773126085601, \"recall\": 0.14770315928688219, \"specificity\": 0.9999999921797885, \"npv\": 0.9997974467250582, \"accuracy\": 0.9997974460181677, \"f1\": 0.25738175293163296, \"f2\": 0.17805274638112234, \"f0_5\": 0.4641996753414601, \"p4\": 0.409384684291351, \"phi\": 0.3842399537790342}, {\"truth_threshold\": 27.079999394714832, \"match_probability\": 0.9999999929513184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44808.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14741364846148025, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8525863515385197, \"precision\": 0.9997768753625775, \"recall\": 0.14741364846148025, \"specificity\": 0.9999999921797885, \"npv\": 0.999797377935077, \"accuracy\": 0.9997973772166607, \"f1\": 0.2569420750675929, \"f2\": 0.17771615230727983, \"f0_5\": 0.4636272771106278, \"p4\": 0.4088283108057407, \"phi\": 0.38386310029733905}, {\"truth_threshold\": 27.099999394267797, \"match_probability\": 0.9999999930483596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44768.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259193.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1472820526317521, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8527179473682479, \"precision\": 0.9997766760462727, \"recall\": 0.1472820526317521, \"specificity\": 0.9999999921797885, \"npv\": 0.9997973466669067, \"accuracy\": 0.9997973459432485, \"f1\": 0.2567421481394395, \"f2\": 0.1775631394660731, \"f0_5\": 0.46336682033564286, \"p4\": 0.4085751921839387, \"phi\": 0.3836916809180183}, {\"truth_threshold\": 27.119999393820763, \"match_probability\": 0.999999993144065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44725.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259236.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14714058711479433, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8528594128852056, \"precision\": 0.999776461383704, \"recall\": 0.14714058711479433, \"specificity\": 0.9999999921797885, \"npv\": 0.9997973130536258, \"accuracy\": 0.9997973123243303, \"f1\": 0.2565271755339895, \"f2\": 0.17739863983137907, \"f0_5\": 0.4630866368054736, \"p4\": 0.40830293502578807, \"phi\": 0.383507319641205}, {\"truth_threshold\": 27.139999393373728, \"match_probability\": 0.9999999932384526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44654.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259307.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14690700451702685, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8530929954829731, \"precision\": 0.9997761060361813, \"recall\": 0.14690700451702685, \"specificity\": 0.9999999921797885, \"npv\": 0.9997972575526323, \"accuracy\": 0.9997972568140236, \"f1\": 0.256172104697024, \"f2\": 0.17712699959064124, \"f0_5\": 0.4626235710718852, \"p4\": 0.4078530430651945, \"phi\": 0.3832027150516636}, {\"truth_threshold\": 27.159999392926693, \"match_probability\": 0.9999999933315408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44570.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259391.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14663065327459773, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8533693467254023, \"precision\": 0.999775684163302, \"recall\": 0.14663065327459773, \"specificity\": 0.9999999921797885, \"npv\": 0.9997971918894929, \"accuracy\": 0.999797191139858, \"f1\": 0.25575183407404006, \"f2\": 0.17680558288322024, \"f0_5\": 0.4620750143588489, \"p4\": 0.40732021102044347, \"phi\": 0.3828420248540101}, {\"truth_threshold\": 27.179999392479658, \"match_probability\": 0.9999999934233474, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44502.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14640694036405985, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8535930596359401, \"precision\": 0.9997753414809489, \"recall\": 0.14640694036405985, \"specificity\": 0.9999999921797885, \"npv\": 0.9997971387336245, \"accuracy\": 0.9997971379750572, \"f1\": 0.25541146659856, \"f2\": 0.17654535702611007, \"f0_5\": 0.4616303844948953, \"p4\": 0.40688842118197754, \"phi\": 0.38254978850270227}, {\"truth_threshold\": 27.199999392032623, \"match_probability\": 0.9999999935138901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44435.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259526.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1461865173492652, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8538134826507348, \"precision\": 0.9997750028124649, \"recall\": 0.1461865173492652, \"specificity\": 0.9999999921797885, \"npv\": 0.9997970863594656, \"accuracy\": 0.9997970855920917, \"f1\": 0.2550759745813792, \"f2\": 0.1762889305548172, \"f0_5\": 0.4611918022339805, \"p4\": 0.4064625871490841, \"phi\": 0.38226163126673923}, {\"truth_threshold\": 27.21999939158559, \"match_probability\": 0.9999999936031864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44375.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259586.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14598912360467298, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.854010876395327, \"precision\": 0.999774698659457, \"recall\": 0.14598912360467298, \"specificity\": 0.9999999921797885, \"npv\": 0.9997970394572383, \"accuracy\": 0.9997970386819733, \"f1\": 0.25477542443432677, \"f2\": 0.17605927176727404, \"f0_5\": 0.46079862762486473, \"p4\": 0.4060809108297666, \"phi\": 0.3820033955487747}, {\"truth_threshold\": 27.239999391138554, \"match_probability\": 0.9999999936912531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44310.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14577528038136472, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8542247196186353, \"precision\": 0.9997743682310469, \"recall\": 0.14577528038136472, \"specificity\": 0.9999999921797885, \"npv\": 0.9997969886464971, \"accuracy\": 0.9997969878626785, \"f1\": 0.2544497115834628, \"f2\": 0.1758104500684038, \"f0_5\": 0.46037224592252113, \"p4\": 0.40566707324417606, \"phi\": 0.381723443075148}, {\"truth_threshold\": 27.25999939069152, \"match_probability\": 0.9999999937781076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44248.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14557130684528607, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8544286931547139, \"precision\": 0.999774052148764, \"recall\": 0.14557130684528607, \"specificity\": 0.9999999921797885, \"npv\": 0.9997969401808718, \"accuracy\": 0.9997969393888895, \"f1\": 0.2541389183243878, \"f2\": 0.1755730885277541, \"f0_5\": 0.4599651138374155, \"p4\": 0.40527199147053145, \"phi\": 0.3814562200583548}, {\"truth_threshold\": 27.279999390244484, \"match_probability\": 0.9999999938637661, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44185.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259776.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14536404341346423, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8546359565865358, \"precision\": 0.9997737300599615, \"recall\": 0.14536404341346423, \"specificity\": 0.9999999921797885, \"npv\": 0.9997968909335478, \"accuracy\": 0.9997968901332652, \"f1\": 0.25382299888555704, \"f2\": 0.17533187464832437, \"f0_5\": 0.45955098483382945, \"p4\": 0.4048701925323913, \"phi\": 0.3811844951307309}, {\"truth_threshold\": 27.29999938979745, \"match_probability\": 0.9999999939482456, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44146.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14523573747947927, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8547642625205207, \"precision\": 0.9997735302110698, \"recall\": 0.14523573747947927, \"specificity\": 0.9999999921797885, \"npv\": 0.9997968604471116, \"accuracy\": 0.9997968596416883, \"f1\": 0.2536273724064036, \"f2\": 0.1751825396825397, \"f0_5\": 0.45929440161469876, \"p4\": 0.40462128544741177, \"phi\": 0.38101618736352966}, {\"truth_threshold\": 27.319999389350414, \"match_probability\": 0.9999999940315618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44079.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1450153144646846, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8549846855353154, \"precision\": 0.9997731860554787, \"recall\": 0.1450153144646846, \"specificity\": 0.9999999921797885, \"npv\": 0.9997968080729818, \"accuracy\": 0.9997968072587229, \"f1\": 0.2532911937939951, \"f2\": 0.17492596828561519, \"f0_5\": 0.4588532156888055, \"p4\": 0.40419336410222273, \"phi\": 0.38072686956813656}, {\"truth_threshold\": 27.33999938890338, \"match_probability\": 0.9999999941137311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44002.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 259959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1447619924924579, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8552380075075421, \"precision\": 0.9997727892392984, \"recall\": 0.1447619924924579, \"specificity\": 0.9999999921797885, \"npv\": 0.9997967478818245, \"accuracy\": 0.9997967470574043, \"f1\": 0.25290467938604433, \"f2\": 0.17463106894756225, \"f0_5\": 0.4583455726871788, \"p4\": 0.4037010865860929, \"phi\": 0.3803940982869903}, {\"truth_threshold\": 27.359999388456345, \"match_probability\": 0.999999994194769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43923.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260038.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14450209072874481, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8554979092712552, \"precision\": 0.9997723806705665, \"recall\": 0.14450209072874481, \"specificity\": 0.9999999921797885, \"npv\": 0.999796686127268, \"accuracy\": 0.9997966852924152, \"f1\": 0.25250794782318753, \"f2\": 0.17432847242011879, \"f0_5\": 0.4578240666426235, \"p4\": 0.40319548017414125, \"phi\": 0.3800523808151002}, {\"truth_threshold\": 27.37999938800931, \"match_probability\": 0.9999999942746914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43877.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260084.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14435075552455742, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8556492444754425, \"precision\": 0.9997721420921913, \"recall\": 0.14435075552455742, \"specificity\": 0.9999999921797885, \"npv\": 0.9997966501689222, \"accuracy\": 0.9997966493279911, \"f1\": 0.25227685655803683, \"f2\": 0.17415225949031976, \"f0_5\": 0.4575200882569462, \"p4\": 0.4029008229901014, \"phi\": 0.37985326449146356}, {\"truth_threshold\": 27.399999387562275, \"match_probability\": 0.9999999943535134, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43829.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260132.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14419284052888365, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8558071594711164, \"precision\": 0.9997718926070394, \"recall\": 0.14419284052888365, \"specificity\": 0.9999999921797885, \"npv\": 0.9997966126471728, \"accuracy\": 0.9997966117998964, \"f1\": 0.25203565267395056, \"f2\": 0.1739683714077272, \"f0_5\": 0.4572026445963736, \"p4\": 0.40259315550558855, \"phi\": 0.37964537960968003}, {\"truth_threshold\": 27.41999938711524, \"match_probability\": 0.9999999944312503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43732.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260229.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14387372064179285, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8561262793582072, \"precision\": 0.9997713867678661, \"recall\": 0.14387372064179285, \"specificity\": 0.9999999921797885, \"npv\": 0.9997965368219794, \"accuracy\": 0.9997965359618718, \"f1\": 0.25154801655435816, \"f2\": 0.17359672146244878, \"f0_5\": 0.45656036698550306, \"p4\": 0.4019707892790293, \"phi\": 0.37922493112166267}, {\"truth_threshold\": 27.439999386668205, \"match_probability\": 0.9999999945079169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43675.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260286.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14368619658443024, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8563138034155697, \"precision\": 0.9997710884743047, \"recall\": 0.14368619658443024, \"specificity\": 0.9999999921797885, \"npv\": 0.9997964922649125, \"accuracy\": 0.9997964913972593, \"f1\": 0.25126134055907445, \"f2\": 0.17337830252419753, \"f0_5\": 0.4561824604502602, \"p4\": 0.4016046804876407, \"phi\": 0.37897764589575544}, {\"truth_threshold\": 27.45999938622117, \"match_probability\": 0.9999999945835281, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43624.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14351841190152684, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8564815880984732, \"precision\": 0.9997708209194665, \"recall\": 0.14351841190152684, \"specificity\": 0.9999999921797885, \"npv\": 0.9997964523980665, \"accuracy\": 0.9997964515236587, \"f1\": 0.2510047612882809, \"f2\": 0.173182858295262, \"f0_5\": 0.4558440282802191, \"p4\": 0.4012768653869231, \"phi\": 0.37875625386050626}, {\"truth_threshold\": 27.479999385774136, \"match_probability\": 0.9999999946580982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43558.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260403.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1433012787824754, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8566987212175247, \"precision\": 0.9997704737421961, \"recall\": 0.1433012787824754, \"specificity\": 0.9999999921797885, \"npv\": 0.9997964008056821, \"accuracy\": 0.9997963999225286, \"f1\": 0.25067260573937716, \"f2\": 0.17292990697246016, \"f0_5\": 0.45540562863708695, \"p4\": 0.4008522914829596, \"phi\": 0.37846955430323415}, {\"truth_threshold\": 27.4999993853271, \"match_probability\": 0.9999999947316417, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43493.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260468.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14308743555916714, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8569125644408329, \"precision\": 0.9997701307955773, \"recall\": 0.14308743555916714, \"specificity\": 0.9999999921797885, \"npv\": 0.9997963499950059, \"accuracy\": 0.9997963491032337, \"f1\": 0.25034535951925957, \"f2\": 0.1726807623315893, \"f0_5\": 0.45497339807897097, \"p4\": 0.40043377226243276, \"phi\": 0.3781869862784873}, {\"truth_threshold\": 27.519999384880066, \"match_probability\": 0.9999999948041728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43433.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1428900418145749, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8571099581854251, \"precision\": 0.9997698133186014, \"recall\": 0.1428900418145749, \"specificity\": 0.9999999921797885, \"npv\": 0.9997963030928477, \"accuracy\": 0.9997963021931153, \"f1\": 0.25004317739576976, \"f2\": 0.17245075983473188, \"f0_5\": 0.45457399844683116, \"p4\": 0.4000471132224374, \"phi\": 0.3779259667628645}, {\"truth_threshold\": 27.53999938443303, \"match_probability\": 0.9999999948757052, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43335.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14256763203174092, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8574323679682591, \"precision\": 0.9997692928826855, \"recall\": 0.14256763203174092, \"specificity\": 0.9999999921797885, \"npv\": 0.9997962264859989, \"accuracy\": 0.9997962255732554, \"f1\": 0.2495493887234888, \"f2\": 0.17207504195160536, \"f0_5\": 0.45392078199861313, \"p4\": 0.3994148803219548, \"phi\": 0.3774992468074033}, {\"truth_threshold\": 27.559999383985996, \"match_probability\": 0.9999999949462529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43250.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14228799089356858, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8577120091064314, \"precision\": 0.9997688395746648, \"recall\": 0.14228799089356858, \"specificity\": 0.9999999921797885, \"npv\": 0.9997961600412926, \"accuracy\": 0.9997961591172544, \"f1\": 0.2491208769054867, \"f2\": 0.17174911683228708, \"f0_5\": 0.4533533472676158, \"p4\": 0.3988658209214777, \"phi\": 0.3771287416069949}, {\"truth_threshold\": 27.57999938353896, \"match_probability\": 0.9999999950158294, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43153.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14196887100647781, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8580311289935222, \"precision\": 0.9997683200889651, \"recall\": 0.14196887100647781, \"specificity\": 0.9999999921797885, \"npv\": 0.999796084216168, \"accuracy\": 0.9997960832792298, \"f1\": 0.24863161291066016, \"f2\": 0.17137712498818514, \"f0_5\": 0.4527048150176349, \"p4\": 0.3982384579299376, \"phi\": 0.37670548464371634}, {\"truth_threshold\": 27.599999383091927, \"match_probability\": 0.9999999950844479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43094.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14177476715762877, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8582252328423712, \"precision\": 0.999768002969562, \"recall\": 0.14177476715762877, \"specificity\": 0.9999999921797885, \"npv\": 0.9997960380957369, \"accuracy\": 0.9997960371509467, \"f1\": 0.24833388558339217, \"f2\": 0.17115083387081914, \"f0_5\": 0.45230983023949517, \"p4\": 0.3978564538031539, \"phi\": 0.3764478069591707}, {\"truth_threshold\": 27.61999938264489, \"match_probability\": 0.9999999951521218, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43047.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14162014205769818, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8583798579423018, \"precision\": 0.9997677497271059, \"recall\": 0.14162014205769818, \"specificity\": 0.9999999921797885, \"npv\": 0.9997960013557355, \"accuracy\": 0.9997960004046873, \"f1\": 0.24809664052008829, \"f2\": 0.17097055288700225, \"f0_5\": 0.45199490118419366, \"p4\": 0.3975519219967475, \"phi\": 0.3762424120261799}, {\"truth_threshold\": 27.639999382197857, \"match_probability\": 0.999999995218864, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42992.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 260969.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14143919779182199, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.858560802208178, \"precision\": 0.9997674526766197, \"recall\": 0.14143919779182199, \"specificity\": 0.9999999921797885, \"npv\": 0.9997959583621204, \"accuracy\": 0.9997959574037455, \"f1\": 0.24781893170165117, \"f2\": 0.1707595686843347, \"f0_5\": 0.45162605127644867, \"p4\": 0.39719530310958934, \"phi\": 0.3760019138017509}, {\"truth_threshold\": 27.659999381750822, \"match_probability\": 0.9999999952846872, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42939.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261022.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14126483331743217, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8587351666825678, \"precision\": 0.9997671657081655, \"recall\": 0.14126483331743217, \"specificity\": 0.9999999921797885, \"npv\": 0.9997959169319129, \"accuracy\": 0.9997959159664743, \"f1\": 0.24755123807327548, \"f2\": 0.17055623919103458, \"f0_5\": 0.45127029134621244, \"p4\": 0.396851394907746, \"phi\": 0.37577001535861615}, {\"truth_threshold\": 27.679999381303787, \"match_probability\": 0.9999999953496044, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42870.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261091.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1410378305111511, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8589621694888488, \"precision\": 0.9997667910447762, \"recall\": 0.1410378305111511, \"specificity\": 0.9999999921797885, \"npv\": 0.9997958629944782, \"accuracy\": 0.9997958620198383, \"f1\": 0.24720260868813088, \"f2\": 0.17029150155236572, \"f0_5\": 0.45080665683802296, \"p4\": 0.3964032865371702, \"phi\": 0.3754678952572022}, {\"truth_threshold\": 27.699999380856752, \"match_probability\": 0.9999999954136277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42780.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14074173989426275, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8592582601057372, \"precision\": 0.9997663005375088, \"recall\": 0.14074173989426275, \"specificity\": 0.9999999921797885, \"npv\": 0.9997957926413111, \"accuracy\": 0.9997957916546607, \"f1\": 0.2467476661927435, \"f2\": 0.16994614796676397, \"f0_5\": 0.45020110666546, \"p4\": 0.39581815243557095, \"phi\": 0.37507345988426233}, {\"truth_threshold\": 27.719999380409718, \"match_probability\": 0.9999999954767697, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42713.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1405213168794681, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8594786831205319, \"precision\": 0.9997659340402125, \"recall\": 0.1405213168794681, \"specificity\": 0.9999999921797885, \"npv\": 0.9997957402672932, \"accuracy\": 0.9997957392716952, \"f1\": 0.24640883340448363, \"f2\": 0.16968901933707145, \"f0_5\": 0.4497497120161397, \"p4\": 0.39538207779055823, \"phi\": 0.374779555150962}, {\"truth_threshold\": 27.739999379962683, \"match_probability\": 0.9999999955390423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42629.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.14024496563703895, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8597550343629611, \"precision\": 0.9997654729238491, \"recall\": 0.14024496563703895, \"specificity\": 0.9999999921797885, \"npv\": 0.9997956746043531, \"accuracy\": 0.9997956735975295, \"f1\": 0.24598384304673976, \"f2\": 0.1693666104349443, \"f0_5\": 0.4491830640419627, \"p4\": 0.39483478384242626, \"phi\": 0.3744107516757931}, {\"truth_threshold\": 27.759999379515648, \"match_probability\": 0.9999999956004576, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42535.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261426.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13993571543717778, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8600642845628222, \"precision\": 0.9997649547537901, \"recall\": 0.13993571543717778, \"specificity\": 0.9999999921797885, \"npv\": 0.9997956011244067, \"accuracy\": 0.9997956001050108, \"f1\": 0.24550801429123884, \"f2\": 0.16900576848653318, \"f0_5\": 0.44854800576199905, \"p4\": 0.39422157803935554, \"phi\": 0.37399761188117714}, {\"truth_threshold\": 27.779999379068613, \"match_probability\": 0.9999999956610274, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42451.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13965936419474867, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8603406358052513, \"precision\": 0.9997644897670804, \"recall\": 0.13965936419474867, \"specificity\": 0.9999999921797885, \"npv\": 0.9997955354614848, \"accuracy\": 0.9997955344308451, \"f1\": 0.2450825871336116, \"f2\": 0.16868326836498304, \"f0_5\": 0.4479796540770992, \"p4\": 0.39367292846700663, \"phi\": 0.37362803666365507}, {\"truth_threshold\": 27.799999378621578, \"match_probability\": 0.9999999957207634, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42361.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261600.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13936327357786032, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8606367264221397, \"precision\": 0.9997639895211348, \"recall\": 0.13936327357786032, \"specificity\": 0.9999999921797885, \"npv\": 0.9997954651083639, \"accuracy\": 0.9997954640656675, \"f1\": 0.24462654331681738, \"f2\": 0.16833768473591557, \"f0_5\": 0.44736981064326375, \"p4\": 0.39308437776023386, \"phi\": 0.37323165717299667}, {\"truth_threshold\": 27.819999378174543, \"match_probability\": 0.9999999957796768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42267.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261694.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13905402337799916, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8609459766220009, \"precision\": 0.9997634647680772, \"recall\": 0.13905402337799916, \"specificity\": 0.9999999921797885, \"npv\": 0.9997953916284482, \"accuracy\": 0.9997953905731488, \"f1\": 0.24414997776096212, \"f2\": 0.16797668904660204, \"f0_5\": 0.4467318720947684, \"p4\": 0.3924688815274202, \"phi\": 0.3728172109335711}, {\"truth_threshold\": 27.83999937772751, \"match_probability\": 0.9999999958377793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42192.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13880728119725885, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8611927188027412, \"precision\": 0.9997630444054784, \"recall\": 0.13880728119725885, \"specificity\": 0.9999999921797885, \"npv\": 0.9997953330008635, \"accuracy\": 0.999795331935501, \"f1\": 0.24376955364958128, \"f2\": 0.16768862187869124, \"f0_5\": 0.44622215077553734, \"p4\": 0.3919772158044927, \"phi\": 0.37248620504518015}, {\"truth_threshold\": 27.859999377280474, \"match_probability\": 0.9999999958950818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42138.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261823.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13862962682712585, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8613703731728741, \"precision\": 0.9997627408180697, \"recall\": 0.13862962682712585, \"specificity\": 0.9999999921797885, \"npv\": 0.999795290789007, \"accuracy\": 0.9997952897163944, \"f1\": 0.24349554620076333, \"f2\": 0.1674811922492353, \"f0_5\": 0.4458547506840502, \"p4\": 0.39162289816272305, \"phi\": 0.3722476985785006}, {\"truth_threshold\": 27.87999937683344, \"match_probability\": 0.9999999959515954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 42054.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13835327558469673, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8616467244153033, \"precision\": 0.9997622670216813, \"recall\": 0.13835327558469673, \"specificity\": 0.9999999921797885, \"npv\": 0.9997952251261258, \"accuracy\": 0.9997952240422288, \"f1\": 0.24306914240300556, \"f2\": 0.1671584885381125, \"f0_5\": 0.44528257136020094, \"p4\": 0.39107120688674274, \"phi\": 0.37187638451120136}, {\"truth_threshold\": 27.899999376386404, \"match_probability\": 0.999999996007331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41975.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 261986.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1380933738209836, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8619066261790164, \"precision\": 0.999761819697511, \"recall\": 0.1380933738209836, \"specificity\": 0.9999999921797885, \"npv\": 0.9997951633717576, \"accuracy\": 0.9997951622772396, \"f1\": 0.24266793083313581, \"f2\": 0.16685495405178288, \"f0_5\": 0.44474370683681536, \"p4\": 0.3905517641776899, \"phi\": 0.3715268338917286}, {\"truth_threshold\": 27.91999937593937, \"match_probability\": 0.9999999960622993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41891.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1378170225785545, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8621829774214456, \"precision\": 0.9997613422114031, \"recall\": 0.1378170225785545, \"specificity\": 0.9999999921797885, \"npv\": 0.9997950977088933, \"accuracy\": 0.9997950966030739, \"f1\": 0.242241125073006, \"f2\": 0.1665321666951568, \"f0_5\": 0.4441699447584108, \"p4\": 0.38999881671149944, \"phi\": 0.3711547987461462}, {\"truth_threshold\": 27.939999375492334, \"match_probability\": 0.9999999961165108, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41847.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262114.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1376722671658535, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8623277328341464, \"precision\": 0.9997610913347827, \"recall\": 0.1376722671658535, \"specificity\": 0.9999999921797885, \"npv\": 0.999795063314063, \"accuracy\": 0.9997950622023205, \"f1\": 0.24201747740140767, \"f2\": 0.16636307039590492, \"f0_5\": 0.4438690762830698, \"p4\": 0.3897089186084811, \"phi\": 0.3709597743062562}, {\"truth_threshold\": 27.9599993750453, \"match_probability\": 0.9999999961699759, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41776.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262185.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13743868456808603, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8625613154319139, \"precision\": 0.9997606853970229, \"recall\": 0.13743868456808603, \"specificity\": 0.9999999921797885, \"npv\": 0.9997950078133192, \"accuracy\": 0.9997950066920137, \"f1\": 0.24165647135043833, \"f2\": 0.16609018550766125, \"f0_5\": 0.4433831099224165, \"p4\": 0.38924075254657153, \"phi\": 0.37064485941482295}, {\"truth_threshold\": 27.979999374598265, \"match_probability\": 0.999999996222705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41687.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262274.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1371458838469409, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8628541161530591, \"precision\": 0.9997601745928963, \"recall\": 0.1371458838469409, \"specificity\": 0.9999999921797885, \"npv\": 0.999794938241973, \"accuracy\": 0.9997949371086715, \"f1\": 0.24120373316978053, \"f2\": 0.1657480750130612, \"f0_5\": 0.4427731126353959, \"p4\": 0.3886532399094182, \"phi\": 0.3702497286788128}, {\"truth_threshold\": 27.99999937415123, \"match_probability\": 0.9999999962747081, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41629.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13695506989383507, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8630449301061649, \"precision\": 0.9997598405341146, \"recall\": 0.13695506989383507, \"specificity\": 0.9999999921797885, \"npv\": 0.9997948929033481, \"accuracy\": 0.9997948917622238, \"f1\": 0.24090856481481482, \"f2\": 0.1655251005381385, \"f0_5\": 0.4423750895291775, \"p4\": 0.38826997278320735, \"phi\": 0.36999200067557125}, {\"truth_threshold\": 28.019999373704195, \"match_probability\": 0.9999999963259953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41573.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262388.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13677083573221566, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8632291642677844, \"precision\": 0.9997595171103576, \"recall\": 0.13677083573221566, \"specificity\": 0.9999999921797885, \"npv\": 0.999794849128128, \"accuracy\": 0.9997948479794467, \"f1\": 0.24062348065658787, \"f2\": 0.16530979532012594, \"f0_5\": 0.44199041873895634, \"p4\": 0.3878996265391731, \"phi\": 0.3697429894041214}, {\"truth_threshold\": 28.03999937325716, \"match_probability\": 0.9999999963765764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41488.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13649119459404332, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8635088054059566, \"precision\": 0.9997590245313027, \"recall\": 0.13649119459404332, \"specificity\": 0.9999999921797885, \"npv\": 0.9997947826836047, \"accuracy\": 0.9997947815234457, \"f1\": 0.2401905870161148, \"f2\": 0.16498295610899819, \"f0_5\": 0.4414058427119308, \"p4\": 0.38733693883325904, \"phi\": 0.3693647051236279}, {\"truth_threshold\": 28.059999372810125, \"match_probability\": 0.9999999964264611, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41434.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262527.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13631354022391032, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8636864597760897, \"precision\": 0.9997587105491748, \"recall\": 0.13631354022391032, \"specificity\": 0.9999999921797885, \"npv\": 0.9997947404717945, \"accuracy\": 0.9997947393043392, \"f1\": 0.23991546155961843, \"f2\": 0.16477529412513284, \"f0_5\": 0.44103402542273656, \"p4\": 0.38697911857298556, \"phi\": 0.3691241819970291}, {\"truth_threshold\": 28.07999937236309, \"match_probability\": 0.9999999964756591, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41363.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13607995762614283, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8639200423738572, \"precision\": 0.9997582964735455, \"recall\": 0.13607995762614283, \"specificity\": 0.9999999921797885, \"npv\": 0.9997946849710866, \"accuracy\": 0.9997946837940325, \"f1\": 0.23955359159538303, \"f2\": 0.16450222992530328, \"f0_5\": 0.4405446338611107, \"p4\": 0.38650823903364384, \"phi\": 0.36880769995128154}, {\"truth_threshold\": 28.099999371916056, \"match_probability\": 0.9999999965241797, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41303.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1358825638815506, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8641174361184494, \"precision\": 0.9997579454409024, \"recall\": 0.1358825638815506, \"specificity\": 0.9999999921797885, \"npv\": 0.9997946380690846, \"accuracy\": 0.9997946368839141, \"f1\": 0.2392476699664614, \"f2\": 0.1642714474007622, \"f0_5\": 0.44013060166704676, \"p4\": 0.38610994716595437, \"phi\": 0.3685400384830014}, {\"truth_threshold\": 28.11999937146902, \"match_probability\": 0.9999999965720324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41235.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262726.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13565885097101274, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8643411490289873, \"precision\": 0.9997575463692568, \"recall\": 0.13565885097101274, \"specificity\": 0.9999999921797885, \"npv\": 0.9997945849134878, \"accuracy\": 0.9997945837191133, \"f1\": 0.2389008302289068, \"f2\": 0.16400986724090338, \"f0_5\": 0.4396608528578222, \"p4\": 0.3856581444077727, \"phi\": 0.3682364536527242}, {\"truth_threshold\": 28.139999371021986, \"match_probability\": 0.9999999966192262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41171.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13544829764344768, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8645517023565523, \"precision\": 0.9997571695684904, \"recall\": 0.13544829764344768, \"specificity\": 0.9999999921797885, \"npv\": 0.9997945348846959, \"accuracy\": 0.9997945336816538, \"f1\": 0.2385742679824536, \"f2\": 0.16376364829657325, \"f0_5\": 0.4392182382623724, \"p4\": 0.3852325243650218, \"phi\": 0.367950497972329}, {\"truth_threshold\": 28.15999937057495, \"match_probability\": 0.9999999966657703, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41077.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1351390474435865, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8648609525564135, \"precision\": 0.999756614014165, \"recall\": 0.1351390474435865, \"specificity\": 0.9999999921797885, \"npv\": 0.9997944614049169, \"accuracy\": 0.9997944601891351, \"f1\": 0.23809441005309406, \"f2\": 0.16340196876359958, \"f0_5\": 0.43856727075499297, \"p4\": 0.38460670130186775, \"phi\": 0.36753009725279157}, {\"truth_threshold\": 28.179999370127916, \"match_probability\": 0.9999999967116737, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 41008.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 262953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13491204463730544, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8650879553626946, \"precision\": 0.9997562045931054, \"recall\": 0.13491204463730544, \"specificity\": 0.9999999921797885, \"npv\": 0.9997944074676391, \"accuracy\": 0.9997944062424989, \"f1\": 0.23774200748451355, \"f2\": 0.1631364461651319, \"f0_5\": 0.4380887672450447, \"p4\": 0.38414679444206523, \"phi\": 0.3672211989726191}, {\"truth_threshold\": 28.19999936968088, \"match_probability\": 0.9999999967569451, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40946.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263015.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1347080711012268, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8652919288987732, \"precision\": 0.9997558355308136, \"recall\": 0.1347080711012268, \"specificity\": 0.9999999921797885, \"npv\": 0.9997943590022642, \"accuracy\": 0.99979435776871, \"f1\": 0.23742523563639947, \"f2\": 0.16289783577339276, \"f0_5\": 0.4376583259403358, \"p4\": 0.3837331642764092, \"phi\": 0.36694341642508455}, {\"truth_threshold\": 28.219999369233847, \"match_probability\": 0.9999999968015931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40874.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1344711986077161, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8655288013922838, \"precision\": 0.9997554055376187, \"recall\": 0.1344711986077161, \"specificity\": 0.9999999921797885, \"npv\": 0.9997943027198991, \"accuracy\": 0.999794301476568, \"f1\": 0.2370572286099552, \"f2\": 0.16262071028894082, \"f0_5\": 0.4371578855051476, \"p4\": 0.38325236690447717, \"phi\": 0.36662056614528765}, {\"truth_threshold\": 28.239999368786812, \"match_probability\": 0.9999999968456266, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40806.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13424748569717826, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8657525143028217, \"precision\": 0.9997549980399844, \"recall\": 0.13424748569717826, \"specificity\": 0.9999999921797885, \"npv\": 0.9997942495643379, \"accuracy\": 0.9997942483117672, \"f1\": 0.23670952528735967, \"f2\": 0.16235895150637403, \"f0_5\": 0.4366846808282947, \"p4\": 0.3827978332048545, \"phi\": 0.3663153907559714}, {\"truth_threshold\": 28.259999368339777, \"match_probability\": 0.9999999968890537, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40707.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13392178601860108, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.866078213981399, \"precision\": 0.9997544023380898, \"recall\": 0.13392178601860108, \"specificity\": 0.9999999921797885, \"npv\": 0.9997941721761044, \"accuracy\": 0.9997941709100719, \"f1\": 0.2362030648895491, \"f2\": 0.16197781086632485, \"f0_5\": 0.4359947646782869, \"p4\": 0.3821353075101571, \"phi\": 0.36587063628365474}, {\"truth_threshold\": 28.279999367892742, \"match_probability\": 0.999999996931883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40632.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13367504383786077, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8663249561621392, \"precision\": 0.9997539491166774, \"recall\": 0.13367504383786077, \"specificity\": 0.9999999921797885, \"npv\": 0.9997941135486629, \"accuracy\": 0.999794112272424, \"f1\": 0.23581918903782034, \"f2\": 0.16168902797166065, \"f0_5\": 0.435471321182606, \"p4\": 0.3816327788779167, \"phi\": 0.36553334085711103}, {\"truth_threshold\": 28.299999367445707, \"match_probability\": 0.9999999969741227, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40562.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1334447511358365, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8665552488641635, \"precision\": 0.9997535245982451, \"recall\": 0.1334447511358365, \"specificity\": 0.9999999921797885, \"npv\": 0.9997940588297236, \"accuracy\": 0.9997940575439526, \"f1\": 0.23546075412224662, \"f2\": 0.16141946616407304, \"f0_5\": 0.4349821661815897, \"p4\": 0.3811632728215207, \"phi\": 0.3652182507793095}, {\"truth_threshold\": 28.319999366998672, \"match_probability\": 0.9999999970157809, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40506.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1332605169742171, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.866739483025783, \"precision\": 0.9997531839273374, \"recall\": 0.1332605169742171, \"specificity\": 0.9999999921797885, \"npv\": 0.9997940150545765, \"accuracy\": 0.9997940137611755, \"f1\": 0.23517390130545726, \"f2\": 0.16120379509057914, \"f0_5\": 0.4345904189689394, \"p4\": 0.3807873342850736, \"phi\": 0.3649659828803089}, {\"truth_threshold\": 28.339999366551638, \"match_probability\": 0.9999999970568655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40437.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263524.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13303351416793602, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8669664858320639, \"precision\": 0.9997527628748732, \"recall\": 0.13303351416793602, \"specificity\": 0.9999999921797885, \"npv\": 0.999793961117347, \"accuracy\": 0.9997939598145393, \"f1\": 0.23482032937678568, \"f2\": 0.1609380310771947, \"f0_5\": 0.43410721225381055, \"p4\": 0.3803237158492928, \"phi\": 0.3646549128300156}, {\"truth_threshold\": 28.359999366104603, \"match_probability\": 0.9999999970973845, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40316.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263645.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13263543678300835, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8673645632169916, \"precision\": 0.9997520210286168, \"recall\": 0.13263543678300835, \"specificity\": 0.9999999921797885, \"npv\": 0.9997938665317846, \"accuracy\": 0.9997938652124674, \"f1\": 0.23419995526987658, \"f2\": 0.16047191064903635, \"f0_5\": 0.4332584656056226, \"p4\": 0.3795096131832498, \"phi\": 0.3641087716116893}, {\"truth_threshold\": 28.379999365657568, \"match_probability\": 0.9999999971373457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40229.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263732.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1323492158533496, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8676507841466504, \"precision\": 0.9997514848778548, \"recall\": 0.1323492158533496, \"specificity\": 0.9999999921797885, \"npv\": 0.9997937985239945, \"accuracy\": 0.9997937971927958, \"f1\": 0.23375363160952933, \"f2\": 0.160136710710996, \"f0_5\": 0.43264711765756036, \"p4\": 0.3789234064990302, \"phi\": 0.36371558483448757}, {\"truth_threshold\": 28.399999365210533, \"match_probability\": 0.9999999971767567, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40156.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263805.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1321090534640957, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8678909465359043, \"precision\": 0.9997510332121695, \"recall\": 0.1321090534640957, \"specificity\": 0.9999999921797885, \"npv\": 0.999793741459994, \"accuracy\": 0.9997937401188185, \"f1\": 0.2333789560249559, \"f2\": 0.159855415163892, \"f0_5\": 0.4321334409470003, \"p4\": 0.37843097564832107, \"phi\": 0.36338534128425}, {\"truth_threshold\": 28.4199993647635, \"match_probability\": 0.999999997215625, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40119.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13198732732159718, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8680126726784029, \"precision\": 0.9997508036582023, \"recall\": 0.13198732732159718, \"specificity\": 0.9999999921797885, \"npv\": 0.9997937125371469, \"accuracy\": 0.9997937111909122, \"f1\": 0.23318899125228865, \"f2\": 0.15971282822162577, \"f0_5\": 0.4318728376216691, \"p4\": 0.37818119329938993, \"phi\": 0.3632178429192783}, {\"truth_threshold\": 28.439999364316463, \"match_probability\": 0.9999999972539584, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40060.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13179322347274816, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8682067765272519, \"precision\": 0.9997504367357125, \"recall\": 0.13179322347274816, \"specificity\": 0.9999999921797885, \"npv\": 0.9997936664169347, \"accuracy\": 0.9997936650626291, \"f1\": 0.2328859899253265, \"f2\": 0.15948544247456434, \"f0_5\": 0.4314569372373401, \"p4\": 0.3777826212612494, \"phi\": 0.36295059104651994}, {\"truth_threshold\": 28.45999936386943, \"match_probability\": 0.9999999972917639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39996.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 263965.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1315826701451831, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8684173298548169, \"precision\": 0.9997500374943759, \"recall\": 0.1315826701451831, \"specificity\": 0.9999999921797885, \"npv\": 0.9997936163882347, \"accuracy\": 0.9997936150251695, \"f1\": 0.2325571929865365, \"f2\": 0.15923876259107378, \"f0_5\": 0.43100531267174585, \"p4\": 0.37734989561992927, \"phi\": 0.36266046805228697}, {\"truth_threshold\": 28.479999363422394, \"match_probability\": 0.9999999973290491, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39945.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1314148854622797, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8685851145377202, \"precision\": 0.9997497184332373, \"recall\": 0.1314148854622797, \"specificity\": 0.9999999921797885, \"npv\": 0.999793576521618, \"accuracy\": 0.999793575151569, \"f1\": 0.23229509531397202, \"f2\": 0.15904217155770947, \"f0_5\": 0.43064506739172154, \"p4\": 0.37700478665963705, \"phi\": 0.36242911004007666}, {\"truth_threshold\": 28.49999936297536, \"match_probability\": 0.9999999973658208, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39869.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264092.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1311648533857962, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8688351466142038, \"precision\": 0.9997492414554026, \"recall\": 0.1311648533857962, \"specificity\": 0.9999999921797885, \"npv\": 0.999793517112548, \"accuracy\": 0.9997935157320857, \"f1\": 0.23190437412750117, \"f2\": 0.15874918274173525, \"f0_5\": 0.4301076428819553, \"p4\": 0.3764900440444002, \"phi\": 0.3620840669841242}, {\"truth_threshold\": 28.519999362528324, \"match_probability\": 0.9999999974020863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39805.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13095430005823117, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8690456999417688, \"precision\": 0.999748838377496, \"recall\": 0.13095430005823117, \"specificity\": 0.9999999921797885, \"npv\": 0.999793467083863, \"accuracy\": 0.9997934656946261, \"f1\": 0.23157521176580098, \"f2\": 0.1585024278088239, \"f0_5\": 0.4296545277524119, \"p4\": 0.37605614656754754, \"phi\": 0.36179324920961514}, {\"truth_threshold\": 28.53999936208129, \"match_probability\": 0.9999999974378526, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39737.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264224.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13073058714769328, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8692694128523067, \"precision\": 0.9997484086849322, \"recall\": 0.13073058714769328, \"specificity\": 0.9999999921797885, \"npv\": 0.9997934139283907, \"accuracy\": 0.9997934125298253, \"f1\": 0.23122534244184018, \"f2\": 0.1582402231299842, \"f0_5\": 0.42917254384392234, \"p4\": 0.3755946990838734, \"phi\": 0.36148399899896916}, {\"truth_threshold\": 28.559999361634254, \"match_probability\": 0.9999999974731264, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39676.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264285.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13052990350735785, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8694700964926422, \"precision\": 0.999748021972484, \"recall\": 0.13052990350735785, \"specificity\": 0.9999999921797885, \"npv\": 0.99979336624481, \"accuracy\": 0.9997933648378717, \"f1\": 0.23091137126178898, \"f2\": 0.15800498594219176, \"f0_5\": 0.4287396937573616, \"p4\": 0.37518037482066746, \"phi\": 0.36120635810986057}, {\"truth_threshold\": 28.57999936118722, \"match_probability\": 0.9999999975079147, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39602.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264359.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13028645122236077, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8697135487776393, \"precision\": 0.9997475512470968, \"recall\": 0.13028645122236077, \"specificity\": 0.9999999921797885, \"npv\": 0.9997933083991608, \"accuracy\": 0.999793306982059, \"f1\": 0.23053033853067617, \"f2\": 0.15771958555297835, \"f0_5\": 0.4282139837243652, \"p4\": 0.3746772704435516, \"phi\": 0.3608692611437524}, {\"truth_threshold\": 28.599999360740185, \"match_probability\": 0.9999999975422239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39531.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.13005286862459328, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8699471313754067, \"precision\": 0.9997470979489643, \"recall\": 0.13005286862459328, \"specificity\": 0.9999999921797885, \"npv\": 0.9997932528986119, \"accuracy\": 0.9997932514717524, \"f1\": 0.23016459875051673, \"f2\": 0.1574457238217758, \"f0_5\": 0.4277089532053016, \"p4\": 0.37419406526317933, \"phi\": 0.36054553404132295}, {\"truth_threshold\": 28.61999936029315, \"match_probability\": 0.9999999975760608, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39467.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264494.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12984231529702825, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8701576847029717, \"precision\": 0.9997466879448793, \"recall\": 0.12984231529702825, \"specificity\": 0.9999999921797885, \"npv\": 0.9997932028699533, \"accuracy\": 0.9997932014342928, \"f1\": 0.22983478822960768, \"f2\": 0.15719883599493675, \"f0_5\": 0.42725318217936253, \"p4\": 0.37375808236914076, \"phi\": 0.3602534744294957}, {\"truth_threshold\": 28.639999359846115, \"match_probability\": 0.9999999976094319, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39393.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264568.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12959886301203116, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8704011369879688, \"precision\": 0.9997462122173438, \"recall\": 0.12959886301203116, \"specificity\": 0.9999999921797885, \"npv\": 0.999793145024323, \"accuracy\": 0.9997931435784801, \"f1\": 0.2294532915506576, \"f2\": 0.15691334056165837, \"f0_5\": 0.42672556670342504, \"p4\": 0.3732534827625235, \"phi\": 0.359915485104055}, {\"truth_threshold\": 28.65999935939908, \"match_probability\": 0.9999999976423436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39280.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264681.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1292271047930491, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8707728952069509, \"precision\": 0.9997454823110206, \"recall\": 0.1292271047930491, \"specificity\": 0.9999999921797885, \"npv\": 0.9997930566924952, \"accuracy\": 0.9997930552310906, \"f1\": 0.22887041844015021, \"f2\": 0.15647731636622067, \"f0_5\": 0.4259185766859458, \"p4\": 0.37248192070084213, \"phi\": 0.35939875306947816}, {\"truth_threshold\": 28.679999358952045, \"match_probability\": 0.9999999976748021, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39221.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1290330009442001, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8709669990557999, \"precision\": 0.9997450995386301, \"recall\": 0.1290330009442001, \"specificity\": 0.9999999921797885, \"npv\": 0.9997930105723435, \"accuracy\": 0.9997930091028077, \"f1\": 0.22856593393785402, \"f2\": 0.15624962651634364, \"f0_5\": 0.4254965989346583, \"p4\": 0.37207857668727096, \"phi\": 0.3591286595206707}, {\"truth_threshold\": 28.69999935850501, \"match_probability\": 0.9999999977068138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39147.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.128789548659203, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.871210451340797, \"precision\": 0.9997446178205684, \"recall\": 0.128789548659203, \"specificity\": 0.9999999921797885, \"npv\": 0.9997929527267355, \"accuracy\": 0.999792951246995, \"f1\": 0.22818389009028964, \"f2\": 0.15596401915217598, \"f0_5\": 0.4249667273860209, \"p4\": 0.3715722085890064, \"phi\": 0.3587896107220892}, {\"truth_threshold\": 28.719999358057976, \"match_probability\": 0.9999999977383848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39056.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12849016814657144, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8715098318534286, \"precision\": 0.999744022935545, \"recall\": 0.12849016814657144, \"specificity\": 0.9999999921797885, \"npv\": 0.9997928815922809, \"accuracy\": 0.9997928800999821, \"f1\": 0.22771385342844733, \"f2\": 0.15561275310580042, \"f0_5\": 0.4243141941441686, \"p4\": 0.37094878075900567, \"phi\": 0.3583722326225818}, {\"truth_threshold\": 28.73999935761094, \"match_probability\": 0.9999999977695211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38999.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 264962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1283026440892088, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8716973559107912, \"precision\": 0.9997436489015356, \"recall\": 0.1283026440892088, \"specificity\": 0.9999999921797885, \"npv\": 0.9997928370355397, \"accuracy\": 0.9997928355353697, \"f1\": 0.22741930781117883, \"f2\": 0.15539270336844235, \"f0_5\": 0.42390493851046857, \"p4\": 0.37055787013410346, \"phi\": 0.3581105502394146}, {\"truth_threshold\": 28.759999357163906, \"match_probability\": 0.9999999978002287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38932.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265029.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12808222107441417, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8719177789255859, \"precision\": 0.9997432078475682, \"recall\": 0.12808222107441417, \"specificity\": 0.9999999921797885, \"npv\": 0.9997927846618314, \"accuracy\": 0.9997927831524043, \"f1\": 0.2270729623246224, \"f2\": 0.15513402285329927, \"f0_5\": 0.4234233646343824, \"p4\": 0.37009797245113246, \"phi\": 0.35780271400289854}, {\"truth_threshold\": 28.77999935671687, \"match_probability\": 0.9999999978305136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38854.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265107.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12782560920644426, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8721743907935557, \"precision\": 0.9997426924660354, \"recall\": 0.12782560920644426, \"specificity\": 0.9999999921797885, \"npv\": 0.9997927236894615, \"accuracy\": 0.9997927221692504, \"f1\": 0.22666958360679648, \"f2\": 0.15483283760046163, \"f0_5\": 0.4228620186018367, \"p4\": 0.36956201534217725, \"phi\": 0.35744400355428374}, {\"truth_threshold\": 28.799999356269836, \"match_probability\": 0.9999999978603816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38776.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265185.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12756899733847435, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8724310026615256, \"precision\": 0.9997421750116021, \"recall\": 0.12756899733847435, \"specificity\": 0.9999999921797885, \"npv\": 0.9997926627170991, \"accuracy\": 0.9997926611860966, \"f1\": 0.2262660212926736, \"f2\": 0.15453161489841627, \"f0_5\": 0.42229990960673486, \"p4\": 0.3690254614333126, \"phi\": 0.3570849328064}, {\"truth_threshold\": 28.8199993558228, \"match_probability\": 0.9999999978898384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38718.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265243.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12737818338536852, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8726218166146315, \"precision\": 0.9997417888865937, \"recall\": 0.12737818338536852, \"specificity\": 0.9999999921797885, \"npv\": 0.9997926173786805, \"accuracy\": 0.9997926158396488, \"f1\": 0.22596581740295135, \"f2\": 0.15430760450575973, \"f0_5\": 0.4218814356041868, \"p4\": 0.368626097978403, \"phi\": 0.3568176972694503}, {\"truth_threshold\": 28.839999355375767, \"match_probability\": 0.9999999979188896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38636.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265325.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1271084119344258, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.8728915880655742, \"precision\": 0.999741241008125, \"recall\": 0.1271084119344258, \"specificity\": 0.9999999921797885, \"npv\": 0.9997925532795442, \"accuracy\": 0.9997925517291537, \"f1\": 0.22554121778013875, \"f2\": 0.1539908648135896, \"f0_5\": 0.421289077407888, \"p4\": 0.3680609158853846, \"phi\": 0.35643953968398484}, {\"truth_threshold\": 28.859999354928732, \"match_probability\": 0.9999999979475409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38519.0, \"tn\": 1278737782.0, \"fp\": 10.0, \"fn\": 265442.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12672349413247094, \"tn_rate\": 0.9999999921797885, \"fp_rate\": 7.820211510570574e-09, \"fn_rate\": 0.873276505867529, \"precision\": 0.9997404552415063, \"recall\": 0.12672349413247094, \"specificity\": 0.9999999921797885, \"npv\": 0.9997924618210344, \"accuracy\": 0.999792460254423, \"f1\": 0.22493503459955036, \"f2\": 0.1535388596533886, \"f0_5\": 0.4204424147032049, \"p4\": 0.3672533499474527, \"phi\": 0.3558992777936303}, {\"truth_threshold\": 28.879999354481697, \"match_probability\": 0.9999999979757976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38444.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265517.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12647675195173064, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8735232480482693, \"precision\": 0.9998439531859558, \"recall\": 0.12647675195173064, \"specificity\": 0.9999999953078731, \"npv\": 0.9997924031944427, \"accuracy\": 0.9997924047441162, \"f1\": 0.2245488608718762, \"f2\": 0.15324955712137664, \"f0_5\": 0.4199134482841483, \"p4\": 0.36673846691938244, \"phi\": 0.35557102637508986}, {\"truth_threshold\": 28.899999354034662, \"match_probability\": 0.9999999980036655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38382.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12627277841565201, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.873727221584348, \"precision\": 0.9998437011566115, \"recall\": 0.12627277841565201, \"specificity\": 0.9999999953078731, \"npv\": 0.9997923547292622, \"accuracy\": 0.9997923562703274, \"f1\": 0.2242273235791546, \"f2\": 0.15300996944743875, \"f0_5\": 0.41946349065491034, \"p4\": 0.3663095153316284, \"phi\": 0.355284136277929}, {\"truth_threshold\": 28.919999353587627, \"match_probability\": 0.9999999980311496, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38279.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12593391915410201, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.874066080845898, \"precision\": 0.9998432806582213, \"recall\": 0.12593391915410201, \"specificity\": 0.9999999953078731, \"npv\": 0.9997922742145372, \"accuracy\": 0.9997922757412908, \"f1\": 0.2236928992595969, \"f2\": 0.15261189239703413, \"f0_5\": 0.4187149010831304, \"p4\": 0.36559605992385297, \"phi\": 0.3548070157994272}, {\"truth_threshold\": 28.939999353140593, \"match_probability\": 0.9999999980582553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38184.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265777.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12562137905849763, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8743786209415023, \"precision\": 0.9998428908091124, \"recall\": 0.12562137905849763, \"specificity\": 0.9999999953078731, \"npv\": 0.9997921999533945, \"accuracy\": 0.9997922014669368, \"f1\": 0.22319969837878598, \"f2\": 0.15224467598167196, \"f0_5\": 0.41802325708693056, \"p4\": 0.3649370845516934, \"phi\": 0.354366383798517}, {\"truth_threshold\": 28.959999352693558, \"match_probability\": 0.999999998084988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38086.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12529896927566364, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8747010307243364, \"precision\": 0.999842486611362, \"recall\": 0.12529896927566364, \"specificity\": 0.9999999953078731, \"npv\": 0.9997921233471747, \"accuracy\": 0.9997921248470768, \"f1\": 0.22269063566172495, \"f2\": 0.15186580495336285, \"f0_5\": 0.4173085646540106, \"p4\": 0.3642563582961765, \"phi\": 0.35391126230973813}, {\"truth_threshold\": 28.979999352246523, \"match_probability\": 0.9999999981113524, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38040.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12514763407147628, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8748523659285238, \"precision\": 0.9998422961677969, \"recall\": 0.12514763407147628, \"specificity\": 0.9999999953078731, \"npv\": 0.9997920873891571, \"accuracy\": 0.9997920888826528, \"f1\": 0.2224515872482142, \"f2\": 0.15168794710859804, \"f0_5\": 0.4169726731631389, \"p4\": 0.36393650356078866, \"phi\": 0.3536974319220314}, {\"truth_threshold\": 28.999999351799488, \"match_probability\": 0.999999998137354, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37995.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 265966.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1249995887630321, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8750004112369679, \"precision\": 0.9998421094181732, \"recall\": 0.1249995887630321, \"specificity\": 0.9999999953078731, \"npv\": 0.9997920522128382, \"accuracy\": 0.999792053700064, \"f1\": 0.2222176733087302, \"f2\": 0.1515139431109906, \"f0_5\": 0.41664382134593664, \"p4\": 0.36362339780122616, \"phi\": 0.3534881248740111}, {\"truth_threshold\": 29.019999351352453, \"match_probability\": 0.9999999981629976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37919.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266042.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12474955668654861, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8752504433134514, \"precision\": 0.9998417930125247, \"recall\": 0.12474955668654861, \"specificity\": 0.9999999953078731, \"npv\": 0.9997919928039496, \"accuracy\": 0.9997919942805807, \"f1\": 0.22182247883797523, \"f2\": 0.15122004133137762, \"f0_5\": 0.41608783722987047, \"p4\": 0.3630941374252815, \"phi\": 0.35313434686970463}, {\"truth_threshold\": 29.03999935090542, \"match_probability\": 0.9999999981882882, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37868.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266093.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1245817720036452, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8754182279963548, \"precision\": 0.9998415799757089, \"recall\": 0.1245817720036452, \"specificity\": 0.9999999953078731, \"npv\": 0.9997919529374625, \"accuracy\": 0.9997919544069802, \"f1\": 0.22155718402153085, \"f2\": 0.15102279779025268, \"f0_5\": 0.4157143264896576, \"p4\": 0.3627386517920589, \"phi\": 0.35289674438025026}, {\"truth_threshold\": 29.059999350458384, \"match_probability\": 0.9999999982132305, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37782.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12429884096972967, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8757011590302703, \"precision\": 0.9998412194347411, \"recall\": 0.12429884096972967, \"specificity\": 0.9999999953078731, \"npv\": 0.9997918857116287, \"accuracy\": 0.9997918871691439, \"f1\": 0.2211096447977902, \"f2\": 0.1506901546865428, \"f0_5\": 0.4150837264591431, \"p4\": 0.3621386150360634, \"phi\": 0.35249571866089424}, {\"truth_threshold\": 29.07999935001135, \"match_probability\": 0.9999999982378295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37731.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266230.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12413105628682627, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8758689437131737, \"precision\": 0.9998410048493521, \"recall\": 0.12413105628682627, \"specificity\": 0.9999999953078731, \"npv\": 0.9997918458451502, \"accuracy\": 0.9997918472955433, \"f1\": 0.2208441372205866, \"f2\": 0.1504928680316629, \"f0_5\": 0.41470931548947154, \"p4\": 0.36178242869459426, \"phi\": 0.3522576854595449}, {\"truth_threshold\": 29.099999349564314, \"match_probability\": 0.9999999982620899, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37679.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266282.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12395998170817966, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8760400182918203, \"precision\": 0.9998407854584052, \"recall\": 0.12395998170817966, \"specificity\": 0.9999999953078731, \"npv\": 0.9997918051969793, \"accuracy\": 0.9997918066401074, \"f1\": 0.22057334199727202, \"f2\": 0.15029169648249063, \"f0_5\": 0.4143272172262652, \"p4\": 0.36141898919059345, \"phi\": 0.3520148192365468}, {\"truth_threshold\": 29.11999934911728, \"match_probability\": 0.9999999982860162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37604.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266357.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12371323952743937, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8762867604725606, \"precision\": 0.9998404679606487, \"recall\": 0.12371323952743937, \"specificity\": 0.9999999953078731, \"npv\": 0.9997917465698154, \"accuracy\": 0.9997917480024595, \"f1\": 0.22018262674524477, \"f2\": 0.15000151581150964, \"f0_5\": 0.41377549785321777, \"p4\": 0.36089431839358915, \"phi\": 0.3516642360336785}, {\"truth_threshold\": 29.139999348670244, \"match_probability\": 0.9999999983096131, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37546.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12352242557433354, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8764775744256664, \"precision\": 0.9998402215594375, \"recall\": 0.12352242557433354, \"specificity\": 0.9999999953078731, \"npv\": 0.9997917012314802, \"accuracy\": 0.9997917026560117, \"f1\": 0.2198803559454545, \"f2\": 0.14977708561380443, \"f0_5\": 0.41334833509112245, \"p4\": 0.3604881843672675, \"phi\": 0.3513928785480281}, {\"truth_threshold\": 29.15999934822321, \"match_probability\": 0.9999999983328851, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37510.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266451.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1234039893275782, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8765960106724218, \"precision\": 0.999840068237552, \"recall\": 0.1234039893275782, \"specificity\": 0.9999999953078731, \"npv\": 0.9997916730904466, \"accuracy\": 0.9997916745099408, \"f1\": 0.21969268794091548, \"f2\": 0.14963777366439013, \"f0_5\": 0.41308298001211385, \"p4\": 0.36023593049442487, \"phi\": 0.35122434432702665}, {\"truth_threshold\": 29.179999347776175, \"match_probability\": 0.9999999983558368, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37436.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266525.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12316053704258112, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8768394629574189, \"precision\": 0.999839752149992, \"recall\": 0.12316053704258112, \"specificity\": 0.9999999953078731, \"npv\": 0.9997916152449935, \"accuracy\": 0.9997916166541281, \"f1\": 0.2193068016391186, \"f2\": 0.14935138507890458, \"f0_5\": 0.4125369989575275, \"p4\": 0.3597169975776734, \"phi\": 0.35087765868259396}, {\"truth_threshold\": 29.19999934732914, \"match_probability\": 0.9999999983784725, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37379.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266582.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1229730129852185, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8770269870147815, \"precision\": 0.9998395078239936, \"recall\": 0.1229730129852185, \"specificity\": 0.9999999953078731, \"npv\": 0.9997915706883653, \"accuracy\": 0.9997915720895156, \"f1\": 0.21900945082116094, \"f2\": 0.14913076540680115, \"f0_5\": 0.4121159600530098, \"p4\": 0.3593169014448192, \"phi\": 0.35061038334301}, {\"truth_threshold\": 29.219999346882105, \"match_probability\": 0.9999999984007966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37315.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266646.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12276245965765345, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8772375403423466, \"precision\": 0.999839232603628, \"recall\": 0.12276245965765345, \"specificity\": 0.9999999953078731, \"npv\": 0.9997915206598752, \"accuracy\": 0.9997915220520561, \"f1\": 0.2186754648648332, \"f2\": 0.1488830281726668, \"f0_5\": 0.41164270979271694, \"p4\": 0.35886727860833795, \"phi\": 0.35031004171971175}, {\"truth_threshold\": 29.23999934643507, \"match_probability\": 0.9999999984228133, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37236.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12250255789394034, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8774974421060596, \"precision\": 0.9998388915740293, \"recall\": 0.12250255789394034, \"specificity\": 0.9999999953078731, \"npv\": 0.9997914589059648, \"accuracy\": 0.999791460287067, \"f1\": 0.2182630281679821, \"f2\": 0.14857719262684285, \"f0_5\": 0.4110578037617375, \"p4\": 0.3583117026091074, \"phi\": 0.3499389520928227}, {\"truth_threshold\": 29.259999345988035, \"match_probability\": 0.9999999984445268, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37145.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266816.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12220317738130879, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8777968226186912, \"precision\": 0.9998384969449006, \"recall\": 0.12220317738130879, \"specificity\": 0.9999999953078731, \"npv\": 0.9997913877717228, \"accuracy\": 0.9997913891400542, \"f1\": 0.21778770609066816, \"f2\": 0.14822485325160914, \"f0_5\": 0.41038303890048944, \"p4\": 0.35767094959220985, \"phi\": 0.3495110061604534}, {\"truth_threshold\": 29.279999345541, \"match_probability\": 0.9999999984659415, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37089.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266872.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12201894321968937, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8779810567803107, \"precision\": 0.9998382531338456, \"recall\": 0.12201894321968937, \"specificity\": 0.9999999953078731, \"npv\": 0.9997913439968097, \"accuracy\": 0.999791345357277, \"f1\": 0.2174950741227247, \"f2\": 0.14800800358197805, \"f0_5\": 0.4099672592137348, \"p4\": 0.35727622125448333, \"phi\": 0.3492473942102038}, {\"truth_threshold\": 29.299999345093966, \"match_probability\": 0.9999999984870613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37044.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1218708979112452, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8781291020887548, \"precision\": 0.9998380566801619, \"recall\": 0.1218708979112452, \"specificity\": 0.9999999953078731, \"npv\": 0.9997913088205431, \"accuracy\": 0.9997913101746883, \"f1\": 0.21725985378770774, \"f2\": 0.1478337353359502, \"f0_5\": 0.4096328520151008, \"p4\": 0.3569587973002979, \"phi\": 0.34903541892139167}, {\"truth_threshold\": 29.31999934464693, \"match_probability\": 0.9999999985078905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36997.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 266964.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12171627281131461, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8782837271886854, \"precision\": 0.9998378509850553, \"recall\": 0.12171627281131461, \"specificity\": 0.9999999953078731, \"npv\": 0.9997912720808895, \"accuracy\": 0.9997912734284289, \"f1\": 0.21701411292687792, \"f2\": 0.14765170846879147, \"f0_5\": 0.4092832978961133, \"p4\": 0.3566270450977556, \"phi\": 0.3488138849914708}, {\"truth_threshold\": 29.339999344199896, \"match_probability\": 0.9999999985284327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36932.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267029.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12150242958800636, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8784975704119936, \"precision\": 0.9998375656505496, \"recall\": 0.12150242958800636, \"specificity\": 0.9999999953078731, \"npv\": 0.9997912212707346, \"accuracy\": 0.999791222609134, \"f1\": 0.21667414688808123, \"f2\": 0.14739994667867196, \"f0_5\": 0.40879939253464037, \"p4\": 0.3561678671702414, \"phi\": 0.3485072762607151}, {\"truth_threshold\": 29.35999934375286, \"match_probability\": 0.9999999985486923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36845.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12121620865834762, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8787837913416524, \"precision\": 0.9998371821660199, \"recall\": 0.12121620865834762, \"specificity\": 0.9999999953078731, \"npv\": 0.9997911532633047, \"accuracy\": 0.9997911545894624, \"f1\": 0.21621891247960753, \"f2\": 0.14706293231792256, \"f0_5\": 0.4081508313670754, \"p4\": 0.3555525990337664, \"phi\": 0.34809646967157637}, {\"truth_threshold\": 29.379999343305826, \"match_probability\": 0.9999999985686728, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36797.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12105829366267383, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8789417063373262, \"precision\": 0.9998369698122436, \"recall\": 0.12105829366267383, \"specificity\": 0.9999999953078731, \"npv\": 0.999791115741968, \"accuracy\": 0.9997911170613677, \"f1\": 0.2159676491648179, \"f2\": 0.14687697332129482, \"f0_5\": 0.4077925762401562, \"p4\": 0.3552128089503222, \"phi\": 0.3478696101186425}, {\"truth_threshold\": 29.39999934285879, \"match_probability\": 0.9999999985883783, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36723.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267238.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12081484137767674, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8791851586223233, \"precision\": 0.9998366413460753, \"recall\": 0.12081484137767674, \"specificity\": 0.9999999953078731, \"npv\": 0.9997910578965794, \"accuracy\": 0.9997910592055551, \"f1\": 0.2155801461739411, \"f2\": 0.14659025861167374, \"f0_5\": 0.4072396684683406, \"p4\": 0.3546885029363053, \"phi\": 0.3475195781971906}, {\"truth_threshold\": 29.419999342411757, \"match_probability\": 0.9999999986078125, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36642.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267319.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12054835982247722, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8794516401775228, \"precision\": 0.9998362802881466, \"recall\": 0.12054835982247722, \"specificity\": 0.9999999953078731, \"npv\": 0.9997909945793375, \"accuracy\": 0.9997909958768953, \"f1\": 0.21515579447401567, \"f2\": 0.14627638340204968, \"f0_5\": 0.40663362578875295, \"p4\": 0.35411395562174136, \"phi\": 0.34713603058269504}, {\"truth_threshold\": 29.43999934196472, \"match_probability\": 0.9999999986269792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36568.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.12030490753748013, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8796950924625199, \"precision\": 0.9998359490348335, \"recall\": 0.12030490753748013, \"specificity\": 0.9999999953078731, \"npv\": 0.999790936733963, \"accuracy\": 0.9997909380210828, \"f1\": 0.2147679386847167, \"f2\": 0.14598959772216624, \"f0_5\": 0.40607919477098636, \"p4\": 0.3535884705023951, \"phi\": 0.34678525829974094}, {\"truth_threshold\": 29.459999341517687, \"match_probability\": 0.999999998645882, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36482.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267479.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1200219765035646, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8799780234964354, \"precision\": 0.9998355623766718, \"recall\": 0.1200219765035646, \"specificity\": 0.9999999953078731, \"npv\": 0.9997908695082659, \"accuracy\": 0.9997908707832465, \"f1\": 0.21431697552349985, \"f2\": 0.14565626367448886, \"f0_5\": 0.405433939450516, \"p4\": 0.35297706249745386, \"phi\": 0.3463771577769845}, {\"truth_threshold\": 29.479999341070652, \"match_probability\": 0.9999999986645245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36396.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267565.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11973904546964907, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8802609545303509, \"precision\": 0.9998351738915444, \"recall\": 0.11973904546964907, \"specificity\": 0.9999999953078731, \"npv\": 0.9997908022825778, \"accuracy\": 0.9997908035454102, \"f1\": 0.21386578447128507, \"f2\": 0.14532288384231212, \"f0_5\": 0.40478769666057934, \"p4\": 0.3523648908671678, \"phi\": 0.3459685759189462}, {\"truth_threshold\": 29.499999340623617, \"match_probability\": 0.9999999986829103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36332.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11952849214208401, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.880471507857916, \"precision\": 0.999834883592933, \"recall\": 0.11952849214208401, \"specificity\": 0.9999999953078731, \"npv\": 0.9997907522541646, \"accuracy\": 0.9997907535079505, \"f1\": 0.21352986638221094, \"f2\": 0.14507475750330223, \"f0_5\": 0.40430612958004775, \"p4\": 0.3519088248396737, \"phi\": 0.34566420160179334}, {\"truth_threshold\": 29.519999340176582, \"match_probability\": 0.9999999987010432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36267.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267694.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11931464891877576, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8806853510812243, \"precision\": 0.9998345877098669, \"recall\": 0.11931464891877576, \"specificity\": 0.9999999953078731, \"npv\": 0.9997907014440626, \"accuracy\": 0.9997907026886557, \"f1\": 0.21318857021931964, \"f2\": 0.14482272822747394, \"f0_5\": 0.403816476006173, \"p4\": 0.35144519849167366, \"phi\": 0.345354796890621}, {\"truth_threshold\": 29.539999339729548, \"match_probability\": 0.9999999987189263, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36211.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267750.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11913041475715634, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8808695852428436, \"precision\": 0.9998343319435624, \"recall\": 0.11913041475715634, \"specificity\": 0.9999999953078731, \"npv\": 0.9997906576692096, \"accuracy\": 0.9997906589058786, \"f1\": 0.21289442585940302, \"f2\": 0.14460557432904628, \"f0_5\": 0.4033941657067614, \"p4\": 0.3510454151359537, \"phi\": 0.34508801040288306}, {\"truth_threshold\": 29.559999339282513, \"match_probability\": 0.9999999987365632, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36098.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1187586565381743, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8812413434618257, \"precision\": 0.999833813427875, \"recall\": 0.1187586565381743, \"specificity\": 0.9999999953078731, \"npv\": 0.9997905693378216, \"accuracy\": 0.9997905705584891, \"f1\": 0.212300589593166, \"f2\": 0.14416732963349915, \"f0_5\": 0.4025407190823793, \"p4\": 0.3502377173175855, \"phi\": 0.34454904447653223}, {\"truth_threshold\": 29.579999338835478, \"match_probability\": 0.9999999987539573, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36004.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 267957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11844940633831313, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8815505936616869, \"precision\": 0.9998333796167731, \"recall\": 0.11844940633831313, \"specificity\": 0.9999999953078731, \"npv\": 0.9997904958586257, \"accuracy\": 0.9997904970659703, \"f1\": 0.21180630112568424, \"f2\": 0.1438027118178318, \"f0_5\": 0.40182946020209775, \"p4\": 0.34956481428793884, \"phi\": 0.3441000580082816}, {\"truth_threshold\": 29.599999338388443, \"match_probability\": 0.9999999987711119, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35947.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11826188228095051, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8817381177190495, \"precision\": 0.9998331154562902, \"recall\": 0.11826188228095051, \"specificity\": 0.9999999953078731, \"npv\": 0.9997904513020973, \"accuracy\": 0.9997904525013579, \"f1\": 0.21150643986420095, \"f2\": 0.14358158711037014, \"f0_5\": 0.4013975831503909, \"p4\": 0.34915632847948447, \"phi\": 0.3438275147321454}, {\"truth_threshold\": 29.619999337941408, \"match_probability\": 0.9999999987880304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35883.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268078.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11805132895338546, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8819486710466146, \"precision\": 0.9998328178550531, \"recall\": 0.11805132895338546, \"specificity\": 0.9999999953078731, \"npv\": 0.9997904012737192, \"accuracy\": 0.9997904024638983, \"f1\": 0.21116963366190966, \"f2\": 0.14333328273681367, \"f0_5\": 0.40091214411966475, \"p4\": 0.3486972732557885, \"phi\": 0.34352124356501423}, {\"truth_threshold\": 29.639999337494373, \"match_probability\": 0.9999999988047159, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35806.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268155.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11779800698115876, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8822019930188413, \"precision\": 0.9998324583938345, \"recall\": 0.11779800698115876, \"specificity\": 0.9999999953078731, \"npv\": 0.9997903410833335, \"accuracy\": 0.9997903422625798, \"f1\": 0.2107642455404049, \"f2\": 0.14303450788395533, \"f0_5\": 0.4003273637158465, \"p4\": 0.3481444045285477, \"phi\": 0.34315239882737214}, {\"truth_threshold\": 29.65999933704734, \"match_probability\": 0.9999999988211717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35749.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11761048292379614, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8823895170762038, \"precision\": 0.9998321913019158, \"recall\": 0.11761048292379614, \"specificity\": 0.9999999953078731, \"npv\": 0.999790296526819, \"accuracy\": 0.9997902976979673, \"f1\": 0.21046403466424896, \"f2\": 0.1428133132097421, \"f0_5\": 0.3998939552240476, \"p4\": 0.3477347379601457, \"phi\": 0.34287910237380825}, {\"truth_threshold\": 29.679999336600304, \"match_probability\": 0.9999999988374011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35676.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268285.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11737032053454226, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8826296794654578, \"precision\": 0.9998318479905834, \"recall\": 0.11737032053454226, \"specificity\": 0.9999999953078731, \"npv\": 0.9997902394632183, \"accuracy\": 0.99979024062399, \"f1\": 0.21007940690666377, \"f2\": 0.14252999937676086, \"f0_5\": 0.39933824204312174, \"p4\": 0.347209579393186, \"phi\": 0.3425287727002029}, {\"truth_threshold\": 29.69999933615327, \"match_probability\": 0.9999999988534068, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35586.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268375.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11707422991765391, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8829257700823461, \"precision\": 0.9998314227916386, \"recall\": 0.11707422991765391, \"specificity\": 0.9999999953078731, \"npv\": 0.999790169110843, \"accuracy\": 0.9997901702588124, \"f1\": 0.20960498066575764, \"f2\": 0.14218066285451272, \"f0_5\": 0.39865211536781164, \"p4\": 0.3465613527563146, \"phi\": 0.3420963656496382}, {\"truth_threshold\": 29.719999335706234, \"match_probability\": 0.9999999988691923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35531.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1168932856517777, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8831067143482223, \"precision\": 0.9998311618876101, \"recall\": 0.1168932856517777, \"specificity\": 0.9999999953078731, \"npv\": 0.9997901261177295, \"accuracy\": 0.9997901272578706, \"f1\": 0.20931492969030746, \"f2\": 0.14196715468750126, \"f0_5\": 0.39823227058857813, \"p4\": 0.34616479452341714, \"phi\": 0.3418318476562068}, {\"truth_threshold\": 29.7399993352592, \"match_probability\": 0.9999999988847605, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35457.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268504.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1166498333667806, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8833501666332194, \"precision\": 0.999830809576178, \"recall\": 0.1166498333667806, \"specificity\": 0.9999999953078731, \"npv\": 0.9997900682724555, \"accuracy\": 0.9997900694020581, \"f1\": 0.20892453097011407, \"f2\": 0.14167985953886617, \"f0_5\": 0.397666734707153, \"p4\": 0.34563074022597745, \"phi\": 0.34147562744747983}, {\"truth_threshold\": 29.759999334812164, \"match_probability\": 0.9999999989001144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35395.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268566.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11644585983070196, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.883554140169298, \"precision\": 0.9998305132623372, \"recall\": 0.11644585983070196, \"specificity\": 0.9999999953078731, \"npv\": 0.9997900198075013, \"accuracy\": 0.9997900209282691, \"f1\": 0.20859730906819265, \"f2\": 0.14143912662987665, \"f0_5\": 0.3971923288409099, \"p4\": 0.34518284421151135, \"phi\": 0.34117688636159926}, {\"truth_threshold\": 29.77999933436513, \"match_probability\": 0.9999999989152568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35340.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268621.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11626491556482575, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8837350844351742, \"precision\": 0.9998302495331862, \"recall\": 0.11626491556482575, \"specificity\": 0.9999999953078731, \"npv\": 0.9997899768144007, \"accuracy\": 0.9997899779273273, \"f1\": 0.20830693148093024, \"f2\": 0.14122555327328384, \"f0_5\": 0.39677104267478025, \"p4\": 0.34478517693007044, \"phi\": 0.34091165501174825}, {\"truth_threshold\": 29.799999333918095, \"match_probability\": 0.9999999989301908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35297.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268664.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11612345004786798, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.883876549952132, \"precision\": 0.9998300427725689, \"recall\": 0.11612345004786798, \"specificity\": 0.9999999953078731, \"npv\": 0.9997899432016156, \"accuracy\": 0.9997899443084092, \"f1\": 0.2080798434257687, \"f2\": 0.141058564661067, \"f0_5\": 0.3964413834621597, \"p4\": 0.3444740503945653, \"phi\": 0.3407041485185936}, {\"truth_threshold\": 29.81999933347106, \"match_probability\": 0.9999999989449192, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35245.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268716.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11595237546922138, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8840476245307787, \"precision\": 0.9998297920626366, \"recall\": 0.11595237546922138, \"specificity\": 0.9999999953078731, \"npv\": 0.9997899025535993, \"accuracy\": 0.9997899036529733, \"f1\": 0.20780514840276876, \"f2\": 0.14085660960998164, \"f0_5\": 0.3960423853561516, \"p4\": 0.3440975426165716, \"phi\": 0.3404530414994522}, {\"truth_threshold\": 29.839999333024025, \"match_probability\": 0.9999999989594448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35132.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11558061725023934, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8844193827497606, \"precision\": 0.9998292446923559, \"recall\": 0.11558061725023934, \"specificity\": 0.9999999953078731, \"npv\": 0.9997898142223447, \"accuracy\": 0.9997898153055836, \"f1\": 0.20720792452941472, \"f2\": 0.14041768786441372, \"f0_5\": 0.3951740444036507, \"p4\": 0.34327837288251434, \"phi\": 0.33990672713867404}, {\"truth_threshold\": 29.85999933257699, \"match_probability\": 0.9999999989737705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35058.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11533716496524225, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8846628350347577, \"precision\": 0.9998288843258042, \"recall\": 0.11533716496524225, \"specificity\": 0.9999999953078731, \"npv\": 0.9997897563771068, \"accuracy\": 0.999789757449771, \"f1\": 0.20681660644495245, \"f2\": 0.1401302094158803, \"f0_5\": 0.3946044388215669, \"p4\": 0.3427411898653972, \"phi\": 0.33954848751650385}, {\"truth_threshold\": 29.879999332129955, \"match_probability\": 0.9999999989878988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34980.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 268981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11508055309727235, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8849194469027276, \"precision\": 0.9998285028297033, \"recall\": 0.11508055309727235, \"specificity\": 0.9999999953078731, \"npv\": 0.9997896954051065, \"accuracy\": 0.9997896964666172, \"f1\": 0.20640395106019524, \"f2\": 0.13982715476923324, \"f0_5\": 0.3940032214099864, \"p4\": 0.3421743384787254, \"phi\": 0.33917047402246747}, {\"truth_threshold\": 29.89999933168292, \"match_probability\": 0.9999999990018327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34918.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269043.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11487657956119371, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8851234204388063, \"precision\": 0.9998281983736113, \"recall\": 0.11487657956119371, \"specificity\": 0.9999999953078731, \"npv\": 0.9997896469401885, \"accuracy\": 0.9997896479928283, \"f1\": 0.20607580742729834, \"f2\": 0.13958623821524055, \"f0_5\": 0.39352472743583444, \"p4\": 0.3417233012771875, \"phi\": 0.33886970098792535}, {\"truth_threshold\": 29.919999331235886, \"match_probability\": 0.9999999990155748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34818.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269143.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11454758998687331, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8854524100131267, \"precision\": 0.9998277050310131, \"recall\": 0.11454758998687331, \"specificity\": 0.9999999953078731, \"npv\": 0.9997895687709758, \"accuracy\": 0.9997895698092977, \"f1\": 0.205546290420178, \"f2\": 0.13919761279572196, \"f0_5\": 0.3927518347143982, \"p4\": 0.3409949562301122, \"phi\": 0.33838401991367023}, {\"truth_threshold\": 29.93999933078885, \"match_probability\": 0.9999999990291276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34755.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11434032655505147, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8856596734449486, \"precision\": 0.999827392767757, \"recall\": 0.11434032655505147, \"specificity\": 0.9999999953078731, \"npv\": 0.999789519524378, \"accuracy\": 0.9997895205536734, \"f1\": 0.2052125341725663, \"f2\": 0.13895274687051468, \"f0_5\": 0.39226419566370585, \"p4\": 0.34053554919192147, \"phi\": 0.33807768262798055}, {\"truth_threshold\": 29.959999330341816, \"match_probability\": 0.9999999990424939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34653.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269308.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11400475718924467, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8859952428107554, \"precision\": 0.9998268847918289, \"recall\": 0.11400475718924467, \"specificity\": 0.9999999953078731, \"npv\": 0.9997894397918015, \"accuracy\": 0.9997894408064723, \"f1\": 0.204671903608765, \"f2\": 0.13855624496702526, \"f0_5\": 0.39147350750231025, \"p4\": 0.33979084472214566, \"phi\": 0.3375811186607381}, {\"truth_threshold\": 29.97999932989478, \"match_probability\": 0.9999999990556762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34550.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11366589792769467, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8863341020723053, \"precision\": 0.9998263687926844, \"recall\": 0.11366589792769467, \"specificity\": 0.9999999953078731, \"npv\": 0.999789359277546, \"accuracy\": 0.9997893602774358, \"f1\": 0.20412564213909493, \"f2\": 0.1381557901471529, \"f0_5\": 0.3906735868471341, \"p4\": 0.33903770459000615, \"phi\": 0.3370789442006503}, {\"truth_threshold\": 29.999999329447746, \"match_probability\": 0.999999999068677, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34448.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269513.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11333032856188788, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8866696714381122, \"precision\": 0.9998258547628722, \"recall\": 0.11333032856188788, \"specificity\": 0.9999999953078731, \"npv\": 0.999789279544995, \"accuracy\": 0.9997892805302345, \"f1\": 0.20358435648538037, \"f2\": 0.13775915821668114, \"f0_5\": 0.38987996206230746, \"p4\": 0.33829075033483597, \"phi\": 0.3365809069395131}, {\"truth_threshold\": 30.01999932900071, \"match_probability\": 0.9999999990814988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34401.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1131757034619573, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8868242965380427, \"precision\": 0.999825616880286, \"recall\": 0.1131757034619573, \"specificity\": 0.9999999953078731, \"npv\": 0.9997892428054905, \"accuracy\": 0.9997892437839752, \"f1\": 0.20333483071685265, \"f2\": 0.13757637466396747, \"f0_5\": 0.3895137786493776, \"p4\": 0.3379461876656204, \"phi\": 0.3363511710186895}, {\"truth_threshold\": 30.039999328553677, \"match_probability\": 0.999999999094144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34316.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269645.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11289606232378496, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8871039376762151, \"precision\": 0.9998251850125284, \"recall\": 0.11289606232378496, \"specificity\": 0.9999999953078731, \"npv\": 0.9997891763617126, \"accuracy\": 0.9997891773279742, \"f1\": 0.20288338462175162, \"f2\": 0.1372457737612445, \"f0_5\": 0.3888507396050756, \"p4\": 0.33732243596353534, \"phi\": 0.33593529220839446}, {\"truth_threshold\": 30.05999932810664, \"match_probability\": 0.9999999991066153, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34221.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11258352222818059, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8874164777718194, \"precision\": 0.9998246997984047, \"recall\": 0.11258352222818059, \"specificity\": 0.9999999953078731, \"npv\": 0.9997891021010302, \"accuracy\": 0.9997891030536201, \"f1\": 0.20237855867150817, \"f2\": 0.13687622543039554, \"f0_5\": 0.3881084857406622, \"p4\": 0.3366243758926614, \"phi\": 0.3354698764351672}, {\"truth_threshold\": 30.079999327659607, \"match_probability\": 0.9999999991189148, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34197.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269764.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11250456473034369, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8874954352696564, \"precision\": 0.9998245767915095, \"recall\": 0.11250456473034369, \"specificity\": 0.9999999953078731, \"npv\": 0.9997890833404385, \"accuracy\": 0.9997890842895728, \"f1\": 0.20225097881501283, \"f2\": 0.13678285696457812, \"f0_5\": 0.38792076647163054, \"p4\": 0.3364478690145262, \"phi\": 0.3353521955218668}, {\"truth_threshold\": 30.099999327212572, \"match_probability\": 0.9999999991310449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34119.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1122479528623738, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8877520471376262, \"precision\": 0.9998241758241758, \"recall\": 0.1122479528623738, \"specificity\": 0.9999999953078731, \"npv\": 0.9997890223685202, \"accuracy\": 0.999789023306419, \"f1\": 0.20183621918683411, \"f2\": 0.13647938468874027, \"f0_5\": 0.3873101137217597, \"p4\": 0.33587378963671394, \"phi\": 0.334969447056039}, {\"truth_threshold\": 30.119999326765537, \"match_probability\": 0.9999999991430081, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 34021.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 269940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11192554307953981, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8880744569204602, \"precision\": 0.9998236694389749, \"recall\": 0.11192554307953981, \"specificity\": 0.9999999953078731, \"npv\": 0.9997889457627873, \"accuracy\": 0.999788946686559, \"f1\": 0.20131483958010343, \"f2\": 0.13609804531827685, \"f0_5\": 0.3865416559675869, \"p4\": 0.33515157243955834, \"phi\": 0.33448793720447834}, {\"truth_threshold\": 30.139999326318502, \"match_probability\": 0.9999999991548065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33936.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11164590194136748, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8883540980586325, \"precision\": 0.9998232278592893, \"recall\": 0.11164590194136748, \"specificity\": 0.9999999953078731, \"npv\": 0.999788879319049, \"accuracy\": 0.999788880230558, \"f1\": 0.20086237766459605, \"f2\": 0.13576724335206186, \"f0_5\": 0.3858740269575125, \"p4\": 0.3345243120217073, \"phi\": 0.33406973913709936}, {\"truth_threshold\": 30.159999325871468, \"match_probability\": 0.9999999991664426, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33849.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11135968101170873, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8886403189882912, \"precision\": 0.9998227735932654, \"recall\": 0.11135968101170873, \"specificity\": 0.9999999953078731, \"npv\": 0.9997888113119376, \"accuracy\": 0.9997888122108864, \"f1\": 0.2003990337935444, \"f2\": 0.13542861120957927, \"f0_5\": 0.3851896190322294, \"p4\": 0.3338814755654109, \"phi\": 0.33364115834283337}, {\"truth_threshold\": 30.179999325424433, \"match_probability\": 0.9999999991779184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33783.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11114254789265728, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8888574521073427, \"precision\": 0.9998224274172068, \"recall\": 0.11114254789265728, \"specificity\": 0.9999999953078731, \"npv\": 0.9997887597203421, \"accuracy\": 0.9997887606097563, \"f1\": 0.20004737231680236, \"f2\": 0.13517168640712912, \"f0_5\": 0.3846696893994084, \"p4\": 0.3333932542511467, \"phi\": 0.3333156605234271}, {\"truth_threshold\": 30.199999324977398, \"match_probability\": 0.9999999991892362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33740.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11100108237569951, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8889989176243005, \"precision\": 0.9998222011497659, \"recall\": 0.11100108237569951, \"specificity\": 0.9999999953078731, \"npv\": 0.9997887261076388, \"accuracy\": 0.9997887269908381, \"f1\": 0.1998181855869141, \"f2\": 0.1350042814043006, \"f0_5\": 0.3843306108965816, \"p4\": 0.33307491395481287, \"phi\": 0.3331034226630631}, {\"truth_threshold\": 30.219999324530363, \"match_probability\": 0.9999999992003983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33670.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11077078967367524, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8892292103263247, \"precision\": 0.9998218315714456, \"recall\": 0.11077078967367524, \"specificity\": 0.9999999953078731, \"npv\": 0.9997886713892894, \"accuracy\": 0.9997886722623667, \"f1\": 0.1994449660434135, \"f2\": 0.134731736987003, \"f0_5\": 0.3837780538679858, \"p4\": 0.3325562517504074, \"phi\": 0.33275762964770766}, {\"truth_threshold\": 30.23999932408333, \"match_probability\": 0.9999999992114066, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33614.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270347.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11058655551205582, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8894134444879441, \"precision\": 0.9998215348007139, \"recall\": 0.11058655551205582, \"specificity\": 0.9999999953078731, \"npv\": 0.9997886276146143, \"accuracy\": 0.9997886284795896, \"f1\": 0.19914627896712198, \"f2\": 0.1345136794657549, \"f0_5\": 0.383335500101496, \"p4\": 0.33214093452381793, \"phi\": 0.3324807363232644}, {\"truth_threshold\": 30.259999323636293, \"match_probability\": 0.9999999992222635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33568.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11043522030786844, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8895647796921315, \"precision\": 0.9998212902841485, \"recall\": 0.11043522030786844, \"specificity\": 0.9999999953078731, \"npv\": 0.9997885916568482, \"accuracy\": 0.9997885925151655, \"f1\": 0.19890085472617655, \"f2\": 0.13433454616469429, \"f0_5\": 0.38297163536463763, \"p4\": 0.3317995231093738, \"phi\": 0.3322531156268966}, {\"truth_threshold\": 30.27999932318926, \"match_probability\": 0.9999999992329708, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33491.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270470.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.11018189833564174, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8898181016643583, \"precision\": 0.9998208794817446, \"recall\": 0.11018189833564174, \"specificity\": 0.9999999953078731, \"npv\": 0.9997885314666803, \"accuracy\": 0.999788532313847, \"f1\": 0.19848988614879481, \"f2\": 0.1340346630743728, \"f0_5\": 0.3823618731861472, \"p4\": 0.33122750865795003, \"phi\": 0.3318717490269033}, {\"truth_threshold\": 30.299999322742224, \"match_probability\": 0.9999999992435307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33432.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270529.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10998779448679272, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8900122055132073, \"precision\": 0.9998205634308271, \"recall\": 0.10998779448679272, \"specificity\": 0.9999999953078731, \"npv\": 0.9997884853469463, \"accuracy\": 0.9997884861855639, \"f1\": 0.19817486121772737, \"f2\": 0.13380485751015384, \"f0_5\": 0.3818940721431623, \"p4\": 0.33078876950765684, \"phi\": 0.3315792362826955}, {\"truth_threshold\": 30.31999932229519, \"match_probability\": 0.9999999992539452, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33376.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270585.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1098035603251733, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8901964396748268, \"precision\": 0.9998202624168714, \"recall\": 0.1098035603251733, \"specificity\": 0.9999999953078731, \"npv\": 0.9997884415722874, \"accuracy\": 0.9997884424027869, \"f1\": 0.19787575257230772, \"f2\": 0.13358671689510146, \"f0_5\": 0.381449590732567, \"p4\": 0.3303719835846308, \"phi\": 0.33130135819182965}, {\"truth_threshold\": 30.339999321848154, \"match_probability\": 0.9999999992642163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33293.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270668.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10953049897848738, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8904695010215127, \"precision\": 0.9998198144088412, \"recall\": 0.10953049897848738, \"specificity\": 0.9999999953078731, \"npv\": 0.9997883766919965, \"accuracy\": 0.9997883775104565, \"f1\": 0.19743224811717963, \"f2\": 0.13326336536329308, \"f0_5\": 0.38078996790626707, \"p4\": 0.32975360942785037, \"phi\": 0.3308890739567709}, {\"truth_threshold\": 30.35999932140112, \"match_probability\": 0.9999999992743461, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33221.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10929362648497669, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8907063735150234, \"precision\": 0.9998194239624402, \"recall\": 0.10929362648497669, \"specificity\": 0.9999999953078731, \"npv\": 0.9997883204103051, \"accuracy\": 0.9997883212183144, \"f1\": 0.19704734450810824, \"f2\": 0.1329828328413677, \"f0_5\": 0.38021695290808, \"p4\": 0.3292165704710509, \"phi\": 0.3305310133023503}, {\"truth_threshold\": 30.379999320954084, \"match_probability\": 0.9999999992843364, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33168.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10911926201058689, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8908807379894131, \"precision\": 0.9998191354675349, \"recall\": 0.10911926201058689, \"specificity\": 0.9999999953078731, \"npv\": 0.9997882789807307, \"accuracy\": 0.9997882797810432, \"f1\": 0.19676390763344062, \"f2\": 0.13277630906840412, \"f0_5\": 0.3797946672101902, \"p4\": 0.3288208826912319, \"phi\": 0.33026719285242484}, {\"truth_threshold\": 30.39999932050705, \"match_probability\": 0.9999999992941891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33073.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270888.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10880672191498252, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8911932780850175, \"precision\": 0.9998186160403881, \"recall\": 0.10880672191498252, \"specificity\": 0.9999999953078731, \"npv\": 0.9997882047201816, \"accuracy\": 0.9997882055066892, \"f1\": 0.19625563731307857, \"f2\": 0.13240608107945806, \"f0_5\": 0.3790367129140431, \"p4\": 0.32811084993625866, \"phi\": 0.3297937790203645}, {\"truth_threshold\": 30.419999320060015, \"match_probability\": 0.9999999993039063, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33005.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 270956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10858300900444465, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8914169909955554, \"precision\": 0.9998182424040472, \"recall\": 0.10858300900444465, \"specificity\": 0.9999999953078731, \"npv\": 0.999788151565269, \"accuracy\": 0.9997881523418884, \"f1\": 0.19589164678370904, \"f2\": 0.13214104119373346, \"f0_5\": 0.3784933659017672, \"p4\": 0.3276019992254154, \"phi\": 0.329454496686554}, {\"truth_threshold\": 30.43999931961298, \"match_probability\": 0.9999999993134896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32906.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 271055.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10825730932586747, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8917426906741326, \"precision\": 0.9998176956733107, \"recall\": 0.10825730932586747, \"specificity\": 0.9999999953078731, \"npv\": 0.9997880741779798, \"accuracy\": 0.9997880749401932, \"f1\": 0.1953614566913941, \"f2\": 0.13175512269810916, \"f0_5\": 0.3777011035125537, \"p4\": 0.32686025072589425, \"phi\": 0.32895991600867713}, {\"truth_threshold\": 30.459999319165945, \"match_probability\": 0.9999999993229409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32843.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 271118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10805004589404561, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8919499541059543, \"precision\": 0.9998173460379312, \"recall\": 0.10805004589404561, \"specificity\": 0.9999999953078731, \"npv\": 0.9997880249315293, \"accuracy\": 0.9997880256845689, \"f1\": 0.19502390071553696, \"f2\": 0.1315095063398289, \"f0_5\": 0.37719618611851885, \"p4\": 0.3263876589844709, \"phi\": 0.32864479536257596}, {\"truth_threshold\": 30.47999931871891, \"match_probability\": 0.9999999993322622, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32784.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 271177.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10785594204519659, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8921440579548034, \"precision\": 0.9998170173833486, \"recall\": 0.10785594204519659, \"specificity\": 0.9999999953078731, \"npv\": 0.999787978811842, \"accuracy\": 0.9997879795562858, \"f1\": 0.19470766233804798, \"f2\": 0.1312794621962881, \"f0_5\": 0.37672279664736935, \"p4\": 0.32594467042256065, \"phi\": 0.3283494081728242}, {\"truth_threshold\": 30.499999318271875, \"match_probability\": 0.9999999993414552, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32710.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 271251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1076124897601995, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8923875102398005, \"precision\": 0.99981660349676, \"recall\": 0.1076124897601995, \"specificity\": 0.9999999953078731, \"npv\": 0.9997879209668165, \"accuracy\": 0.9997879217004733, \"f1\": 0.19431086768623934, \"f2\": 0.13099090151854936, \"f0_5\": 0.3761283274880699, \"p4\": 0.3253885062981087, \"phi\": 0.32797854649780744}, {\"truth_threshold\": 30.51999931782484, \"match_probability\": 0.9999999993505215, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32643.0, \"tn\": 1278737786.0, \"fp\": 6.0, \"fn\": 271318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10739206674540484, \"tn_rate\": 0.9999999953078731, \"fp_rate\": 4.692126906342344e-09, \"fn_rate\": 0.8926079332545952, \"precision\": 0.9998162271432509, \"recall\": 0.10739206674540484, \"specificity\": 0.9999999953078731, \"npv\": 0.9997878685936233, \"accuracy\": 0.9997878693175077, \"f1\": 0.19395145717596032, \"f2\": 0.13072960761494057, \"f0_5\": 0.37558939333620217, \"p4\": 0.32488442227951925, \"phi\": 0.32764240427344743}, {\"truth_threshold\": 30.539999317377806, \"match_probability\": 0.9999999993594632, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32581.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271380.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1071880932093262, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8928119067906738, \"precision\": 1.0, \"recall\": 0.1071880932093262, \"specificity\": 1.0, \"npv\": 0.9997878201298779, \"accuracy\": 0.9997878255347306, \"f1\": 0.19362219277237314, \"f2\": 0.1304884154034083, \"f0_5\": 0.3751108143269972, \"p4\": 0.32442235273190023, \"phi\": 0.32736119203966496}, {\"truth_threshold\": 30.55999931693077, \"match_probability\": 0.9999999993682815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32537.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271424.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10704333779662523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8929566622033748, \"precision\": 1.0, \"recall\": 0.10704333779662523, \"specificity\": 1.0, \"npv\": 0.9997877857355486, \"accuracy\": 0.9997877911339772, \"f1\": 0.1933859933788611, \"f2\": 0.13031678630161786, \"f0_5\": 0.3747561096406663, \"p4\": 0.3240907277856052, \"phi\": 0.3271400643049247}, {\"truth_threshold\": 30.579999316483736, \"match_probability\": 0.9999999993769786, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32424.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10667157957764319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8933284204223568, \"precision\": 1.0, \"recall\": 0.10667157957764319, \"specificity\": 1.0, \"npv\": 0.9997876974046684, \"accuracy\": 0.9997877027865876, \"f1\": 0.19277910727291644, \"f2\": 0.12987595612480654, \"f0_5\": 0.37384384432858225, \"p4\": 0.3232380548307904, \"phi\": 0.32657148210529763}, {\"truth_threshold\": 30.5999993160367, \"match_probability\": 0.999999999385556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32329.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271632.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10635903948203881, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8936409605179612, \"precision\": 1.0, \"recall\": 0.10635903948203881, \"specificity\": 1.0, \"npv\": 0.999787623144206, \"accuracy\": 0.9997876285122336, \"f1\": 0.19226857771566208, \"f2\": 0.12950528492444557, \"f0_5\": 0.3730754228818977, \"p4\": 0.32252009020822525, \"phi\": 0.3260927035118209}, {\"truth_threshold\": 30.619999315589666, \"match_probability\": 0.9999999993940152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32242.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10607281855238007, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.89392718144762, \"precision\": 1.0, \"recall\": 0.10607281855238007, \"specificity\": 1.0, \"npv\": 0.9997875551372659, \"accuracy\": 0.999787560492562, \"f1\": 0.19180078702450604, \"f2\": 0.12916577864025397, \"f0_5\": 0.3723705272689055, \"p4\": 0.32186168977903795, \"phi\": 0.32565362569300976}, {\"truth_threshold\": 30.63999931514263, \"match_probability\": 0.999999999402358, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32156.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271805.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10578988751846453, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8942101124815355, \"precision\": 1.0, \"recall\": 0.10578988751846453, \"specificity\": 1.0, \"npv\": 0.9997874879120239, \"accuracy\": 0.9997874932547257, \"f1\": 0.19133813523267196, \"f2\": 0.1288301282051282, \"f0_5\": 0.37167261925401945, \"p4\": 0.3212100135913672, \"phi\": 0.3252190121880657}, {\"truth_threshold\": 30.659999314695597, \"match_probability\": 0.9999999994105859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32112.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271849.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10564513210576357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8943548678942365, \"precision\": 1.0, \"recall\": 0.10564513210576357, \"specificity\": 1.0, \"npv\": 0.9997874535177175, \"accuracy\": 0.9997874588539722, \"f1\": 0.19110133810213853, \"f2\": 0.12865838218655146, \"f0_5\": 0.37131512063809957, \"p4\": 0.3208762730171451, \"phi\": 0.32499642706430515}, {\"truth_threshold\": 30.679999314248562, \"match_probability\": 0.9999999994187005, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32061.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10547734742286016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8945226525771398, \"precision\": 1.0, \"recall\": 0.10547734742286016, \"specificity\": 1.0, \"npv\": 0.9997874136515925, \"accuracy\": 0.9997874189803716, \"f1\": 0.1908267911029635, \"f2\": 0.12845929778308446, \"f0_5\": 0.37090038292014205, \"p4\": 0.3204891618208593, \"phi\": 0.3247382397851104}, {\"truth_threshold\": 30.699999313801527, \"match_probability\": 0.9999999994267035, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32017.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1053325920101592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8946674079898408, \"precision\": 1.0, \"recall\": 0.1053325920101592, \"specificity\": 1.0, \"npv\": 0.9997873792572913, \"accuracy\": 0.9997873845796181, \"f1\": 0.19058986005036044, \"f2\": 0.1282875256138304, \"f0_5\": 0.37054225526527157, \"p4\": 0.32015494557326984, \"phi\": 0.32451532493275964}, {\"truth_threshold\": 30.719999313354492, \"match_probability\": 0.9999999994345962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31987.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 271974.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10523389513786308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8947661048621369, \"precision\": 1.0, \"recall\": 0.10523389513786308, \"specificity\": 1.0, \"npv\": 0.9997873558066327, \"accuracy\": 0.999787361124559, \"f1\": 0.19042828056723066, \"f2\": 0.12817040128030158, \"f0_5\": 0.37029790997640705, \"p4\": 0.31992694435950225, \"phi\": 0.3243632497079726}, {\"truth_threshold\": 30.739999312907457, \"match_probability\": 0.9999999994423803, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31915.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1049970226443524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8950029773556476, \"precision\": 1.0, \"recall\": 0.1049970226443524, \"specificity\": 1.0, \"npv\": 0.9997872995250565, \"accuracy\": 0.999787304832417, \"f1\": 0.19004037204206314, \"f2\": 0.12788927990100651, \"f0_5\": 0.36971092694748403, \"p4\": 0.3193793225138286, \"phi\": 0.3239979779686415}, {\"truth_threshold\": 30.759999312460423, \"match_probability\": 0.9999999994500571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31846.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10477001983807133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8952299801619287, \"precision\": 1.0, \"recall\": 0.10477001983807133, \"specificity\": 1.0, \"npv\": 0.9997872455885519, \"accuracy\": 0.9997872508857809, \"f1\": 0.189668470282037, \"f2\": 0.12761984146703106, \"f0_5\": 0.3691476660213982, \"p4\": 0.3188539625492852, \"phi\": 0.3236475390825076}, {\"truth_threshold\": 30.779999312013388, \"match_probability\": 0.9999999994576284, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31755.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272206.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10447063932543978, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8955293606745602, \"precision\": 1.0, \"recall\": 0.10447063932543978, \"specificity\": 1.0, \"npv\": 0.9997871744549099, \"accuracy\": 0.9997871797387681, \"f1\": 0.18917775739017503, \"f2\": 0.12726444955470467, \"f0_5\": 0.36840371153252693, \"p4\": 0.31816026342890746, \"phi\": 0.32318478507609144}, {\"truth_threshold\": 30.799999311566353, \"match_probability\": 0.9999999994650954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31706.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10430943443402278, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8956905655659773, \"precision\": 1.0, \"recall\": 0.10430943443402278, \"specificity\": 1.0, \"npv\": 0.9997871361521838, \"accuracy\": 0.9997871414288381, \"f1\": 0.1889134171664179, \"f2\": 0.1270730632038796, \"f0_5\": 0.3680025999048249, \"p4\": 0.3177863400076599, \"phi\": 0.32293533520883966}, {\"truth_threshold\": 30.819999311119318, \"match_probability\": 0.9999999994724595, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31648.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272313.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10411862048091695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8958813795190831, \"precision\": 1.0, \"recall\": 0.10411862048091695, \"specificity\": 1.0, \"npv\": 0.9997870908142669, \"accuracy\": 0.9997870960823904, \"f1\": 0.18860042489921308, \"f2\": 0.12684650482728546, \"f0_5\": 0.3675273427429376, \"p4\": 0.31734338059780237, \"phi\": 0.322639818792118}, {\"truth_threshold\": 30.839999310672283, \"match_probability\": 0.9999999994797224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31572.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10386858840443346, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8961314115955665, \"precision\": 1.0, \"recall\": 0.10386858840443346, \"specificity\": 1.0, \"npv\": 0.9997870314059681, \"accuracy\": 0.9997870366629071, \"f1\": 0.18819013331028542, \"f2\": 0.1265496033400245, \"f0_5\": 0.3669038161622688, \"p4\": 0.3167623657382664, \"phi\": 0.32225218022101404}, {\"truth_threshold\": 30.85999931022525, \"match_probability\": 0.9999999994868852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31506.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10365145528538201, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.896348544714618, \"precision\": 1.0, \"recall\": 0.10365145528538201, \"specificity\": 1.0, \"npv\": 0.9997869798145566, \"accuracy\": 0.999786985061777, \"f1\": 0.1878336766358539, \"f2\": 0.12629173848558944, \"f0_5\": 0.3663616172657186, \"p4\": 0.31625726076999167, \"phi\": 0.3219151680694087}, {\"truth_threshold\": 30.879999309778214, \"match_probability\": 0.9999999994939494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31452.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10347380091524899, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.896526199084751, \"precision\": 1.0, \"recall\": 0.10347380091524899, \"specificity\": 1.0, \"npv\": 0.9997869376034055, \"accuracy\": 0.9997869428426704, \"f1\": 0.18754192592415916, \"f2\": 0.1260807378521217, \"f0_5\": 0.36591750451987, \"p4\": 0.31584361954304124, \"phi\": 0.32163916822930827}, {\"truth_threshold\": 30.89999930933118, \"match_probability\": 0.9999999995009163, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31385.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10325337790045433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8967466220995457, \"precision\": 1.0, \"recall\": 0.10325337790045433, \"specificity\": 1.0, \"npv\": 0.9997868852303158, \"accuracy\": 0.9997868904597049, \"f1\": 0.18717980831737965, \"f2\": 0.12581891537159576, \"f0_5\": 0.3653658547942845, \"p4\": 0.31532993005161275, \"phi\": 0.32129639444071567}, {\"truth_threshold\": 30.919999308884144, \"match_probability\": 0.9999999995077874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31334.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272627.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10308559321755094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.896914406782449, \"precision\": 1.0, \"recall\": 0.10308559321755094, \"specificity\": 1.0, \"npv\": 0.9997868453642362, \"accuracy\": 0.9997868505861044, \"f1\": 0.18690406955069416, \"f2\": 0.12561959880626503, \"f0_5\": 0.3649454806346189, \"p4\": 0.31493856484358357, \"phi\": 0.32103523178223936}, {\"truth_threshold\": 30.93999930843711, \"match_probability\": 0.9999999995145639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31266.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10286188030701307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.897138119692987, \"precision\": 1.0, \"recall\": 0.10286188030701307, \"specificity\": 1.0, \"npv\": 0.9997867922094684, \"accuracy\": 0.9997867974213036, \"f1\": 0.1865362873515558, \"f2\": 0.12535381802727907, \"f0_5\": 0.36438435988578755, \"p4\": 0.3144162762010922, \"phi\": 0.3206866840902236}, {\"truth_threshold\": 30.959999307990074, \"match_probability\": 0.999999999521247, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10250986146249025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8974901385375097, \"precision\": 1.0, \"recall\": 0.10250986146249025, \"specificity\": 1.0, \"npv\": 0.9997867085688893, \"accuracy\": 0.9997867137649259, \"f1\": 0.18595726903795656, \"f2\": 0.12493554546380402, \"f0_5\": 0.3634999778346559, \"p4\": 0.31359335400829497, \"phi\": 0.3201374657665609}, {\"truth_threshold\": 30.97999930754304, \"match_probability\": 0.9999999995278381, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31097.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272864.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10230588792641161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8976941120735884, \"precision\": 1.0, \"recall\": 0.10230588792641161, \"specificity\": 1.0, \"npv\": 0.9997866601042611, \"accuracy\": 0.9997866652911369, \"f1\": 0.18562159387329955, \"f2\": 0.12469314907441491, \"f0_5\": 0.36298672344280014, \"p4\": 0.31311591199926037, \"phi\": 0.3198187955685968}, {\"truth_threshold\": 30.999999307096004, \"match_probability\": 0.9999999995343385, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31008.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 272953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10201308720526646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8979869127947335, \"precision\": 1.0, \"recall\": 0.10201308720526646, \"specificity\": 1.0, \"npv\": 0.9997865905340771, \"accuracy\": 0.9997865957077947, \"f1\": 0.1851395203735271, \"f2\": 0.12434515082784485, \"f0_5\": 0.3622489152859977, \"p4\": 0.31242976960264346, \"phi\": 0.3193607938473489}, {\"truth_threshold\": 31.01999930664897, \"match_probability\": 0.9999999995407494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30930.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273031.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10175647533729656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8982435246627034, \"precision\": 1.0, \"recall\": 0.10175647533729656, \"specificity\": 1.0, \"npv\": 0.9997865295624633, \"accuracy\": 0.9997865347246409, \"f1\": 0.1847168183080465, \"f2\": 0.12404012274879007, \"f0_5\": 0.36160128694050003, \"p4\": 0.311827671951268, \"phi\": 0.31895885837829324}, {\"truth_threshold\": 31.039999306201935, \"match_probability\": 0.9999999995470721, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30877.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273084.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10158211086290675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8984178891370932, \"precision\": 1.0, \"recall\": 0.10158211086290675, \"specificity\": 1.0, \"npv\": 0.9997864881330376, \"accuracy\": 0.9997864932873697, \"f1\": 0.18442948530334072, \"f2\": 0.12383283830143232, \"f0_5\": 0.3611606923542994, \"p4\": 0.31141814888959823, \"phi\": 0.31868545915489527}, {\"truth_threshold\": 31.0599993057549, \"match_probability\": 0.9999999995533077, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30826.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10141432618000336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8985856738199967, \"precision\": 1.0, \"recall\": 0.10141432618000336, \"specificity\": 1.0, \"npv\": 0.9997864482669897, \"accuracy\": 0.999786453413769, \"f1\": 0.18415290916313956, \"f2\": 0.12363335926909286, \"f0_5\": 0.3607363111886066, \"p4\": 0.3110237693821181, \"phi\": 0.31842215528272455}, {\"truth_threshold\": 31.079999305307865, \"match_probability\": 0.9999999995594574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30747.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10115442441629025, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8988455755837097, \"precision\": 1.0, \"recall\": 0.10115442441629025, \"specificity\": 1.0, \"npv\": 0.999786386513706, \"accuracy\": 0.9997863916487799, \"f1\": 0.1837243209006059, \"f2\": 0.1233243301130844, \"f0_5\": 0.36007813579607867, \"p4\": 0.31041226643162684, \"phi\": 0.31801386206742094}, {\"truth_threshold\": 31.09999930486083, \"match_probability\": 0.9999999995655224, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30710.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.1010326982737917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8989673017262083, \"precision\": 1.0, \"recall\": 0.1010326982737917, \"specificity\": 1.0, \"npv\": 0.9997863575912846, \"accuracy\": 0.9997863627208736, \"f1\": 0.1835235201137834, \"f2\": 0.12317958147019704, \"f0_5\": 0.35976954130847866, \"p4\": 0.3101256146793451, \"phi\": 0.3178224557906088}, {\"truth_threshold\": 31.119999304413795, \"match_probability\": 0.999999999571504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30616.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273345.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10072344807393054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8992765519260695, \"precision\": 1.0, \"recall\": 0.10072344807393054, \"specificity\": 1.0, \"npv\": 0.9997862841127082, \"accuracy\": 0.9997862892283549, \"f1\": 0.1830131778335032, \"f2\": 0.12281180302617012, \"f0_5\": 0.35898458111039455, \"p4\": 0.3093966411733223, \"phi\": 0.31733566120569295}, {\"truth_threshold\": 31.13999930396676, \"match_probability\": 0.9999999995774033, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30562.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10054579370379753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8994542062962024, \"precision\": 1.0, \"recall\": 0.10054579370379753, \"specificity\": 1.0, \"npv\": 0.999786241901616, \"accuracy\": 0.9997862470092483, \"f1\": 0.18271987277406934, \"f2\": 0.12260050096036124, \"f0_5\": 0.35853302018493277, \"p4\": 0.30897739919096345, \"phi\": 0.31705567527823075}, {\"truth_threshold\": 31.159999303519726, \"match_probability\": 0.9999999995832213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30470.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273491.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10024312329542277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8997568767045773, \"precision\": 1.0, \"recall\": 0.10024312329542277, \"specificity\": 1.0, \"npv\": 0.9997861699864301, \"accuracy\": 0.9997861750804002, \"f1\": 0.1822199497056194, \"f2\": 0.12224046267633999, \"f0_5\": 0.35776263910708456, \"p4\": 0.3082623437677721, \"phi\": 0.31657809195680015}, {\"truth_threshold\": 31.17999930307269, \"match_probability\": 0.9999999995889592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30417.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273544.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.10006875882103296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.8999312411789671, \"precision\": 1.0, \"recall\": 0.10006875882103296, \"specificity\": 1.0, \"npv\": 0.9997861285570342, \"accuracy\": 0.999786133643129, \"f1\": 0.18193182565838661, \"f2\": 0.12203302518493317, \"f0_5\": 0.35731822784631684, \"p4\": 0.30784995624311434, \"phi\": 0.31630263509997525}, {\"truth_threshold\": 31.199999302625656, \"match_probability\": 0.9999999995946182, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09972989955948296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.900270100440517, \"precision\": 1.0, \"recall\": 0.09972989955948296, \"specificity\": 1.0, \"npv\": 0.9997860480433123, \"accuracy\": 0.9997860531140925, \"f1\": 0.18137162515892605, \"f2\": 0.12162984148077531, \"f0_5\": 0.35645329325967684, \"p4\": 0.30704757407065403, \"phi\": 0.31576662609011097}, {\"truth_threshold\": 31.21999930217862, \"match_probability\": 0.9999999996001991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30243.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273718.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09949631696171549, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9005036830382845, \"precision\": 1.0, \"recall\": 0.09949631696171549, \"specificity\": 1.0, \"npv\": 0.9997859925435698, \"accuracy\": 0.9997859976037858, \"f1\": 0.18098526648394395, \"f2\": 0.12135187992491696, \"f0_5\": 0.355856099667477, \"p4\": 0.30649374414893255, \"phi\": 0.3153966138182183}, {\"truth_threshold\": 31.239999301731586, \"match_probability\": 0.9999999996057033, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30168.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0992495747809752, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9007504252190248, \"precision\": 1.0, \"recall\": 0.0992495747809752, \"specificity\": 1.0, \"npv\": 0.999785933917088, \"accuracy\": 0.9997859389661379, \"f1\": 0.1805769627898207, \"f2\": 0.12105822415835482, \"f0_5\": 0.35522439377062076, \"p4\": 0.3059080629191137, \"phi\": 0.31500528378627424}, {\"truth_threshold\": 31.25999930128455, \"match_probability\": 0.9999999996111317, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30097.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273864.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09901599218320771, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9009840078167923, \"precision\": 1.0, \"recall\": 0.09901599218320771, \"specificity\": 1.0, \"npv\": 0.9997858784173582, \"accuracy\": 0.9997858834558312, \"f1\": 0.18019026636093133, \"f2\": 0.12078019745718296, \"f0_5\": 0.3546255558514336, \"p4\": 0.3053530020301634, \"phi\": 0.31463437625640117}, {\"truth_threshold\": 31.279999300837517, \"match_probability\": 0.9999999996164853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30000.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 273961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09869687229611694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9013031277038831, \"precision\": 1.0, \"recall\": 0.09869687229611694, \"specificity\": 1.0, \"npv\": 0.9997858025937937, \"accuracy\": 0.9997858076178066, \"f1\": 0.17966169702450285, \"f2\": 0.12040030694051583, \"f0_5\": 0.3538061283938853, \"p4\": 0.3045937092381951, \"phi\": 0.3141269356200936}, {\"truth_threshold\": 31.299999300390482, \"match_probability\": 0.9999999996217653, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29945.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09851592803024072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9014840719697593, \"precision\": 1.0, \"recall\": 0.09851592803024072, \"specificity\": 1.0, \"npv\": 0.999785759601056, \"accuracy\": 0.9997857646168647, \"f1\": 0.17936185633082363, \"f2\": 0.12018487881976804, \"f0_5\": 0.3533408379175015, \"p4\": 0.3041626838460277, \"phi\": 0.313838847083208}, {\"truth_threshold\": 31.319999299943447, \"match_probability\": 0.9999999996269726, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29872.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274089.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09827576564098683, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9017242343590132, \"precision\": 1.0, \"recall\": 0.09827576564098683, \"specificity\": 1.0, \"npv\": 0.9997857025379735, \"accuracy\": 0.9997857075428874, \"f1\": 0.17896373336368784, \"f2\": 0.11989891757029693, \"f0_5\": 0.35272252384584685, \"p4\": 0.3035900374099625, \"phi\": 0.3134560661302174}, {\"truth_threshold\": 31.339999299496412, \"match_probability\": 0.9999999996321082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29793.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274168.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09801586387727373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9019841361227263, \"precision\": 1.0, \"recall\": 0.09801586387727373, \"specificity\": 1.0, \"npv\": 0.999785640784782, \"accuracy\": 0.9997856457778982, \"f1\": 0.1785326917430203, \"f2\": 0.11958941489374512, \"f0_5\": 0.35205242796000313, \"p4\": 0.3029696056816463, \"phi\": 0.31304129643485396}, {\"truth_threshold\": 31.359999299049377, \"match_probability\": 0.999999999637173, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29714.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09775596211356062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9022440378864394, \"precision\": 1.0, \"recall\": 0.09775596211356062, \"specificity\": 1.0, \"npv\": 0.9997855790315981, \"accuracy\": 0.9997855840129091, \"f1\": 0.17810144601783173, \"f2\": 0.11927987295653836, \"f0_5\": 0.3513813304573846, \"p4\": 0.30234842581442495, \"phi\": 0.3126259765046679}, {\"truth_threshold\": 31.379999298602343, \"match_probability\": 0.9999999996421682, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29632.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274329.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0974861906626179, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9025138093373821, \"precision\": 1.0, \"recall\": 0.0974861906626179, \"specificity\": 1.0, \"npv\": 0.9997855149333648, \"accuracy\": 0.999785519902414, \"f1\": 0.17765360783949302, \"f2\": 0.1189585347288908, \"f0_5\": 0.3506836864391736, \"p4\": 0.30170286409412755, \"phi\": 0.31219430060543646}, {\"truth_threshold\": 31.399999298155308, \"match_probability\": 0.9999999996470945, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29572.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09728879691802567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9027112030819743, \"precision\": 1.0, \"recall\": 0.09728879691802567, \"specificity\": 1.0, \"npv\": 0.9997854680322236, \"accuracy\": 0.9997854729922957, \"f1\": 0.17732578185666786, \"f2\": 0.11872338238789289, \"f0_5\": 0.35017252853174313, \"p4\": 0.3012299893930695, \"phi\": 0.311878061685942}, {\"truth_threshold\": 31.419999297708273, \"match_probability\": 0.9999999996519531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29507.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274454.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09707495369471741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9029250463052826, \"precision\": 1.0, \"recall\": 0.09707495369471741, \"specificity\": 1.0, \"npv\": 0.9997854172226589, \"accuracy\": 0.9997854221730008, \"f1\": 0.17697050391641778, \"f2\": 0.11846860844854182, \"f0_5\": 0.3496181180078154, \"p4\": 0.3007172189856392, \"phi\": 0.3115351073017989}, {\"truth_threshold\": 31.439999297261238, \"match_probability\": 0.9999999996567448, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29439.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274522.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09685124078417955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9031487592158205, \"precision\": 1.0, \"recall\": 0.09685124078417955, \"specificity\": 1.0, \"npv\": 0.9997853640680429, \"accuracy\": 0.9997853690082, \"f1\": 0.1765986802639472, \"f2\": 0.11820204724548557, \"f0_5\": 0.34903738763199016, \"p4\": 0.30018023660207527, \"phi\": 0.3111759197429207}, {\"truth_threshold\": 31.459999296814203, \"match_probability\": 0.9999999996614705, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29350.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0965584400630344, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9034415599369656, \"precision\": 1.0, \"recall\": 0.0965584400630344, \"specificity\": 1.0, \"npv\": 0.9997852944980393, \"accuracy\": 0.9997852994248578, \"f1\": 0.17611179949056588, \"f2\": 0.11785312168224389, \"f0_5\": 0.3482761812317704, \"p4\": 0.2994765769613239, \"phi\": 0.3107051792852706}, {\"truth_threshold\": 31.47999929636717, \"match_probability\": 0.9999999996661311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29232.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274729.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09617023236533634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9038297676346636, \"precision\": 1.0, \"recall\": 0.09617023236533634, \"specificity\": 1.0, \"npv\": 0.9997852022591732, \"accuracy\": 0.9997852071682917, \"f1\": 0.17546587113174647, \"f2\": 0.11739042435963748, \"f0_5\": 0.3472649558434647, \"p4\": 0.29854215566364606, \"phi\": 0.31007994971730996}, {\"truth_threshold\": 31.499999295920134, \"match_probability\": 0.9999999996707276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09593006997608246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9040699300239176, \"precision\": 1.0, \"recall\": 0.09593006997608246, \"specificity\": 1.0, \"npv\": 0.9997851451961544, \"accuracy\": 0.9997851500943143, \"f1\": 0.17506604226705091, \"f2\": 0.11710413549204299, \"f0_5\": 0.3466382308956079, \"p4\": 0.29796323523445156, \"phi\": 0.3096925232221709}, {\"truth_threshold\": 31.5199992954731, \"match_probability\": 0.9999999996752608, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29070.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0956372692549373, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9043627307450627, \"precision\": 1.0, \"recall\": 0.0956372692549373, \"specificity\": 1.0, \"npv\": 0.9997850756261812, \"accuracy\": 0.9997850805109721, \"f1\": 0.17457834255669893, \"f2\": 0.11675505295948153, \"f0_5\": 0.3458729633710181, \"p4\": 0.29725655119103994, \"phi\": 0.3092195247307792}, {\"truth_threshold\": 31.539999295026064, \"match_probability\": 0.9999999996797315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 29002.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 274959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09541355634439945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9045864436556006, \"precision\": 1.0, \"recall\": 0.09541355634439945, \"specificity\": 1.0, \"npv\": 0.9997850224716016, \"accuracy\": 0.9997850273461714, \"f1\": 0.17420554235755925, \"f2\": 0.11648830457743367, \"f0_5\": 0.34528739025975724, \"p4\": 0.2967159623292457, \"phi\": 0.308857644512615}, {\"truth_threshold\": 31.55999929457903, \"match_probability\": 0.9999999996841408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28915.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09512733541474071, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9048726645852593, \"precision\": 1.0, \"recall\": 0.09512733541474071, \"specificity\": 1.0, \"npv\": 0.9997849544650153, \"accuracy\": 0.9997849593264998, \"f1\": 0.17372835530347636, \"f2\": 0.11614698106219758, \"f0_5\": 0.3445370941873738, \"p4\": 0.2960235033954219, \"phi\": 0.30839403156676815}, {\"truth_threshold\": 31.579999294131994, \"match_probability\": 0.9999999996884893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28867.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09496942041906692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.905030579580933, \"precision\": 1.0, \"recall\": 0.09496942041906692, \"specificity\": 1.0, \"npv\": 0.9997849169441441, \"accuracy\": 0.9997849217984052, \"f1\": 0.17346497289891474, \"f2\": 0.11595864421540422, \"f0_5\": 0.3441226047793548, \"p4\": 0.29564106090232495, \"phi\": 0.30813794655301757}, {\"truth_threshold\": 31.59999929368496, \"match_probability\": 0.999999999692778, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28797.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275164.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09473912771704265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9052608722829574, \"precision\": 1.0, \"recall\": 0.09473912771704265, \"specificity\": 1.0, \"npv\": 0.9997848622262119, \"accuracy\": 0.9997848670699337, \"f1\": 0.1730807373526707, \"f2\": 0.1156839602744888, \"f0_5\": 0.3435174603780517, \"p4\": 0.2950828264575282, \"phi\": 0.307764107316001}, {\"truth_threshold\": 31.619999293237925, \"match_probability\": 0.9999999996970076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28726.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275235.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09450554511927517, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9054944548807248, \"precision\": 1.0, \"recall\": 0.09450554511927517, \"specificity\": 1.0, \"npv\": 0.9997848067266011, \"accuracy\": 0.9997848115596271, \"f1\": 0.17269084755340605, \"f2\": 0.11540532071317805, \"f0_5\": 0.342902844591933, \"p4\": 0.29451600331074057, \"phi\": 0.30738446311039636}, {\"truth_threshold\": 31.63999929279089, \"match_probability\": 0.9999999997011789, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28667.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275294.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09431144127042614, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9056885587295739, \"precision\": 1.0, \"recall\": 0.09431144127042614, \"specificity\": 1.0, \"npv\": 0.9997847606072109, \"accuracy\": 0.999784765431344, \"f1\": 0.17236672799644046, \"f2\": 0.11517375097528267, \"f0_5\": 0.3423914731182025, \"p4\": 0.2940445101729511, \"phi\": 0.30706862707393934}, {\"truth_threshold\": 31.659999292343855, \"match_probability\": 0.999999999705293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28611.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09412720710880672, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9058727928911933, \"precision\": 1.0, \"recall\": 0.09412720710880672, \"specificity\": 1.0, \"npv\": 0.9997847168328783, \"accuracy\": 0.9997847216485669, \"f1\": 0.17205898271652453, \"f2\": 0.11495393565858147, \"f0_5\": 0.341905569962118, \"p4\": 0.29359659515577186, \"phi\": 0.3067685497334236}, {\"truth_threshold\": 31.67999929189682, \"match_probability\": 0.9999999997093503, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28524.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275437.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09384098617914799, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9061590138208521, \"precision\": 1.0, \"recall\": 0.09384098617914799, \"specificity\": 1.0, \"npv\": 0.9997846488263336, \"accuracy\": 0.9997846536288952, \"f1\": 0.17158067281230732, \"f2\": 0.11461239761871087, \"f0_5\": 0.3411496518417345, \"p4\": 0.29289996078032504, \"phi\": 0.3063017750726174}, {\"truth_threshold\": 31.699999291449785, \"match_probability\": 0.9999999997133517, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28422.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275539.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09350541681334118, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9064945831866588, \"precision\": 1.0, \"recall\": 0.09350541681334118, \"specificity\": 1.0, \"npv\": 0.9997845690945343, \"accuracy\": 0.9997845738816941, \"f1\": 0.17101957681349528, \"f2\": 0.1142119128867943, \"f0_5\": 0.34026179878318874, \"p4\": 0.2920820272053228, \"phi\": 0.3057536146257819}, {\"truth_threshold\": 31.71999929100275, \"match_probability\": 0.9999999997172981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28335.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09321919588368245, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9067808041163176, \"precision\": 1.0, \"recall\": 0.09321919588368245, \"specificity\": 1.0, \"npv\": 0.9997845010880096, \"accuracy\": 0.9997845058620225, \"f1\": 0.17054072272913307, \"f2\": 0.11387027107835769, \"f0_5\": 0.3395031404190261, \"p4\": 0.2913833609687839, \"phi\": 0.305285288293414}, {\"truth_threshold\": 31.739999290555716, \"match_probability\": 0.9999999997211901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28264.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09298561328591497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9070143867140851, \"precision\": 1.0, \"recall\": 0.09298561328591497, \"specificity\": 1.0, \"npv\": 0.9997844455884389, \"accuracy\": 0.9997844503517158, \"f1\": 0.17014974791180676, \"f2\": 0.11359142453870565, \"f0_5\": 0.33888306711716787, \"p4\": 0.29081248984137253, \"phi\": 0.30490255792098475}, {\"truth_threshold\": 31.75999929010868, \"match_probability\": 0.9999999997250286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28214.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275747.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09282111849875477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9071788815012453, \"precision\": 1.0, \"recall\": 0.09282111849875477, \"specificity\": 1.0, \"npv\": 0.9997844065042379, \"accuracy\": 0.9997844112599504, \"f1\": 0.1698743132385038, \"f2\": 0.11339503463664877, \"f0_5\": 0.33844588872334863, \"p4\": 0.2904100923710421, \"phi\": 0.3046327409674428}, {\"truth_threshold\": 31.779999289661646, \"match_probability\": 0.9999999997288141, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28137.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275824.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09256779652652808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.907432203473472, \"precision\": 1.0, \"recall\": 0.09256779652652808, \"specificity\": 1.0, \"npv\": 0.9997843463145744, \"accuracy\": 0.999784351058632, \"f1\": 0.16944998163192793, \"f2\": 0.11309256331085443, \"f0_5\": 0.33777181285398394, \"p4\": 0.289789792313489, \"phi\": 0.30421675486411887}, {\"truth_threshold\": 31.79999928921461, \"match_probability\": 0.9999999997325477, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 28055.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09229802507558535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9077019749244146, \"precision\": 1.0, \"recall\": 0.09229802507558535, \"specificity\": 1.0, \"npv\": 0.999784282216499, \"accuracy\": 0.9997842869481368, \"f1\": 0.16899787962025928, \"f2\": 0.11277040981623106, \"f0_5\": 0.3370528688239011, \"p4\": 0.28912840115900396, \"phi\": 0.3037731303953569}, {\"truth_threshold\": 31.819999288767576, \"match_probability\": 0.9999999997362298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27983.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 275978.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09206115258207467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9079388474179253, \"precision\": 1.0, \"recall\": 0.09206115258207467, \"specificity\": 1.0, \"npv\": 0.9997842259352688, \"accuracy\": 0.9997842306559949, \"f1\": 0.1686007278336105, \"f2\": 0.11248750831104326, \"f0_5\": 0.3364206658924291, \"p4\": 0.2885469757823099, \"phi\": 0.3033830716651445}, {\"truth_threshold\": 31.83999928832054, \"match_probability\": 0.9999999997398612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27911.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276050.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.091824280088564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.908175719911436, \"precision\": 1.0, \"recall\": 0.091824280088564, \"specificity\": 1.0, \"npv\": 0.999784169654045, \"accuracy\": 0.9997841743638528, \"f1\": 0.1682034037219169, \"f2\": 0.11220457405196362, \"f0_5\": 0.33578758677109277, \"p4\": 0.2879649025086743, \"phi\": 0.302992510835541}, {\"truth_threshold\": 31.859999287873507, \"match_probability\": 0.9999999997434426, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27831.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276130.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09156108842910768, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9084389115708923, \"precision\": 1.0, \"recall\": 0.09156108842910768, \"specificity\": 1.0, \"npv\": 0.9997841071193594, \"accuracy\": 0.9997841118170284, \"f1\": 0.16776173024063268, \"f2\": 0.1118901642310089, \"f0_5\": 0.33508313567790793, \"p4\": 0.28731739322968486, \"phi\": 0.30255796311115685}, {\"truth_threshold\": 31.87999928742647, \"match_probability\": 0.9999999997469747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27757.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09131763614411059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9086823638558894, \"precision\": 1.0, \"recall\": 0.09131763614411059, \"specificity\": 1.0, \"npv\": 0.9997840492747821, \"accuracy\": 0.9997840539612157, \"f1\": 0.16735299260215003, \"f2\": 0.11159929913211714, \"f0_5\": 0.3344305511712359, \"p4\": 0.2867177325255264, \"phi\": 0.3021554501152678}, {\"truth_threshold\": 31.899999286979437, \"match_probability\": 0.9999999997504582, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27675.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276286.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09104786469316788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9089521353068322, \"precision\": 1.0, \"recall\": 0.09104786469316788, \"specificity\": 1.0, \"npv\": 0.9997839851767448, \"accuracy\": 0.9997839898507207, \"f1\": 0.1668998540568575, \"f2\": 0.11127694872374286, \"f0_5\": 0.3337063287842358, \"p4\": 0.2860524400078892, \"phi\": 0.30170879504046355}, {\"truth_threshold\": 31.919999286532402, \"match_probability\": 0.9999999997538936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27585.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276376.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09075177407627952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9092482259237205, \"precision\": 1.0, \"recall\": 0.09075177407627952, \"specificity\": 1.0, \"npv\": 0.99978391482525, \"accuracy\": 0.9997839194855431, \"f1\": 0.16640224885837862, \"f2\": 0.11092310055499752, \"f0_5\": 0.3329101305572518, \"p4\": 0.2853212665501912, \"phi\": 0.30121780153788946}, {\"truth_threshold\": 31.939999286085367, \"match_probability\": 0.9999999997572819, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27488.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276473.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.09043265418918875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9095673458108112, \"precision\": 1.0, \"recall\": 0.09043265418918875, \"specificity\": 1.0, \"npv\": 0.9997838390019833, \"accuracy\": 0.9997838436475185, \"f1\": 0.16586563845418148, \"f2\": 0.11054167350313512, \"f0_5\": 0.33205045504731673, \"p4\": 0.2845320799436418, \"phi\": 0.3006877220247044}, {\"truth_threshold\": 31.959999285638332, \"match_probability\": 0.9999999997606235, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27423.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276538.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0902188109658805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9097811890341195, \"precision\": 1.0, \"recall\": 0.0902188109658805, \"specificity\": 1.0, \"npv\": 0.9997837881925842, \"accuracy\": 0.9997837928282236, \"f1\": 0.1655058783767472, \"f2\": 0.11028604475144921, \"f0_5\": 0.3314734813962427, \"p4\": 0.2840025780867873, \"phi\": 0.3003319906265376}, {\"truth_threshold\": 31.979999285191298, \"match_probability\": 0.9999999997639191, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27333.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08992272034899214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9100772796510078, \"precision\": 1.0, \"recall\": 0.08992272034899214, \"specificity\": 1.0, \"npv\": 0.9997837178411171, \"accuracy\": 0.9997837224630461, \"f1\": 0.16500751598278265, \"f2\": 0.10993205311874335, \"f0_5\": 0.3306733963556121, \"p4\": 0.2832685383357008, \"phi\": 0.2998387427750164}, {\"truth_threshold\": 31.999999284744263, \"match_probability\": 0.9999999997671692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27239.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08961347014913097, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.910386529850869, \"precision\": 1.0, \"recall\": 0.08961347014913097, \"specificity\": 1.0, \"npv\": 0.9997836443629287, \"accuracy\": 0.9997836489705274, \"f1\": 0.1644867149758454, \"f2\": 0.10956227379829021, \"f0_5\": 0.3298362624934309, \"p4\": 0.282500777266852, \"phi\": 0.29932270506880476}, {\"truth_threshold\": 32.01999928429723, \"match_probability\": 0.9999999997703747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27167.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276794.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0893765976556203, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9106234023443797, \"precision\": 1.0, \"recall\": 0.0893765976556203, \"specificity\": 1.0, \"npv\": 0.9997835880817704, \"accuracy\": 0.9997835926783853, \"f1\": 0.16408760358532049, \"f2\": 0.10927900074898773, \"f0_5\": 0.3291940217483502, \"p4\": 0.28191194516420043, \"phi\": 0.29892683970275535}, {\"truth_threshold\": 32.03999928385019, \"match_probability\": 0.999999999773536, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27102.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276859.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08916275443231204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.910837245567688, \"precision\": 1.0, \"recall\": 0.08916275443231204, \"specificity\": 1.0, \"npv\": 0.9997835372723968, \"accuracy\": 0.9997835418590905, \"f1\": 0.163727145588604, \"f2\": 0.10902323994767271, \"f0_5\": 0.3286134505746067, \"p4\": 0.2813797935134457, \"phi\": 0.29856901048046997}, {\"truth_threshold\": 32.05999928340316, \"match_probability\": 0.9999999997766538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 27027.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 276934.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08891601225157175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9110839877484282, \"precision\": 1.0, \"recall\": 0.08891601225157175, \"specificity\": 1.0, \"npv\": 0.9997834786462029, \"accuracy\": 0.9997834832214426, \"f1\": 0.16331105659419676, \"f2\": 0.1087280980890213, \"f0_5\": 0.32794265038136816, \"p4\": 0.2807651025823617, \"phi\": 0.29815559702313954}, {\"truth_threshold\": 32.07999928295612, \"match_probability\": 0.9999999997797286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26931.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277030.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08860018226022418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9113998177397759, \"precision\": 1.0, \"recall\": 0.08860018226022418, \"specificity\": 1.0, \"npv\": 0.9997834036046848, \"accuracy\": 0.9997834081652532, \"f1\": 0.16277818744484604, \"f2\": 0.10835026452897749, \"f0_5\": 0.32708259956034347, \"p4\": 0.2799772490858889, \"phi\": 0.2976255899282223}, {\"truth_threshold\": 32.09999928250909, \"match_probability\": 0.9999999997827612, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26861.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277100.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0883698895581999, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9116301104418001, \"precision\": 1.0, \"recall\": 0.0883698895581999, \"specificity\": 1.0, \"npv\": 0.9997833488869182, \"accuracy\": 0.9997833534367818, \"f1\": 0.1623894420564533, \"f2\": 0.10807472408978801, \"f0_5\": 0.3264544670093946, \"p4\": 0.2794020285771612, \"phi\": 0.29723853068413625}, {\"truth_threshold\": 32.119999282062054, \"match_probability\": 0.999999999785752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26788.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277173.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08812972716894601, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9118702728310539, \"precision\": 1.0, \"recall\": 0.08812972716894601, \"specificity\": 1.0, \"npv\": 0.9997832918241109, \"accuracy\": 0.9997832963628045, \"f1\": 0.1619838608733511, \"f2\": 0.10778734170695749, \"f0_5\": 0.32579850308795877, \"p4\": 0.278801486129599, \"phi\": 0.2968343456147378}, {\"truth_threshold\": 32.13999928161502, \"match_probability\": 0.9999999997887016, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26743.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277218.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08798168186050184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9120183181394982, \"precision\": 1.0, \"recall\": 0.08798168186050184, \"specificity\": 1.0, \"npv\": 0.9997832566484111, \"accuracy\": 0.9997832611802158, \"f1\": 0.16173375586627317, \"f2\": 0.10761017136023474, \"f0_5\": 0.3253936773147934, \"p4\": 0.27843094760936626, \"phi\": 0.29658491602894604}, {\"truth_threshold\": 32.159999281167984, \"match_probability\": 0.9999999997916106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26686.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277275.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08779415780313922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9122058421968607, \"precision\": 1.0, \"recall\": 0.08779415780313922, \"specificity\": 1.0, \"npv\": 0.9997832120925281, \"accuracy\": 0.9997832166156033, \"f1\": 0.16141685846234807, \"f2\": 0.10738573716529984, \"f0_5\": 0.3248803886000901, \"p4\": 0.2779612248077697, \"phi\": 0.29626867045197475}, {\"truth_threshold\": 32.17999928072095, \"match_probability\": 0.9999999997944796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26607.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277354.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0875342560394261, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9124657439605739, \"precision\": 1.0, \"recall\": 0.0875342560394261, \"specificity\": 1.0, \"npv\": 0.9997831503396443, \"accuracy\": 0.9997831548506142, \"f1\": 0.16097746908351684, \"f2\": 0.10707464519727539, \"f0_5\": 0.3241680454398144, \"p4\": 0.2773095133565976, \"phi\": 0.29582980624969907}, {\"truth_threshold\": 32.199999280273914, \"match_probability\": 0.999999999797309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26528.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277433.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.087274354275713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.912725645724287, \"precision\": 1.0, \"recall\": 0.087274354275713, \"specificity\": 1.0, \"npv\": 0.999783088586768, \"accuracy\": 0.999783093085625, \"f1\": 0.16053786964165223, \"f2\": 0.10676351366579415, \"f0_5\": 0.32345460442409035, \"p4\": 0.2766569964612751, \"phi\": 0.2953902900777007}, {\"truth_threshold\": 32.21999927982688, \"match_probability\": 0.9999999998000996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26470.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277491.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08708354032260718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9129164596773929, \"precision\": 1.0, \"recall\": 0.08708354032260718, \"specificity\": 1.0, \"npv\": 0.9997830432492182, \"accuracy\": 0.9997830477391773, \"f1\": 0.1602149919347761, \"f2\": 0.10653506279410842, \"f0_5\": 0.3229301119214525, \"p4\": 0.2761774198143691, \"phi\": 0.29506719058657166}, {\"truth_threshold\": 32.239999279379845, \"match_probability\": 0.9999999998028516, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26405.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08686969709929893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9131303029007011, \"precision\": 1.0, \"recall\": 0.08686969709929893, \"specificity\": 1.0, \"npv\": 0.9997829924399, \"accuracy\": 0.9997829969198824, \"f1\": 0.15985301150844822, \"f2\": 0.10627901491568921, \"f0_5\": 0.32234161252597165, \"p4\": 0.2756394456328853, \"phi\": 0.29470467542657813}, {\"truth_threshold\": 32.25999927893281, \"match_probability\": 0.9999999998055659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26357.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277604.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08671178210362514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9132882178963748, \"precision\": 1.0, \"recall\": 0.08671178210362514, \"specificity\": 1.0, \"npv\": 0.999782954919176, \"accuracy\": 0.9997829593917877, \"f1\": 0.15958561144109615, \"f2\": 0.1060899162051874, \"f0_5\": 0.32190654853940875, \"p4\": 0.2752418207723427, \"phi\": 0.294436685448451}, {\"truth_threshold\": 32.279999278485775, \"match_probability\": 0.9999999998082427, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26299.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08652096815051931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9134790318494806, \"precision\": 1.0, \"recall\": 0.08652096815051931, \"specificity\": 1.0, \"npv\": 0.9997829095816383, \"accuracy\": 0.99978291404534, \"f1\": 0.1592623993217465, \"f2\": 0.10586140243112105, \"f0_5\": 0.321380301449077, \"p4\": 0.27476095831190844, \"phi\": 0.29411253845653446}, {\"truth_threshold\": 32.29999927803874, \"match_probability\": 0.9999999998108826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26238.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277723.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08632028451018388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9136797154898161, \"precision\": 1.0, \"recall\": 0.08632028451018388, \"specificity\": 1.0, \"npv\": 0.99978286189906, \"accuracy\": 0.9997828663533863, \"f1\": 0.15892234682721632, \"f2\": 0.10562104595348777, \"f0_5\": 0.32082619041214144, \"p4\": 0.2742547518322769, \"phi\": 0.2937712393811428}, {\"truth_threshold\": 32.319999277591705, \"match_probability\": 0.9999999998134863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08604393326775474, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9139560667322453, \"precision\": 1.0, \"recall\": 0.08604393326775474, \"specificity\": 1.0, \"npv\": 0.999782796237812, \"accuracy\": 0.9997828006792207, \"f1\": 0.15845387213546794, \"f2\": 0.10529002462161775, \"f0_5\": 0.32006206908367335, \"p4\": 0.2735568876737741, \"phi\": 0.2933006038209528}, {\"truth_threshold\": 32.33999927714467, \"match_probability\": 0.999999999816054, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26077.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08579061129552805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.914209388704472, \"precision\": 1.0, \"recall\": 0.08579061129552805, \"specificity\": 1.0, \"npv\": 0.9997827360483422, \"accuracy\": 0.9997827404779022, \"f1\": 0.15802422751319545, \"f2\": 0.10498654906390986, \"f0_5\": 0.31936051965738277, \"p4\": 0.27291637038756233, \"phi\": 0.2928685235533222}, {\"truth_threshold\": 32.359999276697636, \"match_probability\": 0.9999999998185866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 26019.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 277942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08559979734242222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9144002026575778, \"precision\": 1.0, \"recall\": 0.08559979734242222, \"specificity\": 1.0, \"npv\": 0.9997826907108244, \"accuracy\": 0.9997826951314543, \"f1\": 0.15770046669495122, \"f2\": 0.10475793223568139, \"f0_5\": 0.31883138048755383, \"p4\": 0.27243339130714145, \"phi\": 0.29254263913369644}, {\"truth_threshold\": 32.3799992762506, \"match_probability\": 0.9999999998210841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25921.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08527738755958823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9147226124404118, \"precision\": 1.0, \"recall\": 0.08527738755958823, \"specificity\": 1.0, \"npv\": 0.9997826141060622, \"accuracy\": 0.9997826185115944, \"f1\": 0.15715316385859185, \"f2\": 0.10437160010146847, \"f0_5\": 0.31793594917146045, \"p4\": 0.2716163226502092, \"phi\": 0.2919911804463637}, {\"truth_threshold\": 32.399999275803566, \"match_probability\": 0.9999999998235473, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25844.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278117.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08502406558736153, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9149759344126385, \"precision\": 1.0, \"recall\": 0.08502406558736153, \"specificity\": 1.0, \"npv\": 0.9997825539166143, \"accuracy\": 0.9997825583102758, \"f1\": 0.15672291202377162, \"f2\": 0.10406801064357551, \"f0_5\": 0.31723118695330893, \"p4\": 0.27097345661812156, \"phi\": 0.2915571598114271}, {\"truth_threshold\": 32.41999927535653, \"match_probability\": 0.9999999998259765, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25785.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08482996173851251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9151700382614875, \"precision\": 1.0, \"recall\": 0.08482996173851251, \"specificity\": 1.0, \"npv\": 0.9997825077974319, \"accuracy\": 0.9997825121819929, \"f1\": 0.1563931025698568, \"f2\": 0.10383536467012287, \"f0_5\": 0.3166904527377727, \"p4\": 0.2704803438785589, \"phi\": 0.29122416088520237}, {\"truth_threshold\": 32.439999274909496, \"match_probability\": 0.9999999998283724, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25707.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278254.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0845733498705426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9154266501294573, \"precision\": 1.0, \"recall\": 0.0845733498705426, \"specificity\": 1.0, \"npv\": 0.999782446826316, \"accuracy\": 0.999782451198839, \"f1\": 0.15595690209544147, \"f2\": 0.1035277648682978, \"f0_5\": 0.31597462074933197, \"p4\": 0.26982772899909213, \"phi\": 0.2907833397391762}, {\"truth_threshold\": 32.45999927446246, \"match_probability\": 0.9999999998307353, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25629.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0843167380025727, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9156832619974273, \"precision\": 1.0, \"recall\": 0.0843167380025727, \"specificity\": 1.0, \"npv\": 0.9997823858552075, \"accuracy\": 0.9997823902156852, \"f1\": 0.15552049516065414, \"f2\": 0.10322012641434812, \"f0_5\": 0.31525768985699065, \"p4\": 0.26917431212820375, \"phi\": 0.2903418493564794}, {\"truth_threshold\": 32.47999927401543, \"match_probability\": 0.9999999998330655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25545.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278416.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08404038676014357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9159596132398564, \"precision\": 1.0, \"recall\": 0.08404038676014357, \"specificity\": 1.0, \"npv\": 0.9997823201940221, \"accuracy\": 0.9997823245415195, \"f1\": 0.15505028739992596, \"f2\": 0.1028887802292432, \"f0_5\": 0.31448437857788303, \"p4\": 0.2684697338225697, \"phi\": 0.2898656462312485}, {\"truth_threshold\": 32.49999927356839, \"match_probability\": 0.9999999998353638, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25452.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0837344264560256, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9162655735439744, \"precision\": 1.0, \"recall\": 0.0837344264560256, \"specificity\": 1.0, \"npv\": 0.9997822474977197, \"accuracy\": 0.999782251830836, \"f1\": 0.15452942051467308, \"f2\": 0.10252188035730397, \"f0_5\": 0.31362671865026653, \"p4\": 0.267688575802364, \"phi\": 0.2893375072041954}, {\"truth_threshold\": 32.51999927312136, \"match_probability\": 0.9999999998376304, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25377.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278584.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08348768427528531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9165123157247147, \"precision\": 1.0, \"recall\": 0.08348768427528531, \"specificity\": 1.0, \"npv\": 0.9997821888716771, \"accuracy\": 0.9997821931931882, \"f1\": 0.15410915229946134, \"f2\": 0.10222595331532419, \"f0_5\": 0.3129339111004787, \"p4\": 0.26705777428922095, \"phi\": 0.28891088544492793}, {\"truth_threshold\": 32.53999927267432, \"match_probability\": 0.9999999998398658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25309.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278652.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08326397136474745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9167360286352525, \"precision\": 1.0, \"recall\": 0.08326397136474745, \"specificity\": 1.0, \"npv\": 0.9997821357174044, \"accuracy\": 0.9997821400283873, \"f1\": 0.15372794363288486, \"f2\": 0.10195761521746312, \"f0_5\": 0.31230487886139335, \"p4\": 0.26648520169055606, \"phi\": 0.28852353650847967}, {\"truth_threshold\": 32.55999927222729, \"match_probability\": 0.9999999998420704, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25224.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08298433022657511, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9170156697734249, \"precision\": 1.0, \"recall\": 0.08298433022657511, \"specificity\": 1.0, \"npv\": 0.9997820692745715, \"accuracy\": 0.9997820735723864, \"f1\": 0.15325121132493885, \"f2\": 0.10162215124392862, \"f0_5\": 0.3115173999708539, \"p4\": 0.26576862055971967, \"phi\": 0.2880386178818556}, {\"truth_threshold\": 32.57999927178025, \"match_probability\": 0.9999999998442447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25136.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08269481940117318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9173051805988268, \"precision\": 1.0, \"recall\": 0.08269481940117318, \"specificity\": 1.0, \"npv\": 0.9997820004867067, \"accuracy\": 0.9997820047708794, \"f1\": 0.15275739371674613, \"f2\": 0.10127479894921755, \"f0_5\": 0.3107007329946478, \"p4\": 0.2650257333594862, \"phi\": 0.2875357229472398}, {\"truth_threshold\": 32.59999927133322, \"match_probability\": 0.999999999846389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 25082.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08251716503104016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9174828349689599, \"precision\": 1.0, \"recall\": 0.08251716503104016, \"specificity\": 1.0, \"npv\": 0.9997819582759763, \"accuracy\": 0.9997819625517729, \"f1\": 0.15245423850378217, \"f2\": 0.10106162655952088, \"f0_5\": 0.31019889237649306, \"p4\": 0.2645693586223899, \"phi\": 0.2872266924331986}, {\"truth_threshold\": 32.61999927088618, \"match_probability\": 0.9999999998485037, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24998.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 278963.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08224081378861103, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.917759186211389, \"precision\": 1.0, \"recall\": 0.08224081378861103, \"specificity\": 1.0, \"npv\": 0.999781892614847, \"accuracy\": 0.9997818968776072, \"f1\": 0.15198246590000578, \"f2\": 0.10072998818544182, \"f0_5\": 0.30941718467247425, \"p4\": 0.2638586667629662, \"phi\": 0.2867453163693572}, {\"truth_threshold\": 32.63999927043915, \"match_probability\": 0.9999999998505895, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24920.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279041.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08198420192064114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9180157980793588, \"precision\": 1.0, \"recall\": 0.08198420192064114, \"specificity\": 1.0, \"npv\": 0.9997818316438061, \"accuracy\": 0.9997818358944534, \"f1\": 0.15154417555285954, \"f2\": 0.10042199805926026, \"f0_5\": 0.308690147928481, \"p4\": 0.26319789170702684, \"phi\": 0.2862975996442762}, {\"truth_threshold\": 32.65999926999211, \"match_probability\": 0.9999999998526464, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24843.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08173087994841444, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9182691200515856, \"precision\": 1.0, \"recall\": 0.08173087994841444, \"specificity\": 1.0, \"npv\": 0.9997817714544525, \"accuracy\": 0.9997817756931349, \"f1\": 0.15111130034914416, \"f2\": 0.1001179185402926, \"f0_5\": 0.3079713289019247, \"p4\": 0.2625447866929543, \"phi\": 0.2858549351285665}, {\"truth_threshold\": 32.67999926954508, \"match_probability\": 0.9999999998546751, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24764.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279197.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08147097818470132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9185290218152987, \"precision\": 1.0, \"recall\": 0.08147097818470132, \"specificity\": 1.0, \"npv\": 0.9997817097017466, \"accuracy\": 0.9997817139281457, \"f1\": 0.15066697087230968, \"f2\": 0.09980590162243029, \"f0_5\": 0.30723269738001124, \"p4\": 0.26187388882180024, \"phi\": 0.2854000593212524}, {\"truth_threshold\": 32.69999926909804, \"match_probability\": 0.9999999998566759, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24686.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279275.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08121436631673143, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9187856336832686, \"precision\": 1.0, \"recall\": 0.08121436631673143, \"specificity\": 1.0, \"npv\": 0.999781648730728, \"accuracy\": 0.9997816529449919, \"f1\": 0.15022805624271635, \"f2\": 0.09949779529717137, \"f0_5\": 0.30650227834270743, \"p4\": 0.2612106579556407, \"phi\": 0.2849502290870513}, {\"truth_threshold\": 32.71999926865101, \"match_probability\": 0.9999999998586491, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24622.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08100381298916637, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9189961870108336, \"precision\": 1.0, \"recall\": 0.08100381298916637, \"specificity\": 1.0, \"npv\": 0.9997815987032311, \"accuracy\": 0.9997816029075323, \"f1\": 0.14986776552651843, \"f2\": 0.0992449611678192, \"f0_5\": 0.3059021143051666, \"p4\": 0.2606658549262645, \"phi\": 0.28458060659743895}, {\"truth_threshold\": 32.739999268203974, \"match_probability\": 0.9999999998605951, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24552.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0807735202871421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9192264797128579, \"precision\": 1.0, \"recall\": 0.0807735202871421, \"specificity\": 1.0, \"npv\": 0.9997815439856622, \"accuracy\": 0.9997815481790608, \"f1\": 0.14947353681589465, \"f2\": 0.09896839396450811, \"f0_5\": 0.3052448100176791, \"p4\": 0.2600693422302368, \"phi\": 0.28417578156105444}, {\"truth_threshold\": 32.75999926775694, \"match_probability\": 0.9999999998625143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24474.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279487.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0805169084191722, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9194830915808277, \"precision\": 1.0, \"recall\": 0.0805169084191722, \"specificity\": 1.0, \"npv\": 0.9997814830146637, \"accuracy\": 0.9997814871959071, \"f1\": 0.14903405544476075, \"f2\": 0.0986601823080855, \"f0_5\": 0.3045113062606848, \"p4\": 0.2594038746017587, \"phi\": 0.2837240104521925}, {\"truth_threshold\": 32.779999267309904, \"match_probability\": 0.9999999998644071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24409.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08030306519586394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9196969348041361, \"precision\": 1.0, \"recall\": 0.08030306519586394, \"specificity\": 1.0, \"npv\": 0.9997814322055042, \"accuracy\": 0.9997814363766122, \"f1\": 0.1486676614794287, \"f2\": 0.09840330964730583, \"f0_5\": 0.3038991825138136, \"p4\": 0.2588486874843309, \"phi\": 0.28334698433548366}, {\"truth_threshold\": 32.79999926686287, \"match_probability\": 0.9999999998662739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24358.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279603.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.08013528051296054, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9198647194870394, \"precision\": 1.0, \"recall\": 0.08013528051296054, \"specificity\": 1.0, \"npv\": 0.9997813923398594, \"accuracy\": 0.9997813965030116, \"f1\": 0.14838008156701257, \"f2\": 0.09820174455451612, \"f0_5\": 0.3034183456114083, \"p4\": 0.2584126770500814, \"phi\": 0.28305081227015216}, {\"truth_threshold\": 32.819999266415834, \"match_probability\": 0.9999999998681149, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07999052510025957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9200094748997404, \"precision\": 1.0, \"recall\": 0.07999052510025957, \"specificity\": 1.0, \"npv\": 0.9997813579459724, \"accuracy\": 0.9997813621022581, \"f1\": 0.14813190160688447, \"f2\": 0.09802783193754344, \"f0_5\": 0.30300311302861044, \"p4\": 0.25803622672996196, \"phi\": 0.2827950420490941}, {\"truth_threshold\": 32.8399992659688, \"match_probability\": 0.9999999998699306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24249.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07977668187695132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9202233181230487, \"precision\": 1.0, \"recall\": 0.07977668187695132, \"specificity\": 1.0, \"npv\": 0.9997813071368256, \"accuracy\": 0.9997813112829632, \"f1\": 0.14776515036104934, \"f2\": 0.0977708929894774, \"f0_5\": 0.3023890342355913, \"p4\": 0.2574796241795879, \"phi\": 0.2824167758579102}, {\"truth_threshold\": 32.859999265521765, \"match_probability\": 0.9999999998717213, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24194.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279767.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0795957376110751, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9204042623889249, \"precision\": 1.0, \"recall\": 0.0795957376110751, \"specificity\": 1.0, \"npv\": 0.9997812641444745, \"accuracy\": 0.9997812682820214, \"f1\": 0.14745470890280507, \"f2\": 0.09755346207132362, \"f0_5\": 0.30186880672361177, \"p4\": 0.2570082024909031, \"phi\": 0.2820963083227297}, {\"truth_threshold\": 32.87999926507473, \"match_probability\": 0.9999999998734873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24108.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279853.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07931280657715957, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9206871934228404, \"precision\": 1.0, \"recall\": 0.07931280657715957, \"specificity\": 1.0, \"npv\": 0.9997811969200785, \"accuracy\": 0.9997812010441851, \"f1\": 0.14696908272345147, \"f2\": 0.09721344052027821, \"f0_5\": 0.3010542142345146, \"p4\": 0.25627024171324175, \"phi\": 0.28159448270660997}, {\"truth_threshold\": 32.899999264627695, \"match_probability\": 0.999999999875229, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24062.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07916147137297219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9208385286270279, \"precision\": 1.0, \"recall\": 0.07916147137297219, \"specificity\": 1.0, \"npv\": 0.9997811609628471, \"accuracy\": 0.9997811650797611, \"f1\": 0.14670922465802702, \"f2\": 0.09703154916582386, \"f0_5\": 0.30061792713307295, \"p4\": 0.25587510293128357, \"phi\": 0.2813256969293728}, {\"truth_threshold\": 32.91999926418066, \"match_probability\": 0.9999999998769469, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24003.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 279958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07896736752412316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9210326324758769, \"precision\": 1.0, \"recall\": 0.07896736752412316, \"specificity\": 1.0, \"npv\": 0.9997811148437932, \"accuracy\": 0.999781118951478, \"f1\": 0.14637582173653205, \"f2\": 0.09679823397564377, \"f0_5\": 0.3000577538983881, \"p4\": 0.25536786985373233, \"phi\": 0.2809805735981536}, {\"truth_threshold\": 32.939999263733625, \"match_probability\": 0.999999999878641, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23933.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280028.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0787370748220989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9212629251779011, \"precision\": 1.0, \"recall\": 0.0787370748220989, \"specificity\": 1.0, \"npv\": 0.9997810601262772, \"accuracy\": 0.9997810642230066, \"f1\": 0.1459801033260749, \"f2\": 0.09652139054039557, \"f0_5\": 0.29939228357764586, \"p4\": 0.2547654480659205, \"phi\": 0.2805705546504837}, {\"truth_threshold\": 32.95999926328659, \"match_probability\": 0.9999999998803117, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23866.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280095.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07851665180730423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9214833481926957, \"precision\": 1.0, \"recall\": 0.07851665180730423, \"specificity\": 1.0, \"npv\": 0.9997810077538032, \"accuracy\": 0.9997810118400412, \"f1\": 0.1456011859913918, \"f2\": 0.09625638254107816, \"f0_5\": 0.2987544595355824, \"p4\": 0.25418821330922664, \"phi\": 0.280177545976406}, {\"truth_threshold\": 32.979999262839556, \"match_probability\": 0.9999999998819595, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23813.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07834228733291441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9216577126670856, \"precision\": 1.0, \"recall\": 0.07834228733291441, \"specificity\": 1.0, \"npv\": 0.9997809663248352, \"accuracy\": 0.9997809704027699, \"f1\": 0.14530133567641118, \"f2\": 0.0960467290548918, \"f0_5\": 0.29824930550858814, \"p4\": 0.2537311568638388, \"phi\": 0.2798662675882877}, {\"truth_threshold\": 32.99999926239252, \"match_probability\": 0.9999999998835846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23754.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280207.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0781481834840654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9218518165159346, \"precision\": 1.0, \"recall\": 0.0781481834840654, \"specificity\": 1.0, \"npv\": 0.9997809202057992, \"accuracy\": 0.999780924274487, \"f1\": 0.1449674259646339, \"f2\": 0.09581332012475012, \"f0_5\": 0.2976863327961261, \"p4\": 0.2532219025460372, \"phi\": 0.2795193424364592}, {\"truth_threshold\": 33.019999261945486, \"match_probability\": 0.9999999998851874, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23674.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280287.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07788499182460908, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9221150081753909, \"precision\": 1.0, \"recall\": 0.07788499182460908, \"specificity\": 1.0, \"npv\": 0.99978085767152, \"accuracy\": 0.9997808617276625, \"f1\": 0.14451447494925757, \"f2\": 0.09549679794888014, \"f0_5\": 0.29692191533072293, \"p4\": 0.25253062029523093, \"phi\": 0.2790482465921386}, {\"truth_threshold\": 33.03999926149845, \"match_probability\": 0.999999999886768, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23606.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280355.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07766127891407121, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9223387210859287, \"precision\": 1.0, \"recall\": 0.07766127891407121, \"specificity\": 1.0, \"npv\": 0.9997808045173889, \"accuracy\": 0.9997808085628617, \"f1\": 0.14412929263326282, \"f2\": 0.09522772197345597, \"f0_5\": 0.2962711949496091, \"p4\": 0.2519423342336974, \"phi\": 0.2786471889550646}, {\"truth_threshold\": 33.059999261051416, \"match_probability\": 0.9999999998883269, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23500.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0773125499652916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9226874500347084, \"precision\": 1.0, \"recall\": 0.0773125499652916, \"specificity\": 1.0, \"npv\": 0.9997807216594898, \"accuracy\": 0.9997807256883192, \"f1\": 0.14352854233023168, \"f2\": 0.09480822112343304, \"f0_5\": 0.2952550626820216, \"p4\": 0.2510240216717281, \"phi\": 0.27802085712700514}, {\"truth_threshold\": 33.07999926060438, \"match_probability\": 0.9999999998898643, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23438.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280523.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07710857642921295, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.922891423570787, \"precision\": 1.0, \"recall\": 0.07710857642921295, \"specificity\": 1.0, \"npv\": 0.9997806731954421, \"accuracy\": 0.9997806772145303, \"f1\": 0.14317697977086064, \"f2\": 0.09456281943899775, \"f0_5\": 0.2946597169315562, \"p4\": 0.25048617212719054, \"phi\": 0.2776538572603318}, {\"truth_threshold\": 33.09999926015735, \"match_probability\": 0.9999999998913806, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23385.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07693421195482315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9230657880451768, \"precision\": 1.0, \"recall\": 0.07693421195482315, \"specificity\": 1.0, \"npv\": 0.9997806317665018, \"accuracy\": 0.9997806357772591, \"f1\": 0.14287634490722356, \"f2\": 0.09435302111232065, \"f0_5\": 0.29415020339571474, \"p4\": 0.25002597350499867, \"phi\": 0.2773397465792652}, {\"truth_threshold\": 33.11999925971031, \"match_probability\": 0.999999999892876, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23308.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07668088998259645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9233191100174035, \"precision\": 1.0, \"recall\": 0.07668088998259645, \"specificity\": 1.0, \"npv\": 0.9997805715772926, \"accuracy\": 0.9997805755759406, \"f1\": 0.14243940000427782, \"f2\": 0.09404818779294227, \"f0_5\": 0.29340899764094536, \"p4\": 0.24935668561421162, \"phi\": 0.2768827622223091}, {\"truth_threshold\": 33.13999925926328, \"match_probability\": 0.9999999998943508, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23266.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280695.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0765427143613819, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9234572856386181, \"precision\": 1.0, \"recall\": 0.0765427143613819, \"specificity\": 1.0, \"npv\": 0.9997805387468179, \"accuracy\": 0.9997805427388577, \"f1\": 0.1422009797480037, \"f2\": 0.09388189910500279, \"f0_5\": 0.2930042188779044, \"p4\": 0.2489912707790455, \"phi\": 0.27663317986345415}, {\"truth_threshold\": 33.15999925881624, \"match_probability\": 0.9999999998958053, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23223.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07640124884442412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9235987511555759, \"precision\": 1.0, \"recall\": 0.07640124884442412, \"specificity\": 1.0, \"npv\": 0.9997805051346675, \"accuracy\": 0.9997805091199395, \"f1\": 0.14195681940437185, \"f2\": 0.09371163948357918, \"f0_5\": 0.29258944747803345, \"p4\": 0.24861690024777836, \"phi\": 0.2763774215861306}, {\"truth_threshold\": 33.17999925836921, \"match_probability\": 0.9999999998972398, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23125.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280836.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07607883906159014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9239211609384098, \"precision\": 1.0, \"recall\": 0.07607883906159014, \"specificity\": 1.0, \"npv\": 0.9997804285302403, \"accuracy\": 0.9997804325000796, \"f1\": 0.14140012106907662, \"f2\": 0.09332356176788927, \"f0_5\": 0.2916428097593458, \"p4\": 0.24776271692565766, \"phi\": 0.275793644450121}, {\"truth_threshold\": 33.19999925792217, \"match_probability\": 0.9999999998986545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23053.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280908.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07584196656807946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9241580334319205, \"precision\": 1.0, \"recall\": 0.07584196656807946, \"specificity\": 1.0, \"npv\": 0.999780372249444, \"accuracy\": 0.9997803762079376, \"f1\": 0.14099090558813995, \"f2\": 0.09303840432255465, \"f0_5\": 0.2909461270707494, \"p4\": 0.2471342958425706, \"phi\": 0.275363958367039}, {\"truth_threshold\": 33.21999925747514, \"match_probability\": 0.9999999999000497, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23024.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07574655959152654, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9242534404084735, \"precision\": 1.0, \"recall\": 0.07574655959152654, \"specificity\": 1.0, \"npv\": 0.9997803495807918, \"accuracy\": 0.9997803535347137, \"f1\": 0.14082603177515787, \"f2\": 0.09292353987672618, \"f0_5\": 0.29066523252966114, \"p4\": 0.24688097619114235, \"phi\": 0.27519070083845254}, {\"truth_threshold\": 33.2399992570281, \"match_probability\": 0.9999999999014259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22973.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 280988.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07557877490862315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9244212250913768, \"precision\": 1.0, \"recall\": 0.07557877490862315, \"specificity\": 1.0, \"npv\": 0.9997803097152335, \"accuracy\": 0.9997803136611132, \"f1\": 0.14053601032624322, \"f2\": 0.09272152384089014, \"f0_5\": 0.2901708462484811, \"p4\": 0.24643519626110652, \"phi\": 0.27488574169287344}, {\"truth_threshold\": 33.25999925658107, \"match_probability\": 0.9999999999027829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22913.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281048.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07538138116403091, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9246186188359691, \"precision\": 1.0, \"recall\": 0.07538138116403091, \"specificity\": 1.0, \"npv\": 0.9997802628145805, \"accuracy\": 0.9997802667509949, \"f1\": 0.14019469275623023, \"f2\": 0.0924838366200958, \"f0_5\": 0.2895885625598754, \"p4\": 0.24591028067996226, \"phi\": 0.27452653254558274}, {\"truth_threshold\": 33.27999925613403, \"match_probability\": 0.9999999999041214, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22875.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07525636512578916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9247436348742109, \"precision\": 1.0, \"recall\": 0.07525636512578916, \"specificity\": 1.0, \"npv\": 0.9997802331108361, \"accuracy\": 0.9997802370412532, \"f1\": 0.13997846014514925, \"f2\": 0.09233328947081622, \"f0_5\": 0.28921941733824574, \"p4\": 0.2455775718062818, \"phi\": 0.2742987901331971}, {\"truth_threshold\": 33.299999255687, \"match_probability\": 0.9999999999054413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22840.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281121.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07514121877477703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.924858781225223, \"precision\": 1.0, \"recall\": 0.07514121877477703, \"specificity\": 1.0, \"npv\": 0.9997802057521256, \"accuracy\": 0.9997802096770175, \"f1\": 0.1397792540414503, \"f2\": 0.0921946194509657, \"f0_5\": 0.2888791640211373, \"p4\": 0.24527094924161627, \"phi\": 0.27408885998360466}, {\"truth_threshold\": 33.31999925523996, \"match_probability\": 0.9999999999067432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22756.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281205.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0748648675323479, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9251351324676521, \"precision\": 1.0, \"recall\": 0.0748648675323479, \"specificity\": 1.0, \"npv\": 0.9997801400912265, \"accuracy\": 0.9997801440028518, \"f1\": 0.13930098525635337, \"f2\": 0.09186177942838689, \"f0_5\": 0.2880615719584288, \"p4\": 0.24453434926700363, \"phi\": 0.27358437044064104}, {\"truth_threshold\": 33.33999925479293, \"match_probability\": 0.999999999908027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22699.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281262.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07467734347498528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9253226565250148, \"precision\": 1.0, \"recall\": 0.07467734347498528, \"specificity\": 1.0, \"npv\": 0.9997800955356213, \"accuracy\": 0.9997800994382394, \"f1\": 0.1389763056388906, \"f2\": 0.09163589798658585, \"f0_5\": 0.2875059846943816, \"p4\": 0.24403394527046393, \"phi\": 0.27324150781637696}, {\"truth_threshold\": 33.359999254345894, \"match_probability\": 0.9999999999092932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22646.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281315.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07450297900059547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9254970209994046, \"precision\": 1.0, \"recall\": 0.07450297900059547, \"specificity\": 1.0, \"npv\": 0.9997800541067289, \"accuracy\": 0.9997800580009681, \"f1\": 0.13867430887886664, \"f2\": 0.0914258492196142, \"f0_5\": 0.2869888098949423, \"p4\": 0.24356824445703798, \"phi\": 0.2729223193077617}, {\"truth_threshold\": 33.37999925389886, \"match_probability\": 0.999999999910542, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22594.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07433190442194887, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9256680955780512, \"precision\": 1.0, \"recall\": 0.07433190442194887, \"specificity\": 1.0, \"npv\": 0.999780013459517, \"accuracy\": 0.9997800173455322, \"f1\": 0.13837791489948095, \"f2\": 0.09121974616411964, \"f0_5\": 0.2864808526716996, \"p4\": 0.24311094326281274, \"phi\": 0.2726087900333508}, {\"truth_threshold\": 33.399999253451824, \"match_probability\": 0.9999999999117737, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22494.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281467.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07400291484762848, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9259970851523716, \"precision\": 1.0, \"recall\": 0.07400291484762848, \"specificity\": 1.0, \"npv\": 0.999779935291811, \"accuracy\": 0.9997799391620017, \"f1\": 0.13780766108652034, \"f2\": 0.09082334548402779, \"f0_5\": 0.28550250420752554, \"p4\": 0.24223043821680748, \"phi\": 0.27200483344559784}, {\"truth_threshold\": 33.41999925300479, \"match_probability\": 0.9999999999129883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22434.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281527.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07380552110303625, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9261944788969637, \"precision\": 1.0, \"recall\": 0.07380552110303625, \"specificity\": 1.0, \"npv\": 0.9997798883911932, \"accuracy\": 0.9997798922518834, \"f1\": 0.13746534107446498, \"f2\": 0.09058547434421027, \"f0_5\": 0.28491454087788326, \"p4\": 0.24170145212254462, \"phi\": 0.2716418149899743}, {\"truth_threshold\": 33.439999252557755, \"match_probability\": 0.9999999999141862, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22384.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281577.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07364102631587605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9263589736841239, \"precision\": 1.0, \"recall\": 0.07364102631587605, \"specificity\": 1.0, \"npv\": 0.9997798493073485, \"accuracy\": 0.9997798531601181, \"f1\": 0.137179978243883, \"f2\": 0.0903872307846374, \"f0_5\": 0.2844240235630767, \"p4\": 0.24126023837265656, \"phi\": 0.27133892863524955}, {\"truth_threshold\": 33.45999925211072, \"match_probability\": 0.9999999999153676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22320.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281641.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.073430472988311, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.926569527011689, \"precision\": 1.0, \"recall\": 0.073430472988311, \"specificity\": 1.0, \"npv\": 0.9997797992800317, \"accuracy\": 0.9997798031226585, \"f1\": 0.13681458620023845, \"f2\": 0.09013345566500076, \"f0_5\": 0.28379543333477436, \"p4\": 0.24069496402890772, \"phi\": 0.27095074007149594}, {\"truth_threshold\": 33.479999251663685, \"match_probability\": 0.9999999999165328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22240.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281721.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0731672813288547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9268327186711454, \"precision\": 1.0, \"recall\": 0.0731672813288547, \"specificity\": 1.0, \"npv\": 0.9997797367458928, \"accuracy\": 0.9997797405758341, \"f1\": 0.13635764451978993, \"f2\": 0.0898161998701219, \"f0_5\": 0.28300854370216916, \"p4\": 0.23998754758094668, \"phi\": 0.2704647209256228}, {\"truth_threshold\": 33.49999925121665, \"match_probability\": 0.9999999999176818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22184.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281777.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07298304716723528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9270169528327648, \"precision\": 1.0, \"recall\": 0.07298304716723528, \"specificity\": 1.0, \"npv\": 0.9997796929720002, \"accuracy\": 0.9997796967930569, \"f1\": 0.13603765196461695, \"f2\": 0.08959409641785161, \"f0_5\": 0.28245695790902403, \"p4\": 0.23949181074856715, \"phi\": 0.2701239872521866}, {\"truth_threshold\": 33.519999250769615, \"match_probability\": 0.9999999999188152, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22097.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281864.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07269682623757653, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9273031737624234, \"precision\": 1.0, \"recall\": 0.07269682623757653, \"specificity\": 1.0, \"npv\": 0.9997796249661389, \"accuracy\": 0.9997796287733853, \"f1\": 0.1355403026455416, \"f2\": 0.08924900298156374, \"f0_5\": 0.2815987806774071, \"p4\": 0.23872075576281718, \"phi\": 0.2695937789935681}, {\"truth_threshold\": 33.53999925032258, \"match_probability\": 0.9999999999199329, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22037.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 281924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0724994324929843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9275005675070157, \"precision\": 1.0, \"recall\": 0.0724994324929843, \"specificity\": 1.0, \"npv\": 0.9997795780655503, \"accuracy\": 0.999779581863267, \"f1\": 0.1351971484487635, \"f2\": 0.08901097924598568, \"f0_5\": 0.2810060467880105, \"p4\": 0.23818835999396737, \"phi\": 0.26922750979019155}, {\"truth_threshold\": 33.559999249875546, \"match_probability\": 0.9999999999210352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21949.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282012.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07220992166758236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9277900783324177, \"precision\": 1.0, \"recall\": 0.07220992166758236, \"specificity\": 1.0, \"npv\": 0.9997795092780284, \"accuracy\": 0.99977951306176, \"f1\": 0.13469362707495935, \"f2\": 0.08866183602589447, \"f0_5\": 0.28013539005046495, \"p4\": 0.23740657531859322, \"phi\": 0.2686894118677183}, {\"truth_threshold\": 33.57999924942851, \"match_probability\": 0.9999999999221223, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21906.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282055.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07206845615062459, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9279315438493754, \"precision\": 1.0, \"recall\": 0.07206845615062459, \"specificity\": 1.0, \"npv\": 0.9997794756659472, \"accuracy\": 0.999779479442842, \"f1\": 0.13444748931312467, \"f2\": 0.08849121389618259, \"f0_5\": 0.2797093862124443, \"p4\": 0.2370241607710673, \"phi\": 0.26842608536117674}, {\"truth_threshold\": 33.599999248981476, \"match_probability\": 0.9999999999231944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21852.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282109.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07189080178049158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9281091982195084, \"precision\": 1.0, \"recall\": 0.07189080178049158, \"specificity\": 1.0, \"npv\": 0.9997794334554299, \"accuracy\": 0.9997794372237354, \"f1\": 0.13413829405210964, \"f2\": 0.08827692745229847, \"f0_5\": 0.2791738742721064, \"p4\": 0.23654354103101088, \"phi\": 0.2680950299329633}, {\"truth_threshold\": 33.61999924853444, \"match_probability\": 0.9999999999242519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21804.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282157.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07173288678481779, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9282671132151822, \"precision\": 1.0, \"recall\": 0.07173288678481779, \"specificity\": 1.0, \"npv\": 0.999779395934973, \"accuracy\": 0.9997793996956408, \"f1\": 0.13386336776510674, \"f2\": 0.08808643491525862, \"f0_5\": 0.27869736717649557, \"p4\": 0.23611596954713707, \"phi\": 0.2678004148958641}, {\"truth_threshold\": 33.639999248087406, \"match_probability\": 0.9999999999252948, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21749.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282212.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07155194251894158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9284480574810584, \"precision\": 1.0, \"recall\": 0.07155194251894158, \"specificity\": 1.0, \"npv\": 0.9997793529427863, \"accuracy\": 0.999779356694699, \"f1\": 0.13354824844186547, \"f2\": 0.08786814405058851, \"f0_5\": 0.278150794077098, \"p4\": 0.23562563383704643, \"phi\": 0.2674624362286915}, {\"truth_threshold\": 33.65999924764037, \"match_probability\": 0.9999999999263233, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21672.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07129862054671487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9287013794532851, \"precision\": 1.0, \"recall\": 0.07129862054671487, \"specificity\": 1.0, \"npv\": 0.9997792927537312, \"accuracy\": 0.9997792964933804, \"f1\": 0.13310690255594487, \"f2\": 0.08756250424236939, \"f0_5\": 0.2773845574927876, \"p4\": 0.23493842706209472, \"phi\": 0.266988547365821}, {\"truth_threshold\": 33.67999924719334, \"match_probability\": 0.9999999999273376, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21593.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07103871878300176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9289612812169983, \"precision\": 1.0, \"recall\": 0.07103871878300176, \"specificity\": 1.0, \"npv\": 0.9997792310013315, \"accuracy\": 0.9997792347283913, \"f1\": 0.1326538761618656, \"f2\": 0.08724888620592403, \"f0_5\": 0.2765971619104713, \"p4\": 0.23423247586917545, \"phi\": 0.266501473985022}, {\"truth_threshold\": 33.6999992467463, \"match_probability\": 0.9999999999283379, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21533.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282428.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07084132503840954, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9291586749615904, \"precision\": 1.0, \"recall\": 0.07084132503840954, \"specificity\": 1.0, \"npv\": 0.9997791841007799, \"accuracy\": 0.9997791878182729, \"f1\": 0.13230965854977358, \"f2\": 0.08701066853513521, \"f0_5\": 0.2759982875878316, \"p4\": 0.23369570374301651, \"phi\": 0.2661309492477702}, {\"truth_threshold\": 33.71999924629927, \"match_probability\": 0.9999999999293245, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21475.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282486.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07065051108530371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9293494889146963, \"precision\": 1.0, \"recall\": 0.07065051108530371, \"specificity\": 1.0, \"npv\": 0.9997791387635842, \"accuracy\": 0.9997791424718252, \"f1\": 0.13197679420838507, \"f2\": 0.08678036949242678, \"f0_5\": 0.2754186748610402, \"p4\": 0.23317632538024274, \"phi\": 0.26577228434521155}, {\"truth_threshold\": 33.73999924585223, \"match_probability\": 0.9999999999302975, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21401.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07040705880030662, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9295929411996934, \"precision\": 1.0, \"recall\": 0.07040705880030662, \"specificity\": 1.0, \"npv\": 0.9997790809195818, \"accuracy\": 0.9997790846160125, \"f1\": 0.13155193292394318, \"f2\": 0.08648650833100963, \"f0_5\": 0.2746781666730841, \"p4\": 0.23251295743630923, \"phi\": 0.26531397350614894}, {\"truth_threshold\": 33.7599992454052, \"match_probability\": 0.9999999999312571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21347.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07022940443017361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9297705955698264, \"precision\": 1.0, \"recall\": 0.07022940443017361, \"specificity\": 1.0, \"npv\": 0.9997790387090978, \"accuracy\": 0.9997790423969061, \"f1\": 0.1312417770236207, \"f2\": 0.08627204691919033, \"f0_5\": 0.27413708523715224, \"p4\": 0.2320283729778861, \"phi\": 0.26497903020864016}, {\"truth_threshold\": 33.77999924495816, \"match_probability\": 0.9999999999322036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.07012083787064788, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9298791621293521, \"precision\": 1.0, \"recall\": 0.07012083787064788, \"specificity\": 1.0, \"npv\": 0.9997790129138038, \"accuracy\": 0.9997790165963409, \"f1\": 0.13105218661132886, \"f2\": 0.0861409779510782, \"f0_5\": 0.27380612871483, \"p4\": 0.23173202793500342, \"phi\": 0.2647741340671426}, {\"truth_threshold\": 33.79999924451113, \"match_probability\": 0.9999999999331369, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21258.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282703.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06993660370902846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9300633962909716, \"precision\": 1.0, \"recall\": 0.06993660370902846, \"specificity\": 1.0, \"npv\": 0.9997789691399745, \"accuracy\": 0.9997789728135638, \"f1\": 0.1307303693818627, \"f2\": 0.08591854188256101, \"f0_5\": 0.27324399153712275, \"p4\": 0.23122877422918434, \"phi\": 0.2644260682333786}, {\"truth_threshold\": 33.81999924406409, \"match_probability\": 0.9999999999340574, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21173.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282788.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06965696257085613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9303430374291438, \"precision\": 1.0, \"recall\": 0.06965696257085613, \"specificity\": 1.0, \"npv\": 0.9997789026975625, \"accuracy\": 0.9997789063575628, \"f1\": 0.13024168496681368, \"f2\": 0.08558087722319095, \"f0_5\": 0.2723895094081353, \"p4\": 0.2304640276796833, \"phi\": 0.2638968768370246}, {\"truth_threshold\": 33.83999924361706, \"match_probability\": 0.9999999999349652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21104.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282857.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06942995976457506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9305700402354249, \"precision\": 1.0, \"recall\": 0.06942995976457506, \"specificity\": 1.0, \"npv\": 0.999778848761964, \"accuracy\": 0.9997788524109267, \"f1\": 0.1298448002707151, \"f2\": 0.08530673884431682, \"f0_5\": 0.27169477080259646, \"p4\": 0.22984245247431723, \"phi\": 0.26346651636026985}, {\"truth_threshold\": 33.85999924317002, \"match_probability\": 0.9999999999358606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21033.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 282928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06919637716680758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9308036228331924, \"precision\": 1.0, \"recall\": 0.06919637716680758, \"specificity\": 1.0, \"npv\": 0.9997787932630208, \"accuracy\": 0.99977879690062, \"f1\": 0.1294362357458907, \"f2\": 0.08502462249682062, \"f0_5\": 0.27097886331369025, \"p4\": 0.22920212872218193, \"phi\": 0.26302294664535214}, {\"truth_threshold\": 33.87999924272299, \"match_probability\": 0.9999999999367437, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20936.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0688772572797168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9311227427202832, \"precision\": 1.0, \"recall\": 0.0688772572797168, \"specificity\": 1.0, \"npv\": 0.9997787174405309, \"accuracy\": 0.9997787210625954, \"f1\": 0.12887776741551937, \"f2\": 0.08463914358252883, \"f0_5\": 0.26999909725177645, \"p4\": 0.22832611802826663, \"phi\": 0.2624157311289412}, {\"truth_threshold\": 33.89999924227595, \"match_probability\": 0.9999999999376146, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20892.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06873250186701584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9312674981329842, \"precision\": 1.0, \"recall\": 0.06873250186701584, \"specificity\": 1.0, \"npv\": 0.9997786830468279, \"accuracy\": 0.9997786866618419, \"f1\": 0.12862433162076387, \"f2\": 0.08446426723245705, \"f0_5\": 0.2695540204733065, \"p4\": 0.2279282938775798, \"phi\": 0.26213982947869396}, {\"truth_threshold\": 33.91999924182892, \"match_probability\": 0.9999999999384734, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20851.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283110.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06859761614154447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9314023838584555, \"precision\": 1.0, \"recall\": 0.06859761614154447, \"specificity\": 1.0, \"npv\": 0.9997786509981523, \"accuracy\": 0.9997786546065944, \"f1\": 0.12838811373964015, \"f2\": 0.08430130306987575, \"f0_5\": 0.2691389258193177, \"p4\": 0.2275573361758907, \"phi\": 0.26188247770265655}, {\"truth_threshold\": 33.939999241381884, \"match_probability\": 0.9999999999393204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20800.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06842983145864108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9315701685413589, \"precision\": 1.0, \"recall\": 0.06842983145864108, \"specificity\": 1.0, \"npv\": 0.9997786111327295, \"accuracy\": 0.9997786147329938, \"f1\": 0.12809419850289905, \"f2\": 0.08409857646986521, \"f0_5\": 0.2686220977836094, \"p4\": 0.22709555334422388, \"phi\": 0.2615620038456789}, {\"truth_threshold\": 33.95999924093485, \"match_probability\": 0.9999999999401559, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20750.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283211.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06826533667148088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9317346633285191, \"precision\": 1.0, \"recall\": 0.06826533667148088, \"specificity\": 1.0, \"npv\": 0.9997785720489846, \"accuracy\": 0.9997785756412285, \"f1\": 0.12780595668147984, \"f2\": 0.08389980866800259, \"f0_5\": 0.2681148746256083, \"p4\": 0.22664245047573406, \"phi\": 0.2612474321746653}, {\"truth_threshold\": 33.979999240487814, \"match_probability\": 0.9999999999409798, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20696.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06808768230134787, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9319123176986521, \"precision\": 1.0, \"recall\": 0.06808768230134787, \"specificity\": 1.0, \"npv\": 0.9997785298385435, \"accuracy\": 0.999778533422122, \"f1\": 0.12749455579272895, \"f2\": 0.08368512138709626, \"f0_5\": 0.26756648437601005, \"p4\": 0.22615268226125676, \"phi\": 0.2609072687974703}, {\"truth_threshold\": 33.99999924004078, \"match_probability\": 0.9999999999417923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20610.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283351.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06780475126743234, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9321952487325676, \"precision\": 1.0, \"recall\": 0.06780475126743234, \"specificity\": 1.0, \"npv\": 0.9997784626145152, \"accuracy\": 0.9997784661842857, \"f1\": 0.12699840712817842, \"f2\": 0.08334317330042201, \"f0_5\": 0.26669185638753523, \"p4\": 0.22537178539169175, \"phi\": 0.2603646096920876}, {\"truth_threshold\": 34.019999239593744, \"match_probability\": 0.9999999999425937, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20571.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283390.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06767644533344738, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9323235546665526, \"precision\": 1.0, \"recall\": 0.06767644533344738, \"specificity\": 1.0, \"npv\": 0.999778432129203, \"accuracy\": 0.9997784356927087, \"f1\": 0.12677332281562373, \"f2\": 0.08318808814192645, \"f0_5\": 0.26629470931662547, \"p4\": 0.22501729456437258, \"phi\": 0.26011814701698865}, {\"truth_threshold\": 34.03999923914671, \"match_probability\": 0.999999999943384, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20477.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283484.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06736719513358622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9326328048664138, \"precision\": 1.0, \"recall\": 0.06736719513358622, \"specificity\": 1.0, \"npv\": 0.9997783586517915, \"accuracy\": 0.99977836220019, \"f1\": 0.12623058951170948, \"f2\": 0.08281425293269305, \"f0_5\": 0.26533616330930965, \"p4\": 0.22416194772812792, \"phi\": 0.25952314690145034}, {\"truth_threshold\": 34.059999238699675, \"match_probability\": 0.9999999999441634, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20431.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283530.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06721585992939884, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9327841400706012, \"precision\": 1.0, \"recall\": 0.06721585992939884, \"specificity\": 1.0, \"npv\": 0.9997783226947643, \"accuracy\": 0.999778326235766, \"f1\": 0.1259648819946238, \"f2\": 0.0826312915815656, \"f0_5\": 0.2648664065234583, \"p4\": 0.22374289240866663, \"phi\": 0.2592314789887613}, {\"truth_threshold\": 34.07999923825264, \"match_probability\": 0.9999999999449322, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20344.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0669296389997401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9330703610002599, \"precision\": 1.0, \"recall\": 0.0669296389997401, \"specificity\": 1.0, \"npv\": 0.9997782546890894, \"accuracy\": 0.9997782582160943, \"f1\": 0.12546214211930126, \"f2\": 0.08228521875313463, \"f0_5\": 0.2639767268650558, \"p4\": 0.2229494648124408, \"phi\": 0.25867894708717787}, {\"truth_threshold\": 34.099999237805605, \"match_probability\": 0.9999999999456903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20229.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283732.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06655130098927164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9334486990107284, \"precision\": 1.0, \"recall\": 0.06655130098927164, \"specificity\": 1.0, \"npv\": 0.9997781647965449, \"accuracy\": 0.9997781683050342, \"f1\": 0.12479718683488078, \"f2\": 0.0818276914065755, \"f0_5\": 0.262798244634, \"p4\": 0.22189893817217585, \"phi\": 0.2579467727417354}, {\"truth_threshold\": 34.11999923735857, \"match_probability\": 0.999999999946438, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06630455880853135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9336954411914686, \"precision\": 1.0, \"recall\": 0.06630455880853135, \"specificity\": 1.0, \"npv\": 0.9997781061709811, \"accuracy\": 0.9997781096673863, \"f1\": 0.12436326612467796, \"f2\": 0.08152925813795815, \"f0_5\": 0.26202815040941085, \"p4\": 0.22121274043184203, \"phi\": 0.25746814606101454}, {\"truth_threshold\": 34.139999236911535, \"match_probability\": 0.9999999999471754, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20101.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283860.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06613019433414155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9338698056658584, \"precision\": 1.0, \"recall\": 0.06613019433414155, \"specificity\": 1.0, \"npv\": 0.9997780647422535, \"accuracy\": 0.9997780682301151, \"f1\": 0.12405650770531565, \"f2\": 0.08131834345379446, \"f0_5\": 0.2614832255798525, \"p4\": 0.22072731615046562, \"phi\": 0.2571293793256951}, {\"truth_threshold\": 34.1599992364645, \"match_probability\": 0.9999999999479027, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20045.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06594596017252213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9340540398274779, \"precision\": 1.0, \"recall\": 0.06594596017252213, \"specificity\": 1.0, \"npv\": 0.9997780209685073, \"accuracy\": 0.999778024447338, \"f1\": 0.1237322765627797, \"f2\": 0.08109547054792138, \"f0_5\": 0.26090680245014203, \"p4\": 0.2202139543557417, \"phi\": 0.2567709515349277}, {\"truth_threshold\": 34.179999236017466, \"match_probability\": 0.9999999999486199, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19990.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 283971.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06576501590664592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.934234984093354, \"precision\": 1.0, \"recall\": 0.06576501590664592, \"specificity\": 1.0, \"npv\": 0.9997779779764389, \"accuracy\": 0.9997779814463962, \"f1\": 0.12341372614994243, \"f2\": 0.08087655785485753, \"f0_5\": 0.26034001786825933, \"p4\": 0.21970929837028677, \"phi\": 0.25641843659287605}, {\"truth_threshold\": 34.19999923557043, \"match_probability\": 0.9999999999493273, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19921.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06553801310036485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9344619868996351, \"precision\": 1.0, \"recall\": 0.06553801310036485, \"specificity\": 1.0, \"npv\": 0.99977792404094, \"accuracy\": 0.99977792749976, \"f1\": 0.12301393717465002, \"f2\": 0.0806018943731211, \"f0_5\": 0.2596280415488277, \"p4\": 0.21907553694554519, \"phi\": 0.25597550406875014}, {\"truth_threshold\": 34.219999235123396, \"match_probability\": 0.9999999999500249, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19885.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284076.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06541957685360951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9345804231463904, \"precision\": 1.0, \"recall\": 0.06541957685360951, \"specificity\": 1.0, \"npv\": 0.9997778959006821, \"accuracy\": 0.999777899353689, \"f1\": 0.12280528399300902, \"f2\": 0.08045857951055611, \"f0_5\": 0.25925616882354935, \"p4\": 0.21874459234778912, \"phi\": 0.2557441043258176}, {\"truth_threshold\": 34.23999923467636, \"match_probability\": 0.9999999999507129, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19810.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284151.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06517283467286922, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9348271653271308, \"precision\": 1.0, \"recall\": 0.06517283467286922, \"specificity\": 1.0, \"npv\": 0.9997778372751499, \"accuracy\": 0.9997778407160411, \"f1\": 0.12237044083627008, \"f2\": 0.08015998005914277, \"f0_5\": 0.2584805363242789, \"p4\": 0.2180544925973008, \"phi\": 0.2552613478345911}, {\"truth_threshold\": 34.259999234229326, \"match_probability\": 0.9999999999513914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19727.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0648997733261833, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9351002266738168, \"precision\": 1.0, \"recall\": 0.0648997733261833, \"specificity\": 1.0, \"npv\": 0.9997777723962354, \"accuracy\": 0.9997777758237107, \"f1\": 0.12188897951113419, \"f2\": 0.079829487742914, \"f0_5\": 0.2576207527901188, \"p4\": 0.21728978530454995, \"phi\": 0.254726030874491}, {\"truth_threshold\": 34.27999923378229, \"match_probability\": 0.9999999999520607, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19676.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284285.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06473198864327989, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9352680113567201, \"precision\": 1.0, \"recall\": 0.06473198864327989, \"specificity\": 1.0, \"npv\": 0.9997777325308826, \"accuracy\": 0.9997777359501101, \"f1\": 0.12159301933956872, \"f2\": 0.07962639212639212, \"f0_5\": 0.25709171207191667, \"p4\": 0.216819384514272, \"phi\": 0.254396542484353}, {\"truth_threshold\": 34.29999923333526, \"match_probability\": 0.9999999999527207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19630.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284331.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06458065343909251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9354193465609075, \"precision\": 1.0, \"recall\": 0.06458065343909251, \"specificity\": 1.0, \"npv\": 0.9997776965739005, \"accuracy\": 0.9997776999856861, \"f1\": 0.12132599485152554, \"f2\": 0.07944319346259007, \"f0_5\": 0.2566140540314421, \"p4\": 0.21639476116382353, \"phi\": 0.2540989904320229}, {\"truth_threshold\": 34.31999923288822, \"match_probability\": 0.9999999999533715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19564.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284397.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06436352032004106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9356364796799589, \"precision\": 1.0, \"recall\": 0.06436352032004106, \"specificity\": 1.0, \"npv\": 0.9997776449834522, \"accuracy\": 0.9997776483845559, \"f1\": 0.12094274012827448, \"f2\": 0.07918031937627083, \"f0_5\": 0.2559279152941915, \"p4\": 0.21578495447037543, \"phi\": 0.2536714583243752}, {\"truth_threshold\": 34.33999923244119, \"match_probability\": 0.9999999999540136, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19483.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284478.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06409703876484155, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9359029612351585, \"precision\": 1.0, \"recall\": 0.06409703876484155, \"specificity\": 1.0, \"npv\": 0.9997775816679095, \"accuracy\": 0.9997775850558961, \"f1\": 0.12047216828879188, \"f2\": 0.078857662788881, \"f0_5\": 0.25508453938668685, \"p4\": 0.2150356446078142, \"phi\": 0.25314577304072755}, {\"truth_threshold\": 34.35999923199415, \"match_probability\": 0.9999999999546466, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19424.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06390293491599251, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9360970650840075, \"precision\": 1.0, \"recall\": 0.06390293491599251, \"specificity\": 1.0, \"npv\": 0.9997775355491859, \"accuracy\": 0.9997775389276131, \"f1\": 0.12012925769593519, \"f2\": 0.07862261468766292, \"f0_5\": 0.25446932717073184, \"p4\": 0.21448921813801902, \"phi\": 0.25276217831129527}, {\"truth_threshold\": 34.37999923154712, \"match_probability\": 0.999999999955271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19357.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284604.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06368251190119785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9363174880988021, \"precision\": 1.0, \"recall\": 0.06368251190119785, \"specificity\": 1.0, \"npv\": 0.9997774831770811, \"accuracy\": 0.9997774865446476, \"f1\": 0.11973969899603486, \"f2\": 0.07835566842967258, \"f0_5\": 0.25376977311878424, \"p4\": 0.2138680520232107, \"phi\": 0.25232586365843296}, {\"truth_threshold\": 34.39999923110008, \"match_probability\": 0.9999999999558868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19350.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284611.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06365948263099543, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9363405173690046, \"precision\": 1.0, \"recall\": 0.06365948263099543, \"specificity\": 1.0, \"npv\": 0.9997774777053691, \"accuracy\": 0.9997774810718004, \"f1\": 0.11969898951783267, \"f2\": 0.07832777685124766, \"f0_5\": 0.25369662865369036, \"p4\": 0.21380311427079157, \"phi\": 0.25228023501028646}, {\"truth_threshold\": 34.41999923065305, \"match_probability\": 0.9999999999564941, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19283.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284678.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06343905961620076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9365609403837992, \"precision\": 1.0, \"recall\": 0.06343905961620076, \"specificity\": 1.0, \"npv\": 0.9997774253332703, \"accuracy\": 0.999777428688835, \"f1\": 0.11930925245325513, \"f2\": 0.07806079860613524, \"f0_5\": 0.25299598785598265, \"p4\": 0.21318118582245313, \"phi\": 0.25184308544935086}, {\"truth_threshold\": 34.43999923020601, \"match_probability\": 0.9999999999570931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19199.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284762.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06316270837377164, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9368372916262284, \"precision\": 1.0, \"recall\": 0.06316270837377164, \"specificity\": 1.0, \"npv\": 0.9997773596727365, \"accuracy\": 0.9997773630146694, \"f1\": 0.11882039856417874, \"f2\": 0.07772603868853149, \"f0_5\": 0.2521161790853484, \"p4\": 0.212400477649509, \"phi\": 0.2512939430382445}, {\"truth_threshold\": 34.45999922975898, \"match_probability\": 0.9999999999576838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06297847421215222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9370215257878478, \"precision\": 1.0, \"recall\": 0.06297847421215222, \"specificity\": 1.0, \"npv\": 0.999777315899052, \"accuracy\": 0.9997773192318922, \"f1\": 0.11849435475883927, \"f2\": 0.07750284011086757, \"f0_5\": 0.25152877674209595, \"p4\": 0.21187940062113314, \"phi\": 0.25092718048717483}, {\"truth_threshold\": 34.47999922931194, \"match_probability\": 0.9999999999582664, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19067.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284894.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06272844213566872, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9372715578643313, \"precision\": 1.0, \"recall\": 0.06272844213566872, \"specificity\": 1.0, \"npv\": 0.999777256491915, \"accuracy\": 0.999777259812409, \"f1\": 0.11805168592196343, \"f2\": 0.07719989537707575, \"f0_5\": 0.2507304808418085, \"p4\": 0.21117144922329673, \"phi\": 0.25042857221653186}, {\"truth_threshold\": 34.49999922886491, \"match_probability\": 0.9999999999588409, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19014.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 284947.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06255407766127892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.937445922338721, \"precision\": 1.0, \"recall\": 0.06255407766127892, \"specificity\": 1.0, \"npv\": 0.9997772150632578, \"accuracy\": 0.9997772183751378, \"f1\": 0.11774285935443919, \"f2\": 0.07698860921660629, \"f0_5\": 0.2501730185754848, \"p4\": 0.21067721699137068, \"phi\": 0.2500802702234708}, {\"truth_threshold\": 34.51999922841787, \"match_probability\": 0.9999999999594076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18951.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285010.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06234681422945707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9376531857705429, \"precision\": 1.0, \"recall\": 0.06234681422945707, \"specificity\": 1.0, \"npv\": 0.9997771658178772, \"accuracy\": 0.9997771691195135, \"f1\": 0.1173756317510653, \"f2\": 0.07673743414898829, \"f0_5\": 0.24950956512580147, \"p4\": 0.21008916674600023, \"phi\": 0.24966561883467311}, {\"truth_threshold\": 34.53999922797084, \"match_probability\": 0.9999999999599665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18912.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285049.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06221850829547212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9377814917045278, \"precision\": 1.0, \"recall\": 0.06221850829547212, \"specificity\": 1.0, \"npv\": 0.9997771353326441, \"accuracy\": 0.9997771386279366, \"f1\": 0.11714822856045566, \"f2\": 0.07658193197684401, \"f0_5\": 0.2490984144211544, \"p4\": 0.20972482679721588, \"phi\": 0.24940858443188652}, {\"truth_threshold\": 34.559999227523804, \"match_probability\": 0.9999999999605176, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18875.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.062096782152973574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9379032178470265, \"precision\": 1.0, \"recall\": 0.062096782152973574, \"specificity\": 1.0, \"npv\": 0.999777106410758, \"accuracy\": 0.9997771097000303, \"f1\": 0.11693243628343802, \"f2\": 0.07643439519437216, \"f0_5\": 0.24870803587193413, \"p4\": 0.209378952377432, \"phi\": 0.2491644861899848}, {\"truth_threshold\": 34.57999922707677, \"match_probability\": 0.9999999999610611, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18838.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285123.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06197505601047503, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.938024943989525, \"precision\": 1.0, \"recall\": 0.06197505601047503, \"specificity\": 1.0, \"npv\": 0.9997770774888736, \"accuracy\": 0.9997770807721239, \"f1\": 0.1167165945371578, \"f2\": 0.0762868495693628, \"f0_5\": 0.2483173526876221, \"p4\": 0.20903286493841935, \"phi\": 0.24892014859259984}, {\"truth_threshold\": 34.599999226629734, \"match_probability\": 0.9999999999615973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18794.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285167.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06183030059777406, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9381696994022259, \"precision\": 1.0, \"recall\": 0.06183030059777406, \"specificity\": 1.0, \"npv\": 0.9997770430952835, \"accuracy\": 0.9997770463713704, \"f1\": 0.1164598534492107, \"f2\": 0.07611137839593468, \"f0_5\": 0.2478523594373538, \"p4\": 0.20862102394212295, \"phi\": 0.24862927242248664}, {\"truth_threshold\": 34.6199992261827, \"match_probability\": 0.999999999962126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18708.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285253.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06154736956385852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9384526304361415, \"precision\": 1.0, \"recall\": 0.06154736956385852, \"specificity\": 1.0, \"npv\": 0.9997769758714551, \"accuracy\": 0.9997769791335342, \"f1\": 0.1159578391478574, \"f2\": 0.07576837589668155, \"f0_5\": 0.24694226134062666, \"p4\": 0.20781519011318045, \"phi\": 0.2480597569445663}, {\"truth_threshold\": 34.639999225735664, \"match_probability\": 0.9999999999626473, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18670.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285291.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06142235352561677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9385776464743832, \"precision\": 1.0, \"recall\": 0.06142235352561677, \"specificity\": 1.0, \"npv\": 0.9997769461679059, \"accuracy\": 0.9997769494237926, \"f1\": 0.1157359336207618, \"f2\": 0.07561680142955042, \"f0_5\": 0.24653959819459595, \"p4\": 0.20745875601891842, \"phi\": 0.24780769365434693}, {\"truth_threshold\": 34.65999922528863, \"match_probability\": 0.9999999999631616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18615.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285346.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06124140925974056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9387585907402595, \"precision\": 1.0, \"recall\": 0.06124140925974056, \"specificity\": 1.0, \"npv\": 0.9997769031759299, \"accuracy\": 0.9997769064228508, \"f1\": 0.11541466197113238, \"f2\": 0.07539740080472498, \"f0_5\": 0.24595622335969727, \"p4\": 0.20694246451436957, \"phi\": 0.24744241046318863}, {\"truth_threshold\": 34.679999224841595, \"match_probability\": 0.9999999999636687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18569.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285392.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06109007405555318, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9389099259444468, \"precision\": 1.0, \"recall\": 0.06109007405555318, \"specificity\": 1.0, \"npv\": 0.9997768672190074, \"accuracy\": 0.9997768704584267, \"f1\": 0.11514587790283075, \"f2\": 0.07521388708641273, \"f0_5\": 0.24546778871448324, \"p4\": 0.20651029328178275, \"phi\": 0.24713648629338025}, {\"truth_threshold\": 34.69999922439456, \"match_probability\": 0.999999999964169, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18530.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06096176812156823, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9390382318784317, \"precision\": 1.0, \"recall\": 0.06096176812156823, \"specificity\": 1.0, \"npv\": 0.9997768367337925, \"accuracy\": 0.9997768399668497, \"f1\": 0.11491793569432945, \"f2\": 0.07505828865481612, \"f0_5\": 0.245053308682531, \"p4\": 0.20614362736144753, \"phi\": 0.24687681886779167}, {\"truth_threshold\": 34.719999223947525, \"match_probability\": 0.9999999999646623, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18476.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285485.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06078411375143522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9392158862485648, \"precision\": 1.0, \"recall\": 0.06078411375143522, \"specificity\": 1.0, \"npv\": 0.999776794523498, \"accuracy\": 0.9997767977477433, \"f1\": 0.11460223237407617, \"f2\": 0.07484282843995074, \"f0_5\": 0.24447884826591507, \"p4\": 0.20563554193682781, \"phi\": 0.24651682783201956}, {\"truth_threshold\": 34.73999922350049, \"match_probability\": 0.9999999999651488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18386.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285575.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06048802313454687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9395119768654532, \"precision\": 1.0, \"recall\": 0.06048802313454687, \"specificity\": 1.0, \"npv\": 0.999776724173015, \"accuracy\": 0.9997767273825657, \"f1\": 0.11407582512013452, \"f2\": 0.0744836861849088, \"f0_5\": 0.24351995337810095, \"p4\": 0.20478771417858946, \"phi\": 0.24591567176810594}, {\"truth_threshold\": 34.759999223053455, \"match_probability\": 0.9999999999656286, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18333.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.06031365866015706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.939686341339843, \"precision\": 1.0, \"recall\": 0.06031365866015706, \"specificity\": 1.0, \"npv\": 0.999776682744402, \"accuracy\": 0.9997766859452946, \"f1\": 0.11376569219408367, \"f2\": 0.07427216679617267, \"f0_5\": 0.2429544147386779, \"p4\": 0.20428784110594206, \"phi\": 0.2455609691694305}, {\"truth_threshold\": 34.77999922260642, \"match_probability\": 0.9999999999661018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18284.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285677.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.060152453768740066, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9398475462312599, \"precision\": 1.0, \"recall\": 0.060152453768740066, \"specificity\": 1.0, \"npv\": 0.9997766444424797, \"accuracy\": 0.9997766476353646, \"f1\": 0.11347887476919735, \"f2\": 0.07407659497232054, \"f0_5\": 0.24243099255629189, \"p4\": 0.20382530015788183, \"phi\": 0.24523258018438812}, {\"truth_threshold\": 34.799999222159386, \"match_probability\": 0.9999999999665684, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18234.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285727.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059987958981579874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9400120410184202, \"precision\": 1.0, \"recall\": 0.059987958981579874, \"specificity\": 1.0, \"npv\": 0.9997766053588887, \"accuracy\": 0.9997766085435993, \"f1\": 0.11318611399928614, \"f2\": 0.07387701587744049, \"f0_5\": 0.24189632711324313, \"p4\": 0.2033529287425534, \"phi\": 0.24489703549249464}, {\"truth_threshold\": 34.81999922171235, \"match_probability\": 0.9999999999670287, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18181.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285780.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059813594507190065, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.94018640549281, \"precision\": 1.0, \"recall\": 0.059813594507190065, \"specificity\": 1.0, \"npv\": 0.9997765639302854, \"accuracy\": 0.9997765671063281, \"f1\": 0.11287568836103333, \"f2\": 0.07366544437916574, \"f0_5\": 0.241328961864688, \"p4\": 0.20285178344684152, \"phi\": 0.24454085546737966}, {\"truth_threshold\": 34.839999221265316, \"match_probability\": 0.9999999999674827, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18118.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059606331075368224, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9403936689246318, \"precision\": 1.0, \"recall\": 0.059606331075368224, \"specificity\": 1.0, \"npv\": 0.9997765146849691, \"accuracy\": 0.9997765178507038, \"f1\": 0.11250655894982287, \"f2\": 0.07341393008860889, \"f0_5\": 0.24065371526938392, \"p4\": 0.20225550385211621, \"phi\": 0.24411679568536454}, {\"truth_threshold\": 34.85999922081828, \"match_probability\": 0.9999999999679303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18070.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285891.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059448416079694436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9405515839203056, \"precision\": 1.0, \"recall\": 0.059448416079694436, \"specificity\": 1.0, \"npv\": 0.9997764771647313, \"accuracy\": 0.9997764803226091, \"f1\": 0.11222522055330077, \"f2\": 0.07322228291436843, \"f0_5\": 0.24013863454541104, \"p4\": 0.20180077318603634, \"phi\": 0.24379320745496597}, {\"truth_threshold\": 34.879999220371246, \"match_probability\": 0.9999999999683719, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18024.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05929708087550706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.940702919124493, \"precision\": 1.0, \"recall\": 0.05929708087550706, \"specificity\": 1.0, \"npv\": 0.9997764412078394, \"accuracy\": 0.999776444358185, \"f1\": 0.11195552587853472, \"f2\": 0.07303860704710714, \"f0_5\": 0.23964452197406244, \"p4\": 0.20136464637364476, \"phi\": 0.2434826985469971}, {\"truth_threshold\": 34.89999921992421, \"match_probability\": 0.9999999999688073, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17977.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 285984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.059142455775576475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9408575442244236, \"precision\": 1.0, \"recall\": 0.059142455775576475, \"specificity\": 1.0, \"npv\": 0.9997764044692786, \"accuracy\": 0.9997764076119257, \"f1\": 0.11167988867421677, \"f2\": 0.0728509240805595, \"f0_5\": 0.23913916816763287, \"p4\": 0.20091869114498573, \"phi\": 0.24316502994219621}, {\"truth_threshold\": 34.91999921947718, \"match_probability\": 0.9999999999692367, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17921.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05895822161395706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.941041778386043, \"precision\": 1.0, \"recall\": 0.05895822161395706, \"specificity\": 1.0, \"npv\": 0.9997763606956778, \"accuracy\": 0.9997763638291486, \"f1\": 0.1113513647858532, \"f2\": 0.07262728315359894, \"f0_5\": 0.23853638408603867, \"p4\": 0.2003868812318948, \"phi\": 0.24278598855430522}, {\"truth_threshold\": 34.93999921903014, \"match_probability\": 0.9999999999696603, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17852.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286109.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05873121880767598, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.941268781192324, \"precision\": 1.0, \"recall\": 0.05873121880767598, \"specificity\": 1.0, \"npv\": 0.9997763067603535, \"accuracy\": 0.9997763098825125, \"f1\": 0.11094641919375538, \"f2\": 0.07235169766295749, \"f0_5\": 0.23779267867085455, \"p4\": 0.1997309281004922, \"phi\": 0.242318140119704}, {\"truth_threshold\": 34.95999921858311, \"match_probability\": 0.9999999999700779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17801.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.058563434124772586, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9414365658752274, \"precision\": 1.0, \"recall\": 0.058563434124772586, \"specificity\": 1.0, \"npv\": 0.9997762668951176, \"accuracy\": 0.9997762700089119, \"f1\": 0.11064699995648958, \"f2\": 0.07214798422560785, \"f0_5\": 0.23724228006343875, \"p4\": 0.1992456047400716, \"phi\": 0.24197175774421129}, {\"truth_threshold\": 34.97999921813607, \"match_probability\": 0.9999999999704898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17720.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286241.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05829695256957307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9417030474304269, \"precision\": 1.0, \"recall\": 0.05829695256957307, \"specificity\": 1.0, \"npv\": 0.9997762035797493, \"accuracy\": 0.9997762066802521, \"f1\": 0.11017125661758077, \"f2\": 0.07182440473295265, \"f0_5\": 0.23636688622642668, \"p4\": 0.1984739422804768, \"phi\": 0.24142059961874932}, {\"truth_threshold\": 34.99999921768904, \"match_probability\": 0.9999999999708962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17682.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286279.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05817193653133132, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9418280634686687, \"precision\": 1.0, \"recall\": 0.05817193653133132, \"specificity\": 1.0, \"npv\": 0.999776173876246, \"accuracy\": 0.9997761769705105, \"f1\": 0.10994798581035496, \"f2\": 0.07167258736337945, \"f0_5\": 0.23595568591551927, \"p4\": 0.1981115657665155, \"phi\": 0.24116159754875208}, {\"truth_threshold\": 35.019999217242, \"match_probability\": 0.9999999999712968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17640.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286321.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.058033760910116756, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9419662390898832, \"precision\": 1.0, \"recall\": 0.058033760910116756, \"specificity\": 1.0, \"npv\": 0.9997761410460602, \"accuracy\": 0.9997761441334276, \"f1\": 0.10970115142676795, \"f2\": 0.07150477833518716, \"f0_5\": 0.23550081303852122, \"p4\": 0.19771077499405504, \"phi\": 0.2408750081123117}, {\"truth_threshold\": 35.03999921679497, \"match_probability\": 0.999999999971692, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17572.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286389.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.057810047999578895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9421899520004211, \"precision\": 1.0, \"recall\": 0.057810047999578895, \"specificity\": 1.0, \"npv\": 0.9997760878924306, \"accuracy\": 0.9997760909686269, \"f1\": 0.10930137808560864, \"f2\": 0.07123306329737898, \"f0_5\": 0.23476348634198088, \"p4\": 0.19706127524986805, \"phi\": 0.24041028187224567}, {\"truth_threshold\": 35.05999921634793, \"match_probability\": 0.9999999999720818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17530.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286431.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05767187237836433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9423281276216356, \"precision\": 1.0, \"recall\": 0.05767187237836433, \"specificity\": 1.0, \"npv\": 0.9997760550622504, \"accuracy\": 0.999776058131544, \"f1\": 0.10905437477254418, \"f2\": 0.07106522433584622, \"f0_5\": 0.23430754301875797, \"p4\": 0.19665974233461123, \"phi\": 0.24012279578268833}, {\"truth_threshold\": 35.0799992159009, \"match_probability\": 0.9999999999724661, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17478.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286483.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05750079779971773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9424992022002823, \"precision\": 1.0, \"recall\": 0.05750079779971773, \"specificity\": 1.0, \"npv\": 0.9997760144153636, \"accuracy\": 0.9997760174761081, \"f1\": 0.10874847171625099, \"f2\": 0.07085740787888321, \"f0_5\": 0.2337424740486743, \"p4\": 0.1961622129608721, \"phi\": 0.23976638306882284}, {\"truth_threshold\": 35.09999921545386, \"match_probability\": 0.9999999999728452, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17436.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286525.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.057362622178503166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9426373778214968, \"precision\": 1.0, \"recall\": 0.057362622178503166, \"specificity\": 1.0, \"npv\": 0.9997759815851882, \"accuracy\": 0.9997759846390253, \"f1\": 0.10850132390781494, \"f2\": 0.07068954333160353, \"f0_5\": 0.23328561298350303, \"p4\": 0.1957600442161878, \"phi\": 0.2394781240422876}, {\"truth_threshold\": 35.11999921500683, \"match_probability\": 0.999999999973219, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17392.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286569.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05721786676580219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9427821332341978, \"precision\": 1.0, \"recall\": 0.05721786676580219, \"specificity\": 1.0, \"npv\": 0.9997759471916735, \"accuracy\": 0.9997759502382718, \"f1\": 0.10824233786521364, \"f2\": 0.07051367297094797, \"f0_5\": 0.2328065558497466, \"p4\": 0.19533841934152674, \"phi\": 0.23917576579174332}, {\"truth_threshold\": 35.13999921455979, \"match_probability\": 0.9999999999735877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17332.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05702047302120996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9429795269787901, \"precision\": 1.0, \"recall\": 0.05702047302120996, \"specificity\": 1.0, \"npv\": 0.99977590029143, \"accuracy\": 0.9997759033281535, \"f1\": 0.10788906076385106, \"f2\": 0.0702738295263612, \"f0_5\": 0.23215256811746396, \"p4\": 0.19476297235993273, \"phi\": 0.23876284206262785}, {\"truth_threshold\": 35.15999921411276, \"match_probability\": 0.9999999999739513, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17264.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05679676011067209, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9432032398893279, \"precision\": 1.0, \"recall\": 0.05679676011067209, \"specificity\": 1.0, \"npv\": 0.999775847137826, \"accuracy\": 0.9997758501633527, \"f1\": 0.10748852050743249, \"f2\": 0.07000197873989951, \"f0_5\": 0.23141036467506843, \"p4\": 0.19411009511990415, \"phi\": 0.23829399689109054}, {\"truth_threshold\": 35.179999213665724, \"match_probability\": 0.99999999997431, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17213.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.056628975427768694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9433710245722313, \"precision\": 1.0, \"recall\": 0.056628975427768694, \"specificity\": 1.0, \"npv\": 0.9997758072726267, \"accuracy\": 0.9997758102897522, \"f1\": 0.10718800401028726, \"f2\": 0.06979807097319914, \"f0_5\": 0.23085300137066037, \"p4\": 0.19361994557756868, \"phi\": 0.23794175678791477}, {\"truth_threshold\": 35.19999921321869, \"match_probability\": 0.9999999999746636, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17138.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286823.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0563822332470284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9436177667529716, \"precision\": 1.0, \"recall\": 0.0563822332470284, \"specificity\": 1.0, \"npv\": 0.9997757486473393, \"accuracy\": 0.9997757516521042, \"f1\": 0.10674589456834185, \"f2\": 0.06949817596688354, \"f0_5\": 0.23003224048556695, \"p4\": 0.19289837068701782, \"phi\": 0.23742280736053292}, {\"truth_threshold\": 35.219999212771654, \"match_probability\": 0.9999999999750124, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17100.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05625721720878665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9437427827912134, \"precision\": 1.0, \"recall\": 0.05625721720878665, \"specificity\": 1.0, \"npv\": 0.9997757189438631, \"accuracy\": 0.9997757219423625, \"f1\": 0.10652181361174357, \"f2\": 0.06934621523767504, \"f0_5\": 0.229615883510894, \"p4\": 0.19253242385973876, \"phi\": 0.23715943957746177}, {\"truth_threshold\": 35.23999921232462, \"match_probability\": 0.9999999999753565, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17072.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.056165100127976944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9438348998720231, \"precision\": 1.0, \"recall\": 0.056165100127976944, \"specificity\": 1.0, \"npv\": 0.9997756970570922, \"accuracy\": 0.999775700050974, \"f1\": 0.10635666738310391, \"f2\": 0.06923423818005443, \"f0_5\": 0.2293088765852964, \"p4\": 0.19226262850232784, \"phi\": 0.23696519181248862}, {\"truth_threshold\": 35.259999211877584, \"match_probability\": 0.9999999999756958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17044.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.056072983047167235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9439270169528328, \"precision\": 1.0, \"recall\": 0.056072983047167235, \"specificity\": 1.0, \"npv\": 0.9997756751703223, \"accuracy\": 0.9997756781595855, \"f1\": 0.106191492344356, \"f2\": 0.06912225603623362, \"f0_5\": 0.22900168486337022, \"p4\": 0.19199270549361414, \"phi\": 0.23677078469438678}, {\"truth_threshold\": 35.27999921143055, \"match_probability\": 0.9999999999760303, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16985.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 286976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05587887919831821, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9441211208016818, \"precision\": 1.0, \"recall\": 0.05587887919831821, \"specificity\": 1.0, \"npv\": 0.9997756290517745, \"accuracy\": 0.9997756320313024, \"f1\": 0.10584335059480411, \"f2\": 0.0688862770100314, \"f0_5\": 0.22835378232379047, \"p4\": 0.19142352086866996, \"phi\": 0.23636061770355632}, {\"truth_threshold\": 35.299999210983515, \"match_probability\": 0.9999999999763604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16947.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05575386316007646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9442461368399235, \"precision\": 1.0, \"recall\": 0.05575386316007646, \"specificity\": 1.0, \"npv\": 0.9997755993483054, \"accuracy\": 0.9997756023215608, \"f1\": 0.10561905592880202, \"f2\": 0.06873427855978832, \"f0_5\": 0.22793605362758204, \"p4\": 0.1910566266939451, \"phi\": 0.23609606510242573}, {\"truth_threshold\": 35.31999921053648, \"match_probability\": 0.9999999999766858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16900.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05559923806014588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9444007619398541, \"precision\": 1.0, \"recall\": 0.05559923806014588, \"specificity\": 1.0, \"npv\": 0.9997755626098065, \"accuracy\": 0.9997755655753015, \"f1\": 0.1053415653507282, \"f2\": 0.06854626751377416, \"f0_5\": 0.22741891640941864, \"p4\": 0.19060251023915611, \"phi\": 0.23576844469152122}, {\"truth_threshold\": 35.339999210089445, \"match_probability\": 0.9999999999770067, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16853.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287108.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05544461296021529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9445553870397847, \"precision\": 1.0, \"recall\": 0.05544461296021529, \"specificity\": 1.0, \"npv\": 0.9997755258713102, \"accuracy\": 0.9997755288290421, \"f1\": 0.1050639934666193, \"f2\": 0.06835824213087238, \"f0_5\": 0.22690125561093563, \"p4\": 0.1901480325414659, \"phi\": 0.23544036841423457}, {\"truth_threshold\": 35.35999920964241, \"match_probability\": 0.9999999999773234, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16779.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287182.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0552011606752182, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9447988393247818, \"precision\": 1.0, \"recall\": 0.0552011606752182, \"specificity\": 1.0, \"npv\": 0.999775468027726, \"accuracy\": 0.9997754709732294, \"f1\": 0.10462680052378874, \"f2\": 0.06806217310564544, \"f0_5\": 0.22608515213823546, \"p4\": 0.18943173873527222, \"phi\": 0.23492289426477783}, {\"truth_threshold\": 35.379999209195375, \"match_probability\": 0.9999999999776356, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16727.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287234.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0550300860965716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9449699139034284, \"precision\": 1.0, \"recall\": 0.0550300860965716, \"specificity\": 1.0, \"npv\": 0.9997754273808869, \"accuracy\": 0.9997754303177936, \"f1\": 0.10431946315421843, \"f2\": 0.06785410333360106, \"f0_5\": 0.22551089468248897, \"p4\": 0.18892785986136573, \"phi\": 0.23455858084070783}, {\"truth_threshold\": 35.39999920874834, \"match_probability\": 0.9999999999779434, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16672.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.054849141830695385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9451508581693047, \"precision\": 1.0, \"recall\": 0.054849141830695385, \"specificity\": 1.0, \"npv\": 0.9997753843890416, \"accuracy\": 0.9997753873168518, \"f1\": 0.10399428630240805, \"f2\": 0.06763401043069624, \"f0_5\": 0.22490280561933257, \"p4\": 0.18839442772737605, \"phi\": 0.23417263259653665}, {\"truth_threshold\": 35.419999208301306, \"match_probability\": 0.9999999999782471, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16629.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.054707676313737616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9452923236862624, \"precision\": 1.0, \"recall\": 0.054707676313737616, \"specificity\": 1.0, \"npv\": 0.9997753507772378, \"accuracy\": 0.9997753536979336, \"f1\": 0.10373997941295736, \"f2\": 0.06746192411517331, \"f0_5\": 0.224426887499089, \"p4\": 0.1879770342574252, \"phi\": 0.23387044763452822}, {\"truth_threshold\": 35.43999920785427, \"match_probability\": 0.9999999999785465, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16575.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287386.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05453002194360461, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9454699780563954, \"precision\": 1.0, \"recall\": 0.05453002194360461, \"specificity\": 1.0, \"npv\": 0.9997753085670688, \"accuracy\": 0.999775311478827, \"f1\": 0.10342052062794818, \"f2\": 0.06724579870969208, \"f0_5\": 0.22382859658457144, \"p4\": 0.18745243442320442, \"phi\": 0.2334904056162401}, {\"truth_threshold\": 35.459999207407236, \"match_probability\": 0.9999999999788419, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16529.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287432.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05437868673941723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9456213132605827, \"precision\": 1.0, \"recall\": 0.05437868673941723, \"specificity\": 1.0, \"npv\": 0.9997752726102609, \"accuracy\": 0.999775275514403, \"f1\": 0.10314830415925613, \"f2\": 0.0670616769435877, \"f0_5\": 0.22331839049711277, \"p4\": 0.1870051738648938, \"phi\": 0.23316617756246044}, {\"truth_threshold\": 35.4799992069602, \"match_probability\": 0.9999999999791332, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16502.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05428985955435072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9457101404456493, \"precision\": 1.0, \"recall\": 0.05428985955435072, \"specificity\": 1.0, \"npv\": 0.9997752515051792, \"accuracy\": 0.9997752544048497, \"f1\": 0.1029884885306572, \"f2\": 0.06695359907039095, \"f0_5\": 0.22301868534931304, \"p4\": 0.18674248870142743, \"phi\": 0.23297565965167233}, {\"truth_threshold\": 35.499999206513166, \"match_probability\": 0.9999999999794205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16455.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05413523445442014, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9458647655455799, \"precision\": 1.0, \"recall\": 0.05413523445442014, \"specificity\": 1.0, \"npv\": 0.9997752147667059, \"accuracy\": 0.9997752176585903, \"f1\": 0.10271022670528313, \"f2\": 0.0667654522157366, \"f0_5\": 0.22249655877397703, \"p4\": 0.1862849346120102, \"phi\": 0.23264364520251543}, {\"truth_threshold\": 35.51999920606613, \"match_probability\": 0.9999999999797038, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16410.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287551.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053987189145975965, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.946012810854024, \"precision\": 1.0, \"recall\": 0.053987189145975965, \"specificity\": 1.0, \"npv\": 0.9997751795915744, \"accuracy\": 0.9997751824760016, \"f1\": 0.10244372930134125, \"f2\": 0.0665852981609311, \"f0_5\": 0.22199615260781222, \"p4\": 0.18584650855133678, \"phi\": 0.23232531442798568}, {\"truth_threshold\": 35.5399992056191, \"match_probability\": 0.9999999999799832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16351.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287610.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05379308529712693, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9462069147028731, \"precision\": 1.0, \"recall\": 0.05379308529712693, \"specificity\": 1.0, \"npv\": 0.9997751334730723, \"accuracy\": 0.9997751363477186, \"f1\": 0.10209420814705662, \"f2\": 0.06634907624199092, \"f0_5\": 0.22133932559933941, \"p4\": 0.18527117520297506, \"phi\": 0.2319072854242907}, {\"truth_threshold\": 35.55999920517206, \"match_probability\": 0.9999999999802588, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16287.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287674.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053582531969561885, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9464174680304381, \"precision\": 1.0, \"recall\": 0.053582531969561885, \"specificity\": 1.0, \"npv\": 0.9997750834462275, \"accuracy\": 0.999775086310259, \"f1\": 0.10171492093627439, \"f2\": 0.06609280993660577, \"f0_5\": 0.22062588557851476, \"p4\": 0.18464643204812747, \"phi\": 0.23145297658731648}, {\"truth_threshold\": 35.57999920472503, \"match_probability\": 0.9999999999805306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16260.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05349370478449538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9465062952155047, \"precision\": 1.0, \"recall\": 0.05349370478449538, \"specificity\": 1.0, \"npv\": 0.9997750623411539, \"accuracy\": 0.9997750652007058, \"f1\": 0.10155486367227634, \"f2\": 0.06598468960412433, \"f0_5\": 0.22032460616637894, \"p4\": 0.1843826645362958, \"phi\": 0.23126104738104544}, {\"truth_threshold\": 35.59999920427799, \"match_probability\": 0.9999999999807986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16234.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287727.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053408167495172076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9465918325048279, \"precision\": 1.0, \"recall\": 0.053408167495172076, \"specificity\": 1.0, \"npv\": 0.9997750420177504, \"accuracy\": 0.9997750448729879, \"f1\": 0.10140070894298786, \"f2\": 0.06588056924967413, \"f0_5\": 0.22003431852251443, \"p4\": 0.18412855166870334, \"phi\": 0.23107607600436855}, {\"truth_threshold\": 35.61999920383096, \"match_probability\": 0.9999999999810629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16210.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287751.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05332920999733518, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9466707900026649, \"precision\": 1.0, \"recall\": 0.05332920999733518, \"specificity\": 1.0, \"npv\": 0.9997750232576864, \"accuracy\": 0.9997750261089405, \"f1\": 0.1012583900478182, \"f2\": 0.06578445425281684, \"f0_5\": 0.21976621538444852, \"p4\": 0.18389388614979174, \"phi\": 0.2309052016854532}, {\"truth_threshold\": 35.63999920338392, \"match_probability\": 0.9999999999813237, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16169.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.053194324271863824, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9468056757281361, \"precision\": 1.0, \"recall\": 0.053194324271863824, \"specificity\": 1.0, \"npv\": 0.9997749912092454, \"accuracy\": 0.999774994053693, \"f1\": 0.10101521256989349, \"f2\": 0.06562024913698151, \"f0_5\": 0.2193078828223971, \"p4\": 0.18349277742195771, \"phi\": 0.2306129985089401}, {\"truth_threshold\": 35.65999920293689, \"match_probability\": 0.9999999999815808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16114.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287847.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05301338000598761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9469866199940123, \"precision\": 1.0, \"recall\": 0.05301338000598761, \"specificity\": 1.0, \"npv\": 0.9997749482174376, \"accuracy\": 0.9997749510527512, \"f1\": 0.10068890103881903, \"f2\": 0.06539995681670967, \"f0_5\": 0.21869240561646178, \"p4\": 0.18295426485115662, \"phi\": 0.23022043621346389}, {\"truth_threshold\": 35.67999920248985, \"match_probability\": 0.9999999999818344, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16053.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287908.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.052812696365652174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9471873036343478, \"precision\": 1.0, \"recall\": 0.052812696365652174, \"specificity\": 1.0, \"npv\": 0.9997749005356187, \"accuracy\": 0.9997749033607974, \"f1\": 0.10032686069984438, \"f2\": 0.06515560960047796, \"f0_5\": 0.21800892515203452, \"p4\": 0.18235641515044296, \"phi\": 0.22978426459613746}, {\"truth_threshold\": 35.69999920204282, \"match_probability\": 0.9999999999820844, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15990.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287971.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.052605432933830326, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9473945670661696, \"precision\": 1.0, \"recall\": 0.052605432933830326, \"specificity\": 1.0, \"npv\": 0.9997748512904662, \"accuracy\": 0.9997748541051732, \"f1\": 0.09995280527330748, \"f2\": 0.06490322559695544, \"f0_5\": 0.21730208387126584, \"p4\": 0.18173831112206137, \"phi\": 0.22933292151039025}, {\"truth_threshold\": 35.71999920159578, \"match_probability\": 0.9999999999823311, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15963.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 287998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05251660574876382, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9474833942512362, \"precision\": 1.0, \"recall\": 0.05251660574876382, \"specificity\": 1.0, \"npv\": 0.9997748301854023, \"accuracy\": 0.99977483299562, \"f1\": 0.09979245070704293, \"f2\": 0.06479505312114642, \"f0_5\": 0.21699885539662817, \"p4\": 0.18147320610597126, \"phi\": 0.22913921662252423}, {\"truth_threshold\": 35.73999920114875, \"match_probability\": 0.9999999999825744, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15896.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288065.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05229618273396916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9477038172660308, \"precision\": 1.0, \"recall\": 0.05229618273396916, \"specificity\": 1.0, \"npv\": 0.9997747778135809, \"accuracy\": 0.9997747806126545, \"f1\": 0.09939441688004327, \"f2\": 0.06452660464058974, \"f0_5\": 0.21624562978682882, \"p4\": 0.18081482533222593, \"phi\": 0.228657832739997}, {\"truth_threshold\": 35.759999200701714, \"match_probability\": 0.9999999999828143, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15816.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288145.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05203299107451285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9479670089254871, \"precision\": 1.0, \"recall\": 0.05203299107451285, \"specificity\": 1.0, \"npv\": 0.9997747152800702, \"accuracy\": 0.9997747180658301, \"f1\": 0.0989189341322234, \"f2\": 0.06420603088514687, \"f0_5\": 0.2153448158485942, \"p4\": 0.18002771243238272, \"phi\": 0.2280817152616393}, {\"truth_threshold\": 35.77999920025468, \"match_probability\": 0.9999999999830509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15782.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288179.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.051921134619243914, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.948078865380756, \"precision\": 1.0, \"recall\": 0.051921134619243914, \"specificity\": 1.0, \"npv\": 0.9997746887033305, \"accuracy\": 0.9997746914834297, \"f1\": 0.09871678191547587, \"f2\": 0.06406977442827612, \"f0_5\": 0.21496149435150605, \"p4\": 0.17969286377105245, \"phi\": 0.22783642421939101}, {\"truth_threshold\": 35.799999199807644, \"match_probability\": 0.9999999999832843, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15720.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288241.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05171716108316528, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9482828389168347, \"precision\": 1.0, \"recall\": 0.05171716108316528, \"specificity\": 1.0, \"npv\": 0.9997746402398676, \"accuracy\": 0.9997746430096407, \"f1\": 0.09834804070307587, \"f2\": 0.06382128740365908, \"f0_5\": 0.21426176463372415, \"p4\": 0.17908175652278527, \"phi\": 0.22738844763124808}, {\"truth_threshold\": 35.81999919936061, \"match_probability\": 0.9999999999835144, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15676.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288285.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.051572405670464304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9484275943295357, \"precision\": 1.0, \"recall\": 0.051572405670464304, \"specificity\": 1.0, \"npv\": 0.9997746058464452, \"accuracy\": 0.9997746086088872, \"f1\": 0.09808626660868422, \"f2\": 0.06364492659477719, \"f0_5\": 0.21376460802094555, \"p4\": 0.1786476745586442, \"phi\": 0.22706999262725455}, {\"truth_threshold\": 35.839999198913574, \"match_probability\": 0.9999999999837413, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15651.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288310.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.051490158276884204, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9485098417231158, \"precision\": 1.0, \"recall\": 0.051490158276884204, \"specificity\": 1.0, \"npv\": 0.9997745863047289, \"accuracy\": 0.9997745890630045, \"f1\": 0.09793749921780158, \"f2\": 0.06354471597529832, \"f0_5\": 0.21348191998690547, \"p4\": 0.1784008915823111, \"phi\": 0.22688885316391574}, {\"truth_threshold\": 35.85999919846654, \"match_probability\": 0.9999999999839652, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15593.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05129934432377838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9487006556762216, \"precision\": 1.0, \"recall\": 0.05129934432377838, \"specificity\": 1.0, \"npv\": 0.9997745409679502, \"accuracy\": 0.9997745437165568, \"f1\": 0.09759226922523266, \"f2\": 0.0633122116681568, \"f0_5\": 0.2128254893771514, \"p4\": 0.1778279485948593, \"phi\": 0.2264680516612936}, {\"truth_threshold\": 35.879999198019505, \"match_probability\": 0.9999999999841859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15559.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288402.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05118748786850945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9488125121314905, \"precision\": 1.0, \"recall\": 0.05118748786850945, \"specificity\": 1.0, \"npv\": 0.9997745143912198, \"accuracy\": 0.9997745171341564, \"f1\": 0.09738983475212819, \"f2\": 0.06317590585697777, \"f0_5\": 0.21244029852784158, \"p4\": 0.1774918210792145, \"phi\": 0.22622101101941325}, {\"truth_threshold\": 35.89999919757247, \"match_probability\": 0.9999999999844036, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15483.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288478.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05093745579202595, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9490625442079741, \"precision\": 1.0, \"recall\": 0.05093745579202595, \"specificity\": 1.0, \"npv\": 0.9997744549844156, \"accuracy\": 0.9997744577146732, \"f1\": 0.09693717834737857, \"f2\": 0.06287119506028861, \"f0_5\": 0.21157824828570101, \"p4\": 0.17673976959970333, \"phi\": 0.22566782469542598}, {\"truth_threshold\": 35.919999197125435, \"match_probability\": 0.9999999999846183, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15466.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288495.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05088152756439149, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9491184724356085, \"precision\": 1.0, \"recall\": 0.05088152756439149, \"specificity\": 1.0, \"npv\": 0.9997744416960525, \"accuracy\": 0.999774444423473, \"f1\": 0.0968358967776675, \"f2\": 0.06280303091829027, \"f0_5\": 0.2113852251759721, \"p4\": 0.1765714135910663, \"phi\": 0.22554389996923394}, {\"truth_threshold\": 35.9399991966784, \"match_probability\": 0.9999999999848301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15405.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05068084392405604, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.949319156075944, \"precision\": 1.0, \"recall\": 0.05068084392405604, \"specificity\": 1.0, \"npv\": 0.9997743940142819, \"accuracy\": 0.9997743967315194, \"f1\": 0.09647238591459328, \"f2\": 0.06255842644339203, \"f0_5\": 0.21069202174073598, \"p4\": 0.1759669089143908, \"phi\": 0.22509866730459677}, {\"truth_threshold\": 35.959999196231365, \"match_probability\": 0.999999999985039, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15353.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05050976934540945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9494902306545906, \"precision\": 1.0, \"recall\": 0.05050976934540945, \"specificity\": 1.0, \"npv\": 0.9997743533675302, \"accuracy\": 0.9997743560760834, \"f1\": 0.09616239814101481, \"f2\": 0.06234989201565631, \"f0_5\": 0.210100363190493, \"p4\": 0.17545109433270856, \"phi\": 0.22471842822975116}, {\"truth_threshold\": 35.97999919578433, \"match_probability\": 0.9999999999852449, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15284.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288677.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05028276653912837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9497172334608717, \"precision\": 1.0, \"recall\": 0.05028276653912837, \"specificity\": 1.0, \"npv\": 0.9997742994324225, \"accuracy\": 0.9997743021294474, \"f1\": 0.09575091230872841, \"f2\": 0.0620731556751207, \"f0_5\": 0.2093142370383761, \"p4\": 0.17476593777250993, \"phi\": 0.22421288475504952}, {\"truth_threshold\": 35.999999195337296, \"match_probability\": 0.9999999999854481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15252.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288709.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.05017748987534585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9498225101246541, \"precision\": 1.0, \"recall\": 0.05017748987534585, \"specificity\": 1.0, \"npv\": 0.9997742744190411, \"accuracy\": 0.9997742771107175, \"f1\": 0.0955600179190697, \"f2\": 0.0619448036546297, \"f0_5\": 0.20894925322424646, \"p4\": 0.1744479086832374, \"phi\": 0.22397804252268275}, {\"truth_threshold\": 36.01999919489026, \"match_probability\": 0.9999999999856484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15192.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04998009613075362, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9500199038692464, \"precision\": 1.0, \"recall\": 0.04998009613075362, \"specificity\": 1.0, \"npv\": 0.9997742275189545, \"accuracy\": 0.9997742302005992, \"f1\": 0.09520198776135584, \"f2\": 0.06170412563076953, \"f0_5\": 0.20826421809069198, \"p4\": 0.1738511332624661, \"phi\": 0.22353704838448432}, {\"truth_threshold\": 36.039999194443226, \"match_probability\": 0.999999999985846, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15136.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288825.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0497958619691342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9502041380308658, \"precision\": 1.0, \"recall\": 0.0497958619691342, \"specificity\": 1.0, \"npv\": 0.9997741837455444, \"accuracy\": 0.9997741864178221, \"f1\": 0.09486770480449519, \"f2\": 0.061479471640481564, \"f0_5\": 0.2076240380790387, \"p4\": 0.17329358803030856, \"phi\": 0.2231246675159359}, {\"truth_threshold\": 36.05999919399619, \"match_probability\": 0.9999999999860408, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15090.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288871.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.049644526764946816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9503554732350532, \"precision\": 1.0, \"recall\": 0.049644526764946816, \"specificity\": 1.0, \"npv\": 0.9997741477888175, \"accuracy\": 0.999774150453398, \"f1\": 0.09459302744702258, \"f2\": 0.06129491914269977, \"f0_5\": 0.2070975870180418, \"p4\": 0.17283520313366377, \"phi\": 0.222785355081531}, {\"truth_threshold\": 36.079999193549156, \"match_probability\": 0.999999999986233, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 15045.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04949648145650264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9505035185434973, \"precision\": 1.0, \"recall\": 0.04949648145650264, \"specificity\": 1.0, \"npv\": 0.999774112613761, \"accuracy\": 0.9997741152708093, \"f1\": 0.09432424468505295, \"f2\": 0.06111436530832593, \"f0_5\": 0.2065820657382717, \"p4\": 0.1723864324327051, \"phi\": 0.22245291822243735}, {\"truth_threshold\": 36.09999919310212, \"match_probability\": 0.9999999999864225, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14965.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 288996.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04923328979704633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9507667102029537, \"precision\": 1.0, \"recall\": 0.04923328979704633, \"specificity\": 1.0, \"npv\": 0.9997740500803334, \"accuracy\": 0.9997740527239849, \"f1\": 0.09384622138050833, \"f2\": 0.060793348114939035, \"f0_5\": 0.20566432393951972, \"p4\": 0.17158776019969246, \"phi\": 0.2218606894859289}, {\"truth_threshold\": 36.11999919265509, \"match_probability\": 0.9999999999866095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14914.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289047.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.049065505114142934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.950934494885857, \"precision\": 1.0, \"recall\": 0.049065505114142934, \"specificity\": 1.0, \"npv\": 0.9997740102152775, \"accuracy\": 0.9997740128503843, \"f1\": 0.09354135633085064, \"f2\": 0.06058867787168558, \"f0_5\": 0.20507842042588767, \"p4\": 0.1710780327851192, \"phi\": 0.2214823171524194}, {\"truth_threshold\": 36.13999919220805, \"match_probability\": 0.9999999999867939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14850.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289111.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04885495178657789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9511450482134222, \"precision\": 1.0, \"recall\": 0.04885495178657789, \"specificity\": 1.0, \"npv\": 0.999773960188545, \"accuracy\": 0.9997739628129246, \"f1\": 0.0931586425813413, \"f2\": 0.0603318127820563, \"f0_5\": 0.20434223815984653, \"p4\": 0.17043774160294634, \"phi\": 0.22100658049589247}, {\"truth_threshold\": 36.15999919176102, \"match_probability\": 0.9999999999869756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14759.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289202.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04855557127394633, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9514444287260537, \"precision\": 1.0, \"recall\": 0.04855557127394633, \"specificity\": 1.0, \"npv\": 0.9997738890567934, \"accuracy\": 0.9997738916659119, \"f1\": 0.09261420682730924, \"f2\": 0.05996653673036714, \"f0_5\": 0.2032936911324336, \"p4\": 0.16952611183833408, \"phi\": 0.22032837386030796}, {\"truth_threshold\": 36.17999919131398, \"match_probability\": 0.9999999999871549, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14718.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289243.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04842068554847497, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.951579314451525, \"precision\": 1.0, \"recall\": 0.04842068554847497, \"specificity\": 1.0, \"npv\": 0.9997738570084251, \"accuracy\": 0.9997738596106643, \"f1\": 0.09236880999375548, \"f2\": 0.05980194415234665, \"f0_5\": 0.20282058136939032, \"p4\": 0.16911491028899997, \"phi\": 0.22002212513697558}, {\"truth_threshold\": 36.19999919086695, \"match_probability\": 0.9999999999873318, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14690.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289271.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04832856846766526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9516714315323347, \"precision\": 1.0, \"recall\": 0.04832856846766526, \"specificity\": 1.0, \"npv\": 0.9997738351217358, \"accuracy\": 0.9997738377192757, \"f1\": 0.09220118562314256, \"f2\": 0.05968953316202559, \"f0_5\": 0.20249723616774326, \"p4\": 0.16883392268415678, \"phi\": 0.2198127344874748}, {\"truth_threshold\": 36.21999919041991, \"match_probability\": 0.9999999999875062, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14653.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289308.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04820684232516671, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9517931576748333, \"precision\": 1.0, \"recall\": 0.04820684232516671, \"specificity\": 1.0, \"npv\": 0.9997738062000406, \"accuracy\": 0.9997738087913695, \"f1\": 0.09197963680189822, \"f2\": 0.059540982221005005, \"f0_5\": 0.2020696521803885, \"p4\": 0.16846240951619507, \"phi\": 0.21953573339280588}, {\"truth_threshold\": 36.23999918997288, \"match_probability\": 0.9999999999876782, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14596.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289365.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0480193182678041, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9519806817321959, \"precision\": 1.0, \"recall\": 0.0480193182678041, \"specificity\": 1.0, \"npv\": 0.999773761645, \"accuracy\": 0.999773764226757, \"f1\": 0.09163823114858566, \"f2\": 0.0593121159910276, \"f0_5\": 0.20141025817935945, \"p4\": 0.16788961427251523, \"phi\": 0.2191083167208195}, {\"truth_threshold\": 36.25999918952584, \"match_probability\": 0.9999999999878478, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14556.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289405.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04788772243807594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9521122775619241, \"precision\": 1.0, \"recall\": 0.04788772243807594, \"specificity\": 1.0, \"npv\": 0.9997737303783072, \"accuracy\": 0.9997737329533448, \"f1\": 0.09139857527227746, \"f2\": 0.05915149544863459, \"f0_5\": 0.20094702983282026, \"p4\": 0.16748731619679705, \"phi\": 0.2188078766892}, {\"truth_threshold\": 36.27999918907881, \"match_probability\": 0.9999999999880151, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14506.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.047723227650915745, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9522767723490843, \"precision\": 1.0, \"recall\": 0.047723227650915745, \"specificity\": 1.0, \"npv\": 0.999773691294944, \"accuracy\": 0.9997736938615795, \"f1\": 0.09109892076730085, \"f2\": 0.05895070508391921, \"f0_5\": 0.20036741853944223, \"p4\": 0.16698405283477585, \"phi\": 0.2184317455615483}, {\"truth_threshold\": 36.29999918863177, \"match_probability\": 0.9999999999881801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04750609453186429, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9524939054681357, \"precision\": 1.0, \"recall\": 0.04750609453186429, \"specificity\": 1.0, \"npv\": 0.9997736397049091, \"accuracy\": 0.9997736422604493, \"f1\": 0.09070323271597765, \"f2\": 0.05868563681231326, \"f0_5\": 0.19960135021190364, \"p4\": 0.16631907947534025, \"phi\": 0.21793425852372875}, {\"truth_threshold\": 36.31999918818474, \"match_probability\": 0.9999999999883429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14408.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289553.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04740081786808176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9525991821319182, \"precision\": 1.0, \"recall\": 0.04740081786808176, \"specificity\": 1.0, \"npv\": 0.9997736146915608, \"accuracy\": 0.9997736172417195, \"f1\": 0.0905113249091463, \"f2\": 0.058557108624899615, \"f0_5\": 0.19922952048297396, \"p4\": 0.16599639511233322, \"phi\": 0.2176926434662146}, {\"truth_threshold\": 36.3399991877377, \"match_probability\": 0.9999999999885034, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14385.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04732515026598807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.952674849734012, \"precision\": 1.0, \"recall\": 0.04732515026598807, \"specificity\": 1.0, \"npv\": 0.9997735967132175, \"accuracy\": 0.9997735992595075, \"f1\": 0.0903733673424513, \"f2\": 0.05846472486016831, \"f0_5\": 0.1989621052223922, \"p4\": 0.1657643554734519, \"phi\": 0.21751881687895502}, {\"truth_threshold\": 36.35999918729067, \"match_probability\": 0.9999999999886616, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14357.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289604.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04723303318517836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9527669668148216, \"precision\": 1.0, \"recall\": 0.04723303318517836, \"specificity\": 1.0, \"npv\": 0.9997735748265395, \"accuracy\": 0.999773577368119, \"f1\": 0.09020539209218455, \"f2\": 0.058352253005809616, \"f0_5\": 0.19863637244077711, \"p4\": 0.165481747886025, \"phi\": 0.21730701423894797}, {\"truth_threshold\": 36.379999186843634, \"match_probability\": 0.9999999999888177, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14291.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289670.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0470159000661269, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9529840999338731, \"precision\": 1.0, \"recall\": 0.0470159000661269, \"specificity\": 1.0, \"npv\": 0.9997735232365167, \"accuracy\": 0.9997735257669887, \"f1\": 0.0898093334841572, \"f2\": 0.0580871205192926, \"f0_5\": 0.19786777431637245, \"p4\": 0.16481505977536753, \"phi\": 0.21680694651520663}, {\"truth_threshold\": 36.3999991863966, \"match_probability\": 0.9999999999889717, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14263.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289698.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04692378298531719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9530762170146828, \"precision\": 1.0, \"recall\": 0.04692378298531719, \"specificity\": 1.0, \"npv\": 0.999773501349842, \"accuracy\": 0.9997735038756003, \"f1\": 0.08964125898737996, \"f2\": 0.0579746314751481, \"f0_5\": 0.1975413627764097, \"p4\": 0.1645319923596642, \"phi\": 0.21659444778620413}, {\"truth_threshold\": 36.419999185949564, \"match_probability\": 0.9999999999891236, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14222.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.046788897259845835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9532111027401542, \"precision\": 1.0, \"recall\": 0.046788897259845835, \"specificity\": 1.0, \"npv\": 0.9997734693014986, \"accuracy\": 0.9997734718203527, \"f1\": 0.0893950965324986, \"f2\": 0.05780990613511795, \"f0_5\": 0.1970630374477967, \"p4\": 0.16411725324463058, \"phi\": 0.21628291226601204}, {\"truth_threshold\": 36.43999918550253, \"match_probability\": 0.9999999999892732, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04656518434930797, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.953434815650692, \"precision\": 1.0, \"recall\": 0.04656518434930797, \"specificity\": 1.0, \"npv\": 0.9997734161481531, \"accuracy\": 0.9997734186555519, \"f1\": 0.08898668720431291, \"f2\": 0.05753667892142914, \"f0_5\": 0.1962687581293316, \"p4\": 0.16342874391753942, \"phi\": 0.2157652275749643}, {\"truth_threshold\": 36.459999185055494, \"match_probability\": 0.9999999999894209, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14100.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04638752997917496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.953612470020825, \"precision\": 1.0, \"recall\": 0.04638752997917496, \"specificity\": 1.0, \"npv\": 0.9997733739381474, \"accuracy\": 0.9997733764364454, \"f1\": 0.0886622377468473, \"f2\": 0.057319682847349146, \"f0_5\": 0.19563715274405388, \"p4\": 0.16288140855104188, \"phi\": 0.2153532385545588}, {\"truth_threshold\": 36.47999918460846, \"match_probability\": 0.9999999999895666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 14050.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289911.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04622303519201477, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9537769648079852, \"precision\": 1.0, \"recall\": 0.04622303519201477, \"specificity\": 1.0, \"npv\": 0.999773334854812, \"accuracy\": 0.9997733373446801, \"f1\": 0.08836172333661414, \"f2\": 0.05711874356651874, \"f0_5\": 0.19505165745319455, \"p4\": 0.16237415967322955, \"phi\": 0.21497106326441226}, {\"truth_threshold\": 36.499999184161425, \"match_probability\": 0.9999999999897102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13992.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 289969.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04603222123890894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9539677787610911, \"precision\": 1.0, \"recall\": 0.04603222123890894, \"specificity\": 1.0, \"npv\": 0.9997732895181467, \"accuracy\": 0.9997732919982324, \"f1\": 0.08801300821190554, \"f2\": 0.05688563353162535, \"f0_5\": 0.19437166774558315, \"p4\": 0.16178519984691853, \"phi\": 0.21452688701384515}, {\"truth_threshold\": 36.51999918371439, \"match_probability\": 0.9999999999898519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13957.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0459170748878968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9540829251121032, \"precision\": 1.0, \"recall\": 0.0459170748878968, \"specificity\": 1.0, \"npv\": 0.9997732621598162, \"accuracy\": 0.9997732646339966, \"f1\": 0.0878025151139602, \"f2\": 0.056744953045248785, \"f0_5\": 0.193960904863684, \"p4\": 0.161429506313905, \"phi\": 0.2142584041514105}, {\"truth_threshold\": 36.539999183267355, \"match_probability\": 0.9999999999899916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13898.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290063.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04572297103904777, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9542770289609522, \"precision\": 1.0, \"recall\": 0.04572297103904777, \"specificity\": 1.0, \"npv\": 0.9997732160414912, \"accuracy\": 0.9997732185057137, \"f1\": 0.08744757895796564, \"f2\": 0.056507787812402926, \"f0_5\": 0.1932677519030574, \"p4\": 0.16082941943805812, \"phi\": 0.21380505560599064}, {\"truth_threshold\": 36.55999918282032, \"match_probability\": 0.9999999999901295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13873.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290088.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04564072364546767, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9543592763545323, \"precision\": 1.0, \"recall\": 0.04564072364546767, \"specificity\": 1.0, \"npv\": 0.9997731964998292, \"accuracy\": 0.999773198959831, \"f1\": 0.08729714253352379, \"f2\": 0.05640728720510491, \"f0_5\": 0.1929737684759899, \"p4\": 0.16057495990830134, \"phi\": 0.21361266856063232}, {\"truth_threshold\": 36.579999182373285, \"match_probability\": 0.9999999999902653, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13826.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04548609854553709, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9545139014544629, \"precision\": 1.0, \"recall\": 0.04548609854553709, \"specificity\": 1.0, \"npv\": 0.9997731597615069, \"accuracy\": 0.9997731622135716, \"f1\": 0.08701425797782791, \"f2\": 0.056218335000447275, \"f0_5\": 0.19242063657745676, \"p4\": 0.16009627684546698, \"phi\": 0.21325051106174378}, {\"truth_threshold\": 36.59999918192625, \"match_probability\": 0.9999999999903993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13757.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290204.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.045259095739256024, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.954740904260744, \"precision\": 1.0, \"recall\": 0.045259095739256024, \"specificity\": 1.0, \"npv\": 0.999773105826528, \"accuracy\": 0.9997731082669356, \"f1\": 0.08659880774775115, \"f2\": 0.05594091091337759, \"f0_5\": 0.19160754229238222, \"p4\": 0.15939282094656337, \"phi\": 0.21271771603262424}, {\"truth_threshold\": 36.619999181479216, \"match_probability\": 0.9999999999905315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13715.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290246.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04512092011804146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9548790798819585, \"precision\": 1.0, \"recall\": 0.04512092011804146, \"specificity\": 1.0, \"npv\": 0.9997730729965436, \"accuracy\": 0.9997730754298527, \"f1\": 0.08634583663858775, \"f2\": 0.05577202883310195, \"f0_5\": 0.19111200292067632, \"p4\": 0.15896421720502665, \"phi\": 0.2123927516720989}, {\"truth_threshold\": 36.63999918103218, \"match_probability\": 0.9999999999906618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13619.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04480509012669388, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9551949098733061, \"precision\": 1.0, \"recall\": 0.04480509012669388, \"specificity\": 1.0, \"npv\": 0.9997729979565876, \"accuracy\": 0.9997730003736633, \"f1\": 0.08576736570312991, \"f2\": 0.055385969321565594, \"f0_5\": 0.18997759717886267, \"p4\": 0.15798337522127456, \"phi\": 0.21164810247124788}, {\"truth_threshold\": 36.659999180585146, \"match_probability\": 0.9999999999907904, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13588.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.044703103358654565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9552968966413454, \"precision\": 1.0, \"recall\": 0.044703103358654565, \"specificity\": 1.0, \"npv\": 0.9997729737249375, \"accuracy\": 0.9997729761367689, \"f1\": 0.08558049308925551, \"f2\": 0.0552612913930986, \"f0_5\": 0.1896107593082026, \"p4\": 0.15766629491728662, \"phi\": 0.21140708261459762}, {\"truth_threshold\": 36.67999918013811, \"match_probability\": 0.9999999999909172, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13525.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290436.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04449583992683272, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9555041600731673, \"precision\": 1.0, \"recall\": 0.04449583992683272, \"specificity\": 1.0, \"npv\": 0.9997729244799748, \"accuracy\": 0.9997729268811446, \"f1\": 0.08520060727087178, \"f2\": 0.055007894293739305, \"f0_5\": 0.18886446722765116, \"p4\": 0.15702137845385067, \"phi\": 0.21091641949085516}, {\"truth_threshold\": 36.699999179691076, \"match_probability\": 0.9999999999910423, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13481.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290480.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04435108451413175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9556489154858683, \"precision\": 1.0, \"recall\": 0.04435108451413175, \"specificity\": 1.0, \"npv\": 0.9997728900866705, \"accuracy\": 0.9997728924803911, \"f1\": 0.08493520076108392, \"f2\": 0.05483090313790088, \"f0_5\": 0.18834262402727134, \"p4\": 0.15657054077181365, \"phi\": 0.21057305607121646}, {\"truth_threshold\": 36.71999917924404, \"match_probability\": 0.9999999999911655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13387.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290574.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.044041834314270584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9559581656857294, \"precision\": 1.0, \"recall\": 0.044041834314270584, \"specificity\": 1.0, \"npv\": 0.9997728166100736, \"accuracy\": 0.9997728189878724, \"f1\": 0.08436794938049082, \"f2\": 0.05445274321913456, \"f0_5\": 0.1872260558475451, \"p4\": 0.1556062287404168, \"phi\": 0.20983762470313203}, {\"truth_threshold\": 36.73999917879701, \"match_probability\": 0.9999999999912872, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13325.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290636.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04383786077819194, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.956162139221808, \"precision\": 1.0, \"recall\": 0.04383786077819194, \"specificity\": 1.0, \"npv\": 0.9997727681467922, \"accuracy\": 0.9997727705140834, \"f1\": 0.08399362089723467, \"f2\": 0.05420328693613327, \"f0_5\": 0.1864883096671621, \"p4\": 0.15496932762849952, \"phi\": 0.20935113904597377}, {\"truth_threshold\": 36.75999917834997, \"match_probability\": 0.9999999999914071, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13274.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04367007609528854, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9563299239047115, \"precision\": 1.0, \"recall\": 0.04367007609528854, \"specificity\": 1.0, \"npv\": 0.9997727282818384, \"accuracy\": 0.9997727306404829, \"f1\": 0.0836855958516557, \"f2\": 0.05399807016087959, \"f0_5\": 0.18588068571684632, \"p4\": 0.1544449084566254, \"phi\": 0.20895011634852495}, {\"truth_threshold\": 36.77999917790294, \"match_probability\": 0.9999999999915254, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13221.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290740.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.043495711620898735, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9565042883791013, \"precision\": 1.0, \"recall\": 0.043495711620898735, \"specificity\": 1.0, \"npv\": 0.9997726868535565, \"accuracy\": 0.9997726892032116, \"f1\": 0.08336538643428694, \"f2\": 0.053784787623111875, \"f0_5\": 0.18524849724670375, \"p4\": 0.15389942896826875, \"phi\": 0.2085325501542466}, {\"truth_threshold\": 36.7999991774559, \"match_probability\": 0.9999999999916421, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13178.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.043354246103940966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.956645753896059, \"precision\": 1.0, \"recall\": 0.043354246103940966, \"specificity\": 1.0, \"npv\": 0.999772653241934, \"accuracy\": 0.9997726555842935, \"f1\": 0.08310551524725751, \"f2\": 0.05361173355725121, \"f0_5\": 0.18473503741522346, \"p4\": 0.15345649905684128, \"phi\": 0.2081931546824747}, {\"truth_threshold\": 36.81999917700887, \"match_probability\": 0.9999999999917571, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13149.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290812.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04325883912738805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.956741160872612, \"precision\": 1.0, \"recall\": 0.04325883912738805, \"specificity\": 1.0, \"npv\": 0.9997726305736317, \"accuracy\": 0.9997726329110697, \"f1\": 0.08293021349058687, \"f2\": 0.05349501583816995, \"f0_5\": 0.18438847084757837, \"p4\": 0.15315759098095869, \"phi\": 0.2079639473321044}, {\"truth_threshold\": 36.83999917656183, \"match_probability\": 0.9999999999918706, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13120.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04316343215083514, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9568365678491648, \"precision\": 1.0, \"recall\": 0.04316343215083514, \"specificity\": 1.0, \"npv\": 0.9997726079053306, \"accuracy\": 0.9997726102378458, \"f1\": 0.08275487966797128, \"f2\": 0.053378292610686724, \"f0_5\": 0.18404167870699498, \"p4\": 0.15285853140512093, \"phi\": 0.20773448709250286}, {\"truth_threshold\": 36.8599991761148, \"match_probability\": 0.9999999999919826, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13071.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04300222725941815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9569977727405818, \"precision\": 1.0, \"recall\": 0.04300222725941815, \"specificity\": 1.0, \"npv\": 0.9997725696037206, \"accuracy\": 0.9997725719279158, \"f1\": 0.08245855307981528, \"f2\": 0.05318105808782544, \"f0_5\": 0.1834552063888616, \"p4\": 0.15235287927133417, \"phi\": 0.2073462014260971}, {\"truth_threshold\": 36.87999917566776, \"match_probability\": 0.999999999992093, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13035.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290926.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042883791012662806, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9571162089873372, \"precision\": 1.0, \"recall\": 0.042883791012662806, \"specificity\": 1.0, \"npv\": 0.999772541463764, \"accuracy\": 0.9997725437818448, \"f1\": 0.08224078537268609, \"f2\": 0.05303614106840462, \"f0_5\": 0.18302391737175688, \"p4\": 0.1519811035933624, \"phi\": 0.2070604663578512}, {\"truth_threshold\": 36.89999917522073, \"match_probability\": 0.9999999999922018, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12980.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 290981.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042702846746786594, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9572971532532134, \"precision\": 1.0, \"recall\": 0.042702846746786594, \"specificity\": 1.0, \"npv\": 0.9997724984721669, \"accuracy\": 0.999772500780903, \"f1\": 0.08190798918410683, \"f2\": 0.05281472367076164, \"f0_5\": 0.18236432964951768, \"p4\": 0.15141266074242363, \"phi\": 0.20662316371575787}, {\"truth_threshold\": 36.91999917477369, \"match_probability\": 0.9999999999923092, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12934.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042551511542599216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9574484884574008, \"precision\": 1.0, \"recall\": 0.042551511542599216, \"specificity\": 1.0, \"npv\": 0.9997724625155612, \"accuracy\": 0.9997724648164789, \"f1\": 0.08162956184225059, \"f2\": 0.05262952298950665, \"f0_5\": 0.1818120478946969, \"p4\": 0.1509368155151254, \"phi\": 0.2062567077180855}, {\"truth_threshold\": 36.93999917432666, \"match_probability\": 0.9999999999924151, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12892.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291069.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04241333592138465, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9575866640786154, \"precision\": 1.0, \"recall\": 0.04241333592138465, \"specificity\": 1.0, \"npv\": 0.9997724296856191, \"accuracy\": 0.999772431979396, \"f1\": 0.08137527496978093, \"f2\": 0.05246041460492734, \"f0_5\": 0.18130729138832558, \"p4\": 0.15050201335872887, \"phi\": 0.2059215479380317}, {\"truth_threshold\": 36.95999917387962, \"match_probability\": 0.9999999999925194, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12845.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291116.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04225871082145407, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.957741289178546, \"precision\": 1.0, \"recall\": 0.04225871082145407, \"specificity\": 1.0, \"npv\": 0.9997723929473531, \"accuracy\": 0.9997723952331367, \"f1\": 0.08109063590967343, \"f2\": 0.05227116056219271, \"f0_5\": 0.18074187892756535, \"p4\": 0.15001506970652315, \"phi\": 0.2055458402421108}, {\"truth_threshold\": 36.97999917343259, \"match_probability\": 0.9999999999926225, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12801.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042113955408753095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9578860445912469, \"precision\": 1.0, \"recall\": 0.042113955408753095, \"specificity\": 1.0, \"npv\": 0.9997723585540853, \"accuracy\": 0.9997723608323832, \"f1\": 0.08082408874801902, \"f2\": 0.05209397344228805, \"f0_5\": 0.18021201413427562, \"p4\": 0.14955884403906253, \"phi\": 0.20519349045973817}, {\"truth_threshold\": 36.999999172985554, \"match_probability\": 0.999999999992724, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12783.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.042054737285375426, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9579452627146245, \"precision\": 1.0, \"recall\": 0.042054737285375426, \"specificity\": 1.0, \"npv\": 0.9997723444841128, \"accuracy\": 0.9997723467593478, \"f1\": 0.08071502538327482, \"f2\": 0.052021484144496255, \"f0_5\": 0.17999509987524395, \"p4\": 0.1493721048470664, \"phi\": 0.20504917286461613}, {\"truth_threshold\": 37.01999917253852, \"match_probability\": 0.9999999999928242, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12728.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041873793019499214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9581262069805008, \"precision\": 1.0, \"recall\": 0.041873793019499214, \"specificity\": 1.0, \"npv\": 0.9997723014925326, \"accuracy\": 0.999772303758406, \"f1\": 0.08038169939593734, \"f2\": 0.05179997590698795, \"f0_5\": 0.17933176093982917, \"p4\": 0.14880114762525448, \"phi\": 0.20460757175463148}, {\"truth_threshold\": 37.039999172091484, \"match_probability\": 0.999999999992923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12695.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291266.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041765226459973485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9582347735400265, \"precision\": 1.0, \"recall\": 0.041765226459973485, \"specificity\": 1.0, \"npv\": 0.9997722756975862, \"accuracy\": 0.9997722779578408, \"f1\": 0.08018164822394018, \"f2\": 0.051667061444528824, \"f0_5\": 0.1789333626504971, \"p4\": 0.14845830886841527, \"phi\": 0.20434215302504943}, {\"truth_threshold\": 37.05999917164445, \"match_probability\": 0.9999999999930205, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12654.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291307.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04163034073450212, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9583696592654979, \"precision\": 1.0, \"recall\": 0.04163034073450212, \"specificity\": 1.0, \"npv\": 0.9997722436493214, \"accuracy\": 0.9997722459025933, \"f1\": 0.07993304170680479, \"f2\": 0.05150191534703353, \"f0_5\": 0.17843796974987097, \"p4\": 0.14803208111206137, \"phi\": 0.20401190935829933}, {\"truth_threshold\": 37.079999171197414, \"match_probability\": 0.9999999999931165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12606.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291355.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04147242573882834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9585275742611716, \"precision\": 1.0, \"recall\": 0.04147242573882834, \"specificity\": 1.0, \"npv\": 0.9997722061294042, \"accuracy\": 0.9997722083744986, \"f1\": 0.07964190834799584, \"f2\": 0.05130855956693394, \"f0_5\": 0.17785741495830806, \"p4\": 0.14753269291877788, \"phi\": 0.20362460208542163}, {\"truth_threshold\": 37.09999917075038, \"match_probability\": 0.9999999999932113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12541.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291420.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04125858251552008, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9587414174844799, \"precision\": 1.0, \"recall\": 0.04125858251552008, \"specificity\": 1.0, \"npv\": 0.9997721553211875, \"accuracy\": 0.9997721575552038, \"f1\": 0.07924752450221484, \"f2\": 0.05104669952824237, \"f0_5\": 0.17707024355806567, \"p4\": 0.14685576689389207, \"phi\": 0.2030989462479768}, {\"truth_threshold\": 37.119999170303345, \"match_probability\": 0.9999999999933048, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12484.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291477.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.041071058458157464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9589289415418425, \"precision\": 1.0, \"recall\": 0.041071058458157464, \"specificity\": 1.0, \"npv\": 0.999772110766294, \"accuracy\": 0.9997721129905913, \"f1\": 0.07890154687228429, \"f2\": 0.05081704560996737, \"f0_5\": 0.17637900293023112, \"p4\": 0.14626151844141064, \"phi\": 0.20263686438088685}, {\"truth_threshold\": 37.13999916985631, \"match_probability\": 0.999999999993397, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12414.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291547.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.040840765756133185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9591592342438668, \"precision\": 1.0, \"recall\": 0.040840765756133185, \"specificity\": 1.0, \"npv\": 0.9997720560497635, \"accuracy\": 0.9997720582621199, \"f1\": 0.07847649150533385, \"f2\": 0.05053498532067367, \"f0_5\": 0.17552889142773112, \"p4\": 0.1455309246923534, \"phi\": 0.20206794983533646}, {\"truth_threshold\": 37.159999169409275, \"match_probability\": 0.9999999999934879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12356.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291605.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.040649951803027363, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9593500481969727, \"precision\": 1.0, \"recall\": 0.040649951803027363, \"specificity\": 1.0, \"npv\": 0.9997720107132143, \"accuracy\": 0.9997720129156722, \"f1\": 0.07812416025695743, \"f2\": 0.0503012538674483, \"f0_5\": 0.17482349279114848, \"p4\": 0.1449248939190236, \"phi\": 0.20159534729131995}, {\"truth_threshold\": 37.17999916896224, \"match_probability\": 0.9999999999935775, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12331.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291630.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.040567704409447264, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9594322955905528, \"precision\": 1.0, \"recall\": 0.040567704409447264, \"specificity\": 1.0, \"npv\": 0.9997719911715995, \"accuracy\": 0.9997719933697895, \"f1\": 0.0779722534872839, \"f2\": 0.0502005007429723, \"f0_5\": 0.17451915592227238, \"p4\": 0.1446634829764091, \"phi\": 0.2013912972665253}, {\"truth_threshold\": 37.199999168515205, \"match_probability\": 0.999999999993666, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12267.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291694.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04035715108188222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9596428489181178, \"precision\": 1.0, \"recall\": 0.04035715108188222, \"specificity\": 1.0, \"npv\": 0.9997719411450691, \"accuracy\": 0.99977194333233, \"f1\": 0.07758326270918452, \"f2\": 0.04994255405252457, \"f0_5\": 0.1737392678788428, \"p4\": 0.1439937465782422, \"phi\": 0.20086798469696016}, {\"truth_threshold\": 37.21999916806817, \"match_probability\": 0.9999999999937531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12222.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04020910577343804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9597908942265619, \"precision\": 1.0, \"recall\": 0.04020910577343804, \"specificity\": 1.0, \"npv\": 0.999771905970168, \"accuracy\": 0.9997719081497413, \"f1\": 0.0773096592795944, \"f2\": 0.04976116918797524, \"f0_5\": 0.17319023151546412, \"p4\": 0.14352238607626294, \"phi\": 0.20049921275772192}, {\"truth_threshold\": 37.239999167621136, \"match_probability\": 0.9999999999938392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12178.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.04006435036073707, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9599356496392629, \"precision\": 1.0, \"recall\": 0.04006435036073707, \"specificity\": 1.0, \"npv\": 0.9997718715769336, \"accuracy\": 0.9997718737489878, \"f1\": 0.07704206061257865, \"f2\": 0.049583802244585196, \"f0_5\": 0.1726528540602768, \"p4\": 0.14306113882524926, \"phi\": 0.20013797876382208}, {\"truth_threshold\": 37.2599991671741, \"match_probability\": 0.999999999993924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12134.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291827.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0399195949480361, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9600804050519639, \"precision\": 1.0, \"recall\": 0.0399195949480361, \"specificity\": 1.0, \"npv\": 0.9997718371837017, \"accuracy\": 0.9997718393482343, \"f1\": 0.07677438744681188, \"f2\": 0.04940642259063273, \"f0_5\": 0.17211493998530483, \"p4\": 0.14259953378938364, \"phi\": 0.1997760916146556}, {\"truth_threshold\": 37.279999166727066, \"match_probability\": 0.9999999999940076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12086.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291875.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03976167995236231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9602383200476377, \"precision\": 1.0, \"recall\": 0.03976167995236231, \"specificity\": 1.0, \"npv\": 0.999771799663815, \"accuracy\": 0.9997718018201397, \"f1\": 0.07648229535480483, \"f2\": 0.04921290301564422, \"f0_5\": 0.17152751167312413, \"p4\": 0.1420955561178097, \"phi\": 0.19938055653355444}, {\"truth_threshold\": 37.29999916628003, \"match_probability\": 0.9999999999940901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12056.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.039662983080066196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9603370169199338, \"precision\": 1.0, \"recall\": 0.039662983080066196, \"specificity\": 1.0, \"npv\": 0.9997717762138872, \"accuracy\": 0.9997717783650805, \"f1\": 0.0762996927380489, \"f2\": 0.04909194559817575, \"f0_5\": 0.17116004372701846, \"p4\": 0.14178035335749636, \"phi\": 0.19913294816252564}, {\"truth_threshold\": 37.319999165832996, \"match_probability\": 0.9999999999941714, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12014.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291947.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03952480745885163, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9604751925411483, \"precision\": 1.0, \"recall\": 0.03952480745885163, \"specificity\": 1.0, \"npv\": 0.9997717433839902, \"accuracy\": 0.9997717455279976, \"f1\": 0.0760439908220587, \"f2\": 0.04892259528381947, \"f0_5\": 0.1706451677049688, \"p4\": 0.14133878913328426, \"phi\": 0.198785778314377}, {\"truth_threshold\": 37.33999916538596, \"match_probability\": 0.9999999999942517, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11983.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 291978.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03942282069081231, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9605771793091877, \"precision\": 1.0, \"recall\": 0.03942282069081231, \"specificity\": 1.0, \"npv\": 0.9997717191524009, \"accuracy\": 0.9997717212911031, \"f1\": 0.07585521484820094, \"f2\": 0.04879759119159295, \"f0_5\": 0.17026482481890803, \"p4\": 0.1410126626850624, \"phi\": 0.19852914449997072}, {\"truth_threshold\": 37.35999916493893, \"match_probability\": 0.9999999999943309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11924.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03922871684196328, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9607712831580367, \"precision\": 1.0, \"recall\": 0.03922871684196328, \"specificity\": 1.0, \"npv\": 0.9997716730342182, \"accuracy\": 0.9997716751628201, \"f1\": 0.07549582917834022, \"f2\": 0.0485596627375856, \"f0_5\": 0.16954020537057415, \"p4\": 0.14039147709224584, \"phi\": 0.19803979364783036}, {\"truth_threshold\": 37.37999916449189, \"match_probability\": 0.9999999999944089, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11884.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292077.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03909712101223512, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9609028789877648, \"precision\": 1.0, \"recall\": 0.03909712101223512, \"specificity\": 1.0, \"npv\": 0.999771641767656, \"accuracy\": 0.9997716438894079, \"f1\": 0.07525210150548528, \"f2\": 0.04839834230383277, \"f0_5\": 0.16904838448123313, \"p4\": 0.1399699659949761, \"phi\": 0.19770734144889773}, {\"truth_threshold\": 37.39999916404486, \"match_probability\": 0.9999999999944859, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11826.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292135.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03890630705912929, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9610936929408707, \"precision\": 1.0, \"recall\": 0.03890630705912929, \"specificity\": 1.0, \"npv\": 0.9997715964311443, \"accuracy\": 0.9997715985429602, \"f1\": 0.07489858670559586, \"f2\": 0.048164409002419216, \"f0_5\": 0.1683344483509601, \"p4\": 0.13935824549731549, \"phi\": 0.1972242903897641}, {\"truth_threshold\": 37.41999916359782, \"match_probability\": 0.9999999999945618, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11798.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292163.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.038814189978319584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9611858100216805, \"precision\": 1.0, \"recall\": 0.038814189978319584, \"specificity\": 1.0, \"npv\": 0.999771574544554, \"accuracy\": 0.9997715766515716, \"f1\": 0.07472787790688468, \"f2\": 0.048051467773178175, \"f0_5\": 0.16798945189134082, \"p4\": 0.13906270762313558, \"phi\": 0.1969906693965377}, {\"truth_threshold\": 37.43999916315079, \"match_probability\": 0.9999999999946366, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11739.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292222.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03862008612947056, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9613799138705295, \"precision\": 1.0, \"recall\": 0.03862008612947056, \"specificity\": 1.0, \"npv\": 0.9997715284263845, \"accuracy\": 0.9997715305232886, \"f1\": 0.07436807095343681, \"f2\": 0.04781346760259795, \"f0_5\": 0.1672617741517225, \"p4\": 0.13843948786947854, \"phi\": 0.19649748735701275}, {\"truth_threshold\": 37.45999916270375, \"match_probability\": 0.9999999999947105, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11694.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292267.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.038472040821026385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9615279591789736, \"precision\": 1.0, \"recall\": 0.038472040821026385, \"specificity\": 1.0, \"npv\": 0.9997714932515124, \"accuracy\": 0.9997714953406998, \"f1\": 0.07409355150401546, \"f2\": 0.047631926669479886, \"f0_5\": 0.16670610742522174, \"p4\": 0.1379637133192854, \"phi\": 0.1961204979089914}, {\"truth_threshold\": 37.47999916225672, \"match_probability\": 0.9999999999947833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11663.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292298.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03837005405298706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9616299459470129, \"precision\": 1.0, \"recall\": 0.03837005405298706, \"specificity\": 1.0, \"npv\": 0.9997714690199353, \"accuracy\": 0.9997714711038053, \"f1\": 0.07390439256837249, \"f2\": 0.04750685739470325, \"f0_5\": 0.166322982889967, \"p4\": 0.13763573703435367, \"phi\": 0.1958603719666875}, {\"truth_threshold\": 37.49999916180968, \"match_probability\": 0.9999999999948551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11622.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292339.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0382351683275157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9617648316724843, \"precision\": 1.0, \"recall\": 0.0382351683275157, \"specificity\": 1.0, \"npv\": 0.9997714369717221, \"accuracy\": 0.9997714390485578, \"f1\": 0.07365415754334043, \"f2\": 0.047341433489807454, \"f0_5\": 0.1658158533766682, \"p4\": 0.13720168540192226, \"phi\": 0.19551580289494772}, {\"truth_threshold\": 37.51999916136265, \"match_probability\": 0.999999999994926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11563.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292398.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03804106447866667, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9619589355213334, \"precision\": 1.0, \"recall\": 0.03804106447866667, \"specificity\": 1.0, \"npv\": 0.9997713908535654, \"accuracy\": 0.9997713929202747, \"f1\": 0.07329394911322118, \"f2\": 0.04710336506146698, \"f0_5\": 0.16508524812042957, \"p4\": 0.13657652115765062, \"phi\": 0.19501889124745517}, {\"truth_threshold\": 37.53999916091561, \"match_probability\": 0.9999999999949958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11514.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292447.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03787985958724968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9621201404127503, \"precision\": 1.0, \"recall\": 0.03787985958724968, \"specificity\": 1.0, \"npv\": 0.9997713525520486, \"accuracy\": 0.9997713546103447, \"f1\": 0.07299469054600206, \"f2\": 0.046905629816239434, \"f0_5\": 0.164477725367625, \"p4\": 0.1360568199647918, \"phi\": 0.1946052374784047}, {\"truth_threshold\": 37.55999916046858, \"match_probability\": 0.9999999999950647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11478.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292483.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.037761423340494336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9622385766595056, \"precision\": 1.0, \"recall\": 0.037761423340494336, \"specificity\": 1.0, \"npv\": 0.9997713244121607, \"accuracy\": 0.9997713264642738, \"f1\": 0.07277476786320017, \"f2\": 0.04676034488096848, \"f0_5\": 0.16403094837269525, \"p4\": 0.1356747109381765, \"phi\": 0.1943007674323864}, {\"truth_threshold\": 37.57999916002154, \"match_probability\": 0.9999999999951327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11446.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292515.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03765614667671181, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9623438533232882, \"precision\": 1.0, \"recall\": 0.03765614667671181, \"specificity\": 1.0, \"npv\": 0.9997712993989282, \"accuracy\": 0.9997713014455439, \"f1\": 0.07257923888816671, \"f2\": 0.04663119556095136, \"f0_5\": 0.16363350441035612, \"p4\": 0.135334853641175, \"phi\": 0.1940297263136059}, {\"truth_threshold\": 37.59999915957451, \"match_probability\": 0.9999999999951996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11403.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292558.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.037514681159754044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9624853188402459, \"precision\": 1.0, \"recall\": 0.037514681159754044, \"specificity\": 1.0, \"npv\": 0.999771265787399, \"accuracy\": 0.9997712678266258, \"f1\": 0.07231643434253751, \"f2\": 0.046457640556465, \"f0_5\": 0.16309898075652296, \"p4\": 0.1348778665271273, \"phi\": 0.19366491749591097}, {\"truth_threshold\": 37.619999159127474, \"match_probability\": 0.9999999999952658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11370.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292591.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.037406114600228316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9625938853997716, \"precision\": 1.0, \"recall\": 0.037406114600228316, \"specificity\": 1.0, \"npv\": 0.9997712399925061, \"accuracy\": 0.9997712420260607, \"f1\": 0.07211469852313918, \"f2\": 0.04632443893241114, \"f0_5\": 0.1626884080574403, \"p4\": 0.134526918946755, \"phi\": 0.1933844812211467}, {\"truth_threshold\": 37.63999915868044, \"match_probability\": 0.999999999995331, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11341.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03731070762367541, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9626892923763246, \"precision\": 1.0, \"recall\": 0.03731070762367541, \"specificity\": 1.0, \"npv\": 0.999771217324268, \"accuracy\": 0.9997712193528369, \"f1\": 0.07193738066996086, \"f2\": 0.046207377045840686, \"f0_5\": 0.16232734559507622, \"p4\": 0.13421834073251185, \"phi\": 0.19313770108436054}, {\"truth_threshold\": 37.659999158233404, \"match_probability\": 0.9999999999953952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11292.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.037149502732258415, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9628504972677416, \"precision\": 1.0, \"recall\": 0.037149502732258415, \"specificity\": 1.0, \"npv\": 0.9997711790227645, \"accuracy\": 0.9997711810429069, \"f1\": 0.07163770051355578, \"f2\": 0.04600957025138208, \"f0_5\": 0.16171672934645934, \"p4\": 0.13369658879718826, \"phi\": 0.19272000972068107}, {\"truth_threshold\": 37.67999915778637, \"match_probability\": 0.9999999999954586, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11251.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292710.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03701461700678706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9629853829932129, \"precision\": 1.0, \"recall\": 0.03701461700678706, \"specificity\": 1.0, \"npv\": 0.9997711469745699, \"accuracy\": 0.9997711489876594, \"f1\": 0.07138687613415733, \"f2\": 0.045844046304483355, \"f0_5\": 0.16120527846632185, \"p4\": 0.13325967179646564, \"phi\": 0.19236981597875466}, {\"truth_threshold\": 37.699999157339334, \"match_probability\": 0.9999999999955211, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11216.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292745.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03689947065577492, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9631005293442251, \"precision\": 1.0, \"recall\": 0.03689947065577492, \"specificity\": 1.0, \"npv\": 0.9997711196163568, \"accuracy\": 0.9997711216234236, \"f1\": 0.0711727061302062, \"f2\": 0.04570273662249605, \"f0_5\": 0.16076829355694117, \"p4\": 0.13288644196731508, \"phi\": 0.19207036494674284}, {\"truth_threshold\": 37.7199991568923, \"match_probability\": 0.9999999999955828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11186.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292775.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036800773783478805, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9631992262165212, \"precision\": 1.0, \"recall\": 0.036800773783478805, \"specificity\": 1.0, \"npv\": 0.9997710961664609, \"accuracy\": 0.9997710981683645, \"f1\": 0.07098909397836566, \"f2\": 0.04558160762165554, \"f0_5\": 0.1603934557864097, \"p4\": 0.13256634584640067, \"phi\": 0.1918133205626829}, {\"truth_threshold\": 37.739999156445265, \"match_probability\": 0.9999999999956436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036659308266521036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9633406917334789, \"precision\": 1.0, \"recall\": 0.036659308266521036, \"specificity\": 1.0, \"npv\": 0.9997710625549454, \"accuracy\": 0.9997710645494463, \"f1\": 0.0707258555905352, \"f2\": 0.04540797905764283, \"f0_5\": 0.1598557381940878, \"p4\": 0.13210724357761186, \"phi\": 0.1914442884448346}, {\"truth_threshold\": 37.75999915599823, \"match_probability\": 0.9999999999957035, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11105.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03653429222827929, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9634657077717207, \"precision\": 1.0, \"recall\": 0.03653429222827929, \"specificity\": 1.0, \"npv\": 0.9997710328517476, \"accuracy\": 0.9997710348397048, \"f1\": 0.07049316651114369, \"f2\": 0.04525452973187965, \"f0_5\": 0.15938010396663424, \"p4\": 0.13170123296407793, \"phi\": 0.19111757395795487}, {\"truth_threshold\": 37.779999155551195, \"match_probability\": 0.9999999999957627, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11051.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292910.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03635663785814627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9636433621418538, \"precision\": 1.0, \"recall\": 0.03635663785814627, \"specificity\": 1.0, \"npv\": 0.9997709906419432, \"accuracy\": 0.9997709926205982, \"f1\": 0.07016240651149798, \"f2\": 0.045036453812265925, \"f0_5\": 0.1587034882885988, \"p4\": 0.13112379811631739, \"phi\": 0.19065233239551327}, {\"truth_threshold\": 37.79999915510416, \"match_probability\": 0.999999999995821, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 11018.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036248071298620545, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9637519287013795, \"precision\": 1.0, \"recall\": 0.036248071298620545, \"specificity\": 1.0, \"npv\": 0.9997709648470644, \"accuracy\": 0.9997709668200331, \"f1\": 0.06996021957019356, \"f2\": 0.04490317574429724, \"f0_5\": 0.15828958748164684, \"p4\": 0.13077064796359983, \"phi\": 0.1903674583957748}, {\"truth_threshold\": 37.819999154657125, \"match_probability\": 0.9999999999958786, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10981.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 292980.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.036126345156122, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.963873654843878, \"precision\": 1.0, \"recall\": 0.036126345156122, \"specificity\": 1.0, \"npv\": 0.9997709359255353, \"accuracy\": 0.9997709378921268, \"f1\": 0.06973347473503058, \"f2\": 0.04475373423267377, \"f0_5\": 0.15782514336634232, \"p4\": 0.13037444490764388, \"phi\": 0.19004754644116043}, {\"truth_threshold\": 37.83999915421009, \"match_probability\": 0.9999999999959354, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10942.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293019.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03599803922213705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9640019607778629, \"precision\": 1.0, \"recall\": 0.03599803922213705, \"specificity\": 1.0, \"npv\": 0.9997709054406821, \"accuracy\": 0.9997709074005499, \"f1\": 0.06949441574072016, \"f2\": 0.04459620504309635, \"f0_5\": 0.15733516617825952, \"p4\": 0.12995654273009585, \"phi\": 0.18970975796517467}, {\"truth_threshold\": 37.859999153763056, \"match_probability\": 0.9999999999959913, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10900.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293061.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.035859863600922484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9641401363990775, \"precision\": 1.0, \"recall\": 0.035859863600922484, \"specificity\": 1.0, \"npv\": 0.9997708726108423, \"accuracy\": 0.999770874563467, \"f1\": 0.0692369013628236, \"f2\": 0.044426547022035565, \"f0_5\": 0.15680700653985918, \"p4\": 0.12950616936829606, \"phi\": 0.18934531186168846}, {\"truth_threshold\": 37.87999915331602, \"match_probability\": 0.9999999999960465, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10851.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293110.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0356986587095055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9643013412904945, \"precision\": 1.0, \"recall\": 0.0356986587095055, \"specificity\": 1.0, \"npv\": 0.9997708343093653, \"accuracy\": 0.999770836253537, \"f1\": 0.06893638107823082, \"f2\": 0.04422859798075316, \"f0_5\": 0.1561901746002044, \"p4\": 0.12898030748833614, \"phi\": 0.18891923618765666}, {\"truth_threshold\": 37.899999152868986, \"match_probability\": 0.9999999999961009, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10808.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293153.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03555719319254773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9644428068074523, \"precision\": 1.0, \"recall\": 0.03555719319254773, \"specificity\": 1.0, \"npv\": 0.9997708006978674, \"accuracy\": 0.9997708026346189, \"f1\": 0.06867258211577379, \"f2\": 0.044054874569152455, \"f0_5\": 0.1556482993608742, \"p4\": 0.12851845820378927, \"phi\": 0.1885445398538027}, {\"truth_threshold\": 37.91999915242195, \"match_probability\": 0.9999999999961546, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10746.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293215.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.035353219656469086, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9646467803435309, \"precision\": 1.0, \"recall\": 0.035353219656469086, \"specificity\": 1.0, \"npv\": 0.9997707522347814, \"accuracy\": 0.9997707541608299, \"f1\": 0.06829209391592815, \"f2\": 0.043804368207795596, \"f0_5\": 0.15486604505036822, \"p4\": 0.1278519120076, \"phi\": 0.18800296542839307}, {\"truth_threshold\": 37.93999915197492, \"match_probability\": 0.9999999999962075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10674.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293287.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0351163471629584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9648836528370416, \"precision\": 1.0, \"recall\": 0.0351163471629584, \"specificity\": 1.0, \"npv\": 0.9997706959550746, \"accuracy\": 0.999770697868688, \"f1\": 0.06785004846886074, \"f2\": 0.04351342581193264, \"f0_5\": 0.15395621608679472, \"p4\": 0.12707693215507773, \"phi\": 0.18737207594118965}, {\"truth_threshold\": 37.95999915152788, \"match_probability\": 0.9999999999962598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10601.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293360.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03487618477370452, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9651238152262955, \"precision\": 1.0, \"recall\": 0.03487618477370452, \"specificity\": 1.0, \"npv\": 0.9997706388937116, \"accuracy\": 0.9997706407947107, \"f1\": 0.06740165690706443, \"f2\": 0.043218407674212866, \"f0_5\": 0.15303220590995048, \"p4\": 0.12629017065684103, \"phi\": 0.18673024804080807}, {\"truth_threshold\": 37.97999915108085, \"match_probability\": 0.9999999999963113, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10565.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293396.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.034757748526949184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9652422514730509, \"precision\": 1.0, \"recall\": 0.034757748526949184, \"specificity\": 1.0, \"npv\": 0.9997706107538638, \"accuracy\": 0.9997706126486396, \"f1\": 0.06718045566980155, \"f2\": 0.04307290634690385, \"f0_5\": 0.15257595582012645, \"p4\": 0.12590180067481982, \"phi\": 0.18641291659436368}, {\"truth_threshold\": 37.99999915063381, \"match_probability\": 0.999999999996362, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10543.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293418.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03468537082059869, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9653146291794013, \"precision\": 1.0, \"recall\": 0.03468537082059869, \"specificity\": 1.0, \"npv\": 0.9997705935572909, \"accuracy\": 0.9997705954482629, \"f1\": 0.0670452522066492, \"f2\": 0.04298398466389484, \"f0_5\": 0.15229694943851063, \"p4\": 0.12566434039884516, \"phi\": 0.18621872562410233}, {\"truth_threshold\": 38.01999915018678, \"match_probability\": 0.9999999999964121, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10502.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293459.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.034550485095127335, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9654495149048726, \"precision\": 1.0, \"recall\": 0.034550485095127335, \"specificity\": 1.0, \"npv\": 0.9997705615091339, \"accuracy\": 0.9997705633930154, \"f1\": 0.06679323163615433, \"f2\": 0.04281825846865404, \"f0_5\": 0.15177660426223158, \"p4\": 0.12522155145374878, \"phi\": 0.18585628287461367}, {\"truth_threshold\": 38.03999914973974, \"match_probability\": 0.9999999999964615, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10469.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293492.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03444191853560161, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9655580814643984, \"precision\": 1.0, \"recall\": 0.03444191853560161, \"specificity\": 1.0, \"npv\": 0.9997705357142773, \"accuracy\": 0.9997705375924503, \"f1\": 0.06659033807206692, \"f2\": 0.04268486104281696, \"f0_5\": 0.15135743139108887, \"p4\": 0.12486492442016078, \"phi\": 0.1855640464782063}, {\"truth_threshold\": 38.05999914929271, \"match_probability\": 0.9999999999965102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10421.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293540.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03428400353992782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9657159964600722, \"precision\": 1.0, \"recall\": 0.03428400353992782, \"specificity\": 1.0, \"npv\": 0.9997704981944884, \"accuracy\": 0.9997705000643556, \"f1\": 0.06629514412402746, \"f2\": 0.04249081560674079, \"f0_5\": 0.15074715387174703, \"p4\": 0.12434581814401632, \"phi\": 0.18513815192773}, {\"truth_threshold\": 38.07999914884567, \"match_probability\": 0.9999999999965583, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10384.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293577.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.034162277397429275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9658377226025707, \"precision\": 1.0, \"recall\": 0.034162277397429275, \"specificity\": 1.0, \"npv\": 0.9997704692729862, \"accuracy\": 0.9997704711364492, \"f1\": 0.06606753726001686, \"f2\": 0.04234122854803511, \"f0_5\": 0.15027626867961227, \"p4\": 0.12394536921859219, \"phi\": 0.18480918836752083}, {\"truth_threshold\": 38.09999914839864, \"match_probability\": 0.9999999999966056, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10328.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03397804323580986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9660219567641901, \"precision\": 1.0, \"recall\": 0.03397804323580986, \"specificity\": 1.0, \"npv\": 0.9997704254999051, \"accuracy\": 0.9997704273536722, \"f1\": 0.06572294926007592, \"f2\": 0.04211480934159319, \"f0_5\": 0.14956280971868638, \"p4\": 0.12333877947423343, \"phi\": 0.18431018079183742}, {\"truth_threshold\": 38.1199991479516, \"match_probability\": 0.9999999999966523, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10306.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293655.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.033905665529459374, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9660943344705406, \"precision\": 1.0, \"recall\": 0.033905665529459374, \"specificity\": 1.0, \"npv\": 0.9997704083033386, \"accuracy\": 0.9997704101532955, \"f1\": 0.06558754180362558, \"f2\": 0.04202585328059373, \"f0_5\": 0.14928226892825586, \"p4\": 0.12310030983310534, \"phi\": 0.1841137720817865}, {\"truth_threshold\": 38.13999914750457, \"match_probability\": 0.9999999999966984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10272.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293689.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03379380907419044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9662061909258096, \"precision\": 1.0, \"recall\": 0.03379380907419044, \"specificity\": 1.0, \"npv\": 0.9997703817268279, \"accuracy\": 0.9997703835708951, \"f1\": 0.06537823844090214, \"f2\": 0.04188836945280871, \"f0_5\": 0.14884842442667562, \"p4\": 0.12273158088528714, \"phi\": 0.18380981855740708}, {\"truth_threshold\": 38.15999914705753, \"match_probability\": 0.9999999999967439, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10253.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293708.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.033731301055069565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9662686989449304, \"precision\": 1.0, \"recall\": 0.033731301055069565, \"specificity\": 1.0, \"npv\": 0.999770366875249, \"accuracy\": 0.9997703687160242, \"f1\": 0.06526125506820192, \"f2\": 0.04181153693386412, \"f0_5\": 0.14860583292025753, \"p4\": 0.12252542858624703, \"phi\": 0.18363974305962852}, {\"truth_threshold\": 38.1799991466105, \"match_probability\": 0.9999999999967888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10207.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293754.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03357996585088219, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9664200341491178, \"precision\": 1.0, \"recall\": 0.03357996585088219, \"specificity\": 1.0, \"npv\": 0.9997703309187966, \"accuracy\": 0.9997703327516002, \"f1\": 0.06497797356828194, \"f2\": 0.04162551149992945, \"f0_5\": 0.14801806322127445, \"p4\": 0.12202603211445627, \"phi\": 0.1832273275769157}, {\"truth_threshold\": 38.199999146163464, \"match_probability\": 0.999999999996833, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10163.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293798.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03343521043818121, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9665647895618188, \"precision\": 1.0, \"recall\": 0.03343521043818121, \"specificity\": 1.0, \"npv\": 0.9997702965256706, \"accuracy\": 0.9997702983508467, \"f1\": 0.06470693102087074, \"f2\": 0.04144756106612768, \"f0_5\": 0.14745526140917492, \"p4\": 0.12154796287622813, \"phi\": 0.18283197273501875}, {\"truth_threshold\": 38.21999914571643, \"match_probability\": 0.9999999999968766, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10129.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293832.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03332335398291228, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9666766460170877, \"precision\": 1.0, \"recall\": 0.03332335398291228, \"specificity\": 1.0, \"npv\": 0.9997702699491658, \"accuracy\": 0.9997702717684464, \"f1\": 0.06449743704033875, \"f2\": 0.04131004516412678, \"f0_5\": 0.14701997520879478, \"p4\": 0.12117828717721214, \"phi\": 0.18252588475914266}, {\"truth_threshold\": 38.239999145269394, \"match_probability\": 0.9999999999969196, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10080.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03316214909149529, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9668378509085047, \"precision\": 1.0, \"recall\": 0.03316214909149529, \"specificity\": 1.0, \"npv\": 0.9997702316477349, \"accuracy\": 0.9997702334585163, \"f1\": 0.06419543944898914, \"f2\": 0.041111847063928925, \"f0_5\": 0.14639204603216557, \"p4\": 0.12064512228820046, \"phi\": 0.18208385287866954}, {\"truth_threshold\": 38.25999914482236, \"match_probability\": 0.999999999996962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10043.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03304042294899675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9669595770510032, \"precision\": 1.0, \"recall\": 0.03304042294899675, \"specificity\": 1.0, \"npv\": 0.9997702027262483, \"accuracy\": 0.99977020453061, \"f1\": 0.06396733799569432, \"f2\": 0.040962176774857716, \"f0_5\": 0.145917421462051, \"p4\": 0.12024221747053566, \"phi\": 0.18174936134655179}, {\"truth_threshold\": 38.279999144375324, \"match_probability\": 0.9999999999970038, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 10009.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 293952.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.032928566493727815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9670714335062722, \"precision\": 1.0, \"recall\": 0.032928566493727815, \"specificity\": 1.0, \"npv\": 0.9997701761497485, \"accuracy\": 0.9997701779482097, \"f1\": 0.0637576838551454, \"f2\": 0.040824633948768736, \"f0_5\": 0.14548091989174325, \"p4\": 0.11987174447827585, \"phi\": 0.18144144709462873}, {\"truth_threshold\": 38.29999914392829, \"match_probability\": 0.999999999997045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9955.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0327509121235948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9672490878764052, \"precision\": 1.0, \"recall\": 0.0327509121235948, \"specificity\": 1.0, \"npv\": 0.9997701339400163, \"accuracy\": 0.9997701357291031, \"f1\": 0.06342461040533136, \"f2\": 0.040606167895389046, \"f0_5\": 0.14478694285024477, \"p4\": 0.11928288084284165, \"phi\": 0.18095132992178886}, {\"truth_threshold\": 38.319999143481255, \"match_probability\": 0.9999999999970858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9928.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294033.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0326620849385283, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9673379150614717, \"precision\": 1.0, \"recall\": 0.0326620849385283, \"specificity\": 1.0, \"npv\": 0.9997701128351517, \"accuracy\": 0.9997701146195499, \"f1\": 0.06325803070512187, \"f2\": 0.04049692765049291, \"f0_5\": 0.14443962720376638, \"p4\": 0.11898823463528968, \"phi\": 0.18070577285859948}, {\"truth_threshold\": 38.33999914303422, \"match_probability\": 0.9999999999971259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9876.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294085.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.032491010359881695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9675089896401183, \"precision\": 1.0, \"recall\": 0.032491010359881695, \"specificity\": 1.0, \"npv\": 0.9997700721887481, \"accuracy\": 0.999770073964114, \"f1\": 0.06293712978393243, \"f2\": 0.040286525470743725, \"f0_5\": 0.14377010758010278, \"p4\": 0.11842036467957041, \"phi\": 0.18023190553557458}, {\"truth_threshold\": 38.359999142587185, \"match_probability\": 0.9999999999971654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9859.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294102.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03243508213224723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9675649178677528, \"precision\": 1.0, \"recall\": 0.03243508213224723, \"specificity\": 1.0, \"npv\": 0.9997700589005015, \"accuracy\": 0.9997700606729137, \"f1\": 0.06283219680071378, \"f2\": 0.040217736270532094, \"f0_5\": 0.14355105024213957, \"p4\": 0.11823459966115071, \"phi\": 0.18007671691198562}, {\"truth_threshold\": 38.37999914214015, \"match_probability\": 0.9999999999972045, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9839.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294122.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03236928421738315, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9676307157826168, \"precision\": 1.0, \"recall\": 0.03236928421738315, \"specificity\": 1.0, \"npv\": 0.9997700432672707, \"accuracy\": 0.9997700450362077, \"f1\": 0.0627087316762269, \"f2\": 0.040136805356686844, \"f0_5\": 0.14329322462913285, \"p4\": 0.11801597983135911, \"phi\": 0.17989397066756777}, {\"truth_threshold\": 38.399999141693115, \"match_probability\": 0.9999999999972429, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9789.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294172.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03220478943022296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.967795210569777, \"precision\": 1.0, \"recall\": 0.03220478943022296, \"specificity\": 1.0, \"npv\": 0.9997700041841957, \"accuracy\": 0.9997700059444424, \"f1\": 0.0624, \"f2\": 0.039934466516485766, \"f0_5\": 0.14264813460131676, \"p4\": 0.11746908590291497, \"phi\": 0.17943629082046125}, {\"truth_threshold\": 38.41999914124608, \"match_probability\": 0.9999999999972808, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9738.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294223.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.032037004747319554, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9679629952526805, \"precision\": 1.0, \"recall\": 0.032037004747319554, \"specificity\": 1.0, \"npv\": 0.9997699643194623, \"accuracy\": 0.9997699660708418, \"f1\": 0.06208499230153746, \"f2\": 0.039728063891277775, \"f0_5\": 0.14198936756553412, \"p4\": 0.11691074675304157, \"phi\": 0.178968251634557}, {\"truth_threshold\": 38.439999140799046, \"match_probability\": 0.9999999999973184, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9706.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294255.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03193172808353703, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9680682719164629, \"precision\": 1.0, \"recall\": 0.03193172808353703, \"specificity\": 1.0, \"npv\": 0.999769939306298, \"accuracy\": 0.999769941052112, \"f1\": 0.06188728811127724, \"f2\": 0.03959854759087757, \"f0_5\": 0.14157562320404918, \"p4\": 0.11656015439245608, \"phi\": 0.17867395402806482}, {\"truth_threshold\": 38.45999914035201, \"match_probability\": 0.9999999999973552, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9657.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294304.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.031770523192120044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.96822947680788, \"precision\": 1.0, \"recall\": 0.031770523192120044, \"specificity\": 1.0, \"npv\": 0.9997699010048924, \"accuracy\": 0.999769902742182, \"f1\": 0.06158447538087737, \"f2\": 0.0394002126477253, \"f0_5\": 0.14094147798090423, \"p4\": 0.11602291798350298, \"phi\": 0.17822236904120506}, {\"truth_threshold\": 38.479999139904976, \"match_probability\": 0.9999999999973916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9620.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0316487970496215, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9683512029503785, \"precision\": 1.0, \"recall\": 0.0316487970496215, \"specificity\": 1.0, \"npv\": 0.9997698720834248, \"accuracy\": 0.9997698738142757, \"f1\": 0.06135575816136819, \"f2\": 0.03925043901738443, \"f0_5\": 0.14046215260439024, \"p4\": 0.11561693518371642, \"phi\": 0.17788061664468774}, {\"truth_threshold\": 38.49999913945794, \"match_probability\": 0.9999999999974276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9595.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294366.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0315665496560414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9684334503439586, \"precision\": 1.0, \"recall\": 0.0315665496560414, \"specificity\": 1.0, \"npv\": 0.9997698525418937, \"accuracy\": 0.999769854268393, \"f1\": 0.06120118894232609, \"f2\": 0.039149235498462186, \"f0_5\": 0.14013804948866773, \"p4\": 0.11534246913454974, \"phi\": 0.17764933069076527}, {\"truth_threshold\": 38.519999139010906, \"match_probability\": 0.999999999997463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9576.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294385.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03150404163692053, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9684959583630794, \"precision\": 1.0, \"recall\": 0.03150404163692053, \"specificity\": 1.0, \"npv\": 0.9997698376903305, \"accuracy\": 0.9997698394135223, \"f1\": 0.06108369985041638, \"f2\": 0.03907231806237861, \"f0_5\": 0.1398916044585336, \"p4\": 0.11513379216853101, \"phi\": 0.17747335178536933}, {\"truth_threshold\": 38.53999913856387, \"match_probability\": 0.9999999999974979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9511.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294450.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.031290198413612275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9687098015863878, \"precision\": 1.0, \"recall\": 0.031290198413612275, \"specificity\": 1.0, \"npv\": 0.9997697868823544, \"accuracy\": 0.9997697885942274, \"f1\": 0.06068165577786852, \"f2\": 0.03880916142668859, \"f0_5\": 0.13904767474159735, \"p4\": 0.11441935618271021, \"phi\": 0.17686999462736389}, {\"truth_threshold\": 38.55999913811684, \"match_probability\": 0.9999999999975323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9487.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294474.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03121124091577538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9687887590842246, \"precision\": 1.0, \"recall\": 0.03121124091577538, \"specificity\": 1.0, \"npv\": 0.9997697681224877, \"accuracy\": 0.9997697698301801, \"f1\": 0.06053316658584518, \"f2\": 0.03871198884219856, \"f0_5\": 0.13873574547613546, \"p4\": 0.11415535254387099, \"phi\": 0.17664669567580327}, {\"truth_threshold\": 38.5799991376698, \"match_probability\": 0.9999999999975663, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9458.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294503.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.031115833939222466, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9688841660607775, \"precision\": 1.0, \"recall\": 0.031115833939222466, \"specificity\": 1.0, \"npv\": 0.9997697454543163, \"accuracy\": 0.9997697471569562, \"f1\": 0.06035371180432584, \"f2\": 0.03859456689044823, \"f0_5\": 0.13835859716261012, \"p4\": 0.11383619551481443, \"phi\": 0.17637649893626764}, {\"truth_threshold\": 38.59999913722277, \"match_probability\": 0.9999999999975998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9427.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294534.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.031013847171183145, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9689861528288168, \"precision\": 1.0, \"recall\": 0.031013847171183145, \"specificity\": 1.0, \"npv\": 0.9997697212228239, \"accuracy\": 0.9997697229200617, \"f1\": 0.06016184410379466, \"f2\": 0.0384690407265005, \"f0_5\": 0.13795515542820683, \"p4\": 0.11349484280834404, \"phi\": 0.17608720947411552}, {\"truth_threshold\": 38.61999913677573, \"match_probability\": 0.9999999999976329, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9405.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294556.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.03094146946483266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9690585305351673, \"precision\": 1.0, \"recall\": 0.03094146946483266, \"specificity\": 1.0, \"npv\": 0.9997697040262816, \"accuracy\": 0.9997697057196849, \"f1\": 0.06002565689959983, \"f2\": 0.038379953788984934, \"f0_5\": 0.13766866424069255, \"p4\": 0.11325247653698059, \"phi\": 0.17588161862171378}, {\"truth_threshold\": 38.6399991363287, \"match_probability\": 0.9999999999976654, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9343.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294618.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030737495928754018, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969262504071246, \"precision\": 1.0, \"recall\": 0.030737495928754018, \"specificity\": 1.0, \"npv\": 0.999769655563302, \"accuracy\": 0.9997696572458961, \"f1\": 0.0596417536960907, \"f2\": 0.038128873388307255, \"f0_5\": 0.1368604852153176, \"p4\": 0.11256892582213278, \"phi\": 0.17530092902654223}, {\"truth_threshold\": 38.65999913588166, \"match_probability\": 0.9999999999976976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9299.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030592740516053048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9694072594839469, \"precision\": 1.0, \"recall\": 0.030592740516053048, \"specificity\": 1.0, \"npv\": 0.9997696211702225, \"accuracy\": 0.9997696228451426, \"f1\": 0.05936921407137841, \"f2\": 0.03795067188075188, \"f0_5\": 0.13628622598979356, \"p4\": 0.11208336044121468, \"phi\": 0.17488765707245688}, {\"truth_threshold\": 38.67999913543463, \"match_probability\": 0.9999999999977293, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9242.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030405216458690425, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9695947835413096, \"precision\": 1.0, \"recall\": 0.030405216458690425, \"specificity\": 1.0, \"npv\": 0.9997695766155549, \"accuracy\": 0.9997695782805301, \"f1\": 0.05901603752199053, \"f2\": 0.03771980089561059, \"f0_5\": 0.13554141771453881, \"p4\": 0.11145375789944167, \"phi\": 0.17435082559543336}, {\"truth_threshold\": 38.69999913498759, \"match_probability\": 0.9999999999977606, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9209.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294752.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030296649899164696, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9697033501008353, \"precision\": 1.0, \"recall\": 0.030296649899164696, \"specificity\": 1.0, \"npv\": 0.9997695508207491, \"accuracy\": 0.999769552479965, \"f1\": 0.05881150812657662, \"f2\": 0.037586128926666844, \"f0_5\": 0.13510975742157355, \"p4\": 0.11108895434080296, \"phi\": 0.17403927160575391}, {\"truth_threshold\": 38.71999913454056, \"match_probability\": 0.9999999999977914, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9171.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030171633860922947, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9698283661390771, \"precision\": 1.0, \"recall\": 0.030171633860922947, \"specificity\": 1.0, \"npv\": 0.9997695211176411, \"accuracy\": 0.9997695227702235, \"f1\": 0.05857593602697904, \"f2\": 0.0374321947078199, \"f0_5\": 0.13461227964596575, \"p4\": 0.1106686075632527, \"phi\": 0.17367982017629954}, {\"truth_threshold\": 38.73999913409352, \"match_probability\": 0.9999999999978217, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9132.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294829.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.030043327926937997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.969956672073062, \"precision\": 1.0, \"recall\": 0.030043327926937997, \"specificity\": 1.0, \"npv\": 0.9997694906328741, \"accuracy\": 0.9997694922786465, \"f1\": 0.058334105201968744, \"f2\": 0.03727419965778921, \"f0_5\": 0.13410124849848307, \"p4\": 0.11023689825944509, \"phi\": 0.1733101343211966}, {\"truth_threshold\": 38.75999913364649, \"match_probability\": 0.9999999999978518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9088.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029898572514237023, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.970101427485763, \"precision\": 1.0, \"recall\": 0.029898572514237023, \"specificity\": 1.0, \"npv\": 0.9997694562398061, \"accuracy\": 0.9997694578778931, \"f1\": 0.05806119808720041, \"f2\": 0.03709593675404022, \"f0_5\": 0.1335241380728917, \"p4\": 0.10974947543779502, \"phi\": 0.17289210388246526}, {\"truth_threshold\": 38.77999913319945, \"match_probability\": 0.9999999999978814, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 9046.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294915.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02976039689302246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9702396031069775, \"precision\": 1.0, \"recall\": 0.02976039689302246, \"specificity\": 1.0, \"npv\": 0.9997694234100614, \"accuracy\": 0.9997694250408102, \"f1\": 0.05780062426718891, \"f2\": 0.036925764762550106, \"f0_5\": 0.1329727028179159, \"p4\": 0.10928384562816437, \"phi\": 0.17249212979783063}, {\"truth_threshold\": 38.79999913275242, \"match_probability\": 0.9999999999979106, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8989.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294972.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029572872835659837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9704271271643402, \"precision\": 1.0, \"recall\": 0.029572872835659837, \"specificity\": 1.0, \"npv\": 0.9997693788554114, \"accuracy\": 0.9997693804761978, \"f1\": 0.05744687649784311, \"f2\": 0.03669479839292377, \"f0_5\": 0.1322234545491988, \"p4\": 0.10865135228200747, \"phi\": 0.17194781971830206}, {\"truth_threshold\": 38.819999132305384, \"match_probability\": 0.9999999999979393, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8963.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 294998.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029487335546336535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9705126644536635, \"precision\": 1.0, \"recall\": 0.029487335546336535, \"specificity\": 1.0, \"npv\": 0.999769358532239, \"accuracy\": 0.9997693601484798, \"f1\": 0.05728547506742851, \"f2\": 0.03658943817270802, \"f0_5\": 0.13188135827646383, \"p4\": 0.1083626293994758, \"phi\": 0.17169896488909236}, {\"truth_threshold\": 38.83999913185835, \"match_probability\": 0.9999999999979676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8934.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029391928569783624, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9706080714302163, \"precision\": 1.0, \"recall\": 0.029391928569783624, \"specificity\": 1.0, \"npv\": 0.9997693358640862, \"accuracy\": 0.999769337475256, \"f1\": 0.05710541875069912, \"f2\": 0.036471915726768445, \"f0_5\": 0.1314995422391131, \"p4\": 0.10804043168052696, \"phi\": 0.17142096985484956}, {\"truth_threshold\": 38.859999131411314, \"match_probability\": 0.9999999999979956, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8895.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295066.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02926362263579867, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9707363773642014, \"precision\": 1.0, \"recall\": 0.02926362263579867, \"specificity\": 1.0, \"npv\": 0.9997693053793306, \"accuracy\": 0.999769306983679, \"f1\": 0.05686322141816043, \"f2\": 0.0363138595243558, \"f0_5\": 0.1309856541625312, \"p4\": 0.1076068639471827, \"phi\": 0.17104640211204472}, {\"truth_threshold\": 38.87999913096428, \"match_probability\": 0.9999999999980232, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8879.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02921098430390741, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9707890156960925, \"precision\": 1.0, \"recall\": 0.02921098430390741, \"specificity\": 1.0, \"npv\": 0.9997692928727647, \"accuracy\": 0.9997692944743142, \"f1\": 0.05676384094105613, \"f2\": 0.036249013042132794, \"f0_5\": 0.13077469165805047, \"p4\": 0.1074289012233523, \"phi\": 0.17089249580258034}, {\"truth_threshold\": 38.899999130517244, \"match_probability\": 0.9999999999980504, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8860.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295101.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.029148476284786534, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9708515237152134, \"precision\": 1.0, \"recall\": 0.029148476284786534, \"specificity\": 1.0, \"npv\": 0.9997692780212182, \"accuracy\": 0.9997692796194434, \"f1\": 0.05664581342045451, \"f2\": 0.03617200564381271, \"f0_5\": 0.1305240703474651, \"p4\": 0.10721750335283725, \"phi\": 0.17070955184364944}, {\"truth_threshold\": 38.91999913007021, \"match_probability\": 0.9999999999980773, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8811.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028987271393369544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9710127286066305, \"precision\": 1.0, \"recall\": 0.028987271393369544, \"specificity\": 1.0, \"npv\": 0.9997692397198633, \"accuracy\": 0.9997692413095134, \"f1\": 0.05634136047983835, \"f2\": 0.0359733965892435, \"f0_5\": 0.1298772128948571, \"p4\": 0.10667198272786048, \"phi\": 0.1702368417308733}, {\"truth_threshold\": 38.939999129623175, \"match_probability\": 0.9999999999981037, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8737.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295224.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028743819108372457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9712561808916276, \"precision\": 1.0, \"recall\": 0.028743819108372457, \"specificity\": 1.0, \"npv\": 0.9997691818770064, \"accuracy\": 0.9997691834537007, \"f1\": 0.05588139354904732, \"f2\": 0.03567342625763424, \"f0_5\": 0.12889890796644526, \"p4\": 0.10584721446122991, \"phi\": 0.16952045455931916}, {\"truth_threshold\": 38.95999912917614, \"match_probability\": 0.9999999999981298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8695.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295266.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02860564348715789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9713943565128421, \"precision\": 1.0, \"recall\": 0.02860564348715789, \"specificity\": 1.0, \"npv\": 0.9997691490472798, \"accuracy\": 0.9997691506166179, \"f1\": 0.055620234378998004, \"f2\": 0.03550315669815335, \"f0_5\": 0.12834289324292011, \"p4\": 0.10537860913341625, \"phi\": 0.16911250647750956}, {\"truth_threshold\": 38.979999128729105, \"match_probability\": 0.9999999999981556, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8665.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295296.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028506946614861774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9714930533851382, \"precision\": 1.0, \"recall\": 0.028506946614861774, \"specificity\": 1.0, \"npv\": 0.9997691255974763, \"accuracy\": 0.9997691271615587, \"f1\": 0.05543364915266165, \"f2\": 0.03538152843302907, \"f0_5\": 0.1279454020866987, \"p4\": 0.10504367191020056, \"phi\": 0.16882051146289745}, {\"truth_threshold\": 38.99999912828207, \"match_probability\": 0.999999999998181, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8600.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295361.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.028293103391553522, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9717068966084464, \"precision\": 1.0, \"recall\": 0.028293103391553522, \"specificity\": 1.0, \"npv\": 0.9997690747895727, \"accuracy\": 0.9997690763422639, \"f1\": 0.05502925828878203, \"f2\": 0.035117980079121626, \"f0_5\": 0.1270832040335618, \"p4\": 0.10431734735885044, \"phi\": 0.16818611655157267}, {\"truth_threshold\": 39.019999127835035, \"match_probability\": 0.9999999999982061, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8559.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295402.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02815821766608216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9718417823339178, \"precision\": 1.0, \"recall\": 0.02815821766608216, \"specificity\": 1.0, \"npv\": 0.9997690427415131, \"accuracy\": 0.9997690442870163, \"f1\": 0.05477409445795469, \"f2\": 0.0349517274949506, \"f0_5\": 0.1265386742046795, \"p4\": 0.10385876218274602, \"phi\": 0.1677847261264449}, {\"truth_threshold\": 39.039999127388, \"match_probability\": 0.9999999999982307, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8515.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02801346225338119, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9719865377466188, \"precision\": 1.0, \"recall\": 0.02801346225338119, \"specificity\": 1.0, \"npv\": 0.9997690083484758, \"accuracy\": 0.9997690098862628, \"f1\": 0.054500185614255174, \"f2\": 0.03477329770108277, \"f0_5\": 0.12595371293499516, \"p4\": 0.10336624110819141, \"phi\": 0.16735289473884332}, {\"truth_threshold\": 39.059999126940966, \"match_probability\": 0.9999999999982551, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8496.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027950954234260316, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9720490457657397, \"precision\": 1.0, \"recall\": 0.027950954234260316, \"specificity\": 1.0, \"npv\": 0.9997689934969377, \"accuracy\": 0.999768995031392, \"f1\": 0.05438188294709352, \"f2\": 0.03469624450724472, \"f0_5\": 0.12570092766574442, \"p4\": 0.1031534395340628, \"phi\": 0.16716607724674706}, {\"truth_threshold\": 39.07999912649393, \"match_probability\": 0.9999999999982792, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8455.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295506.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027816068508788955, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9721839314912111, \"precision\": 1.0, \"recall\": 0.027816068508788955, \"specificity\": 1.0, \"npv\": 0.9997689614488833, \"accuracy\": 0.9997689629761445, \"f1\": 0.05412654921642938, \"f2\": 0.03452996367717363, \"f0_5\": 0.12515505608663602, \"p4\": 0.10269398513337165, \"phi\": 0.16676223170917007}, {\"truth_threshold\": 39.099999126046896, \"match_probability\": 0.9999999999983028, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8415.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295546.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027684472679060802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9723155273209392, \"precision\": 1.0, \"recall\": 0.027684472679060802, \"specificity\": 1.0, \"npv\": 0.9997689301824907, \"accuracy\": 0.9997689317027323, \"f1\": 0.053877378543806184, \"f2\": 0.03436772774388426, \"f0_5\": 0.12462198737637765, \"p4\": 0.10224540604579874, \"phi\": 0.1663672913556358}, {\"truth_threshold\": 39.11999912559986, \"match_probability\": 0.9999999999983262, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8379.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295582.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02756603643230546, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9724339635676945, \"precision\": 1.0, \"recall\": 0.02756603643230546, \"specificity\": 1.0, \"npv\": 0.999768902042739, \"accuracy\": 0.9997689035566613, \"f1\": 0.05365307037203048, \"f2\": 0.03422170633944959, \"f0_5\": 0.12414179336665906, \"p4\": 0.10184140514921593, \"phi\": 0.16601104173396472}, {\"truth_threshold\": 39.139999125152826, \"match_probability\": 0.9999999999983492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8353.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02748049914298216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9725195008570179, \"precision\": 1.0, \"recall\": 0.02748049914298216, \"specificity\": 1.0, \"npv\": 0.9997688817195861, \"accuracy\": 0.9997688832289433, \"f1\": 0.05349103786573769, \"f2\": 0.03411624109518321, \"f0_5\": 0.12379473164716798, \"p4\": 0.10154946176614336, \"phi\": 0.16575327416758714}, {\"truth_threshold\": 39.15999912470579, \"match_probability\": 0.999999999998372, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8330.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02740483154088847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9725951684591115, \"precision\": 1.0, \"recall\": 0.02740483154088847, \"specificity\": 1.0, \"npv\": 0.9997688637414129, \"accuracy\": 0.9997688652467314, \"f1\": 0.05334767892766682, \"f2\": 0.03402294118319781, \"f0_5\": 0.12348753709814665, \"p4\": 0.10129108874146096, \"phi\": 0.16552491441066777}, {\"truth_threshold\": 39.17999912425876, \"match_probability\": 0.9999999999983944, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8282.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295679.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027246916545214682, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9727530834547853, \"precision\": 1.0, \"recall\": 0.027246916545214682, \"specificity\": 1.0, \"npv\": 0.9997688262217495, \"accuracy\": 0.9997688277186366, \"f1\": 0.0530484270263865, \"f2\": 0.03382821702994626, \"f0_5\": 0.12284589529768103, \"p4\": 0.10075152614882274, \"phi\": 0.1650473197982059}, {\"truth_threshold\": 39.19999912381172, \"match_probability\": 0.9999999999984165, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8271.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02721072769203944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9727892723079605, \"precision\": 1.0, \"recall\": 0.02721072769203944, \"specificity\": 1.0, \"npv\": 0.9997688176234936, \"accuracy\": 0.9997688191184483, \"f1\": 0.05297983550693074, \"f2\": 0.03378359059402099, \"f0_5\": 0.12269874942515094, \"p4\": 0.10062780981501857, \"phi\": 0.16493767626393047}, {\"truth_threshold\": 39.21999912336469, \"match_probability\": 0.9999999999984382, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8231.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295730.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027079131862311284, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9729208681376887, \"precision\": 1.0, \"recall\": 0.027079131862311284, \"specificity\": 1.0, \"npv\": 0.9997687863571101, \"accuracy\": 0.9997687878450361, \"f1\": 0.052730371053710534, \"f2\": 0.033621305884034884, \"f0_5\": 0.12216334951096071, \"p4\": 0.10017772278971719, \"phi\": 0.16453835661506744}, {\"truth_threshold\": 39.23999912291765, \"match_probability\": 0.9999999999984598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8213.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295748.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.027019913738933612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9729800862610664, \"precision\": 1.0, \"recall\": 0.027019913738933612, \"specificity\": 1.0, \"npv\": 0.999768772287238, \"accuracy\": 0.9997687737720006, \"f1\": 0.05261809119273226, \"f2\": 0.03354827430421949, \"f0_5\": 0.12192225359472467, \"p4\": 0.09997507637279446, \"phi\": 0.164358346262308}, {\"truth_threshold\": 39.25999912247062, \"match_probability\": 0.999999999998481, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8202.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295759.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02698372488575837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9730162751142416, \"precision\": 1.0, \"recall\": 0.02698372488575837, \"specificity\": 1.0, \"npv\": 0.9997687636889832, \"accuracy\": 0.9997687651718122, \"f1\": 0.052549469347744605, \"f2\": 0.03350364283695221, \"f0_5\": 0.12177486645148455, \"p4\": 0.09985120410261189, \"phi\": 0.16424824281787095}, {\"truth_threshold\": 39.27999912202358, \"match_probability\": 0.9999999999985019, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8170.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295791.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026878448221975847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9731215517780242, \"precision\": 1.0, \"recall\": 0.026878448221975847, \"specificity\": 1.0, \"npv\": 0.9997687386758789, \"accuracy\": 0.9997687401530824, \"f1\": 0.052349814661151885, \"f2\": 0.03337380128005072, \"f0_5\": 0.1213458847852757, \"p4\": 0.09949070687603175, \"phi\": 0.1639275214125124}, {\"truth_threshold\": 39.29999912157655, \"match_probability\": 0.9999999999985225, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8135.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295826.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02676330187096371, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9732366981290362, \"precision\": 1.0, \"recall\": 0.02676330187096371, \"specificity\": 1.0, \"npv\": 0.9997687113177974, \"accuracy\": 0.9997687127888467, \"f1\": 0.05213139546806111, \"f2\": 0.03323177930340308, \"f0_5\": 0.12087631240323209, \"p4\": 0.09909617166243116, \"phi\": 0.16357601236777533}, {\"truth_threshold\": 39.31999912112951, \"match_probability\": 0.9999999999985428, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8096.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295865.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026634995936978757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9733650040630213, \"precision\": 1.0, \"recall\": 0.026634995936978757, \"specificity\": 1.0, \"npv\": 0.9997686808330799, \"accuracy\": 0.9997686822972698, \"f1\": 0.051887956366945785, \"f2\": 0.03307351667565404, \"f0_5\": 0.12035261413132349, \"p4\": 0.09865624936489242, \"phi\": 0.1631834389633571}, {\"truth_threshold\": 39.33999912068248, \"match_probability\": 0.9999999999985629, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8078.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026575777813601088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9734242221863989, \"precision\": 1.0, \"recall\": 0.026575777813601088, \"specificity\": 1.0, \"npv\": 0.9997686667632109, \"accuracy\": 0.9997686682242343, \"f1\": 0.051775579334634454, \"f2\": 0.03300046898413461, \"f0_5\": 0.12011074335435792, \"p4\": 0.09845310250656883, \"phi\": 0.16300193235940266}, {\"truth_threshold\": 39.35999912023544, \"match_probability\": 0.9999999999985827, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 8026.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026404703234954485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9735952967650455, \"precision\": 1.0, \"recall\": 0.026404703234954485, \"specificity\": 1.0, \"npv\": 0.9997686261169249, \"accuracy\": 0.9997686275687984, \"f1\": 0.05145086173462356, \"f2\": 0.032789430249944844, \"f0_5\": 0.119411423385357, \"p4\": 0.09786585808510087, \"phi\": 0.16247644098833394}, {\"truth_threshold\": 39.37999911978841, \"match_probability\": 0.9999999999986022, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7985.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 295976.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026269817509483123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9737301824905169, \"precision\": 1.0, \"recall\": 0.026269817509483123, \"specificity\": 1.0, \"npv\": 0.9997685940688941, \"accuracy\": 0.9997685955135508, \"f1\": 0.05119475806710136, \"f2\": 0.03262302168031645, \"f0_5\": 0.11885942584273343, \"p4\": 0.09740244446873014, \"phi\": 0.16206090990088376}, {\"truth_threshold\": 39.39999911934137, \"match_probability\": 0.9999999999986214, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7960.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296001.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026187570115903027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.973812429884097, \"precision\": 1.0, \"recall\": 0.026187570115903027, \"specificity\": 1.0, \"npv\": 0.9997685745274129, \"accuracy\": 0.9997685759676682, \"f1\": 0.05103856425184582, \"f2\": 0.03252154756807463, \"f0_5\": 0.11852257735980536, \"p4\": 0.09711970452090246, \"phi\": 0.1618070135844335}, {\"truth_threshold\": 39.41999911889434, \"match_probability\": 0.9999999999986404, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7921.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296040.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.026059264181918076, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9739407358180819, \"precision\": 1.0, \"recall\": 0.026059264181918076, \"specificity\": 1.0, \"npv\": 0.9997685440427037, \"accuracy\": 0.9997685454760913, \"f1\": 0.050794851899115694, \"f2\": 0.03236323967428387, \"f0_5\": 0.11799669293449924, \"p4\": 0.09667837177762705, \"phi\": 0.16141013787857444}, {\"truth_threshold\": 39.439999118447304, \"match_probability\": 0.9999999999986592, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7887.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296074.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025947407726649142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9740525922733508, \"precision\": 1.0, \"recall\": 0.025947407726649142, \"specificity\": 1.0, \"npv\": 0.999768517466292, \"accuracy\": 0.9997685188936909, \"f1\": 0.050582334983710016, \"f2\": 0.03222521943139464, \"f0_5\": 0.1175378305798056, \"p4\": 0.0962933629494916, \"phi\": 0.1610633457834694}, {\"truth_threshold\": 39.45999911800027, \"match_probability\": 0.9999999999986776, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7857.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296104.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025848710854353026, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.974151289145647, \"precision\": 1.0, \"recall\": 0.025848710854353026, \"specificity\": 1.0, \"npv\": 0.9997684940165182, \"accuracy\": 0.9997684954386317, \"f1\": 0.05039478157130121, \"f2\": 0.03210343049486762, \"f0_5\": 0.1171326429906765, \"p4\": 0.09595345012327161, \"phi\": 0.16075673150174755}, {\"truth_threshold\": 39.479999117553234, \"match_probability\": 0.9999999999986958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7771.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02556577982043749, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9744342201795625, \"precision\": 1.0, \"recall\": 0.02556577982043749, \"specificity\": 1.0, \"npv\": 0.9997684267938395, \"accuracy\": 0.9997684282007954, \"f1\": 0.049856928387204395, \"f2\": 0.03175426911242507, \"f0_5\": 0.1159694966347804, \"p4\": 0.0949779971590915, \"phi\": 0.15987451163595928}, {\"truth_threshold\": 39.4999991171062, \"match_probability\": 0.9999999999987138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7734.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296227.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025444053677938946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9745559463220611, \"precision\": 1.0, \"recall\": 0.025444053677938946, \"specificity\": 1.0, \"npv\": 0.9997683978724572, \"accuracy\": 0.9997683992728891, \"f1\": 0.049625435120871364, \"f2\": 0.031604033416749895, \"f0_5\": 0.11546833802631853, \"p4\": 0.09455785216455585, \"phi\": 0.1594934505895895}, {\"truth_threshold\": 39.519999116659164, \"match_probability\": 0.9999999999987315, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7693.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296268.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.025309167952467588, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9746908320475324, \"precision\": 1.0, \"recall\": 0.025309167952467588, \"specificity\": 1.0, \"npv\": 0.999768365824441, \"accuracy\": 0.9997683672176416, \"f1\": 0.049368851354386595, \"f2\": 0.03143754541137701, \"f0_5\": 0.1149124824860411, \"p4\": 0.09409195295039043, \"phi\": 0.15907012756710429}, {\"truth_threshold\": 39.53999911621213, \"match_probability\": 0.999999999998749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7661.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296300.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02520389128868506, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.974796108711315, \"precision\": 1.0, \"recall\": 0.02520389128868506, \"specificity\": 1.0, \"npv\": 0.9997683408113566, \"accuracy\": 0.9997683421989118, \"f1\": 0.04916854394105679, \"f2\": 0.03130759580058929, \"f0_5\": 0.1144782654174325, \"p4\": 0.0937280807061281, \"phi\": 0.15873894473530578}, {\"truth_threshold\": 39.559999115765095, \"match_probability\": 0.9999999999987662, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7593.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024980178378147196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9750198216218529, \"precision\": 1.0, \"recall\": 0.024980178378147196, \"specificity\": 1.0, \"npv\": 0.9997682876585564, \"accuracy\": 0.999768289034111, \"f1\": 0.048742754065105885, \"f2\": 0.031031430306587098, \"f0_5\": 0.11355445020383868, \"p4\": 0.09295414219054905, \"phi\": 0.1580328768406293}, {\"truth_threshold\": 39.57999911531806, \"match_probability\": 0.9999999999987832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7560.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024871611818621468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9751283881813785, \"precision\": 1.0, \"recall\": 0.024871611818621468, \"specificity\": 1.0, \"npv\": 0.9997682618638171, \"accuracy\": 0.999768263233546, \"f1\": 0.048536053749185445, \"f2\": 0.0308973977525004, \"f0_5\": 0.11310558615922753, \"p4\": 0.09257820595367557, \"phi\": 0.15768908686924013}, {\"truth_threshold\": 39.599999114871025, \"match_probability\": 0.9999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7546.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024825553278216613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9751744467217834, \"precision\": 1.0, \"recall\": 0.024825553278216613, \"specificity\": 1.0, \"npv\": 0.9997682509205948, \"accuracy\": 0.9997682522878516, \"f1\": 0.04844834947529269, \"f2\": 0.030840533272300737, \"f0_5\": 0.1129150518487483, \"p4\": 0.09241864899397982, \"phi\": 0.15754300993410866}, {\"truth_threshold\": 39.61999911442399, \"match_probability\": 0.9999999999988164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7528.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296433.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024766335154838944, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.975233664845161, \"precision\": 1.0, \"recall\": 0.024766335154838944, \"specificity\": 1.0, \"npv\": 0.9997682368507379, \"accuracy\": 0.9997682382148161, \"f1\": 0.0483355752530587, \"f2\": 0.03076741988536602, \"f0_5\": 0.1126699853026135, \"p4\": 0.09221344401754888, \"phi\": 0.15735499747706705}, {\"truth_threshold\": 39.639999113976955, \"match_probability\": 0.9999999999988327, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7497.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296464.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024664348386799623, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9753356516132003, \"precision\": 1.0, \"recall\": 0.024664348386799623, \"specificity\": 1.0, \"npv\": 0.9997682126193186, \"accuracy\": 0.9997682139779216, \"f1\": 0.04814132242549557, \"f2\": 0.03064149734211475, \"f0_5\": 0.11224767853774079, \"p4\": 0.09185987629779317, \"phi\": 0.15703067057772768}, {\"truth_threshold\": 39.65999911352992, \"match_probability\": 0.9999999999988488, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7456.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296505.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02452946266132826, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9754705373386717, \"precision\": 1.0, \"recall\": 0.02452946266132826, \"specificity\": 1.0, \"npv\": 0.9997681805713142, \"accuracy\": 0.9997681819226741, \"f1\": 0.04788434799641638, \"f2\": 0.03047494482138478, \"f0_5\": 0.1116886618631754, \"p4\": 0.09139194493091732, \"phi\": 0.15660069046881037}, {\"truth_threshold\": 39.679999113082886, \"match_probability\": 0.9999999999988647, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7420.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296541.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024411026414572923, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9755889735854271, \"precision\": 1.0, \"recall\": 0.024411026414572923, \"specificity\": 1.0, \"npv\": 0.9997681524316048, \"accuracy\": 0.9997681537766031, \"f1\": 0.04765865611581953, \"f2\": 0.03032869437831899, \"f0_5\": 0.11119736483225982, \"p4\": 0.09098078740682057, \"phi\": 0.15622217120964832}, {\"truth_threshold\": 39.69999911263585, \"match_probability\": 0.9999999999988802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7398.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296563.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024338648708222436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9756613512917776, \"precision\": 1.0, \"recall\": 0.024338648708222436, \"specificity\": 1.0, \"npv\": 0.9997681352351165, \"accuracy\": 0.9997681365762264, \"f1\": 0.04752070760761693, \"f2\": 0.030239314869829517, \"f0_5\": 0.11089691893042485, \"p4\": 0.09072939042038033, \"phi\": 0.15599040173408787}, {\"truth_threshold\": 39.719999112188816, \"match_probability\": 0.9999999999988957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7362.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296599.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024220212461467095, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9757797875385329, \"precision\": 1.0, \"recall\": 0.024220212461467095, \"specificity\": 1.0, \"npv\": 0.9997681070954096, \"accuracy\": 0.9997681084301554, \"f1\": 0.04729493163049309, \"f2\": 0.030093050557305965, \"f0_5\": 0.11040493807905605, \"p4\": 0.09031779398092579, \"phi\": 0.15561039800106422}, {\"truth_threshold\": 39.73999911174178, \"match_probability\": 0.9999999999989109, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7321.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296640.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.024085326735995737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9759146732640043, \"precision\": 1.0, \"recall\": 0.024085326735995737, \"specificity\": 1.0, \"npv\": 0.999768075047412, \"accuracy\": 0.9997680763749078, \"f1\": 0.047037734273102844, \"f2\": 0.0299264612705563, \"f0_5\": 0.10984410868880254, \"p4\": 0.08984869910922609, \"phi\": 0.1551764825859074}, {\"truth_threshold\": 39.759999111294746, \"match_probability\": 0.9999999999989259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7295.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296666.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023999789446672436, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9760002105533275, \"precision\": 1.0, \"recall\": 0.023999789446672436, \"specificity\": 1.0, \"npv\": 0.9997680547242926, \"accuracy\": 0.9997680560471899, \"f1\": 0.046874598401315956, \"f2\": 0.029820813497075965, \"f0_5\": 0.10948817467678851, \"p4\": 0.08955104080097064, \"phi\": 0.15490068692195108}, {\"truth_threshold\": 39.77999911084771, \"match_probability\": 0.9999999999989406, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7255.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296706.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02386819361694428, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9761318063830557, \"precision\": 1.0, \"recall\": 0.02386819361694428, \"specificity\": 1.0, \"npv\": 0.9997680234579568, \"accuracy\": 0.9997680247737777, \"f1\": 0.0466235669117269, \"f2\": 0.02965826969035213, \"f0_5\": 0.10894014973827336, \"p4\": 0.08909282655633681, \"phi\": 0.1544754244400196}, {\"truth_threshold\": 39.79999911040068, \"match_probability\": 0.9999999999989553, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7215.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296746.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023736597787216124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9762634022127838, \"precision\": 1.0, \"recall\": 0.023736597787216124, \"specificity\": 1.0, \"npv\": 0.9997679921916229, \"accuracy\": 0.9997679935003654, \"f1\": 0.04637247088464406, \"f2\": 0.02949571525167633, \"f0_5\": 0.10839159788595071, \"p4\": 0.08863427454480735, \"phi\": 0.15404898802389186}, {\"truth_threshold\": 39.81999910995364, \"match_probability\": 0.9999999999989696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7173.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296788.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02359842216600156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9764015778339984, \"precision\": 1.0, \"recall\": 0.02359842216600156, \"specificity\": 1.0, \"npv\": 0.9997679593619744, \"accuracy\": 0.9997679606632826, \"f1\": 0.04610875057049374, \"f2\": 0.029325021647286995, \"f0_5\": 0.10781505051810746, \"p4\": 0.08815243100226212, \"phi\": 0.15359995564148368}, {\"truth_threshold\": 39.83999910950661, \"match_probability\": 0.9999999999989838, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02349972529370544, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9765002747062945, \"precision\": 1.0, \"recall\": 0.02349972529370544, \"specificity\": 1.0, \"npv\": 0.9997679359122268, \"accuracy\": 0.9997679372082234, \"f1\": 0.045920335321950216, \"f2\": 0.029203090466211005, \"f0_5\": 0.10740287430119717, \"p4\": 0.08780802855853038, \"phi\": 0.15327841286819302}, {\"truth_threshold\": 39.85999910905957, \"match_probability\": 0.9999999999989978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7096.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296865.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023345100193774858, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9766548998062251, \"precision\": 1.0, \"recall\": 0.023345100193774858, \"specificity\": 1.0, \"npv\": 0.9997678991742911, \"accuracy\": 0.9997679004619641, \"f1\": 0.04562507836184365, \"f2\": 0.02901205292164783, \"f0_5\": 0.10675653312070288, \"p4\": 0.08726808149201605, \"phi\": 0.15277330191084967}, {\"truth_threshold\": 39.87999910861254, \"match_probability\": 0.9999999999990116, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7060.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02322666394701952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9767733360529804, \"precision\": 1.0, \"recall\": 0.02322666394701952, \"specificity\": 1.0, \"npv\": 0.9997678710345975, \"accuracy\": 0.999767872315893, \"f1\": 0.04539886374231965, \"f2\": 0.028865716360401143, \"f0_5\": 0.10626096851002857, \"p4\": 0.08685418826804014, \"phi\": 0.15238527607858887}, {\"truth_threshold\": 39.8999991081655, \"match_probability\": 0.9999999999990252, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 7008.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296953.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023055589368372917, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9769444106316271, \"precision\": 1.0, \"recall\": 0.023055589368372917, \"specificity\": 1.0, \"npv\": 0.9997678303883762, \"accuracy\": 0.9997678316604571, \"f1\": 0.0450720168248282, \"f2\": 0.028654326116324787, \"f0_5\": 0.10554439400830741, \"p4\": 0.08625585680963711, \"phi\": 0.1518230435775265}, {\"truth_threshold\": 39.91999910771847, \"match_probability\": 0.9999999999990387, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6992.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296969.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.023002951036481655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9769970489635184, \"precision\": 1.0, \"recall\": 0.023002951036481655, \"specificity\": 1.0, \"npv\": 0.9997678178818472, \"accuracy\": 0.9997678191510923, \"f1\": 0.04497142654999309, \"f2\": 0.0285892793473532, \"f0_5\": 0.10532372886972817, \"p4\": 0.08607163923269867, \"phi\": 0.1516496296157239}, {\"truth_threshold\": 39.93999910727143, \"match_probability\": 0.9999999999990519, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6972.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 296989.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022937153121617575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9770628468783824, \"precision\": 1.0, \"recall\": 0.022937153121617575, \"specificity\": 1.0, \"npv\": 0.9997678022486864, \"accuracy\": 0.9997678035143861, \"f1\": 0.04484567414844999, \"f2\": 0.028507968492397874, \"f0_5\": 0.10504777775434007, \"p4\": 0.08584129070615129, \"phi\": 0.1514325829081747}, {\"truth_threshold\": 39.9599991068244, \"match_probability\": 0.999999999999065, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6916.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297045.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022752918959998158, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9772470810400018, \"precision\": 1.0, \"recall\": 0.022752918959998158, \"specificity\": 1.0, \"npv\": 0.9997677584758389, \"accuracy\": 0.999767759731609, \"f1\": 0.04449348134471189, \"f2\": 0.028280283947790245, \"f0_5\": 0.10427440633245383, \"p4\": 0.08519586191981222, \"phi\": 0.1508231904828292}, {\"truth_threshold\": 39.97999910637736, \"match_probability\": 0.9999999999990778, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6880.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297081.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022634482713242816, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9773655172867571, \"precision\": 1.0, \"recall\": 0.022634482713242816, \"specificity\": 1.0, \"npv\": 0.9997677303361532, \"accuracy\": 0.999767731585538, \"f1\": 0.044267004674415536, \"f2\": 0.028133904298926003, \"f0_5\": 0.10377668704993649, \"p4\": 0.08478059059536108, \"phi\": 0.15043013464579386}, {\"truth_threshold\": 39.99999910593033, \"match_probability\": 0.9999999999990905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6849.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297112.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022532495945203495, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9774675040547965, \"precision\": 1.0, \"recall\": 0.022532495945203495, \"specificity\": 1.0, \"npv\": 0.9997677061047585, \"accuracy\": 0.9997677073486435, \"f1\": 0.04407194105723754, \"f2\": 0.028007848249724174, \"f0_5\": 0.10334774880265092, \"p4\": 0.08442277433459783, \"phi\": 0.15009084510372667}, {\"truth_threshold\": 40.01999910548329, \"match_probability\": 0.999999999999103, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6811.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297150.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02240747990696175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9775925200930382, \"precision\": 1.0, \"recall\": 0.02240747990696175, \"specificity\": 1.0, \"npv\": 0.9997676764017601, \"accuracy\": 0.999767677638902, \"f1\": 0.04383277772772322, \"f2\": 0.027853319211061173, \"f0_5\": 0.10282151537567367, \"p4\": 0.0839838809494582, \"phi\": 0.14967389258184702}, {\"truth_threshold\": 40.03999910503626, \"match_probability\": 0.9999999999991154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6795.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297166.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022354841575070485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9776451584249295, \"precision\": 1.0, \"recall\": 0.022354841575070485, \"specificity\": 1.0, \"npv\": 0.999767663895235, \"accuracy\": 0.999767665129537, \"f1\": 0.04373205987977706, \"f2\": 0.027788251478972945, \"f0_5\": 0.10259979887721545, \"p4\": 0.08379899142826176, \"phi\": 0.1494979857331071}, {\"truth_threshold\": 40.059999104589224, \"match_probability\": 0.9999999999991276, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6754.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297207.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022219955849599127, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9777800441504009, \"precision\": 1.0, \"recall\": 0.022219955849599127, \"specificity\": 1.0, \"npv\": 0.9997676318472658, \"accuracy\": 0.9997676330742895, \"f1\": 0.04347392304845276, \"f2\": 0.027621507641923185, \"f0_5\": 0.10203125896965651, \"p4\": 0.08332496213470897, \"phi\": 0.14904627683878763}, {\"truth_threshold\": 40.07999910414219, \"match_probability\": 0.9999999999991396, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6713.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.022085070124127765, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9779149298758723, \"precision\": 1.0, \"recall\": 0.022085070124127765, \"specificity\": 1.0, \"npv\": 0.9997675997992987, \"accuracy\": 0.9997676010190419, \"f1\": 0.04321571808390789, \"f2\": 0.02745475262094119, \"f0_5\": 0.10146215535665164, \"p4\": 0.08285057301624199, \"phi\": 0.14859319482869468}, {\"truth_threshold\": 40.099999103695154, \"match_probability\": 0.9999999999991515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6703.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297258.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02205217116669573, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9779478288333042, \"precision\": 1.0, \"recall\": 0.02205217116669573, \"specificity\": 1.0, \"npv\": 0.9997675919827217, \"accuracy\": 0.9997675932006889, \"f1\": 0.04315273092472897, \"f2\": 0.027414078967925158, \"f0_5\": 0.10132326399071266, \"p4\": 0.08273481372291813, \"phi\": 0.14848247730058317}, {\"truth_threshold\": 40.11999910324812, \"match_probability\": 0.9999999999991631, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6679.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297282.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021973213668858835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9780267863311412, \"precision\": 1.0, \"recall\": 0.021973213668858835, \"specificity\": 1.0, \"npv\": 0.9997675732229373, \"accuracy\": 0.9997675744366415, \"f1\": 0.04300154519701262, \"f2\": 0.027316459485833805, \"f0_5\": 0.10098978761752404, \"p4\": 0.08245690394978117, \"phi\": 0.14821641780053946}, {\"truth_threshold\": 40.139999102801085, \"match_probability\": 0.9999999999991747, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6669.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297292.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021940314711426795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9780596852885732, \"precision\": 1.0, \"recall\": 0.021940314711426795, \"specificity\": 1.0, \"npv\": 0.9997675654063607, \"accuracy\": 0.9997675666182885, \"f1\": 0.04293854424878473, \"f2\": 0.02727578357039966, \"f0_5\": 0.100850781975399, \"p4\": 0.08234107175063979, \"phi\": 0.1481054186155676}, {\"truth_threshold\": 40.15999910235405, \"match_probability\": 0.999999999999186, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6620.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021779109820009804, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9782208901799901, \"precision\": 1.0, \"recall\": 0.021779109820009804, \"specificity\": 1.0, \"npv\": 0.9997675271051369, \"accuracy\": 0.9997675283083585, \"f1\": 0.04262978095891249, \"f2\": 0.02707646196534213, \"f0_5\": 0.10016916786960456, \"p4\": 0.08177318371635758, \"phi\": 0.1475603156926089}, {\"truth_threshold\": 40.179999101907015, \"match_probability\": 0.9999999999991972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6591.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297370.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02168370284345689, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9783162971565431, \"precision\": 1.0, \"recall\": 0.02168370284345689, \"specificity\": 1.0, \"npv\": 0.9997675044370672, \"accuracy\": 0.9997675056351346, \"f1\": 0.04244699760426595, \"f2\": 0.0269584885903954, \"f0_5\": 0.09976538257776432, \"p4\": 0.08143684376349439, \"phi\": 0.14723675315205045}, {\"truth_threshold\": 40.19999910145998, \"match_probability\": 0.9999999999992082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6556.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297405.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021568556492444754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9784314435075553, \"precision\": 1.0, \"recall\": 0.021568556492444754, \"specificity\": 1.0, \"npv\": 0.9997674770790533, \"accuracy\": 0.999767478270899, \"f1\": 0.0422263515363088, \"f2\": 0.02681609947643979, \"f0_5\": 0.09927767766555114, \"p4\": 0.08103067539209075, \"phi\": 0.14684529719636422}, {\"truth_threshold\": 40.219999101012945, \"match_probability\": 0.9999999999992192, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6531.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297430.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021486309098864658, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9785136909011354, \"precision\": 1.0, \"recall\": 0.021486309098864658, \"specificity\": 1.0, \"npv\": 0.9997674575376158, \"accuracy\": 0.9997674587250163, \"f1\": 0.04206871674632519, \"f2\": 0.026714387974230494, \"f0_5\": 0.09892906372600997, \"p4\": 0.08074039371551825, \"phi\": 0.1465650456952109}, {\"truth_threshold\": 40.23999910056591, \"match_probability\": 0.9999999999992298, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6504.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297457.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02139748191379815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9786025180862018, \"precision\": 1.0, \"recall\": 0.02139748191379815, \"specificity\": 1.0, \"npv\": 0.9997674364328641, \"accuracy\": 0.999767437615463, \"f1\": 0.04189844265859276, \"f2\": 0.026604534878774292, \"f0_5\": 0.0985523233437482, \"p4\": 0.08042673830194348, \"phi\": 0.14626177094195375}, {\"truth_threshold\": 40.259999100118876, \"match_probability\": 0.9999999999992405, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6473.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297488.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02129549514575883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9787045048542412, \"precision\": 1.0, \"recall\": 0.02129549514575883, \"specificity\": 1.0, \"npv\": 0.9997674122014836, \"accuracy\": 0.9997674133785686, \"f1\": 0.04170290625382529, \"f2\": 0.02647840126579275, \"f0_5\": 0.09811946533758978, \"p4\": 0.08006642163612628, \"phi\": 0.14591278927299198}, {\"truth_threshold\": 40.27999909967184, \"match_probability\": 0.9999999999992509, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6438.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297523.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021180348794746694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9788196512052533, \"precision\": 1.0, \"recall\": 0.021180348794746694, \"specificity\": 1.0, \"npv\": 0.9997673848434748, \"accuracy\": 0.9997673860143329, \"f1\": 0.04148209240364821, \"f2\": 0.0263359846582049, \"f0_5\": 0.09763036337663361, \"p4\": 0.07965936331687487, \"phi\": 0.14551777185140155}, {\"truth_threshold\": 40.299999099224806, \"match_probability\": 0.9999999999992613, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6408.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297553.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021081651922450578, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9789183480775494, \"precision\": 1.0, \"recall\": 0.021081651922450578, \"specificity\": 1.0, \"npv\": 0.9997673613937541, \"accuracy\": 0.9997673625592737, \"f1\": 0.041292783750954506, \"f2\": 0.02621390678845279, \"f0_5\": 0.09721080241388622, \"p4\": 0.07931024565151014, \"phi\": 0.14517833005076886}, {\"truth_threshold\": 40.31999909877777, \"match_probability\": 0.9999999999992715, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6398.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297563.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.021048752965018538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9789512470349815, \"precision\": 1.0, \"recall\": 0.021048752965018538, \"specificity\": 1.0, \"npv\": 0.9997673535771808, \"accuracy\": 0.9997673547409206, \"f1\": 0.041229672733834044, \"f2\": 0.02617321283346506, \"f0_5\": 0.09707088085983134, \"p4\": 0.0791938298797364, \"phi\": 0.14506500628317096}, {\"truth_threshold\": 40.339999098330736, \"match_probability\": 0.9999999999992815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6378.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297583.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02098295505015446, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9790170449498455, \"precision\": 1.0, \"recall\": 0.02098295505015446, \"specificity\": 1.0, \"npv\": 0.9997673379440346, \"accuracy\": 0.9997673391042146, \"f1\": 0.041103438497900685, \"f2\": 0.026091822925785987, \"f0_5\": 0.096790935827822, \"p4\": 0.07896093347509238, \"phi\": 0.1448380927542622}, {\"truth_threshold\": 40.3599990978837, \"match_probability\": 0.9999999999992913, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6359.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297602.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020920447031033587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9790795529689664, \"precision\": 1.0, \"recall\": 0.020920447031033587, \"specificity\": 1.0, \"npv\": 0.9997673230925461, \"accuracy\": 0.9997673242493437, \"f1\": 0.040983500902294405, \"f2\": 0.026014500046228, \"f0_5\": 0.09652486209649754, \"p4\": 0.07873960175077119, \"phi\": 0.14462219513655522}, {\"truth_threshold\": 40.37999909743667, \"match_probability\": 0.9999999999993011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6326.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297635.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02081188047150786, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9791881195284922, \"precision\": 1.0, \"recall\": 0.02081188047150786, \"specificity\": 1.0, \"npv\": 0.9997672972978566, \"accuracy\": 0.9997672984487787, \"f1\": 0.04077515332579193, \"f2\": 0.025880196699313514, \"f0_5\": 0.09606244210590253, \"p4\": 0.07835499778143755, \"phi\": 0.14424644706434006}, {\"truth_threshold\": 40.39999909698963, \"match_probability\": 0.9999999999993108, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6310.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297651.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020759242139616597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9792407578603834, \"precision\": 1.0, \"recall\": 0.020759242139616597, \"specificity\": 1.0, \"npv\": 0.999767284791341, \"accuracy\": 0.9997672859394138, \"f1\": 0.04067412036574478, \"f2\": 0.025815077314315545, \"f0_5\": 0.09583810498753041, \"p4\": 0.07816843822890665, \"phi\": 0.1440639134143262}, {\"truth_threshold\": 40.4199990965426, \"match_probability\": 0.9999999999993202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6269.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297692.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020624356414145235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9793756435858547, \"precision\": 1.0, \"recall\": 0.020624356414145235, \"specificity\": 1.0, \"npv\": 0.9997672527433962, \"accuracy\": 0.9997672538841662, \"f1\": 0.04041517583728202, \"f2\": 0.025648201107426237, \"f0_5\": 0.09526284278059914, \"p4\": 0.07769012608599984, \"phi\": 0.14359511186586618}, {\"truth_threshold\": 40.43999909609556, \"match_probability\": 0.9999999999993295, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6239.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02052565954184912, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9794743404581508, \"precision\": 1.0, \"recall\": 0.02052565954184912, \"specificity\": 1.0, \"npv\": 0.9997672292936817, \"accuracy\": 0.999767230429107, \"f1\": 0.040225660863958734, \"f2\": 0.02552608947182802, \"f0_5\": 0.0948415557724289, \"p4\": 0.07733991055004309, \"phi\": 0.14325111437465302}, {\"truth_threshold\": 40.45999909564853, \"match_probability\": 0.9999999999993389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6226.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297735.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020482890897187467, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9795171091028125, \"precision\": 1.0, \"recall\": 0.020482890897187467, \"specificity\": 1.0, \"npv\": 0.9997672191321391, \"accuracy\": 0.999767220265248, \"f1\": 0.040143526324443, \"f2\": 0.025473172567856178, \"f0_5\": 0.09465890258920834, \"p4\": 0.07718808980235552, \"phi\": 0.14310179199460824}, {\"truth_threshold\": 40.47999909520149, \"match_probability\": 0.999999999999348, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6163.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297798.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020275627465365622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9797243725346344, \"precision\": 1.0, \"recall\": 0.020275627465365622, \"specificity\": 1.0, \"npv\": 0.9997671698877433, \"accuracy\": 0.9997671710096238, \"f1\": 0.039745392165714356, \"f2\": 0.025216713161217572, \"f0_5\": 0.09377291829598951, \"p4\": 0.07645182282923307, \"phi\": 0.14237593437356885}, {\"truth_threshold\": 40.49999909475446, \"match_probability\": 0.9999999999993568, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6131.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0201703508015831, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798296491984169, \"precision\": 1.0, \"recall\": 0.0201703508015831, \"specificity\": 1.0, \"npv\": 0.9997671448747187, \"accuracy\": 0.999767145990894, \"f1\": 0.039543103337074156, \"f2\": 0.02508643793858303, \"f0_5\": 0.09332237392879432, \"p4\": 0.07607751529001416, \"phi\": 0.14200582393697883}, {\"truth_threshold\": 40.51999909430742, \"match_probability\": 0.9999999999993657, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6124.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297837.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.02014732153138067, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798526784686193, \"precision\": 1.0, \"recall\": 0.02014732153138067, \"specificity\": 1.0, \"npv\": 0.9997671394031198, \"accuracy\": 0.9997671405180468, \"f1\": 0.03949884709031395, \"f2\": 0.025057939324106687, \"f0_5\": 0.09322377053921822, \"p4\": 0.07599560579312162, \"phi\": 0.1419247336233658}, {\"truth_threshold\": 40.53999909386039, \"match_probability\": 0.9999999999993745, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6110.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.020101262990975817, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9798987370090242, \"precision\": 1.0, \"recall\": 0.020101262990975817, \"specificity\": 1.0, \"npv\": 0.9997671284599221, \"accuracy\": 0.9997671295723526, \"f1\": 0.03941032860215886, \"f2\": 0.02500094111562301, \"f0_5\": 0.09302651331755993, \"p4\": 0.07583175477449444, \"phi\": 0.14176241384409902}, {\"truth_threshold\": 40.55999909341335, \"match_probability\": 0.999999999999383, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6056.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019923608620842807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9800763913791571, \"precision\": 1.0, \"recall\": 0.019923608620842807, \"specificity\": 1.0, \"npv\": 0.9997670862504473, \"accuracy\": 0.999767087353246, \"f1\": 0.03906882525796972, \"f2\": 0.0247810786480072, \"f0_5\": 0.09226503344150402, \"p4\": 0.07519935772521165, \"phi\": 0.1411345745678723}, {\"truth_threshold\": 40.57999909296632, \"match_probability\": 0.9999999999993916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6029.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297932.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0198347814357763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9801652185642237, \"precision\": 1.0, \"recall\": 0.0198347814357763, \"specificity\": 1.0, \"npv\": 0.9997670651457112, \"accuracy\": 0.9997670662436928, \"f1\": 0.03889802896867641, \"f2\": 0.024671140126674377, \"f0_5\": 0.09188391749497832, \"p4\": 0.07488292059755867, \"phi\": 0.14081960525385911}, {\"truth_threshold\": 40.59999909251928, \"match_probability\": 0.9999999999993999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5999.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019736084563480184, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9802639154365198, \"precision\": 1.0, \"recall\": 0.019736084563480184, \"specificity\": 1.0, \"npv\": 0.9997670416960056, \"accuracy\": 0.9997670427886337, \"f1\": 0.03870822041553749, \"f2\": 0.024548980515499946, \"f0_5\": 0.09146016093573243, \"p4\": 0.07453113703405019, \"phi\": 0.14046881105317574}, {\"truth_threshold\": 40.61999909207225, \"match_probability\": 0.9999999999994083, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5979.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 297982.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019670286648616104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9803297133513839, \"precision\": 1.0, \"recall\": 0.019670286648616104, \"specificity\": 1.0, \"npv\": 0.9997670260628692, \"accuracy\": 0.9997670271519276, \"f1\": 0.0385816609666387, \"f2\": 0.024467537442002647, \"f0_5\": 0.09117748423951665, \"p4\": 0.07429650536654311, \"phi\": 0.1402344607594406}, {\"truth_threshold\": 40.639999091625214, \"match_probability\": 0.9999999999994164, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5919.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298042.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01947289290402387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9805271070959761, \"precision\": 1.0, \"recall\": 0.01947289290402387, \"specificity\": 1.0, \"npv\": 0.9997669791634626, \"accuracy\": 0.9997669802418092, \"f1\": 0.03820188460049051, \"f2\": 0.02422319222304162, \"f0_5\": 0.09032862588779655, \"p4\": 0.07359208522505575, \"phi\": 0.13952904828110013}, {\"truth_threshold\": 40.65999909117818, \"match_probability\": 0.9999999999994243, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5888.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298073.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01937090613598455, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9806290938640154, \"precision\": 1.0, \"recall\": 0.01937090613598455, \"specificity\": 1.0, \"npv\": 0.9997669549321043, \"accuracy\": 0.9997669560049147, \"f1\": 0.038005609183828254, \"f2\": 0.02409693778995721, \"f0_5\": 0.08988956163572133, \"p4\": 0.07322782587049827, \"phi\": 0.13916318421856008}, {\"truth_threshold\": 40.679999090731144, \"match_probability\": 0.9999999999994323, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5847.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298114.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.019236020410513192, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9807639795894868, \"precision\": 1.0, \"recall\": 0.019236020410513192, \"specificity\": 1.0, \"npv\": 0.9997669228841806, \"accuracy\": 0.9997669239496672, \"f1\": 0.03774595878737799, \"f2\": 0.023929946279378337, \"f0_5\": 0.0893083528588754, \"p4\": 0.07274573980521322, \"phi\": 0.13867781702332954}, {\"truth_threshold\": 40.69999909028411, \"match_probability\": 0.9999999999994401, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5803.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298158.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01909126499781222, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9809087350021878, \"precision\": 1.0, \"recall\": 0.01909126499781222, \"specificity\": 1.0, \"npv\": 0.999766888491289, \"accuracy\": 0.9997668895489137, \"f1\": 0.037467233119407035, \"f2\": 0.02375072340864423, \"f0_5\": 0.08868396842037699, \"p4\": 0.0722279686066419, \"phi\": 0.13815503828751735}, {\"truth_threshold\": 40.719999089837074, \"match_probability\": 0.9999999999994479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5766.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298195.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018969538855313675, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810304611446863, \"precision\": 1.0, \"recall\": 0.018969538855313675, \"specificity\": 1.0, \"npv\": 0.9997668595699958, \"accuracy\": 0.9997668606210074, \"f1\": 0.037232788875364436, \"f2\": 0.023600003274367433, \"f0_5\": 0.08815839767601866, \"p4\": 0.07179224074054556, \"phi\": 0.1377138928680326}, {\"truth_threshold\": 40.73999908939004, \"match_probability\": 0.9999999999994554, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5752.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298209.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01892348031490882, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9810765196850911, \"precision\": 1.0, \"recall\": 0.01892348031490882, \"specificity\": 1.0, \"npv\": 0.9997668486268042, \"accuracy\": 0.9997668496753132, \"f1\": 0.03714406563495882, \"f2\": 0.023542971653476272, \"f0_5\": 0.08795940899595986, \"p4\": 0.07162729220181309, \"phi\": 0.13754660402746322}, {\"truth_threshold\": 40.759999088943005, \"match_probability\": 0.999999999999463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5730.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298231.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018851102608558334, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9811488973914416, \"precision\": 1.0, \"recall\": 0.018851102608558334, \"specificity\": 1.0, \"npv\": 0.9997668314303607, \"accuracy\": 0.9997668324749364, \"f1\": 0.03700462719291164, \"f2\": 0.02345334789378294, \"f0_5\": 0.08764657474738513, \"p4\": 0.07136800018098592, \"phi\": 0.1372833097063404}, {\"truth_threshold\": 40.77999908849597, \"match_probability\": 0.9999999999994703, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5692.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298269.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018726086570316585, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9812739134296834, \"precision\": 1.0, \"recall\": 0.018726086570316585, \"specificity\": 1.0, \"npv\": 0.9997668017274143, \"accuracy\": 0.9997668027651948, \"f1\": 0.03676373230680794, \"f2\": 0.02329853561417756, \"f0_5\": 0.08710582776551822, \"p4\": 0.07091988101528861, \"phi\": 0.13682733527799223}, {\"truth_threshold\": 40.799999088048935, \"match_probability\": 0.9999999999994776, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5663.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298298.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018630679593763674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9813693204062364, \"precision\": 1.0, \"recall\": 0.018630679593763674, \"specificity\": 1.0, \"npv\": 0.9997667790593774, \"accuracy\": 0.999766780091971, \"f1\": 0.03657985169108338, \"f2\": 0.023180382920441715, \"f0_5\": 0.08669281381941318, \"p4\": 0.07057768114716141, \"phi\": 0.1364783298884639}, {\"truth_threshold\": 40.8199990876019, \"match_probability\": 0.9999999999994849, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5630.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298331.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018522113034237946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9814778869657621, \"precision\": 1.0, \"recall\": 0.018522113034237946, \"specificity\": 1.0, \"npv\": 0.9997667532647161, \"accuracy\": 0.9997667542914058, \"f1\": 0.036370566327832525, \"f2\": 0.023045926478991775, \"f0_5\": 0.08622247542736025, \"p4\": 0.07018805554293976, \"phi\": 0.13608009704524077}, {\"truth_threshold\": 40.839999087154865, \"match_probability\": 0.999999999999492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5593.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018400386891739402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9815996131082606, \"precision\": 1.0, \"recall\": 0.018400386891739402, \"specificity\": 1.0, \"npv\": 0.9997667243434306, \"accuracy\": 0.9997667253634995, \"f1\": 0.036135859979195877, \"f2\": 0.022895163647408748, \"f0_5\": 0.08569467384542782, \"p4\": 0.06975091654921557, \"phi\": 0.13563220314293392}, {\"truth_threshold\": 40.85999908670783, \"match_probability\": 0.999999999999499, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5553.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298408.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018268791062011246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9817312089379887, \"precision\": 1.0, \"recall\": 0.018268791062011246, \"specificity\": 1.0, \"npv\": 0.9997666930771779, \"accuracy\": 0.9997666940900873, \"f1\": 0.03588206026221754, \"f2\": 0.022732166527345325, \"f0_5\": 0.08512353873557897, \"p4\": 0.06927799334326994, \"phi\": 0.1351463237627457}, {\"truth_threshold\": 40.879999086260796, \"match_probability\": 0.9999999999995058, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5518.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298443.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018153644710999107, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9818463552890009, \"precision\": 1.0, \"recall\": 0.018153644710999107, \"specificity\": 1.0, \"npv\": 0.9997666657192085, \"accuracy\": 0.9997666667258516, \"f1\": 0.035659931691649514, \"f2\": 0.02258953528929179, \"f0_5\": 0.08462333567460963, \"p4\": 0.06886389502639899, \"phi\": 0.1347197418471648}, {\"truth_threshold\": 40.89999908581376, \"match_probability\": 0.9999999999995126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5489.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298472.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.018058237734446196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9819417622655539, \"precision\": 1.0, \"recall\": 0.018058237734446196, \"specificity\": 1.0, \"npv\": 0.9997666430511778, \"accuracy\": 0.9997666440526277, \"f1\": 0.03547584423978026, \"f2\": 0.022471348927769905, \"f0_5\": 0.08420855616614045, \"p4\": 0.06852057938681369, \"phi\": 0.13436526232321871}, {\"truth_threshold\": 40.919999085366726, \"match_probability\": 0.9999999999995193, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5451.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017933221696204447, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9820667783037955, \"precision\": 1.0, \"recall\": 0.017933221696204447, \"specificity\": 1.0, \"npv\": 0.9997666133482426, \"accuracy\": 0.9997666143428862, \"f1\": 0.035234573966103445, \"f2\": 0.02231647554440164, \"f0_5\": 0.08366460485319172, \"p4\": 0.0680704352017517, \"phi\": 0.1338993514608549}, {\"truth_threshold\": 40.93999908491969, \"match_probability\": 0.9999999999995259, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5425.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298536.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017847684406881146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9821523155931189, \"precision\": 1.0, \"recall\": 0.017847684406881146, \"specificity\": 1.0, \"npv\": 0.9997665930251827, \"accuracy\": 0.9997665940151682, \"f1\": 0.03506946015656817, \"f2\": 0.022210503992158976, \"f0_5\": 0.08329213507297466, \"p4\": 0.0677622571390261, \"phi\": 0.13357963404971673}, {\"truth_threshold\": 40.959999084472656, \"match_probability\": 0.9999999999995325, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5358.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298603.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017627261392086487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9823727386079135, \"precision\": 1.0, \"recall\": 0.017627261392086487, \"specificity\": 1.0, \"npv\": 0.9997665406542243, \"accuracy\": 0.9997665416322027, \"f1\": 0.034643846643756124, \"f2\": 0.021937402657381824, \"f0_5\": 0.08233121179619722, \"p4\": 0.06696741360339917, \"phi\": 0.13275219826117407}, {\"truth_threshold\": 40.97999908402562, \"match_probability\": 0.9999999999995389, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5339.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017564753372965612, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9824352466270344, \"precision\": 1.0, \"recall\": 0.017564753372965612, \"specificity\": 1.0, \"npv\": 0.9997665258027595, \"accuracy\": 0.9997665267773319, \"f1\": 0.034523116715163275, \"f2\": 0.021859950556141053, \"f0_5\": 0.08205842301508989, \"p4\": 0.06674182845580554, \"phi\": 0.1325166120011832}, {\"truth_threshold\": 40.99999908357859, \"match_probability\": 0.9999999999995453, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017482505979385513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9825174940206145, \"precision\": 1.0, \"recall\": 0.017482505979385513, \"specificity\": 1.0, \"npv\": 0.9997665062613591, \"accuracy\": 0.9997665072314492, \"f1\": 0.034364238945921916, \"f2\": 0.021758036224632685, \"f0_5\": 0.08169929616225474, \"p4\": 0.06644488340804057, \"phi\": 0.13220599049855333}, {\"truth_threshold\": 41.01999908313155, \"match_probability\": 0.9999999999995515, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5281.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298680.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017373939419859784, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9826260605801402, \"precision\": 1.0, \"recall\": 0.017373939419859784, \"specificity\": 1.0, \"npv\": 0.9997664804667118, \"accuracy\": 0.9997664814308841, \"f1\": 0.03415448095666177, \"f2\": 0.02162350291739175, \"f0_5\": 0.08122491040804712, \"p4\": 0.06605270266688544, \"phi\": 0.13179484916200285}, {\"truth_threshold\": 41.03999908268452, \"match_probability\": 0.9999999999995577, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5250.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017271952651820462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9827280473481795, \"precision\": 1.0, \"recall\": 0.017271952651820462, \"specificity\": 1.0, \"npv\": 0.9997664562353776, \"accuracy\": 0.9997664571939897, \"f1\": 0.03395739478867181, \"f2\": 0.021497116520104102, \"f0_5\": 0.08077892424013959, \"p4\": 0.06568406919260475, \"phi\": 0.13140745372685592}, {\"truth_threshold\": 41.05999908223748, \"match_probability\": 0.9999999999995638, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5193.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298768.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.017084428594457843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9829155714055422, \"precision\": 1.0, \"recall\": 0.017084428594457843, \"specificity\": 1.0, \"npv\": 0.9997664116809921, \"accuracy\": 0.9997664126293773, \"f1\": 0.033594907392432254, \"f2\": 0.021264711880147776, \"f0_5\": 0.0799579962615441, \"p4\": 0.06500569921791956, \"phi\": 0.13069214923437922}, {\"truth_threshold\": 41.07999908179045, \"match_probability\": 0.9999999999995698, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5166.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016995601409391336, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9830043985906086, \"precision\": 1.0, \"recall\": 0.016995601409391336, \"specificity\": 1.0, \"npv\": 0.9997663905762846, \"accuracy\": 0.9997663915198239, \"f1\": 0.03342315617852856, \"f2\": 0.021154617898297312, \"f0_5\": 0.07956873315363881, \"p4\": 0.06468411257554949, \"phi\": 0.13035195079760176}, {\"truth_threshold\": 41.09999908134341, \"match_probability\": 0.9999999999995757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5130.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016877165162635994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983122834837364, \"precision\": 1.0, \"recall\": 0.016877165162635994, \"specificity\": 1.0, \"npv\": 0.9997663624366759, \"accuracy\": 0.999766363373753, \"f1\": 0.033194107884085916, \"f2\": 0.021007818348302256, \"f0_5\": 0.07904931259457411, \"p4\": 0.06425507660346434, \"phi\": 0.12989696695031636}, {\"truth_threshold\": 41.11999908089638, \"match_probability\": 0.9999999999995816, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5109.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016808077352028713, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9831919226479713, \"precision\": 1.0, \"recall\": 0.016808077352028713, \"specificity\": 1.0, \"npv\": 0.999766346021905, \"accuracy\": 0.9997663469552116, \"f1\": 0.03306047173779403, \"f2\": 0.020922181279705278, \"f0_5\": 0.0787461043104591, \"p4\": 0.06400467157338754, \"phi\": 0.12963082225262357}, {\"truth_threshold\": 41.13999908044934, \"match_probability\": 0.9999999999995873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5097.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298864.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016768598603110266, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9832314013968897, \"precision\": 1.0, \"recall\": 0.016768598603110266, \"specificity\": 1.0, \"npv\": 0.999766336642036, \"accuracy\": 0.9997663375731879, \"f1\": 0.032984100071831175, \"f2\": 0.020873244489291457, \"f0_5\": 0.07857277192160296, \"p4\": 0.06386153860985133, \"phi\": 0.12947849395190042}, {\"truth_threshold\": 41.15999908000231, \"match_probability\": 0.999999999999593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5062.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01665345225209813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9833465477479019, \"precision\": 1.0, \"recall\": 0.01665345225209813, \"specificity\": 1.0, \"npv\": 0.999766309284086, \"accuracy\": 0.9997663102089522, \"f1\": 0.032761315500787966, \"f2\": 0.020730506689294673, \"f0_5\": 0.07806692596442419, \"p4\": 0.06344388301315011, \"phi\": 0.12903317594680408}, {\"truth_threshold\": 41.17999907955527, \"match_probability\": 0.9999999999995985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5027.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298934.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016538305901085994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983461694098914, \"precision\": 1.0, \"recall\": 0.016538305901085994, \"specificity\": 1.0, \"npv\": 0.9997662819261376, \"accuracy\": 0.9997662828447165, \"f1\": 0.032538480458788044, \"f2\": 0.020587760705266977, \"f0_5\": 0.07756064294949533, \"p4\": 0.06302595248729008, \"phi\": 0.1285863157574936}, {\"truth_threshold\": 41.19999907910824, \"match_probability\": 0.9999999999996041, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5013.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01649224736068114, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9835077526393189, \"precision\": 1.0, \"recall\": 0.01649224736068114, \"specificity\": 1.0, \"npv\": 0.9997662709829587, \"accuracy\": 0.9997662718990222, \"f1\": 0.0324493323062782, \"f2\": 0.020530660019969577, \"f0_5\": 0.07735800724045024, \"p4\": 0.06285870323596357, \"phi\": 0.1284071362655391}, {\"truth_threshold\": 41.2199990786612, \"match_probability\": 0.9999999999996095, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4977.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 298984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0163738111139258, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836261888860742, \"precision\": 1.0, \"recall\": 0.0163738111139258, \"specificity\": 1.0, \"npv\": 0.9997662428433567, \"accuracy\": 0.9997662437529512, \"f1\": 0.03222005709883537, \"f2\": 0.02038382367275792, \"f0_5\": 0.07683662221453735, \"p4\": 0.062428431422538996, \"phi\": 0.12794523679448325}, {\"truth_threshold\": 41.23999907821417, \"match_probability\": 0.999999999999615, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4957.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299004.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01630801319906172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9836919868009383, \"precision\": 1.0, \"recall\": 0.01630801319906172, \"specificity\": 1.0, \"npv\": 0.9997662272102452, \"accuracy\": 0.999766228116245, \"f1\": 0.03209265889329854, \"f2\": 0.02030224418230326, \"f0_5\": 0.07654676347868519, \"p4\": 0.06218926556148491, \"phi\": 0.1276879040055119}, {\"truth_threshold\": 41.259999077767134, \"match_probability\": 0.9999999999996202, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4953.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299008.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016294853616088907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983705146383911, \"precision\": 1.0, \"recall\": 0.016294853616088907, \"specificity\": 1.0, \"npv\": 0.9997662240836229, \"accuracy\": 0.9997662249889039, \"f1\": 0.03206717727263899, \"f2\": 0.020285927963453382, \"f0_5\": 0.07648877454265797, \"p4\": 0.062141421586202804, \"phi\": 0.12763637519043142}, {\"truth_threshold\": 41.2799990773201, \"match_probability\": 0.9999999999996255, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4937.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299024.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016242215284197645, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9837577847158023, \"precision\": 1.0, \"recall\": 0.016242215284197645, \"specificity\": 1.0, \"npv\": 0.9997662115771342, \"accuracy\": 0.999766212479539, \"f1\": 0.03196524419063898, \"f2\": 0.020220662018822378, \"f0_5\": 0.07625676147403995, \"p4\": 0.06195000966127955, \"phi\": 0.12743005156674192}, {\"truth_threshold\": 41.299999076873064, \"match_probability\": 0.9999999999996306, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4897.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299064.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01611061945446949, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9838893805455305, \"precision\": 1.0, \"recall\": 0.01611061945446949, \"specificity\": 1.0, \"npv\": 0.9997661803109136, \"accuracy\": 0.9997661812061267, \"f1\": 0.03171036528113243, \"f2\": 0.02005748967225644, \"f0_5\": 0.07567632723327843, \"p4\": 0.06147122753994943, \"phi\": 0.12691277506396925}, {\"truth_threshold\": 41.31999907642603, \"match_probability\": 0.9999999999996357, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4875.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.016038241748119002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.983961758251881, \"precision\": 1.0, \"recall\": 0.016038241748119002, \"specificity\": 1.0, \"npv\": 0.9997661631144931, \"accuracy\": 0.99976616400575, \"f1\": 0.0315701537385538, \"f2\": 0.01996774032353064, \"f0_5\": 0.07535684363802746, \"p4\": 0.061207743622187616, \"phi\": 0.12662737230006638}, {\"truth_threshold\": 41.339999075978994, \"match_probability\": 0.9999999999996407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4828.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299133.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01588361664818842, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9841163833518116, \"precision\": 1.0, \"recall\": 0.01588361664818842, \"specificity\": 1.0, \"npv\": 0.9997661263766877, \"accuracy\": 0.9997661272594907, \"f1\": 0.03127054396367746, \"f2\": 0.019775992240339747, \"f0_5\": 0.07467372777806992, \"p4\": 0.06064448023288375, \"phi\": 0.12601548273609717}, {\"truth_threshold\": 41.35999907553196, \"match_probability\": 0.9999999999996457, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4764.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299197.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01567306332062337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9843269366793767, \"precision\": 1.0, \"recall\": 0.01567306332062337, \"specificity\": 1.0, \"npv\": 0.9997660763507442, \"accuracy\": 0.999766077222031, \"f1\": 0.03086241800955543, \"f2\": 0.019514864723154363, \"f0_5\": 0.07374224885996712, \"p4\": 0.05987668068197286, \"phi\": 0.12517746211062275}, {\"truth_threshold\": 41.379999075084925, \"match_probability\": 0.9999999999996505, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4726.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299235.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015548047282381622, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9844519527176184, \"precision\": 1.0, \"recall\": 0.015548047282381622, \"specificity\": 1.0, \"npv\": 0.9997660466478426, \"accuracy\": 0.9997660475122895, \"f1\": 0.030620013152481317, \"f2\": 0.01935980730314525, \"f0_5\": 0.07318848435104455, \"p4\": 0.05942036118080113, \"phi\": 0.12467722231667021}, {\"truth_threshold\": 41.39999907463789, \"match_probability\": 0.9999999999996554, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4710.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299251.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015495408950490359, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9845045910495096, \"precision\": 1.0, \"recall\": 0.015495408950490359, \"specificity\": 1.0, \"npv\": 0.9997660341413583, \"accuracy\": 0.9997660350029246, \"f1\": 0.030517930093853975, \"f2\": 0.01929451707994894, \"f0_5\": 0.07295516432724805, \"p4\": 0.059228128795094044, \"phi\": 0.12446599356382551}, {\"truth_threshold\": 41.419999074190855, \"match_probability\": 0.9999999999996602, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4708.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299253.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015488829159003951, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984511170840996, \"precision\": 1.0, \"recall\": 0.015488829159003951, \"specificity\": 1.0, \"npv\": 0.9997660325780479, \"accuracy\": 0.999766033439254, \"f1\": 0.030505168967405214, \"f2\": 0.019286355681691562, \"f0_5\": 0.0729259928189273, \"p4\": 0.05920409566727281, \"phi\": 0.12443956475967184}, {\"truth_threshold\": 41.43999907374382, \"match_probability\": 0.9999999999996648, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4691.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299270.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015432900931369484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9845670990686305, \"precision\": 1.0, \"recall\": 0.015432900931369484, \"specificity\": 1.0, \"npv\": 0.9997660192899086, \"accuracy\": 0.9997660201480537, \"f1\": 0.030396692715420604, \"f2\": 0.019216982716595592, \"f0_5\": 0.07267797660546906, \"p4\": 0.05899977746555824, \"phi\": 0.1242146928919876}, {\"truth_threshold\": 41.459999073296785, \"match_probability\": 0.9999999999996694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4672.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299289.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01537039291224861, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9846296070877514, \"precision\": 1.0, \"recall\": 0.01537039291224861, \"specificity\": 1.0, \"npv\": 0.9997660044384593, \"accuracy\": 0.9997660052931829, \"f1\": 0.030275440409807116, \"f2\": 0.019139445939258478, \"f0_5\": 0.07240065830050613, \"p4\": 0.05877134426240358, \"phi\": 0.1239628827856468}, {\"truth_threshold\": 41.47999907284975, \"match_probability\": 0.9999999999996739, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4646.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299315.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01528485562292531, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9847151443770746, \"precision\": 1.0, \"recall\": 0.01528485562292531, \"specificity\": 1.0, \"npv\": 0.9997659841154241, \"accuracy\": 0.999765984965465, \"f1\": 0.030109492007634305, \"f2\": 0.019033339068734688, \"f0_5\": 0.0720209583158939, \"p4\": 0.05845861870186086, \"phi\": 0.12361746933146664}, {\"truth_threshold\": 41.499999072402716, \"match_probability\": 0.9999999999996785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4629.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299332.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015228927395290843, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9847710726047092, \"precision\": 1.0, \"recall\": 0.015228927395290843, \"specificity\": 1.0, \"npv\": 0.9997659708272861, \"accuracy\": 0.9997659716742648, \"f1\": 0.03000097216371237, \"f2\": 0.018963959055218756, \"f0_5\": 0.07177256052369627, \"p4\": 0.05825406130407352, \"phi\": 0.1233910992819628}, {\"truth_threshold\": 41.51999907195568, \"match_probability\": 0.9999999999996829, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4600.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299361.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01513352041873793, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.984866479581262, \"precision\": 1.0, \"recall\": 0.01513352041873793, \"specificity\": 1.0, \"npv\": 0.999765948159287, \"accuracy\": 0.999765949001041, \"f1\": 0.029815822479185638, \"f2\": 0.01884560045360541, \"f0_5\": 0.07134858124897242, \"p4\": 0.05790495889268654, \"phi\": 0.12300397713256046}, {\"truth_threshold\": 41.539999071508646, \"match_probability\": 0.9999999999996873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4588.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.015094041669819484, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9849059583301805, \"precision\": 1.0, \"recall\": 0.015094041669819484, \"specificity\": 1.0, \"npv\": 0.9997659387794255, \"accuracy\": 0.9997659396190173, \"f1\": 0.02973919863619717, \"f2\": 0.018796622835192785, \"f0_5\": 0.07117305228147794, \"p4\": 0.057760446795502546, \"phi\": 0.12284343181465929}, {\"truth_threshold\": 41.55999907106161, \"match_probability\": 0.9999999999996916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4551.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299410.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014972315527320939, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9850276844726791, \"precision\": 1.0, \"recall\": 0.014972315527320939, \"specificity\": 1.0, \"npv\": 0.9997659098581873, \"accuracy\": 0.999765910691111, \"f1\": 0.029502904263043254, \"f2\": 0.018645602448387612, \"f0_5\": 0.07063150869895861, \"p4\": 0.05731466158878015, \"phi\": 0.12234709091701317}, {\"truth_threshold\": 41.579999070614576, \"match_probability\": 0.9999999999996958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4536.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01492296709117288, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9850770329088271, \"precision\": 1.0, \"recall\": 0.01492296709117288, \"specificity\": 1.0, \"npv\": 0.9997658981333614, \"accuracy\": 0.9997658989635814, \"f1\": 0.029407093099770826, \"f2\": 0.018584375358494894, \"f0_5\": 0.0704118222318809, \"p4\": 0.05713384907265983, \"phi\": 0.12214529707164762}, {\"truth_threshold\": 41.59999907016754, \"match_probability\": 0.9999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4509.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299452.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014834139906106375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9851658600938936, \"precision\": 1.0, \"recall\": 0.014834139906106375, \"specificity\": 1.0, \"npv\": 0.9997658770286755, \"accuracy\": 0.9997658778540282, \"f1\": 0.02923460952442701, \"f2\": 0.01847416280371335, \"f0_5\": 0.0700161802749715, \"p4\": 0.05680825736948858, \"phi\": 0.12178122553659292}, {\"truth_threshold\": 41.61999906972051, \"match_probability\": 0.9999999999997041, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4496.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014791371261444725, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9852086287385553, \"precision\": 1.0, \"recall\": 0.014791371261444725, \"specificity\": 1.0, \"npv\": 0.9997658668671604, \"accuracy\": 0.9997658676901692, \"f1\": 0.02915155110760981, \"f2\": 0.018421095760197976, \"f0_5\": 0.06982559132771125, \"p4\": 0.05665143172979845, \"phi\": 0.12160554309468088}, {\"truth_threshold\": 41.63999906927347, \"match_probability\": 0.9999999999997082, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4472.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299489.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014712413763607832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9852875862363921, \"precision\": 1.0, \"recall\": 0.014712413763607832, \"specificity\": 1.0, \"npv\": 0.9997658481074407, \"accuracy\": 0.9997658489261219, \"f1\": 0.028998194097259372, \"f2\": 0.01832312286325837, \"f0_5\": 0.06947357301094613, \"p4\": 0.05636180620584885, \"phi\": 0.12128053769703104}, {\"truth_threshold\": 41.65999906882644, \"match_probability\": 0.9999999999997122, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4460.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299501.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014672935014689385, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9853270649853106, \"precision\": 1.0, \"recall\": 0.014672935014689385, \"specificity\": 1.0, \"npv\": 0.9997658387275812, \"accuracy\": 0.9997658395440981, \"f1\": 0.02892150664189533, \"f2\": 0.01827413496964691, \"f0_5\": 0.06929748509171817, \"p4\": 0.056216944156481416, \"phi\": 0.1211177079602988}, {\"truth_threshold\": 41.6799990683794, \"match_probability\": 0.9999999999997161, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4445.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299516.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014623586578541327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9853764134214587, \"precision\": 1.0, \"recall\": 0.014623586578541327, \"specificity\": 1.0, \"npv\": 0.999765827002757, \"accuracy\": 0.9997658278165685, \"f1\": 0.028825638930500705, \"f2\": 0.018212898747755654, \"f0_5\": 0.06907730130757349, \"p4\": 0.05603582036555831, \"phi\": 0.12091386243703318}, {\"truth_threshold\": 41.69999906793237, \"match_probability\": 0.9999999999997201, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4417.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299544.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014531469497731616, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9854685305022683, \"precision\": 1.0, \"recall\": 0.014531469497731616, \"specificity\": 1.0, \"npv\": 0.9997658051164192, \"accuracy\": 0.9997658059251799, \"f1\": 0.028646660916148363, \"f2\": 0.018098587105545454, \"f0_5\": 0.06866607177835332, \"p4\": 0.055697585118975226, \"phi\": 0.12053242842457104}, {\"truth_threshold\": 41.71999906748533, \"match_probability\": 0.9999999999997239, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4395.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299566.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014459091791381131, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9855409082086188, \"precision\": 1.0, \"recall\": 0.014459091791381131, \"specificity\": 1.0, \"npv\": 0.9997657879200116, \"accuracy\": 0.9997657887248033, \"f1\": 0.028506012530970695, \"f2\": 0.018008767134962904, \"f0_5\": 0.06834276188728654, \"p4\": 0.05543170315040707, \"phi\": 0.1202318813685369}, {\"truth_threshold\": 41.7399990670383, \"match_probability\": 0.9999999999997278, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4372.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014383424189287442, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9856165758107126, \"precision\": 1.0, \"recall\": 0.014383424189287442, \"specificity\": 1.0, \"npv\": 0.9997657699419498, \"accuracy\": 0.9997657707425912, \"f1\": 0.028358949577242786, \"f2\": 0.017914860975433856, \"f0_5\": 0.06800456682086427, \"p4\": 0.055153617280646036, \"phi\": 0.11991686770010558}, {\"truth_threshold\": 41.75999906659126, \"match_probability\": 0.9999999999997314, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4352.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014317626274423364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9856823737255767, \"precision\": 1.0, \"recall\": 0.014317626274423364, \"specificity\": 1.0, \"npv\": 0.9997657543088531, \"accuracy\": 0.9997657551058852, \"f1\": 0.028231050912546664, \"f2\": 0.017833200567777634, \"f0_5\": 0.06771032675833699, \"p4\": 0.05491170507526909, \"phi\": 0.11964226858498266}, {\"truth_threshold\": 41.77999906614423, \"match_probability\": 0.9999999999997352, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4333.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299628.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01425511825530249, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9857448817446975, \"precision\": 1.0, \"recall\": 0.01425511825530249, \"specificity\": 1.0, \"npv\": 0.9997657394574117, \"accuracy\": 0.9997657402510143, \"f1\": 0.02810953181054448, \"f2\": 0.017755620700931094, \"f0_5\": 0.06743066297740692, \"p4\": 0.054681803641401655, \"phi\": 0.119380814386422}, {\"truth_threshold\": 41.79999906569719, \"match_probability\": 0.9999999999997388, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4313.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299648.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014189320340438412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9858106796595616, \"precision\": 1.0, \"recall\": 0.014189320340438412, \"specificity\": 1.0, \"npv\": 0.9997657238243158, \"accuracy\": 0.9997657246143082, \"f1\": 0.02798160078371838, \"f2\": 0.017673955072994706, \"f0_5\": 0.06713613708037969, \"p4\": 0.05443971277822579, \"phi\": 0.11910497941200231}, {\"truth_threshold\": 41.81999906525016, \"match_probability\": 0.9999999999997424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4278.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.014074173989426276, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9859258260105738, \"precision\": 1.0, \"recall\": 0.014074173989426276, \"specificity\": 1.0, \"npv\": 0.9997656964663995, \"accuracy\": 0.9997656972500725, \"f1\": 0.027757681539325004, \"f2\": 0.017531033781867714, \"f0_5\": 0.06662036359332613, \"p4\": 0.05401583309241928, \"phi\": 0.11862072483646374}, {\"truth_threshold\": 41.83999906480312, \"match_probability\": 0.999999999999746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4264.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299697.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01402811544902142, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9859718845509786, \"precision\": 1.0, \"recall\": 0.01402811544902142, \"specificity\": 1.0, \"npv\": 0.9997656855232333, \"accuracy\": 0.9997656863043782, \"f1\": 0.027668099602563063, \"f2\": 0.017473862969507616, \"f0_5\": 0.06641392823433027, \"p4\": 0.05384620252606523, \"phi\": 0.11842646857223246}, {\"truth_threshold\": 41.85999906435609, \"match_probability\": 0.9999999999997494, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4250.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013982056908616565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9860179430913835, \"precision\": 1.0, \"recall\": 0.013982056908616565, \"specificity\": 1.0, \"npv\": 0.9997656745800674, \"accuracy\": 0.9997656753586839, \"f1\": 0.02757850952756391, \"f2\": 0.017416690845131606, \"f0_5\": 0.066207420839292, \"p4\": 0.053676526965998984, \"phi\": 0.11823189314757643}, {\"truth_threshold\": 41.879999063909054, \"match_probability\": 0.9999999999997529, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4239.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299722.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013945868055441324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9860541319445587, \"precision\": 1.0, \"recall\": 0.013945868055441324, \"specificity\": 1.0, \"npv\": 0.9997656659818658, \"accuracy\": 0.9997656667584955, \"f1\": 0.027508111615833875, \"f2\": 0.017371768969815987, \"f0_5\": 0.0660451144688502, \"p4\": 0.053543178878388886, \"phi\": 0.1180787875282581}, {\"truth_threshold\": 41.89999906346202, \"match_probability\": 0.9999999999997563, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4197.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299764.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013807692434226759, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9861923075657733, \"precision\": 1.0, \"recall\": 0.013807692434226759, \"specificity\": 1.0, \"npv\": 0.9997656331523701, \"accuracy\": 0.9997656339214127, \"f1\": 0.02723927335976999, \"f2\": 0.01720024163122387, \"f0_5\": 0.06542498963363877, \"p4\": 0.05303377587806101, \"phi\": 0.11749236727923183}, {\"truth_threshold\": 41.919999063014984, \"match_probability\": 0.9999999999997596, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4168.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299793.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013712285457673846, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9862877145423261, \"precision\": 1.0, \"recall\": 0.013712285457673846, \"specificity\": 1.0, \"npv\": 0.9997656104843862, \"accuracy\": 0.9997656112481889, \"f1\": 0.027053604172278495, \"f2\": 0.01708179919541775, \"f0_5\": 0.06499642893900504, \"p4\": 0.05268180848183825, \"phi\": 0.11708574397307071}, {\"truth_threshold\": 41.93999906256795, \"match_probability\": 0.999999999999763, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4157.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013676096604498603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9863239033955014, \"precision\": 1.0, \"recall\": 0.013676096604498603, \"specificity\": 1.0, \"npv\": 0.9997656018861857, \"accuracy\": 0.9997656026480005, \"f1\": 0.02698316878598459, \"f2\": 0.017036871281253047, \"f0_5\": 0.06483379030472038, \"p4\": 0.052548252974881395, \"phi\": 0.11693113765481872}, {\"truth_threshold\": 41.959999062120914, \"match_probability\": 0.9999999999997662, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4138.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299823.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01361358858537773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9863864114146222, \"precision\": 1.0, \"recall\": 0.01361358858537773, \"specificity\": 1.0, \"npv\": 0.9997655870347488, \"accuracy\": 0.9997655877931297, \"f1\": 0.026861495817902686, \"f2\": 0.016959266612130344, \"f0_5\": 0.06455276385045225, \"p4\": 0.0523175005612997, \"phi\": 0.1166636077948463}, {\"truth_threshold\": 41.97999906167388, \"match_probability\": 0.9999999999997694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4111.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013524761400311225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9864752385996888, \"precision\": 1.0, \"recall\": 0.013524761400311225, \"specificity\": 1.0, \"npv\": 0.999765565930076, \"accuracy\": 0.9997655666835764, \"f1\": 0.026688566309174478, \"f2\": 0.01684898213458693, \"f0_5\": 0.06415318113013217, \"p4\": 0.05198944615763253, \"phi\": 0.11628237499918635}, {\"truth_threshold\": 41.999999061226845, \"match_probability\": 0.9999999999997726, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4074.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299887.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01340303525781268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9865969647421873, \"precision\": 1.0, \"recall\": 0.01340303525781268, \"specificity\": 1.0, \"npv\": 0.9997655370088593, \"accuracy\": 0.9997655377556701, \"f1\": 0.02645153959777298, \"f2\": 0.01669784362555516, \"f0_5\": 0.06360516710017268, \"p4\": 0.05153961711318292, \"phi\": 0.1157579057433045}, {\"truth_threshold\": 42.01999906077981, \"match_probability\": 0.9999999999997757, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4047.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013314208072746175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9866857919272538, \"precision\": 1.0, \"recall\": 0.013314208072746175, \"specificity\": 1.0, \"npv\": 0.9997655159041887, \"accuracy\": 0.9997655166461169, \"f1\": 0.0262785382197865, \"f2\": 0.016587547575971952, \"f0_5\": 0.06320494519739246, \"p4\": 0.05121116409071269, \"phi\": 0.11537368028586413}, {\"truth_threshold\": 42.039999060332775, \"match_probability\": 0.9999999999997788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4032.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013264859636598117, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9867351403634019, \"precision\": 1.0, \"recall\": 0.013264859636598117, \"specificity\": 1.0, \"npv\": 0.999765504179372, \"accuracy\": 0.9997655049185873, \"f1\": 0.02618241323666447, \"f2\": 0.016526269883168455, \"f0_5\": 0.06298248299691649, \"p4\": 0.05102861743856849, \"phi\": 0.11515966777675297}, {\"truth_threshold\": 42.05999905988574, \"match_probability\": 0.9999999999997818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4006.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013179322347274815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9868206776527252, \"precision\": 1.0, \"recall\": 0.013179322347274815, \"specificity\": 1.0, \"npv\": 0.9997654838563572, \"accuracy\": 0.9997654845908693, \"f1\": 0.026015774417388875, \"f2\": 0.016420051645694142, \"f0_5\": 0.06259668421957279, \"p4\": 0.05071208006311119, \"phi\": 0.1147877675687706}, {\"truth_threshold\": 42.079999059438705, \"match_probability\": 0.9999999999997848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3992.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299969.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01313326380686996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.98686673619313, \"precision\": 1.0, \"recall\": 0.01313326380686996, \"specificity\": 1.0, \"npv\": 0.9997654729131957, \"accuracy\": 0.9997654736451751, \"f1\": 0.025926034167551543, \"f2\": 0.01636285533465154, \"f0_5\": 0.062388842524435106, \"p4\": 0.050541572118036664, \"phi\": 0.11458701366546342}, {\"truth_threshold\": 42.09999905899167, \"match_probability\": 0.9999999999997878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3984.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01310694464092433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9868930553590757, \"precision\": 1.0, \"recall\": 0.01310694464092433, \"specificity\": 1.0, \"npv\": 0.9997654666599607, \"accuracy\": 0.9997654673904927, \"f1\": 0.02587475036126581, \"f2\": 0.016330171138881876, \"f0_5\": 0.06227004317014539, \"p4\": 0.0504441186495194, \"phi\": 0.11447213907942833}, {\"truth_threshold\": 42.119999058544636, \"match_probability\": 0.9999999999997907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3964.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 299997.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.013041146726060252, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9869588532739397, \"precision\": 1.0, \"recall\": 0.013041146726060252, \"specificity\": 1.0, \"npv\": 0.9997654510268734, \"accuracy\": 0.9997654517537865, \"f1\": 0.0257465291873021, \"f2\": 0.01624845877383982, \"f0_5\": 0.06197294077550599, \"p4\": 0.050200420179965184, \"phi\": 0.11418444700784455}, {\"truth_threshold\": 42.1399990580976, \"match_probability\": 0.9999999999997936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3943.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300018.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012972058915452968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9870279410845471, \"precision\": 1.0, \"recall\": 0.012972058915452968, \"specificity\": 1.0, \"npv\": 0.9997654346121324, \"accuracy\": 0.9997654353352451, \"f1\": 0.025611879027229265, \"f2\": 0.01616265790666731, \"f0_5\": 0.06166082324939872, \"p4\": 0.04994443711322572, \"phi\": 0.1138815881493669}, {\"truth_threshold\": 42.159999057650566, \"match_probability\": 0.9999999999997965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3922.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300039.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012902971104845687, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9870970288951543, \"precision\": 1.0, \"recall\": 0.012902971104845687, \"specificity\": 1.0, \"npv\": 0.9997654181973918, \"accuracy\": 0.9997654189167037, \"f1\": 0.02547721049879337, \"f2\": 0.016076854085127802, \"f0_5\": 0.06134854168165707, \"p4\": 0.04968835188155497, \"phi\": 0.11357792172171892}, {\"truth_threshold\": 42.17999905720353, \"match_probability\": 0.9999999999997993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3886.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300075.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012784534858090347, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9872154651419096, \"precision\": 1.0, \"recall\": 0.012784534858090347, \"specificity\": 1.0, \"npv\": 0.9997653900578379, \"accuracy\": 0.9997653907706326, \"f1\": 0.025246307418945124, \"f2\": 0.015929754945766685, \"f0_5\": 0.060812819830675574, \"p4\": 0.04924911076118085, \"phi\": 0.1130554531153041}, {\"truth_threshold\": 42.199999056756496, \"match_probability\": 0.999999999999802, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3866.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300095.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01271873694322627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9872812630567738, \"precision\": 1.0, \"recall\": 0.01271873694322627, \"specificity\": 1.0, \"npv\": 0.9997653744247531, \"accuracy\": 0.9997653751339265, \"f1\": 0.0251180045934892, \"f2\": 0.015848029449623272, \"f0_5\": 0.0605149878688268, \"p4\": 0.04900495799203916, \"phi\": 0.11276414679433595}, {\"truth_threshold\": 42.21999905630946, \"match_probability\": 0.9999999999998048, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3842.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300119.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012639779445389375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9873602205546106, \"precision\": 1.0, \"recall\": 0.012639779445389375, \"specificity\": 1.0, \"npv\": 0.9997653556650519, \"accuracy\": 0.9997653563698792, \"f1\": 0.024964019194094925, \"f2\": 0.01574995531636831, \"f0_5\": 0.06015739253246651, \"p4\": 0.04871185207563734, \"phi\": 0.11241358277693812}, {\"truth_threshold\": 42.23999905586243, \"match_probability\": 0.9999999999998075, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3827.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300134.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012590431009241317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9874095689907587, \"precision\": 1.0, \"recall\": 0.012590431009241317, \"specificity\": 1.0, \"npv\": 0.9997653439402391, \"accuracy\": 0.9997653446423496, \"f1\": 0.024867766124735208, \"f2\": 0.015688657023082454, \"f0_5\": 0.05993378624294873, \"p4\": 0.048528592925799606, \"phi\": 0.11219392402581344}, {\"truth_threshold\": 42.25999905541539, \"match_probability\": 0.9999999999998102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3814.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012547662364579666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9874523376354203, \"precision\": 1.0, \"recall\": 0.012547662364579666, \"specificity\": 1.0, \"npv\": 0.9997653337787348, \"accuracy\": 0.9997653344784906, \"f1\": 0.024784339208837623, \"f2\": 0.015635530615959556, \"f0_5\": 0.059739926131753635, \"p4\": 0.048369726027060564, \"phi\": 0.11200320465087979}, {\"truth_threshold\": 42.27999905496836, \"match_probability\": 0.9999999999998127, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3801.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300160.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012504893719918015, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.987495106280082, \"precision\": 1.0, \"recall\": 0.012504893719918015, \"specificity\": 1.0, \"npv\": 0.9997653236172307, \"accuracy\": 0.9997653243146316, \"f1\": 0.024700905244962015, \"f2\": 0.01558240307630499, \"f0_5\": 0.05954600285118982, \"p4\": 0.04821081983237315, \"phi\": 0.11181215996792526}, {\"truth_threshold\": 42.29999905452132, \"match_probability\": 0.9999999999998154, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3773.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300188.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012412776639108307, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9875872233608917, \"precision\": 1.0, \"recall\": 0.012412776639108307, \"specificity\": 1.0, \"npv\": 0.9997653017309149, \"accuracy\": 0.9997653024232431, \"f1\": 0.024521177380464946, \"f2\": 0.015467970682599537, \"f0_5\": 0.05912810724237039, \"p4\": 0.04786842680082508, \"phi\": 0.11139956634528057}, {\"truth_threshold\": 42.31999905407429, \"match_probability\": 0.9999999999998178, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3750.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300211.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012337109037014618, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9876628909629854, \"precision\": 1.0, \"recall\": 0.012337109037014618, \"specificity\": 1.0, \"npv\": 0.9997652837528707, \"accuracy\": 0.9997652844410311, \"f1\": 0.024373519308701998, \"f2\": 0.015373968714178654, \"f0_5\": 0.05878461630105248, \"p4\": 0.047587038855638294, \"phi\": 0.11105950349736407}, {\"truth_threshold\": 42.33999905362725, \"match_probability\": 0.9999999999998204, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3719.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300242.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012235122268975296, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9877648777310247, \"precision\": 1.0, \"recall\": 0.012235122268975296, \"specificity\": 1.0, \"npv\": 0.9997652595215945, \"accuracy\": 0.9997652602041366, \"f1\": 0.024174466978679147, \"f2\": 0.015247264798948475, \"f0_5\": 0.05832133660773373, \"p4\": 0.04720758185223373, \"phi\": 0.11059950357266768}, {\"truth_threshold\": 42.35999905318022, \"match_probability\": 0.9999999999998228, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3701.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300260.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012175904145597626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9878240958544023, \"precision\": 1.0, \"recall\": 0.012175904145597626, \"specificity\": 1.0, \"npv\": 0.9997652454518218, \"accuracy\": 0.9997652461311011, \"f1\": 0.02405886979867517, \"f2\": 0.015173691827689835, \"f0_5\": 0.058052170093956364, \"p4\": 0.04698714917200935, \"phi\": 0.11033152675786402}, {\"truth_threshold\": 42.37999905273318, \"match_probability\": 0.9999999999998253, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3681.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300280.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.012110106230733548, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9878898937692665, \"precision\": 1.0, \"recall\": 0.012110106230733548, \"specificity\": 1.0, \"npv\": 0.9997652298187415, \"accuracy\": 0.9997652304943949, \"f1\": 0.023930412622463773, \"f2\": 0.015091941534613887, \"f0_5\": 0.05775295354346769, \"p4\": 0.04674213532676896, \"phi\": 0.11003300931492649}, {\"truth_threshold\": 42.39999905228615, \"match_probability\": 0.9999999999998277, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3637.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300324.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011965350818032577, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9880346491819674, \"precision\": 1.0, \"recall\": 0.011965350818032577, \"specificity\": 1.0, \"npv\": 0.9997651954259665, \"accuracy\": 0.9997651960936416, \"f1\": 0.023647748034772657, \"f2\": 0.014912081451043517, \"f0_5\": 0.057094148046052076, \"p4\": 0.04620277615758398, \"phi\": 0.10937340306916754}, {\"truth_threshold\": 42.41999905183911, \"match_probability\": 0.99999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3594.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300367.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011823885301074808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9881761146989252, \"precision\": 1.0, \"recall\": 0.011823885301074808, \"specificity\": 1.0, \"npv\": 0.9997651618148478, \"accuracy\": 0.9997651624747234, \"f1\": 0.02337142950041456, \"f2\": 0.014736296556282485, \"f0_5\": 0.05644961157515463, \"p4\": 0.04567523802168284, \"phi\": 0.10872492171213212}, {\"truth_threshold\": 42.43999905139208, \"match_probability\": 0.9999999999998324, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3562.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011718608637292285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9882813913627078, \"precision\": 1.0, \"recall\": 0.011718608637292285, \"specificity\": 1.0, \"npv\": 0.9997651368019237, \"accuracy\": 0.9997651374559936, \"f1\": 0.02316574695226048, \"f2\": 0.014605471844488217, \"f0_5\": 0.055969504319488134, \"p4\": 0.04528237074770206, \"phi\": 0.10823980953138602}, {\"truth_threshold\": 42.459999050945044, \"match_probability\": 0.9999999999998347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3534.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300427.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011626491556482575, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9883735084435175, \"precision\": 1.0, \"recall\": 0.011626491556482575, \"specificity\": 1.0, \"npv\": 0.9997651149156161, \"accuracy\": 0.999765115564605, \"f1\": 0.02298573960552204, \"f2\": 0.014490994589044579, \"f0_5\": 0.05554909351549999, \"p4\": 0.04493841516192851, \"phi\": 0.10781354584203341}, {\"truth_threshold\": 42.47999905049801, \"match_probability\": 0.999999999999837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3522.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011587012807564129, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9884129871924359, \"precision\": 1.0, \"recall\": 0.011587012807564129, \"specificity\": 1.0, \"npv\": 0.9997651055357704, \"accuracy\": 0.9997651061825814, \"f1\": 0.022908583563969392, \"f2\": 0.01444193129872409, \"f0_5\": 0.05536882681599376, \"p4\": 0.0447909493805537, \"phi\": 0.10763034461711378}, {\"truth_threshold\": 42.499999050050974, \"match_probability\": 0.9999999999998392, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3500.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300461.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011514635101213642, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9884853648987864, \"precision\": 1.0, \"recall\": 0.011514635101213642, \"specificity\": 1.0, \"npv\": 0.9997650883393868, \"accuracy\": 0.9997650889822046, \"f1\": 0.02276711517883569, \"f2\": 0.014351979425002296, \"f0_5\": 0.05503819650837681, \"p4\": 0.04452050774832735, \"phi\": 0.10729366327589276}, {\"truth_threshold\": 42.51999904960394, \"match_probability\": 0.9999999999998415, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3491.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300470.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011485026039524808, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9885149739604752, \"precision\": 1.0, \"recall\": 0.011485026039524808, \"specificity\": 1.0, \"npv\": 0.9997650813045028, \"accuracy\": 0.9997650819456869, \"f1\": 0.022709235913248246, \"f2\": 0.014315179995653368, \"f0_5\": 0.05490288590076276, \"p4\": 0.0444098398102009, \"phi\": 0.10715562510755025}, {\"truth_threshold\": 42.539999049156904, \"match_probability\": 0.9999999999998436, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3452.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300509.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011356720105539855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9886432798944601, \"precision\": 1.0, \"recall\": 0.011356720105539855, \"specificity\": 1.0, \"npv\": 0.9997650508200067, \"accuracy\": 0.99976505145411, \"f1\": 0.022458386600436545, \"f2\": 0.014155709524184448, \"f0_5\": 0.054316185656876535, \"p4\": 0.04393005902445993, \"phi\": 0.10655539335699366}, {\"truth_threshold\": 42.55999904870987, \"match_probability\": 0.9999999999998458, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3433.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300528.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011294212086418981, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.988705787913581, \"precision\": 1.0, \"recall\": 0.011294212086418981, \"specificity\": 1.0, \"npv\": 0.9997650359685861, \"accuracy\": 0.9997650365992391, \"f1\": 0.022336154902177663, \"f2\": 0.014078015085989484, \"f0_5\": 0.054030148602581735, \"p4\": 0.04369619024053967, \"phi\": 0.10626174454061778}, {\"truth_threshold\": 42.579999048262835, \"match_probability\": 0.9999999999998479, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3424.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300537.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011264603024730147, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9887353969752699, \"precision\": 1.0, \"recall\": 0.011264603024730147, \"specificity\": 1.0, \"npv\": 0.9997650289337029, \"accuracy\": 0.9997650295627214, \"f1\": 0.022278250402589586, \"f2\": 0.01404121161221323, \"f0_5\": 0.05389460959462565, \"p4\": 0.04358538067464515, \"phi\": 0.10612236413191148}, {\"truth_threshold\": 42.5999990478158, \"match_probability\": 0.99999999999985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3409.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011215254588582088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9887847454114179, \"precision\": 1.0, \"recall\": 0.011215254588582088, \"specificity\": 1.0, \"npv\": 0.9997650172088977, \"accuracy\": 0.9997650178351918, \"f1\": 0.02218173536779777, \"f2\": 0.013979871281842244, \"f0_5\": 0.05366864296577109, \"p4\": 0.043400655739424684, \"phi\": 0.1058896557589831}, {\"truth_threshold\": 42.619999047368765, \"match_probability\": 0.999999999999852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3382.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300579.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011126427403515583, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9888735725964845, \"precision\": 1.0, \"recall\": 0.011126427403515583, \"specificity\": 1.0, \"npv\": 0.999764996104249, \"accuracy\": 0.9997649967256386, \"f1\": 0.02200798456447682, \"f2\": 0.0138694548836721, \"f0_5\": 0.05326168780650668, \"p4\": 0.04306801746608101, \"phi\": 0.10546948681836832}, {\"truth_threshold\": 42.63999904692173, \"match_probability\": 0.9999999999998541, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3355.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300606.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.011037600218449078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9889623997815509, \"precision\": 1.0, \"recall\": 0.011037600218449078, \"specificity\": 1.0, \"npv\": 0.9997649749996013, \"accuracy\": 0.9997649756160853, \"f1\": 0.021834203230550964, \"f2\": 0.01375903359500787, \"f0_5\": 0.05285445568575309, \"p4\": 0.04273520757831508, \"phi\": 0.10504763731971002}, {\"truth_threshold\": 42.659999046474695, \"match_probability\": 0.9999999999998561, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3339.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010984961886557815, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9890150381134422, \"precision\": 1.0, \"recall\": 0.010984961886557815, \"specificity\": 1.0, \"npv\": 0.9997649624931437, \"accuracy\": 0.9997649631067204, \"f1\": 0.021731207289293848, \"f2\": 0.013693596449425558, \"f0_5\": 0.05261300213981602, \"p4\": 0.04253790586862347, \"phi\": 0.10479685113830038}, {\"truth_threshold\": 42.67999904602766, \"match_probability\": 0.9999999999998581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3314.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300647.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010902714492977717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9890972855070223, \"precision\": 1.0, \"recall\": 0.010902714492977717, \"specificity\": 1.0, \"npv\": 0.9997649429518044, \"accuracy\": 0.9997649435608378, \"f1\": 0.021570254657879748, \"f2\": 0.013591347470959466, \"f0_5\": 0.052235535926510875, \"p4\": 0.042229501140061625, \"phi\": 0.10440379175629436}, {\"truth_threshold\": 42.699999045580626, \"match_probability\": 0.99999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3303.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010866525639802475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891334743601975, \"precision\": 1.0, \"recall\": 0.010866525639802475, \"specificity\": 1.0, \"npv\": 0.9997649343536154, \"accuracy\": 0.9997649349606494, \"f1\": 0.02149942720266611, \"f2\": 0.013546356591945023, \"f0_5\": 0.05206937538819509, \"p4\": 0.042093756363476315, \"phi\": 0.10423037605673789}, {\"truth_threshold\": 42.71999904513359, \"match_probability\": 0.999999999999862, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3292.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300669.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010830336786627232, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9891696632133727, \"precision\": 1.0, \"recall\": 0.010830336786627232, \"specificity\": 1.0, \"npv\": 0.9997649257554265, \"accuracy\": 0.999764926360461, \"f1\": 0.02142859467604873, \"f2\": 0.013501364901044675, \"f0_5\": 0.05190316874205765, \"p4\": 0.04195798303761339, \"phi\": 0.1040566713545491}, {\"truth_threshold\": 42.739999044686556, \"match_probability\": 0.9999999999998639, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3281.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300680.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010794147933451988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989205852066548, \"precision\": 1.0, \"recall\": 0.010794147933451988, \"specificity\": 1.0, \"npv\": 0.9997649171572378, \"accuracy\": 0.9997649177602727, \"f1\": 0.021357757077482897, \"f2\": 0.01345637239823644, \"f0_5\": 0.051736915968904236, \"p4\": 0.04182218115346511, \"phi\": 0.10388267619998338}, {\"truth_threshold\": 42.75999904423952, \"match_probability\": 0.9999999999998658, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3273.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010767828767506357, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9892321712324936, \"precision\": 1.0, \"recall\": 0.010767828767506357, \"specificity\": 1.0, \"npv\": 0.9997649109040097, \"accuracy\": 0.9997649115055902, \"f1\": 0.021306235637982774, \"f2\": 0.013423650068041049, \"f0_5\": 0.05161597587785008, \"p4\": 0.041723398204230946, \"phi\": 0.10375595100222264}, {\"truth_threshold\": 42.779999043792486, \"match_probability\": 0.9999999999998676, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3236.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010646102625007814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9893538973749922, \"precision\": 1.0, \"recall\": 0.010646102625007814, \"specificity\": 1.0, \"npv\": 0.9997648819828309, \"accuracy\": 0.9997648825776839, \"f1\": 0.02106791407468172, \"f2\": 0.013272303704432852, \"f0_5\": 0.05105631025070605, \"p4\": 0.041266330416658455, \"phi\": 0.10316782218535023}, {\"truth_threshold\": 42.79999904334545, \"match_probability\": 0.9999999999998694, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3214.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300747.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010573724918657327, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9894262750813426, \"precision\": 1.0, \"recall\": 0.010573724918657327, \"specificity\": 1.0, \"npv\": 0.999764864786455, \"accuracy\": 0.9997648653773072, \"f1\": 0.020926182143729145, \"f2\": 0.013182309619394648, \"f0_5\": 0.05072328820738786, \"p4\": 0.04099440698026753, \"phi\": 0.1028165291360811}, {\"truth_threshold\": 42.81999904289842, \"match_probability\": 0.9999999999998712, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3187.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300774.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010484897733590822, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9895151022664092, \"precision\": 1.0, \"recall\": 0.010484897733590822, \"specificity\": 1.0, \"npv\": 0.9997648436818128, \"accuracy\": 0.9997648442677539, \"f1\": 0.020752210660658705, \"f2\": 0.01307185789368769, \"f0_5\": 0.050314326400575926, \"p4\": 0.040660526279106705, \"phi\": 0.10238374941192192}, {\"truth_threshold\": 42.83999904245138, \"match_probability\": 0.999999999999873, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3172.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300789.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010435549297442764, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9895644507025573, \"precision\": 1.0, \"recall\": 0.010435549297442764, \"specificity\": 1.0, \"npv\": 0.9997648319570119, \"accuracy\": 0.9997648325402243, \"f1\": 0.020655546619868265, \"f2\": 0.013010493709680595, \"f0_5\": 0.05008700485395501, \"p4\": 0.04047496243895747, \"phi\": 0.1021425239052618}, {\"truth_threshold\": 42.85999904200435, \"match_probability\": 0.9999999999998748, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3162.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300799.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010402650340010726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9895973496599892, \"precision\": 1.0, \"recall\": 0.010402650340010726, \"specificity\": 1.0, \"npv\": 0.9997648241404782, \"accuracy\": 0.9997648247218713, \"f1\": 0.02059109868033329, \"f2\": 0.012969583414683766, \"f0_5\": 0.0499354092903234, \"p4\": 0.040351223609477384, \"phi\": 0.1019813899090207}, {\"truth_threshold\": 42.87999904155731, \"match_probability\": 0.9999999999998764, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3144.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300817.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010343432216633055, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989656567783367, \"precision\": 1.0, \"recall\": 0.010343432216633055, \"specificity\": 1.0, \"npv\": 0.9997648100707177, \"accuracy\": 0.9997648106488358, \"f1\": 0.020475081812409437, \"f2\": 0.012895943192221745, \"f0_5\": 0.04966244072572874, \"p4\": 0.04012843401277409, \"phi\": 0.10169070530555625}, {\"truth_threshold\": 42.89999904111028, \"match_probability\": 0.9999999999998782, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3130.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0102973736762282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9897026263237718, \"precision\": 1.0, \"recall\": 0.0102973736762282, \"specificity\": 1.0, \"npv\": 0.999764799127571, \"accuracy\": 0.9997647997031415, \"f1\": 0.020384837067839827, \"f2\": 0.012838665960061495, \"f0_5\": 0.04945004597432389, \"p4\": 0.03995510012409489, \"phi\": 0.1014640415366736}, {\"truth_threshold\": 42.91999904066324, \"match_probability\": 0.9999999999998799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3109.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300852.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010228285865620919, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.989771714134379, \"precision\": 1.0, \"recall\": 0.010228285865620919, \"specificity\": 1.0, \"npv\": 0.9997647827128513, \"accuracy\": 0.9997647832846001, \"f1\": 0.02024945452177028, \"f2\": 0.012752747644905095, \"f0_5\": 0.04913131287591222, \"p4\": 0.039695012144044056, \"phi\": 0.10112309328717861}, {\"truth_threshold\": 42.93999904021621, \"match_probability\": 0.9999999999998815, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3106.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010218416178391306, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9897815838216087, \"precision\": 1.0, \"recall\": 0.010218416178391306, \"specificity\": 1.0, \"npv\": 0.9997647803678914, \"accuracy\": 0.9997647809390942, \"f1\": 0.0202301126464257, \"f2\": 0.012740473358218138, \"f0_5\": 0.0490857657600708, \"p4\": 0.03965784817836357, \"phi\": 0.10107429250950556}, {\"truth_threshold\": 42.95999903976917, \"match_probability\": 0.9999999999998831, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3082.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010139458680554414, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9898605413194456, \"precision\": 1.0, \"recall\": 0.010139458680554414, \"specificity\": 1.0, \"npv\": 0.9997647616082126, \"accuracy\": 0.9997647621750468, \"f1\": 0.020075364036958993, \"f2\": 0.012642276889655319, \"f0_5\": 0.04872126441324232, \"p4\": 0.039360459557948695, \"phi\": 0.10068303477051535}, {\"truth_threshold\": 42.97999903932214, \"match_probability\": 0.9999999999998848, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3063.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300898.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.01007695066143354, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9899230493385665, \"precision\": 1.0, \"recall\": 0.01007695066143354, \"specificity\": 1.0, \"npv\": 0.9997647467568006, \"accuracy\": 0.9997647473201761, \"f1\": 0.019952837563187244, \"f2\": 0.012564535276276205, \"f0_5\": 0.04843254388655748, \"p4\": 0.03912492990802258, \"phi\": 0.10037220743865743}, {\"truth_threshold\": 42.9999990388751, \"match_probability\": 0.9999999999998863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3054.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.010047341599744705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9899526584002553, \"precision\": 1.0, \"recall\": 0.010047341599744705, \"specificity\": 1.0, \"npv\": 0.9997647397219214, \"accuracy\": 0.9997647402836582, \"f1\": 0.019894793414002573, \"f2\": 0.012527709455590213, \"f0_5\": 0.04829573308621437, \"p4\": 0.03901333330005631, \"phi\": 0.10022463698794822}, {\"truth_threshold\": 43.01999903842807, \"match_probability\": 0.9999999999998879, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3038.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300923.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009994703267853441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9900052967321465, \"precision\": 1.0, \"recall\": 0.009994703267853441, \"specificity\": 1.0, \"npv\": 0.9997647272154698, \"accuracy\": 0.9997647277742934, \"f1\": 0.019791595412362906, \"f2\": 0.012462239987135752, \"f0_5\": 0.0480524369450165, \"p4\": 0.03881489179969294, \"phi\": 0.09996175161623098}, {\"truth_threshold\": 43.03999903798103, \"match_probability\": 0.9999999999998894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3019.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009932195248732567, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9900678047512674, \"precision\": 1.0, \"recall\": 0.009932195248732567, \"specificity\": 1.0, \"npv\": 0.9997647123640588, \"accuracy\": 0.9997647129194226, \"f1\": 0.01966903381327774, \"f2\": 0.012384492760876324, \"f0_5\": 0.047763394792381904, \"p4\": 0.03857916346498711, \"phi\": 0.09964867448186548}, {\"truth_threshold\": 43.059999037534, \"match_probability\": 0.999999999999891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3003.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009879556916841305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9901204430831587, \"precision\": 1.0, \"recall\": 0.009879556916841305, \"specificity\": 1.0, \"npv\": 0.999764699857608, \"accuracy\": 0.9997647004100577, \"f1\": 0.019565812277661226, \"f2\": 0.01231901953239414, \"f0_5\": 0.04751988302798024, \"p4\": 0.038380588790140495, \"phi\": 0.09938426563441521}, {\"truth_threshold\": 43.079999037086964, \"match_probability\": 0.9999999999998924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2999.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300962.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009866397333868489, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9901336026661315, \"precision\": 1.0, \"recall\": 0.009866397333868489, \"specificity\": 1.0, \"npv\": 0.9997646967309952, \"accuracy\": 0.9997646972827164, \"f1\": 0.019540005212405526, \"f2\": 0.012302650956685972, \"f0_5\": 0.04745898967264533, \"p4\": 0.038330935603083434, \"phi\": 0.09931805343603212}, {\"truth_threshold\": 43.09999903663993, \"match_probability\": 0.999999999999894, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2987.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300974.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009826918584950044, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.99017308141505, \"precision\": 1.0, \"recall\": 0.009826918584950044, \"specificity\": 1.0, \"npv\": 0.9997646873511573, \"accuracy\": 0.9997646879006928, \"f1\": 0.019462579980973976, \"f2\": 0.012253544584934252, \"f0_5\": 0.04727627259748852, \"p4\": 0.038181953190874356, \"phi\": 0.09911915146281196}, {\"truth_threshold\": 43.119999036192894, \"match_probability\": 0.9999999999998954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2962.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 300999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009744671191369946, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9902553288086301, \"precision\": 1.0, \"recall\": 0.009744671191369946, \"specificity\": 1.0, \"npv\": 0.9997646678098288, \"accuracy\": 0.9997646683548101, \"f1\": 0.019301257970240092, \"f2\": 0.012151236538054456, \"f0_5\": 0.04689543363235373, \"p4\": 0.037871463032515366, \"phi\": 0.09870348502740915}, {\"truth_threshold\": 43.13999903574586, \"match_probability\": 0.9999999999998969, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2947.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301014.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009695322755221888, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9903046772447781, \"precision\": 1.0, \"recall\": 0.009695322755221888, \"specificity\": 1.0, \"npv\": 0.9997646560850321, \"accuracy\": 0.9997646566272805, \"f1\": 0.019204452148526594, \"f2\": 0.012089849695312814, \"f0_5\": 0.04666681446338706, \"p4\": 0.03768509746429717, \"phi\": 0.09845324281103084}, {\"truth_threshold\": 43.159999035298824, \"match_probability\": 0.9999999999998982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2925.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301036.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0096229450488714, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9903770549511286, \"precision\": 1.0, \"recall\": 0.0096229450488714, \"specificity\": 1.0, \"npv\": 0.999764638888664, \"accuracy\": 0.9997646394269039, \"f1\": 0.019062453158501854, \"f2\": 0.011999812925993359, \"f0_5\": 0.04633134913720732, \"p4\": 0.03741166427458923, \"phi\": 0.09808506604896779}, {\"truth_threshold\": 43.17999903485179, \"match_probability\": 0.9999999999998996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2916.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301045.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009593335987182566, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9904066640128174, \"precision\": 1.0, \"recall\": 0.009593335987182566, \"specificity\": 1.0, \"npv\": 0.9997646318537863, \"accuracy\": 0.999764632390386, \"f1\": 0.019004356794416005, \"f2\": 0.011962978765302439, \"f0_5\": 0.046194059405940596, \"p4\": 0.03729977197295106, \"phi\": 0.09793404934687046}, {\"truth_threshold\": 43.199999034404755, \"match_probability\": 0.9999999999999011, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2875.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301086.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009458450261711207, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905415497382888, \"precision\": 1.0, \"recall\": 0.009458450261711207, \"specificity\": 1.0, \"npv\": 0.9997645998060115, \"accuracy\": 0.9997646003351386, \"f1\": 0.018739652452776076, \"f2\": 0.011795171815652336, \"f0_5\": 0.04556823188920342, \"p4\": 0.03678979575445792, \"phi\": 0.09724311667508796}, {\"truth_threshold\": 43.21999903395772, \"match_probability\": 0.9999999999999024, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2862.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301099.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009415681617049556, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9905843183829505, \"precision\": 1.0, \"recall\": 0.009415681617049556, \"specificity\": 1.0, \"npv\": 0.9997645896445224, \"accuracy\": 0.9997645901712796, \"f1\": 0.018655707036304318, \"f2\": 0.011741962376487848, \"f0_5\": 0.04536966288216253, \"p4\": 0.03662801215903448, \"phi\": 0.09702301308500484}, {\"truth_threshold\": 43.239999033510685, \"match_probability\": 0.9999999999999037, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2846.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301115.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009363043285158293, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906369567148418, \"precision\": 1.0, \"recall\": 0.009363043285158293, \"specificity\": 1.0, \"npv\": 0.9997645771380745, \"accuracy\": 0.9997645776619147, \"f1\": 0.01855237983487991, \"f2\": 0.011676472277609564, \"f0_5\": 0.04512518035802058, \"p4\": 0.03642883844889172, \"phi\": 0.09675142898537348}, {\"truth_threshold\": 43.25999903306365, \"match_probability\": 0.9999999999999051, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2833.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301128.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009320274640496643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9906797253595033, \"precision\": 1.0, \"recall\": 0.009320274640496643, \"specificity\": 1.0, \"npv\": 0.9997645669765858, \"accuracy\": 0.9997645674980558, \"f1\": 0.01846841854795074, \"f2\": 0.011623260306053203, \"f0_5\": 0.04492646522441031, \"p4\": 0.03626696474716721, \"phi\": 0.09653020428891146}, {\"truth_threshold\": 43.279999032616615, \"match_probability\": 0.9999999999999064, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2824.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301137.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009290665578807807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9907093344211922, \"precision\": 1.0, \"recall\": 0.009290665578807807, \"specificity\": 1.0, \"npv\": 0.9997645599417092, \"accuracy\": 0.9997645604615379, \"f1\": 0.018410287334778428, \"f2\": 0.01158642058378492, \"f0_5\": 0.04478885480734766, \"p4\": 0.03615487466300746, \"phi\": 0.09637675126275201}, {\"truth_threshold\": 43.29999903216958, \"match_probability\": 0.9999999999999076, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2816.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301145.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009264346412862176, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9907356535871378, \"precision\": 1.0, \"recall\": 0.009264346412862176, \"specificity\": 1.0, \"npv\": 0.9997645536884856, \"accuracy\": 0.9997645542068555, \"f1\": 0.01835861228188554, \"f2\": 0.011553673707186582, \"f0_5\": 0.044666508049805695, \"p4\": 0.03605522276615392, \"phi\": 0.09624014316630393}, {\"truth_threshold\": 43.319999031722546, \"match_probability\": 0.999999999999909, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2790.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301171.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009178809123538875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908211908764611, \"precision\": 1.0, \"recall\": 0.009178809123538875, \"specificity\": 1.0, \"npv\": 0.9997645333655094, \"accuracy\": 0.9997645338791376, \"f1\": 0.018190649745233104, \"f2\": 0.011447243388909222, \"f0_5\": 0.0442687094798506, \"p4\": 0.0357312483255251, \"phi\": 0.09579482146883475}, {\"truth_threshold\": 43.33999903127551, \"match_probability\": 0.9999999999999102, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2780.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009145910166106837, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9908540898338931, \"precision\": 1.0, \"recall\": 0.009145910166106837, \"specificity\": 1.0, \"npv\": 0.9997645255489803, \"accuracy\": 0.9997645260607845, \"f1\": 0.01812604118784251, \"f2\": 0.011406307441836037, \"f0_5\": 0.04411564010524278, \"p4\": 0.035606599677088284, \"phi\": 0.09562299168051266}, {\"truth_threshold\": 43.359999030828476, \"match_probability\": 0.9999999999999114, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2771.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009116301104418, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.990883698895582, \"precision\": 1.0, \"recall\": 0.009116301104418, \"specificity\": 1.0, \"npv\": 0.9997645185141042, \"accuracy\": 0.9997645190242668, \"f1\": 0.018067889884328992, \"f2\": 0.011369464515043717, \"f0_5\": 0.043977844434921996, \"p4\": 0.0354943954148292, \"phi\": 0.09546808044727861}, {\"truth_threshold\": 43.37999903038144, \"match_probability\": 0.9999999999999126, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2747.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301214.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009037343606581108, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9909626563934189, \"precision\": 1.0, \"recall\": 0.009037343606581108, \"specificity\": 1.0, \"npv\": 0.9997644997544352, \"accuracy\": 0.9997645002602195, \"f1\": 0.017912803056979277, \"f2\": 0.011271214049668838, \"f0_5\": 0.04361023530793875, \"p4\": 0.035195089161051976, \"phi\": 0.09505374958381443}, {\"truth_threshold\": 43.399999029934406, \"match_probability\": 0.9999999999999138, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2742.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301219.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.009020894127865088, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9909791058721349, \"precision\": 1.0, \"recall\": 0.009020894127865088, \"specificity\": 1.0, \"npv\": 0.9997644958461709, \"accuracy\": 0.9997644963510429, \"f1\": 0.017880490246264303, \"f2\": 0.011250744715596601, \"f0_5\": 0.04353362186397569, \"p4\": 0.0351327163130442, \"phi\": 0.09496720312732561}, {\"truth_threshold\": 43.41999902948737, \"match_probability\": 0.9999999999999151, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2732.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301229.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008987995170433048, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991012004829567, \"precision\": 1.0, \"recall\": 0.008987995170433048, \"specificity\": 1.0, \"npv\": 0.9997644880296424, \"accuracy\": 0.9997644885326898, \"f1\": 0.017815861464069934, \"f2\": 0.01120980554351965, \"f0_5\": 0.043380365779687444, \"p4\": 0.03500795263256124, \"phi\": 0.09479387316689247}, {\"truth_threshold\": 43.43999902904034, \"match_probability\": 0.9999999999999162, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2720.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301241.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008948516421514603, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9910514835784854, \"precision\": 1.0, \"recall\": 0.008948516421514603, \"specificity\": 1.0, \"npv\": 0.9997644786498083, \"accuracy\": 0.9997644791506661, \"f1\": 0.01773830136200156, \"f2\": 0.011160677650086496, \"f0_5\": 0.04319640707531738, \"p4\": 0.03485820455510385, \"phi\": 0.09458545794594851}, {\"truth_threshold\": 43.4599990285933, \"match_probability\": 0.9999999999999174, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2714.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301247.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00892877704705538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9910712229529446, \"precision\": 1.0, \"recall\": 0.00892877704705538, \"specificity\": 1.0, \"npv\": 0.9997644739598914, \"accuracy\": 0.9997644744596543, \"f1\": 0.017699519034808837, \"f2\": 0.011136113340522159, \"f0_5\": 0.04310440668705947, \"p4\": 0.03478331756071153, \"phi\": 0.09448107793391475}, {\"truth_threshold\": 43.47999902814627, \"match_probability\": 0.9999999999999185, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2683.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301278.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008826790279016058, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991173209720984, \"precision\": 1.0, \"recall\": 0.008826790279016058, \"specificity\": 1.0, \"npv\": 0.9997644497286545, \"accuracy\": 0.9997644502227598, \"f1\": 0.017499119500136967, \"f2\": 0.011009193887373854, \"f0_5\": 0.042628847797694894, \"p4\": 0.03439626376423921, \"phi\": 0.0939399336074426}, {\"truth_threshold\": 43.49999902769923, \"match_probability\": 0.9999999999999196, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2660.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301301.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008751122676922369, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9912488773230776, \"precision\": 1.0, \"recall\": 0.008751122676922369, \"specificity\": 1.0, \"npv\": 0.9997644317506408, \"accuracy\": 0.9997644322405478, \"f1\": 0.01735040978928384, \"f2\": 0.010915023668367113, \"f0_5\": 0.04227577153283047, \"p4\": 0.034108945672114, \"phi\": 0.09353641638567002}, {\"truth_threshold\": 43.5199990272522, \"match_probability\": 0.9999999999999207, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2643.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301318.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008695194449287902, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9913048055507121, \"precision\": 1.0, \"recall\": 0.008695194449287902, \"specificity\": 1.0, \"npv\": 0.9997644184625442, \"accuracy\": 0.9997644189493476, \"f1\": 0.017240479576261236, \"f2\": 0.010845417308514576, \"f0_5\": 0.04201466936696627, \"p4\": 0.033896498411757695, \"phi\": 0.09323704211315939}, {\"truth_threshold\": 43.53999902680516, \"match_probability\": 0.9999999999999218, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2619.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301342.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00861623695145101, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991383763048549, \"precision\": 1.0, \"recall\": 0.00861623695145101, \"specificity\": 1.0, \"npv\": 0.9997643997028788, \"accuracy\": 0.9997644001853003, \"f1\": 0.017085263226564028, \"f2\": 0.010747146199761503, \"f0_5\": 0.04164586228719903, \"p4\": 0.03359645454994029, \"phi\": 0.09281275215973923}, {\"truth_threshold\": 43.55999902635813, \"match_probability\": 0.9999999999999228, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2614.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301347.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00859978747273499, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991400212527265, \"precision\": 1.0, \"recall\": 0.00859978747273499, \"specificity\": 1.0, \"npv\": 0.9997643957946153, \"accuracy\": 0.9997643962761238, \"f1\": 0.017052923428198648, \"f2\": 0.010726672564831943, \"f0_5\": 0.04156899913172634, \"p4\": 0.03353392796930489, \"phi\": 0.09272411405152922}, {\"truth_threshold\": 43.57999902591109, \"match_probability\": 0.999999999999924, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2593.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301368.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008530699662127708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9914693003378723, \"precision\": 1.0, \"recall\": 0.008530699662127708, \"specificity\": 1.0, \"npv\": 0.9997643793799089, \"accuracy\": 0.9997643798575824, \"f1\": 0.016917084755051312, \"f2\": 0.010640681463218862, \"f0_5\": 0.041246067069000074, \"p4\": 0.03327125061802787, \"phi\": 0.09235090499493498}, {\"truth_threshold\": 43.59999902546406, \"match_probability\": 0.999999999999925, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2582.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301379.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008494510808952464, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9915054891910475, \"precision\": 1.0, \"recall\": 0.008494510808952464, \"specificity\": 1.0, \"npv\": 0.9997643707817295, \"accuracy\": 0.9997643712573939, \"f1\": 0.016845923736637274, \"f2\": 0.010595637322250181, \"f0_5\": 0.041076843287547446, \"p4\": 0.033133615340479886, \"phi\": 0.09215481134488292}, {\"truth_threshold\": 43.61999902501702, \"match_probability\": 0.9999999999999261, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2560.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301401.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008422133102601979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.991577866897398, \"precision\": 1.0, \"recall\": 0.008422133102601979, \"specificity\": 1.0, \"npv\": 0.9997643535853713, \"accuracy\": 0.9997643540570172, \"f1\": 0.01670358637744233, \"f2\": 0.01050554660030663, \"f0_5\": 0.040738253538340104, \"p4\": 0.03285825733271867, \"phi\": 0.09176136690967951}, {\"truth_threshold\": 43.63999902456999, \"match_probability\": 0.9999999999999271, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2544.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301417.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008369494770710716, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9916305052292893, \"precision\": 1.0, \"recall\": 0.008369494770710716, \"specificity\": 1.0, \"npv\": 0.9997643410789293, \"accuracy\": 0.9997643415476524, \"f1\": 0.016600055464021796, \"f2\": 0.010440024031753432, \"f0_5\": 0.04049188729758035, \"p4\": 0.032657923690286805, \"phi\": 0.09147416260673362}, {\"truth_threshold\": 43.65999902412295, \"match_probability\": 0.9999999999999281, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2523.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301438.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008300406960103434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9916995930398965, \"precision\": 1.0, \"recall\": 0.008300406960103434, \"specificity\": 1.0, \"npv\": 0.9997643246642247, \"accuracy\": 0.999764325129111, \"f1\": 0.016464154735646885, \"f2\": 0.010354023048884286, \"f0_5\": 0.04016837922261529, \"p4\": 0.032394892091191965, \"phi\": 0.091095832829532}, {\"truth_threshold\": 43.67999902367592, \"match_probability\": 0.9999999999999291, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2503.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008234609045239356, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9917653909547607, \"precision\": 1.0, \"recall\": 0.008234609045239356, \"specificity\": 1.0, \"npv\": 0.9997643090311732, \"accuracy\": 0.9997643094924048, \"f1\": 0.01633470815495458, \"f2\": 0.010272114594610566, \"f0_5\": 0.03986011536023798, \"p4\": 0.032144286873554084, \"phi\": 0.09073405216486022}, {\"truth_threshold\": 43.699999023228884, \"match_probability\": 0.9999999999999301, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2490.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008191840400577705, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9918081595994223, \"precision\": 1.0, \"recall\": 0.008191840400577705, \"specificity\": 1.0, \"npv\": 0.99976429886969, \"accuracy\": 0.9997642993285458, \"f1\": 0.016250558816907106, \"f2\": 0.010218872657251623, \"f0_5\": 0.03965965959588559, \"p4\": 0.03198134169642499, \"phi\": 0.09049811917678714}, {\"truth_threshold\": 43.71999902278185, \"match_probability\": 0.9999999999999309, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2464.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301497.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008106303111254404, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9918936968887456, \"precision\": 1.0, \"recall\": 0.008106303111254404, \"specificity\": 1.0, \"npv\": 0.9997642785467241, \"accuracy\": 0.9997642790008279, \"f1\": 0.016082238720731012, \"f2\": 0.010112385373813518, \"f0_5\": 0.03925854877205505, \"p4\": 0.03165532887009581, \"phi\": 0.09002439825794074}, {\"truth_threshold\": 43.75999902188778, \"match_probability\": 0.9999999999999328, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2456.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301505.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.008079983945308773, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9919200160546913, \"precision\": 1.0, \"recall\": 0.008079983945308773, \"specificity\": 1.0, \"npv\": 0.9997642722935041, \"accuracy\": 0.9997642727461454, \"f1\": 0.016030442175205682, \"f2\": 0.010079619141426579, \"f0_5\": 0.039135076565164045, \"p4\": 0.03155498436387622, \"phi\": 0.08987813565725994}, {\"truth_threshold\": 43.779999021440744, \"match_probability\": 0.9999999999999338, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2414.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301547.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00794180832409421, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9920581916759058, \"precision\": 1.0, \"recall\": 0.00794180832409421, \"specificity\": 1.0, \"npv\": 0.9997642394640999, \"accuracy\": 0.9997642399090626, \"f1\": 0.015758465932272543, \"f2\": 0.009907589361202635, \"f0_5\": 0.038486434089988746, \"p4\": 0.031027921765024204, \"phi\": 0.0891063182894889}, {\"truth_threshold\": 43.79999902099371, \"match_probability\": 0.9999999999999347, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2381.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301580.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007833241764568481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921667582354315, \"precision\": 1.0, \"recall\": 0.007833241764568481, \"specificity\": 1.0, \"npv\": 0.9997642136695695, \"accuracy\": 0.9997642141084975, \"f1\": 0.01554471799492071, \"f2\": 0.009772414783804306, \"f0_5\": 0.03797629870647718, \"p4\": 0.030613501624231206, \"phi\": 0.08849516819147495}, {\"truth_threshold\": 43.819999020546675, \"match_probability\": 0.9999999999999356, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2372.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301589.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0078036327028796456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9921963672971204, \"precision\": 1.0, \"recall\": 0.0078036327028796456, \"specificity\": 1.0, \"npv\": 0.9997642066346978, \"accuracy\": 0.9997642070719798, \"f1\": 0.015486415110353766, \"f2\": 0.009735547718959528, \"f0_5\": 0.03783709630593813, \"p4\": 0.030500432166403003, \"phi\": 0.08832775700799297}, {\"truth_threshold\": 43.83999902009964, \"match_probability\": 0.9999999999999365, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2357.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301604.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0077542842667315875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9922457157332684, \"precision\": 1.0, \"recall\": 0.0077542842667315875, \"specificity\": 1.0, \"npv\": 0.9997641949099119, \"accuracy\": 0.9997641953444502, \"f1\": 0.015389236022695369, \"f2\": 0.009674101400343622, \"f0_5\": 0.037605021235588995, \"p4\": 0.030311939443127607, \"phi\": 0.0880480310230246}, {\"truth_threshold\": 43.859999019652605, \"match_probability\": 0.9999999999999374, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2336.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301625.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007685196456124305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923148035438757, \"precision\": 1.0, \"recall\": 0.007685196456124305, \"specificity\": 1.0, \"npv\": 0.999764178495212, \"accuracy\": 0.9997641789259087, \"f1\": 0.015253169309526375, \"f2\": 0.009588074012050763, \"f0_5\": 0.03727996680550901, \"p4\": 0.030047957974285146, \"phi\": 0.08765491498787407}, {\"truth_threshold\": 43.87999901920557, \"match_probability\": 0.9999999999999383, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2330.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007665457081665082, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923345429183349, \"precision\": 1.0, \"recall\": 0.007665457081665082, \"specificity\": 1.0, \"npv\": 0.9997641738052979, \"accuracy\": 0.9997641742348969, \"f1\": 0.015214289678769536, \"f2\": 0.009563494213470325, \"f0_5\": 0.03718706209441364, \"p4\": 0.029972515048887163, \"phi\": 0.08754227188102248}, {\"truth_threshold\": 43.899999018758535, \"match_probability\": 0.999999999999939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2323.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301638.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007642427811462655, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9923575721885374, \"precision\": 1.0, \"recall\": 0.007642427811462655, \"specificity\": 1.0, \"npv\": 0.9997641683337315, \"accuracy\": 0.9997641687620498, \"f1\": 0.015168928184299539, \"f2\": 0.009534817475764817, \"f0_5\": 0.03707865527225597, \"p4\": 0.029884487261799823, \"phi\": 0.08741067145936783}, {\"truth_threshold\": 43.9199990183115, \"match_probability\": 0.9999999999999399, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2299.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007563470313625761, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9924365296863742, \"precision\": 1.0, \"recall\": 0.007563470313625761, \"specificity\": 1.0, \"npv\": 0.9997641495740756, \"accuracy\": 0.9997641499980024, \"f1\": 0.015013387317965128, \"f2\": 0.009436494730093265, \"f0_5\": 0.03670682756572582, \"p4\": 0.029582587406280798, \"phi\": 0.08695795803680549}, {\"truth_threshold\": 43.939999017864466, \"match_probability\": 0.9999999999999407, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2290.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301671.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007533861251936926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9924661387480631, \"precision\": 1.0, \"recall\": 0.007533861251936926, \"specificity\": 1.0, \"npv\": 0.9997641425392049, \"accuracy\": 0.9997641429614847, \"f1\": 0.014955053207989524, \"f2\": 0.009399622701607541, \"f0_5\": 0.036567333395077305, \"p4\": 0.029469338899449325, \"phi\": 0.0867875816839717}, {\"truth_threshold\": 43.95999901741743, \"match_probability\": 0.9999999999999416, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2276.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301685.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007487802711532072, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.992512197288468, \"precision\": 1.0, \"recall\": 0.007487802711532072, \"specificity\": 1.0, \"npv\": 0.9997641315960727, \"accuracy\": 0.9997641320157904, \"f1\": 0.014864304443943743, \"f2\": 0.009342265129872263, \"f0_5\": 0.03635027869611742, \"p4\": 0.029293135441299446, \"phi\": 0.08652188495090465}, {\"truth_threshold\": 43.979999016970396, \"match_probability\": 0.9999999999999424, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2265.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301696.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0074516138583568285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9925483861416432, \"precision\": 1.0, \"recall\": 0.0074516138583568285, \"specificity\": 1.0, \"npv\": 0.9997641229978976, \"accuracy\": 0.9997641234156021, \"f1\": 0.01479299602254544, \"f2\": 0.009297197541435126, \"f0_5\": 0.036179681235444267, \"p4\": 0.029154656451097348, \"phi\": 0.08631254945845995}, {\"truth_threshold\": 43.99999901652336, \"match_probability\": 0.9999999999999432, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2247.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301714.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007392395734979159, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9926076042650208, \"precision\": 1.0, \"recall\": 0.007392395734979159, \"specificity\": 1.0, \"npv\": 0.9997641089281569, \"accuracy\": 0.9997641093425665, \"f1\": 0.01467629846378932, \"f2\": 0.009223448822789101, \"f0_5\": 0.03590041827901671, \"p4\": 0.028927991011259768, \"phi\": 0.08596890097486268}, {\"truth_threshold\": 44.019999016076326, \"match_probability\": 0.9999999999999439, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2223.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301738.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007313438237142265, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9926865617628577, \"precision\": 1.0, \"recall\": 0.007313438237142265, \"specificity\": 1.0, \"npv\": 0.9997640901685032, \"accuracy\": 0.9997640905785192, \"f1\": 0.014520680375199227, \"f2\": 0.00912511380736856, \"f0_5\": 0.03552786772062278, \"p4\": 0.028625647826607717, \"phi\": 0.08550855468992608}, {\"truth_threshold\": 44.03999901562929, \"match_probability\": 0.9999999999999447, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2204.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007250930218021391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9927490697819786, \"precision\": 1.0, \"recall\": 0.007250930218021391, \"specificity\": 1.0, \"npv\": 0.9997640753171112, \"accuracy\": 0.9997640757236484, \"f1\": 0.014397465418973429, \"f2\": 0.00904726250525431, \"f0_5\": 0.035232769672961885, \"p4\": 0.02838619337907929, \"phi\": 0.0851423487144268}, {\"truth_threshold\": 44.05999901518226, \"match_probability\": 0.9999999999999455, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2194.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301767.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007218031260589352, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9927819687394106, \"precision\": 1.0, \"recall\": 0.007218031260589352, \"specificity\": 1.0, \"npv\": 0.9997640675005893, \"accuracy\": 0.9997640679052954, \"f1\": 0.014332609299211183, \"f2\": 0.009006287160170701, \"f0_5\": 0.03507739730188625, \"p4\": 0.02826012941232045, \"phi\": 0.08494897464026989}, {\"truth_threshold\": 44.07999901473522, \"match_probability\": 0.9999999999999463, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2183.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301778.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007181842407414109, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9928181575925858, \"precision\": 1.0, \"recall\": 0.007181842407414109, \"specificity\": 1.0, \"npv\": 0.9997640589024154, \"accuracy\": 0.999764059305107, \"f1\": 0.014261262673774432, \"f2\": 0.008961213503477346, \"f0_5\": 0.03490644178155571, \"p4\": 0.028121430911642105, \"phi\": 0.08473575346708039}, {\"truth_threshold\": 44.09999901428819, \"match_probability\": 0.9999999999999469, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007086435430861196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9929135645691388, \"precision\": 1.0, \"recall\": 0.007086435430861196, \"specificity\": 1.0, \"npv\": 0.9997640362345028, \"accuracy\": 0.9997640366318831, \"f1\": 0.014073142446466198, \"f2\": 0.008842379051525536, \"f0_5\": 0.03445551016229601, \"p4\": 0.027755629864503632, \"phi\": 0.08417103592610095}, {\"truth_threshold\": 44.11999901384115, \"match_probability\": 0.9999999999999477, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2147.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.007063406160658769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9929365938393412, \"precision\": 1.0, \"recall\": 0.007063406160658769, \"specificity\": 1.0, \"npv\": 0.999764030762938, \"accuracy\": 0.999764031159036, \"f1\": 0.014027728775464869, \"f2\": 0.008813694025653719, \"f0_5\": 0.03434661445085411, \"p4\": 0.02766730233606182, \"phi\": 0.08403415623480716}, {\"truth_threshold\": 44.13999901339412, \"match_probability\": 0.9999999999999484, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2126.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301835.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006994318350051487, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930056816499485, \"precision\": 1.0, \"recall\": 0.006994318350051487, \"specificity\": 1.0, \"npv\": 0.9997640143482435, \"accuracy\": 0.9997640147404946, \"f1\": 0.013891475299506349, \"f2\": 0.008727636969711898, \"f0_5\": 0.0340198102187445, \"p4\": 0.027402248021990507, \"phi\": 0.08362217284474888}, {\"truth_threshold\": 44.15999901294708, \"match_probability\": 0.9999999999999492, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2110.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301851.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006941680018160225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930583199818398, \"precision\": 1.0, \"recall\": 0.006941680018160225, \"specificity\": 1.0, \"npv\": 0.99976400184181, \"accuracy\": 0.9997640022311297, \"f1\": 0.01378765057780711, \"f2\": 0.008662067697137987, \"f0_5\": 0.033770698557302956, \"p4\": 0.027200229630514976, \"phi\": 0.08330691324530752}, {\"truth_threshold\": 44.17999901250005, \"match_probability\": 0.9999999999999498, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2108.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301853.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0069351002266738165, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930648997733262, \"precision\": 1.0, \"recall\": 0.0069351002266738165, \"specificity\": 1.0, \"npv\": 0.9997640002785059, \"accuracy\": 0.9997640006674591, \"f1\": 0.013774671724349739, \"f2\": 0.00865387141693597, \"f0_5\": 0.03373955242274955, \"p4\": 0.027174972936499463, \"phi\": 0.08326742187045176}, {\"truth_threshold\": 44.19999901205301, \"match_probability\": 0.9999999999999505, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2107.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301854.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006931810330930613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930681896690694, \"precision\": 1.0, \"recall\": 0.006931810330930613, \"specificity\": 1.0, \"npv\": 0.9997639994968538, \"accuracy\": 0.9997639998856237, \"f1\": 0.013768182234013356, \"f2\": 0.008649773266740615, \"f0_5\": 0.03372397875725458, \"p4\": 0.02716234422316766, \"phi\": 0.08324766915778962}, {\"truth_threshold\": 44.21999901160598, \"match_probability\": 0.9999999999999512, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2100.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301861.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006908781060728186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9930912189392718, \"precision\": 1.0, \"recall\": 0.006908781060728186, \"specificity\": 1.0, \"npv\": 0.9997639940252893, \"accuracy\": 0.9997639944127766, \"f1\": 0.01372275461427624, \"f2\": 0.008621086026943767, \"f0_5\": 0.03361495193061874, \"p4\": 0.027073936391134923, \"phi\": 0.08310926871967941}, {\"truth_threshold\": 44.23999901115894, \"match_probability\": 0.9999999999999518, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2082.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006849562937350516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931504370626495, \"precision\": 1.0, \"recall\": 0.006849562937350516, \"specificity\": 1.0, \"npv\": 0.9997639799555521, \"accuracy\": 0.9997639803397411, \"f1\": 0.013605931192675539, \"f2\": 0.008547317324697889, \"f0_5\": 0.03333450745943661, \"p4\": 0.026846546998168, \"phi\": 0.08275231902008301}, {\"truth_threshold\": 44.25999901071191, \"match_probability\": 0.9999999999999525, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2078.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0068364033543776995, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931635966456223, \"precision\": 1.0, \"recall\": 0.0068364033543776995, \"specificity\": 1.0, \"npv\": 0.9997639768289439, \"accuracy\": 0.9997639772123998, \"f1\": 0.013579968566097785, \"f2\": 0.008530923983637704, \"f0_5\": 0.033272168903491495, \"p4\": 0.026796005269691076, \"phi\": 0.08267278757111908}, {\"truth_threshold\": 44.27999901026487, \"match_probability\": 0.9999999999999531, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2068.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0068035043969456605, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9931964956030543, \"precision\": 1.0, \"recall\": 0.0068035043969456605, \"specificity\": 1.0, \"npv\": 0.9997639690124236, \"accuracy\": 0.9997639693940469, \"f1\": 0.013515059030353332, \"f2\": 0.008489940159880189, \"f0_5\": 0.033116294562073836, \"p4\": 0.026669633837332292, \"phi\": 0.08247362341430058}, {\"truth_threshold\": 44.29999900981784, \"match_probability\": 0.9999999999999538, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2062.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006783765022486438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932162349775135, \"precision\": 1.0, \"recall\": 0.006783765022486438, \"specificity\": 1.0, \"npv\": 0.9997639643225114, \"accuracy\": 0.999763964703035, \"f1\": 0.013476111272682119, \"f2\": 0.008465349542575535, \"f0_5\": 0.033022750785531484, \"p4\": 0.026593799242275593, \"phi\": 0.0823538937264865}, {\"truth_threshold\": 44.319999009370804, \"match_probability\": 0.9999999999999545, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2060.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00677718523100003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993222814769, \"precision\": 1.0, \"recall\": 0.00677718523100003, \"specificity\": 1.0, \"npv\": 0.9997639627592073, \"accuracy\": 0.9997639631393643, \"f1\": 0.013463128347400995, \"f2\": 0.008457152616298164, \"f0_5\": 0.03299156633066518, \"p4\": 0.026568519087642527, \"phi\": 0.08231394513020114}, {\"truth_threshold\": 44.33999900892377, \"match_probability\": 0.999999999999955, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2055.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00676073575228401, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993239264247716, \"precision\": 1.0, \"recall\": 0.00676073575228401, \"specificity\": 1.0, \"npv\": 0.9997639588509473, \"accuracy\": 0.9997639592301879, \"f1\": 0.013430670291749451, \"f2\": 0.008436660182823042, \"f0_5\": 0.03291359820104363, \"p4\": 0.026505314421157337, \"phi\": 0.08221398871511222}, {\"truth_threshold\": 44.359999008476734, \"match_probability\": 0.9999999999999557, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2052.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301909.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006750866065054399, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932491339349456, \"precision\": 1.0, \"recall\": 0.006750866065054399, \"specificity\": 1.0, \"npv\": 0.9997639565059913, \"accuracy\": 0.9997639568846819, \"f1\": 0.013411194949234182, \"f2\": 0.008424364641972713, \"f0_5\": 0.03286681252782948, \"p4\": 0.026467388686191987, \"phi\": 0.08215395649048692}, {\"truth_threshold\": 44.3799990080297, \"match_probability\": 0.9999999999999564, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2037.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00670151762890634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9932984823710936, \"precision\": 1.0, \"recall\": 0.00670151762890634, \"specificity\": 1.0, \"npv\": 0.9997639447812111, \"accuracy\": 0.9997639451571524, \"f1\": 0.013313812508578488, \"f2\": 0.008362886029094796, \"f0_5\": 0.032632830197142665, \"p4\": 0.02627772698443147, \"phi\": 0.08185313494727145}, {\"truth_threshold\": 44.399999007582664, \"match_probability\": 0.9999999999999569, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2025.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301936.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006662038879987893, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9933379611200122, \"precision\": 1.0, \"recall\": 0.006662038879987893, \"specificity\": 1.0, \"npv\": 0.9997639354013873, \"accuracy\": 0.9997639357751287, \"f1\": 0.013235899681684782, \"f2\": 0.008313702048414074, \"f0_5\": 0.03244557955015205, \"p4\": 0.026125957979196538, \"phi\": 0.08161167936302835}, {\"truth_threshold\": 44.41999900713563, \"match_probability\": 0.9999999999999575, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1994.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301967.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006560052111948572, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9934399478880515, \"precision\": 1.0, \"recall\": 0.006560052111948572, \"specificity\": 1.0, \"npv\": 0.9997639111701765, \"accuracy\": 0.9997639115382342, \"f1\": 0.013034596591001944, \"f2\": 0.008186638945409816, \"f0_5\": 0.03196158198610617, \"p4\": 0.02573372485489892, \"phi\": 0.0809845871565811}, {\"truth_threshold\": 44.439999006688595, \"match_probability\": 0.9999999999999581, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1973.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 301988.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006490964301341291, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935090356986587, \"precision\": 1.0, \"recall\": 0.006490964301341291, \"specificity\": 1.0, \"npv\": 0.999763894755486, \"accuracy\": 0.9997638951196928, \"f1\": 0.012898206802774455, \"f2\": 0.00810056026480169, \"f0_5\": 0.03163349398594851, \"p4\": 0.025467884772652737, \"phi\": 0.0805570093202807}, {\"truth_threshold\": 44.45999900624156, \"match_probability\": 0.9999999999999587, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1961.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302000.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0064514855524228434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935485144475772, \"precision\": 1.0, \"recall\": 0.0064514855524228434, \"specificity\": 1.0, \"npv\": 0.9997638853756631, \"accuracy\": 0.9997638857376692, \"f1\": 0.01282026137381424, \"f2\": 0.00805137111442308, \"f0_5\": 0.03144593576113276, \"p4\": 0.025315927613351073, \"phi\": 0.08031165707626271}, {\"truth_threshold\": 44.479999005794525, \"match_probability\": 0.9999999999999593, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1955.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302006.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006431746177963621, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9935682538220364, \"precision\": 1.0, \"recall\": 0.006431746177963621, \"specificity\": 1.0, \"npv\": 0.9997638806857517, \"accuracy\": 0.9997638810466573, \"f1\": 0.012781286366192027, \"f2\": 0.008026776175707157, \"f0_5\": 0.03135213499219003, \"p4\": 0.025239935790279954, \"phi\": 0.08018869944366637}, {\"truth_threshold\": 44.49999900534749, \"match_probability\": 0.9999999999999598, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1936.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302025.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006369238158842746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9936307618411573, \"precision\": 1.0, \"recall\": 0.006369238158842746, \"specificity\": 1.0, \"npv\": 0.9997638658343659, \"accuracy\": 0.9997638661917865, \"f1\": 0.012657855421923065, \"f2\": 0.007948890604214226, \"f0_5\": 0.031055003929997913, \"p4\": 0.024999236749823257, \"phi\": 0.07979808371198135}, {\"truth_threshold\": 44.519999004900455, \"match_probability\": 0.9999999999999604, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1923.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302038.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006326469514181096, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9936735304858189, \"precision\": 1.0, \"recall\": 0.006326469514181096, \"specificity\": 1.0, \"npv\": 0.9997638556728917, \"accuracy\": 0.9997638560279275, \"f1\": 0.012573393835571654, \"f2\": 0.007895599076013721, \"f0_5\": 0.03085162023147539, \"p4\": 0.024834496883910546, \"phi\": 0.07952971491395337}, {\"truth_threshold\": 44.53999900445342, \"match_probability\": 0.9999999999999609, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1908.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006277121078033037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993722878921967, \"precision\": 1.0, \"recall\": 0.006277121078033037, \"specificity\": 1.0, \"npv\": 0.999763843948114, \"accuracy\": 0.9997638443003979, \"f1\": 0.012475929237680183, \"f2\": 0.007834107437310717, \"f0_5\": 0.030616862381375703, \"p4\": 0.024644360860161977, \"phi\": 0.0792189289116057}, {\"truth_threshold\": 44.559999004006386, \"match_probability\": 0.9999999999999615, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1902.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302059.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006257381703573814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9937426182964262, \"precision\": 1.0, \"recall\": 0.006257381703573814, \"specificity\": 1.0, \"npv\": 0.9997638392582031, \"accuracy\": 0.9997638396093861, \"f1\": 0.01243694072182644, \"f2\": 0.007809510357660793, \"f0_5\": 0.03052293392474861, \"p4\": 0.024568290976642756, \"phi\": 0.0790942725844861}, {\"truth_threshold\": 44.57999900355935, \"match_probability\": 0.9999999999999619, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1893.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302068.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006227772641884979, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.993772227358115, \"precision\": 1.0, \"recall\": 0.006227772641884979, \"specificity\": 1.0, \"npv\": 0.9997638322233366, \"accuracy\": 0.9997638325728683, \"f1\": 0.012378455079874711, \"f2\": 0.0077726142837082225, \"f0_5\": 0.030382014104444795, \"p4\": 0.02445416956723756, \"phi\": 0.07890691885168613}, {\"truth_threshold\": 44.599999003112316, \"match_probability\": 0.9999999999999625, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1879.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302082.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006181714101480124, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938182858985198, \"precision\": 1.0, \"recall\": 0.006181714101480124, \"specificity\": 1.0, \"npv\": 0.9997638212802114, \"accuracy\": 0.999763821627174, \"f1\": 0.012287470572848548, \"f2\": 0.007715219306853857, \"f0_5\": 0.030162740748113023, \"p4\": 0.02427660780750013, \"phi\": 0.07861459223425087}, {\"truth_threshold\": 44.61999900266528, \"match_probability\": 0.999999999999963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1874.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302087.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006165264622764104, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938347353772359, \"precision\": 1.0, \"recall\": 0.006165264622764104, \"specificity\": 1.0, \"npv\": 0.9997638173719523, \"accuracy\": 0.9997638177179975, \"f1\": 0.012254974087334674, \"f2\": 0.007694720781001841, \"f0_5\": 0.03008440972590117, \"p4\": 0.024213181216549483, \"phi\": 0.07850992608812526}, {\"truth_threshold\": 44.63999900221825, \"match_probability\": 0.9999999999999635, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1867.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302094.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006142235352561677, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938577646474384, \"precision\": 1.0, \"recall\": 0.006142235352561677, \"specificity\": 1.0, \"npv\": 0.9997638119003898, \"accuracy\": 0.9997638122451503, \"f1\": 0.012209477222491074, \"f2\": 0.007666022562003628, \"f0_5\": 0.029974729392574232, \"p4\": 0.02412437366190383, \"phi\": 0.0783631586248691}, {\"truth_threshold\": 44.65999900177121, \"match_probability\": 0.999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1861.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302100.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0061224959781024536, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9938775040218976, \"precision\": 1.0, \"recall\": 0.0061224959781024536, \"specificity\": 1.0, \"npv\": 0.9997638072104791, \"accuracy\": 0.9997638075541385, \"f1\": 0.012170478252055117, \"f2\": 0.007641423825967702, \"f0_5\": 0.029880701979737, \"p4\": 0.024048243309456496, \"phi\": 0.0782371388069538}, {\"truth_threshold\": 44.67999900132418, \"match_probability\": 0.9999999999999645, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1850.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302111.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006086307124927211, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9939136928750728, \"precision\": 1.0, \"recall\": 0.006086307124927211, \"specificity\": 1.0, \"npv\": 0.9997637986123096, \"accuracy\": 0.9997637989539502, \"f1\": 0.012098976165016954, \"f2\": 0.0075963255136347885, \"f0_5\": 0.029708280741647157, \"p4\": 0.02390864799670586, \"phi\": 0.0780055737158467}, {\"truth_threshold\": 44.69999900087714, \"match_probability\": 0.999999999999965, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1830.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302131.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.006020509210063133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9939794907899369, \"precision\": 1.0, \"recall\": 0.006020509210063133, \"specificity\": 1.0, \"npv\": 0.9997637829792745, \"accuracy\": 0.999763783317244, \"f1\": 0.01196895919108149, \"f2\": 0.007514326494611858, \"f0_5\": 0.029394662700261177, \"p4\": 0.023654762053349116, \"phi\": 0.07758277555820159}, {\"truth_threshold\": 44.71999900043011, \"match_probability\": 0.9999999999999655, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1823.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302138.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005997479939860706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940025200601393, \"precision\": 1.0, \"recall\": 0.005997479939860706, \"specificity\": 1.0, \"npv\": 0.9997637775077124, \"accuracy\": 0.999763777844397, \"f1\": 0.011923449232137718, \"f2\": 0.0074856262015805634, \"f0_5\": 0.029284858298554553, \"p4\": 0.0235658787103478, \"phi\": 0.07743425082095046}, {\"truth_threshold\": 44.73999899998307, \"match_probability\": 0.9999999999999659, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1819.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302142.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00598432035688789, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9940156796431121, \"precision\": 1.0, \"recall\": 0.00598432035688789, \"specificity\": 1.0, \"npv\": 0.9997637743811054, \"accuracy\": 0.9997637747170557, \"f1\": 0.011897442605795016, \"f2\": 0.007469225885979947, \"f0_5\": 0.029222104055751725, \"p4\": 0.02351508281132036, \"phi\": 0.07734925149675284}, {\"truth_threshold\": 44.75999899953604, \"match_probability\": 0.9999999999999665, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1805.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302156.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005938261816483036, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994061738183517, \"precision\": 1.0, \"recall\": 0.005938261816483036, \"specificity\": 1.0, \"npv\": 0.9997637634379813, \"accuracy\": 0.9997637637713614, \"f1\": 0.011806414055192532, \"f2\": 0.007411823932841073, \"f0_5\": 0.029002413386421406, \"p4\": 0.02333726613077648, \"phi\": 0.07705101545033098}, {\"truth_threshold\": 44.779998999089, \"match_probability\": 0.9999999999999669, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1800.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302161.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005921812337767016, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994078187662233, \"precision\": 1.0, \"recall\": 0.005921812337767016, \"specificity\": 1.0, \"npv\": 0.9997637595297229, \"accuracy\": 0.9997637598621849, \"f1\": 0.011773901838363951, \"f2\": 0.0073913229154005606, \"f0_5\": 0.028923933269272176, \"p4\": 0.02327374847152395, \"phi\": 0.07694422243440666}, {\"truth_threshold\": 44.79999899864197, \"match_probability\": 0.9999999999999674, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1785.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302176.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005872463901618958, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994127536098381, \"precision\": 1.0, \"recall\": 0.005872463901618958, \"specificity\": 1.0, \"npv\": 0.9997637478049474, \"accuracy\": 0.9997637481346553, \"f1\": 0.011676358807637713, \"f2\": 0.007329818852868977, \"f0_5\": 0.028688432374052157, \"p4\": 0.023083158528162197, \"phi\": 0.07662295034212552}, {\"truth_threshold\": 44.81999899819493, \"match_probability\": 0.9999999999999678, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1769.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302192.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005819825569727695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9941801744302723, \"precision\": 1.0, \"recall\": 0.005819825569727695, \"specificity\": 1.0, \"npv\": 0.9997637352985206, \"accuracy\": 0.9997637356252904, \"f1\": 0.011572302358289994, \"f2\": 0.007264212849238633, \"f0_5\": 0.028437131273771288, \"p4\": 0.022879801450765975, \"phi\": 0.07627876867370632}, {\"truth_threshold\": 44.8399989977479, \"match_probability\": 0.9999999999999682, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1745.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302216.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005740868071890802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9942591319281092, \"precision\": 1.0, \"recall\": 0.005740868071890802, \"specificity\": 1.0, \"npv\": 0.999763716538881, \"accuracy\": 0.9997637168612431, \"f1\": 0.011416197261421105, \"f2\": 0.007165800610879369, \"f0_5\": 0.02805998565644286, \"p4\": 0.022574647440272717, \"phi\": 0.07575956441079203}, {\"truth_threshold\": 44.85999899730086, \"match_probability\": 0.9999999999999687, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1740.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302221.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005724418593174782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9942755814068253, \"precision\": 1.0, \"recall\": 0.005724418593174782, \"specificity\": 1.0, \"npv\": 0.9997637126306228, \"accuracy\": 0.9997637129520666, \"f1\": 0.011383672281085113, \"f2\": 0.007145297572898461, \"f0_5\": 0.027981384338787024, \"p4\": 0.022511055797790308, \"phi\": 0.07565094834411652}, {\"truth_threshold\": 44.87999899685383, \"match_probability\": 0.9999999999999691, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1736.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005711259010201967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.994288740989798, \"precision\": 1.0, \"recall\": 0.005711259010201967, \"specificity\": 1.0, \"npv\": 0.9997637095040163, \"accuracy\": 0.9997637098247253, \"f1\": 0.011357651530764123, \"f2\": 0.007128895021271703, \"f0_5\": 0.027918496003602387, \"p4\": 0.022460178040653193, \"phi\": 0.07556394308119285}, {\"truth_threshold\": 44.899998996406794, \"match_probability\": 0.9999999999999696, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1731.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302230.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005694809531485948, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943051904685141, \"precision\": 1.0, \"recall\": 0.005694809531485948, \"specificity\": 1.0, \"npv\": 0.9997637055957581, \"accuracy\": 0.9997637059155488, \"f1\": 0.011325124635253784, \"f2\": 0.007108391680183972, \"f0_5\": 0.027839876481657203, \"p4\": 0.022396575289538208, \"phi\": 0.07545504542348665}, {\"truth_threshold\": 44.91999899595976, \"match_probability\": 0.9999999999999699, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1724.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302237.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0056717802612835195, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9943282197387164, \"precision\": 1.0, \"recall\": 0.0056717802612835195, \"specificity\": 1.0, \"npv\": 0.9997637001241968, \"accuracy\": 0.9997637004427017, \"f1\": 0.011279585193908762, \"f2\": 0.007079686719756104, \"f0_5\": 0.027729792155235366, \"p4\": 0.022307521067605706, \"phi\": 0.07530232413619248}, {\"truth_threshold\": 44.939998995512724, \"match_probability\": 0.9999999999999704, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1696.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302265.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005579663180473811, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9944203368195262, \"precision\": 1.0, \"recall\": 0.005579663180473811, \"specificity\": 1.0, \"npv\": 0.9997636782379522, \"accuracy\": 0.9997636785513131, \"f1\": 0.011097406570109632, \"f2\": 0.006964863577377334, \"f0_5\": 0.027289256464303527, \"p4\": 0.021951183145224953, \"phi\": 0.07468831625253958}, {\"truth_threshold\": 44.95999899506569, \"match_probability\": 0.9999999999999708, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1681.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302280.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005530314744325753, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9944696852556743, \"precision\": 1.0, \"recall\": 0.005530314744325753, \"specificity\": 1.0, \"npv\": 0.9997636665131786, \"accuracy\": 0.9997636668237835, \"f1\": 0.010999797148297682, \"f2\": 0.006903349007207244, \"f0_5\": 0.027053124547371132, \"p4\": 0.021760208130429195, \"phi\": 0.07435729786482968}, {\"truth_threshold\": 44.979998994618654, \"match_probability\": 0.9999999999999711, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1660.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302301.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00546122693371847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945387730662816, \"precision\": 1.0, \"recall\": 0.00546122693371847, \"specificity\": 1.0, \"npv\": 0.9997636500984962, \"accuracy\": 0.9997636504052421, \"f1\": 0.01086312786097814, \"f2\": 0.006817226062501643, \"f0_5\": 0.0267223865988841, \"p4\": 0.021492749636736922, \"phi\": 0.0738913809132743}, {\"truth_threshold\": 44.99999899417162, \"match_probability\": 0.9999999999999716, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1645.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302316.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005411878497570412, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9945881215024296, \"precision\": 1.0, \"recall\": 0.005411878497570412, \"specificity\": 1.0, \"npv\": 0.9997636383737233, \"accuracy\": 0.9997636386777125, \"f1\": 0.01076549544184342, \"f2\": 0.0067557078544446805, \"f0_5\": 0.026486035660347587, \"p4\": 0.021301641056041477, \"phi\": 0.07355677628313732}, {\"truth_threshold\": 45.019998993724585, \"match_probability\": 0.999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1641.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302320.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005398718914597597, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946012810854024, \"precision\": 1.0, \"recall\": 0.005398718914597597, \"specificity\": 1.0, \"npv\": 0.9997636352471172, \"accuracy\": 0.9997636355503713, \"f1\": 0.010739458511397177, \"f2\": 0.0067393027429496054, \"f0_5\": 0.026422993317768297, \"p4\": 0.021250669362794003, \"phi\": 0.07346729100583105}, {\"truth_threshold\": 45.03999899327755, \"match_probability\": 0.9999999999999724, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1626.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302335.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005349370478449538, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946506295215505, \"precision\": 1.0, \"recall\": 0.005349370478449538, \"specificity\": 1.0, \"npv\": 0.9997636235223447, \"accuracy\": 0.9997636238228417, \"f1\": 0.010641813951509718, \"f2\": 0.006677782614766688, \"f0_5\": 0.026186526661620472, \"p4\": 0.021059490232483942, \"phi\": 0.07313074601765095}, {\"truth_threshold\": 45.059998992830515, \"match_probability\": 0.9999999999999727, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1624.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302337.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0053427906869631305, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9946572093130369, \"precision\": 1.0, \"recall\": 0.0053427906869631305, \"specificity\": 1.0, \"npv\": 0.9997636219590418, \"accuracy\": 0.999763622259171, \"f1\": 0.010628793952582751, \"f2\": 0.006669579816471562, \"f0_5\": 0.0261549908683006, \"p4\": 0.021033995471999745, \"phi\": 0.07308575626322338}, {\"truth_threshold\": 45.07999899238348, \"match_probability\": 0.9999999999999731, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1600.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302361.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005263833189126236, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947361668108737, \"precision\": 1.0, \"recall\": 0.005263833189126236, \"specificity\": 1.0, \"npv\": 0.9997636031994064, \"accuracy\": 0.9997636034951237, \"f1\": 0.010472540671093497, \"f2\": 0.006571144134761024, \"f0_5\": 0.02577643453913346, \"p4\": 0.02072798105363292, \"phi\": 0.07254370293692947}, {\"truth_threshold\": 45.099998991936445, \"match_probability\": 0.9999999999999735, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1583.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302378.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00520790496149177, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9947920950385082, \"precision\": 1.0, \"recall\": 0.00520790496149177, \"specificity\": 1.0, \"npv\": 0.9997635899113317, \"accuracy\": 0.9997635902039236, \"f1\": 0.010361846411646114, \"f2\": 0.006501416512037272, \"f0_5\": 0.025508148749730095, \"p4\": 0.020511134469748164, \"phi\": 0.07215728487282519}, {\"truth_threshold\": 45.11999899148941, \"match_probability\": 0.9999999999999738, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1573.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302388.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005175006004059731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9948249939959403, \"precision\": 1.0, \"recall\": 0.005175006004059731, \"specificity\": 1.0, \"npv\": 0.9997635820948174, \"accuracy\": 0.9997635823855705, \"f1\": 0.010296726387243318, \"f2\": 0.006460399353713641, \"f0_5\": 0.025350278643558644, \"p4\": 0.020383544181241685, \"phi\": 0.07192901041986428}, {\"truth_threshold\": 45.139998991042376, \"match_probability\": 0.9999999999999742, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1566.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005151976733857304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9948480232661427, \"precision\": 1.0, \"recall\": 0.005151976733857304, \"specificity\": 1.0, \"npv\": 0.9997635766232574, \"accuracy\": 0.9997635769127233, \"f1\": 0.010251139833795376, \"f2\": 0.006431686941950535, \"f0_5\": 0.025239745346119752, \"p4\": 0.020294216220854346, \"phi\": 0.07176878629404977}, {\"truth_threshold\": 45.15999899059534, \"match_probability\": 0.9999999999999746, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1536.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302425.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.005053279861561187, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949467201384388, \"precision\": 1.0, \"recall\": 0.005053279861561187, \"specificity\": 1.0, \"npv\": 0.9997635531737155, \"accuracy\": 0.9997635534576642, \"f1\": 0.01005574522826738, \"f2\": 0.006308630008707223, \"f0_5\": 0.024765805130520308, \"p4\": 0.019911244379304856, \"phi\": 0.07107802072072346}, {\"truth_threshold\": 45.179998990148306, \"match_probability\": 0.9999999999999749, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1522.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302439.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0050072213211563325, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9949927786788436, \"precision\": 1.0, \"recall\": 0.0050072213211563325, \"specificity\": 1.0, \"npv\": 0.9997635422305962, \"accuracy\": 0.9997635425119699, \"f1\": 0.00996454794538485, \"f2\": 0.006251201364256928, \"f0_5\": 0.024544507481075572, \"p4\": 0.01973244771716884, \"phi\": 0.07075335557252264}, {\"truth_threshold\": 45.19999898970127, \"match_probability\": 0.9999999999999752, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1515.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302446.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004984192050953905, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950158079490461, \"precision\": 1.0, \"recall\": 0.004984192050953905, \"specificity\": 1.0, \"npv\": 0.9997635367590366, \"accuracy\": 0.9997635370391228, \"f1\": 0.00991894616925716, \"f2\": 0.006222486546696579, \"f0_5\": 0.02443382867612194, \"p4\": 0.019643031128667186, \"phi\": 0.07059046304386984}, {\"truth_threshold\": 45.219998989254236, \"match_probability\": 0.9999999999999756, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1505.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302456.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004951293093521866, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950487069064782, \"precision\": 1.0, \"recall\": 0.004951293093521866, \"specificity\": 1.0, \"npv\": 0.9997635289425232, \"accuracy\": 0.9997635292207697, \"f1\": 0.009853797149273568, \"f2\": 0.006181464805902005, \"f0_5\": 0.02427568141273175, \"p4\": 0.019515272024688314, \"phi\": 0.07035710522760415}, {\"truth_threshold\": 45.2399989888072, \"match_probability\": 0.9999999999999759, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1498.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302463.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004928263823319439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950717361766805, \"precision\": 1.0, \"recall\": 0.004928263823319439, \"specificity\": 1.0, \"npv\": 0.9997635234709638, \"accuracy\": 0.9997635237479225, \"f1\": 0.009808190297224833, \"f2\": 0.006152749186342047, \"f0_5\": 0.024164954041419183, \"p4\": 0.01942582586416822, \"phi\": 0.07019329315964827}, {\"truth_threshold\": 45.25999898836017, \"match_probability\": 0.9999999999999762, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1496.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302465.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004921684031833031, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995078315968167, \"precision\": 1.0, \"recall\": 0.004921684031833031, \"specificity\": 1.0, \"npv\": 0.9997635219076612, \"accuracy\": 0.9997635221842519, \"f1\": 0.009795159384135901, \"f2\": 0.006144544662953653, \"f0_5\": 0.02413331397506009, \"p4\": 0.01940026758109171, \"phi\": 0.07014641944805229}, {\"truth_threshold\": 45.27999898791313, \"match_probability\": 0.9999999999999766, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1491.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302470.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004905234553117012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995094765446883, \"precision\": 1.0, \"recall\": 0.004905234553117012, \"specificity\": 1.0, \"npv\": 0.9997635179994044, \"accuracy\": 0.9997635182750754, \"f1\": 0.009762581354844624, \"f2\": 0.00612403323653719, \"f0_5\": 0.024054206662902314, \"p4\": 0.019336367522670393, \"phi\": 0.07002909790534574}, {\"truth_threshold\": 45.2999989874661, \"match_probability\": 0.9999999999999769, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1490.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302471.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004901944657373807, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9950980553426262, \"precision\": 1.0, \"recall\": 0.004901944657373807, \"specificity\": 1.0, \"npv\": 0.9997635172177531, \"accuracy\": 0.9997635174932401, \"f1\": 0.009756065620999767, \"f2\": 0.006119930931034539, \"f0_5\": 0.024038383975271117, \"p4\": 0.019323586765088652, \"phi\": 0.07000561000279058}, {\"truth_threshold\": 45.31999898701906, \"match_probability\": 0.9999999999999772, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1486.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004888785074400992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995111214925599, \"precision\": 1.0, \"recall\": 0.004888785074400992, \"specificity\": 1.0, \"npv\": 0.9997635140911478, \"accuracy\": 0.9997635143658989, \"f1\": 0.009730002258984374, \"f2\": 0.006103521641625525, \"f0_5\": 0.02397508914022039, \"p4\": 0.019272461248194896, \"phi\": 0.06991157948165304}, {\"truth_threshold\": 45.33999898657203, \"match_probability\": 0.9999999999999776, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1471.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302490.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004839436638252934, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951605633617471, \"precision\": 1.0, \"recall\": 0.004839436638252934, \"specificity\": 1.0, \"npv\": 0.9997635023663781, \"accuracy\": 0.9997635026383693, \"f1\": 0.009632258571465989, \"f2\": 0.006041985845898556, \"f0_5\": 0.02373767528925753, \"p4\": 0.01908070511937149, \"phi\": 0.06955783293734735}, {\"truth_threshold\": 45.35999898612499, \"match_probability\": 0.9999999999999779, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1463.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302498.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004813117472307302, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9951868825276927, \"precision\": 1.0, \"recall\": 0.004813117472307302, \"specificity\": 1.0, \"npv\": 0.9997634961131678, \"accuracy\": 0.9997634963836869, \"f1\": 0.00958012467913458, \"f2\": 0.006009166134754832, \"f0_5\": 0.023611016968300234, \"p4\": 0.018978412297121824, \"phi\": 0.06936843050925487}, {\"truth_threshold\": 45.37999898567796, \"match_probability\": 0.9999999999999781, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1454.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302507.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004783508410618468, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952164915893815, \"precision\": 1.0, \"recall\": 0.004783508410618468, \"specificity\": 1.0, \"npv\": 0.9997634890783063, \"accuracy\": 0.9997634893471691, \"f1\": 0.00952147078565231, \"f2\": 0.0059722434440868215, \"f0_5\": 0.023468495078717917, \"p4\": 0.01886331383522891, \"phi\": 0.06915473272766906}, {\"truth_threshold\": 45.39999898523092, \"match_probability\": 0.9999999999999785, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004737449870213613, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952625501297864, \"precision\": 1.0, \"recall\": 0.004737449870213613, \"specificity\": 1.0, \"npv\": 0.9997634781351884, \"accuracy\": 0.9997634784014748, \"f1\": 0.009430224524477653, \"f2\": 0.005914807062279632, \"f0_5\": 0.023246728507269446, \"p4\": 0.01868423170680082, \"phi\": 0.06882099505046303}, {\"truth_threshold\": 45.41999898478389, \"match_probability\": 0.9999999999999788, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1431.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302530.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004707840808524778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9952921591914752, \"precision\": 1.0, \"recall\": 0.004707840808524778, \"specificity\": 1.0, \"npv\": 0.999763471100327, \"accuracy\": 0.999763471364957, \"f1\": 0.009371561795986798, \"f2\": 0.005877882976320059, \"f0_5\": 0.02310412193034858, \"p4\": 0.018569081709833204, \"phi\": 0.0686055921052978}, {\"truth_threshold\": 45.43999898433685, \"match_probability\": 0.999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1416.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302545.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004658492372376719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9953415076276233, \"precision\": 1.0, \"recall\": 0.004658492372376719, \"specificity\": 1.0, \"npv\": 0.9997634593755583, \"accuracy\": 0.9997634596374275, \"f1\": 0.009273782897860678, \"f2\": 0.005816341619703268, \"f0_5\": 0.0228663706096084, \"p4\": 0.0183771202115546, \"phi\": 0.06824507637684935}, {\"truth_threshold\": 45.45999898388982, \"match_probability\": 0.9999999999999793, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1385.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302576.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0045565056043373985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9954434943956626, \"precision\": 1.0, \"recall\": 0.0045565056043373985, \"specificity\": 1.0, \"npv\": 0.9997634351443707, \"accuracy\": 0.999763435400533, \"f1\": 0.009071676065840063, \"f2\": 0.005689151342927255, \"f0_5\": 0.02237472576825277, \"p4\": 0.017980222083644727, \"phi\": 0.06749390857882609}, {\"truth_threshold\": 45.47999898344278, \"match_probability\": 0.9999999999999796, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1374.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302587.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004520316751162156, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9954796832488378, \"precision\": 1.0, \"recall\": 0.004520316751162156, \"specificity\": 1.0, \"npv\": 0.9997634265462075, \"accuracy\": 0.9997634268003447, \"f1\": 0.008999950873630603, \"f2\": 0.005644017751955689, \"f0_5\": 0.02220017643808348, \"p4\": 0.017839329660901116, \"phi\": 0.06722534763179806}, {\"truth_threshold\": 45.49999898299575, \"match_probability\": 0.9999999999999799, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1363.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302598.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004484127897986913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955158721020131, \"precision\": 1.0, \"recall\": 0.004484127897986913, \"specificity\": 1.0, \"npv\": 0.9997634179480446, \"accuracy\": 0.9997634182001562, \"f1\": 0.0089282205132908, \"f2\": 0.005598883345232159, \"f0_5\": 0.022025577464424573, \"p4\": 0.017698407049496826, \"phi\": 0.06695570949372112}, {\"truth_threshold\": 45.519998982548714, \"match_probability\": 0.9999999999999801, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1343.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302618.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004418329983122835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9955816700168771, \"precision\": 1.0, \"recall\": 0.004418329983122835, \"specificity\": 1.0, \"npv\": 0.9997634023150215, \"accuracy\": 0.9997634025634502, \"f1\": 0.008797788433823337, \"f2\": 0.0055168186975378475, \"f0_5\": 0.02170799753016975, \"p4\": 0.017442106745176593, \"phi\": 0.06646265580367186}, {\"truth_threshold\": 45.53999898210168, \"match_probability\": 0.9999999999999805, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1330.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0043755613384611845, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956244386615388, \"precision\": 1.0, \"recall\": 0.0043755613384611845, \"specificity\": 1.0, \"npv\": 0.9997633921535567, \"accuracy\": 0.9997633923995912, \"f1\": 0.008712998417902918, \"f2\": 0.005463475230328614, \"f0_5\": 0.021501482470633503, \"p4\": 0.01727545798625935, \"phi\": 0.06614019992648881}, {\"truth_threshold\": 45.559998981654644, \"match_probability\": 0.9999999999999807, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1328.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302633.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004368981546974776, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956310184530253, \"precision\": 1.0, \"recall\": 0.004368981546974776, \"specificity\": 1.0, \"npv\": 0.9997633905902544, \"accuracy\": 0.9997633908359206, \"f1\": 0.008699953159137736, \"f2\": 0.005455268441929325, \"f0_5\": 0.021469704759225668, \"p4\": 0.017249815968847344, \"phi\": 0.0660904516918273}, {\"truth_threshold\": 45.57999898120761, \"match_probability\": 0.999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1318.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302643.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004336082589542737, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956639174104572, \"precision\": 1.0, \"recall\": 0.004336082589542737, \"specificity\": 1.0, \"npv\": 0.9997633827737432, \"accuracy\": 0.9997633830175675, \"f1\": 0.008634724301376774, \"f2\": 0.005414234095379251, \"f0_5\": 0.021310791539066013, \"p4\": 0.01712159089089904, \"phi\": 0.06584114669192494}, {\"truth_threshold\": 45.599998980760574, \"match_probability\": 0.9999999999999812, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1313.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302648.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004319633110826718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9956803668891733, \"precision\": 1.0, \"recall\": 0.004319633110826718, \"specificity\": 1.0, \"npv\": 0.9997633788654876, \"accuracy\": 0.999763379108391, \"f1\": 0.008602108269947653, \"f2\": 0.0053937166692546645, \"f0_5\": 0.021231319511146037, \"p4\": 0.017057468981067636, \"phi\": 0.06571613952705498}, {\"truth_threshold\": 45.639998979866505, \"match_probability\": 0.9999999999999818, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1304.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302657.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004290024049137883, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9957099759508621, \"precision\": 1.0, \"recall\": 0.004290024049137883, \"specificity\": 1.0, \"npv\": 0.9997633718306277, \"accuracy\": 0.9997633720718733, \"f1\": 0.008543396720881856, \"f2\": 0.0053567848774347905, \"f0_5\": 0.021088243950876034, \"p4\": 0.016942033796648825, \"phi\": 0.06549052533458999}, {\"truth_threshold\": 45.65999897941947, \"match_probability\": 0.999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1294.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302667.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004257125091705844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9957428749082942, \"precision\": 1.0, \"recall\": 0.004257125091705844, \"specificity\": 1.0, \"npv\": 0.9997633640141168, \"accuracy\": 0.9997633642535202, \"f1\": 0.00847815760593602, \"f2\": 0.0053157489126130315, \"f0_5\": 0.0209292320233424, \"p4\": 0.016813748730016318, \"phi\": 0.06523892781700769}, {\"truth_threshold\": 45.679998978972435, \"match_probability\": 0.9999999999999822, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1268.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302693.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004171587802382542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958284121976174, \"precision\": 1.0, \"recall\": 0.004171587802382542, \"specificity\": 1.0, \"npv\": 0.9997633436911889, \"accuracy\": 0.9997633439258022, \"f1\": 0.008308515901175838, \"f2\": 0.005209052248272961, \"f0_5\": 0.020515608365449644, \"p4\": 0.016480090502430517, \"phi\": 0.06458018713050737}, {\"truth_threshold\": 45.6999989785254, \"match_probability\": 0.9999999999999825, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1262.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302699.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004151848427923319, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958481515720767, \"precision\": 1.0, \"recall\": 0.004151848427923319, \"specificity\": 1.0, \"npv\": 0.9997633390012827, \"accuracy\": 0.9997633392347904, \"f1\": 0.008269363711122687, \"f2\": 0.005184429293750914, \"f0_5\": 0.020420117213414496, \"p4\": 0.016403068428931945, \"phi\": 0.06442721356172283}, {\"truth_threshold\": 45.719998978078365, \"match_probability\": 0.9999999999999828, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1250.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302711.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0041123696790048726, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9958876303209951, \"precision\": 1.0, \"recall\": 0.0041123696790048726, \"specificity\": 1.0, \"npv\": 0.9997633296214702, \"accuracy\": 0.9997633298527667, \"f1\": 0.00819105471296906, \"f2\": 0.005135182656393015, \"f0_5\": 0.020229090402995847, \"p4\": 0.016248997246740053, \"phi\": 0.0641201715758488}, {\"truth_threshold\": 45.73999897763133, \"match_probability\": 0.999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1241.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302720.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.004082760617316037, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.995917239382684, \"precision\": 1.0, \"recall\": 0.004082760617316037, \"specificity\": 1.0, \"npv\": 0.9997633225866109, \"accuracy\": 0.999763322816249, \"f1\": 0.00813231892320496, \"f2\": 0.005098247041085874, \"f0_5\": 0.020085781338512583, \"p4\": 0.01613342019807252, \"phi\": 0.06388892173212539}, {\"truth_threshold\": 45.759998977184296, \"match_probability\": 0.9999999999999832, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1218.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302743.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0040070930152223475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9959929069847776, \"precision\": 1.0, \"recall\": 0.0040070930152223475, \"specificity\": 1.0, \"npv\": 0.9997633046086377, \"accuracy\": 0.999763304834037, \"f1\": 0.007982200610133725, \"f2\": 0.005003853542383215, \"f0_5\": 0.01971939527187833, \"p4\": 0.01583796444553498, \"phi\": 0.06329411153316622}, {\"truth_threshold\": 45.77999897673726, \"match_probability\": 0.9999999999999835, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1211.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302750.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00398406374501992, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960159362549801, \"precision\": 1.0, \"recall\": 0.00398406374501992, \"specificity\": 1.0, \"npv\": 0.9997632991370808, \"accuracy\": 0.9997632993611898, \"f1\": 0.007936507936507936, \"f2\": 0.004975124378109453, \"f0_5\": 0.0196078431372549, \"p4\": 0.0157480168171193, \"phi\": 0.06311196965468238}, {\"truth_threshold\": 45.799998976290226, \"match_probability\": 0.9999999999999837, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1203.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003957744579074289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960422554209257, \"precision\": 1.0, \"recall\": 0.003957744579074289, \"specificity\": 1.0, \"npv\": 0.999763292883873, \"accuracy\": 0.9997632931065074, \"f1\": 0.007884285171252179, \"f2\": 0.004942290642842882, \"f0_5\": 0.01948033021021916, \"p4\": 0.01564520448625587, \"phi\": 0.06290316170725133}, {\"truth_threshold\": 45.839998975396156, \"match_probability\": 0.9999999999999841, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1199.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302762.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003944584996101473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960554150038985, \"precision\": 1.0, \"recall\": 0.003944584996101473, \"specificity\": 1.0, \"npv\": 0.9997632897572691, \"accuracy\": 0.9997632899791662, \"f1\": 0.00785817276182986, \"f2\": 0.0049258736133398736, \"f0_5\": 0.019416563834989974, \"p4\": 0.015593792303210795, \"phi\": 0.06279849737397841}, {\"truth_threshold\": 45.85999897494912, \"match_probability\": 0.9999999999999843, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1198.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302763.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0039412951003582695, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960587048996418, \"precision\": 1.0, \"recall\": 0.0039412951003582695, \"specificity\": 1.0, \"npv\": 0.9997632889756182, \"accuracy\": 0.9997632891973308, \"f1\": 0.00785164455251197, \"f2\": 0.004921769339102513, \"f0_5\": 0.019400621208538863, \"p4\": 0.015580938630535305, \"phi\": 0.06277230402301379}, {\"truth_threshold\": 45.91999897360802, \"match_probability\": 0.999999999999985, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1192.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302769.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003921555725899046, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996078444274101, \"precision\": 1.0, \"recall\": 0.003921555725899046, \"specificity\": 1.0, \"npv\": 0.9997632842857124, \"accuracy\": 0.999763284506319, \"f1\": 0.007812474398088827, \"f2\": 0.004897143552039546, \"f0_5\": 0.019304956774387892, \"p4\": 0.015503811327837786, \"phi\": 0.06261491381479553}, {\"truth_threshold\": 45.93999897316098, \"match_probability\": 0.9999999999999852, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1189.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302772.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003911686038669435, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9960883139613306, \"precision\": 1.0, \"recall\": 0.003911686038669435, \"specificity\": 1.0, \"npv\": 0.9997632819407595, \"accuracy\": 0.9997632821608131, \"f1\": 0.007792888743241029, \"f2\": 0.0048848305674538, \"f0_5\": 0.01925711897951846, \"p4\": 0.01546524429045862, \"phi\": 0.06253607016708039}, {\"truth_threshold\": 45.95999897271395, \"match_probability\": 0.9999999999999853, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1177.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302784.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003872207289750988, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996127792710249, \"precision\": 1.0, \"recall\": 0.003872207289750988, \"specificity\": 1.0, \"npv\": 0.9997632725609481, \"accuracy\": 0.9997632727787894, \"f1\": 0.007714542272676625, \"f2\": 0.004835578022071928, \"f0_5\": 0.01906573060462826, \"p4\": 0.015310953562780494, \"phi\": 0.06221969649585095}, {\"truth_threshold\": 45.97999897226691, \"match_probability\": 0.9999999999999856, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1174.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003862337602521376, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961376623974786, \"precision\": 1.0, \"recall\": 0.003862337602521376, \"specificity\": 1.0, \"npv\": 0.9997632702159952, \"accuracy\": 0.9997632704332835, \"f1\": 0.0076949546921854265, \"f2\": 0.004823264733964493, \"f0_5\": 0.019017874209883462, \"p4\": 0.015272375235329204, \"phi\": 0.06214035140047872}, {\"truth_threshold\": 45.99999897181988, \"match_probability\": 0.9999999999999858, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1173.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302788.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003859047706778172, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961409522932219, \"precision\": 1.0, \"recall\": 0.003859047706778172, \"specificity\": 1.0, \"npv\": 0.9997632694343443, \"accuracy\": 0.9997632696514482, \"f1\": 0.007688425413097197, \"f2\": 0.004819160291105218, \"f0_5\": 0.0190019212513729, \"p4\": 0.015259515290942048, \"phi\": 0.062113880511779775}, {\"truth_threshold\": 46.01999897137284, \"match_probability\": 0.999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1171.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0038524679152917643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961475320847082, \"precision\": 1.0, \"recall\": 0.0038524679152917643, \"specificity\": 1.0, \"npv\": 0.9997632678710424, \"accuracy\": 0.9997632680877776, \"f1\": 0.007675366726531468, \"f2\": 0.004810951385151374, \"f0_5\": 0.01897001409386188, \"p4\": 0.01523379464926857, \"phi\": 0.06206090486256574}, {\"truth_threshold\": 46.03999897092581, \"match_probability\": 0.9999999999999862, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1164.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302797.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003829438645089337, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961705613549107, \"precision\": 1.0, \"recall\": 0.003829438645089337, \"specificity\": 1.0, \"npv\": 0.9997632623994859, \"accuracy\": 0.9997632626149304, \"f1\": 0.00762965997541991, \"f2\": 0.004782220001840579, \"f0_5\": 0.018858326015741195, \"p4\": 0.015143764497198687, \"phi\": 0.06187513291277185}, {\"truth_threshold\": 46.05999897047877, \"match_probability\": 0.9999999999999863, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1163.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302798.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003826148749346133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9961738512506538, \"precision\": 1.0, \"recall\": 0.003826148749346133, \"specificity\": 1.0, \"npv\": 0.999763261617835, \"accuracy\": 0.9997632618330952, \"f1\": 0.007623130268349917, \"f2\": 0.00477811549152963, \"f0_5\": 0.018842368921594358, \"p4\": 0.0151309020428415, \"phi\": 0.06184854851232396}, {\"truth_threshold\": 46.07999897003174, \"match_probability\": 0.9999999999999866, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1153.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302808.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003793249791914094, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962067502080859, \"precision\": 1.0, \"recall\": 0.003793249791914094, \"specificity\": 1.0, \"npv\": 0.9997632538013258, \"accuracy\": 0.9997632540147421, \"f1\": 0.007557830843553557, \"f2\": 0.004737070017428145, \"f0_5\": 0.01868277522660764, \"p4\": 0.01500226369099876, \"phi\": 0.06158207332044965}, {\"truth_threshold\": 46.0999989695847, \"match_probability\": 0.9999999999999868, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1147.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003773510417454871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962264895825451, \"precision\": 1.0, \"recall\": 0.003773510417454871, \"specificity\": 1.0, \"npv\": 0.9997632491114203, \"accuracy\": 0.9997632493237303, \"f1\": 0.007518649134077114, \"f2\": 0.0047124424091879065, \"f0_5\": 0.01858699914762323, \"p4\": 0.014925068627039038, \"phi\": 0.061421633285923566}, {\"truth_threshold\": 46.11999896913767, \"match_probability\": 0.9999999999999869, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1131.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0037208720855636084, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9962791279144364, \"precision\": 1.0, \"recall\": 0.0037208720855636084, \"specificity\": 1.0, \"npv\": 0.999763236605006, \"accuracy\": 0.9997632368143654, \"f1\": 0.007414157041154799, \"f2\": 0.004646767599991783, \"f0_5\": 0.018331523412807756, \"p4\": 0.014719170915543074, \"phi\": 0.06099172992509962}, {\"truth_threshold\": 46.139998968690634, \"match_probability\": 0.9999999999999871, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1119.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0036813933366451617, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963186066633548, \"precision\": 1.0, \"recall\": 0.0036813933366451617, \"specificity\": 1.0, \"npv\": 0.9997632272251954, \"accuracy\": 0.9997632274323417, \"f1\": 0.007335780778812115, \"f2\": 0.004597510359805516, \"f0_5\": 0.018139847035213024, \"p4\": 0.014564705419747052, \"phi\": 0.060667303244249265}, {\"truth_threshold\": 46.1599989682436, \"match_probability\": 0.9999999999999872, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1117.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003674813545158754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963251864548412, \"precision\": 1.0, \"recall\": 0.003674813545158754, \"specificity\": 1.0, \"npv\": 0.9997632256618937, \"accuracy\": 0.9997632258686711, \"f1\": 0.007322717468975147, \"f2\": 0.0045893007253313784, \"f0_5\": 0.018107895171984478, \"p4\": 0.014538957651736241, \"phi\": 0.060613063308283095}, {\"truth_threshold\": 46.179998967796564, \"match_probability\": 0.9999999999999875, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1111.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302850.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0036550741706995304, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9963449258293005, \"precision\": 1.0, \"recall\": 0.0036550741706995304, \"specificity\": 1.0, \"npv\": 0.9997632209719884, \"accuracy\": 0.9997632211776593, \"f1\": 0.00728352651177427, \"f2\": 0.0045646716600038625, \"f0_5\": 0.018012029636354794, \"p4\": 0.014461708314449095, \"phi\": 0.06045005149534682}, {\"truth_threshold\": 46.19999896734953, \"match_probability\": 0.9999999999999877, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1092.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302869.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035925661515786565, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964074338484213, \"precision\": 1.0, \"recall\": 0.0035925661515786565, \"specificity\": 1.0, \"npv\": 0.9997632061206223, \"accuracy\": 0.9997632063227885, \"f1\": 0.007159411643222653, \"f2\": 0.004486678017578574, \"f0_5\": 0.017708356982314346, \"p4\": 0.014217025693214652, \"phi\": 0.059930922351509854}, {\"truth_threshold\": 46.219998966902494, \"match_probability\": 0.9999999999999878, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1083.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035629570898898216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964370429101101, \"precision\": 1.0, \"recall\": 0.0035629570898898216, \"specificity\": 1.0, \"npv\": 0.9997631990857648, \"accuracy\": 0.9997631992862707, \"f1\": 0.007100614993246876, \"f2\": 0.00444973281059587, \"f0_5\": 0.01756445978338788, \"p4\": 0.014101091705486409, \"phi\": 0.05968344308427216}, {\"truth_threshold\": 46.23999896645546, \"match_probability\": 0.999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1079.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302882.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035497975069170057, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996450202493083, \"precision\": 1.0, \"recall\": 0.0035497975069170057, \"specificity\": 1.0, \"npv\": 0.9997631959591615, \"accuracy\": 0.9997631961589295, \"f1\": 0.007074482035142932, \"f2\": 0.004433312543192955, \"f0_5\": 0.017500494684974877, \"p4\": 0.014049558946754175, \"phi\": 0.05957312229960093}, {\"truth_threshold\": 46.259998966008425, \"match_probability\": 0.9999999999999881, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1078.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302883.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003546507611173802, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964534923888262, \"precision\": 1.0, \"recall\": 0.003546507611173802, \"specificity\": 1.0, \"npv\": 0.9997631951775107, \"accuracy\": 0.9997631953770941, \"f1\": 0.0070679486885283525, \"f2\": 0.004429207459475628, \"f0_5\": 0.01748450237289675, \"p4\": 0.014036675127950093, \"phi\": 0.059545510167169455}, {\"truth_threshold\": 46.27999896556139, \"match_probability\": 0.9999999999999883, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1076.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003539927819687394, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964600721803126, \"precision\": 1.0, \"recall\": 0.003539927819687394, \"specificity\": 1.0, \"npv\": 0.9997631936142091, \"accuracy\": 0.9997631938134235, \"f1\": 0.0070548818667899305, \"f2\": 0.00442099727180094, \"f0_5\": 0.01745251650365757, \"p4\": 0.014010906735345087, \"phi\": 0.05949024745430509}, {\"truth_threshold\": 46.299998965114355, \"match_probability\": 0.9999999999999885, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1074.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302887.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003533348028200986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964666519717991, \"precision\": 1.0, \"recall\": 0.003533348028200986, \"specificity\": 1.0, \"npv\": 0.9997631920509074, \"accuracy\": 0.999763192249753, \"f1\": 0.0070418148737030175, \"f2\": 0.004412787057139429, \"f0_5\": 0.0174205289742001, \"p4\": 0.013985137336028464, \"phi\": 0.059434933358261596}, {\"truth_threshold\": 46.31999896466732, \"match_probability\": 0.9999999999999886, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1072.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302889.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035267682367145785, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964732317632854, \"precision\": 1.0, \"recall\": 0.0035267682367145785, \"specificity\": 1.0, \"npv\": 0.9997631904876058, \"accuracy\": 0.9997631906860823, \"f1\": 0.007028747709264244, \"f2\": 0.004404576815490962, \"f0_5\": 0.01738853978439508, \"p4\": 0.013959366929941224, \"phi\": 0.059379567735443436}, {\"truth_threshold\": 46.339998964220285, \"match_probability\": 0.9999999999999888, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1065.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302896.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0035037389665121513, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9964962610334879, \"precision\": 1.0, \"recall\": 0.0035037389665121513, \"specificity\": 1.0, \"npv\": 0.9997631850160501, \"accuracy\": 0.9997631852132352, \"f1\": 0.006983011284283963, \"f2\": 0.0043758407571971285, \"f0_5\": 0.017276564542974035, \"p4\": 0.013869162579465397, \"phi\": 0.05918538019329632}, {\"truth_threshold\": 46.35999896377325, \"match_probability\": 0.9999999999999889, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1062.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034938692792825395, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965061307207175, \"precision\": 1.0, \"recall\": 0.0034938692792825395, \"specificity\": 1.0, \"npv\": 0.9997631826710976, \"accuracy\": 0.9997631828677292, \"f1\": 0.00696340931667448, \"f2\": 0.004363525202439629, \"f0_5\": 0.017228568925631634, \"p4\": 0.013830499795880547, \"phi\": 0.05910196164673628}, {\"truth_threshold\": 46.379998963326216, \"match_probability\": 0.9999999999999891, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1059.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034839995920529277, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965160004079471, \"precision\": 1.0, \"recall\": 0.0034839995920529277, \"specificity\": 1.0, \"npv\": 0.9997631803261453, \"accuracy\": 0.9997631805222233, \"f1\": 0.006943806963477805, \"f2\": 0.004351209586959684, \"f0_5\": 0.01718056957076156, \"p4\": 0.013791834746265124, \"phi\": 0.05901842519422073}, {\"truth_threshold\": 46.39999896287918, \"match_probability\": 0.9999999999999892, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1048.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302913.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003447810738877685, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965521892611223, \"precision\": 1.0, \"recall\": 0.003447810738877685, \"specificity\": 1.0, \"npv\": 0.9997631717279866, \"accuracy\": 0.999763171922035, \"f1\": 0.006871928369326806, \"f2\": 0.004306051810678351, \"f0_5\": 0.017004539952556037, \"p4\": 0.013650043507304888, \"phi\": 0.0587111079764142}, {\"truth_threshold\": 46.419998962432146, \"match_probability\": 0.9999999999999893, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1045.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034379410516480733, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965620589483519, \"precision\": 1.0, \"recall\": 0.0034379410516480733, \"specificity\": 1.0, \"npv\": 0.9997631693830342, \"accuracy\": 0.9997631695765291, \"f1\": 0.006852324216572789, \"f2\": 0.004293735911821046, \"f0_5\": 0.016956523150116344, \"p4\": 0.01361136788024549, \"phi\": 0.05862701460886201}, {\"truth_threshold\": 46.43999896198511, \"match_probability\": 0.9999999999999896, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1044.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0034346511559048692, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9965653488440951, \"precision\": 1.0, \"recall\": 0.0034346511559048692, \"specificity\": 1.0, \"npv\": 0.9997631686013835, \"accuracy\": 0.9997631687946937, \"f1\": 0.006845789413288307, \"f2\": 0.004289630598707523, \"f0_5\": 0.016940516718213002, \"p4\": 0.01359847550075557, \"phi\": 0.0585989566687655}, {\"truth_threshold\": 46.459998961538076, \"match_probability\": 0.9999999999999897, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1032.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033951724069864225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966048275930136, \"precision\": 1.0, \"recall\": 0.0033951724069864225, \"specificity\": 1.0, \"npv\": 0.9997631592215741, \"accuracy\": 0.9997631594126701, \"f1\": 0.006767368431406622, \"f2\": 0.00424036631505593, \"f0_5\": 0.016748407116125536, \"p4\": 0.013443747295469962, \"phi\": 0.05826120743436976}, {\"truth_threshold\": 46.47999896109104, \"match_probability\": 0.9999999999999898, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1026.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302935.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033754330325271994, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966245669674728, \"precision\": 1.0, \"recall\": 0.0033754330325271994, \"specificity\": 1.0, \"npv\": 0.9997631545316695, \"accuracy\": 0.9997631547216582, \"f1\": 0.006728155626305384, \"f2\": 0.004215733808870298, \"f0_5\": 0.016652329865450472, \"p4\": 0.01336636958548131, \"phi\": 0.058091596436229846}, {\"truth_threshold\": 46.49999896064401, \"match_probability\": 0.9999999999999899, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1020.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302941.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003355693658067976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996644306341932, \"precision\": 1.0, \"recall\": 0.003355693658067976, \"specificity\": 1.0, \"npv\": 0.9997631498417651, \"accuracy\": 0.9997631500306464, \"f1\": 0.006688941278309141, \"f2\": 0.004191101059773319, \"f0_5\": 0.016556237643690287, \"p4\": 0.013288982801801153, \"phi\": 0.05792148877138842}, {\"truth_threshold\": 46.51999896019697, \"match_probability\": 0.9999999999999901, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1017.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003345823970838364, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966541760291616, \"precision\": 1.0, \"recall\": 0.003345823970838364, \"specificity\": 1.0, \"npv\": 0.9997631474968128, \"accuracy\": 0.9997631476851405, \"f1\": 0.006669333525696935, \"f2\": 0.004178784594131951, \"f0_5\": 0.01650818591755971, \"p4\": 0.013250286006827969, \"phi\": 0.05783624731996057}, {\"truth_threshold\": 46.53999895974994, \"match_probability\": 0.9999999999999902, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1014.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302947.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033359542836087523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966640457163912, \"precision\": 1.0, \"recall\": 0.0033359542836087523, \"specificity\": 1.0, \"npv\": 0.9997631451518606, \"accuracy\": 0.9997631453396346, \"f1\": 0.00664972538732683, \"f2\": 0.0041664680677613985, \"f0_5\": 0.01646013044734544, \"p4\": 0.013211586942833314, \"phi\": 0.05775088005098717}, {\"truth_threshold\": 46.5599989593029, \"match_probability\": 0.9999999999999903, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1006.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0033096351176631214, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9966903648823369, \"precision\": 1.0, \"recall\": 0.0033096351176631214, \"specificity\": 1.0, \"npv\": 0.9997631388986546, \"accuracy\": 0.9997631390849522, \"f1\": 0.006597435132325792, \"f2\": 0.004133623700538275, \"f0_5\": 0.01633196421903664, \"p4\": 0.013108378344335833, \"phi\": 0.05752261462976192}, {\"truth_threshold\": 46.57999895885587, \"match_probability\": 0.9999999999999905, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1000.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302961.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003289895743203898, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967101042567961, \"precision\": 1.0, \"recall\": 0.003289895743203898, \"specificity\": 1.0, \"npv\": 0.9997631342087503, \"accuracy\": 0.9997631343939403, \"f1\": 0.0065582156406884815, \"f2\": 0.004108990141710852, \"f0_5\": 0.01623582206837879, \"p4\": 0.013030961303487283, \"phi\": 0.05735081934415196}, {\"truth_threshold\": 46.59999895840883, \"match_probability\": 0.9999999999999907, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 984.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302977.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0032372574113126353, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967627425886874, \"precision\": 1.0, \"recall\": 0.0032372574113126353, \"specificity\": 1.0, \"npv\": 0.9997631217023388, \"accuracy\": 0.9997631218845754, \"f1\": 0.006453622784436537, \"f2\": 0.004043299463851916, \"f0_5\": 0.015979369724290916, \"p4\": 0.012824471462786532, \"phi\": 0.05689016237705736}, {\"truth_threshold\": 46.6199989579618, \"match_probability\": 0.9999999999999908, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 977.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302984.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003214228141110208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9967857718588898, \"precision\": 1.0, \"recall\": 0.003214228141110208, \"specificity\": 1.0, \"npv\": 0.9997631162307838, \"accuracy\": 0.9997631164117283, \"f1\": 0.006407859958417777, \"f2\": 0.00401455924905964, \"f0_5\": 0.015867138295833617, \"p4\": 0.012734111844482419, \"phi\": 0.05668744784017906}, {\"truth_threshold\": 46.63999895751476, \"match_probability\": 0.9999999999999909, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 971.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302990.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003194488766650985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.996805511233349, \"precision\": 1.0, \"recall\": 0.003194488766650985, \"specificity\": 1.0, \"npv\": 0.9997631115408797, \"accuracy\": 0.9997631117207164, \"f1\": 0.006368633006703134, \"f2\": 0.003989924516052152, \"f0_5\": 0.015770923679124235, \"p4\": 0.012656650899209067, \"phi\": 0.05651311378016058}, {\"truth_threshold\": 46.65999895706773, \"match_probability\": 0.999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 962.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 302999.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0031648797049621496, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968351202950378, \"precision\": 1.0, \"recall\": 0.0031648797049621496, \"specificity\": 1.0, \"npv\": 0.9997631045060236, \"accuracy\": 0.9997631046841987, \"f1\": 0.006309789684608901, \"f2\": 0.0039529719610192585, \"f0_5\": 0.015626573621953875, \"p4\": 0.012540442440167042, \"phi\": 0.05625059963432449}, {\"truth_threshold\": 46.69999895617366, \"match_probability\": 0.9999999999999912, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 952.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303009.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0031319807475301106, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968680192524699, \"precision\": 1.0, \"recall\": 0.0031319807475301106, \"specificity\": 1.0, \"npv\": 0.9997630966895168, \"accuracy\": 0.9997630968658456, \"f1\": 0.006244404141509218, \"f2\": 0.003911912925420531, \"f0_5\": 0.015466145063342962, \"p4\": 0.0124112979404416, \"phi\": 0.055957472878272935}, {\"truth_threshold\": 46.71999895572662, \"match_probability\": 0.9999999999999913, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 948.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303013.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0031188211645572952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968811788354427, \"precision\": 1.0, \"recall\": 0.0031188211645572952, \"specificity\": 1.0, \"npv\": 0.9997630935629142, \"accuracy\": 0.9997630937385044, \"f1\": 0.006218248723389602, \"f2\": 0.003895489122216451, \"f0_5\": 0.015401961963002798, \"p4\": 0.01235963306831892, \"phi\": 0.055839791329725545}, {\"truth_threshold\": 46.73999895527959, \"match_probability\": 0.9999999999999915, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 945.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303016.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0031089514773276834, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9968910485226723, \"precision\": 1.0, \"recall\": 0.0031089514773276834, \"specificity\": 1.0, \"npv\": 0.9997630912179621, \"accuracy\": 0.9997630913929985, \"f1\": 0.006198631709444878, \"f2\": 0.003883171198950681, \"f0_5\": 0.01535382025794418, \"p4\": 0.012320881761698809, \"phi\": 0.05575136715292079}, {\"truth_threshold\": 46.759998954832554, \"match_probability\": 0.9999999999999916, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 935.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303026.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0030760525198956445, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969239474801044, \"precision\": 1.0, \"recall\": 0.0030760525198956445, \"specificity\": 1.0, \"npv\": 0.9997630834014556, \"accuracy\": 0.9997630835746454, \"f1\": 0.006133238874895046, \"f2\": 0.0038421110160513946, \"f0_5\": 0.015193320788687719, \"p4\": 0.012191694316489527, \"phi\": 0.05545560162865143}, {\"truth_threshold\": 46.77999895438552, \"match_probability\": 0.9999999999999917, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 934.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303027.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003072762624152441, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969272373758475, \"precision\": 1.0, \"recall\": 0.003072762624152441, \"specificity\": 1.0, \"npv\": 0.999763082619805, \"accuracy\": 0.9997630827928101, \"f1\": 0.006126699355515833, \"f2\": 0.003838004960641958, \"f0_5\": 0.015177268546654663, \"p4\": 0.012178774182127818, \"phi\": 0.05542593827154905}, {\"truth_threshold\": 46.799998953938484, \"match_probability\": 0.9999999999999918, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 924.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303037.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.003039863666720402, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969601363332796, \"precision\": 1.0, \"recall\": 0.003039863666720402, \"specificity\": 1.0, \"npv\": 0.9997630748032985, \"accuracy\": 0.999763074974457, \"f1\": 0.006061301802318907, \"f2\": 0.003796944035346097, \"f0_5\": 0.01501672316898364, \"p4\": 0.012049558937248045, \"phi\": 0.05512842684516962}, {\"truth_threshold\": 46.81999895349145, \"match_probability\": 0.9999999999999919, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 915.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303046.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0030102546050315665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9969897453949684, \"precision\": 1.0, \"recall\": 0.0030102546050315665, \"specificity\": 1.0, \"npv\": 0.9997630677684429, \"accuracy\": 0.9997630679379393, \"f1\": 0.006002440336399061, \"f2\": 0.003759988625520748, \"f0_5\": 0.014872196631569367, \"p4\": 0.011933243602483542, \"phi\": 0.05485928707785439}, {\"truth_threshold\": 46.839998953044415, \"match_probability\": 0.999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 908.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303053.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0029872253348291393, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970127746651709, \"precision\": 1.0, \"recall\": 0.0029872253348291393, \"specificity\": 1.0, \"npv\": 0.9997630622968886, \"accuracy\": 0.9997630624650922, \"f1\": 0.005956656793573633, \"f2\": 0.003731245151025024, \"f0_5\": 0.014759763713738609, \"p4\": 0.011842761959505899, \"phi\": 0.05464903977673925}, {\"truth_threshold\": 46.85999895259738, \"match_probability\": 0.9999999999999921, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 905.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303056.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0029773556475995275, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970226443524005, \"precision\": 1.0, \"recall\": 0.0029773556475995275, \"specificity\": 1.0, \"npv\": 0.9997630599519367, \"accuracy\": 0.9997630601195863, \"f1\": 0.005937034631608641, \"f2\": 0.003718926417856107, \"f0_5\": 0.014711571911138855, \"p4\": 0.011803980318850691, \"phi\": 0.054558685768714074}, {\"truth_threshold\": 46.879998952150345, \"match_probability\": 0.9999999999999922, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 894.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303067.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002941166794424285, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970588332055758, \"precision\": 1.0, \"recall\": 0.002941166794424285, \"specificity\": 1.0, \"npv\": 0.9997630513537801, \"accuracy\": 0.9997630515193979, \"f1\": 0.005865083400305063, \"f2\": 0.003673757209851258, \"f0_5\": 0.01453483645870253, \"p4\": 0.011661761491634285, \"phi\": 0.054226099702394594}, {\"truth_threshold\": 46.89999895170331, \"match_probability\": 0.9999999999999923, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 891.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303070.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002931297107194673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970687028928054, \"precision\": 1.0, \"recall\": 0.002931297107194673, \"specificity\": 1.0, \"npv\": 0.9997630490088283, \"accuracy\": 0.999763049173892, \"f1\": 0.005845459436054216, \"f2\": 0.003661438193197368, \"f0_5\": 0.01448662710348752, \"p4\": 0.011622969225651458, \"phi\": 0.0541350397934619}, {\"truth_threshold\": 46.919998951256275, \"match_probability\": 0.9999999999999925, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 884.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303077.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002908267836992246, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9970917321630077, \"precision\": 1.0, \"recall\": 0.002908267836992246, \"specificity\": 1.0, \"npv\": 0.9997630435372742, \"accuracy\": 0.9997630437010449, \"f1\": 0.005799668684085355, \"f2\": 0.0036326935847617544, \"f0_5\": 0.014374123975193253, \"p4\": 0.01153244508136248, \"phi\": 0.05392196865965608}, {\"truth_threshold\": 46.93999895080924, \"match_probability\": 0.9999999999999926, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 876.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303085.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0028819486710466146, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971180513289534, \"precision\": 1.0, \"recall\": 0.0028819486710466146, \"specificity\": 1.0, \"npv\": 0.9997630372840696, \"accuracy\": 0.9997630374463624, \"f1\": 0.005747333821025663, \"f2\": 0.0035998421986981393, \"f0_5\": 0.014245523880766917, \"p4\": 0.011428973730365008, \"phi\": 0.053677423155944724}, {\"truth_threshold\": 46.959998950362206, \"match_probability\": 0.9999999999999927, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 870.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303091.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002862209296587391, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971377907034126, \"precision\": 1.0, \"recall\": 0.002862209296587391, \"specificity\": 1.0, \"npv\": 0.9997630325941661, \"accuracy\": 0.9997630327553506, \"f1\": 0.005708080871040019, \"f2\": 0.0035752033756494953, \"f0_5\": 0.014149056241685396, \"p4\": 0.01135135958466512, \"phi\": 0.05349328038431954}, {\"truth_threshold\": 46.97999894991517, \"match_probability\": 0.9999999999999928, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 864.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303097.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002842469922128168, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971575300778718, \"precision\": 1.0, \"recall\": 0.002842469922128168, \"specificity\": 1.0, \"npv\": 0.9997630279042627, \"accuracy\": 0.9997630280643387, \"f1\": 0.0056688263757893875, \"f2\": 0.0035505643095960575, \"f0_5\": 0.014052573540175072, \"p4\": 0.0112737363236512, \"phi\": 0.05330850153656217}, {\"truth_threshold\": 46.999998949468136, \"match_probability\": 0.9999999999999929, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 857.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303104.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0028194406519257403, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971805593480743, \"precision\": 1.0, \"recall\": 0.0028194406519257403, \"specificity\": 1.0, \"npv\": 0.9997630224327089, \"accuracy\": 0.9997630225914916, \"f1\": 0.005623027511498665, \"f2\": 0.0035218184253978588, \"f0_5\": 0.013939991346469782, \"p4\": 0.01118316432958165, \"phi\": 0.053092113423171675}, {\"truth_threshold\": 47.0199989490211, \"match_probability\": 0.999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 852.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303109.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0028029911732097208, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9971970088267903, \"precision\": 1.0, \"recall\": 0.0028029911732097208, \"specificity\": 1.0, \"npv\": 0.999763018524456, \"accuracy\": 0.9997630186823151, \"f1\": 0.005590312749128154, \"f2\": 0.0035012854484604205, \"f0_5\": 0.013859562935754745, \"p4\": 0.01111846244925711, \"phi\": 0.05293700894672419}, {\"truth_threshold\": 47.039998948574066, \"match_probability\": 0.9999999999999931, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 843.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303118.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002773382111520886, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972266178884791, \"precision\": 1.0, \"recall\": 0.002773382111520886, \"specificity\": 1.0, \"npv\": 0.9997630114896012, \"accuracy\": 0.9997630116457973, \"f1\": 0.0055314234721329115, \"f2\": 0.003464325664694371, \"f0_5\": 0.013714765417316071, \"p4\": 0.011001983103815243, \"phi\": 0.052656669585395444}, {\"truth_threshold\": 47.05999894812703, \"match_probability\": 0.9999999999999932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 837.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303124.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0027536427370616627, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972463572629383, \"precision\": 1.0, \"recall\": 0.0027536427370616627, \"specificity\": 1.0, \"npv\": 0.999763006799698, \"accuracy\": 0.9997630069547855, \"f1\": 0.005492162022060512, \"f2\": 0.0034396855050748717, \"f0_5\": 0.013618214891200714, \"p4\": 0.010924318804009158, \"phi\": 0.05246894455253429}, {\"truth_threshold\": 47.07999894768, \"match_probability\": 0.9999999999999932, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 828.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303133.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0027240336753728274, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9972759663246272, \"precision\": 1.0, \"recall\": 0.0027240336753728274, \"specificity\": 1.0, \"npv\": 0.9997629997648433, \"accuracy\": 0.9997629999182677, \"f1\": 0.00543326694861035, \"f2\": 0.0034027248099734357, \"f0_5\": 0.013473360822460808, \"p4\": 0.010807805246013661, \"phi\": 0.05218609085523833}, {\"truth_threshold\": 47.09999894723296, \"match_probability\": 0.9999999999999933, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 814.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303147.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002677975134967973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973220248650321, \"precision\": 1.0, \"recall\": 0.002677975134967973, \"specificity\": 1.0, \"npv\": 0.9997629888217362, \"accuracy\": 0.9997629889725734, \"f1\": 0.0053416454761709455, \"f2\": 0.0033452293084827453, \"f0_5\": 0.013247964793614937, \"p4\": 0.01062652111555724, \"phi\": 0.051743022958905996}, {\"truth_threshold\": 47.11999894678593, \"match_probability\": 0.9999999999999934, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 813.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303148.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002674685239224769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973253147607752, \"precision\": 1.0, \"recall\": 0.002674685239224769, \"specificity\": 1.0, \"npv\": 0.9997629880400857, \"accuracy\": 0.9997629881907382, \"f1\": 0.005335100763188461, \"f2\": 0.0033411224363152476, \"f0_5\": 0.013231861932926015, \"p4\": 0.010613570347188692, \"phi\": 0.05171122998763486}, {\"truth_threshold\": 47.13999894633889, \"match_probability\": 0.9999999999999936, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 809.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303152.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0026615256562519535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997338474343748, \"precision\": 1.0, \"recall\": 0.0026615256562519535, \"specificity\": 1.0, \"npv\": 0.9997629849134837, \"accuracy\": 0.9997629850633969, \"f1\": 0.005308921481773141, \"f2\": 0.00332469488013427, \"f0_5\": 0.013167446296676074, \"p4\": 0.010561764737366171, \"phi\": 0.0515838621520168}, {\"truth_threshold\": 47.15999894589186, \"match_probability\": 0.9999999999999937, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 802.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303159.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0026384963860495263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973615036139505, \"precision\": 1.0, \"recall\": 0.0026384963860495263, \"specificity\": 1.0, \"npv\": 0.9997629794419303, \"accuracy\": 0.9997629795905497, \"f1\": 0.005263106085712505, \"f2\": 0.0032959463968977006, \"f0_5\": 0.013054702785762887, \"p4\": 0.010471095154088155, \"phi\": 0.05136020841238516}, {\"truth_threshold\": 47.17999894544482, \"match_probability\": 0.9999999999999938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 795.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303166.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0026154671158470986, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973845328841529, \"precision\": 1.0, \"recall\": 0.0026154671158470986, \"specificity\": 1.0, \"npv\": 0.999762973970377, \"accuracy\": 0.9997629741177027, \"f1\": 0.005217288584966334, \"f2\": 0.0032671975828491443, \"f0_5\": 0.012941938718699229, \"p4\": 0.010380413139051622, \"phi\": 0.05113557648116446}, {\"truth_threshold\": 47.19999894499779, \"match_probability\": 0.9999999999999938, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 794.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303167.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002612177220103895, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9973878227798961, \"precision\": 1.0, \"recall\": 0.002612177220103895, \"specificity\": 1.0, \"npv\": 0.9997629731887264, \"accuracy\": 0.9997629733358673, \"f1\": 0.00521074305589736, \"f2\": 0.003263090582408243, \"f0_5\": 0.012925827887880652, \"p4\": 0.010367457550488455, \"phi\": 0.05110340560145608}, {\"truth_threshold\": 47.21999894455075, \"match_probability\": 0.9999999999999939, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 789.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303172.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025957277413878755, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974042722586122, \"precision\": 1.0, \"recall\": 0.0025957277413878755, \"specificity\": 1.0, \"npv\": 0.9997629692804741, \"accuracy\": 0.9997629694266909, \"f1\": 0.005178014766201805, \"f2\": 0.003242555478932431, \"f0_5\": 0.012845267438793684, \"p4\": 0.010302675800988538, \"phi\": 0.050942246457862855}, {\"truth_threshold\": 47.23999894410372, \"match_probability\": 0.999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 783.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303178.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002575988366928652, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974240116330714, \"precision\": 1.0, \"recall\": 0.002575988366928652, \"specificity\": 1.0, \"npv\": 0.9997629645905713, \"accuracy\": 0.9997629647356789, \"f1\": 0.0051387394009398055, \"f2\": 0.0032179131319623844, \"f0_5\": 0.012748581048737679, \"p4\": 0.010224929325899289, \"phi\": 0.0507481799325987}, {\"truth_threshold\": 47.25999894365668, \"match_probability\": 0.9999999999999941, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 780.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303181.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00256611867969904, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997433881320301, \"precision\": 1.0, \"recall\": 0.00256611867969904, \"specificity\": 1.0, \"npv\": 0.9997629622456199, \"accuracy\": 0.999762962390173, \"f1\": 0.005119101138343708, \"f2\": 0.003205591867331238, \"f0_5\": 0.012700232186296123, \"p4\": 0.010186052661466416, \"phi\": 0.05065086783747868}, {\"truth_threshold\": 47.27999894320965, \"match_probability\": 0.9999999999999941, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 778.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303183.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025595388882126324, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974404611117874, \"precision\": 1.0, \"recall\": 0.0025595388882126324, \"specificity\": 1.0, \"npv\": 0.9997629606823191, \"accuracy\": 0.9997629608265024, \"f1\": 0.0051060087484700025, \"f2\": 0.0031973776571523446, \"f0_5\": 0.012667997511992263, \"p4\": 0.010160133615823203, \"phi\": 0.05058588910813956}, {\"truth_threshold\": 47.29999894276261, \"match_probability\": 0.9999999999999942, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 772.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303189.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025397995137534093, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974602004862466, \"precision\": 1.0, \"recall\": 0.0025397995137534093, \"specificity\": 1.0, \"npv\": 0.9997629559924163, \"accuracy\": 0.9997629561354906, \"f1\": 0.005066730547725386, \"f2\": 0.0031727348645751823, \"f0_5\": 0.012571283410791112, \"p4\": 0.010082370385334796, \"phi\": 0.05039045018153945}, {\"truth_threshold\": 47.31999894231558, \"match_probability\": 0.9999999999999943, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 771.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303190.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0025365096180102052, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974634903819898, \"precision\": 1.0, \"recall\": 0.0025365096180102052, \"specificity\": 1.0, \"npv\": 0.9997629552107659, \"accuracy\": 0.9997629553536553, \"f1\": 0.0050601840305579985, \"f2\": 0.00316862770884791, \"f0_5\": 0.012555162924001368, \"p4\": 0.010069408958197726, \"phi\": 0.05035780328432142}, {\"truth_threshold\": 47.379998940974474, \"match_probability\": 0.9999999999999946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 767.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303194.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00252335003503739, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9974766499649627, \"precision\": 1.0, \"recall\": 0.00252335003503739, \"specificity\": 1.0, \"npv\": 0.9997629520841641, \"accuracy\": 0.9997629522263141, \"f1\": 0.00503399753222546, \"f2\": 0.0031521990184208426, \"f0_5\": 0.012490676776460855, \"p4\": 0.010017560710169144, \"phi\": 0.050227003495835386}, {\"truth_threshold\": 47.39999894052744, \"match_probability\": 0.9999999999999946, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 736.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303225.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0024213632669980688, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997578636733002, \"precision\": 1.0, \"recall\": 0.0024213632669980688, \"specificity\": 1.0, \"npv\": 0.999762927853001, \"accuracy\": 0.9997629279894196, \"f1\": 0.00483102885817714, \"f2\": 0.003024873004652386, \"f0_5\": 0.011990681155406396, \"p4\": 0.009615598972539352, \"phi\": 0.04920151653363641}, {\"truth_threshold\": 47.419998940080404, \"match_probability\": 0.9999999999999947, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 730.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303231.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0024016238925388456, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9975983761074612, \"precision\": 1.0, \"recall\": 0.0024016238925388456, \"specificity\": 1.0, \"npv\": 0.9997629231630986, \"accuracy\": 0.9997629232984078, \"f1\": 0.0047917398282194094, \"f2\": 0.0030002285105550507, \"f0_5\": 0.011893861138356561, \"p4\": 0.009537771717040629, \"phi\": 0.0490005563554433}, {\"truth_threshold\": 47.43999893963337, \"match_probability\": 0.9999999999999948, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 728.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303233.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0023950441010524375, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976049558989476, \"precision\": 1.0, \"recall\": 0.0023950441010524375, \"specificity\": 1.0, \"npv\": 0.9997629215997977, \"accuracy\": 0.9997629217347371, \"f1\": 0.004778643141038896, \"f2\": 0.0029920136251697393, \"f0_5\": 0.011861584433951505, \"p4\": 0.009511827264646432, \"phi\": 0.04893338622891886}, {\"truth_threshold\": 47.459998939186335, \"match_probability\": 0.9999999999999948, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 716.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303245.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002355565352133991, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997644434647866, \"precision\": 1.0, \"recall\": 0.002355565352133991, \"specificity\": 1.0, \"npv\": 0.9997629122199931, \"accuracy\": 0.9997629123527135, \"f1\": 0.004700059407175468, \"f2\": 0.0029427237456434536, \"f0_5\": 0.011667888861728998, \"p4\": 0.009356139190201356, \"phi\": 0.04852841308320304}, {\"truth_threshold\": 47.4799989387393, \"match_probability\": 0.9999999999999949, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 713.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303248.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002345695664904379, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976543043350956, \"precision\": 1.0, \"recall\": 0.002345695664904379, \"specificity\": 1.0, \"npv\": 0.999762909875042, \"accuracy\": 0.9997629100072075, \"f1\": 0.004680412506482339, \"f2\": 0.002930401123827326, \"f0_5\": 0.01161945549895213, \"p4\": 0.00931721144918675, \"phi\": 0.04842664063948762}, {\"truth_threshold\": 47.499998938292265, \"match_probability\": 0.999999999999995, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 709.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303252.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0023325360819315636, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9976674639180685, \"precision\": 1.0, \"recall\": 0.0023325360819315636, \"specificity\": 1.0, \"npv\": 0.9997629067484405, \"accuracy\": 0.9997629068798664, \"f1\": 0.004654216037023665, \"f2\": 0.002913970866867288, \"f0_5\": 0.011554871788185673, \"p4\": 0.009265304233230957, \"phi\": 0.04829061040582857}, {\"truth_threshold\": 47.51999893784523, \"match_probability\": 0.999999999999995, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 687.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303274.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002260158375581078, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997739841624419, \"precision\": 1.0, \"recall\": 0.002260158375581078, \"specificity\": 1.0, \"npv\": 0.9997628895521327, \"accuracy\": 0.9997628896794896, \"f1\": 0.004510123158530501, \"f2\": 0.0028236025222538514, \"f0_5\": 0.011199540932936432, \"p4\": 0.0089797417731377, \"phi\": 0.047535486411904866}, {\"truth_threshold\": 47.55999893695116, \"match_probability\": 0.9999999999999952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 682.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303279.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0022437088968650584, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9977562911031349, \"precision\": 1.0, \"recall\": 0.0022437088968650584, \"specificity\": 1.0, \"npv\": 0.9997628856438809, \"accuracy\": 0.9997628857703131, \"f1\": 0.004477371874620458, \"f2\": 0.0028030638062811644, \"f0_5\": 0.011118755481937729, \"p4\": 0.008914824033516044, \"phi\": 0.047362188307495466}, {\"truth_threshold\": 47.579998936504126, \"match_probability\": 0.9999999999999952, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 667.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303294.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002194360460717, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.997805639539283, \"precision\": 1.0, \"recall\": 0.002194360460717, \"specificity\": 1.0, \"npv\": 0.999762873919126, \"accuracy\": 0.9997628740427835, \"f1\": 0.004379111572147012, \"f2\": 0.002741446645365311, \"f0_5\": 0.01087633589777875, \"p4\": 0.00872003262001662, \"phi\": 0.04683844703468429}, {\"truth_threshold\": 47.59999893605709, \"match_probability\": 0.9999999999999953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 658.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303303.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0021647513990281646, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978352486009718, \"precision\": 1.0, \"recall\": 0.0021647513990281646, \"specificity\": 1.0, \"npv\": 0.9997628668842732, \"accuracy\": 0.9997628670062657, \"f1\": 0.004320150745685594, \"f2\": 0.002704475619440001, \"f0_5\": 0.010730838603621087, \"p4\": 0.008603130263959013, \"phi\": 0.0465213721292068}, {\"truth_threshold\": 47.619998935610056, \"match_probability\": 0.9999999999999953, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 654.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303307.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002151591816055349, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978484081839446, \"precision\": 1.0, \"recall\": 0.002151591816055349, \"specificity\": 1.0, \"npv\": 0.999762863757672, \"accuracy\": 0.9997628638789245, \"f1\": 0.004293944815586888, \"f2\": 0.0026880438767675737, \"f0_5\": 0.01066616217133053, \"p4\": 0.00855116703716204, \"phi\": 0.04637975415692785}, {\"truth_threshold\": 47.659998934715986, \"match_probability\": 0.9999999999999954, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 646.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303315.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002125272650109718, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9978747273498902, \"precision\": 1.0, \"recall\": 0.002125272650109718, \"specificity\": 1.0, \"npv\": 0.9997628575044696, \"accuracy\": 0.9997628576242421, \"f1\": 0.004241530890622999, \"f2\": 0.0026551800672426407, \"f0_5\": 0.01053678905217831, \"p4\": 0.008447228351932857, \"phi\": 0.046095212958069606}, {\"truth_threshold\": 47.67999893426895, \"match_probability\": 0.9999999999999956, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 636.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303325.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002092373692677679, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979076263073223, \"precision\": 1.0, \"recall\": 0.002092373692677679, \"specificity\": 1.0, \"npv\": 0.9997628496879667, \"accuracy\": 0.999762849805889, \"f1\": 0.004176009612701373, \"f2\": 0.002614099697487834, \"f0_5\": 0.01037503466501362, \"p4\": 0.008317282056131062, \"phi\": 0.045737047189379966}, {\"truth_threshold\": 47.71999893337488, \"match_probability\": 0.9999999999999957, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 630.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303331.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0020726343182184558, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979273656817815, \"precision\": 1.0, \"recall\": 0.0020726343182184558, \"specificity\": 1.0, \"npv\": 0.999762844998065, \"accuracy\": 0.9997628451148772, \"f1\": 0.0041366947808700845, \"f2\": 0.002589451151442612, \"f0_5\": 0.010277961765982231, \"p4\": 0.008239302041494792, \"phi\": 0.04552079505701442}, {\"truth_threshold\": 47.73999893292785, \"match_probability\": 0.9999999999999958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 626.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303335.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00205947473524564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979405252647544, \"precision\": 1.0, \"recall\": 0.00205947473524564, \"specificity\": 1.0, \"npv\": 0.9997628418714639, \"accuracy\": 0.999762841987536, \"f1\": 0.004110484032476764, \"f2\": 0.0025730186523301025, \"f0_5\": 0.01021323805328504, \"p4\": 0.00818731026525555, \"phi\": 0.045376054412781}, {\"truth_threshold\": 47.75999893248081, \"match_probability\": 0.9999999999999958, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 620.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303341.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.002039735360786417, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979602646392136, \"precision\": 1.0, \"recall\": 0.002039735360786417, \"specificity\": 1.0, \"npv\": 0.9997628371815623, \"accuracy\": 0.9997628372965242, \"f1\": 0.004071166619060282, \"f2\": 0.0025483697010351314, \"f0_5\": 0.010116139811578738, \"p4\": 0.008109314949973306, \"phi\": 0.0451580736015099}, {\"truth_threshold\": 47.77999893203378, \"match_probability\": 0.9999999999999959, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 612.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303349.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0020134161948407855, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979865838051593, \"precision\": 1.0, \"recall\": 0.0020134161948407855, \"specificity\": 1.0, \"npv\": 0.9997628309283603, \"accuracy\": 0.9997628310418417, \"f1\": 0.004018740991486441, \"f2\": 0.0025155040544006524, \"f0_5\": 0.009986651828112099, \"p4\": 0.008005306912017765, \"phi\": 0.04486578512397873}, {\"truth_threshold\": 47.79999893158674, \"match_probability\": 0.9999999999999959, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 611.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303350.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0020101262990975814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9979898737009024, \"precision\": 1.0, \"recall\": 0.0020101262990975814, \"specificity\": 1.0, \"npv\": 0.99976283014671, \"accuracy\": 0.9997628302600063, \"f1\": 0.004012187594394757, \"f2\": 0.002511395818176587, \"f0_5\": 0.009970463928460698, \"p4\": 0.007992304759263203, \"phi\": 0.04482911506753318}, {\"truth_threshold\": 47.81999893113971, \"match_probability\": 0.999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 598.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303363.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001967357654435931, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980326423455641, \"precision\": 1.0, \"recall\": 0.001967357654435931, \"specificity\": 1.0, \"npv\": 0.9997628199852568, \"accuracy\": 0.9997628200961474, \"f1\": 0.0039269895159886915, \"f2\": 0.0024579881326031163, \"f0_5\": 0.009759982764980267, \"p4\": 0.00782325355312641, \"phi\": 0.044349645280638346}, {\"truth_threshold\": 47.85999893024564, \"match_probability\": 0.9999999999999961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 596.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303365.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001960777862949523, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980392221370504, \"precision\": 1.0, \"recall\": 0.001960777862949523, \"specificity\": 1.0, \"npv\": 0.9997628184219564, \"accuracy\": 0.9997628185324768, \"f1\": 0.003913881473747115, \"f2\": 0.002449771464272796, \"f0_5\": 0.009727594705315902, \"p4\": 0.007797241847131748, \"phi\": 0.04427541984625099}, {\"truth_threshold\": 47.8799989297986, \"match_probability\": 0.9999999999999961, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 588.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303373.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001934458697003892, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9980655413029961, \"precision\": 1.0, \"recall\": 0.001934458697003892, \"specificity\": 1.0, \"npv\": 0.9997628121687545, \"accuracy\": 0.9997628122777943, \"f1\": 0.0038614475831475394, \"f2\": 0.002416904520762361, \"f0_5\": 0.009598025549029913, \"p4\": 0.007693184812509008, \"phi\": 0.04397726534177535}, {\"truth_threshold\": 47.89999892935157, \"match_probability\": 0.9999999999999962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 584.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303377.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0019212991140310763, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998078700885969, \"precision\": 1.0, \"recall\": 0.0019212991140310763, \"specificity\": 1.0, \"npv\": 0.9997628090421536, \"accuracy\": 0.9997628091504531, \"f1\": 0.0038352296048203057, \"f2\": 0.002400470886891785, \"f0_5\": 0.009533230818453984, \"p4\": 0.007641150167969427, \"phi\": 0.043827427477025276}, {\"truth_threshold\": 47.91999892890453, \"match_probability\": 0.9999999999999962, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 569.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303392.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001871950677883018, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998128049322117, \"precision\": 1.0, \"recall\": 0.001871950677883018, \"specificity\": 1.0, \"npv\": 0.9997627973174006, \"accuracy\": 0.9997627974229235, \"f1\": 0.0037369060519489047, \"f2\": 0.00233884379729582, \"f0_5\": 0.00929019027746484, \"p4\": 0.0074459838608869145, \"phi\": 0.043260913607557225}, {\"truth_threshold\": 47.9399989284575, \"match_probability\": 0.9999999999999963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 568.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303393.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001868660782139814, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981313392178602, \"precision\": 1.0, \"recall\": 0.001868660782139814, \"specificity\": 1.0, \"npv\": 0.9997627965357503, \"accuracy\": 0.9997627966410882, \"f1\": 0.003730350804028516, \"f2\": 0.002334735270615548, \"f0_5\": 0.009273984188510056, \"p4\": 0.007432970730396335, \"phi\": 0.04322288201090694}, {\"truth_threshold\": 47.959998928010464, \"match_probability\": 0.9999999999999963, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 566.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303395.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018620809906534062, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981379190093466, \"precision\": 1.0, \"recall\": 0.0018620809906534062, \"specificity\": 1.0, \"npv\": 0.9997627949724499, \"accuracy\": 0.9997627950774176, \"f1\": 0.0037172401790317444, \"f2\": 0.002326518196989502, \"f0_5\": 0.00924157074046861, \"p4\": 0.007406943703022885, \"phi\": 0.04314671824925643}, {\"truth_threshold\": 47.97999892756343, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 562.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303399.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018489214076805906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981510785923194, \"precision\": 1.0, \"recall\": 0.0018489214076805906, \"specificity\": 1.0, \"npv\": 0.9997627918458492, \"accuracy\": 0.9997627919500764, \"f1\": 0.0036910184124023474, \"f2\": 0.0023100839686749325, \"f0_5\": 0.00917673876339363, \"p4\": 0.007354886582496173, \"phi\": 0.042993985956716135}, {\"truth_threshold\": 47.999998927116394, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 555.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303406.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018258921374781634, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981741078625218, \"precision\": 1.0, \"recall\": 0.0018258921374781634, \"specificity\": 1.0, \"npv\": 0.9997627863742978, \"accuracy\": 0.9997627864772293, \"f1\": 0.0036451286631901114, \"f2\": 0.0022813238090462094, \"f0_5\": 0.009063266499227582, \"p4\": 0.007263776784275582, \"phi\": 0.04272539070604377}, {\"truth_threshold\": 48.01999892666936, \"match_probability\": 0.9999999999999964, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 552.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303409.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018160224502485516, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981839775497514, \"precision\": 1.0, \"recall\": 0.0018160224502485516, \"specificity\": 1.0, \"npv\": 0.9997627840293473, \"accuracy\": 0.9997627841317234, \"f1\": 0.0036254609819613612, \"f2\": 0.0022689979250178397, \"f0_5\": 0.009014629175390062, \"p4\": 0.0072247258946547205, \"phi\": 0.04260976015797659}, {\"truth_threshold\": 48.039998926222324, \"match_probability\": 0.9999999999999966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 550.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303411.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0018094426587621439, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9981905573412378, \"precision\": 1.0, \"recall\": 0.0018094426587621439, \"specificity\": 1.0, \"npv\": 0.999762782466047, \"accuracy\": 0.9997627825680527, \"f1\": 0.003612348979183018, \"f2\": 0.0022607806352218113, \"f0_5\": 0.008982202174672802, \"p4\": 0.007198690690343412, \"phi\": 0.04253249848335744}, {\"truth_threshold\": 48.05999892577529, \"match_probability\": 0.9999999999999966, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 549.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303412.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00180615276301894, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998193847236981, \"precision\": 1.0, \"recall\": 0.00180615276301894, \"specificity\": 1.0, \"npv\": 0.9997627816843968, \"accuracy\": 0.9997627817862175, \"f1\": 0.003605792913204821, \"f2\": 0.0022566719801906127, \"f0_5\": 0.008965988038816685, \"p4\": 0.007185672704795956, \"phi\": 0.04249381496762528}, {\"truth_threshold\": 48.079998925328255, \"match_probability\": 0.9999999999999967, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 546.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303415.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017962830757893282, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982037169242107, \"precision\": 1.0, \"recall\": 0.0017962830757893282, \"specificity\": 1.0, \"npv\": 0.9997627793394462, \"accuracy\": 0.9997627794407115, \"f1\": 0.0035861244569090366, \"f2\": 0.0022443459745640788, \"f0_5\": 0.008917343089059107, \"p4\": 0.00714661721449604, \"phi\": 0.042377552552401464}, {\"truth_threshold\": 48.119998924434185, \"match_probability\": 0.9999999999999968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 540.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303421.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017765437013301049, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982234562986699, \"precision\": 1.0, \"recall\": 0.0017765437013301049, \"specificity\": 1.0, \"npv\": 0.9997627746495452, \"accuracy\": 0.9997627747496997, \"f1\": 0.003546786381653919, \"f2\": 0.0022196937809112914, \"f0_5\": 0.008820041748197609, \"p4\": 0.007068499331759631, \"phi\": 0.04214406553867292}, {\"truth_threshold\": 48.13999892398715, \"match_probability\": 0.9999999999999968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 539.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303422.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001773253805586901, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982267461944131, \"precision\": 1.0, \"recall\": 0.001773253805586901, \"specificity\": 1.0, \"npv\": 0.999762773867895, \"accuracy\": 0.9997627739678644, \"f1\": 0.003540229885057471, \"f2\": 0.0022155850583245574, \"f0_5\": 0.008803823374722736, \"p4\": 0.00705547878982764, \"phi\": 0.042105025156688375}, {\"truth_threshold\": 48.159998923540115, \"match_probability\": 0.9999999999999968, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 529.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303432.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001740354848154862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982596451518452, \"precision\": 1.0, \"recall\": 0.001740354848154862, \"specificity\": 1.0, \"npv\": 0.9997627660513935, \"accuracy\": 0.9997627661495113, \"f1\": 0.003474662550494269, \"f2\": 0.002174497460893986, \"f0_5\": 0.008641616325303763, \"p4\": 0.00692525930687216, \"phi\": 0.041712611724780045}, {\"truth_threshold\": 48.17999892309308, \"match_probability\": 0.9999999999999969, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 521.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303440.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0017140356822092308, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9982859643177908, \"precision\": 1.0, \"recall\": 0.0017140356822092308, \"specificity\": 1.0, \"npv\": 0.9997627597981923, \"accuracy\": 0.9997627598948289, \"f1\": 0.0034222055819391624, \"f2\": 0.0021416268965318798, \"f0_5\": 0.008511820157166429, \"p4\": 0.006821065306495174, \"phi\": 0.0413960027543491}, {\"truth_threshold\": 48.199998922646046, \"match_probability\": 0.9999999999999969, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 520.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303441.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001710745786466027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998289254213534, \"precision\": 1.0, \"recall\": 0.001710745786466027, \"specificity\": 1.0, \"npv\": 0.9997627590165422, \"accuracy\": 0.9997627591129935, \"f1\": 0.0034156482670511462, \"f2\": 0.0021375180455850385, \"f0_5\": 0.0084955937276378, \"p4\": 0.006808039905357526, \"phi\": 0.04135625620692956}, {\"truth_threshold\": 48.21999892219901, \"match_probability\": 0.999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 513.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303448.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016877165162635997, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983122834837364, \"precision\": 1.0, \"recall\": 0.0016877165162635997, \"specificity\": 1.0, \"npv\": 0.9997627535449912, \"accuracy\": 0.9997627536401464, \"f1\": 0.0033697458567890854, \"f2\": 0.002108755899789289, \"f0_5\": 0.008381996843271365, \"p4\": 0.006716854933927483, \"phi\": 0.04107695353240131}, {\"truth_threshold\": 48.239998921751976, \"match_probability\": 0.999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 506.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303455.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016646872460611723, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983353127539388, \"precision\": 1.0, \"recall\": 0.0016646872460611723, \"specificity\": 1.0, \"npv\": 0.9997627480734403, \"accuracy\": 0.9997627481672993, \"f1\": 0.0033238413358426364, \"f2\": 0.002079993422945698, \"f0_5\": 0.00826837916891351, \"p4\": 0.006625657424584175, \"phi\": 0.04079573869664484}, {\"truth_threshold\": 48.25999892130494, \"match_probability\": 0.999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 503.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303458.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016548175588315607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983451824411684, \"precision\": 1.0, \"recall\": 0.0016548175588315607, \"specificity\": 1.0, \"npv\": 0.99976274572849, \"accuracy\": 0.9997627458217934, \"f1\": 0.0033041673235587785, \"f2\": 0.0020676665458129956, \"f0_5\": 0.008219679514205502, \"p4\": 0.006586568938945177, \"phi\": 0.04067462287836432}, {\"truth_threshold\": 48.279998920857906, \"match_probability\": 0.9999999999999971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 495.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303466.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0016284983928859294, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9983715016071141, \"precision\": 1.0, \"recall\": 0.0016284983928859294, \"specificity\": 1.0, \"npv\": 0.999762739475289, \"accuracy\": 0.9997627395671109, \"f1\": 0.0032517013952755077, \"f2\": 0.00203479457618312, \"f0_5\": 0.008089795091210397, \"p4\": 0.006482321714836004, \"phi\": 0.04034987006797844}, {\"truth_threshold\": 48.29999892041087, \"match_probability\": 0.9999999999999971, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 486.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303475.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015988893311970943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984011106688029, \"precision\": 1.0, \"recall\": 0.0015988893311970943, \"specificity\": 1.0, \"npv\": 0.9997627324404381, \"accuracy\": 0.9997627325305931, \"f1\": 0.003192673930109346, \"f2\": 0.0019978130934861426, \"f0_5\": 0.007943642634151125, \"p4\": 0.0063650240026388305, \"phi\": 0.039981370244496016}, {\"truth_threshold\": 48.3399989195168, \"match_probability\": 0.9999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 481.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303480.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015824398524810748, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984175601475189, \"precision\": 1.0, \"recall\": 0.0015824398524810748, \"specificity\": 1.0, \"npv\": 0.9997627285321876, \"accuracy\": 0.9997627286214167, \"f1\": 0.0031598793858928793, \"f2\": 0.0019772675888434423, \"f0_5\": 0.007862431959723425, \"p4\": 0.00629984964454557, \"phi\": 0.039775172968254356}, {\"truth_threshold\": 48.35999891906977, \"match_probability\": 0.9999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 480.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303481.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001579149956737871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984208500432621, \"precision\": 1.0, \"recall\": 0.001579149956737871, \"specificity\": 1.0, \"npv\": 0.9997627277505375, \"accuracy\": 0.9997627278395813, \"f1\": 0.003153320347784957, \"f2\": 0.001973158467645134, \"f0_5\": 0.007846188550449358, \"p4\": 0.006286814004605584, \"phi\": 0.03973380510692875}, {\"truth_threshold\": 48.37999891862273, \"match_probability\": 0.9999999999999972, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 473.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303488.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015561206865354438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9984438793134646, \"precision\": 1.0, \"recall\": 0.0015561206865354438, \"specificity\": 1.0, \"npv\": 0.999762722278987, \"accuracy\": 0.9997627223667341, \"f1\": 0.0031074058745081037, \"f2\": 0.0019443944300704503, \"f0_5\": 0.007732472789215734, \"p4\": 0.006195557353110668, \"phi\": 0.0394430152722294}, {\"truth_threshold\": 48.3999989181757, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 461.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303500.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0015166419376169968, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998483358062383, \"precision\": 1.0, \"recall\": 0.0015166419376169968, \"specificity\": 1.0, \"npv\": 0.9997627128991861, \"accuracy\": 0.9997627129847105, \"f1\": 0.0030286904363022384, \"f2\": 0.001895083881098902, \"f0_5\": 0.007537483036575595, \"p4\": 0.00603908817344129, \"phi\": 0.038939466586596264}, {\"truth_threshold\": 48.41999891772866, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 451.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303510.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014837429801849579, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985162570198151, \"precision\": 1.0, \"recall\": 0.0014837429801849579, \"specificity\": 1.0, \"npv\": 0.9997627050826854, \"accuracy\": 0.9997627051663575, \"f1\": 0.002963089497128891, \"f2\": 0.001853991013693224, \"f0_5\": 0.007374944810557127, \"p4\": 0.005908669001434949, \"phi\": 0.038514813974848155}, {\"truth_threshold\": 48.43999891728163, \"match_probability\": 0.9999999999999973, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 450.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303511.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001480453084441754, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985195469155582, \"precision\": 1.0, \"recall\": 0.001480453084441754, \"specificity\": 1.0, \"npv\": 0.9997627043010354, \"accuracy\": 0.9997627043845222, \"f1\": 0.0029565291661602243, \"f2\": 0.0018498816897888175, \"f0_5\": 0.007358688648977469, \"p4\": 0.00589562567446832, \"phi\": 0.038472090913963815}, {\"truth_threshold\": 48.45999891683459, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 443.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303518.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014574238142393268, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985425761857607, \"precision\": 1.0, \"recall\": 0.0014574238142393268, \"specificity\": 1.0, \"npv\": 0.999762698829485, \"accuracy\": 0.999762698911675, \"f1\": 0.0029106056425014125, \"f2\": 0.0018211162332574466, \"f0_5\": 0.007244883607592245, \"p4\": 0.005804315207441807, \"phi\": 0.03817169063405852}, {\"truth_threshold\": 48.47999891638756, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 442.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303519.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001454133918496123, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985458660815039, \"precision\": 1.0, \"recall\": 0.001454133918496123, \"specificity\": 1.0, \"npv\": 0.999762698047835, \"accuracy\": 0.9997626981298398, \"f1\": 0.0029040449667053214, \"f2\": 0.0018170068552955472, \"f0_5\": 0.007228624042861488, \"p4\": 0.005791269829453013, \"phi\": 0.03812858310609711}, {\"truth_threshold\": 48.49999891594052, \"match_probability\": 0.9999999999999974, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 441.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303520.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0014508440227529189, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998549155977247, \"precision\": 1.0, \"recall\": 0.0014508440227529189, \"specificity\": 1.0, \"npv\": 0.9997626972661849, \"accuracy\": 0.9997626973480044, \"f1\": 0.0028974842478038908, \"f2\": 0.0018128974705763864, \"f0_5\": 0.0072123640526617055, \"p4\": 0.005778224195052433, \"phi\": 0.038085426786370405}, {\"truth_threshold\": 48.53999891504645, \"match_probability\": 0.9999999999999976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 440.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303521.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001447554127009715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985524458729903, \"precision\": 1.0, \"recall\": 0.001447554127009715, \"specificity\": 1.0, \"npv\": 0.9997626964845349, \"accuracy\": 0.9997626965661691, \"f1\": 0.002890923485796696, \"f2\": 0.001808788079099947, \"f0_5\": 0.007196103636976197, \"p4\": 0.005765178304232506, \"phi\": 0.03804222150882555}, {\"truth_threshold\": 48.55999891459942, \"match_probability\": 0.9999999999999976, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 430.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303531.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001414655169577676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9985853448304223, \"precision\": 1.0, \"recall\": 0.001414655169577676, \"specificity\": 1.0, \"npv\": 0.9997626886680345, \"accuracy\": 0.999762688747816, \"f1\": 0.0028253134948142355, \"f2\": 0.0017676937926815832, \"f0_5\": 0.007033476074731501, \"p4\": 0.005634705291305735, \"phi\": 0.03760743883695235}, {\"truth_threshold\": 48.579998914152384, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 415.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303546.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013653067334296175, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986346932665704, \"precision\": 1.0, \"recall\": 0.0013653067334296175, \"specificity\": 1.0, \"npv\": 0.9997626769432842, \"accuracy\": 0.9997626770202864, \"f1\": 0.002726890425000657, \"f2\": 0.0017060510960247776, \"f0_5\": 0.006789454913111337, \"p4\": 0.005438947675327323, \"phi\": 0.0369456724754373}, {\"truth_threshold\": 48.59999891370535, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 412.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303549.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001355437046200006, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986445629538, \"precision\": 1.0, \"recall\": 0.001355437046200006, \"specificity\": 1.0, \"npv\": 0.9997626745983342, \"accuracy\": 0.9997626746747805, \"f1\": 0.0027072046469299184, \"f2\": 0.0016937223742370027, \"f0_5\": 0.006740639182746581, \"p4\": 0.005399789224316499, \"phi\": 0.03681189164602362}, {\"truth_threshold\": 48.619998913258314, \"match_probability\": 0.9999999999999977, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 409.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303552.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013455673589703942, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986544326410296, \"precision\": 1.0, \"recall\": 0.0013455673589703942, \"specificity\": 1.0, \"npv\": 0.9997626722533842, \"accuracy\": 0.9997626723292746, \"f1\": 0.002687518480796399, \"f2\": 0.001681393591629373, \"f0_5\": 0.006691819618648089, \"p4\": 0.0053606284635572075, \"phi\": 0.036677622857829405}, {\"truth_threshold\": 48.659998912364244, \"match_probability\": 0.9999999999999978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 408.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303553.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013422774632271903, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986577225367728, \"precision\": 1.0, \"recall\": 0.0013422774632271903, \"specificity\": 1.0, \"npv\": 0.9997626714717341, \"accuracy\": 0.9997626715474394, \"f1\": 0.002680956339180403, \"f2\": 0.0016772839839112289, \"f0_5\": 0.0066755455785963685, \"p4\": 0.0053475743633246845, \"phi\": 0.03663275723300552}, {\"truth_threshold\": 48.67999891191721, \"match_probability\": 0.9999999999999978, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 407.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303554.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013389875674839865, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998661012432516, \"precision\": 1.0, \"recall\": 0.0013389875674839865, \"specificity\": 1.0, \"npv\": 0.9997626706900842, \"accuracy\": 0.999762670765604, \"f1\": 0.0026743941544446195, \"f2\": 0.0016731743694352564, \"f0_5\": 0.006659271112507322, \"p4\": 0.005334520006423165, \"phi\": 0.03658783659207811}, {\"truth_threshold\": 48.71999891102314, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 404.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303557.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013291178802543747, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986708821197456, \"precision\": 1.0, \"recall\": 0.0013291178802543747, \"specificity\": 1.0, \"npv\": 0.9997626683451342, \"accuracy\": 0.9997626684200981, \"f1\": 0.0026547073415143004, \"f2\": 0.0016608454854602022, \"f0_5\": 0.006610445157848922, \"p4\": 0.0052953553956289244, \"phi\": 0.03645274253754225}, {\"truth_threshold\": 48.739998910576105, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 403.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303558.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013258279845111708, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986741720154888, \"precision\": 1.0, \"recall\": 0.0013258279845111708, \"specificity\": 1.0, \"npv\": 0.9997626675634842, \"accuracy\": 0.9997626676382628, \"f1\": 0.0026481449842951205, \"f2\": 0.0016567358439527498, \"f0_5\": 0.006594168987443263, \"p4\": 0.005282300011975715, \"phi\": 0.036407599790774535}, {\"truth_threshold\": 48.75999891012907, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 401.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303560.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013192481930247631, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9986807518069752, \"precision\": 1.0, \"recall\": 0.0013192481930247631, \"specificity\": 1.0, \"npv\": 0.9997626660001842, \"accuracy\": 0.9997626660745922, \"f1\": 0.0026350201404906, \"f2\": 0.0016485165406640932, \"f0_5\": 0.006561615368252254, \"p4\": 0.005256188474541174, \"phi\": 0.0363171459585464}, {\"truth_threshold\": 48.779998909682035, \"match_probability\": 0.9999999999999979, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 397.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303564.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0013060886100519475, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998693911389948, \"precision\": 1.0, \"recall\": 0.0013060886100519475, \"specificity\": 1.0, \"npv\": 0.9997626628735842, \"accuracy\": 0.9997626629472509, \"f1\": 0.0026087699354050164, \"f2\": 0.0016320778529913067, \"f0_5\": 0.006496503015882886, \"p4\": 0.005203962318947586, \"phi\": 0.036135559034480055}, {\"truth_threshold\": 48.819998908787966, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 384.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303577.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012633199653902967, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987366800346097, \"precision\": 1.0, \"recall\": 0.0012633199653902967, \"specificity\": 1.0, \"npv\": 0.9997626527121345, \"accuracy\": 0.9997626527833919, \"f1\": 0.0025234520034828896, \"f2\": 0.001578651371288936, \"f0_5\": 0.006284840767667113, \"p4\": 0.005034198939630048, \"phi\": 0.03553899435581718}, {\"truth_threshold\": 48.83999890834093, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 383.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303578.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012600300696470929, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987399699303529, \"precision\": 1.0, \"recall\": 0.0012600300696470929, \"specificity\": 1.0, \"npv\": 0.9997626519304844, \"accuracy\": 0.9997626520015567, \"f1\": 0.00251688878374471, \"f2\": 0.0015745415946200833, \"f0_5\": 0.006268556071661217, \"p4\": 0.005021138420400878, \"phi\": 0.035492689443637974}, {\"truth_threshold\": 48.859998907893896, \"match_probability\": 0.999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 381.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303580.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012534502781606852, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987465497218393, \"precision\": 1.0, \"recall\": 0.0012534502781606852, \"specificity\": 1.0, \"npv\": 0.9997626503671845, \"accuracy\": 0.999762650437886, \"f1\": 0.0025037622148766847, \"f2\": 0.001566322021007626, \"f0_5\": 0.006235985400265152, \"p4\": 0.004995016611359936, \"phi\": 0.03539989791224561}, {\"truth_threshold\": 48.87999890744686, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 380.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303581.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001250160382417481, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987498396175826, \"precision\": 1.0, \"recall\": 0.001250160382417481, \"specificity\": 1.0, \"npv\": 0.9997626495855345, \"accuracy\": 0.9997626496560508, \"f1\": 0.0024971988657459887, \"f2\": 0.0015622122240639882, \"f0_5\": 0.006219699424841479, \"p4\": 0.004981955321533011, \"phi\": 0.035353410816108904}, {\"truth_threshold\": 48.899998906999826, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 373.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303588.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012271311122150539, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987728688877849, \"precision\": 1.0, \"recall\": 0.0012271311122150539, \"specificity\": 1.0, \"npv\": 0.9997626441139849, \"accuracy\": 0.9997626441832036, \"f1\": 0.002451254214120013, \"f2\": 0.0015334434562253281, \"f0_5\": 0.006105685653766701, \"p4\": 0.004890519099650036, \"phi\": 0.035026273644546566}, {\"truth_threshold\": 48.91999890655279, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 371.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303590.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012205513207286462, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987794486792714, \"precision\": 1.0, \"recall\": 0.0012205513207286462, \"specificity\": 1.0, \"npv\": 0.9997626425506849, \"accuracy\": 0.999762642619533, \"f1\": 0.0024381267825926947, \"f2\": 0.0015252237474459697, \"f0_5\": 0.0060731064512432684, \"p4\": 0.004864392152532856, \"phi\": 0.03493224318277313}, {\"truth_threshold\": 48.93999890610576, \"match_probability\": 0.9999999999999981, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 370.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303591.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0012172614249854423, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9987827385750145, \"precision\": 1.0, \"recall\": 0.0012172614249854423, \"specificity\": 1.0, \"npv\": 0.999762641769035, \"accuracy\": 0.9997626418376977, \"f1\": 0.0024315630021259746, \"f2\": 0.0015211138829186312, \"f0_5\": 0.006056816210004551, \"p4\": 0.004851328293554119, \"phi\": 0.034885132907400335}, {\"truth_threshold\": 48.97999890521169, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 354.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303607.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011646230930941798, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988353769069058, \"precision\": 1.0, \"recall\": 0.0011646230930941798, \"specificity\": 1.0, \"npv\": 0.9997626292626358, \"accuracy\": 0.9997626293283328, \"f1\": 0.0023265366478813073, \"f2\": 0.001455355131319078, \"f0_5\": 0.005796114311162923, \"p4\": 0.004642271598603462, \"phi\": 0.03412252402229092}, {\"truth_threshold\": 48.99999890476465, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 353.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303608.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001161333197350976, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998838666802649, \"precision\": 1.0, \"recall\": 0.001161333197350976, \"specificity\": 1.0, \"npv\": 0.9997626284809858, \"accuracy\": 0.9997626285464974, \"f1\": 0.0023199721340457554, \"f2\": 0.0014512451518956223, \"f0_5\": 0.0057798168141911695, \"p4\": 0.004629203370326596, \"phi\": 0.034074294268932985}, {\"truth_threshold\": 49.01999890431762, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 352.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303609.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001158043301607772, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988419566983923, \"precision\": 1.0, \"recall\": 0.001158043301607772, \"specificity\": 1.0, \"npv\": 0.9997626276993359, \"accuracy\": 0.9997626277646622, \"f1\": 0.002313407577067033, \"f2\": 0.0014471351657134213, \"f0_5\": 0.005763518890260636, \"p4\": 0.00461613488496393, \"phi\": 0.03402599615301514}, {\"truth_threshold\": 49.03999890387058, \"match_probability\": 0.9999999999999982, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 348.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303613.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011448837186349564, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998855116281365, \"precision\": 1.0, \"recall\": 0.0011448837186349564, \"specificity\": 1.0, \"npv\": 0.9997626245727361, \"accuracy\": 0.999762624637321, \"f1\": 0.002287148917711931, \"f2\": 0.0014306951533968322, \"f0_5\": 0.0056983229246151176, \"p4\": 0.004563858372503539, \"phi\": 0.033832114201939524}, {\"truth_threshold\": 49.05999890342355, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 347.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303614.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011415938228917526, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988584061771082, \"precision\": 1.0, \"recall\": 0.0011415938228917526, \"specificity\": 1.0, \"npv\": 0.9997626237910863, \"accuracy\": 0.9997626238554856, \"f1\": 0.002280584145010976, \"f2\": 0.0014265851334206551, \"f0_5\": 0.00568202286563899, \"p4\": 0.004550788601598072, \"phi\": 0.0337834698584671}, {\"truth_threshold\": 49.07999890297651, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 344.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303617.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011317241356621408, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988682758643379, \"precision\": 1.0, \"recall\": 0.0011317241356621408, \"specificity\": 1.0, \"npv\": 0.9997626214461365, \"accuracy\": 0.9997626215099797, \"f1\": 0.002260889568032073, \"f2\": 0.0014142550329389865, \"f0_5\": 0.005633120126286693, \"p4\": 0.004511577746063377, \"phi\": 0.03363711474879266}, {\"truth_threshold\": 49.09999890252948, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 343.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303618.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001128434239918937, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988715657600811, \"precision\": 1.0, \"recall\": 0.001128434239918937, \"specificity\": 1.0, \"npv\": 0.9997626206644865, \"accuracy\": 0.9997626207281445, \"f1\": 0.002254324622745675, \"f2\": 0.0014101449859273286, \"f0_5\": 0.0056168183589720075, \"p4\": 0.004498506946587086, \"phi\": 0.03358818799740311}, {\"truth_threshold\": 49.11999890208244, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 341.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303620.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011218544484325292, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988781455515675, \"precision\": 1.0, \"recall\": 0.0011218544484325292, \"specificity\": 1.0, \"npv\": 0.9997626191011867, \"accuracy\": 0.9997626191644738, \"f1\": 0.0022411946027301823, \"f2\": 0.0014019248716272607, \"f0_5\": 0.005584213542946041, \"p4\": 0.004472364576141878, \"phi\": 0.03349012005973139}, {\"truth_threshold\": 49.13999890163541, \"match_probability\": 0.9999999999999983, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 339.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303622.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011152746569461213, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988847253430538, \"precision\": 1.0, \"recall\": 0.0011152746569461213, \"specificity\": 1.0, \"npv\": 0.9997626175378869, \"accuracy\": 0.9997626176008032, \"f1\": 0.0022280644101215904, \"f2\": 0.0013937047302914117, \"f0_5\": 0.0055516070182793625, \"p4\": 0.004446221176989236, \"phi\": 0.033391764108865574}, {\"truth_threshold\": 49.17999890074134, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 338.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303623.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011119847612029174, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988880152387971, \"precision\": 1.0, \"recall\": 0.0011119847612029174, \"specificity\": 1.0, \"npv\": 0.9997626167562369, \"accuracy\": 0.9997626168189679, \"f1\": 0.002221499249093819, \"f2\": 0.0013895946494850277, \"f0_5\": 0.005535303115163783, \"p4\": 0.0044331490916286525, \"phi\": 0.03334247733227524}, {\"truth_threshold\": 49.21999889984727, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 335.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303626.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0011021150739733059, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9988978849260267, \"precision\": 1.0, \"recall\": 0.0011021150739733059, \"specificity\": 1.0, \"npv\": 0.9997626144112872, \"accuracy\": 0.999762614473462, \"f1\": 0.002201803507111497, \"f2\": 0.0013772643665118374, \"f0_5\": 0.005486388842486595, \"p4\": 0.0043939312923187614, \"phi\": 0.03319417791929243}, {\"truth_threshold\": 49.239998899400234, \"match_probability\": 0.9999999999999984, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 332.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303629.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001092245386743694, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989077546132563, \"precision\": 1.0, \"recall\": 0.001092245386743694, \"specificity\": 1.0, \"npv\": 0.9997626120663374, \"accuracy\": 0.999762612127956, \"f1\": 0.0021821073767717297, \"f2\": 0.0013649340227072397, \"f0_5\": 0.005437470724461085, \"p4\": 0.0043547111780072355, \"phi\": 0.03304521297961752}, {\"truth_threshold\": 49.2599988989532, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 330.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303631.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010856655952572864, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989143344047428, \"precision\": 1.0, \"recall\": 0.0010856655952572864, \"specificity\": 1.0, \"npv\": 0.9997626105030376, \"accuracy\": 0.9997626105642855, \"f1\": 0.0021689764074520773, \"f2\": 0.001356713759708726, \"f0_5\": 0.005404856509248856, \"p4\": 0.004328563148919638, \"phi\": 0.032945528826348484}, {\"truth_threshold\": 49.279998898506165, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 327.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303634.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010757959080276746, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989242040919724, \"precision\": 1.0, \"recall\": 0.0010757959080276746, \"specificity\": 1.0, \"npv\": 0.9997626081580879, \"accuracy\": 0.9997626082187796, \"f1\": 0.0021492796298243767, \"f2\": 0.0013443833145174485, \"f0_5\": 0.005355931981301737, \"p4\": 0.004289339175816508, \"phi\": 0.032795434481884}, {\"truth_threshold\": 49.29999889805913, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 324.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303637.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010659262207980628, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998934073779202, \"precision\": 1.0, \"recall\": 0.0010659262207980628, \"specificity\": 1.0, \"npv\": 0.9997626058131382, \"accuracy\": 0.9997626058732736, \"f1\": 0.0021295824638086006, \"f2\": 0.0013320528084935633, \"f0_5\": 0.005307003606796896, \"p4\": 0.004250112887165047, \"phi\": 0.032644650038093866}, {\"truth_threshold\": 49.319998897612095, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 308.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303653.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010132878889068005, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989867121110932, \"precision\": 1.0, \"recall\": 0.0010132878889068005, \"specificity\": 1.0, \"npv\": 0.99976259330674, \"accuracy\": 0.9997625933639087, \"f1\": 0.002024524351807118, \"f2\": 0.0012662890822857668, \"f0_5\": 0.0050459872932865435, \"p4\": 0.004040866898852193, \"phi\": 0.031828404414607006}, {\"truth_threshold\": 49.33999889716506, \"match_probability\": 0.9999999999999986, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 307.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303654.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0010099979931635966, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9989900020068364, \"precision\": 1.0, \"recall\": 0.0010099979931635966, \"specificity\": 1.0, \"npv\": 0.99976259252509, \"accuracy\": 0.9997625925820735, \"f1\": 0.0020179578529454295, \"f2\": 0.0012621787919427768, \"f0_5\": 0.005029670138832002, \"p4\": 0.0040277868367719055, \"phi\": 0.03177669290675755}, {\"truth_threshold\": 49.359998896718025, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 304.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303657.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.001000128305933985, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.998999871694066, \"precision\": 1.0, \"recall\": 0.001000128305933985, \"specificity\": 1.0, \"npv\": 0.9997625901801405, \"accuracy\": 0.9997625902365675, \"f1\": 0.001998258097382216, \"f2\": 0.001249847880356667, \"f0_5\": 0.004980716109012147, \"p4\": 0.003988545105890093, \"phi\": 0.031621050989064814}, {\"truth_threshold\": 49.37999889627099, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 303.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303658.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000996838410190781, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990031615898092, \"precision\": 1.0, \"recall\": 0.000996838410190781, \"specificity\": 1.0, \"npv\": 0.9997625893984906, \"accuracy\": 0.9997625894547322, \"f1\": 0.0019916914258670104, \"f2\": 0.0012457375629755284, \"f0_5\": 0.004964397243530719, \"p4\": 0.003975464014023837, \"phi\": 0.03156899982869603}, {\"truth_threshold\": 49.399998895823956, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 299.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303662.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009836788272179656, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999016321172782, \"precision\": 1.0, \"recall\": 0.0009836788272179656, \"specificity\": 1.0, \"npv\": 0.9997625862718911, \"accuracy\": 0.999762586327391, \"f1\": 0.001965424308157497, \"f2\": 0.0012292962258550187, \"f0_5\": 0.004899117503449044, \"p4\": 0.003923137071827848, \"phi\": 0.03135993125566977}, {\"truth_threshold\": 49.41999889537692, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 297.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303664.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009770990357315576, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990229009642685, \"precision\": 1.0, \"recall\": 0.0009770990357315576, \"specificity\": 1.0, \"npv\": 0.9997625847085914, \"accuracy\": 0.9997625847637204, \"f1\": 0.001952290490307568, \"f2\": 0.0012210755167369573, \"f0_5\": 0.004866475066279096, \"p4\": 0.0038969720557848458, \"phi\": 0.03125487253980176}, {\"truth_threshold\": 49.439998894929886, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 287.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303674.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009442000782995186, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990557999217005, \"precision\": 1.0, \"recall\": 0.0009442000782995186, \"specificity\": 1.0, \"npv\": 0.9997625768920927, \"accuracy\": 0.9997625769453673, \"f1\": 0.0018866188109699982, \"f2\": 0.0011799715655632494, \"f0_5\": 0.0047032372037534124, \"p4\": 0.0037661315236867015, \"phi\": 0.030724190849922194}, {\"truth_threshold\": 49.45999889448285, \"match_probability\": 0.9999999999999987, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 284.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303677.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000934330391069907, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990656696089301, \"precision\": 1.0, \"recall\": 0.000934330391069907, \"specificity\": 1.0, \"npv\": 0.9997625745471431, \"accuracy\": 0.9997625745998614, \"f1\": 0.00186691646534865, \"f2\": 0.0011676402483949057, \"f0_5\": 0.004654257498434924, \"p4\": 0.003726874341453776, \"phi\": 0.030563189579192965}, {\"truth_threshold\": 49.479998894035816, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 279.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303682.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009178809123538875, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990821190876461, \"precision\": 1.0, \"recall\": 0.0009178809123538875, \"specificity\": 1.0, \"npv\": 0.999762570638894, \"accuracy\": 0.9997625706906849, \"f1\": 0.001834078359190113, \"f2\": 0.0011470879179161977, \"f0_5\": 0.0045726160936419335, \"p4\": 0.003661440552097964, \"phi\": 0.030292952653633746}, {\"truth_threshold\": 49.51999889314175, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 278.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303683.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009145910166106836, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990854089833893, \"precision\": 1.0, \"recall\": 0.0009145910166106836, \"specificity\": 1.0, \"npv\": 0.9997625698572441, \"accuracy\": 0.9997625699088496, \"f1\": 0.0018275106084361308, \"f2\": 0.0011429774315405855, \"f0_5\": 0.004556286528142444, \"p4\": 0.003648353021313192, \"phi\": 0.03023861546326231}, {\"truth_threshold\": 49.53999889269471, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 276.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303685.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009080112251242758, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990919887748757, \"precision\": 1.0, \"recall\": 0.0009080112251242758, \"specificity\": 1.0, \"npv\": 0.9997625682939444, \"accuracy\": 0.999762568345179, \"f1\": 0.0018143749774024857, \"f2\": 0.0011347564385093577, \"f0_5\": 0.004523626112467835, \"p4\": 0.0036221771867691707, \"phi\": 0.030129647101650177}, {\"truth_threshold\": 49.55999889224768, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 275.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303686.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0009047213293810719, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999095278670619, \"precision\": 1.0, \"recall\": 0.0009047213293810719, \"specificity\": 1.0, \"npv\": 0.9997625675122945, \"accuracy\": 0.9997625675633437, \"f1\": 0.001807807097121971, \"f2\": 0.0011306459318537083, \"f0_5\": 0.004507295262259023, \"p4\": 0.0036090888829947033, \"phi\": 0.030075014865252468}, {\"truth_threshold\": 49.59999889135361, \"match_probability\": 0.9999999999999988, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 274.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303687.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000901431433637868, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9990985685663621, \"precision\": 1.0, \"recall\": 0.000901431433637868, \"specificity\": 1.0, \"npv\": 0.9997625667306447, \"accuracy\": 0.9997625667815083, \"f1\": 0.0018012391736650945, \"f2\": 0.0011265354184380133, \"f0_5\": 0.0044909639837800806, \"p4\": 0.0035960003215417848, \"phi\": 0.030020283206949928}, {\"truth_threshold\": 49.63999889045954, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 273.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303688.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008981415378946641, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991018584621053, \"precision\": 1.0, \"recall\": 0.0008981415378946641, \"specificity\": 1.0, \"npv\": 0.9997625659489948, \"accuracy\": 0.9997625659996731, \"f1\": 0.0017946712070314298, \"f2\": 0.001122424898262256, \"f0_5\": 0.004474632277014158, \"p4\": 0.003582911502402806, \"phi\": 0.029965451581962618}, {\"truth_threshold\": 49.6599988900125, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 271.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303690.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008915617464082563, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991084382535917, \"precision\": 1.0, \"recall\": 0.0008915617464082563, \"specificity\": 1.0, \"npv\": 0.9997625643856952, \"accuracy\": 0.9997625644360024, \"f1\": 0.0017815351442320335, \"f2\": 0.0011142038376304873, \"f0_5\": 0.004441967578553984, \"p4\": 0.003556733091036224, \"phi\": 0.029855486227782443}, {\"truth_threshold\": 49.67999888956547, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 270.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303691.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008882718506650524, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991117281493349, \"precision\": 1.0, \"recall\": 0.0008882718506650524, \"specificity\": 1.0, \"npv\": 0.9997625636040454, \"accuracy\": 0.9997625636541672, \"f1\": 0.0017749670480654502, \"f2\": 0.0011100932971744425, \"f0_5\": 0.004425634586826033, \"p4\": 0.0035436434987934006, \"phi\": 0.029800351383804227}, {\"truth_threshold\": 49.69999888911843, \"match_probability\": 0.9999999999999989, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 269.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303692.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008849819549218485, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991150180450782, \"precision\": 1.0, \"recall\": 0.0008849819549218485, \"specificity\": 1.0, \"npv\": 0.9997625628223955, \"accuracy\": 0.9997625628723318, \"f1\": 0.001768398908720376, \"f2\": 0.0011059827499582686, \"f0_5\": 0.0044093011667437065, \"p4\": 0.0035305536488340734, \"phi\": 0.029745114343438673}, {\"truth_threshold\": 49.75999888777733, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 261.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303700.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008586627889762173, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991413372110238, \"precision\": 1.0, \"recall\": 0.0008586627889762173, \"specificity\": 1.0, \"npv\": 0.9997625565691969, \"accuracy\": 0.9997625566176493, \"f1\": 0.001715852239483009, \"f2\": 0.0010730981288622282, \"f0_5\": 0.004278618383305192, \"p4\": 0.0034258255704519044, \"phi\": 0.029299469366145522}, {\"truth_threshold\": 49.859998885542154, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 260.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303701.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008553728932330135, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999144627106767, \"precision\": 1.0, \"recall\": 0.0008553728932330135, \"specificity\": 1.0, \"npv\": 0.999762555787547, \"accuracy\": 0.9997625558358141, \"f1\": 0.0017092837115123545, \"f2\": 0.0010689875208041418, \"f0_5\": 0.004262281107275058, \"p4\": 0.003412733400701498, \"phi\": 0.029243286236160702}, {\"truth_threshold\": 49.899998884648085, \"match_probability\": 0.999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 251.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303710.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008257638315441783, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991742361684558, \"precision\": 1.0, \"recall\": 0.0008257638315441783, \"specificity\": 1.0, \"npv\": 0.9997625487526988, \"accuracy\": 0.9997625487992963, \"f1\": 0.0016501650165016502, \"f2\": 0.0010319917440660474, \"f0_5\": 0.00411522633744856, \"p4\": 0.0032948922713656507, \"phi\": 0.028732694842155022}, {\"truth_threshold\": 49.95999888330698, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 249.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303712.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008191840400577706, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991808159599422, \"precision\": 1.0, \"recall\": 0.0008191840400577706, \"specificity\": 1.0, \"npv\": 0.999762547189399, \"accuracy\": 0.9997625472356257, \"f1\": 0.0016370270536800236, \"f2\": 0.0010237703859819931, \"f0_5\": 0.004082542784720469, \"p4\": 0.00326870251745806, \"phi\": 0.028617992985271686}, {\"truth_threshold\": 50.03999888151884, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 248.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303713.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0008158941443145666, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9991841058556854, \"precision\": 1.0, \"recall\": 0.0008158941443145666, \"specificity\": 1.0, \"npv\": 0.9997625464077493, \"accuracy\": 0.9997625464537904, \"f1\": 0.0016304580074882728, \"f2\": 0.0010196596967992552, \"f0_5\": 0.004066200365302194, \"p4\": 0.0032556072536934644, \"phi\": 0.028560469311954644}, {\"truth_threshold\": 50.059998881071806, \"match_probability\": 0.9999999999999991, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 242.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303719.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007961547698553433, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992038452301446, \"precision\": 1.0, \"recall\": 0.0007961547698553433, \"specificity\": 1.0, \"npv\": 0.9997625417178505, \"accuracy\": 0.9997625417627786, \"f1\": 0.0015910428233778101, \"f2\": 0.000994995419731828, \"f0_5\": 0.003968136844970468, \"p4\": 0.0031770302552747505, \"phi\": 0.028212864376226818}, {\"truth_threshold\": 50.1199988797307, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 236.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303725.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007764153953961198, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992235846046039, \"precision\": 1.0, \"recall\": 0.0007764153953961198, \"specificity\": 1.0, \"npv\": 0.9997625370279517, \"accuracy\": 0.9997625370717668, \"f1\": 0.001551626084412404, \"f2\": 0.0009703308992829419, \"f0_5\": 0.0038700578868827995, \"p4\": 0.0030984439713854983, \"phi\": 0.027860922911647865}, {\"truth_threshold\": 50.13999887928367, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 235.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303726.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000773125499652916, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992268745003471, \"precision\": 1.0, \"recall\": 0.000773125499652916, \"specificity\": 1.0, \"npv\": 0.9997625362463018, \"accuracy\": 0.9997625362899314, \"f1\": 0.0015450564767452563, \"f2\": 0.000966220122212455, \"f0_5\": 0.003853709892719276, \"p4\": 0.0030853453545343036, \"phi\": 0.02780183285989772}, {\"truth_threshold\": 50.15999887883663, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 232.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303729.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007632558124233043, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992367441875767, \"precision\": 1.0, \"recall\": 0.0007632558124233043, \"specificity\": 1.0, \"npv\": 0.9997625339013525, \"accuracy\": 0.9997625339444255, \"f1\": 0.0015253473945817293, \"f2\": 0.0009538877504366504, \"f0_5\": 0.003804663336492953, \"p4\": 0.0030460479560517426, \"phi\": 0.027623804318798274}, {\"truth_threshold\": 50.19999887794256, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 226.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303735.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000743516437964081, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992564835620359, \"precision\": 1.0, \"recall\": 0.000743516437964081, \"specificity\": 1.0, \"npv\": 0.9997625292114538, \"accuracy\": 0.9997625292534137, \"f1\": 0.0014859280639869553, \"f2\": 0.0009292228243439934, \"f0_5\": 0.0037065586407098224, \"p4\": 0.0029674461927201965, \"phi\": 0.027264260021670504}, {\"truth_threshold\": 50.25999887660146, \"match_probability\": 0.9999999999999992, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 224.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303737.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007369366464776731, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992630633535223, \"precision\": 1.0, \"recall\": 0.0007369366464776731, \"specificity\": 1.0, \"npv\": 0.9997625276481542, \"accuracy\": 0.999762527689743, \"f1\": 0.0014727879415487287, \"f2\": 0.0009210011282263821, \"f0_5\": 0.0036738536428555027, \"p4\": 0.002941243540610822, \"phi\": 0.0271433535952924}, {\"truth_threshold\": 50.29999887570739, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 222.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303739.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007303568549912653, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992696431450088, \"precision\": 1.0, \"recall\": 0.0007303568549912653, \"specificity\": 1.0, \"npv\": 0.9997625260848547, \"accuracy\": 0.9997625261260724, \"f1\": 0.0014596476463181703, \"f2\": 0.0009127794050651856, \"f0_5\": 0.0036411469284793455, \"p4\": 0.0029150398562336915, \"phi\": 0.027021906192744014}, {\"truth_threshold\": 50.33999887481332, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 215.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303746.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000707327584788838, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992926724152111, \"precision\": 1.0, \"recall\": 0.000707327584788838, \"specificity\": 1.0, \"npv\": 0.9997625206133063, \"accuracy\": 0.9997625206532254, \"f1\": 0.0014136552522223975, \"f2\": 0.0008840031610308381, \"f0_5\": 0.0035266599086020978, \"p4\": 0.002823318830924385, \"phi\": 0.02659247278964126}, {\"truth_threshold\": 50.35999887436628, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 214.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303747.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0007040376890456342, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9992959623109544, \"precision\": 1.0, \"recall\": 0.0007040376890456342, \"specificity\": 1.0, \"npv\": 0.9997625198316565, \"accuracy\": 0.99976251987139, \"f1\": 0.0014070847374044546, \"f2\": 0.0008798922419818792, \"f0_5\": 0.0035103029030533073, \"p4\": 0.002810214794827481, \"phi\": 0.026530557741154245}, {\"truth_threshold\": 50.37999887391925, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 212.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303749.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006974578975592263, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993025421024407, \"precision\": 1.0, \"recall\": 0.0006974578975592263, \"specificity\": 1.0, \"npv\": 0.999762518268357, \"accuracy\": 0.9997625183077193, \"f1\": 0.0013939435781611122, \"f2\": 0.0008716703836007553, \"f0_5\": 0.003477587604040563, \"p4\": 0.0027840059481964315, \"phi\": 0.026406292129906573}, {\"truth_threshold\": 50.399998873472214, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 211.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303750.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006941680018160225, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999305831998184, \"precision\": 1.0, \"recall\": 0.0006941680018160225, \"specificity\": 1.0, \"npv\": 0.9997625174867072, \"accuracy\": 0.9997625175258841, \"f1\": 0.0013873729337348605, \"f2\": 0.0008675594442685569, \"f0_5\": 0.003461229310542806, \"p4\": 0.002770901137647029, \"phi\": 0.026343939512804528}, {\"truth_threshold\": 50.439998872578144, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 206.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303755.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000677718523100003, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993222814768999, \"precision\": 1.0, \"recall\": 0.000677718523100003, \"specificity\": 1.0, \"npv\": 0.9997625135784585, \"accuracy\": 0.9997625136167075, \"f1\": 0.0013545190635407523, \"f2\": 0.0008470046461905349, \"f0_5\": 0.003379431402464032, \"p4\": 0.0027053732122560765, \"phi\": 0.026029936115041456}, {\"truth_threshold\": 50.479998871684074, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 204.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303757.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006711387316135952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993288612683864, \"precision\": 1.0, \"recall\": 0.0006711387316135952, \"specificity\": 1.0, \"npv\": 0.999762512015159, \"accuracy\": 0.9997625120530369, \"f1\": 0.0013413772130258248, \"f2\": 0.0008387826796310672, \"f0_5\": 0.003346709233308288, \"p4\": 0.002679160234723434, \"phi\": 0.02590326898730497}, {\"truth_threshold\": 50.519998870790005, \"match_probability\": 0.9999999999999993, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 203.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303758.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006678488358703913, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993321511641297, \"precision\": 1.0, \"recall\": 0.0006678488358703913, \"specificity\": 1.0, \"npv\": 0.9997625112335092, \"accuracy\": 0.9997625112712016, \"f1\": 0.001334806222958667, \"f2\": 0.0008346716862094968, \"f0_5\": 0.003330347504536163, \"p4\": 0.002666053358631678, \"phi\": 0.025839702577122637}, {\"truth_threshold\": 50.559998869895935, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 202.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303759.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006645589401271874, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993354410598728, \"precision\": 1.0, \"recall\": 0.0006645589401271874, \"specificity\": 1.0, \"npv\": 0.9997625104518595, \"accuracy\": 0.9997625104893664, \"f1\": 0.0013282351896844783, \"f2\": 0.00083056068602668, \"f0_5\": 0.003313985346278657, \"p4\": 0.0026529462243127903, \"phi\": 0.025775979405733236}, {\"truth_threshold\": 50.5799988694489, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 201.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303760.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006612690443839835, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999338730955616, \"precision\": 1.0, \"recall\": 0.0006612690443839835, \"specificity\": 1.0, \"npv\": 0.9997625096702096, \"accuracy\": 0.999762509707531, \"f1\": 0.0013216641132028327, \"f2\": 0.0008264496790825998, \"f0_5\": 0.003297622758518859, \"p4\": 0.0026398388317591397, \"phi\": 0.025712098307616834}, {\"truth_threshold\": 50.61999886855483, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 200.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303761.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006579791486407795, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993420208513593, \"precision\": 1.0, \"recall\": 0.0006579791486407795, \"specificity\": 1.0, \"npv\": 0.9997625088885599, \"accuracy\": 0.9997625089256957, \"f1\": 0.0013150929935133039, \"f2\": 0.0008223386653772397, \"f0_5\": 0.0032812597412398567, \"p4\": 0.002626731180963094, \"phi\": 0.02564805810273878}, {\"truth_threshold\": 50.639998868107796, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 199.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303762.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006546892528975757, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993453107471024, \"precision\": 1.0, \"recall\": 0.0006546892528975757, \"specificity\": 1.0, \"npv\": 0.9997625081069101, \"accuracy\": 0.9997625081438604, \"f1\": 0.0013085218306154655, \"f2\": 0.000818227644910583, \"f0_5\": 0.0032648962944247383, \"p4\": 0.0026136232719170213, \"phi\": 0.025583857596295355}, {\"truth_threshold\": 50.65999886766076, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 187.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303774.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006152105039791289, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993847894960208, \"precision\": 1.0, \"recall\": 0.0006152105039791289, \"specificity\": 1.0, \"npv\": 0.9997624987271133, \"accuracy\": 0.9997624987618368, \"f1\": 0.001229664505438142, \"f2\": 0.0007688948719234953, \"f0_5\": 0.0030685014226688413, \"p4\": 0.002456308217083531, \"phi\": 0.024800491743135672}, {\"truth_threshold\": 50.679998867213726, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 183.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303778.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0006020509210063133, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9993979490789937, \"precision\": 1.0, \"recall\": 0.0006020509210063133, \"specificity\": 1.0, \"npv\": 0.9997624956005143, \"accuracy\": 0.9997624956344955, \"f1\": 0.0012033773475722026, \"f2\": 0.0007524503978941257, \"f0_5\": 0.0030030227146668944, \"p4\": 0.0024038615989471924, \"phi\": 0.024533812000255076}, {\"truth_threshold\": 50.69999886676669, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 178.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303783.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005856014422902938, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994143985577097, \"precision\": 1.0, \"recall\": 0.0005856014422902938, \"specificity\": 1.0, \"npv\": 0.9997624916922657, \"accuracy\": 0.999762491725319, \"f1\": 0.0011705174278865914, \"f2\": 0.0007318946532217345, \"f0_5\": 0.002921164658502723, \"p4\": 0.0023382975126735425, \"phi\": 0.024196329413419895}, {\"truth_threshold\": 50.719998866319656, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 174.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303787.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005724418593174782, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994275581406825, \"precision\": 1.0, \"recall\": 0.0005724418593174782, \"specificity\": 1.0, \"npv\": 0.9997624885656669, \"accuracy\": 0.9997624885979778, \"f1\": 0.0011442287142223026, \"f2\": 0.000715449935773977, \"f0_5\": 0.002855670475321427, \"p4\": 0.002285841592176266, \"phi\": 0.023922915746839878}, {\"truth_threshold\": 50.77999886497855, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 171.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303790.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005625721720878665, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994374278279121, \"precision\": 1.0, \"recall\": 0.0005625721720878665, \"specificity\": 1.0, \"npv\": 0.9997624862207177, \"accuracy\": 0.9997624862524719, \"f1\": 0.0011245117251719647, \"f2\": 0.0007031163266900491, \"f0_5\": 0.0028065453232450884, \"p4\": 0.0022464969381200814, \"phi\": 0.023715787008766018}, {\"truth_threshold\": 50.79999886453152, \"match_probability\": 0.9999999999999994, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 169.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303792.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005559923806014587, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994440076193986, \"precision\": 1.0, \"recall\": 0.0005559923806014587, \"specificity\": 1.0, \"npv\": 0.9997624846574183, \"accuracy\": 0.9997624846888012, \"f1\": 0.0011113668497024299, \"f2\": 0.0006948938868252231, \"f0_5\": 0.002773793071754252, \"p4\": 0.002220265876404577, \"phi\": 0.0235766902656142}, {\"truth_threshold\": 50.83999886363745, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 166.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303795.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000546122693371847, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994538773066282, \"precision\": 1.0, \"recall\": 0.000546122693371847, \"specificity\": 1.0, \"npv\": 0.9997624823124692, \"accuracy\": 0.9997624823432953, \"f1\": 0.0010916492123356361, \"f2\": 0.0006825601763143396, \"f0_5\": 0.002724661469019286, \"p4\": 0.002180917345161422, \"phi\": 0.023366492667334763}, {\"truth_threshold\": 50.85999886319041, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 165.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303796.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005428327976286432, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994571672023713, \"precision\": 1.0, \"recall\": 0.0005428327976286432, \"specificity\": 1.0, \"npv\": 0.9997624815308195, \"accuracy\": 0.99976248156146, \"f1\": 0.0010850765801016684, \"f2\": 0.000678448925953673, \"f0_5\": 0.0027082834079068746, \"p4\": 0.0021678006510711632, \"phi\": 0.023296005340262292}, {\"truth_threshold\": 50.91999886184931, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 159.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303802.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005230934231694197, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994769065768305, \"precision\": 1.0, \"recall\": 0.0005230934231694197, \"specificity\": 1.0, \"npv\": 0.9997624768409212, \"accuracy\": 0.9997624768704482, \"f1\": 0.0010456398789951335, \"f2\": 0.0006537812817896009, \"f0_5\": 0.002610006007938358, \"p4\": 0.0020890950573979297, \"phi\": 0.022868519330447593}, {\"truth_threshold\": 50.93999886140227, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 157.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303804.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000516513631683012, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999483486368317, \"precision\": 1.0, \"recall\": 0.000516513631683012, \"specificity\": 1.0, \"npv\": 0.9997624752776219, \"accuracy\": 0.9997624753067775, \"f1\": 0.0010324939661578729, \"f2\": 0.0006455586796392437, \"f0_5\": 0.002577243432953915, \"p4\": 0.0020628577910827605, \"phi\": 0.022724236993264306}, {\"truth_threshold\": 50.9799988605082, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 155.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303806.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005099338401966042, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994900661598034, \"precision\": 1.0, \"recall\": 0.0005099338401966042, \"specificity\": 1.0, \"npv\": 0.9997624737143225, \"accuracy\": 0.999762473743107, \"f1\": 0.0010193478804140525, \"f2\": 0.0006373360504408309, \"f0_5\": 0.0025444791369126766, \"p4\": 0.0020366194904536178, \"phi\": 0.022579032696411087}, {\"truth_threshold\": 50.99999886006117, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 154.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303807.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0005066439444534002, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9994933560555466, \"precision\": 1.0, \"recall\": 0.0005066439444534002, \"specificity\": 1.0, \"npv\": 0.9997624729326727, \"accuracy\": 0.9997624729612716, \"f1\": 0.0010127747727011163, \"f2\": 0.0006332247256985621, \"f0_5\": 0.0025280963434533795, \"p4\": 0.0020234999522521922, \"phi\": 0.022506079241020528}, {\"truth_threshold\": 51.0399988591671, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 148.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303813.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004869045699941769, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995130954300058, \"precision\": 1.0, \"recall\": 0.0004869045699941769, \"specificity\": 1.0, \"npv\": 0.9997624682427746, \"accuracy\": 0.9997624682702598, \"f1\": 0.0009733352186222703, \"f2\": 0.0006085566352410214, \"f0_5\": 0.0024297905454879775, \"p4\": 0.0019447772921459706, \"phi\": 0.02206329337828025}, {\"truth_threshold\": 51.07999885827303, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 147.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303814.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000483614674250973, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999516385325749, \"precision\": 1.0, \"recall\": 0.000483614674250973, \"specificity\": 1.0, \"npv\": 0.999762467461125, \"accuracy\": 0.9997624674884246, \"f1\": 0.0009667618083049443, \"f2\": 0.0006044452631639544, \"f0_5\": 0.0024134047394672124, \"p4\": 0.0019316559435739497, \"phi\": 0.021988628880163515}, {\"truth_threshold\": 51.099998857825994, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 146.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303815.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00048032477850776906, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995196752214922, \"precision\": 1.0, \"recall\": 0.00048032477850776906, \"specificity\": 1.0, \"npv\": 0.9997624666794752, \"accuracy\": 0.9997624667065892, \"f1\": 0.000960188354756714, \"f2\": 0.0006003338843247067, \"f0_5\": 0.002397018503012691, \"p4\": 0.001918534336346968, \"phi\": 0.021913709986403483}, {\"truth_threshold\": 51.139998856931925, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 143.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303818.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004704550912781574, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995295449087218, \"precision\": 1.0, \"recall\": 0.0004704550912781574, \"specificity\": 1.0, \"npv\": 0.9997624643345262, \"accuracy\": 0.9997624643610833, \"f1\": 0.0009404677347223319, \"f2\": 0.0005879997072337122, \"f0_5\": 0.002347857210876982, \"p4\": 0.001879167962659773, \"phi\": 0.021687400522307304}, {\"truth_threshold\": 51.179998856037855, \"match_probability\": 0.9999999999999996, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 142.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303819.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004671651955349535, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995328348044651, \"precision\": 1.0, \"recall\": 0.0004671651955349535, \"specificity\": 1.0, \"npv\": 0.9997624635528766, \"accuracy\": 0.999762463579248, \"f1\": 0.0009338941082462192, \"f2\": 0.0005838883013455747, \"f0_5\": 0.0023314692525178227, \"p4\": 0.0018660453207364615, \"phi\": 0.021611437406479615}, {\"truth_threshold\": 51.219998855143785, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 140.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303821.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0004605854040485457, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995394145959514, \"precision\": 1.0, \"recall\": 0.0004605854040485457, \"specificity\": 1.0, \"npv\": 0.9997624619895772, \"accuracy\": 0.9997624620155774, \"f1\": 0.0009207467255944571, \"f2\": 0.0005756654692824905, \"f0_5\": 0.002298692044226835, \"p4\": 0.0018397992608025712, \"phi\": 0.021458704469469684}, {\"truth_threshold\": 51.27999885380268, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 131.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303830.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00043097634235971064, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995690236576403, \"precision\": 1.0, \"recall\": 0.00043097634235971064, \"specificity\": 1.0, \"npv\": 0.9997624549547302, \"accuracy\": 0.9997624549790596, \"f1\": 0.0008615813635347197, \"f2\": 0.0005386623902629577, \"f0_5\": 0.0021511732926088314, \"p4\": 0.001721679184145328, \"phi\": 0.02075750384957099}, {\"truth_threshold\": 51.33999885246158, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 130.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303831.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00042768644661650673, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9995723135533835, \"precision\": 1.0, \"recall\": 0.00042768644661650673, \"specificity\": 1.0, \"npv\": 0.9997624541730805, \"accuracy\": 0.9997624541972243, \"f1\": 0.0008550072182340155, \"f2\": 0.0005345509032265493, \"f0_5\": 0.0021347801669069663, \"p4\": 0.0017085534373985879, \"phi\": 0.02067812495092055}, {\"truth_threshold\": 51.35999885201454, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 120.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303841.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00039478748918446774, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996052125108156, \"precision\": 1.0, \"recall\": 0.00039478748918446774, \"specificity\": 1.0, \"npv\": 0.999762446356584, \"accuracy\": 0.9997624463788712, \"f1\": 0.0007892633870580536, \"f2\": 0.0004934356609241721, \"f0_5\": 0.001970825217365598, \"p4\": 0.0015772817354919105, \"phi\": 0.019866899757587667}, {\"truth_threshold\": 51.37999885156751, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 119.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303842.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00039149759344126383, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996085024065587, \"precision\": 1.0, \"recall\": 0.00039149759344126383, \"specificity\": 1.0, \"npv\": 0.9997624455749343, \"accuracy\": 0.999762445597036, \"f1\": 0.0007826887661141805, \"f2\": 0.0004893240994997381, \"f0_5\": 0.001954427352785634, \"p4\": 0.0015641531416889078, \"phi\": 0.019783947822806732}, {\"truth_threshold\": 51.4399988502264, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 118.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303843.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003882076976980599, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996117923023019, \"precision\": 1.0, \"recall\": 0.0003882076976980599, \"specificity\": 1.0, \"npv\": 0.9997624447932846, \"accuracy\": 0.9997624448152006, \"f1\": 0.0007761141019274597, \"f2\": 0.00048521253131265615, \"f0_5\": 0.0019380290572966793, \"p4\": 0.0015510242890166752, \"phi\": 0.019700646612184708}, {\"truth_threshold\": 51.599998846650124, \"match_probability\": 0.9999999999999997, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 117.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303844.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00038491780195485607, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996150821980452, \"precision\": 1.0, \"recall\": 0.00038491780195485607, \"specificity\": 1.0, \"npv\": 0.9997624440116349, \"accuracy\": 0.9997624440333653, \"f1\": 0.0007695393944974645, \"f2\": 0.00048110095636290964, \"f0_5\": 0.0019216303308817492, \"p4\": 0.0015378951774675563, \"phi\": 0.019616991676247746}, {\"truth_threshold\": 51.679998844861984, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 116.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303845.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00038162790621165216, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996183720937883, \"precision\": 1.0, \"recall\": 0.00038162790621165216, \"specificity\": 1.0, \"npv\": 0.9997624432299853, \"accuracy\": 0.9997624432515301, \"f1\": 0.0007629646438237684, \"f2\": 0.0004769893746504819, \"f0_5\": 0.0019052311735238564, \"p4\": 0.0015247658070338935, \"phi\": 0.01953297847024117}, {\"truth_threshold\": 51.69999884441495, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 115.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303846.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00037833801046844825, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996216619895315, \"precision\": 1.0, \"recall\": 0.00037833801046844825, \"specificity\": 1.0, \"npv\": 0.9997624424483357, \"accuracy\": 0.9997624424696947, \"f1\": 0.0007563898499059446, \"f2\": 0.0004728777861753562, \"f0_5\": 0.001888831585206014, \"p4\": 0.0015116361777080293, \"phi\": 0.019448602351248272}, {\"truth_threshold\": 51.719998843967915, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 114.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303847.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00037504811472524434, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996249518852748, \"precision\": 1.0, \"recall\": 0.00037504811472524434, \"specificity\": 1.0, \"npv\": 0.999762441666686, \"accuracy\": 0.9997624416878594, \"f1\": 0.0007498150127435665, \"f2\": 0.0004687661909375159, \"f0_5\": 0.0018724315659112336, \"p4\": 0.0014985062894823063, \"phi\": 0.019363858575196156}, {\"truth_threshold\": 51.799998842179775, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 113.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303848.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003717582189820405, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999628241781018, \"precision\": 1.0, \"recall\": 0.0003717582189820405, \"specificity\": 1.0, \"npv\": 0.9997624408850364, \"accuracy\": 0.9997624409060242, \"f1\": 0.0007432401323362077, \"f2\": 0.0004646545889369443, \"f0_5\": 0.001856031115622526, \"p4\": 0.0014853761423490662, \"phi\": 0.019278742293743094}, {\"truth_threshold\": 51.81999884173274, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 107.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303854.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003520188445228171, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996479811554771, \"precision\": 1.0, \"recall\": 0.0003520188445228171, \"specificity\": 1.0, \"npv\": 0.9997624361951386, \"accuracy\": 0.9997624362150123, \"f1\": 0.0007037899417235618, \"f2\": 0.0004399848349152227, \"f0_5\": 0.0017576193620663033, \"p4\": 0.0014065898220628798, \"phi\": 0.018759936502737138}, {\"truth_threshold\": 51.85999884083867, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 106.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303855.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00034872894877961317, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996512710512204, \"precision\": 1.0, \"recall\": 0.00034872894877961317, \"specificity\": 1.0, \"npv\": 0.999762435413489, \"accuracy\": 0.999762435433177, \"f1\": 0.0006972147585893898, \"f2\": 0.0004358731855750648, \"f0_5\": 0.0017412158943443336, \"p4\": 0.0013934578623625699, \"phi\": 0.018672067457330264}, {\"truth_threshold\": 51.879998840391636, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 105.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303856.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00034543905303640926, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996545609469636, \"precision\": 1.0, \"recall\": 0.00034543905303640926, \"specificity\": 1.0, \"npv\": 0.9997624346318393, \"accuracy\": 0.9997624346513416, \"f1\": 0.0006906395322068235, \"f2\": 0.000431761529472042, \"f0_5\": 0.0017248119954924913, \"p4\": 0.0013803256436934676, \"phi\": 0.018583782948597888}, {\"truth_threshold\": 51.8999988399446, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 99.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303862.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003256996785771859, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996743003214228, \"precision\": 1.0, \"recall\": 0.0003256996785771859, \"specificity\": 1.0, \"npv\": 0.9997624299419415, \"accuracy\": 0.9997624299603298, \"f1\": 0.0006511872656712491, \"f2\": 0.0004070914508328104, \"f0_5\": 0.001626379547702205, \"p4\": 0.0013015268929051917, \"phi\": 0.018045007677627536}, {\"truth_threshold\": 51.919998839497566, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 98.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303863.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000322409782833982, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996775902171661, \"precision\": 1.0, \"recall\": 0.000322409782833982, \"specificity\": 1.0, \"npv\": 0.9997624291602919, \"accuracy\": 0.9997624291784946, \"f1\": 0.0006446117365379745, \"f2\": 0.00040297974738926694, \"f0_5\": 0.001609972630465282, \"p4\": 0.001288392861240025, \"phi\": 0.01795363995604078}, {\"truth_threshold\": 51.9599988386035, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 95.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303866.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00031254009560437027, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996874599043957, \"precision\": 1.0, \"recall\": 0.00031254009560437027, \"specificity\": 1.0, \"npv\": 0.999762426815343, \"accuracy\": 0.9997624268329887, \"f1\": 0.0006248848896255953, \"f2\": 0.00039064459648058004, \"f0_5\": 0.001560749291091243, \"p4\": 0.0012489892120333503, \"phi\": 0.017676703438665384}, {\"truth_threshold\": 52.09999883547425, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 94.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303867.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0003092501998611664, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9996907498001388, \"precision\": 1.0, \"recall\": 0.0003092501998611664, \"specificity\": 1.0, \"npv\": 0.9997624260336934, \"accuracy\": 0.9997624260511533, \"f1\": 0.0006183091874825278, \"f2\": 0.0003865328659849433, \"f0_5\": 0.001544340648688789, \"p4\": 0.0012358541442018557, \"phi\": 0.017583422023730314}, {\"truth_threshold\": 52.23999883234501, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 91.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303870.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002993805126315547, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997006194873684, \"precision\": 1.0, \"recall\": 0.0002993805126315547, \"specificity\": 1.0, \"npv\": 0.9997624236887446, \"accuracy\": 0.9997624237056474, \"f1\": 0.0005985818215305277, \"f2\": 0.0003741976339195763, \"f0_5\": 0.0014951121334100057, \"p4\": 0.001196447386312265, \"phi\": 0.01730056030635141}, {\"truth_threshold\": 52.259998831897974, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 88.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303873.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000289510825401943, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999710489174598, \"precision\": 1.0, \"recall\": 0.000289510825401943, \"specificity\": 1.0, \"npv\": 0.9997624213437957, \"accuracy\": 0.9997624213601415, \"f1\": 0.0005788540662853684, \"f2\": 0.00036186234098617355, \"f0_5\": 0.0014458797356668956, \"p4\": 0.0011570382966690524, \"phi\": 0.0170129963207275}, {\"truth_threshold\": 52.27999883145094, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 85.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303876.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00027964113817233134, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997203588618276, \"precision\": 1.0, \"recall\": 0.00027964113817233134, \"specificity\": 1.0, \"npv\": 0.9997624189988469, \"accuracy\": 0.9997624190146356, \"f1\": 0.0005591259217355268, \"f2\": 0.00034952698718428464, \"f0_5\": 0.001396643455000148, \"p4\": 0.0011176268750652466, \"phi\": 0.01672048745553672}, {\"truth_threshold\": 52.299998831003904, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 84.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303877.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00027635124242912743, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997236487575709, \"precision\": 1.0, \"recall\": 0.00027635124242912743, \"specificity\": 1.0, \"npv\": 0.9997624182171972, \"accuracy\": 0.9997624182328002, \"f1\": 0.0005525497870381029, \"f2\": 0.0003454151890572468, \"f0_5\": 0.0013802304984932483, \"p4\": 0.0011044892162814031, \"phi\": 0.016621840644413344}, {\"truth_threshold\": 52.31999883055687, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 83.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303878.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002730613466859235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997269386533141, \"precision\": 1.0, \"recall\": 0.0002730613466859235, \"specificity\": 1.0, \"npv\": 0.9997624174355476, \"accuracy\": 0.999762417450965, \"f1\": 0.0005459736090828959, \"f2\": 0.00034130338416697714, \"f0_5\": 0.0013638171104823312, \"p4\": 0.0010913512983601607, \"phi\": 0.01652260488152292}, {\"truth_threshold\": 52.379998829215765, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 82.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303879.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002697714509427196, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997302285490572, \"precision\": 1.0, \"recall\": 0.0002697714509427196, \"specificity\": 1.0, \"npv\": 0.9997624166538981, \"accuracy\": 0.9997624166691297, \"f1\": 0.000539397387869479, \"f2\": 0.00033719157251345887, \"f0_5\": 0.0013474032909503795, \"p4\": 0.0010782131212938519, \"phi\": 0.016422769490519004}, {\"truth_threshold\": 52.419998828321695, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 81.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303880.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002664815551995157, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997335184448005, \"precision\": 1.0, \"recall\": 0.0002664815551995157, \"specificity\": 1.0, \"npv\": 0.9997624158722485, \"accuracy\": 0.9997624158872943, \"f1\": 0.0005328211233974254, \"f2\": 0.00033307975409667536, \"f0_5\": 0.0013309890398803753, \"p4\": 0.0010650746850748088, \"phi\": 0.01632232346854031}, {\"truth_threshold\": 52.459998827427626, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 80.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303881.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00026319165945631185, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997368083405437, \"precision\": 1.0, \"recall\": 0.00026319165945631185, \"specificity\": 1.0, \"npv\": 0.9997624150905988, \"accuracy\": 0.999762415105459, \"f1\": 0.0005262448156663082, \"f2\": 0.0003289679289166099, \"f0_5\": 0.0013145743572553002, \"p4\": 0.0010519359896953636, \"phi\": 0.01622125547205717}, {\"truth_threshold\": 52.65999882295728, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 77.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303884.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0002533219722267001, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997466780277733, \"precision\": 1.0, \"recall\": 0.0002533219722267001, \"specificity\": 1.0, \"npv\": 0.99976241274565, \"accuracy\": 0.9997624127599531, \"f1\": 0.0005065156329143068, \"f2\": 0.00031663241279655504, \"f0_5\": 0.0012653277198794487, \"p4\": 0.0010125183485179298, \"phi\": 0.015914200770219416}, {\"truth_threshold\": 52.69999882206321, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 76.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303885.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00025003207648349626, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997499679235166, \"precision\": 1.0, \"recall\": 0.00025003207648349626, \"specificity\": 1.0, \"npv\": 0.9997624119640004, \"accuracy\": 0.9997624119781178, \"f1\": 0.0004999391521426669, \"f2\": 0.0003125205605631949, \"f0_5\": 0.001248911310863885, \"p4\": 0.0009993786164201894, \"phi\": 0.015810524085352377}, {\"truth_threshold\": 52.77999882027507, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 75.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303886.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00024674218074029235, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997532578192597, \"precision\": 1.0, \"recall\": 0.00024674218074029235, \"specificity\": 1.0, \"npv\": 0.9997624111823509, \"accuracy\": 0.9997624111962825, \"f1\": 0.0004933626281098291, \"f2\": 0.0003084087015664695, \"f0_5\": 0.0012324944702081437, \"p4\": 0.0009862386251237021, \"phi\": 0.015706163043764258}, {\"truth_threshold\": 52.879998818039894, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 74.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303887.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00024345228499708844, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997565477150029, \"precision\": 1.0, \"recall\": 0.00024345228499708844, \"specificity\": 1.0, \"npv\": 0.9997624104007012, \"accuracy\": 0.9997624104144472, \"f1\": 0.00048678606081536664, \"f2\": 0.00030429683580636196, \"f0_5\": 0.0012160771978952005, \"p4\": 0.0009730983746207983, \"phi\": 0.015601103911782897}, {\"truth_threshold\": 52.93999881669879, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 71.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303890.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00023358259776747674, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997664174022325, \"precision\": 1.0, \"recall\": 0.00023358259776747674, \"specificity\": 1.0, \"npv\": 0.9997624080557524, \"accuracy\": 0.9997624080689412, \"f1\": 0.0004670560993579623, \"f2\": 0.0002919611979455801, \"f0_5\": 0.0011668227908429062, \"p4\": 0.0009336760677968834, \"phi\": 0.015281593517167336}, {\"truth_threshold\": 52.999998815357685, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 68.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303893.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00022371291053786507, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997762870894621, \"precision\": 1.0, \"recall\": 0.00022371291053786507, \"specificity\": 1.0, \"npv\": 0.9997624057108037, \"accuracy\": 0.9997624057234353, \"f1\": 0.0004473257485305678, \"f2\": 0.0002796254992137589, \"f0_5\": 0.0011175644982628445, \"p4\": 0.000894251427839075, \"phi\": 0.014955258527618363}, {\"truth_threshold\": 53.05999881401658, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 64.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303897.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00021055332756504945, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999789446672435, \"precision\": 1.0, \"recall\": 0.00021055332756504945, \"specificity\": 1.0, \"npv\": 0.9997624025842053, \"accuracy\": 0.9997624025960942, \"f1\": 0.00042101800838746813, \"f2\": 0.00026317780621560184, \"f0_5\": 0.0010518807298737414, \"p4\": 0.0008416816115512596, \"phi\": 0.014508731875616595}, {\"truth_threshold\": 53.119998812675476, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 63.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303898.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00020726343182184557, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997927365681781, \"precision\": 1.0, \"recall\": 0.00020726343182184557, \"specificity\": 1.0, \"npv\": 0.9997624018025558, \"accuracy\": 0.9997624018142588, \"f1\": 0.0004144409651869589, \"f2\": 0.0002590658660571902, \"f0_5\": 0.0010354587082077361, \"p4\": 0.000828538509271476, \"phi\": 0.014394936137546725}, {\"truth_threshold\": 53.13999881222844, \"match_probability\": 0.9999999999999998, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 62.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303899.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00020397353607864166, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997960264639214, \"precision\": 1.0, \"recall\": 0.00020397353607864166, \"specificity\": 1.0, \"npv\": 0.9997624010209062, \"accuracy\": 0.9997624010324235, \"f1\": 0.00040786387871970215, \"f2\": 0.0002549539191351963, \"f0_5\": 0.0010190362546801705, \"p4\": 0.000815395147693214, \"phi\": 0.014280233617651612}, {\"truth_threshold\": 53.29999880865216, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 61.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303900.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00020068364033543778, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9997993163596646, \"precision\": 1.0, \"recall\": 0.00020068364033543778, \"specificity\": 1.0, \"npv\": 0.9997624002392567, \"accuracy\": 0.9997624002505883, \"f1\": 0.0004012867489852708, \"f2\": 0.00025084196544960337, \"f0_5\": 0.0010026133692740092, \"p4\": 0.0008022515268087998, \"phi\": 0.014164602287057302}, {\"truth_threshold\": 53.33999880775809, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 60.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303901.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00019739374459223387, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998026062554077, \"precision\": 1.0, \"recall\": 0.00019739374459223387, \"specificity\": 1.0, \"npv\": 0.999762399457607, \"accuracy\": 0.9997623994687529, \"f1\": 0.000394709575983238, \"f2\": 0.00024673000500039476, \"f0_5\": 0.0009861900519722157, \"p4\": 0.0007891076466105595, \"phi\": 0.014048019210246468}, {\"truth_threshold\": 53.41999880596995, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 59.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303902.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00019410384884902996, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999805896151151, \"precision\": 1.0, \"recall\": 0.00019410384884902996, \"specificity\": 1.0, \"npv\": 0.9997623986759575, \"accuracy\": 0.9997623986869176, \"f1\": 0.00038813235971317674, \"f2\": 0.00024261803778755377, \"f0_5\": 0.0009697663027577524, \"p4\": 0.0007759635070908185, \"phi\": 0.013930460491941452}, {\"truth_threshold\": 53.699998799711466, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 58.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303903.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00019081395310582608, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998091860468942, \"precision\": 1.0, \"recall\": 0.00019081395310582608, \"specificity\": 1.0, \"npv\": 0.9997623978943079, \"accuracy\": 0.9997623979050823, \"f1\": 0.0003815551001746601, \"f2\": 0.00023850606381106373, \"f0_5\": 0.0009533421216135809, \"p4\": 0.0007628191082419022, \"phi\": 0.013811901219918012}, {\"truth_threshold\": 53.79999879747629, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 57.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303904.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00018752405736262217, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998124759426373, \"precision\": 1.0, \"recall\": 0.00018752405736262217, \"specificity\": 1.0, \"npv\": 0.9997623971126584, \"accuracy\": 0.999762397123247, \"f1\": 0.00037497779736726116, \"f2\": 0.00023439408307090792, \"f0_5\": 0.0009369175085226619, \"p4\": 0.0007496744500561356, \"phi\": 0.013692315403362092}, {\"truth_threshold\": 53.83999879658222, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 56.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303905.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00018423416161941829, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998157658383806, \"precision\": 1.0, \"recall\": 0.00018423416161941829, \"specificity\": 1.0, \"npv\": 0.9997623963310087, \"accuracy\": 0.9997623963414117, \"f1\": 0.00036840045129055284, \"f2\": 0.00023028209556706967, \"f0_5\": 0.0009204924634679554, \"p4\": 0.0007365295325258434, \"phi\": 0.013571675906337581}, {\"truth_threshold\": 53.93999879434705, \"match_probability\": 0.9999999999999999, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 55.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303906.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00018094426587621438, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998190557341238, \"precision\": 1.0, \"recall\": 0.00018094426587621438, \"specificity\": 1.0, \"npv\": 0.9997623955493592, \"accuracy\": 0.9997623955595764, \"f1\": 0.0003618230619441082, \"f2\": 0.00022617010129953228, \"f0_5\": 0.0009040669864324201, \"p4\": 0.00072338435564335, \"phi\": 0.013449954375882629}, {\"truth_threshold\": 54.079998791217804, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 54.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303907.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001776543701330105, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998223456298669, \"precision\": 1.0, \"recall\": 0.0001776543701330105, \"specificity\": 1.0, \"npv\": 0.9997623947677096, \"accuracy\": 0.9997623947777411, \"f1\": 0.0003552456293275003, \"f2\": 0.00022205810026827908, \"f0_5\": 0.0008876410773990144, \"p4\": 0.0007102389194009796, \"phi\": 0.013327121164194749}, {\"truth_threshold\": 54.119998790323734, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 48.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303913.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001579149956737871, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998420850043263, \"precision\": 1.0, \"recall\": 0.0001579149956737871, \"specificity\": 1.0, \"npv\": 0.9997623900778122, \"accuracy\": 0.9997623900867293, \"f1\": 0.00031578012493051194, \"f2\": 0.00019738595204179317, \"f0_5\": 0.0007890765502888349, \"p4\": 0.0006313608549594503, \"phi\": 0.012564930302391364}, {\"truth_threshold\": 54.25999878719449, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 47.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303914.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001546250999305832, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998453749000694, \"precision\": 1.0, \"recall\": 0.0001546250999305832, \"specificity\": 1.0, \"npv\": 0.9997623892961627, \"accuracy\": 0.9997623893048939, \"f1\": 0.000309202389410805, \"f2\": 0.000193273903664062, \"f0_5\": 0.0007726476167930849, \"p4\": 0.0006182136029829899, \"phi\": 0.012433356721004903}, {\"truth_threshold\": 54.279998786747456, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 45.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303916.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00014804530844417542, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998519546915559, \"precision\": 1.0, \"recall\": 0.00014804530844417542, \"specificity\": 1.0, \"npv\": 0.9997623877328635, \"accuracy\": 0.9997623877412233, \"f1\": 0.000296046788550226, \"f2\": 0.00018504978661703495, \"f0_5\": 0.0007397884533818196, \"p4\": 0.000591918320758505, \"phi\": 0.012165941437587025}, {\"truth_threshold\": 54.51999878138304, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 44.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303917.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001447554127009715, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999855244587299, \"precision\": 1.0, \"recall\": 0.0001447554127009715, \"specificity\": 1.0, \"npv\": 0.999762386951214, \"accuracy\": 0.999762386959388, \"f1\": 0.00028946892320849986, \"f2\": 0.0001809377179477057, \"f0_5\": 0.0007233582234322033, \"p4\": 0.000578770290495123, \"phi\": 0.01203000485976757}, {\"truth_threshold\": 54.539998780936, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 43.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303918.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.0001414655169577676, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998585344830422, \"precision\": 1.0, \"recall\": 0.0001414655169577676, \"specificity\": 1.0, \"npv\": 0.9997623861695644, \"accuracy\": 0.9997623861775528, \"f1\": 0.00028289101459191325, \"f2\": 0.0001768256425144771, \"f0_5\": 0.0007069275612971957, \"p4\": 0.0005656220007874091, \"phi\": 0.011892514569863209}, {\"truth_threshold\": 54.55999878048897, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 40.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303921.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00013159582972815592, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998684041702719, \"precision\": 1.0, \"recall\": 0.00013159582972815592, \"specificity\": 1.0, \"npv\": 0.9997623838246157, \"accuracy\": 0.9997623838320469, \"f1\": 0.0002631570290887201, \"f2\": 0.00016448937563122798, \"f0_5\": 0.0006576329816092936, \"p4\": 0.0005261755749214791, \"phi\": 0.011470159564295495}, {\"truth_threshold\": 54.5999987795949, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 39.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303922.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.000128305933984952, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998716940660151, \"precision\": 1.0, \"recall\": 0.000128305933984952, \"specificity\": 1.0, \"npv\": 0.9997623830429662, \"accuracy\": 0.9997623830502115, \"f1\": 0.00025657894736842105, \"f2\": 0.0001603772731422349, \"f0_5\": 0.000641200590562185, \"p4\": 0.0005130262473596392, \"phi\": 0.011325875079628466}, {\"truth_threshold\": 54.61999877914786, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 38.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303923.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00012501603824174813, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998749839617582, \"precision\": 1.0, \"recall\": 0.00012501603824174813, \"specificity\": 1.0, \"npv\": 0.9997623822613166, \"accuracy\": 0.9997623822683762, \"f1\": 0.0002500008223711262, \"f2\": 0.00015626516388925898, \"f0_5\": 0.0006247677672444125, \"p4\": 0.0004998766603150666, \"phi\": 0.01117972862879247}, {\"truth_threshold\": 54.87999877333641, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 37.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303924.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00012172614249854422, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998782738575015, \"precision\": 1.0, \"recall\": 0.00012172614249854422, \"specificity\": 1.0, \"npv\": 0.9997623814796671, \"accuracy\": 0.9997623814865408, \"f1\": 0.00024342265409640852, \"f2\": 0.00015215304787228356, \"f0_5\": 0.0006083345116389189, \"p4\": 0.0004867268137800805, \"phi\": 0.011031646210456438}, {\"truth_threshold\": 55.01999877020717, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 36.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303925.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00011843624675534032, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998815637532447, \"precision\": 1.0, \"recall\": 0.00011843624675534032, \"specificity\": 1.0, \"npv\": 0.9997623806980175, \"accuracy\": 0.9997623807047056, \"f1\": 0.0002368444425438409, \"f2\": 0.0001480409250912919, \"f0_5\": 0.0005919008237286464, \"p4\": 0.0004735767077469994, \"phi\": 0.010881548787606334}, {\"truth_threshold\": 55.03999876976013, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 35.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303926.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00011514635101213643, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998848536489878, \"precision\": 1.0, \"recall\": 0.00011514635101213643, \"specificity\": 1.0, \"npv\": 0.999762379916368, \"accuracy\": 0.9997623799228703, \"f1\": 0.00023026618771299624, \"f2\": 0.00014392879554626735, \"f0_5\": 0.0005754667034965357, \"p4\": 0.00046042634220814154, \"phi\": 0.010729351794334036}, {\"truth_threshold\": 55.09999876841903, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 33.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303928.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00010856655952572862, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998914334404743, \"precision\": 1.0, \"recall\": 0.00010856655952572862, \"specificity\": 1.0, \"npv\": 0.9997623783530689, \"accuracy\": 0.9997623783591997, \"f1\": 0.0002171095482147674, \"f2\": 0.00013570451616405277, \"f0_5\": 0.0005425971659985596, \"p4\": 0.00043412483258236794, \"phi\": 0.01041828977140934}, {\"truth_threshold\": 55.25999876484275, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 32.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303929.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00010527666378252473, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998947233362174, \"precision\": 1.0, \"recall\": 0.00010527666378252473, \"specificity\": 1.0, \"npv\": 0.9997623775714194, \"accuracy\": 0.9997623775773643, \"f1\": 0.00021053116354652904, \"f2\": 0.00013159236632682937, \"f0_5\": 0.0005261617486985718, \"p4\": 0.0004209736884800873, \"phi\": 0.010259222567329546}, {\"truth_threshold\": 55.33999876305461, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 31.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303930.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 0.00010198676803932083, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9998980132319607, \"precision\": 1.0, \"recall\": 0.00010198676803932083, \"specificity\": 1.0, \"npv\": 0.9997623767897698, \"accuracy\": 0.999762376795529, \"f1\": 0.00020395273559830522, \"f2\": 0.00012748020972550632, \"f0_5\": 0.0005097258990085009, \"p4\": 0.0004078222848413003, \"phi\": 0.010097649905601715}, {\"truth_threshold\": 55.359998762607574, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 30.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303931.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 9.869687229611694e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999013031277039, \"precision\": 1.0, \"recall\": 9.869687229611694e-05, \"specificity\": 1.0, \"npv\": 0.9997623760081202, \"accuracy\": 0.9997623760136938, \"f1\": 0.00019737426436966884, \"f2\": 0.0001233680463600669, \"f0_5\": 0.0004932896169112835, \"p4\": 0.00039467062165832385, \"phi\": 0.009933449529309338}, {\"truth_threshold\": 55.399998761713505, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 24.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303937.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 7.895749783689355e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999210425021631, \"precision\": 1.0, \"recall\": 7.895749783689355e-05, \"specificity\": 1.0, \"npv\": 0.999762371318223, \"accuracy\": 0.9997623713226819, \"f1\": 0.00015790252808526738, \"f2\": 9.869492412005251e-05, \"f0_5\": 0.000394662842822234, \"p4\": 0.00031575519170219093, \"phi\": 0.00888474733860036}, {\"truth_threshold\": 55.4599987603724, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 23.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303938.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 7.566760209368965e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999243323979063, \"precision\": 1.0, \"recall\": 7.566760209368965e-05, \"specificity\": 1.0, \"npv\": 0.9997623705365735, \"accuracy\": 0.9997623705408466, \"f1\": 0.00015132375388178325, \"f2\": 9.458271340533133e-05, \"f0_5\": 0.000378223533397138, \"p4\": 0.0003026017114947341, \"phi\": 0.008697679072143635}, {\"truth_threshold\": 55.559998758137226, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 22.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303939.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 7.237770635048575e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999276222936495, \"precision\": 1.0, \"recall\": 7.237770635048575e-05, \"specificity\": 1.0, \"npv\": 0.9997623697549239, \"accuracy\": 0.9997623697590113, \"f1\": 0.00014474493639446943, \"f2\": 9.04704959263603e-05, \"f0_5\": 0.0003617837914283553, \"p4\": 0.0002894479716816115, \"phi\": 0.008506497940891283}, {\"truth_threshold\": 55.67999875545502, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 21.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303940.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.908781060728186e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999309121893927, \"precision\": 1.0, \"recall\": 6.908781060728186e-05, \"specificity\": 1.0, \"npv\": 0.9997623689732744, \"accuracy\": 0.999762368977176, \"f1\": 0.00013816607562289874, \"f2\": 8.635827168312271e-05, \"f0_5\": 0.00034534361689881433, \"p4\": 0.0002762939722551373, \"phi\": 0.008310920117526882}, {\"truth_threshold\": 55.77999875321984, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 20.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303941.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.579791486407796e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999934202085136, \"precision\": 1.0, \"recall\": 6.579791486407796e-05, \"specificity\": 1.0, \"npv\": 0.9997623681916249, \"accuracy\": 0.9997623681953407, \"f1\": 0.00013158717156664396, \"f2\": 8.224604067560188e-05, \"f0_5\": 0.0003289030097914426, \"p4\": 0.00026313971320762524, \"phi\": 0.008110627545793328}, {\"truth_threshold\": 55.87999875098467, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 19.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303942.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.250801912087407e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999374919808791, \"precision\": 1.0, \"recall\": 6.250801912087407e-05, \"specificity\": 1.0, \"npv\": 0.9997623674099754, \"accuracy\": 0.9997623674135054, \"f1\": 0.00012500822422527799, \"f2\": 7.81338029037811e-05, \"f0_5\": 0.00031246197008916675, \"p4\": 0.0002499851945313888, \"phi\": 0.007905261866528715}, {\"truth_threshold\": 55.99999874830246, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 18.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303943.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 5.921812337767016e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999407818766223, \"precision\": 1.0, \"recall\": 5.921812337767016e-05, \"specificity\": 1.0, \"npv\": 0.9997623666283258, \"accuracy\": 0.9997623666316701, \"f1\": 0.00011842923359837357, \"f2\": 7.40215583676437e-05, \"f0_5\": 0.00029602049777491257, \"p4\": 0.00023683041621874127, \"phi\": 0.007694416883386792}, {\"truth_threshold\": 56.03999874740839, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 17.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303944.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 5.5928227634466266e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999440717723656, \"precision\": 1.0, \"recall\": 5.5928227634466266e-05, \"specificity\": 1.0, \"npv\": 0.9997623658466763, \"accuracy\": 0.9997623658498348, \"f1\": 0.00011185019968550356, \"f2\": 6.990930706717297e-05, \"f0_5\": 0.0002795785928316049, \"p4\": 0.00022367537826199549, \"phi\": 0.007477629114729176}, {\"truth_threshold\": 56.15999874472618, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 16.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303945.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 5.2638331891262364e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999473616681087, \"precision\": 1.0, \"recall\": 5.2638331891262364e-05, \"specificity\": 1.0, \"npv\": 0.9997623650650268, \"accuracy\": 0.9997623650679994, \"f1\": 0.00010527112248624073, \"f2\": 6.579704900235225e-05, \"f0_5\": 0.0002631362552421676, \"p4\": 0.00021052008065346398, \"phi\": 0.00725436580168703}, {\"truth_threshold\": 56.45999873802066, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 13.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303948.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 4.2768644661650676e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999572313553383, \"precision\": 1.0, \"recall\": 4.2768644661650676e-05, \"specificity\": 1.0, \"npv\": 0.9997623627200782, \"accuracy\": 0.9997623627224935, \"f1\": 8.553363116582339e-05, \"f2\": 5.34602342216231e-05, \"f0_5\": 0.00021380664642630415, \"p4\": 0.00017105262984027676, \"phi\": 0.006538996959570125}, {\"truth_threshold\": 56.53999873623252, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 12.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303949.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 3.947874891844677e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999605212510816, \"precision\": 1.0, \"recall\": 3.947874891844677e-05, \"specificity\": 1.0, \"npv\": 0.9997623619384287, \"accuracy\": 0.9997623619406583, \"f1\": 7.895438081671727e-05, \"f2\": 4.9347949099235435e-05, \"f0_5\": 0.00019736257808156994, \"p4\": 0.00015789629354772232, \"phi\": 0.006282465062782326}, {\"truth_threshold\": 56.559998735785484, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 6.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303955.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 1.9739374459223386e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999802606255408, \"precision\": 1.0, \"recall\": 1.9739374459223386e-05, \"specificity\": 1.0, \"npv\": 0.9997623572485316, \"accuracy\": 0.9997623572496465, \"f1\": 3.9477969648021004e-05, \"f2\": 2.4674096311222602e-05, \"f0_5\": 9.868908005329211e-05, \"p4\": 7.89528220284883e-05, \"phi\": 0.004442373638041338}, {\"truth_threshold\": 56.87999872863293, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 5.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303956.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 1.644947871601949e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.999983550521284, \"precision\": 1.0, \"recall\": 1.644947871601949e-05, \"specificity\": 1.0, \"npv\": 0.9997623564668822, \"accuracy\": 0.9997623564678111, \"f1\": 3.289841627024075e-05, \"f2\": 2.056176383745021e-05, \"f0_5\": 8.224198222915248e-05, \"p4\": 6.579466774285809e-05, \"phi\": 0.0040553137491172574}, {\"truth_threshold\": 57.2399987205863, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 4.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303957.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 1.3159582972815591e-05, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999868404170272, \"precision\": 1.0, \"recall\": 1.3159582972815591e-05, \"specificity\": 1.0, \"npv\": 0.9997623556852326, \"accuracy\": 0.9997623556859758, \"f1\": 2.63188196009409e-05, \"f2\": 1.6449424599127523e-05, \"f0_5\": 6.579445155390046e-05, \"p4\": 5.263625371316953e-05, \"phi\": 0.003627182883828356}, {\"truth_threshold\": 57.259998720139265, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 3.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303958.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 9.869687229611693e-06, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999901303127704, \"precision\": 1.0, \"recall\": 9.869687229611693e-06, \"specificity\": 1.0, \"npv\": 0.9997623549035831, \"accuracy\": 0.9997623549041404, \"f1\": 1.9739179639694174e-05, \"f2\": 1.233707859623785e-05, \"f0_5\": 4.9346488010448293e-05, \"p4\": 3.9477579931731253e-05, \"phi\": 0.0031412325203394936}, {\"truth_threshold\": 58.27999869734049, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 2.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303959.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 6.5797914864077955e-06, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999934202085136, \"precision\": 1.0, \"recall\": 6.5797914864077955e-06, \"specificity\": 1.0, \"npv\": 0.9997623541219336, \"accuracy\": 0.9997623541223052, \"f1\": 1.3159496386073305e-05, \"f2\": 8.224725828764498e-06, \"f0_5\": 3.289809158170734e-05, \"p4\": 2.631864639085161e-05, \"phi\": 0.0025648056117535526}, {\"truth_threshold\": 59.079998679459095, \"match_probability\": 1.0, \"total_clerical_labels\": 1279041753.0, \"p\": 303961.0, \"n\": 1278737792.0, \"tp\": 1.0, \"tn\": 1278737792.0, \"fp\": 0.0, \"fn\": 303960.0, \"P_rate\": 0.00023764744136542664, \"N_rate\": 0.9997623525586345, \"tp_rate\": 3.2898957432038977e-06, \"tn_rate\": 1.0, \"fp_rate\": 0.0, \"fn_rate\": 0.9999967101042568, \"precision\": 1.0, \"recall\": 3.2898957432038977e-06, \"specificity\": 1.0, \"npv\": 0.9997623533402841, \"accuracy\": 0.9997623533404699, \"f1\": 6.579769839651009e-06, \"f2\": 4.112366296690779e-06, \"f0_5\": 1.644926225058806e-05, \"p4\": 1.3159453082838614e-05, \"phi\": 0.0018135914397872834}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linker.evaluation.accuracy_analysis_from_labels_column(\n",
    "    \"cluster\", output_type=\"roc\", match_weight_round_to_nearest=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:10:07.391167Z",
     "iopub.status.busy": "2024-06-07T09:10:07.390901Z",
     "iopub.status.idle": "2024-06-07T09:10:10.809464Z",
     "shell.execute_reply": "2024-06-07T09:10:10.808740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-30f46e85a4e44dfca423566652868fe3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-30f46e85a4e44dfca423566652868fe3.vega-embed details,\n",
       "  #altair-viz-30f46e85a4e44dfca423566652868fe3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-30f46e85a4e44dfca423566652868fe3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-30f46e85a4e44dfca423566652868fe3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-30f46e85a4e44dfca423566652868fe3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-6d8503d6a59f8a2e86436af7f8684650\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 57, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-6d8503d6a59f8a2e86436af7f8684650\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 24.043155919777696, \"log2_bayes_factor\": 4.587554372424933, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"georgie\", \"value_r\": \"george\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"gregory\", \"value_r\": \"gregory\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.8420757245086126, \"log2_bayes_factor\": -0.24797811995577201, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.19 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"gregory\", \"value_r\": \"gregory\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1849-01-01\", \"value_r\": \"1849-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"stroud\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.970658491459915, \"bayes_factor\": 1003.3842564076232, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2307260588972029, \"log2_bayes_factor\": 0.29950967534672124, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.23 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1830-11-20\", \"value_r\": \"1850-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8543585092023467, \"log2_bayes_factor\": 0.8909201918853701, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.85 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.997925725268708, \"bayes_factor\": 1022.5287735556542, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2307260588972029, \"log2_bayes_factor\": 0.29950967534672124, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.23 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1850-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8543585092023467, \"log2_bayes_factor\": 0.8909201918853701, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.85 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 9.997925725268708, \"bayes_factor\": 1022.5287735556542, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.11872295301233, \"bayes_factor\": 1111.8318904706177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.11872295301233, \"bayes_factor\": 1111.8318904706177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.11872295301233, \"bayes_factor\": 1111.8318904706177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.11872295301233, \"bayes_factor\": 1111.8318904706177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.11872295301233, \"bayes_factor\": 1111.8318904706177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"m9 6ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.11872295301233, \"bayes_factor\": 1111.8318904706177, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"georgie\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 5.509489833884195, \"log2_bayes_factor\": 2.4619187347309412, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 5.51 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"georgie\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.1851436122713805, \"log2_bayes_factor\": 0.2450618913243448, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.19 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-01-01\", \"value_r\": \"1857-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ip29 5qh\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football manager\", \"value_r\": \"rugby union player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.348013921975618, \"bayes_factor\": 1303.3545910052014, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 10}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 10}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 10}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 10}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 10}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 10}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 10}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 10}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 10}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 11}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 11}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 11}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 11}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 11}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 11}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 11}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 12}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 12}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 12}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 12}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 12}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 12}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 12}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 13}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 13}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 13}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 13}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 13}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 13}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 13}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 14}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 14}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 14}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 14}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 14}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 14}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 14}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 14}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 14}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 15}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 15}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 15}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 15}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 15}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 15}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 15}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 16}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 16}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 16}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 16}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 16}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 16}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 16}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 17}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 17}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 17}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 17}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 17}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"me17 4nw\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"maidstone\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 17}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.376720317423045, \"bayes_factor\": 1329.5481564228148, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 17}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 18}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 24.043155919777696, \"log2_bayes_factor\": 4.587554372424933, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"george\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 18}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 18}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 18}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.1851436122713805, \"log2_bayes_factor\": 0.2450618913243448, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.19 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"thom\", \"value_r\": \"thom\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 18}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-01-01\", \"value_r\": \"1857-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 18}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 18}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 18}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"rugby union player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 18}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 10.463698502740032, \"bayes_factor\": 1412.1704349440624, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 18}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 19}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 19}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 19}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 19}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8822869136074871, \"log2_bayes_factor\": 0.9124865522374742, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.88 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 19}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1499-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 19}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"essex\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 19}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 19}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 19}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.0633920523098, \"bayes_factor\": 2139.995507014684, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 19}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 20}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 20}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 20}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 20}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8822869136074871, \"log2_bayes_factor\": 0.9124865522374742, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.88 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 20}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1499-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 20}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"essex\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 20}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.0633920523098, \"bayes_factor\": 2139.995507014684, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 20}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 21}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 21}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 21}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 21}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8822869136074871, \"log2_bayes_factor\": 0.9124865522374742, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.88 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 21}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1499-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 21}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"essex\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 21}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.0633920523098, \"bayes_factor\": 2139.995507014684, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 21}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 22}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 22}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 22}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 22}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2307260588972029, \"log2_bayes_factor\": 0.29950967534672124, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.23 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 22}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 22}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 22}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8543585092023467, \"log2_bayes_factor\": 0.8909201918853701, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.85 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 22}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.646054393547955, \"bayes_factor\": 3204.879488435071, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 22}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 23}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 23}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 23}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 23}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 23}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-81\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 23}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol3 7ne\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 23}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 23}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 23}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 23}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 23}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.841378737775504, \"bayes_factor\": 3669.5278664592824, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 23}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 24}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 24}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 24}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 24}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 24}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-81\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 24}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol3 7ne\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 24}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 24}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 24}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.841378737775504, \"bayes_factor\": 3669.5278664592824, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 24}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 25}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 25}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 25}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 25}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8822869136074871, \"log2_bayes_factor\": 0.9124865522374742, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.88 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1544-01-01\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 25}, {\"sql_condition\": \"levenshtein(\\\"postcode_fake_l\\\", \\\"postcode_fake_r\\\") <= 2\", \"label_for_charts\": \"Levenshtein distance of postcode_fake <= 2\", \"m_probability\": 0.056075932948771445, \"u_probability\": 0.0005255426965321298, \"bayes_factor\": 106.70100320829626, \"log2_bayes_factor\": 6.737429930293483, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `levenshtein distance of postcode_fake <= 2` then comparison is 106.70 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4tl\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 25}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 25}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.2042374732027894, \"log2_bayes_factor\": 1.1402796608220873, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.20 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 25}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 11.860100605475015, \"bayes_factor\": 3717.457685826799, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 25}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 26}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"ed\", \"value_r\": \"ed\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 26}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 7.904920196442541, \"log2_bayes_factor\": 2.982750898032382, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 7.90 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"ed\", \"value_r\": \"ed\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thomas\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 26}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 26}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 26}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 26}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.7087170184046934, \"log2_bayes_factor\": 1.89092019188537, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.71 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 26}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.901636179698437, \"bayes_factor\": 7652.079673100087, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 26}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 27}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 24.043155919777696, \"log2_bayes_factor\": 4.587554372424933, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"willie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 27}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 27}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 27}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2307260588972029, \"log2_bayes_factor\": 0.29950967534672124, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.23 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 27}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 27}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 27}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8543585092023467, \"log2_bayes_factor\": 0.8909201918853701, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.85 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"wales\", \"value_r\": \"wales\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football manager\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 27}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 12.907055174613246, \"bayes_factor\": 7680.87616496785, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 27}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 28}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 24.043155919777696, \"log2_bayes_factor\": 4.587554372424933, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"will\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 28}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 28}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 28}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2307260588972029, \"log2_bayes_factor\": 0.29950967534672124, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.23 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 28}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"l37 5aa\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 28}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 28}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3362476534282113, \"log2_bayes_factor\": 0.41818741444495755, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 28}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.000291964192016, \"bayes_factor\": 8193.658016854437, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 28}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 29}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 29}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 29}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 29}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 29}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 29}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"ch42 0ns\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 29}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.369881800963869, \"bayes_factor\": 10586.087042047991, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 29}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 30}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 30}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 30}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 30}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 30}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 30}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"ch42 0ns\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 30}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.369881800963869, \"bayes_factor\": 10586.087042047991, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 30}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 31}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 31}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 31}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 31}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 31}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 31}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 31}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.369881800963869, \"bayes_factor\": 10586.087042047991, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 31}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 32}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 32}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 45.45329112954461, \"log2_bayes_factor\": 5.506312854089395, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 45.45 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"irwin\", \"value_r\": \"irwin\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 32}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 32}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7804604275933482, \"log2_bayes_factor\": -0.35760261113027025, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.28 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"bevan\", \"value_r\": \"bevan\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 32}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1852-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 32}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wales\", \"value_r\": \"wirral\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"visual artist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 32}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.369881800963869, \"bayes_factor\": 10586.087042047991, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 32}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 33}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 33}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 33}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 33}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 33}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 33}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"oswestry\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 33}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.971654801636351, \"bayes_factor\": 16065.23875917928, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 33}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 34}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 34}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 34}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 34}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 34}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 34}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"oswestry\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 34}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 13.971654801636351, \"bayes_factor\": 16065.23875917928, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 34}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 35}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 24.043155919777696, \"log2_bayes_factor\": 4.587554372424933, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"will\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 35}, {\"sql_condition\": \"jaro_winkler_similarity(\\\"first_name_l\\\", \\\"first_name_r\\\") >= 0.9\", \"label_for_charts\": \"Jaro-Winkler distance of first_name >= 0.9\", \"m_probability\": 0.10032523202258627, \"u_probability\": 0.004172714778265011, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 2, \"bayes_factor_description\": \"If comparison level is `jaro-winkler distance of first_name >= 0.9` then comparison is 24.04 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 35}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 35}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.2307260588972029, \"log2_bayes_factor\": 0.29950967534672124, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.23 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"owen\", \"value_r\": \"owen\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 35}, {\"sql_condition\": \"\\\"dob_l\\\" = \\\"dob_r\\\"\", \"label_for_charts\": \"Exact match on dob\", \"m_probability\": 0.6137512443354165, \"u_probability\": 0.001891143163086508, \"bayes_factor\": 324.5398107955623, \"log2_bayes_factor\": 8.342251652019065, \"comparison_vector_value\": 5, \"bayes_factor_description\": \"If comparison level is `exact match on dob` then comparison is 324.54 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-11-20\", \"value_r\": \"1860-11-20\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 35}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sw1p 4lg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 35}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 35}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.3362476534282113, \"log2_bayes_factor\": 0.41818741444495755, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 1.34 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"association football player\", \"value_r\": \"association football player\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 35}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 15.55168694496826, \"bayes_factor\": 48031.290304703194, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 35}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 36}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 36}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 36}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 36}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 36}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 36}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 36}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 36}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 36}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 15.599135884066413, \"bayes_factor\": 49637.26083581348, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 36}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 37}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 37}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 17.315539477921757, \"log2_bayes_factor\": 4.113995431310634, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison 17.32 times more likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"norman\", \"value_r\": \"norman\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 37}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 37}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.908988866484298, \"log2_bayes_factor\": 1.5405177748505163, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.91 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"macdougall\", \"value_r\": \"macdougall\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 37}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1852-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 37}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"dn32 0sd\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 37}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"north east lincolnshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 37}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.3886654951714915, \"log2_bayes_factor\": -1.3633990606720094, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.57 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"painter\", \"value_r\": \"painter\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 37}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 15.599135884066413, \"bayes_factor\": 49637.26083581348, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 37}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 38}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 38}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 38}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 38}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8822869136074871, \"log2_bayes_factor\": 0.9124865522374742, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.88 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1544-01-01\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 38}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 38}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 38}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.2042374732027894, \"log2_bayes_factor\": 1.1402796608220873, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.20 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 38}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 17.329212582789655, \"bayes_factor\": 164669.35661457683, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 38}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 39}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 39}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 39}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 39}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 39}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 39}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 39}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 39}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 39}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 18.305873920885062, \"bayes_factor\": 324053.8212497647, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 39}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 40}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 40}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 40}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 40}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 40}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 40}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 40}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 18.305873920885062, \"bayes_factor\": 324053.8212497647, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 40}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 41}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 41}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 41}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 41}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1680-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 41}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 41}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 21.523665584627, \"bayes_factor\": 3014872.5500689214, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 41}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 42}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 42}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 42}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 42}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1680-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 42}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 42}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 21.523665584627, \"bayes_factor\": 3014872.5500689214, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 42}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 43}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 43}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 43}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 43}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.8822869136074871, \"log2_bayes_factor\": 0.9124865522374742, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 1.88 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"barlow\", \"value_r\": \"barlow\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 43}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1498-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 43}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"cm3 4bs\", \"value_r\": \"cm3 4bs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.2042374732027894, \"log2_bayes_factor\": 1.1402796608220873, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 2.20 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"chelmsford\", \"value_r\": \"chelmsford\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"scientist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 43}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 22.175234823692264, \"bayes_factor\": 4735990.721005969, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 43}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 44}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 44}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5568550214951866, \"log2_bayes_factor\": -0.8446263274570361, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.80 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 44}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 44}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.9999649228539774, \"log2_bayes_factor\": -5.060651218650823e-05, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.00 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 44}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1655-01-11\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 44}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ec1m 3ln\", \"value_r\": \"ec1m 3ln\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7324425459545318, \"log2_bayes_factor\": -0.449212498379583, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison  1.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.41234142795872775, \"log2_bayes_factor\": -1.2780886787545982, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.43 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 44}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.10040005681167, \"bayes_factor\": 17986361.779243216, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 44}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 45}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 45}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.5568550214951866, \"log2_bayes_factor\": -0.8446263274570361, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.80 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"henry\", \"value_r\": \"henry\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 45}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 45}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.9999649228539774, \"log2_bayes_factor\": -5.060651218650823e-05, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.00 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"norfolk\", \"value_r\": \"norfolk\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 45}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1655-01-11\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 45}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ec1m 3ln\", \"value_r\": \"ec1m 3ln\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7324425459545318, \"log2_bayes_factor\": -0.449212498379583, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison  1.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"camden\", \"value_r\": \"camden\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.41234142795872775, \"log2_bayes_factor\": -1.2780886787545982, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison  2.43 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"politician\", \"value_r\": \"politician\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 45}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.10040005681167, \"bayes_factor\": 17986361.779243216, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 45}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 46}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 46}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 46}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 46}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 46}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 46}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 46}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.402027091444314, \"bayes_factor\": 22168796.13051127, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 46}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 47}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 47}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 47}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 47}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 47}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 47}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 47}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 24.402027091444314, \"bayes_factor\": 22168796.13051127, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 47}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 48}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 48}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7983014907494115, \"log2_bayes_factor\": -0.3249943897126558, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 48}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 48}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.133258502088485, \"log2_bayes_factor\": 1.093058797879295, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.13 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 48}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 48}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.7087170184046934, \"log2_bayes_factor\": 1.89092019188537, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.71 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 48}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.85873752716976, \"bayes_factor\": 486794466.2835595, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 48}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 49}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 49}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7983014907494115, \"log2_bayes_factor\": -0.3249943897126558, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 49}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 49}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.133258502088485, \"log2_bayes_factor\": 1.093058797879295, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.13 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 49}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 49}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.7087170184046934, \"log2_bayes_factor\": 1.89092019188537, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.71 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 49}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.85873752716976, \"bayes_factor\": 486794466.2835595, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 49}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 50}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 50}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7983014907494115, \"log2_bayes_factor\": -0.3249943897126558, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 50}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 50}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.133258502088485, \"log2_bayes_factor\": 1.093058797879295, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.13 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 50}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 50}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 50}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 50}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.7087170184046934, \"log2_bayes_factor\": 1.89092019188537, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.71 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 50}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 50}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 50}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.85873752716976, \"bayes_factor\": 486794466.2835595, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 50}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 51}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 51}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7983014907494115, \"log2_bayes_factor\": -0.3249943897126558, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"edward\", \"value_r\": \"edward\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 51}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 51}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.133258502088485, \"log2_bayes_factor\": 1.093058797879295, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison 2.13 times more likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"dyer\", \"value_r\": \"dyer\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 51}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-01-01\", \"value_r\": \"1851-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 51}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl2 8jb\", \"value_r\": \"gl2 8jb\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 51}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 51}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 3.7087170184046934, \"log2_bayes_factor\": 1.89092019188537, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 3.71 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"tewkesbury\", \"value_r\": \"tewkesbury\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 51}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 51}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 51}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 28.85873752716976, \"bayes_factor\": 486794466.2835595, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 51}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 52}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 52}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 52}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 52}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 52}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 52}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 52}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 52}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 52}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 52}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 52}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.512415828493186, \"bayes_factor\": 1531624851.981952, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 52}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 53}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 53}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 53}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 53}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 53}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 53}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 53}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 53}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 53}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 53}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 53}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.512415828493186, \"bayes_factor\": 1531624851.981952, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 53}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 54}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 54}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 54}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 54}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 54}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 54}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 54}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 54}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 54}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 54}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 54}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.512415828493186, \"bayes_factor\": 1531624851.981952, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 54}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 55}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 55}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 55}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 55}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 55}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 55}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 55}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 55}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 55}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 55}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 55}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.512415828493186, \"bayes_factor\": 1531624851.981952, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 55}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 56}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 56}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 56}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 56}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 56}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 56}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 56}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 56}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 56}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 56}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 56}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.512415828493186, \"bayes_factor\": 1531624851.981952, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 56}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 57}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Exact match on first_name\", \"m_probability\": 0.5521425828423275, \"u_probability\": 0.014397906556447383, \"bayes_factor\": 38.34880999384442, \"log2_bayes_factor\": 5.261109904881116, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on first_name` then comparison is 38.35 times more likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 57}, {\"sql_condition\": \"\\\"first_name_l\\\" = \\\"first_name_r\\\"\", \"label_for_charts\": \"Term freq adjustment on first_name with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.2616016755657244, \"log2_bayes_factor\": -1.934556313521475, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on first_name makes comparison  3.82 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"william\", \"value_r\": \"william\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 57}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Exact match on surname\", \"m_probability\": 0.7808979520654842, \"u_probability\": 0.0006946763678294353, \"bayes_factor\": 1124.1176297755087, \"log2_bayes_factor\": 10.134577294433035, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on surname` then comparison is 1,124.12 times more likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 57}, {\"sql_condition\": \"\\\"surname_l\\\" = \\\"surname_r\\\"\", \"label_for_charts\": \"Term freq adjustment on surname with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 0.7999719382831819, \"log2_bayes_factor\": -0.3219787013995489, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"Term frequency adjustment on surname makes comparison  1.25 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"cartwright\", \"value_r\": \"cartwright\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 57}, {\"sql_condition\": \"damerau_levenshtein(\\\"dob_l\\\", \\\"dob_r\\\") <= 1\", \"label_for_charts\": \"Damerau-Levenshtein distance of dob <= 1\", \"m_probability\": 0.3396908201996453, \"u_probability\": 0.019230847232137062, \"bayes_factor\": 17.6638510045455, \"log2_bayes_factor\": 4.142728002963574, \"comparison_vector_value\": 4, \"bayes_factor_description\": \"If comparison level is `damerau-levenshtein distance of dob <= 1` then comparison is 17.66 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1600-01-01\", \"value_r\": \"1606-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 57}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" = \\\"postcode_fake_r\\\"\", \"label_for_charts\": \"Exact match on postcode_fake\", \"m_probability\": 0.6870506533855032, \"u_probability\": 0.00014536287350888695, \"bayes_factor\": 4726.452063040013, \"log2_bayes_factor\": 12.206541907608122, \"comparison_vector_value\": 3, \"bayes_factor_description\": \"If comparison level is `exact match on postcode_fake` then comparison is 4,726.45 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sy10 8ra\", \"value_r\": \"sy10 8ra\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 57}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Exact match on birth_place\", \"m_probability\": 0.8438248944830462, \"u_probability\": 0.005352664822329286, \"bayes_factor\": 157.64575636474171, \"log2_bayes_factor\": 7.300542524693252, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on birth_place` then comparison is 157.65 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 57}, {\"sql_condition\": \"\\\"birth_place_l\\\" = \\\"birth_place_r\\\"\", \"label_for_charts\": \"Term freq adjustment on birth_place with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 1.374406895055857, \"log2_bayes_factor\": 0.45880917924758485, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on birth_place makes comparison 1.37 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"shropshire\", \"value_r\": \"shropshire\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 57}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Exact match on occupation\", \"m_probability\": 0.8988237439900274, \"u_probability\": 0.03667032589185728, \"bayes_factor\": 24.510928717696864, \"log2_bayes_factor\": 4.615353243760895, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `exact match on occupation` then comparison is 24.51 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 57}, {\"sql_condition\": \"\\\"occupation_l\\\" = \\\"occupation_r\\\"\", \"label_for_charts\": \"Term freq adjustment on occupation with weight {cl.tf_adjustment_weight}\", \"m_probability\": null, \"u_probability\": null, \"bayes_factor\": 2.818710855559814, \"log2_bayes_factor\": 1.4950354932879772, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"Term frequency adjustment on occupation makes comparison 2.82 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"actor\", \"value_r\": \"actor\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 57}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": 30.512415828493186, \"bayes_factor\": 1531624851.981952, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 57}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = linker.evaluation.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.999,\n",
    "    include_false_negatives=False,\n",
    "    include_false_positives=True,\n",
    ").as_record_dict()\n",
    "linker.visualisations.waterfall_chart(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-07T09:10:10.819376Z",
     "iopub.status.busy": "2024-06-07T09:10:10.818967Z",
     "iopub.status.idle": "2024-06-07T09:10:13.601958Z",
     "shell.execute_reply": "2024-06-07T09:10:13.601341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6a9dc7eacd4649e5be0b4d280ff5f037.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6a9dc7eacd4649e5be0b4d280ff5f037.vega-embed details,\n",
       "  #altair-viz-6a9dc7eacd4649e5be0b4d280ff5f037.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6a9dc7eacd4649e5be0b4d280ff5f037\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6a9dc7eacd4649e5be0b4d280ff5f037\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6a9dc7eacd4649e5be0b4d280ff5f037\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": \"rule\", \"encoding\": {\"color\": {\"value\": \"black\"}, \"size\": {\"value\": 0.5}, \"y\": {\"field\": \"zero\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.log2_bayes_factor < 0)\", \"value\": \"red\"}, \"value\": \"green\"}, \"opacity\": {\"condition\": {\"test\": \"datum.column_name == 'Prior match weight' || datum.column_name == 'Final score'\", \"value\": 1}, \"value\": 0.5}, \"tooltip\": [{\"field\": \"column_name\", \"title\": \"Comparison column\", \"type\": \"nominal\"}, {\"field\": \"value_l\", \"title\": \"Value (L)\", \"type\": \"nominal\"}, {\"field\": \"value_r\", \"title\": \"Value (R)\", \"type\": \"nominal\"}, {\"field\": \"label_for_charts\", \"title\": \"Label\", \"type\": \"ordinal\"}, {\"field\": \"sql_condition\", \"title\": \"SQL condition\", \"type\": \"nominal\"}, {\"field\": \"comparison_vector_value\", \"title\": \"Comparison vector value\", \"type\": \"nominal\"}, {\"field\": \"bayes_factor\", \"format\": \",.4f\", \"title\": \"Bayes factor = m/u\", \"type\": \"quantitative\"}, {\"field\": \"log2_bayes_factor\", \"format\": \",.4f\", \"title\": \"Match weight = log2(m/u)\", \"type\": \"quantitative\"}, {\"field\": \"prob\", \"format\": \".4f\", \"title\": \"Cumulative match probability\", \"type\": \"quantitative\"}, {\"field\": \"bayes_factor_description\", \"title\": \"Match weight description\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"grid\": true, \"labelAlign\": \"center\", \"labelAngle\": -20, \"labelExpr\": \"datum.value == 'Prior' || datum.value == 'Final score' ? '' : datum.value\", \"labelPadding\": 10, \"tickBand\": \"extent\", \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"grid\": false, \"orient\": \"left\", \"title\": \"Match Weight\"}, \"field\": \"previous_sum\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"sum\"}}}, {\"mark\": {\"type\": \"text\", \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"white\"}, \"text\": {\"condition\": {\"test\": \"abs(datum.log2_bayes_factor) > 1\", \"field\": \"log2_bayes_factor\", \"format\": \".2f\", \"type\": \"nominal\"}, \"value\": \"\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"orient\": \"left\"}, \"field\": \"center\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -25, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"column_name\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -13, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_l\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"bottom\", \"dy\": -5, \"fontSize\": 8}, \"encoding\": {\"color\": {\"value\": \"grey\"}, \"text\": {\"field\": \"value_r\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"y\": {\"field\": \"sum_top\", \"type\": \"quantitative\"}}}]}, {\"mark\": {\"type\": \"rule\", \"color\": \"black\", \"strokeWidth\": 2, \"x2Offset\": 30, \"xOffset\": -30}, \"encoding\": {\"x\": {\"axis\": {\"labelAngle\": -20, \"title\": \"Column\"}, \"field\": \"column_name\", \"sort\": {\"field\": \"bar_sort_order\", \"order\": \"ascending\"}, \"type\": \"nominal\"}, \"x2\": {\"field\": \"lead\"}, \"y\": {\"axis\": {\"labelExpr\": \"format(1 / (1 + pow(2, -1*datum.value)), '.2r')\", \"orient\": \"right\", \"title\": \"Probability\"}, \"field\": \"sum\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-e2fb615b67bcfa610bfc52e8ab0a1043\"}, \"height\": 450, \"params\": [{\"name\": \"record_number\", \"bind\": {\"input\": \"range\", \"max\": 49, \"min\": 0, \"step\": 1}, \"value\": 0}], \"resolve\": {\"axis\": {\"y\": \"independent\"}}, \"title\": {\"text\": \"Match weights waterfall chart\", \"subtitle\": \"How each comparison contributes to the final match score\"}, \"transform\": [{\"filter\": \"(datum.record_number == record_number)\"}, {\"filter\": \"(datum.bayes_factor !== 1.0)\"}, {\"window\": [{\"op\": \"sum\", \"field\": \"log2_bayes_factor\", \"as\": \"sum\"}, {\"op\": \"lead\", \"field\": \"column_name\", \"as\": \"lead\"}], \"frame\": [null, 0]}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" ? datum.sum - datum.log2_bayes_factor : datum.sum\", \"as\": \"sum\"}, {\"calculate\": \"datum.lead === null ? datum.column_name : datum.lead\", \"as\": \"lead\"}, {\"calculate\": \"datum.column_name === \\\"Final score\\\" || datum.column_name === \\\"Prior match weight\\\" ? 0 : datum.sum - datum.log2_bayes_factor\", \"as\": \"previous_sum\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"top_label\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.column_name : \\\"\\\"\", \"as\": \"bottom_label\"}, {\"calculate\": \"datum.sum > datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_top\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? datum.sum : datum.previous_sum\", \"as\": \"sum_bottom\"}, {\"calculate\": \"(datum.sum + datum.previous_sum) / 2\", \"as\": \"center\"}, {\"calculate\": \"(datum.log2_bayes_factor > 0 ? \\\"+\\\" : \\\"\\\") + datum.log2_bayes_factor\", \"as\": \"text_log2_bayes_factor\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? 4 : -4\", \"as\": \"dy\"}, {\"calculate\": \"datum.sum < datum.previous_sum ? \\\"top\\\" : \\\"bottom\\\"\", \"as\": \"baseline\"}, {\"calculate\": \"1. / (1 + pow(2, -1.*datum.sum))\", \"as\": \"prob\"}, {\"calculate\": \"0*datum.sum\", \"as\": \"zero\"}], \"width\": {\"step\": 75}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-e2fb615b67bcfa610bfc52e8ab0a1043\": [{\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"rt.\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"spicer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1817-03-16\", \"value_r\": \"1847-03-15\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 0}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"se5 7aq\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"southwark\", \"value_r\": \"brixton\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"businessperson\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 0}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 0}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -29.564786799116543, \"bayes_factor\": 1.259251155537776e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 0}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"joseph\", \"value_r\": \"jozef\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"conrad\", \"value_r\": \"korzeniowski\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-12-08\", \"value_r\": \"1857-42-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"fy6 8jx\", \"value_r\": \"fy3 9dl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 1}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"berdychiv\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 1}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"science fiction writer\", \"value_r\": \"autobiographer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 1}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 1}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -29.445161194025662, \"bayes_factor\": 1.3681170442112893e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 1}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"morfudd\", \"value_r\": \"anna\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"thomas\", \"value_r\": \"fison\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1889-02-14\", \"value_r\": \"1839-82-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ip6 8ru\", \"value_r\": \"ip14 2ae\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"mid suffolk\", \"value_r\": \"suffolk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 2}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 2}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 2}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 2}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.86502293194125, \"bayes_factor\": 2.0453247418802805e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 2}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"henfy\", \"value_r\": \"real\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stubbe\", \"value_r\": \"societies,\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1632-05-28\", \"value_r\": \"1622-02-28\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ln4 4qa\", \"value_r\": \"ln4 3lh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"lincolnshire\", \"value_r\": \"east lindsey\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 3}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 3}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"writer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 3}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 3}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.86502293194125, \"bayes_factor\": 2.0453247418802805e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 3}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"thomas\", \"value_r\": \"t.\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"whittaker\", \"value_r\": \"w-r\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1856-01-81\", \"value_r\": \"1856-04-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"pe15 0ds\", \"value_r\": \"pe14 9pa\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"fenland\", \"value_r\": \"march\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 4}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 4}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 4}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 4}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.86502293194125, \"bayes_factor\": 2.0453247418802805e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 4}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"jack\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"seigne\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1844-12-74\", \"value_r\": \"1844-02-14\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"yo17 6sb\", \"value_r\": \"yo60 7pl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"malton\", \"value_r\": \"ryedale\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 5}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 5}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"land agent\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 5}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 5}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.86502293194125, \"bayes_factor\": 2.0453247418802805e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 5}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"c.\", \"value_r\": \"charlotte\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"m.\", \"value_r\": \"duffield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1831-01-07\", \"value_r\": \"1831-21-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"se11 6ez\", \"value_r\": \"ba2 4ll\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"bath and north east somerset\", \"value_r\": \"bath\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 6}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 6}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 6}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 6}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.86502293194125, \"bayes_factor\": 2.0453247418802805e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 6}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-00-27\", \"value_r\": \"1851-02-27\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"bo0 8au\", \"value_r\": \"b14 6ph\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"solihull\", \"value_r\": \"cheswick green\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 7}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 7}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"military personnel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 7}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 7}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -28.86502293194125, \"bayes_factor\": 2.0453247418802805e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 7}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"harry\", \"value_r\": \"real\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stubbe\", \"value_r\": \"societies,\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 8}, {\"sql_condition\": \"ABS(EPOCH(try_strptime(\\\"dob_l\\\", '%Y-%m-%d')) - EPOCH(try_strptime(\\\"dob_r\\\", '%Y-%m-%d'))) <= 315576000.0\", \"label_for_charts\": \"Abs difference of 'transformed dob <= 10 year'\", \"m_probability\": 0.013464734404494298, \"u_probability\": 0.20047773757760617, \"bayes_factor\": 0.0671632400045517, \"log2_bayes_factor\": -3.896184361141375, \"comparison_vector_value\": 1, \"bayes_factor_description\": \"If comparison level is `abs difference of 'transformed dob <= 10 year'` then comparison is  14.89 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1632-02-26\", \"value_r\": \"1622-02-28\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ln4 4xt\", \"value_r\": \"ln4 3lh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"lincolnshire\", \"value_r\": \"east lindsey\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 8}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 8}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"classical philologist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 8}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 8}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.915185052180014, \"bayes_factor\": 3.9508629492571565e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 8}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"elizabeth\", \"value_r\": \"gabriel\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"siddal\", \"value_r\": \"dante\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 9}, {\"sql_condition\": \"\\\"dob_l\\\" IS NULL OR \\\"dob_r\\\" IS NULL\", \"label_for_charts\": \"dob is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `dob is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"None\", \"value_r\": \"1829-07-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"nw1 3jn\", \"value_r\": \"wc1r 4th\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"holborn\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"visual artist\", \"value_r\": \"model\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 9}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 9}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -27.27015953899018, \"bayes_factor\": 6.1782288656486526e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 9}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"lord\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"mcauley\", \"value_r\": \"babington\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1800-11-25\", \"value_r\": \"1880-10-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 10}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 10}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"rothley court\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 10}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 0.10502765432160308, \"log2_bayes_factor\": -3.251158847951538, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"historian\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 10}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.10117625600997256, \"u_probability\": 0.9633296741081427, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  9.52 times less likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 10}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.893766213249418, \"bayes_factor\": 8.019913301989631e-09, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 10}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"john\", \"value_r\": \"jack\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bond\", \"value_r\": \"pearce\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1855-01-01\", \"value_r\": \"1845-00-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 11}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"tf2 9tu\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"telford and wrekin\", \"value_r\": \"oakengates\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 11}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 11}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 11}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 11}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"5th\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"fletcher-vane\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1860-10-16\", \"value_r\": \"1861-70-16\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 12}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ch3 7ah\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"dublin\", \"value_r\": \"ireland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 12}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 12}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 12}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 12}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"5th\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"fletcher-vane\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1864-10-16\", \"value_r\": \"1861-70-16\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 13}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"bb1 4ah\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"dublin\", \"value_r\": \"ireland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 13}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 13}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 13}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 13}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"george\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"jeffreys\", \"value_r\": \"wem\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1675-05-15\", \"value_r\": \"1645-05-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 14}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ll13 7jb\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"wrexham\", \"value_r\": \"offa\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 14}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 14}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"judge\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 14}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 14}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 14}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"andrew\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"taylor\", \"value_r\": \"thomas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-10-18\", \"value_r\": \"1850-00-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 15}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"city of edinburgh\", \"value_r\": \"edinburgh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 15}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 15}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 15}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 15}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"flinders\", \"value_r\": \"william\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"petrie\", \"value_r\": \"flinders\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-08-03\", \"value_r\": \"1853-86-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 16}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"se7 8uq\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"charlton\", \"value_r\": \"greenwich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 16}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"egyptologist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 16}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 16}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 16}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bobby\", \"value_r\": \"robert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baron\", \"value_r\": \"chalmers\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1858-08-48\", \"value_r\": \"1858-09-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 17}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"rm2 6gp\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"stoke newington\", \"value_r\": \"hackney\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 17}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"politician\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 17}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 17}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 17}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"anne\", \"value_r\": \"julia\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cobden-sanderson\", \"value_r\": \"sarah\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-01-81\", \"value_r\": \"1883-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 18}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"n1 8sy\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"london\", \"value_r\": \"camden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 18}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 18}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 18}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 18}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"francesca\", \"value_r\": \"darley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"steele\", \"value_r\": \"dale\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1878-01-01\", \"value_r\": \"1849-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 19}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"pe19 6ry\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"huntingdonshire\", \"value_r\": \"yelling\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 19}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 19}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 19}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 19}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 19}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"trader\", \"value_r\": \"fred\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"horn\", \"value_r\": \"smythe\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1831-01-01\", \"value_r\": \"1861-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 20}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"ex20 1qt\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"west devon\", \"value_r\": \"belstone\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 20}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"adventurer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 20}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 20}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 20}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bobby\", \"value_r\": \"robert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baron\", \"value_r\": \"chalmers\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1858-08-48\", \"value_r\": \"1859-08-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 21}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"stoke newington\", \"value_r\": \"hackney\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 21}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 21}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 21}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 21}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"martin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"martin\", \"value_r\": \"allington\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1856-04-15\", \"value_r\": \"1856-04-72\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 22}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"me2 4sn\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"rochester\", \"value_r\": \"medway\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 22}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 22}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 22}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 22}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 22}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"john\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-23-07\", \"value_r\": \"1853-03-87\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 23}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"sk10 2ly\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"macclesfield\", \"value_r\": \"cheshire east\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 23}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 23}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 23}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 23}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 23}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"david\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"morrow\", \"value_r\": \"murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1848-01-29\", \"value_r\": \"1849-01-59\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 24}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"g5 9ne\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"glasgow city\", \"value_r\": \"glasgow\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 24}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 24}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 24}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 24}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"alexander\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"sprot\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-05-24\", \"value_r\": \"1853-24-24\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 25}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"gl7 6ew\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"cotswold\", \"value_r\": \"somerford keynes\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 25}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 25}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 25}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 25}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"thompson\", \"value_r\": \"ernest\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"meysey-thompson\", \"value_r\": \"thompson\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1829-02-18\", \"value_r\": \"1859-82-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 26}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sa14 7aq\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"carmarthenshire\", \"value_r\": \"gorslas\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 26}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 26}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 26}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 26}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"1st\", \"value_r\": \"georgie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1868-11-08\", \"value_r\": \"1860-71-08\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 27}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"renfrewshire\", \"value_r\": \"paisley\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 27}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 27}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 27}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 27}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 27}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"frank\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"adam\", \"value_r\": \"baronet\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1846-86-17\", \"value_r\": \"1846-06-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 28}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ne5 1ns\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"woolsington\", \"value_r\": \"newcastle upon tyne\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 28}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 28}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 28}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 28}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"arthur\", \"value_r\": \"young\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"perigal\", \"value_r\": \"artie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1816-88-17\", \"value_r\": \"1816-06-17\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 29}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"wc2r 0bp\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"westminster\", \"value_r\": \"london\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 29}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"painter\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 29}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 29}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 29}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"baron\", \"value_r\": \"6th\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"robartes\", \"value_r\": \"gowran\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1844-01-04\", \"value_r\": \"1844-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 30}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"w1h 7as\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"westminster\", \"value_r\": \"grosvenor place\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 30}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 30}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 30}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 30}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"dame\", \"value_r\": \"mary\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stewart-mackenzie\", \"value_r\": \"helier\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1842-05-18\", \"value_r\": \"1845-05-48\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 31}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"pe34 4px\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"germany\", \"value_r\": \"munich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 31}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"essayist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 31}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 31}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 31}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"dame\", \"value_r\": \"mary\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stewart-mackenzie\", \"value_r\": \"helier\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1842-05-18\", \"value_r\": \"1855-05-18\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 32}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"pe34 4px\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"germany\", \"value_r\": \"munich\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 32}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"essayist\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 32}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 32}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 32}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"2nd\", \"value_r\": \"sir\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"bt.\", \"value_r\": \"bonham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1857-08-28\", \"value_r\": \"1847-28-28\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 33}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"rhondda cynon taf\", \"value_r\": \"pont-y-clun\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 33}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"diplomat\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 33}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 33}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 33}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"james\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"morrow\", \"value_r\": \"wolfe-murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-03-18\", \"value_r\": \"1823-03-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 34}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"bl6 6bw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"ireland\", \"value_r\": \"ireland | united kingdom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 34}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"military personnel\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 34}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 34}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 34}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"james\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"murray\", \"value_r\": \"wolfe-murray\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1853-03-43\", \"value_r\": \"1823-03-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 35}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"bl6 6bw\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"ireland\", \"value_r\": \"ireland | united kingdom\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 35}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"military personnel\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 35}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 35}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 35}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"franciscus\", \"value_r\": \"the\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"junius\", \"value_r\": \"jon\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1581-01-29\", \"value_r\": \"1591-01-59\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 36}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"heidelberg\", \"value_r\": \"germany\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 36}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 36}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 36}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 36}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"eddie\", \"value_r\": \"edward\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"jack\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1805-12-07\", \"value_r\": \"1805-12-88\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 37}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"None\", \"value_r\": \"s43 3dt\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"staveley\", \"value_r\": \"chesterfield\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 37}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 37}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 37}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 37}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"william\", \"value_r\": \"fuller\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"fuller-maitland\", \"value_r\": \"maitland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1874-05-06\", \"value_r\": \"1844-05-03\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 38}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"bd20 9fa\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"bradford\", \"value_r\": \"silsden\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 38}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 38}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 38}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 38}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bert\", \"value_r\": \"herbie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"wight\", \"value_r\": \"white\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1838-01-01\", \"value_r\": \"1830-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 39}, {\"sql_condition\": \"\\\"postcode_fake_l\\\" IS NULL OR \\\"postcode_fake_r\\\" IS NULL\", \"label_for_charts\": \"postcode_fake is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `postcode_fake is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sr8 2pp\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 0.1570155571663566, \"log2_bayes_factor\": -2.671020585867125, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"easington village\", \"value_r\": \"county durham\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 39}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.1561751055169538, \"u_probability\": 0.9946473351776707, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  6.37 times less likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"cricketer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 39}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 39}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.313627951165003, \"bayes_factor\": 1.1989710364108961e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 39}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"owen\", \"value_r\": \"hugh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"hall\", \"value_r\": \"lusk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1887-01-01\", \"value_r\": \"1837-00-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 40}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"de45 1qs\", \"value_r\": \"ol6 8ug\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"tameside\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 40}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 40}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 40}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 40}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"owen\", \"value_r\": \"hugh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"hall\", \"value_r\": \"lusk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1887-01-01\", \"value_r\": \"1837-81-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 41}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"de45 1qs\", \"value_r\": \"ol14 7aq\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"tameside\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 41}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 41}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 41}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 41}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"owen\", \"value_r\": \"hugh\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"hall\", \"value_r\": \"lusk\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1887-01-01\", \"value_r\": \"1837-01-81\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 42}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"de45 1qs\", \"value_r\": \"ol6 8ug\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"tameside\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 42}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 42}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 42}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 42}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"hughes\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"lusk\", \"value_r\": \"hall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1837-00-01\", \"value_r\": \"1887-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 43}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol6 8ug\", \"value_r\": \"de45 1qs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tameside\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 43}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 43}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 43}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 43}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"hugh\", \"value_r\": \"owen\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"lusk\", \"value_r\": \"hall\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1831-01-01\", \"value_r\": \"1887-01-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 44}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"ol6 8ug\", \"value_r\": \"de45 1qs\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"tameside\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 44}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 44}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 44}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 44}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"bob\", \"value_r\": \"robert\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"stephenson\", \"value_r\": \"sitivensin\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1850-11-03\", \"value_r\": \"1850-17-13\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 45}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"e5 0ry\", \"value_r\": \"bh4 8an\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"edinburgh\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 45}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"short story writer\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 45}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 45}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 45}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"mr.\", \"value_r\": \"john\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"cousins\", \"value_r\": \"cozens\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1762-01-01\", \"value_r\": \"1752-81-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 46}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"w10 5az\", \"value_r\": \"w1t 2rf\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"london\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 46}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"artist\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 46}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 46}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 46}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"mrs.\", \"value_r\": \"annie\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"smyth\", \"value_r\": \"burnett-smith\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1849-07-08\", \"value_r\": \"1859-87-08\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 47}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"wf2 0xg\", \"value_r\": \"hg3 1tl\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"leeds\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 47}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"autobiographer\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 47}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 47}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 47}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"prince\", \"value_r\": \"fred\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"britain\", \"value_r\": \"ireland\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1760-09-22\", \"value_r\": \"1780-09-25\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 48}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"sl4 3dn\", \"value_r\": \"sl4 2jg\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"windsor castle\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 48}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 48}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 48}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 48}, {\"column_name\": \"Prior\", \"label_for_charts\": \"Starting match weight (prior)\", \"sql_condition\": null, \"log2_bayes_factor\": -12.845746707461347, \"bayes_factor\": 0.00013584539607096294, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 0, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 0.24042255008598706, \"log2_bayes_factor\": -2.0563558769934662, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"first_name\", \"value_l\": \"sir\", \"value_r\": \"1st\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 1, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.23431597896264, \"u_probability\": 0.974600672353059, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  4.16 times less likely to be a match\", \"column_name\": \"tf_first_name\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 2, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 0.06724251335324409, \"log2_bayes_factor\": -3.894482539940456, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"surname\", \"value_l\": \"baronet\", \"value_r\": \"bt.\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 3, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.06694967393729967, \"u_probability\": 0.9956450257234429, \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  14.87 times less likely to be a match\", \"column_name\": \"tf_surname\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 4, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.026077429203334265, \"u_probability\": 0.7500027040474182, \"bayes_factor\": 0.03476978024559968, \"log2_bayes_factor\": -4.84602224090261, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  28.76 times less likely to be a match\", \"column_name\": \"dob\", \"value_l\": \"1859-03-04\", \"value_r\": \"1859-83-01\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 5, \"record_number\": 49}, {\"sql_condition\": \"ELSE\", \"label_for_charts\": \"All other comparisons\", \"m_probability\": 0.17046156615157143, \"u_probability\": 0.9992470948602873, \"bayes_factor\": 0.17059000424254925, \"log2_bayes_factor\": -2.5513949807762453, \"comparison_vector_value\": 0, \"bayes_factor_description\": \"If comparison level is `all other comparisons` then comparison is  5.86 times less likely to be a match\", \"column_name\": \"postcode_fake\", \"value_l\": \"en3 7ne\", \"value_r\": \"cm2 8wq\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 6, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"birth_place\", \"value_l\": \"None\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 7, \"record_number\": 49}, {\"sql_condition\": \"\\\"birth_place_l\\\" IS NULL OR \\\"birth_place_r\\\" IS NULL\", \"label_for_charts\": \"birth_place is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `birth_place is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_birth_place\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 8, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"occupation\", \"value_l\": \"politician\", \"value_r\": \"None\", \"term_frequency_adjustment\": false, \"bar_sort_order\": 9, \"record_number\": 49}, {\"sql_condition\": \"\\\"occupation_l\\\" IS NULL OR \\\"occupation_r\\\" IS NULL\", \"label_for_charts\": \"occupation is NULL\", \"bayes_factor\": 1.0, \"log2_bayes_factor\": 0.0, \"comparison_vector_value\": -1, \"bayes_factor_description\": \"If comparison level is `occupation is null` then comparison is 1.00 times more likely to be a match\", \"column_name\": \"tf_occupation\", \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": true, \"bar_sort_order\": 10, \"record_number\": 49}, {\"column_name\": \"Final score\", \"label_for_charts\": \"Final score\", \"sql_condition\": null, \"log2_bayes_factor\": -26.194002346074125, \"bayes_factor\": 1.3026255351966673e-08, \"comparison_vector_value\": null, \"m_probability\": null, \"u_probability\": null, \"bayes_factor_description\": null, \"value_l\": \"\", \"value_r\": \"\", \"term_frequency_adjustment\": null, \"bar_sort_order\": 11, \"record_number\": 49}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the false negatives will be because they weren't detected by the blocking rules\n",
    "records = linker.evaluation.prediction_errors_from_labels_column(\n",
    "    \"cluster\",\n",
    "    threshold=0.5,\n",
    "    include_false_negatives=True,\n",
    "    include_false_positives=False,\n",
    ").as_record_dict(limit=50)\n",
    "\n",
    "linker.visualisations.waterfall_chart(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06545e908438426c8185e5bc9b35b182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fe1cfa86b4f4e9bbecf34be2378fbe7",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_40efa7951ddc4ca8bb74e0c91d1abf66",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "1e58ea15a76f4887b75ee41c6210f8bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "40efa7951ddc4ca8bb74e0c91d1abf66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "4816c47151d145b994566568e51c630c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5007a2aafc44df2b5a0932cc17d4a0c",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e58ea15a76f4887b75ee41c6210f8bd",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "5fcb5354d9c746bcbbd42fb211dc84ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "5fe1cfa86b4f4e9bbecf34be2378fbe7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "8d093bba3d464dafaebcaeb55dcbef47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f0a6693a457e40b68664a1569829e678",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ef73e739ae9e4d9e942ff4eb0ec2338c",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "9fe5f6a7b06a455fa9fb04d4088d3a78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fcb5354d9c746bcbbd42fb211dc84ec",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ad735d4f18bb437fb01e563f9175ba97",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     },
     "a5007a2aafc44df2b5a0932cc17d4a0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "ad735d4f18bb437fb01e563f9175ba97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "ef73e739ae9e4d9e942ff4eb0ec2338c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "f0a6693a457e40b68664a1569829e678": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
